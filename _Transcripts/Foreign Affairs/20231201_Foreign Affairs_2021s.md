---
Date Generated: June 19, 2025
Transcription Model: whisper medium 20231117
Length: 2021s
Video Keywords: ['Foreign Affairs', 'AI', 'Artificial Intelligence', 'Michèle A. Flournoy', 'Flournoy', 'Military', 'Drones', 'Shield AI', 'China', 'United States', 'Cold War', 'Beijing', 'Pentagon', 'Department of Defense', 'F-35', 'Russia', 'Ukraine', 'Putin', 'Rhombus Power', 'U.S. Strategic Command', 'Predictive AI', 'CIA', 'Intelligence', 'Deep State', 'Xi Jinping', 'Taiwan', 'Machine Learning', 'Replicator', 'People’s Liberation Army', 'Silicon Valley', 'Defense Department', 'H-1B', 'Congress', 'Immigration', 'Responsible AI', 'AI Warfare']
Video Views: 4543
Video Rating: None
Video Description: Foreign Affairs invites you to listen to its podcast, the Foreign Affairs Interview. This episode with Michèle Flournoy was originally published on November 30, 2023.
From killer robots to smarter logistics, artificial intelligence promises to change the way the U.S. military fights and develops weapons. As this new technology comes online, the opportunities are coming into focus—but so are the dangers.
In a new piece for Foreign Affairs, Michèle Flournoy argues the U.S. military has no choice but to move forward with AI and to do so quickly. Flournoy served as the Pentagon’s policy chief during the Obama administration and today is a co-founder and managing partner at the consulting company WestExec Advisors.
Deputy Editor Kate Brannen talked to her about how the U.S. Defense Department will need to change the way it does business if it wants to integrate AI safely and responsibly.
Sources:
“AI Is Already at War” by Michèle A. Flournoy
https://www.foreignaffairs.com/united-states/ai-already-war-flournoy
---

# How Will Artificial Intelligence Transform the Military? | Foreign Affairs Interview
**Foreign Affairs:** [December 01, 2023](https://www.youtube.com/watch?v=684UwOKut1Y)
*  I'm Dan Kurtz-Faelen and this is the Foreign Affairs Interview. [[00:00:00](https://www.youtube.com/watch?v=684UwOKut1Y&t=0.0s)]
*  If we stand still, I think we will cede a lot of the territory to China who may not have the same [[00:00:05](https://www.youtube.com/watch?v=684UwOKut1Y&t=5.44s)]
*  standards for security and safety, who may not be interested in the sort of norms and guardrails [[00:00:12](https://www.youtube.com/watch?v=684UwOKut1Y&t=12.16s)]
*  that we want to put in place. Hi everyone, I'm Kate Brannon, Deputy Editor at the Magazine, [[00:00:17](https://www.youtube.com/watch?v=684UwOKut1Y&t=17.68s)]
*  sitting in for Dan this week. From killer robots to smarter logistics, artificial intelligence [[00:00:25](https://www.youtube.com/watch?v=684UwOKut1Y&t=25.52s)]
*  promises to change the way the U.S. military fights and develops weapons. As this new technology [[00:00:31](https://www.youtube.com/watch?v=684UwOKut1Y&t=31.52s)]
*  comes online, the opportunities are coming into focus, but so are the dangers. In a new piece for [[00:00:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=36.879999999999995s)]
*  Foreign Affairs, Michelle Flournoy argues the U.S. military has no choice but to move forward with [[00:00:42](https://www.youtube.com/watch?v=684UwOKut1Y&t=42.56s)]
*  AI and to do so quickly. Flournoy served as the Pentagon's Policy Chief during the Obama [[00:00:48](https://www.youtube.com/watch?v=684UwOKut1Y&t=48.08s)]
*  administration. I talked to her about how the Defense Department will need to change the way [[00:00:53](https://www.youtube.com/watch?v=684UwOKut1Y&t=53.2s)]
*  it does business if it wants to integrate AI safely and responsibly. [[00:00:57](https://www.youtube.com/watch?v=684UwOKut1Y&t=57.92s)]
*  Michelle, thank you so much for joining us today and for your recent piece in Foreign Affairs titled [[00:01:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=69.04s)]
*  AI is Already at War. Well, good to see you. Thanks for including me. One of the most heated [[00:01:13](https://www.youtube.com/watch?v=684UwOKut1Y&t=73.60000000000001s)]
*  debates these days around artificial intelligence is about how quickly it should be developed and [[00:01:19](https://www.youtube.com/watch?v=684UwOKut1Y&t=79.44s)]
*  whether the United States can afford to slow down to put safeguards in place. You write in your piece [[00:01:24](https://www.youtube.com/watch?v=684UwOKut1Y&t=84.64s)]
*  is that the Pentagon needs to accelerate, not slow down its adoption of responsible AI. Why is it so [[00:01:30](https://www.youtube.com/watch?v=684UwOKut1Y&t=90.08s)]
*  important for the U.S. government to move full steam ahead? Well, I think it's important for [[00:01:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=96.32s)]
*  the national security community writ large to move forward with AI, but to do so with an eye [[00:01:42](https://www.youtube.com/watch?v=684UwOKut1Y&t=102.72s)]
*  towards safety. But the reason that we have to keep accelerating and moving forward is that this [[00:01:49](https://www.youtube.com/watch?v=684UwOKut1Y&t=109.28s)]
*  we're in a strategic competition with China, first and foremost, but other countries as well. And they [[00:01:54](https://www.youtube.com/watch?v=684UwOKut1Y&t=114.32s)]
*  are very quickly developing AI models and applications and they will be applying those [[00:02:01](https://www.youtube.com/watch?v=684UwOKut1Y&t=121.28s)]
*  in the field of the military and intelligence and so forth. And if there's a country that is a first [[00:02:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=129.52s)]
*  mover, they will gain tremendous advantage. So this is an area where the U.S. needs to compete. [[00:02:16](https://www.youtube.com/watch?v=684UwOKut1Y&t=136.88000000000002s)]
*  We're poised well to compete, but we're also have to do it responsibly and ensure that we're setting [[00:02:23](https://www.youtube.com/watch?v=684UwOKut1Y&t=143.04000000000002s)]
*  not only standards here at home, also trying to influence international standards. And when it [[00:02:28](https://www.youtube.com/watch?v=684UwOKut1Y&t=148.96s)]
*  comes to AI, what's the United States' competitive advantage when you look at the two countries? [[00:02:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=156.4s)]
*  I think our competitive advantage is the incredible innovation ecosystem that we've [[00:02:41](https://www.youtube.com/watch?v=684UwOKut1Y&t=161.84s)]
*  spawned in places like Silicon Valley, but more broadly. We have free flow of private capital. [[00:02:46](https://www.youtube.com/watch?v=684UwOKut1Y&t=166.88s)]
*  We attract some of the best talent from around the world. More than half the founders in Silicon [[00:02:53](https://www.youtube.com/watch?v=684UwOKut1Y&t=173.52s)]
*  Valley are either immigrants or first generation Americans who've come to this country to [[00:02:59](https://www.youtube.com/watch?v=684UwOKut1Y&t=179.12s)]
*  develop their companies. So we have incredible capital flow, talent, and a culture of innovation. [[00:03:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=184.96s)]
*  And so I think most of the AI innovation at this point is coming from inside the United States. [[00:03:12](https://www.youtube.com/watch?v=684UwOKut1Y&t=192.88s)]
*  That said, if you look at the human resources, the fiscal, the financial resources that China [[00:03:20](https://www.youtube.com/watch?v=684UwOKut1Y&t=200.0s)]
*  is throwing at the problem, they are definitely trying to keep up if not surpass us in some areas. [[00:03:26](https://www.youtube.com/watch?v=684UwOKut1Y&t=206.16s)]
*  So if we stand still, I think we will cede a lot of the territory to China who may not have the same [[00:03:32](https://www.youtube.com/watch?v=684UwOKut1Y&t=212.16s)]
*  standards for security and safety, who may not be interested in the sort of norms and guardrails that [[00:03:39](https://www.youtube.com/watch?v=684UwOKut1Y&t=219.68s)]
*  we want to put in place. And are there any other aspects of its system that let it move faster? [[00:03:45](https://www.youtube.com/watch?v=684UwOKut1Y&t=225.35999999999999s)]
*  Well, I think the primary aspect is that the state can direct capital to flow into priority areas in a [[00:03:51](https://www.youtube.com/watch?v=684UwOKut1Y&t=231.28s)]
*  way that just doesn't happen in the United States in our system. And they can also throw human talent [[00:03:58](https://www.youtube.com/watch?v=684UwOKut1Y&t=238.16s)]
*  at the problem. They can decide, okay, now we're going to switch the number of engineers we create [[00:04:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=244.72s)]
*  and put them all into AI and computer science. And so the state really controls the allocation [[00:04:11](https://www.youtube.com/watch?v=684UwOKut1Y&t=251.44s)]
*  of resources in a much more direct way than a free market system that we have here. [[00:04:18](https://www.youtube.com/watch?v=684UwOKut1Y&t=258.8s)]
*  I'm curious, were you ever an AI skeptic? And do you remember what tipped you into thinking [[00:04:25](https://www.youtube.com/watch?v=684UwOKut1Y&t=265.04s)]
*  this is really going to be revolutionary, especially when it comes to the military? [[00:04:30](https://www.youtube.com/watch?v=684UwOKut1Y&t=270.16s)]
*  I think I've always been concerned about the security and safety of AI. But I also see its [[00:04:34](https://www.youtube.com/watch?v=684UwOKut1Y&t=274.48s)]
*  tremendous potential to giving us an advantage, ultimately to deter and prevent conflict. That [[00:04:40](https://www.youtube.com/watch?v=684UwOKut1Y&t=280.96000000000004s)]
*  really is the name of the game here. And so I think it is a place where we have to be a leader, [[00:04:46](https://www.youtube.com/watch?v=684UwOKut1Y&t=286.96000000000004s)]
*  not only in developing new applications, but also ensuring the security of the data of the models [[00:04:53](https://www.youtube.com/watch?v=684UwOKut1Y&t=293.12s)]
*  of the applications and their safety, which is going to mean investing not just in the models [[00:04:59](https://www.youtube.com/watch?v=684UwOKut1Y&t=299.92s)]
*  and applications, but in the testing and evaluation infrastructure, in the cybersecurity elements, [[00:05:06](https://www.youtube.com/watch?v=684UwOKut1Y&t=306.24s)]
*  in the safety elements. But I think it's an opportunity for the United States to lead [[00:05:13](https://www.youtube.com/watch?v=684UwOKut1Y&t=313.28000000000003s)]
*  in responsible AI and to demonstrate to the world you can be a leader in AI and also a leader in [[00:05:19](https://www.youtube.com/watch?v=684UwOKut1Y&t=319.84s)]
*  safety and security. What's your understanding of when people talk about the danger of AI? What are [[00:05:25](https://www.youtube.com/watch?v=684UwOKut1Y&t=325.91999999999996s)]
*  they talking about? And what are sort of these worst case scenarios that we should legitimately [[00:05:31](https://www.youtube.com/watch?v=684UwOKut1Y&t=331.84s)]
*  be worried about? I think there are a couple of basic scenarios. One is that we get to a point [[00:05:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=336.55999999999995s)]
*  of what's called artificial general intelligence, which is you have a system that starts making [[00:05:42](https://www.youtube.com/watch?v=684UwOKut1Y&t=342.0s)]
*  decisions entirely separate from the human beings who created them and then somehow turns [[00:05:48](https://www.youtube.com/watch?v=684UwOKut1Y&t=348.48s)]
*  against the humans. This is the Space Odyssey 2001 kind of scenario with Hal the computer who [[00:05:55](https://www.youtube.com/watch?v=684UwOKut1Y&t=355.04s)]
*  decides to destroy the human. But I think the more near-term and realistic concerns are [[00:06:02](https://www.youtube.com/watch?v=684UwOKut1Y&t=362.88s)]
*  applications of AI where we prematurely take human beings out of the decision-making loop. [[00:06:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=369.6s)]
*  I think the case that worries people is the application of AI in very high-stake situations, [[00:06:17](https://www.youtube.com/watch?v=684UwOKut1Y&t=377.6s)]
*  such as a military situation where human life may be at stake without adequate human involvement [[00:06:25](https://www.youtube.com/watch?v=684UwOKut1Y&t=385.52000000000004s)]
*  in the decision-making about when lethal force is used. And again, both as a matter of policy [[00:06:32](https://www.youtube.com/watch?v=684UwOKut1Y&t=392.24s)]
*  and as a matter of design, that's one we can control for. That's one where we have agencies [[00:06:39](https://www.youtube.com/watch?v=684UwOKut1Y&t=399.28000000000003s)]
*  to decide on how limited or how broadly AI is used and what sort of applications are acceptable [[00:06:45](https://www.youtube.com/watch?v=684UwOKut1Y&t=405.36s)]
*  or not in terms of things that go towards full automation or AI working without a human in or [[00:06:53](https://www.youtube.com/watch?v=684UwOKut1Y&t=413.84000000000003s)]
*  on the loop. Is that a live debate inside the Defense Department? Absolutely. I mean, not only [[00:07:01](https://www.youtube.com/watch?v=684UwOKut1Y&t=421.6s)]
*  is there a framework for responsible AI, there's a much more specific policy on the use of fully [[00:07:07](https://www.youtube.com/watch?v=684UwOKut1Y&t=427.92s)]
*  autonomous weapons. And so this has been something that the department has been debating [[00:07:14](https://www.youtube.com/watch?v=684UwOKut1Y&t=434.0s)]
*  even before the latest kind of AI craze or the bursting of AI into the public consciousness. [[00:07:19](https://www.youtube.com/watch?v=684UwOKut1Y&t=439.36s)]
*  And there are ethical aspects, there are legal aspects, and there are also just fundamental [[00:07:26](https://www.youtube.com/watch?v=684UwOKut1Y&t=446.64s)]
*  command and control elements that, you know, what do commanders feel comfortable with in the field? [[00:07:32](https://www.youtube.com/watch?v=684UwOKut1Y&t=452.32s)]
*  Where are they willing to rely on AI and where are they not willing to rely? And that's going to [[00:07:38](https://www.youtube.com/watch?v=684UwOKut1Y&t=458.08s)]
*  evolve over time. But I don't think we're at any danger of the United States fielding killer robots [[00:07:43](https://www.youtube.com/watch?v=684UwOKut1Y&t=463.68s)]
*  that, you know, act freely without human oversight. Not in my lifetime, probably not in my children's [[00:07:51](https://www.youtube.com/watch?v=684UwOKut1Y&t=471.12s)]
*  lifetime, maybe never. When people talk about AI in the military, it often does go to kind of [[00:07:57](https://www.youtube.com/watch?v=684UwOKut1Y&t=477.92s)]
*  that killer robots, the AI making targeting decisions. I feel like that's what the public [[00:08:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=484.0s)]
*  is thinking about. But in your piece, you talk about all the ways AI can improve things like [[00:08:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=489.04s)]
*  procurement, weapons maintenance, logistics, which are giant parts of what the US military does. [[00:08:14](https://www.youtube.com/watch?v=684UwOKut1Y&t=494.64000000000004s)]
*  Could you talk a little bit more about what are some of these sort of mundane tasks, but that [[00:08:19](https://www.youtube.com/watch?v=684UwOKut1Y&t=499.68s)]
*  they're actually could be quite transformative when AI is applied to them? So the first is just [[00:08:23](https://www.youtube.com/watch?v=684UwOKut1Y&t=503.28000000000003s)]
*  really smart resource allocation decisions and understanding the second and third and fourth [[00:08:29](https://www.youtube.com/watch?v=684UwOKut1Y&t=509.36s)]
*  degree effects of making a certain budget decision or what have you. [[00:08:34](https://www.youtube.com/watch?v=684UwOKut1Y&t=514.8s)]
*  The second example is called predictive maintenance, where we're taking data off of [[00:08:39](https://www.youtube.com/watch?v=684UwOKut1Y&t=519.12s)]
*  weapons systems as they operate. And we're using machine learning and AI to get a much better sense [[00:08:44](https://www.youtube.com/watch?v=684UwOKut1Y&t=524.88s)]
*  of a part that's going to fail before it fails. So you can do preventative maintenance, and you can [[00:08:52](https://www.youtube.com/watch?v=684UwOKut1Y&t=532.0799999999999s)]
*  optimize maintenance schedules, and you're not doing things that aren't necessary and you are [[00:08:59](https://www.youtube.com/watch?v=684UwOKut1Y&t=539.4399999999999s)]
*  getting to things before there's catastrophic failure. So that's already in a documented way, [[00:09:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=544.4s)]
*  saving huge amounts of money. It has potential to save much more the more it's applied, but where [[00:09:10](https://www.youtube.com/watch?v=684UwOKut1Y&t=550.9599999999999s)]
*  it has been applied, it's having a meaningful creating meaningful savings for maintenance. [[00:09:16](https://www.youtube.com/watch?v=684UwOKut1Y&t=556.4s)]
*  A third example is predictive intelligence. So we have a number of situations where we're using AI [[00:09:21](https://www.youtube.com/watch?v=684UwOKut1Y&t=561.36s)]
*  to look at just vast quantities of data to try to recognize patterns of behavior, patterns of data [[00:09:29](https://www.youtube.com/watch?v=684UwOKut1Y&t=569.04s)]
*  that an analyst may not be easily discerned by a human analyst, and to sort of nominate those [[00:09:37](https://www.youtube.com/watch?v=684UwOKut1Y&t=577.4399999999999s)]
*  patterns for analysts to go deeper. And what's happening in reality is we're seeing indications [[00:09:46](https://www.youtube.com/watch?v=684UwOKut1Y&t=586.0s)]
*  of warnings of future events much earlier than we did before. And so in practical terms, [[00:09:52](https://www.youtube.com/watch?v=684UwOKut1Y&t=592.8000000000001s)]
*  when a decision maker has much more warning, whether it's the invasion of Ukraine or an [[00:10:00](https://www.youtube.com/watch?v=684UwOKut1Y&t=600.0s)]
*  operation that's happening in space by an adversary, you have more decision time, you have more time to [[00:10:05](https://www.youtube.com/watch?v=684UwOKut1Y&t=605.6s)]
*  look at options, you have more time to evaluate the pros and cons of different reactions or [[00:10:12](https://www.youtube.com/watch?v=684UwOKut1Y&t=612.88s)]
*  responses. So that's already here and now and starting to happen. It's not replacing [[00:10:18](https://www.youtube.com/watch?v=684UwOKut1Y&t=618.0s)]
*  human judgment or analysis, it is facilitating and making that better. [[00:10:24](https://www.youtube.com/watch?v=684UwOKut1Y&t=624.4s)]
*  Across industries, people are worried about AI making their jobs obsolete, myself included. [[00:10:31](https://www.youtube.com/watch?v=684UwOKut1Y&t=631.92s)]
*  But in the next 10 to 15 years, are there jobs in the military or at the Defense Department? Or maybe [[00:10:37](https://www.youtube.com/watch?v=684UwOKut1Y&t=637.2s)]
*  it's a longer timeline that you think will become obsolete because of AI? Or is that a discussion [[00:10:43](https://www.youtube.com/watch?v=684UwOKut1Y&t=643.04s)]
*  that's taking place? I don't think it's been a focus of the discussion yet, because I think most [[00:10:48](https://www.youtube.com/watch?v=684UwOKut1Y&t=648.7199999999999s)]
*  of the discussion in the Pentagon has been on operational applications, how is this going to [[00:10:55](https://www.youtube.com/watch?v=684UwOKut1Y&t=655.36s)]
*  help the warfighter, the decision maker, etc. But the Pentagon is one of the largest business [[00:11:00](https://www.youtube.com/watch?v=684UwOKut1Y&t=660.56s)]
*  enterprises in the world and to the extent you start applying AI to certain back office functions, [[00:11:07](https://www.youtube.com/watch?v=684UwOKut1Y&t=667.36s)]
*  like any business, there is the potential for you to, in some cases, maybe replace some people in [[00:11:13](https://www.youtube.com/watch?v=684UwOKut1Y&t=673.6800000000001s)]
*  terms of jobs, but more likely, even more likely, it's sort of a, if you upskill your workforce, [[00:11:20](https://www.youtube.com/watch?v=684UwOKut1Y&t=680.8000000000001s)]
*  AI is a productivity enhancer for the workforce that you have in terms it will help people [[00:11:27](https://www.youtube.com/watch?v=684UwOKut1Y&t=687.6800000000001s)]
*  be much more productive with data. I mean, the Department of Defense has massive amounts of data [[00:11:34](https://www.youtube.com/watch?v=684UwOKut1Y&t=694.32s)]
*  that it sits on, and most of that data is not actively used in the most productive way to inform [[00:11:42](https://www.youtube.com/watch?v=684UwOKut1Y&t=702.88s)]
*  the best resource allocation, the best decision making, and so forth. And so there's real [[00:11:51](https://www.youtube.com/watch?v=684UwOKut1Y&t=711.2s)]
*  opportunity there. And I think with some upskilling, you're more likely to see a more [[00:11:55](https://www.youtube.com/watch?v=684UwOKut1Y&t=715.5200000000001s)]
*  greater productivity of the workforce rather than a dramatic shrinking of the workforce. [[00:12:00](https://www.youtube.com/watch?v=684UwOKut1Y&t=720.56s)]
*  LESLIE KENDRICK Are there any areas of AI and ways that it could be applied [[00:12:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=724.4799999999999s)]
*  that seem overhyped to you? [[00:12:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=729.1999999999999s)]
*  KATE BAKER I think the overhyping is really like assuming a sort of fully automated and automatic [[00:12:10](https://www.youtube.com/watch?v=684UwOKut1Y&t=730.56s)]
*  type of warfare, which I just don't see us as a democracy adopting and I don't see our commanders [[00:12:18](https://www.youtube.com/watch?v=684UwOKut1Y&t=738.0799999999999s)]
*  seeking to implement. What I do see is AI being applied in ways that give human beings more agency [[00:12:26](https://www.youtube.com/watch?v=684UwOKut1Y&t=746.4s)]
*  and more effectiveness. [[00:12:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=756.64s)]
*  LESLIE KENDRICK Let's talk a little bit about regulation and making sure that AI is developed [[00:12:37](https://www.youtube.com/watch?v=684UwOKut1Y&t=757.52s)]
*  and used responsibly and ethically, as you write in your piece. I'm quoting you, [[00:12:42](https://www.youtube.com/watch?v=684UwOKut1Y&t=762.16s)]
*  the essential effort to simultaneously foster AI and put guardrails around its use, [[00:12:46](https://www.youtube.com/watch?v=684UwOKut1Y&t=766.3199999999999s)]
*  aims that are seemingly in tension, is underway. Is it fair to say that right now the fostering [[00:12:51](https://www.youtube.com/watch?v=684UwOKut1Y&t=771.04s)]
*  of new technology is really out ahead of the guardrails? Is there catching up that needs to [[00:12:57](https://www.youtube.com/watch?v=684UwOKut1Y&t=777.28s)]
*  be done? [[00:13:02](https://www.youtube.com/watch?v=684UwOKut1Y&t=782.24s)]
*  KATE BAKER I think in the commercial world with chat GPT and other recent developments, [[00:13:02](https://www.youtube.com/watch?v=684UwOKut1Y&t=782.64s)]
*  that may be a true statement. I think there are not clear guardrails in place yet, [[00:13:07](https://www.youtube.com/watch?v=684UwOKut1Y&t=787.92s)]
*  and people have raised very valid safety concerns, concerns of implicit bias, [[00:13:13](https://www.youtube.com/watch?v=684UwOKut1Y&t=793.52s)]
*  concerns about cybersecurity or data poisoning, unexplainability, lack of transparency, [[00:13:18](https://www.youtube.com/watch?v=684UwOKut1Y&t=798.96s)]
*  those sorts of things. But I think in the DOD context, there is a very clear framework. [[00:13:24](https://www.youtube.com/watch?v=684UwOKut1Y&t=804.88s)]
*  What I argue in the piece is that we need to resource the full implementation of that [[00:13:30](https://www.youtube.com/watch?v=684UwOKut1Y&t=810.72s)]
*  framework. So we need more people who are capable of testing and evaluating and verifying and [[00:13:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=816.4000000000001s)]
*  validating AI models before they're put into use in the field. We need more people who know how, [[00:13:43](https://www.youtube.com/watch?v=684UwOKut1Y&t=823.6s)]
*  that's not a one and done situation. Once something's in use, you've got to monitor it. [[00:13:51](https://www.youtube.com/watch?v=684UwOKut1Y&t=831.28s)]
*  Is it behaving as expected? Are there unexpected behaviors? If the latter, we need to take it [[00:13:55](https://www.youtube.com/watch?v=684UwOKut1Y&t=835.9200000000001s)]
*  offline, understand what's happening, correct it, et cetera. We need people who can recognize [[00:14:01](https://www.youtube.com/watch?v=684UwOKut1Y&t=841.2s)]
*  whether data has been poisoned or manipulated by the adversary to make the model behave [[00:14:06](https://www.youtube.com/watch?v=684UwOKut1Y&t=846.64s)]
*  differently. We need people who are looking at how is AI being used to accelerate cyber attacks [[00:14:13](https://www.youtube.com/watch?v=684UwOKut1Y&t=853.12s)]
*  and how do we combat that? There's just a lot of investment in human talent, both inside the [[00:14:20](https://www.youtube.com/watch?v=684UwOKut1Y&t=860.08s)]
*  government and leveraging outside talent, as well as rigorous protocols for testing and evaluating [[00:14:28](https://www.youtube.com/watch?v=684UwOKut1Y&t=868.08s)]
*  and monitoring AI when it is used at scale in the department. [[00:14:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=876.24s)]
*  The Defense Department's been talking for years about needing to do a better job recruiting the [[00:14:41](https://www.youtube.com/watch?v=684UwOKut1Y&t=881.9200000000001s)]
*  best talent for its tech workforce. Have you seen improvements over the years in that way, [[00:14:47](https://www.youtube.com/watch?v=684UwOKut1Y&t=887.2800000000001s)]
*  or what can actually make a difference in this area? I feel like that call is just always put [[00:14:53](https://www.youtube.com/watch?v=684UwOKut1Y&t=893.52s)]
*  out there, but I'm not sure what's changing. Yeah. I do think there have been some good [[00:14:59](https://www.youtube.com/watch?v=684UwOKut1Y&t=899.52s)]
*  pilots at a local level. The Air Force has a program called Kessel Run. The Army has [[00:15:05](https://www.youtube.com/watch?v=684UwOKut1Y&t=905.0400000000001s)]
*  started a software factory, but they're small and they're disaggregated. I think the first [[00:15:12](https://www.youtube.com/watch?v=684UwOKut1Y&t=912.8000000000001s)]
*  thing the military needs to do a better job of is to manage the tech savvy talent they have. [[00:15:21](https://www.youtube.com/watch?v=684UwOKut1Y&t=921.6s)]
*  Currently, if you have tech acumen or aptitude, that doesn't necessarily mean you'll be placed [[00:15:28](https://www.youtube.com/watch?v=684UwOKut1Y&t=928.64s)]
*  in a tech-related job. Even if you are in a tech-related job, it doesn't mean that there's a career [[00:15:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=936.56s)]
*  path that will keep you developing as a technologist. In fact, there isn't one right now in any of the [[00:15:42](https://www.youtube.com/watch?v=684UwOKut1Y&t=942.7199999999999s)]
*  services. How we manage tech savvy talent that we already have is job number one. The second is how [[00:15:47](https://www.youtube.com/watch?v=684UwOKut1Y&t=947.76s)]
*  do we create more of that talent? Here, borrowing from something that Eric Schmidt and the National [[00:15:56](https://www.youtube.com/watch?v=684UwOKut1Y&t=956.72s)]
*  Security Commission on AI talked about, I think we do need something like a digital academy, [[00:16:02](https://www.youtube.com/watch?v=684UwOKut1Y&t=962.8000000000001s)]
*  like another service academy where you'll get your education paid for at the university level, [[00:16:10](https://www.youtube.com/watch?v=684UwOKut1Y&t=970.4s)]
*  and then you commit to some number of years of service to the government or to the national [[00:16:17](https://www.youtube.com/watch?v=684UwOKut1Y&t=977.76s)]
*  security sector at large. That's one model. Another is the notion of a digital reserve core. [[00:16:22](https://www.youtube.com/watch?v=684UwOKut1Y&t=982.8s)]
*  There are people in Silicon Valley and other tech hubs around the country who would love to [[00:16:30](https://www.youtube.com/watch?v=684UwOKut1Y&t=990.24s)]
*  serve their country on weekends or two weeks a year, whatever the commitment is, [[00:16:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=996.8s)]
*  and there's no real pathway for them to do that right now. It's very, very minimal. [[00:16:41](https://www.youtube.com/watch?v=684UwOKut1Y&t=1001.28s)]
*  Then there's just the fact that we're never going to fully compete as a government for the best [[00:16:47](https://www.youtube.com/watch?v=684UwOKut1Y&t=1007.12s)]
*  tech talent with private industry, so we have to figure out better public-private partnerships [[00:16:51](https://www.youtube.com/watch?v=684UwOKut1Y&t=1011.92s)]
*  to leverage that talent from industry to help where we need it as well. The talent piece is [[00:16:56](https://www.youtube.com/watch?v=684UwOKut1Y&t=1016.7199999999999s)]
*  huge. It even extends to immigration policy. So much of our tech talent coming from outside the [[00:17:02](https://www.youtube.com/watch?v=684UwOKut1Y&t=1022.4s)]
*  United States, studying in our universities, we want to widen that pipeline, and we also want [[00:17:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=1029.92s)]
*  to encourage people to stay, build their businesses here, become American citizens, [[00:17:16](https://www.youtube.com/watch?v=684UwOKut1Y&t=1036.16s)]
*  and bring their talents to this country. We've got to do some targeted reform for high-tech [[00:17:21](https://www.youtube.com/watch?v=684UwOKut1Y&t=1041.8400000000001s)]
*  talent to bring more of them in and allow more of them to stay. [[00:17:30](https://www.youtube.com/watch?v=684UwOKut1Y&t=1050.5600000000002s)]
*  We'll be back after a short break. In a world where knowledge isn't just power, [[00:17:37](https://www.youtube.com/watch?v=684UwOKut1Y&t=1057.44s)]
*  but a means to ensure safety, security, and prosperity, the need for skilled intelligence [[00:17:42](https://www.youtube.com/watch?v=684UwOKut1Y&t=1062.72s)]
*  professionals has never been greater. At Georgetown University, our online masters [[00:17:47](https://www.youtube.com/watch?v=684UwOKut1Y&t=1067.92s)]
*  in applied intelligence offers concentrations in Homeland Security Intelligence, Cyber Intelligence, [[00:17:53](https://www.youtube.com/watch?v=684UwOKut1Y&t=1073.3600000000001s)]
*  Law Enforcement Intelligence, and Competitive Business Intelligence. For more information [[00:17:59](https://www.youtube.com/watch?v=684UwOKut1Y&t=1079.68s)]
*  or to apply, visit scs.georgetown.edu. [[00:18:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=1084.32s)]
*  To stay on the idea of more fusion between Silicon Valley and the Defense Department, [[00:18:13](https://www.youtube.com/watch?v=684UwOKut1Y&t=1093.52s)]
*  I used to be a defense reporter a million years ago, and when I covered the Pentagon, [[00:18:18](https://www.youtube.com/watch?v=684UwOKut1Y&t=1098.8s)]
*  I wrote about that clash of cultures between the Pentagon and Silicon Valley. In your current role [[00:18:22](https://www.youtube.com/watch?v=684UwOKut1Y&t=1102.8s)]
*  at WestExec Advisors, you often act as an intermediary between these tech companies and [[00:18:28](https://www.youtube.com/watch?v=684UwOKut1Y&t=1108.72s)]
*  the government. I'm curious what they say about their interactions with the Defense Department. [[00:18:34](https://www.youtube.com/watch?v=684UwOKut1Y&t=1114.24s)]
*  What are their impressions? What are their frustrations in terms of doing business? [[00:18:39](https://www.youtube.com/watch?v=684UwOKut1Y&t=1119.3600000000001s)]
*  I like to describe us as coaches and navigators. We don't do any representation or lobbying, but [[00:18:44](https://www.youtube.com/watch?v=684UwOKut1Y&t=1124.4s)]
*  we try to help them understand how working with the federal government is very different than [[00:18:50](https://www.youtube.com/watch?v=684UwOKut1Y&t=1130.72s)]
*  working with their commercial customers and how to navigate the maze. I think there is [[00:18:56](https://www.youtube.com/watch?v=684UwOKut1Y&t=1136.48s)]
*  a lot of frustration that there are still many, many obstacles. You have a company with cutting [[00:19:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=1144.32s)]
*  edge tech that's really relevant to a priority operational need. You have people in the military [[00:19:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=1149.92s)]
*  and in the department who want the technology or the capability, but that is not enough [[00:19:17](https://www.youtube.com/watch?v=684UwOKut1Y&t=1157.1200000000001s)]
*  to get them over the many, many hurdles to become a program of record and to have a production at [[00:19:24](https://www.youtube.com/watch?v=684UwOKut1Y&t=1164.8s)]
*  scale contract and so forth. We still make it much too hard for them. That said, I am seeing [[00:19:31](https://www.youtube.com/watch?v=684UwOKut1Y&t=1171.12s)]
*  companies become more sophisticated in how they do navigate. I am seeing the department making an [[00:19:40](https://www.youtube.com/watch?v=684UwOKut1Y&t=1180.3999999999999s)]
*  effort like reinvigorating and re-empowering DIU, creating the CDAO, the chief data and AI officer, [[00:19:46](https://www.youtube.com/watch?v=684UwOKut1Y&t=1186.32s)]
*  creating this Office of Strategic Capital. These are all efforts to try to close that gap and bridge [[00:19:56](https://www.youtube.com/watch?v=684UwOKut1Y&t=1196.96s)]
*  the so-called valley of death for these companies. I'm also seeing in this more volatile international [[00:20:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=1204.16s)]
*  environment, more of the investors being willing to play in the national security space, more venture [[00:20:11](https://www.youtube.com/watch?v=684UwOKut1Y&t=1211.52s)]
*  capital firms, private equity firms saying, hey, we're willing to be more patient capital because [[00:20:20](https://www.youtube.com/watch?v=684UwOKut1Y&t=1220.16s)]
*  we think this is so important for the nation. People are starting funds that are national [[00:20:25](https://www.youtube.com/watch?v=684UwOKut1Y&t=1225.44s)]
*  security focused, which just didn't happen five, 10 years ago. I am optimistic. I'm frustrated. I [[00:20:31](https://www.youtube.com/watch?v=684UwOKut1Y&t=1231.44s)]
*  want the pace of change to be faster than it is. On the flip side, you used to serve in the defense [[00:20:39](https://www.youtube.com/watch?v=684UwOKut1Y&t=1239.76s)]
*  department. What do they say about their private sector counterparts and do they have their own set [[00:20:47](https://www.youtube.com/watch?v=684UwOKut1Y&t=1247.12s)]
*  of frustrations? I think that most of the, there are many people who don't really understand the [[00:20:53](https://www.youtube.com/watch?v=684UwOKut1Y&t=1253.04s)]
*  life cycle of a venture-backed startup. It's hard for them to understand why they're so impatient. [[00:21:01](https://www.youtube.com/watch?v=684UwOKut1Y&t=1261.2s)]
*  They don't understand that they've got to show a return on investment in a relatively short amount [[00:21:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=1269.76s)]
*  of time to be able to continue to attract capital and continue to exist and grow as a company. [[00:21:14](https://www.youtube.com/watch?v=684UwOKut1Y&t=1274.64s)]
*  To be fair, I think what the department needs to do is actually create a separate cadre of [[00:21:20](https://www.youtube.com/watch?v=684UwOKut1Y&t=1280.32s)]
*  acquisition professionals that are really educated and trained on commercial tech [[00:21:27](https://www.youtube.com/watch?v=684UwOKut1Y&t=1287.52s)]
*  and development and particularly software-driven tech, which most of these are, and the agile [[00:21:34](https://www.youtube.com/watch?v=684UwOKut1Y&t=1294.24s)]
*  development process, the venture-backed ecosystem to understand how to work with these companies [[00:21:40](https://www.youtube.com/watch?v=684UwOKut1Y&t=1300.32s)]
*  more effectively, to have a different risk tolerance, and to have our acquisition folks [[00:21:49](https://www.youtube.com/watch?v=684UwOKut1Y&t=1309.1200000000001s)]
*  be rewarded and promoted for a different set of behaviors than the ones you want the folks who [[00:22:00](https://www.youtube.com/watch?v=684UwOKut1Y&t=1320.32s)]
*  are doing a 10 or 15-year procurement of an aircraft carrier. We understand why we want them to be [[00:22:07](https://www.youtube.com/watch?v=684UwOKut1Y&t=1327.28s)]
*  risk-averse and focused on keeping things on schedule and to requirements and on cost. [[00:22:14](https://www.youtube.com/watch?v=684UwOKut1Y&t=1334.3999999999999s)]
*  But when you're working with a company who's developing a product where each of the companies [[00:22:22](https://www.youtube.com/watch?v=684UwOKut1Y&t=1342.48s)]
*  is three to six months cycles, the current requirements-driven acquisition system does not [[00:22:28](https://www.youtube.com/watch?v=684UwOKut1Y&t=1348.64s)]
*  work for that type of capability, and so you need a different approach. [[00:22:34](https://www.youtube.com/watch?v=684UwOKut1Y&t=1354.64s)]
*  When you look to Congress to regulate the industry, it's proven fairly inept or inactive when it comes [[00:22:41](https://www.youtube.com/watch?v=684UwOKut1Y&t=1361.5200000000002s)]
*  to regulating tech companies so far, especially in the social media space. Do you think it'll be any [[00:22:48](https://www.youtube.com/watch?v=684UwOKut1Y&t=1368.8000000000002s)]
*  different this time with AI? Is it wrong to expect Congress to step in and make sure things are [[00:22:54](https://www.youtube.com/watch?v=684UwOKut1Y&t=1374.24s)]
*  developed safely? I do think that there will be some move towards regulation. You see right now, [[00:22:59](https://www.youtube.com/watch?v=684UwOKut1Y&t=1379.84s)]
*  particularly in the Senate, but to a degree in the House, real serious efforts for members to educate [[00:23:08](https://www.youtube.com/watch?v=684UwOKut1Y&t=1388.88s)]
*  themselves about the technology, both the potential positives, but also the dangers. [[00:23:17](https://www.youtube.com/watch?v=684UwOKut1Y&t=1397.12s)]
*  And I think actually Leader Schumer is taking an approach that was very similar to what they did [[00:23:23](https://www.youtube.com/watch?v=684UwOKut1Y&t=1403.6s)]
*  as a precursor to the CHIPS Act, where they spent a lot of time learning about the semiconductor [[00:23:29](https://www.youtube.com/watch?v=684UwOKut1Y&t=1409.9199999999998s)]
*  industry and the state of the competition and so forth. So I'm hoping that that kind of process [[00:23:35](https://www.youtube.com/watch?v=684UwOKut1Y&t=1415.76s)]
*  will yield some smart regulatory frameworks that make a positive contribution in terms of [[00:23:44](https://www.youtube.com/watch?v=684UwOKut1Y&t=1424.24s)]
*  safety and security while not being overly heavy-handed and thwarting innovation [[00:23:57](https://www.youtube.com/watch?v=684UwOKut1Y&t=1437.52s)]
*  and the speed of adoption. So it's a threading a needle, and [[00:24:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=1444.72s)]
*  regulation, you know, legislation can be a blunt instrument, but I think [[00:24:10](https://www.youtube.com/watch?v=684UwOKut1Y&t=1450.88s)]
*  if they set up some mechanisms for doing this over time, I think, you know, that could be a [[00:24:15](https://www.youtube.com/watch?v=684UwOKut1Y&t=1455.8400000000001s)]
*  very important investment for the nation. As I was preparing for this, I was thinking a lot about [[00:24:23](https://www.youtube.com/watch?v=684UwOKut1Y&t=1463.68s)]
*  how important leadership is to maintaining this commitment to responsibility and safety. It requires [[00:24:29](https://www.youtube.com/watch?v=684UwOKut1Y&t=1469.52s)]
*  a lot of work. I think there's responsible leaders in the private sector, responsible leaders in the [[00:24:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=1476.24s)]
*  military, responsible leaders at the White House. Does responsible AI depend on having [[00:24:40](https://www.youtube.com/watch?v=684UwOKut1Y&t=1480.64s)]
*  responsible leaders in business and in government? I do think at this moment when we don't have all [[00:24:46](https://www.youtube.com/watch?v=684UwOKut1Y&t=1486.56s)]
*  of the systems and mechanisms in place, the leadership component is even more important [[00:24:54](https://www.youtube.com/watch?v=684UwOKut1Y&t=1494.0s)]
*  because, you know, we're in the infancy of sort of figuring out how we're going to construct a [[00:25:02](https://www.youtube.com/watch?v=684UwOKut1Y&t=1502.24s)]
*  system that keeps our applications of AI responsible and safe. I think the name of the game for the [[00:25:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=1509.28s)]
*  Pentagon is to bake it into their normal processes so that there's a certain approach to testing and [[00:25:20](https://www.youtube.com/watch?v=684UwOKut1Y&t=1520.16s)]
*  evaluation. There's a certain set of requirements that are put into contracts in terms of data, [[00:25:27](https://www.youtube.com/watch?v=684UwOKut1Y&t=1527.2s)]
*  sources, and transparency so that vendors have to meet those as a matter of a first principle. [[00:25:34](https://www.youtube.com/watch?v=684UwOKut1Y&t=1534.96s)]
*  The more we can figure out how to bake this into our processes, the less it will depend on an [[00:25:43](https://www.youtube.com/watch?v=684UwOKut1Y&t=1543.28s)]
*  individual leader focusing on this and driving the change, and the more it will become part of this [[00:25:49](https://www.youtube.com/watch?v=684UwOKut1Y&t=1549.92s)]
*  systemic effort. Okay, but we're not there yet. We're at the sort of nascent phase. We're at the very early stages of that, [[00:25:56](https://www.youtube.com/watch?v=684UwOKut1Y&t=1556.32s)]
*  and I think trying to figure out how to, you know, what the guardrails should be and then how to [[00:26:03](https://www.youtube.com/watch?v=684UwOKut1Y&t=1563.28s)]
*  systematize them is, you know, we're at the earliest stages of that. Before we close, I'd love to zoom [[00:26:08](https://www.youtube.com/watch?v=684UwOKut1Y&t=1568.8s)]
*  out and ask a few bigger picture questions. There seems to be a consensus that we're at a geostrategic [[00:26:15](https://www.youtube.com/watch?v=684UwOKut1Y&t=1575.12s)]
*  inflection point these days. You hear that term a lot. If so, I'd love to know what you think we're [[00:26:21](https://www.youtube.com/watch?v=684UwOKut1Y&t=1581.52s)]
*  leaving behind and what will define this new era if we know yet. Well, I think we are moving into a [[00:26:27](https://www.youtube.com/watch?v=684UwOKut1Y&t=1587.44s)]
*  much more multipolar competitive environment where you have numerous countries that can exercise some [[00:26:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=1596.4s)]
*  power and influence, whether it's a rising China or a declining Russia, but that's still powerful [[00:26:48](https://www.youtube.com/watch?v=684UwOKut1Y&t=1608.8s)]
*  enough to, you know, start a war in Europe, which we had thought was, you know, Europe whole, [[00:26:55](https://www.youtube.com/watch?v=684UwOKut1Y&t=1615.92s)]
*  free, and at peace. Well, no longer because of Vladimir Putin. And you see other countries [[00:27:02](https://www.youtube.com/watch?v=684UwOKut1Y&t=1622.08s)]
*  not aligning necessarily with either whole or any, you know, on a permanent basis, [[00:27:10](https://www.youtube.com/watch?v=684UwOKut1Y&t=1630.0s)]
*  but acting more like swing states, like, you know, a number of countries in Asia want China as their [[00:27:20](https://www.youtube.com/watch?v=684UwOKut1Y&t=1640.0s)]
*  primary, see China as their primary trading partner, but they count on the U.S. as their [[00:27:26](https://www.youtube.com/watch?v=684UwOKut1Y&t=1646.32s)]
*  most important security partner. You see Gulf states swinging between the U.S. and China to see [[00:27:32](https://www.youtube.com/watch?v=684UwOKut1Y&t=1652.96s)]
*  who's going to give them the best deal on a given issue. You see the global south also kind of [[00:27:39](https://www.youtube.com/watch?v=684UwOKut1Y&t=1659.12s)]
*  wanting to stay out of these, you know, the strategic competition between the U.S. and China, [[00:27:47](https://www.youtube.com/watch?v=684UwOKut1Y&t=1667.28s)]
*  but again, some, you know, often aligning with China, which has invested heavily in their [[00:27:53](https://www.youtube.com/watch?v=684UwOKut1Y&t=1673.6s)]
*  infrastructure through the Belt and Road Initiative, but also wanting certain protections and [[00:27:59](https://www.youtube.com/watch?v=684UwOKut1Y&t=1679.4399999999998s)]
*  investments from the United States. So things are in flux. The international order, the inherited [[00:28:05](https://www.youtube.com/watch?v=684UwOKut1Y&t=1685.2s)]
*  rules that we architected after World War II are now being challenged by both Russia and China [[00:28:12](https://www.youtube.com/watch?v=684UwOKut1Y&t=1692.56s)]
*  and others like Iran. So it's just a much more volatile, much more uncertain environment [[00:28:18](https://www.youtube.com/watch?v=684UwOKut1Y&t=1698.96s)]
*  that I think will be more multipolar and more chaotic for a while. [[00:28:25](https://www.youtube.com/watch?v=684UwOKut1Y&t=1705.1200000000001s)]
*  For you, what are the open questions of this new era? I guess the main one is sort of where it is [[00:28:30](https://www.youtube.com/watch?v=684UwOKut1Y&t=1710.24s)]
*  in such a volatile, multipolar time, who gets on top or who outpaces whom, [[00:28:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=1716.88s)]
*  but what are the open questions for you? I think the number one in my mind is, [[00:28:43](https://www.youtube.com/watch?v=684UwOKut1Y&t=1723.76s)]
*  how do we prevent the competition from becoming conflict? Because I think an actual war between [[00:28:49](https://www.youtube.com/watch?v=684UwOKut1Y&t=1729.04s)]
*  the United States and China, two nuclear-armed powers, would be catastrophic. I mean, not only [[00:28:55](https://www.youtube.com/watch?v=684UwOKut1Y&t=1735.68s)]
*  for them, but for the region, for the world, the global economy. There's so much that's integrated [[00:29:03](https://www.youtube.com/watch?v=684UwOKut1Y&t=1743.6000000000001s)]
*  now that everyone would feel the effects of something like that. So I think managing [[00:29:12](https://www.youtube.com/watch?v=684UwOKut1Y&t=1752.16s)]
*  competition so that it does not become conflict is number one. Number two is creating some space [[00:29:21](https://www.youtube.com/watch?v=684UwOKut1Y&t=1761.28s)]
*  for cooperation where we can, because we cannot solve or manage climate change and its impacts [[00:29:28](https://www.youtube.com/watch?v=684UwOKut1Y&t=1768.3999999999999s)]
*  without some collaboration between the United States and China and other great powers. [[00:29:38](https://www.youtube.com/watch?v=684UwOKut1Y&t=1778.8s)]
*  We can't prevent the next pandemic without some cooperation. We can't [[00:29:44](https://www.youtube.com/watch?v=684UwOKut1Y&t=1784.8s)]
*  prevent further nuclear proliferation without cooperation. So we have got to somehow carve out [[00:29:49](https://www.youtube.com/watch?v=684UwOKut1Y&t=1789.8400000000001s)]
*  space for cooperation when it's in our interests to do so. And then I think the kind of discussion [[00:29:56](https://www.youtube.com/watch?v=684UwOKut1Y&t=1796.0s)]
*  we've been having here on AI, AI is not the only disruptive technology out there. There's synthetic [[00:30:08](https://www.youtube.com/watch?v=684UwOKut1Y&t=1808.16s)]
*  bio. And when you combine AI with synthetic bio, you can enter a world where an individual or a [[00:30:15](https://www.youtube.com/watch?v=684UwOKut1Y&t=1815.68s)]
*  very small group of people can do very dangerous things like design a new pathogen for use as a [[00:30:22](https://www.youtube.com/watch?v=684UwOKut1Y&t=1822.48s)]
*  biotero weapon. So we've got to start thinking about the sort of safety and security guardrails [[00:30:29](https://www.youtube.com/watch?v=684UwOKut1Y&t=1829.28s)]
*  across a number of disruptive technologies, not just AI. [[00:30:36](https://www.youtube.com/watch?v=684UwOKut1Y&t=1836.5600000000002s)]
*  What are you worried about in the near term, even over the next six months? What are you, [[00:30:41](https://www.youtube.com/watch?v=684UwOKut1Y&t=1841.3600000000001s)]
*  sort of what's most concerning to you as you look at the world? [[00:30:46](https://www.youtube.com/watch?v=684UwOKut1Y&t=1846.08s)]
*  I'm worried about conflict escalating as a result of miscalculation, be it in Ukraine or with Israel [[00:30:49](https://www.youtube.com/watch?v=684UwOKut1Y&t=1849.3600000000001s)]
*  and Iran potentially. I don't think that's the likely outcome in either case, but I think it's [[00:31:00](https://www.youtube.com/watch?v=684UwOKut1Y&t=1860.8s)]
*  a very real risk. I worry about our own degree of domestic polarization and dysfunction [[00:31:06](https://www.youtube.com/watch?v=684UwOKut1Y&t=1866.08s)]
*  preventing us from doing what we need to do to keep competing effectively and to safeguard [[00:31:18](https://www.youtube.com/watch?v=684UwOKut1Y&t=1878.08s)]
*  our national security. A concrete example, you know, if we live with a continuing resolution [[00:31:25](https://www.youtube.com/watch?v=684UwOKut1Y&t=1885.6s)]
*  for all of 2024 or a series of them, those don't allow any new starts in defense. So any new [[00:31:31](https://www.youtube.com/watch?v=684UwOKut1Y&t=1891.68s)]
*  investments that we are trying to make to give our commanders new tools to ensure deterrence and that [[00:31:38](https://www.youtube.com/watch?v=684UwOKut1Y&t=1898.8s)]
*  you know, she doesn't go to war over Taiwan, for example, none of those are possible with a continuing [[00:31:45](https://www.youtube.com/watch?v=684UwOKut1Y&t=1905.92s)]
*  resolution. So we can be our own worst enemy if we're not careful. We have to make sure that we, [[00:31:51](https://www.youtube.com/watch?v=684UwOKut1Y&t=1911.92s)]
*  you know, we rise above our politics. I know this sounds naive, but it's really a national [[00:31:59](https://www.youtube.com/watch?v=684UwOKut1Y&t=1919.44s)]
*  security imperative that we get beyond some of these political issues to focus on safeguarding [[00:32:06](https://www.youtube.com/watch?v=684UwOKut1Y&t=1926.0800000000002s)]
*  national security. Another example is, you know, the hold that's been put on, you know, hundreds and [[00:32:12](https://www.youtube.com/watch?v=684UwOKut1Y&t=1932.72s)]
*  hundreds of senior officers in the military, the input, what that's doing to them, what that's [[00:32:18](https://www.youtube.com/watch?v=684UwOKut1Y&t=1938.96s)]
*  doing to their families, but also what it's doing in the system, which is really preventing [[00:32:24](https://www.youtube.com/watch?v=684UwOKut1Y&t=1944.32s)]
*  progress from being made in these areas where we need urgent progress. So. [[00:32:32](https://www.youtube.com/watch?v=684UwOKut1Y&t=1952.48s)]
*  All right. Well, we'll leave it there. Thank you for the excellent piece in the magazine. And [[00:32:39](https://www.youtube.com/watch?v=684UwOKut1Y&t=1959.76s)]
*  thank you so much for joining us today. Yeah, thank you. Look forward to continuing [[00:32:43](https://www.youtube.com/watch?v=684UwOKut1Y&t=1963.6799999999998s)]
*  the discussion sometime. Thank you for listening. You can find the articles that we discussed on [[00:32:48](https://www.youtube.com/watch?v=684UwOKut1Y&t=1968.4s)]
*  today's show at foreignaffairs.com. The Foreign Affairs Interview is produced by Kate Brannon, [[00:32:58](https://www.youtube.com/watch?v=684UwOKut1Y&t=1978.96s)]
*  Julia Fleming-Dresser, and Molly McAnany. Special thanks also to Grace Finlayson, [[00:33:04](https://www.youtube.com/watch?v=684UwOKut1Y&t=1984.3200000000002s)]
*  Kaitlyn Joseph, Nora Revenaugh, Asher Ross, Gabrielle Sierra, and Marcus Zacharia. [[00:33:09](https://www.youtube.com/watch?v=684UwOKut1Y&t=1989.68s)]
*  Our theme music was written and performed by Robin Hilton. Make sure you subscribe to the [[00:33:16](https://www.youtube.com/watch?v=684UwOKut1Y&t=1996.08s)]
*  show wherever you listen to podcasts. And if you like what you heard, please take a minute [[00:33:20](https://www.youtube.com/watch?v=684UwOKut1Y&t=2000.48s)]
*  to rate and review it. We release a new show every other Thursday. Thanks again for tuning in. [[00:33:24](https://www.youtube.com/watch?v=684UwOKut1Y&t=2004.1599999999999s)]
