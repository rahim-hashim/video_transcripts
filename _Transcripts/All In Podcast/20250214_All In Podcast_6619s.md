---
Date Generated: February 28, 2025
Transcription Model: whisper medium 20231117
Length: 6619s
Video Keywords: ['chamath', 'david sacks', 'david friedberg', 'jason calacanis', 'all in podcast', 'tech', 'news', 'politics', 'big tech', 'antitrust', 'election', 'covid', 'quarantine', 'stocks', 'stock market', 'tech stocks', 'palihapitiya', 'government']
Video Views: 616131
Video Rating: None
Video Description: (0:00) The Besties intro Naval Ravikant!
(9:07) Naval reflects on his thoughtful tweets and reputation
(14:17) Unique views on parenting
(23:20) Sacks joins to talk AI: JD Vance's speech in Paris, Techno-Optimists vs Doomers
(1:11:06) Tariffs and the US economic experiment
(1:21:15) Thomson Reuters wins first major AI copyright decision on behalf of rights holders
(1:35:35) Chamath's dinner with Bryan Johnson, sleep hacks
(1:45:09) Tulsi Gabbard, RFK Jr. confirmed

Follow Naval:
https://x.com/naval

Follow the besties: 
https://x.com/chamath
https://x.com/Jason
https://x.com/DavidSacks
https://x.com/friedberg

Follow on X:
https://x.com/theallinpod

Follow on Instagram:
https://www.instagram.com/theallinpod

Follow on TikTok:
https://www.tiktok.com/@theallinpod

Follow on LinkedIn: 
https://www.linkedin.com/company/allinpod

Intro Music Credit:
https://rb.gy/tppkzl
https://x.com/yung_spielburg

Intro Video Credit:
https://x.com/TheZachEffect

Referenced in the show:
https://x.com/naval/status/1002103360646823936
https://x.com/CollinRugg/status/1889349078657716680
https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artificial-intelligence
https://www.cnn.com/2021/06/09/politics/kamala-harris-foreign-trip/index.html
https://www.cnbc.com/2025/02/11/anduril-to-take-over-microsofts-22-billion-us-army-headset-program.html
https://x.com/JDVance/status/1889640434793910659
https://www.youtube.com/watch?v=QCNYhuISzxg
https://www.wired.com/story/thomson-reuters-ai-copyright-lawsuit
https://admin.bakerlaw.com/wp-content/uploads/2023/11/ECF-1-Complaint.pdf
https://www.youtube.com/watch?v=7xTGNNLPyMI
https://polymarket.com/event/which-trump-picks-will-be-confirmed?tid=1739471077488

#allin #tech #news
---

# JD Vance's AI Speech, Techno-Optimists vs Doomers, Tariffs, AI Court Cases with Naval Ravikant
**All In Podcast:** [February 14, 2025](https://www.youtube.com/watch?v=AI5qI6ej-yM)
*  Great job, Naval, you rocked it. [[00:00:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=0.0s)]
*  Maybe I should have said this on air, but that was literally the most fun podcast I've [[00:00:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1.8800000000000001s)]
*  ever recorded. [[00:00:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5.5200000000000005s)]
*  Oh, that's on air, cut that in. [[00:00:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6.5200000000000005s)]
*  Yeah, put it in the show, put it in the show. [[00:00:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=8.08s)]
*  I had my theory on why you were number one, but now I have the realization. [[00:00:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=9.76s)]
*  What's the actual reason? [[00:00:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=13.36s)]
*  You know us for a long time. [[00:00:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=14.36s)]
*  Yeah, what was your theory? [[00:00:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=15.36s)]
*  What's the reality? [[00:00:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=16.36s)]
*  My theory was that my problem with going on podcasts is usually the person I'm talking [[00:00:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=17.36s)]
*  to is not that interesting. [[00:00:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=21.2s)]
*  They're just asking the same questions and they're dialing it in and they're not that [[00:00:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=22.2s)]
*  interested. [[00:00:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=25.6s)]
*  It's not like we're having a peer level actual conversation. [[00:00:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=26.6s)]
*  That's why I wanted to do AirChat and Clubhouse and things like that, because you can actually [[00:00:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=28.8s)]
*  have a conversation. [[00:00:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=32.0s)]
*  Oh, I see. [[00:00:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=33.0s)]
*  Right? [[00:00:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=34.0s)]
*  And what you guys have very uniquely is four people, you know, of whom at least three are [[00:00:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=35.0s)]
*  intelligent. [[00:00:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=39.8s)]
*  I'm kidding. [[00:00:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=40.8s)]
*  How could you say that? [[00:00:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=41.8s)]
*  Sax isn't here. [[00:00:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=42.8s)]
*  How did you? [[00:00:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=43.8s)]
*  Yeah. [[00:00:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=44.8s)]
*  Sax isn't even here. [[00:00:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=45.8s)]
*  You say that in the world? [[00:00:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=46.8s)]
*  That is so cold. [[00:00:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=47.8s)]
*  Oh my God, that's the best. [[00:00:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=48.8s)]
*  Right, of whom at least three are intelligent and all of you get along and you can have [[00:00:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=49.8s)]
*  an ongoing conversation. [[00:00:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=55.96s)]
*  That's a very high hit rate. [[00:00:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=57.88s)]
*  Normally in a podcast, you only get one interesting person and now you've got three, maybe four. [[00:00:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=59.040000000000006s)]
*  Right? [[00:01:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=64.24000000000001s)]
*  Okay. [[00:01:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=65.24000000000001s)]
*  So that to me was why all of this is successful. [[00:01:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=66.24000000000001s)]
*  Who invited this guy? [[00:01:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=67.24000000000001s)]
*  Who are you talking to? [[00:01:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=68.24000000000001s)]
*  His number four? [[00:01:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=69.24000000000001s)]
*  We don't know. [[00:01:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=70.24000000000001s)]
*  Children remain mysterious forever. [[00:01:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=71.24000000000001s)]
*  Of the four, right, the problem is if you get people together to talk, two is a good [[00:01:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=72.24000000000001s)]
*  conversation. [[00:01:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=77.04s)]
*  Three possibly, four is the max. [[00:01:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=78.04s)]
*  That's why the dinner table at a restaurant, four top, right? [[00:01:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=79.44s)]
*  You don't do five or six because then it splits into multiple conversations. [[00:01:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=82.52000000000001s)]
*  You had four people who were capable of talking, right? [[00:01:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=86.16s)]
*  That I thought was a secret, but there's another secret. [[00:01:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=89.52s)]
*  The other secret is you guys are having fun. [[00:01:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=91.96s)]
*  You're talking over each other, you're making fun of each other. [[00:01:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=94.76s)]
*  You're actually having fun. [[00:01:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=97.4s)]
*  That's why I'm saying this is the most fun podcast I've ever been on. [[00:01:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=99.8s)]
*  That's why you'll be successful. [[00:01:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=103.0s)]
*  Welcome back anytime, Nimal. [[00:01:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=104.0s)]
*  Thanks, guys. [[00:01:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=105.0s)]
*  Welcome back. [[00:01:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=106.0s)]
*  Keep it fun. [[00:01:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=107.0s)]
*  Absolutely. [[00:01:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=108.0s)]
*  Keep it fun, guys. [[00:01:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=109.0s)]
*  Thanks for having me. [[00:01:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=110.0s)]
*  188 and three smart guys. [[00:01:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=111.0s)]
*  I can't believe you'd say that about Sax. [[00:01:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=112.0s)]
*  He's not even here to defend themselves. [[00:01:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=115.0s)]
*  Sorry, David. [[00:01:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=118.0s)]
*  Let your winners slide. [[00:01:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=119.0s)]
*  Rain man, David. [[00:02:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=123.0s)]
*  We open source it to the fans and they've just gone crazy. [[00:02:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=126.0s)]
*  Love you. [[00:02:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=131.0s)]
*  Queen of King. [[00:02:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=132.0s)]
*  All right, everybody. [[00:02:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=133.0s)]
*  Welcome back to the number one podcast in the world. [[00:02:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=136.0s)]
*  We're really excited today. [[00:02:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=140.0s)]
*  Back again. [[00:02:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=143.0s)]
*  Your Sultan of science, David Friedberg. [[00:02:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=144.0s)]
*  What do you got going on there, Friedberg? [[00:02:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=147.0s)]
*  What's in the background? [[00:02:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=149.0s)]
*  Everybody wants to know. [[00:02:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=150.0s)]
*  I used to play. [[00:02:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=151.0s)]
*  I used to play a lot of a game called Sim Earth on my Macintosh LC way back in the day. [[00:02:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=152.0s)]
*  That tracks. [[00:02:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=158.0s)]
*  Yeah, that tracks. [[00:02:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=159.0s)]
*  And of course, with us again, your chairman. [[00:02:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=162.0s)]
*  What games did you play growing up, J. Cal? [[00:02:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=164.0s)]
*  Actually, I'm kind of curious. [[00:02:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=166.0s)]
*  Did you ever play video games? [[00:02:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=167.0s)]
*  Let's see. [[00:02:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=168.0s)]
*  Andrea, Allison, Susan. [[00:02:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=169.0s)]
*  I mean, it was like a lot of cute girls. [[00:02:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=171.0s)]
*  I was out dating girls. [[00:02:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=175.0s)]
*  Freeburg. [[00:02:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=177.0s)]
*  Yeah, I was not on my Apple to playing civilization. [[00:02:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=178.0s)]
*  Let me find one of those pictures. [[00:03:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=182.0s)]
*  Well, don't get me in trouble, man. [[00:03:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=184.0s)]
*  Yeah, 80s were 80s were good to me in Brooklyn. [[00:03:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=185.0s)]
*  Rejection, the video game. [[00:03:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=188.0s)]
*  Yes, you have three lives. [[00:03:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=191.0s)]
*  Reject, reject. [[00:03:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=193.0s)]
*  It's a numbers game, as you know, as you well know, it is a numbers game. [[00:03:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=194.0s)]
*  Yeah, they go ahead. [[00:03:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=199.0s)]
*  Pull up, pull up Rico Suave here. [[00:03:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=200.0s)]
*  Oh, no. [[00:03:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=202.0s)]
*  What is this? [[00:03:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=203.0s)]
*  Oh, here I am. [[00:03:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=204.0s)]
*  No, that's the 80s. [[00:03:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=205.0s)]
*  That's fat J. Cal. [[00:03:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=206.0s)]
*  That's fat J. Cal. [[00:03:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=207.0s)]
*  Nick, help out your uncle. [[00:03:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=208.0s)]
*  Yeah, here he is out slaying. [[00:03:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=211.0s)]
*  How about your uncle with the thin J. Cal? [[00:03:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=213.0s)]
*  You know what he was slaying in that snack. [[00:03:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=216.0s)]
*  Preazempic and postazempic, right? [[00:03:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=219.0s)]
*  Correct. [[00:03:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=222.0s)]
*  And weightlifting. [[00:03:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=223.0s)]
*  Beef jerky. [[00:03:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=224.0s)]
*  Go find my Leonardo DiCaprio picture, please, and replace my fat J. Cal picture with that. [[00:03:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=226.0s)]
*  Thank you. [[00:03:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=232.0s)]
*  Oh, God, I was fat. [[00:03:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=233.0s)]
*  Plus 40 pounds is a lot heavier than I am. [[00:03:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=235.0s)]
*  It's no joke. [[00:03:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=238.0s)]
*  It's no joke. [[00:03:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=239.0s)]
*  40 pounds is a lot. [[00:04:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=240.0s)]
*  There's so many great emo photos of me. [[00:04:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=241.0s)]
*  I'm proud of you. [[00:04:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=244.0s)]
*  Thank you, my man. [[00:04:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=245.0s)]
*  Thank you. [[00:04:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=246.0s)]
*  If you want a good photo. [[00:04:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=247.0s)]
*  Can you get through the intros, please, so we can start? [[00:04:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=248.0s)]
*  Come on, quick. [[00:04:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=250.0s)]
*  How you doing, brother? [[00:04:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=251.0s)]
*  How you doing? [[00:04:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=252.0s)]
*  Chairman, dictator, Chamath. [[00:04:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=253.0s)]
*  Good, good, good. [[00:04:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=254.0s)]
*  You're good? [[00:04:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=255.0s)]
*  You get to our guest investi- [[00:04:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=256.0s)]
*  Oh, all right, all right. [[00:04:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=257.0s)]
*  And we are really excited today. [[00:04:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=258.0s)]
*  Today for the first time on the All In podcast, the iron fist of Angel List, the zen-like [[00:04:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=261.0s)]
*  mage of the early stage. [[00:04:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=268.16s)]
*  He has such a way with words. [[00:04:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=270.8s)]
*  He's the Socrates of nerds. [[00:04:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=272.64s)]
*  Please welcome my guy, Namaste, Naval. [[00:04:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=275.4s)]
*  How you doing? [[00:04:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=278.2s)]
*  The intros are back. [[00:04:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=279.2s)]
*  That is the best intro I've ever gotten. [[00:04:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=280.2s)]
*  I didn't think you could do that. [[00:04:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=281.84s)]
*  That was amazing. [[00:04:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=284.08s)]
*  That's your superpower right there. [[00:04:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=285.08s)]
*  Lock it in. [[00:04:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=286.52s)]
*  Quit venture capital. [[00:04:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=287.52s)]
*  Just do that. [[00:04:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=288.52s)]
*  Absolutely. [[00:04:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=289.52s)]
*  That's actually, you know what? [[00:04:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=290.52s)]
*  Interestingly, I was talking to- [[00:04:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=291.52s)]
*  Number one podcast in the world, like someone said. [[00:04:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=292.52s)]
*  I mean, that's what I'm manifesting. [[00:04:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=293.91999999999996s)]
*  It's getting close. [[00:04:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=296.08s)]
*  We've been in the top 10. [[00:04:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=297.08s)]
*  So I mean, the weekends are good for All In. [[00:04:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=298.15999999999997s)]
*  This one will hit number one. [[00:05:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=301.0s)]
*  This one will go viral. [[00:05:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=302.0s)]
*  I think it could. [[00:05:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=303.0s)]
*  If you have some really great pithy insights, we might go right to the top. [[00:05:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=304.0s)]
*  Because you have a new audience. [[00:05:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=307.96s)]
*  I just got to do a Sieg Heil and it'll go viral. [[00:05:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=308.96s)]
*  Oh, no. [[00:05:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=311.47999999999996s)]
*  Oh, no. [[00:05:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=312.47999999999996s)]
*  Are you going to send us your heart? [[00:05:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=313.88s)]
*  My heart goes out to you. [[00:05:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=315.8s)]
*  My heart? [[00:05:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=316.8s)]
*  I end here at the heart. [[00:05:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=317.8s)]
*  I don't send it out. [[00:05:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=319.48s)]
*  I keep it right here. [[00:05:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=321.48s)]
*  I put both hands on the heart and I hold it nice and steady. [[00:05:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=323.04s)]
*  I hold it in. [[00:05:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=326.84000000000003s)]
*  It's sending out to you, but just not explicitly. [[00:05:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=327.84000000000003s)]
*  All right. [[00:05:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=330.68s)]
*  For those of you who don't know, Navarro was an entrepreneur. [[00:05:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=331.68s)]
*  He kicked a bit of ass. [[00:05:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=335.24s)]
*  He got his ass kicked and then he started venture hacks. [[00:05:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=336.24s)]
*  And he started emailing folks and saying, you know, 20, 15, 20 years ago, maybe 15, [[00:05:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=341.36s)]
*  here are some deals in Silicon Valley. [[00:05:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=347.84000000000003s)]
*  He went around, he started writing 50K, 100K checks. [[00:05:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=349.12s)]
*  He hit a bunch of home runs and he turned venture hacks into Angel List. [[00:05:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=351.52000000000004s)]
*  And then he has invested in a ton of great startups. [[00:05:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=356.96000000000004s)]
*  Maybe give us some of the greatest hits there. [[00:06:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=360.84000000000003s)]
*  Yeah, Twitter, Uber, Notion, a bunch of others, Postmates, Udemy, a lot of unicorns, a bunch [[00:06:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=362.96000000000004s)]
*  of upcoming. [[00:06:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=370.52s)]
*  It's actually a lot of deals at this point. [[00:06:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=371.52s)]
*  But honestly, I'm not necessarily proud of being an investor. [[00:06:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=373.4s)]
*  Investor to me is a side job. [[00:06:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=377.32s)]
*  It's a hobby. [[00:06:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=378.56s)]
*  So I do startups. [[00:06:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=380.24s)]
*  How do you define yourself? [[00:06:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=381.24s)]
*  I don't. [[00:06:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=384.12s)]
*  I mean, I guess these days I would say more like building things. [[00:06:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=385.12s)]
*  You know, every so-called career is an evolution, right? [[00:06:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=388.35999999999996s)]
*  And all of you guys are independent and you kind of do what you're most interested in, [[00:06:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=392.44s)]
*  right? [[00:06:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=396.03999999999996s)]
*  That's the point of making money so you can just do what you want. [[00:06:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=397.03999999999996s)]
*  So these days I'm really into building and crafting products. [[00:06:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=399.6s)]
*  So I built one recently called AirChat. [[00:06:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=403.26000000000005s)]
*  It kind of didn't work. [[00:06:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=405.32000000000005s)]
*  I'm still proud of what I built and got to work with an incredible team. [[00:06:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=407.24s)]
*  And now I'm building a new product. [[00:06:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=410.92s)]
*  This time I'm going into hardware. [[00:06:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=411.92s)]
*  And I'm just building something that I really want. [[00:06:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=413.92s)]
*  I'm not ready to talk about it yet. [[00:06:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=416.92s)]
*  And you funded all yourself, Naval? [[00:06:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=417.92s)]
*  Partially, I bring investors along. [[00:06:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=419.92s)]
*  Last time they got their money back. [[00:07:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=422.16s)]
*  Previous times they've made money. [[00:07:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=424.04s)]
*  Next time, hopefully they'll make a lot of money. [[00:07:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=425.18s)]
*  It's good to bring your friends along. [[00:07:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=427.68s)]
*  I'll be honest. [[00:07:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=429.44s)]
*  I love that you said, I love the product, but it didn't work. [[00:07:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=430.44s)]
*  Not enough people say that. [[00:07:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=433.48s)]
*  Yeah, I know. [[00:07:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=434.71999999999997s)]
*  I built a product that I loved, that I was proud of, but it didn't catch fire. [[00:07:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=435.71999999999997s)]
*  And it was a social product, so it had to catch fire for it to work. [[00:07:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=439.71999999999997s)]
*  So I found the team great homes. [[00:07:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=442.36s)]
*  They all got paid. [[00:07:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=443.72s)]
*  The investors that I brought in got their money back. [[00:07:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=444.72s)]
*  And I learned a ton, which I'm leveraging into the new thing. [[00:07:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=447.76s)]
*  But the new thing is much harder. [[00:07:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=450.72s)]
*  The new thing is hardware and software and... [[00:07:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=452.4s)]
*  What did you learn building in 2024 and 2025 that you didn't know maybe before then? [[00:07:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=455.32s)]
*  The main thing was actually just the craft. [[00:07:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=460.73999999999995s)]
*  The craft of pixel by pixel designing a software product and launching it. [[00:07:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=463.11999999999995s)]
*  I guess the main thing I took away that was a learning was that I really enjoyed building [[00:07:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=468.55999999999995s)]
*  products and that I wanted to build something even harder and something even more real. [[00:07:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=474.35999999999996s)]
*  And I think like a lot of us, I'm inspired by Elon and all the incredible work he's done. [[00:08:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=480.67999999999995s)]
*  So I don't want to build things that are easy. [[00:08:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=485.16s)]
*  I want to build things that are hard and interesting. [[00:08:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=486.8s)]
*  And I want to take on more technical risk and less market risk. [[00:08:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=489.44s)]
*  This is the classic VC learning, right? [[00:08:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=492.84000000000003s)]
*  Which is you want to build something that if people get it, if you can deliver it, you [[00:08:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=495.16s)]
*  know people will want it. [[00:08:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=499.6s)]
*  And it's just hard to build as opposed to you build it and you don't know if they want [[00:08:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=501.76000000000005s)]
*  it. [[00:08:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=505.24s)]
*  So that's a learning. [[00:08:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=506.24s)]
*  AirChat was a lot of fun for those of you who don't know. [[00:08:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=507.24s)]
*  It was kind of like a social media network where you could ask a question and then people [[00:08:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=509.28000000000003s)]
*  could respond. [[00:08:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=514.04s)]
*  And it was like an audio based Twitter. [[00:08:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=515.3199999999999s)]
*  Would you say that was the best way to describe it? [[00:08:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=517.8399999999999s)]
*  Audio Twitter, asynchronous AI transcripts and all kinds of AI to make it easier for [[00:08:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=520.8399999999999s)]
*  you. [[00:08:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=526.12s)]
*  Translation. [[00:08:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=527.12s)]
*  Really good way for kind of trying to make podcasting type conversations more accessible [[00:08:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=528.52s)]
*  to everybody. [[00:08:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=533.5999999999999s)]
*  Because honestly, one of the reasons I don't go on podcasts, I don't like being intermediated, [[00:08:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=534.5999999999999s)]
*  so to speak, right? [[00:08:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=538.7199999999999s)]
*  Where you sit there and someone interviews you and then you go back and forth and you [[00:08:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=539.7199999999999s)]
*  go through the same old things. [[00:09:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=541.9599999999999s)]
*  I just want to talk to people. [[00:09:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=543.4s)]
*  I want peer relationships, kind of like you guys have running here. [[00:09:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=544.4s)]
*  Naval, what happened when you went through that phase? [[00:09:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=547.56s)]
*  There was a period where it just seemed like something had gone on in your life and you [[00:09:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=550.28s)]
*  just knew the answers. [[00:09:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=555.1999999999999s)]
*  You were just so grounded. [[00:09:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=556.4399999999999s)]
*  It's not to say that you're not grounded now, but you're less active posting and writing. [[00:09:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=559.0s)]
*  But there was this period where I think all of us were like, all right, what does Naval [[00:09:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=563.54s)]
*  think? [[00:09:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=566.9599999999999s)]
*  Oh, really? [[00:09:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=567.96s)]
*  Oh, okay. [[00:09:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=568.96s)]
*  That's news to me. [[00:09:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=569.96s)]
*  I would say it would be like the late teens, the early 20s. [[00:09:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=570.96s)]
*  Jason, you can correct me if I'm getting the dates wrong, but it's in that moment where [[00:09:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=573.9200000000001s)]
*  these Naval-isms and this sort of philosophy really started to... [[00:09:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=576.6800000000001s)]
*  I think people had a tremendous respect for how you were thinking about things. [[00:09:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=580.6s)]
*  I was just curious, were you going through something in that moment? [[00:09:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=584.24s)]
*  Oh, yeah, yeah, yeah. [[00:09:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=587.9200000000001s)]
*  That's right. [[00:09:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=588.9200000000001s)]
*  No, very insightful. [[00:09:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=589.9200000000001s)]
*  Yeah. [[00:09:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=590.9200000000001s)]
*  I've been on Twitter since 2007 because I was an early investor, but I never really [[00:09:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=591.9200000000001s)]
*  tweeted and get featured. [[00:09:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=596.6800000000001s)]
*  I had no audience. [[00:09:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=597.96s)]
*  I was just doing the usual techie guy thing talking to each other. [[00:09:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=598.96s)]
*  And then I started AngelList in 2010. [[00:10:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=602.84s)]
*  The original thing about matching investors to startups didn't scale. [[00:10:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=605.32s)]
*  It was just an email list that exploded early on, but then just didn't scale. [[00:10:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=608.52s)]
*  So we didn't have a business. [[00:10:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=612.9200000000001s)]
*  And I was trying to figure out the business. [[00:10:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=615.24s)]
*  And at the same time, I got a letter from the Securities Exchange Commission saying, [[00:10:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=616.48s)]
*  oh, you're acting as an unlicensed broker dealer. [[00:10:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=620.8000000000001s)]
*  And I'm like, what? [[00:10:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=622.48s)]
*  I'm not making any money. [[00:10:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=623.48s)]
*  I'm just making intros. [[00:10:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=624.48s)]
*  I'm not taking anything. [[00:10:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=625.48s)]
*  It's just a public service. [[00:10:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=626.48s)]
*  But even then, they were coming after me. [[00:10:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=627.8s)]
*  So I was in it and I'd raised a bunch of money from investors. [[00:10:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=629.4799999999999s)]
*  So I was in a very high stress period of my life. [[00:10:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=632.4799999999999s)]
*  Now looking back, it's almost comical that I was stressed over it. [[00:10:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=634.56s)]
*  But at the time, it all felt very real. [[00:10:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=638.02s)]
*  The weight of everything was on my shoulders, expectations, people, money, regulators. [[00:10:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=639.8599999999999s)]
*  And I eventually went to DC and got the law changed to legalize what we do, which ironically [[00:10:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=645.28s)]
*  enabled a whole bunch of other things like ICOs and incubator days and so on, demo days. [[00:10:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=649.92s)]
*  In that process, I was in a very high stress period of my life and I just started tweeting [[00:10:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=655.5600000000001s)]
*  whatever I was going through, whatever realizations I was happening. [[00:10:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=659.32s)]
*  It's only in stress that you sort of are forced to grow. [[00:11:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=662.6s)]
*  And so whatever internal growth I was going through, I just started tweeting it, not thinking [[00:11:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=665.8000000000001s)]
*  much of it. [[00:11:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=669.6800000000001s)]
*  And it was a mix of... [[00:11:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=671.0s)]
*  There are three things that I kind of always kind of are running through. [[00:11:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=672.0s)]
*  One is I love science. [[00:11:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=675.92s)]
*  You know, I'm an amateur, love physics. [[00:11:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=676.92s)]
*  Let's just leave it at that. [[00:11:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=680.4s)]
*  I love reading a lot of philosophy and thinking deeply about it. [[00:11:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=681.4s)]
*  And I like making money, right? [[00:11:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=687.0799999999999s)]
*  Truth, love and money. [[00:11:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=688.72s)]
*  That's my joke on my Twitter bio. [[00:11:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=689.72s)]
*  Those are the three things that I keep coming back to. [[00:11:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=691.9599999999999s)]
*  And so I just started tweeting about all of them. [[00:11:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=694.34s)]
*  And I think before that, the expectation was that someone like me should just be talking [[00:11:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=696.48s)]
*  about money, stay in your lane. [[00:11:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=702.1999999999999s)]
*  And people had been playing it very safe. [[00:11:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=704.16s)]
*  And so I think the combination, the three sort of caught people's attentions because [[00:11:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=706.1999999999999s)]
*  every person thinks about everything. [[00:11:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=710.36s)]
*  We don't just stay in our lane in real life. [[00:11:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=713.2s)]
*  We're dealing with our relationships. [[00:11:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=715.28s)]
*  We're dealing with our relationship with the universe. [[00:11:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=716.54s)]
*  We're dealing with what we know to be true and with science and how we make decisions [[00:11:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=719.04s)]
*  and how we figure things out. [[00:12:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=723.5600000000001s)]
*  And we're also dealing with the practical, everyday material things of how to deal with [[00:12:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=725.12s)]
*  our spouses or girlfriends or wives or husbands and how to make money and how to deal with [[00:12:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=729.52s)]
*  our children. [[00:12:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=733.92s)]
*  So I'm just tweeting about everything. [[00:12:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=735.0s)]
*  I just got interested in everything. [[00:12:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=737.0s)]
*  I'm tweeting about it. [[00:12:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=738.0s)]
*  And a lot of it, my best stuff was just notes to self. [[00:12:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=739.04s)]
*  It's like, hey, don't forget this. [[00:12:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=741.64s)]
*  How to get rich. [[00:12:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=743.28s)]
*  Remember that one? [[00:12:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=744.28s)]
*  How to get rich. [[00:12:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=745.28s)]
*  That was like one of the first threads. [[00:12:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=746.28s)]
*  And that one went super viral. [[00:12:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=747.28s)]
*  Yeah, that was a banger. [[00:12:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=748.28s)]
*  Yeah. [[00:12:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=749.28s)]
*  Yeah. [[00:12:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=750.28s)]
*  Yeah. [[00:12:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=751.28s)]
*  I think that is still the most viral thread ever on Twitter. [[00:12:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=752.28s)]
*  I like timeless things. [[00:12:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=755.0s)]
*  I like philosophy. [[00:12:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=756.12s)]
*  I like things that are still apply in the future. [[00:12:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=757.12s)]
*  I like compound interest, if you will, in ideas. [[00:12:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=760.44s)]
*  Obviously, recently, X has become so addictive that we're all checking it every day. [[00:12:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=764.36s)]
*  And Elon's built the perfect for you. [[00:12:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=769.88s)]
*  He's built TikTok for nerds. [[00:12:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=771.96s)]
*  And we're all in it. [[00:12:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=773.84s)]
*  But normally, I try to ignore the news. [[00:12:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=774.84s)]
*  Obviously, last year, things got real. [[00:12:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=776.56s)]
*  We all had to pay a lot of attention to the news. [[00:12:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=778.52s)]
*  But I just like to tweet timeless things. [[00:13:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=781.52s)]
*  I don't know. [[00:13:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=782.92s)]
*  I mean, people pay attention. [[00:13:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=783.92s)]
*  Sometimes they like what I write. [[00:13:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=784.92s)]
*  Sometimes they go non-linear on me. [[00:13:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=786.52s)]
*  But yeah, the how to get rich feedstorm was a big one. [[00:13:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=788.84s)]
*  Is it problematic when people now meet you because the hype versus the reality, it's [[00:13:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=790.98s)]
*  discordant now because people, if they absorb this content, they expect to see some quasi [[00:13:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=796.86s)]
*  deity floating in the air? [[00:13:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=802.02s)]
*  You know what I mean? [[00:13:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=804.02s)]
*  Yeah. [[00:13:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=805.82s)]
*  Like many of you have stopped drinking, but I used to have the occasional glass of wine. [[00:13:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=806.82s)]
*  And there was a moment there where I went and met with an information reporter back [[00:13:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=810.7s)]
*  when I used to meet with reporters. [[00:13:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=814.9s)]
*  And she said, where are we going to meet? [[00:13:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=817.3000000000001s)]
*  So I said, oh, let's meet at the wine merchant. [[00:13:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=818.78s)]
*  And we'll get over the last one. [[00:13:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=820.9399999999999s)]
*  She's like, what you drink? [[00:13:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=821.9399999999999s)]
*  Like, it was like a big deal for her. [[00:13:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=822.9399999999999s)]
*  I'm so disappointed. [[00:13:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=824.9399999999999s)]
*  I was like, I'm an entrepreneur. [[00:13:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=827.9399999999999s)]
*  Most of them are alcoholics or psychedelics or whatever it takes to manage. [[00:13:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=829.3s)]
*  Yeah, ketamine. [[00:13:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=833.9s)]
*  Yeah, ketamine in the heart. [[00:13:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=834.9s)]
*  Yeah. [[00:13:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=835.9s)]
*  Right. [[00:13:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=836.9s)]
*  Yeah. [[00:13:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=837.9s)]
*  When they say I'm on therapy, you know what that's code for. [[00:13:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=838.9s)]
*  Yeah. [[00:14:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=840.9s)]
*  So, yes, it is highly distorted. [[00:14:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=841.9s)]
*  Plant medicine. [[00:14:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=843.4599999999999s)]
*  Yeah, I'm almost reminded of that line in The Matrix where that agent is about to like [[00:14:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=844.7s)]
*  shoot one of the Matrix characters and says only human. [[00:14:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=849.46s)]
*  Right. [[00:14:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=852.58s)]
*  So that's kind of what I want to say to everybody, like only human. [[00:14:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=853.58s)]
*  Yeah, yeah, yeah. [[00:14:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=855.9000000000001s)]
*  You did recently a podcast with Tim Ferriss on parenting. [[00:14:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=857.26s)]
*  This was out there. [[00:14:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=861.46s)]
*  I love this. [[00:14:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=862.98s)]
*  I bought the book from this guy. [[00:14:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=863.98s)]
*  Just give a brief overview of this philosophy of parenting. [[00:14:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=867.26s)]
*  Oh, I didn't listen to this. [[00:14:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=870.5400000000001s)]
*  I have to write this down. [[00:14:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=871.9000000000001s)]
*  Tell us what is your... [[00:14:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=872.9000000000001s)]
*  I love this. [[00:14:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=874.34s)]
*  This spoke to me, but it was a little crazy. [[00:14:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=875.34s)]
*  Yeah. [[00:14:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=877.06s)]
*  So I'm a big fan of David Deutsch. [[00:14:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=878.06s)]
*  David Deutsch, I think, is basically the smartest living human. [[00:14:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=879.54s)]
*  He's a scientist who pioneered quantum computation. [[00:14:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=882.02s)]
*  And he's written a couple of great books, but it's about the intersection of the greatest [[00:14:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=885.9399999999999s)]
*  theories that we have today, the theories with the most reach. [[00:14:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=889.86s)]
*  And those are epistemology, the theory of knowledge, evolution, quantum physics, and [[00:14:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=892.74s)]
*  computation. [[00:14:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=897.34s)]
*  This is the beginning of infinity, guy. [[00:14:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=898.34s)]
*  That's the book that you always reference. [[00:15:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=900.5799999999999s)]
*  Correct. [[00:15:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=903.82s)]
*  Yes, The Fabric of Reality is another book. [[00:15:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=904.82s)]
*  I've spent a fair bit of time with him, done some podcasts with him, hired and worked with [[00:15:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=905.82s)]
*  people around him. [[00:15:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=910.1s)]
*  And I'm just really impressed because it's like the framework that's made me smarter, [[00:15:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=911.1s)]
*  I feel like, because we're all fighting aging. [[00:15:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=914.58s)]
*  Our brains are getting slower and we're always trying to have better ideas. [[00:15:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=916.94s)]
*  So as you age, you should have wisdom. [[00:15:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=920.14s)]
*  That's your substitute for the raw horsepower of intelligence going down. [[00:15:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=921.94s)]
*  And so scientific wisdom I take from David, not take, but I learned from David. [[00:15:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=925.58s)]
*  And one of the things that he pioneered is called taking children seriously. [[00:15:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=931.0999999999999s)]
*  And it's this idea that you should take your children seriously like adults. [[00:15:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=934.5s)]
*  You should always give them the same freedom that you would give an adult. [[00:15:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=938.26s)]
*  If you wouldn't speak that way with your spouse, if you wouldn't force your spouse to do something, [[00:15:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=941.8599999999999s)]
*  don't force a child to do something. [[00:15:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=945.7399999999999s)]
*  And it's only through the latent threat of physical violence, hey, I can control you, [[00:15:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=947.9799999999999s)]
*  I can make you go to your room, I can take your dinner away or whatever, that you intimidate [[00:15:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=953.06s)]
*  children. [[00:15:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=958.2199999999999s)]
*  And it resonated with me because I grew up very, very free. [[00:15:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=959.66s)]
*  My father wasn't around when I was young. [[00:16:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=963.26s)]
*  My mother didn't have the bandwidth to watch us all the time. [[00:16:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=965.26s)]
*  She had other things to do. [[00:16:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=969.02s)]
*  And so I kind of was making my own decisions from an extremely young age. [[00:16:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=970.0600000000001s)]
*  From the age of five, nobody was telling me what to do. [[00:16:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=973.98s)]
*  And from the age of nine, I was telling everybody what to do. [[00:16:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=976.46s)]
*  So I've used to that. [[00:16:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=978.58s)]
*  And I've been homeschooling my own kids. [[00:16:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=980.46s)]
*  So the philosophy resonated. [[00:16:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=982.46s)]
*  And I found this guy, Aaron Stupel on AirChat. [[00:16:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=984.7s)]
*  And he was an incredible expositor to philosophy. [[00:16:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=987.74s)]
*  He lives his life with it 99% as extreme as one can go. [[00:16:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=990.22s)]
*  So his kids can eat all the ice cream they want and all the Snickers bars they want. [[00:16:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=994.6600000000001s)]
*  They can play on the iPad all they want. [[00:16:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=998.1800000000001s)]
*  They don't have to go to school if they don't feel like it. [[00:16:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=999.5400000000001s)]
*  They dress how they want. [[00:16:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1001.38s)]
*  They don't have to do anything they don't want to do. [[00:16:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1002.7800000000001s)]
*  Everything is a discussion, negotiation, explanation, just like you would with a roommate or an [[00:16:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1004.58s)]
*  adult living in your house. [[00:16:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1008.7800000000001s)]
*  And it's kind of insane and extreme. [[00:16:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1010.82s)]
*  I live my own home life in that arc, in that direction. [[00:16:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1013.42s)]
*  And I'm a very free person. [[00:16:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1019.22s)]
*  I don't have an office to go to. [[00:17:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1020.46s)]
*  I try really not to maintain a calendar. [[00:17:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1021.86s)]
*  If I can't remember it, I don't want to do it. [[00:17:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1023.86s)]
*  I don't send my kids to school. [[00:17:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1026.38s)]
*  I really try not to coerce them. [[00:17:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1027.74s)]
*  And so obviously, that's an extreme model. [[00:17:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1029.22s)]
*  But I was... [[00:17:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1032.42s)]
*  Sorry, sorry, sorry. [[00:17:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1033.7s)]
*  Hold on a second. [[00:17:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1034.54s)]
*  Your kids, if they were like, I want Haagen-Dazs and it's 9 p.m. [[00:17:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1035.86s)]
*  You're like, OK. [[00:17:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1043.14s)]
*  Two nights ago, I did this. [[00:17:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1044.98s)]
*  I ordered the Haagen-Dazs. [[00:17:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1045.94s)]
*  It wasn't Haagen-Dazs. [[00:17:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1047.0200000000002s)]
*  It was a different brand. [[00:17:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1047.7800000000002s)]
*  OK. [[00:17:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1048.46s)]
*  I'm just going to go through a couple of examples. [[00:17:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1049.3400000000001s)]
*  We do a hash ice cream at 9 p.m. [[00:17:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1050.9s)]
*  and we all eat ice cream. [[00:17:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1052.74s)]
*  Yeah, so they're like, Dad, I want... [[00:17:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1053.3400000000001s)]
*  And they're happy. [[00:17:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1054.8600000000001s)]
*  They're happy kids. [[00:17:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1055.6200000000001s)]
*  I want to be on my iPad. [[00:17:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1056.7800000000002s)]
*  I'm playing Fortnite. [[00:17:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1057.94s)]
*  Leave me alone. [[00:17:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1058.8200000000002s)]
*  I'll go to sleep when I want. [[00:17:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1059.5400000000002s)]
*  You're like, OK. [[00:17:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1060.6200000000001s)]
*  My oldest probably plays iPad nine hours a day. [[00:17:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1061.98s)]
*  OK, so then your other kid pees in their pants because they're too lazy to walk to the bathroom. [[00:17:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1065.26s)]
*  They don't do that because they don't like pee in their pants. [[00:17:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1071.14s)]
*  I understand. [[00:17:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1072.94s)]
*  But I'm just saying, like, there's a spectrum of all of these things, right? [[00:17:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1073.54s)]
*  Yeah. [[00:17:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1076.46s)]
*  And your point of view is 100 percent of it is allowed and you have no judgements. [[00:17:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1076.82s)]
*  No, no, that's not where I am. [[00:18:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1081.82s)]
*  OK. [[00:18:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1083.06s)]
*  That's where Aaron is. [[00:18:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1083.7s)]
*  My rules are a little different. [[00:18:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1084.7s)]
*  My rules are they got to do one hour of math or programming plus two hours of reading every [[00:18:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1085.8999999999999s)]
*  single day. [[00:18:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1092.22s)]
*  And the moment they've done that, they're free creatures. [[00:18:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1093.22s)]
*  And everything else is a negotiation. [[00:18:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1096.7s)]
*  We have to persuade them. [[00:18:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1098.8999999999999s)]
*  It's a persuasion, I should say, not even a negotiation. [[00:18:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1099.94s)]
*  And even the hour of math and two hours of reading, really, you get 15 to 30 minutes [[00:18:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1102.46s)]
*  of math, maybe an hour if you're lucky, and you get half an hour to two hours of reading. [[00:18:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1106.38s)]
*  And what do you think the long term consequences of that are? [[00:18:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1110.3400000000001s)]
*  And then also, what is the long term consequences, let's say, on health if they're making decisions [[00:18:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1114.02s)]
*  you know are just not good, like the ice cream thing at 9 p.m.? [[00:18:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1119.82s)]
*  Yeah. [[00:18:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1122.82s)]
*  How do you manage that in your mind? [[00:18:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1123.3400000000001s)]
*  I think whatever age you're at, whatever part you're at in life, you're still always [[00:18:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1125.54s)]
*  struggling with your own habits. [[00:18:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1130.22s)]
*  I think all of us, for example, still eat food and feel guilty or want to eat something [[00:18:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1131.9399999999998s)]
*  that we shouldn't be eating. [[00:18:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1135.54s)]
*  And we're still always evolving our diets. [[00:18:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1136.82s)]
*  And kids are the same. [[00:18:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1138.54s)]
*  So my oldest is already, he passed on the ice cream last time, and he said, I want to [[00:18:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1139.8999999999999s)]
*  eat healthier because finally I managed to get through to him and persuade him that he [[00:19:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1143.82s)]
*  should be healthier. [[00:19:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1146.82s)]
*  My younger kids will eat it, but they'll eat a limited amount. [[00:19:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1148.62s)]
*  My middle kid will sometimes eat some and not others. [[00:19:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1151.1799999999998s)]
*  So if they say something, you'll enable it, but then you'll be like, hey, listen, this [[00:19:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1153.6999999999998s)]
*  is not the choice I would make. [[00:19:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1158.5s)]
*  But if you want it, I do it. [[00:19:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1160.5s)]
*  Yeah. [[00:19:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1161.5s)]
*  I'll try it. [[00:19:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1162.02s)]
*  But you also have to be careful where you don't want to intimidate them and you don't [[00:19:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1163.02s)]
*  want to be so overbearing that then they just view dad as like control it. [[00:19:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1165.78s)]
*  I find this so fascinating. [[00:19:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1169.9s)]
*  And so what do you think happens to these kids? [[00:19:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1170.9s)]
*  I'm sure you have a vision of what they'll be like when they're fully formed adults. [[00:19:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1174.34s)]
*  Like, what is that vision? [[00:19:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1177.18s)]
*  I try not to. [[00:19:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1179.14s)]
*  They're going to be who they're going to be. [[00:19:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1180.3s)]
*  This is kind of how I grew up. [[00:19:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1182.02s)]
*  I kind of did what I wanted. [[00:19:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1183.42s)]
*  I would rather they have agency than turn out exactly the way I want, because agency [[00:19:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1185.5s)]
*  is the hardest thing. [[00:19:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1193.62s)]
*  Right. [[00:19:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1194.62s)]
*  Having control over your own life, making your own decisions. [[00:19:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1195.14s)]
*  And I want them to be happy. [[00:19:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1198.1s)]
*  I have a very happy household. [[00:19:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1199.42s)]
*  What is the Plato? [[00:20:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1201.06s)]
*  What's Plato's goal? [[00:20:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1202.14s)]
*  Eudaimonia, right? [[00:20:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1203.3s)]
*  Like, yeah, the happy. [[00:20:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1204.78s)]
*  Yeah. [[00:20:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1206.06s)]
*  I like the fulfillment. [[00:20:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1206.26s)]
*  This concept. [[00:20:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1208.3s)]
*  Is that what you want for them? [[00:20:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1208.74s)]
*  I don't really want anything for them. [[00:20:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1211.7s)]
*  I just want them to be free and their best selves. [[00:20:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1213.58s)]
*  God damn. [[00:20:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1218.26s)]
*  Shamath is worrying about details. [[00:20:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1220.46s)]
*  He's got like 17 kids now. [[00:20:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1222.34s)]
*  I don't know if you know, but Shamath has got like a whole bunch of things. [[00:20:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1223.9399999999998s)]
*  I love this interview because the guy made a really interesting point, which was they're [[00:20:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1227.06s)]
*  going to have to make these decisions at some point. [[00:20:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1232.22s)]
*  They're going to have to learn the pros and cons, the upside, the downside to all these [[00:20:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1234.74s)]
*  things, eating iPad and the quicker you get them to have agency to make these decisions [[00:20:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1240.82s)]
*  for themselves with knowledge, to ask questions, the more secure it will be. [[00:20:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1246.3s)]
*  I found it a fascinating discussion. [[00:20:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1250.3s)]
*  I like cause and effect, especially in teenagers. [[00:20:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1252.22s)]
*  Now that I have a teenager, it's really good for them to learn. [[00:20:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1255.1s)]
*  Hey, you know, if you don't do your homework, you have a problem and then you got to solve [[00:20:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1258.26s)]
*  that problem. [[00:21:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1263.66s)]
*  How are we going to solve that problem? [[00:21:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1264.18s)]
*  So I like to present it as what's your plan? [[00:21:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1265.1399999999999s)]
*  Anytime they have a problem, eight year old kids, 15 year old kids, I just say, what's [[00:21:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1267.58s)]
*  your plan to solve this? [[00:21:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1271.54s)]
*  And then I like to hear their plan and let me know if you want to brainstorm it. [[00:21:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1272.54s)]
*  But I thought it was a very interesting, super interesting discussion. [[00:21:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1276.1s)]
*  I would say overall, my kids are very happy. [[00:21:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1280.38s)]
*  The household is very happy. [[00:21:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1282.98s)]
*  Everybody gets along. [[00:21:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1284.98s)]
*  Everybody loves each other. [[00:21:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1286.46s)]
*  Yeah. [[00:21:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1288.26s)]
*  Some of them are way ahead of their peers. [[00:21:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1289.54s)]
*  Nobody's behind in anything that matters. [[00:21:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1291.7s)]
*  Nobody seems unhealthy in any obvious way. [[00:21:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1294.58s)]
*  No one has abridged eating habits. [[00:21:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1296.94s)]
*  I haven't even found a really an abridged behavior that's out of line. [[00:21:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1298.7s)]
*  So it's all good. [[00:21:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1303.54s)]
*  Self correct. [[00:21:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1304.18s)]
*  It's like, I worry, I worry a lot about this, like iPad situation. [[00:21:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1304.94s)]
*  I see my kids on an iPad and it's almost like, unless they're doing an interactive [[00:21:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1308.46s)]
*  project, if they end up watching says the guy who has a video game theme in the [[00:21:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1315.26s)]
*  background, probably, and who probably grew up playing video games nonstop and [[00:21:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1319.98s)]
*  probably spends nine hours a day on his screen just called a phone. [[00:22:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1324.98s)]
*  So yeah, it's the same thing, man. [[00:22:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1328.22s)]
*  Well, I mean, I feel like watch is it, but do they watch shows? [[00:22:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1331.02s)]
*  No, there's a hypocrisy to picking up your phone and then saying to your kid, no, [[00:22:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1333.7s)]
*  you can't use your iPad. [[00:22:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1338.9s)]
*  I grew up playing video games nonstop and video games when I was older and I was an [[00:22:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1340.02s)]
*  avid gamer until just a few years ago. [[00:22:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1344.5s)]
*  I'm not criticizing the iPad. [[00:22:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1347.94s)]
*  I was obviously on a computer since I was four years old, so I totally get it. [[00:22:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1349.5s)]
*  And I think the question for me is like, but I didn't have the ability to play a [[00:22:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1353.1s)]
*  30 minute show and then play the next 30 minute show and the next 30 minute show [[00:22:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1358.06s)]
*  and then sit there for two hours and just have a show playing the whole time. [[00:22:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1362.86s)]
*  I was, you know, interacting on the computer and doing stuff and building [[00:22:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1367.34s)]
*  stuff, which was a little different for me from a use case perspective. [[00:22:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1370.58s)]
*  We did use to control their YouTube access, although now we don't do that. [[00:22:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1374.22s)]
*  The only thing I ask them is that they put on captions when they're watching [[00:22:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1378.98s)]
*  YouTube, so it helps their reading. [[00:23:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1383.46s)]
*  They learn to read. [[00:23:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1385.5800000000002s)]
*  That's a good tip. [[00:23:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1386.14s)]
*  Yeah. [[00:23:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1386.98s)]
*  I like that. [[00:23:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1387.26s)]
*  I will say that one of my kids is really into YouTube. [[00:23:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1387.66s)]
*  The other two are not like they just got over it. [[00:23:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1390.26s)]
*  And to the extent that they use YouTube, it's mostly because they're looking up [[00:23:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1393.14s)]
*  videos on their favorite games. [[00:23:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1396.26s)]
*  They want to know how to be better at a game. [[00:23:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1398.0600000000002s)]
*  All right. [[00:23:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1400.0200000000002s)]
*  Let's keep moving through this docket. [[00:23:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1400.26s)]
*  We have David Sacks with us here. [[00:23:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1401.98s)]
*  So David, give us your philosophy of parenting. [[00:23:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1403.98s)]
*  Okay. [[00:23:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1406.46s)]
*  Next item on the docket. [[00:23:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1406.7800000000002s)]
*  Let's go. [[00:23:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1407.78s)]
*  So that's some real issues. [[00:23:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1410.74s)]
*  Parenting show. [[00:23:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1413.94s)]
*  The parenting show. [[00:23:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1415.06s)]
*  I asked David, what's your parenting philosophy? [[00:23:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1416.78s)]
*  He said, Oh, well, I set up their trust four years ago. [[00:23:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1419.3s)]
*  So he's done. [[00:23:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1421.58s)]
*  He's good. [[00:23:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1422.1399999999999s)]
*  Trust is set up. [[00:23:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1423.22s)]
*  Everything's good. [[00:23:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1424.1s)]
*  G R A T. [[00:23:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1426.3799999999999s)]
*  You're all set guys. [[00:23:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1430.78s)]
*  Let me know how it works out. [[00:23:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1432.1399999999999s)]
*  All right. [[00:23:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1434.1399999999999s)]
*  Speaking of working out, we've got a vice president who isn't cuckoo for [[00:23:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1434.74s)]
*  cocoa puffs and who actually understands what AI is. [[00:23:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1439.54s)]
*  JD Vance gave a great speech. [[00:24:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1443.42s)]
*  I watched it myself. [[00:24:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1445.74s)]
*  He talked about AI in Paris. [[00:24:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1446.82s)]
*  This was on Tuesday at the AI action summit, whatever that is. [[00:24:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1449.02s)]
*  And he gave a 15 minute banger of a speech. [[00:24:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1453.34s)]
*  He talked about over-regulating AI and America's intention to dominate this. [[00:24:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1455.74s)]
*  And we happen to have with us Naval de Czar. [[00:24:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1460.66s)]
*  The Czar of AI. [[00:24:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1464.66s)]
*  So before I go into all the details about the speech, I don't want to [[00:24:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1465.9s)]
*  steal your thunder. [[00:24:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1468.46s)]
*  Sax, this, this speech had a lot of verbiage, a lot of ideas that I've [[00:24:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1469.74s)]
*  heard before that maybe we've all talked about, maybe tell us a little bit about [[00:24:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1475.7s)]
*  how this all came together and how proud you are. [[00:24:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1479.34s)]
*  I mean, gosh, having a vice president who understands AI is just. [[00:24:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1482.82s)]
*  It's mind blowing. [[00:24:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1487.94s)]
*  He could speak on a topic. [[00:24:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1488.74s)]
*  That's topical credible. [[00:24:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1491.5s)]
*  This was an awesome moment for America. [[00:24:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1493.26s)]
*  I think. [[00:24:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1494.94s)]
*  What are you implying there, J Cal? [[00:24:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1495.7s)]
*  I'm implying you might've workshopped it with him. [[00:24:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1497.7s)]
*  No. [[00:24:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1499.8600000000001s)]
*  Or that he's smart. [[00:25:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1500.42s)]
*  Both of those things. [[00:25:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1501.7s)]
*  The vice president wrote the speech or at least directed all of it. [[00:25:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1502.7s)]
*  So the ideas came from him. [[00:25:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1505.94s)]
*  I'm not going to take any credit whatsoever for this. [[00:25:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1508.02s)]
*  Okay. [[00:25:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1510.3s)]
*  Well, it was on point. [[00:25:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1510.5800000000002s)]
*  Maybe you could talk about it. [[00:25:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1511.78s)]
*  I agree. [[00:25:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1512.6200000000001s)]
*  It was on point. [[00:25:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1512.8600000000001s)]
*  I think it was a very well crafted and well delivered speech. [[00:25:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1513.5800000000002s)]
*  He made four main points about the Trump administration's approach to AI. [[00:25:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1516.1000000000001s)]
*  He's going to ensure this is point one, that American AI continues to be the [[00:25:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1520.8999999999999s)]
*  gold standard. [[00:25:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1525.2199999999998s)]
*  Fantastic check. [[00:25:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1525.82s)]
*  Two, he says that the administration understands that excessive regulation [[00:25:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1526.9799999999998s)]
*  could kill AI just as it's taking off. [[00:25:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1531.6599999999999s)]
*  And he did this in front of all the EU elites who love regulation. [[00:25:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1534.02s)]
*  Did it on their home court. [[00:25:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1537.8999999999999s)]
*  And then he said, number three, AI must remain free from ideological bias. [[00:25:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1539.4599999999998s)]
*  As we've talked about here on this program. [[00:25:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1544.1799999999998s)]
*  And then number four, the White House, he said, will, quote, maintain a pro [[00:25:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1546.46s)]
*  worker growth path for AI so that it can be a potent tool for job creation in the [[00:25:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1551.46s)]
*  U.S. [[00:25:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1556.98s)]
*  So what are your thoughts on the four major bullet points and his speech here [[00:25:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1557.54s)]
*  in Paris? [[00:26:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1561.3799999999999s)]
*  Well, I think that the vice president, you knew he was going to deliver an [[00:26:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1563.22s)]
*  important speech as soon as he got up there and said that I'm here to talk [[00:26:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1567.62s)]
*  about not AI safety, but AI opportunity. [[00:26:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1572.46s)]
*  And to understand what a bracing statement that was, and really almost like [[00:26:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1576.1s)]
*  a shot across the bow, you have to understand the history and context of [[00:26:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1581.26s)]
*  these events. [[00:26:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1584.8999999999999s)]
*  For the last couple of years, the last couple of these events have been [[00:26:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1586.02s)]
*  exclusively focused on AI safety. [[00:26:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1588.62s)]
*  The last in-person event was in the UK at Bletchley Park and the whole [[00:26:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1590.6599999999999s)]
*  conference was devoted to AI safety. [[00:26:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1594.78s)]
*  Similarly, the European AI regulation obviously is completely preoccupied with [[00:26:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1597.3799999999999s)]
*  safety and trying to regulate away safety risks before they happen. [[00:26:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1602.82s)]
*  Similarly, you had the Biden EO, which was based around safety. [[00:26:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1607.1799999999998s)]
*  And then you have just the whole media coverage around AI, which is preoccupied [[00:26:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1610.1799999999998s)]
*  with all the risks from AI. [[00:26:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1615.58s)]
*  So to have the vice president get up there and say right off the bat that there [[00:26:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1618.06s)]
*  are other things to talk about in respect to AI besides safety risks, that [[00:27:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1621.6599999999999s)]
*  actually there are huge opportunities there, was a breath of fresh air. [[00:27:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1627.58s)]
*  And like I said, kind of a shot across the bow and yeah, you could almost see [[00:27:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1632.22s)]
*  some of the Eurocrats. [[00:27:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1636.3s)]
*  They needed their fainting couches after that. [[00:27:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1638.66s)]
*  Trudeau looks like his dog just died. [[00:27:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1642.38s)]
*  So I think that was just a really important statement right off the bat to [[00:27:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1644.02s)]
*  set the context for the speech, which is AI is a huge opportunity for all of us. [[00:27:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1648.02s)]
*  Because really that point just has not been made enough. [[00:27:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1653.54s)]
*  And it's true, there are risks, but when you look at the media coverage and when [[00:27:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1656.26s)]
*  you look at the dialogue that the regulators have had around this, they never [[00:27:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1659.94s)]
*  talk about the opportunities. [[00:27:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1664.18s)]
*  It's always just around the risk. [[00:27:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1665.3s)]
*  So I think that was a very important corrective. [[00:27:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1667.3400000000001s)]
*  And then like you said, he went on to say that the United States has to win this AI [[00:27:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1669.66s)]
*  race. We want to be the gold standard. [[00:27:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1674.54s)]
*  We want to dominate. [[00:27:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1676.18s)]
*  That was my favorite part. [[00:27:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1677.14s)]
*  Yeah. And by the way, that language about dominating AI and winning the global [[00:27:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1678.8600000000001s)]
*  race, that is in President Trump's executive order from week one. [[00:28:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1682.74s)]
*  So this is very much elaborating on the official policy of this administration. [[00:28:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1686.18s)]
*  And the vice president that went on to say that he specified how we would do that. [[00:28:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1691.06s)]
*  Right. We have to win some of these key building block technologies. [[00:28:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1694.98s)]
*  We want to win in chips. We want to win in AI models. [[00:28:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1698.42s)]
*  We want to win in applications. [[00:28:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1700.5800000000002s)]
*  He said we need to build. [[00:28:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1702.78s)]
*  We need to unlock energy for these companies. [[00:28:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1703.8600000000001s)]
*  And then most of all, we just need to be supportive towards them as opposed to [[00:28:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1706.7s)]
*  regulating them to death. [[00:28:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1709.66s)]
*  And he had a lot to say about the risk of overregulation, how often it's big [[00:28:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1711.5800000000002s)]
*  companies that want regulation. [[00:28:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1717.3000000000002s)]
*  He warned about regulatory capture, which our friend Bill Gurley would like. [[00:28:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1719.3000000000002s)]
*  And he said that, so basically having less regulation can actually be more fair, [[00:28:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1723.94s)]
*  can create a more level playing field for small companies as well as big companies. [[00:28:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1727.6200000000001s)]
*  And then he said to the Europeans that we want you to be partners with us. [[00:28:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1732.5400000000002s)]
*  We want to lead the world, but we want you to be our partners and benefit [[00:28:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1737.14s)]
*  from this technology that we're going to take the lead in creating. [[00:29:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1741.02s)]
*  But you also have to be a good partner to us. [[00:29:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1745.3s)]
*  And then he specifically called out the overregulation that Europeans have been [[00:29:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1747.6200000000001s)]
*  engaged in. He mentioned the Digital Services Act, which has acted as like a [[00:29:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1751.38s)]
*  speed trap for American companies. [[00:29:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1756.6200000000001s)]
*  It's American companies who've been overregulated and fined by these European [[00:29:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1758.26s)]
*  regulations because the truth of the matter is that it's American technology [[00:29:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1764.22s)]
*  companies that are winning the race. [[00:29:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1767.7s)]
*  And so when Europe passes these owners regulations, they fall most of all on [[00:29:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1769.74s)]
*  American companies. And he's basically saying we need you to rebalance and [[00:29:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1774.9s)]
*  correct this because it's not fair and it's not smart policy. [[00:29:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1779.06s)]
*  And it's not going to help us collectively win this AI race. [[00:29:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1782.6200000000001s)]
*  And that kind of brings me just to the last point is I don't think he mentioned [[00:29:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1785.78s)]
*  China by name, but clearly he talked about adversarial countries who are using AI [[00:29:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1788.5800000000002s)]
*  to control their populations, to engage in censorship and thought control. [[00:29:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1795.3400000000001s)]
*  And he basically painted a picture where it's like, yeah, you could go work with [[00:29:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1799.46s)]
*  them or you could work with us. [[00:30:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1802.7800000000002s)]
*  And we have hundreds of years of shared history together. [[00:30:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1804.6200000000001s)]
*  We believe in things like free speech, hopefully. [[00:30:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1808.14s)]
*  And we want you to work with us. [[00:30:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1811.3000000000002s)]
*  But if you are going to work with us, then you have to cooperate and we have to [[00:30:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1812.7800000000002s)]
*  create a reasonable regulatory regime. [[00:30:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1816.66s)]
*  Naval, did you see the speech and your thoughts just generally on JD Vance and [[00:30:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1819.98s)]
*  having somebody like this, you know, representing us and wanting to win [[00:30:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1824.82s)]
*  American exceptionalism? [[00:30:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1829.58s)]
*  Very surprising, very impressive. [[00:30:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1830.42s)]
*  I thought he was polite, optimistic. [[00:30:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1832.34s)]
*  And just very forward looking, just it's what you would expect an entrepreneur or [[00:30:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1835.7s)]
*  a smart investor to say. So I was very impressed. [[00:30:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1839.66s)]
*  I think the idea that America should win. Great. [[00:30:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1842.46s)]
*  I think that we should not regulate. [[00:30:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1845.22s)]
*  I also agree with I'm not an AI doomer. [[00:30:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1847.54s)]
*  I don't think AI is going to end the world. [[00:30:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1849.3s)]
*  That's a separate conversation. [[00:30:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1850.78s)]
*  But there's just a religion that comes along in many faces, which is that [[00:30:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1852.02s)]
*  climate change is going to end the world. [[00:30:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1856.42s)]
*  AI is going to end the world. Asteroids going to end the world. [[00:30:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1857.66s)]
*  Covid-19 is going to end the world. [[00:31:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1860.42s)]
*  And it just as a way of fixating your attention, right? [[00:31:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1862.26s)]
*  It captures everybody's attention at once. [[00:31:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1864.42s)]
*  It's a very seductive thing. [[00:31:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1866.02s)]
*  And I think in the case of AI, it's really been overplayed by incentive bias, [[00:31:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1867.9s)]
*  motivated reasoning by the companies ahead. [[00:31:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1872.8600000000001s)]
*  And they want to pull up the ladder behind them. [[00:31:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1875.42s)]
*  I think they genuinely believe it. [[00:31:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1877.46s)]
*  I think they generally believe that there's safety risks, [[00:31:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1878.78s)]
*  but I think they're motivated to believe in those safety risks. [[00:31:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1880.66s)]
*  And then they pass that along. [[00:31:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1883.1000000000001s)]
*  But it's kind of a weird position because they have to say, [[00:31:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1884.6200000000001s)]
*  oh, it's so dangerous that you shouldn't just let open source go at it. [[00:31:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1887.26s)]
*  And you should let just a few of us work with you on it. [[00:31:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1891.5400000000002s)]
*  But it's not so dangerous that a private company can't own the whole thing. [[00:31:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1894.1000000000001s)]
*  Because it was truly the Manhattan project. [[00:31:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1898.6200000000001s)]
*  If they were building nuclear weapons, you wouldn't want one company to own that. [[00:31:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1900.3000000000002s)]
*  No. Sam Altman famously said that AI will capture the light cone of all future value. [[00:31:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1903.5400000000002s)]
*  In other words, like all value ever created at the speed of light from here [[00:31:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1908.46s)]
*  will be captured by AI. [[00:31:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1911.7s)]
*  So if that's true, then I think open source AI really matters [[00:31:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1914.1000000000001s)]
*  and little tech AI really matters. [[00:31:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1917.54s)]
*  The problem is that the nature of training these models is highly centralized. [[00:31:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1919.74s)]
*  They benefit from supercomputer clustered compute. [[00:32:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1923.7s)]
*  So it's not clear how any decentralized model can compete. [[00:32:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1926.74s)]
*  So to me, the real issue boils down to is how do you push AI forward [[00:32:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1930.3000000000002s)]
*  while not having just a very small number of players control the entire thing? [[00:32:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1935.26s)]
*  And we thought we had that solution with the original open AI, [[00:32:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1939.42s)]
*  which was a nonprofit was supposed to do for humanity. [[00:32:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1942.26s)]
*  But now because of the one incentivize the team and they want to raise money, [[00:32:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1944.82s)]
*  they have to privatize at least a part of it. [[00:32:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1948.46s)]
*  Oh, that's not clear to me why they need to privatize the whole thing. [[00:32:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1950.46s)]
*  Like why do you need to buy out the nonprofit portion? [[00:32:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1952.82s)]
*  You could leave a nonprofit portion and you could have the private portion [[00:32:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1954.9s)]
*  for the incentives. [[00:32:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1958.14s)]
*  But I think that the real challenge is how do you keep AI [[00:32:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1959.9s)]
*  from naturally centralizing because all the economics [[00:32:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1963.86s)]
*  and the technology underneath are centralizing in nature? [[00:32:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1967.5s)]
*  If you really think you're going to get God, [[00:32:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1970.6999999999998s)]
*  do you want to put God on a leash with one entity controlling God? [[00:32:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1972.9799999999998s)]
*  That to me is the real fear. [[00:32:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1976.5s)]
*  Not I'm not scared of AI. [[00:32:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1978.4199999999998s)]
*  I'm scared of what a very small number of people who control AI [[00:33:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1980.1799999999998s)]
*  do to the rest of us for our own good, because that's how it always works. [[00:33:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1983.3s)]
*  So well said. Probably should go with the Greek model, [[00:33:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1987.1s)]
*  having many gods and heroes as well. [[00:33:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1988.8999999999999s)]
*  Freeberg, you heard the J.D. Vance speech, I assume. [[00:33:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1991.34s)]
*  What are your thoughts on overregulation? [[00:33:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1995.46s)]
*  And maybe to Naval's point, one person owning this versus open source. [[00:33:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=1998.3s)]
*  I think that there is this kind of big definition of social balance right now [[00:33:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2003.74s)]
*  on what I would call techno optimism and techno pessimism. [[00:33:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2009.02s)]
*  Generally, people sort of fall into one of those two camps. [[00:33:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2013.18s)]
*  Generally speaking, techno optimists, [[00:33:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2016.78s)]
*  I would say, are folks that believe that accelerating outcomes with AI, [[00:33:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2019.94s)]
*  with automation, with bioengineering, manufacturing, semiconductors, [[00:33:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2024.34s)]
*  quantum computing, nuclear energy, etc. [[00:33:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2028.26s)]
*  will usher in this era of abundance by making by creating leverage, [[00:33:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2031.22s)]
*  which is what technology gives us. [[00:33:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2035.26s)]
*  Technology will make things cheaper and it will be deflationary [[00:33:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2038.06s)]
*  and will give everyone more. So it creates abundance. [[00:34:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2041.74s)]
*  The challenge is that people who already have a lot [[00:34:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2045.1s)]
*  worry more about the exposure to the downside than they desire the upside. [[00:34:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2048.14s)]
*  And so, you know, the techno pessimists are generally like the EU [[00:34:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2053.54s)]
*  and large parts, frankly, of the United States are worried about the loss of X, [[00:34:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2058.2200000000003s)]
*  the loss of jobs, the loss of this, the loss of that. [[00:34:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2064.2200000000003s)]
*  Whereas countries like China and India are more excited about the opportunity [[00:34:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2067.38s)]
*  to create wealth, the opportunity to create leverage, the opportunity [[00:34:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2072.98s)]
*  to create abundance for their people. [[00:34:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2075.66s)]
*  You know, GDP per capita in the EU, sixty thousand dollars a year, [[00:34:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2077.38s)]
*  GDP per capita in the United States, like eighty two thousand. [[00:34:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2081.6600000000003s)]
*  But GDP per capita in India is twenty five hundred and China's twelve thousand six hundred. [[00:34:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2085.06s)]
*  There's a greater incentive in those countries to manifest upside [[00:34:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2089.02s)]
*  than there is for the United States and the EU, who are more worried [[00:34:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2094.42s)]
*  about manifesting downside. [[00:34:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2098.02s)]
*  And so it is a very difficult kind of social battle that's underway. [[00:34:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2099.78s)]
*  I do think like over time, those governments and those countries [[00:35:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2104.3399999999997s)]
*  and those social systems that embrace these technologies are going to become more capitalist [[00:35:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2108.1s)]
*  and they're going to require less government control and intervention in job creation, [[00:35:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2113.5s)]
*  the economy, payments to people and so on. [[00:35:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2118.18s)]
*  And the countries that are more techno pessimistic are unfortunately going to find themselves [[00:35:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2121.18s)]
*  asking for greater government control, government intervention in markets, [[00:35:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2125.02s)]
*  governments creating jobs, government making payments to people, governments [[00:35:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2129.14s)]
*  effectively running the economy. [[00:35:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2132.5s)]
*  My personal view, obviously, is that I'm a very strong advocate [[00:35:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2134.7000000000003s)]
*  for technology acceleration, because I think in nearly every case in human history, [[00:35:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2139.3s)]
*  when a new technology has emerged, we've largely found ourselves assuming [[00:35:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2143.46s)]
*  that the technology works in the framework of today or of yesteryear. [[00:35:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2147.86s)]
*  The automobile came along and no one envisioned that everyone [[00:35:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2152.5s)]
*  in the United States would own an automobile and therefore you would need to create [[00:35:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2156.1000000000004s)]
*  all of these new industries like mechanics and car dealerships, [[00:35:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2159.18s)]
*  roads, all the people servicing building roads and all the other industry that emerged. [[00:36:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2163.5s)]
*  And it's very hard for us to sit here today and say, OK, [[00:36:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2168.5s)]
*  AI is going to destroy jobs. [[00:36:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2171.8599999999997s)]
*  What's it going to create and be right? [[00:36:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2173.4199999999996s)]
*  I think we're very likely going to be wrong. [[00:36:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2175.3399999999997s)]
*  Whatever estimations we give, the area that I think is most underestimated [[00:36:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2177.18s)]
*  is the large technical projects that seem technically infeasible today [[00:36:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2181.14s)]
*  that AI can unlock. For example, habitation in [[00:36:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2185.54s)]
*  in the oceans. Like it's very difficult for us to envision, like creating cities [[00:36:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2189.02s)]
*  underwater and creating cities in the oceans or creating cities on the moon [[00:36:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2193.4199999999996s)]
*  or creating cities on Mars or finding new places to live. [[00:36:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2196.8999999999996s)]
*  Those are like technically people might argue, oh, that sounds stupid. [[00:36:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2199.18s)]
*  I don't want to go do that. [[00:36:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2202.2599999999998s)]
*  But at the end of the day, like human civilization will drive us to want to do that. [[00:36:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2203.02s)]
*  But those technically are very hard to pull off today. [[00:36:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2207.2999999999997s)]
*  But AI can unlock a new set of industries to enable those transitions. [[00:36:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2209.58s)]
*  So I think we really get it wrong when we try and assume the technology [[00:36:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2213.3799999999997s)]
*  as a transplant for last year or last century. [[00:36:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2217.3s)]
*  And then we kind of become techno pessimists because we're worried [[00:37:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2220.5s)]
*  about losing what we have. [[00:37:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2222.82s)]
*  Are you a techno pessimist? Are you optimist? [[00:37:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2223.94s)]
*  Because you bring up the downside of an awful lot here on the program. [[00:37:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2226.0600000000004s)]
*  But you are working every day in a very optimistic way to breed, [[00:37:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2229.46s)]
*  you know, better strawberries and potatoes for folks. [[00:37:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2233.98s)]
*  So you're a little bit of no, I have no techno pessimism whatsoever. [[00:37:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2236.2200000000003s)]
*  I try and point out why the other side is acting the way they are. [[00:37:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2239.94s)]
*  OK, putting it in full context. [[00:37:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2242.6200000000003s)]
*  And what I'm trying to highlight is I think that that framework is wrong. [[00:37:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2244.38s)]
*  I think that that framework of trying to transplant new technology [[00:37:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2247.02s)]
*  to the old way of things operating is the wrong way to think about it. [[00:37:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2251.14s)]
*  And it creates this, you know, because of this manifestation [[00:37:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2254.54s)]
*  about worrying about downside, it creates this fear that creates regulation [[00:37:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2256.94s)]
*  like we see in the EU. [[00:37:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2260.74s)]
*  And as a result, China's GDP will scale while the EUs will stagnate. [[00:37:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2261.9s)]
*  If that's where they go. [[00:37:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2266.2599999999998s)]
*  That's my assessment or my opinion on what will happen. [[00:37:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2267.34s)]
*  Chamath, you want to wrap this up for us? [[00:37:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2269.74s)]
*  What are your thoughts on JD? I'll give you two. [[00:37:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2271.18s)]
*  OK, the first is I would say this is a really interesting moment [[00:37:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2274.2999999999997s)]
*  where I would call this the tale of two vice presidents. [[00:37:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2278.54s)]
*  Very early in the Biden administration, Kamala was dispatched [[00:38:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2281.9799999999996s)]
*  on an equally important topic at that time, which was illegal immigration. [[00:38:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2286.2999999999997s)]
*  And she went to Mexico and Guatemala. [[00:38:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2290.54s)]
*  And so you actually have a really interesting A.B. test here. [[00:38:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2292.9399999999996s)]
*  You have both vice presidents dealing with what we're in the moment, [[00:38:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2297.54s)]
*  incredibly important issues. [[00:38:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2302.38s)]
*  And I think that JD was focused. [[00:38:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2303.86s)]
*  He was precise. He was ambitious. [[00:38:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2307.1s)]
*  And even the part of the press that was very supportive of Kamala [[00:38:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2311.82s)]
*  couldn't find a lot of very positive things to say about her. [[00:38:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2317.2200000000003s)]
*  And the feedback was it was meandering. [[00:38:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2320.5s)]
*  She was ducking questions. [[00:38:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2323.2200000000003s)]
*  She didn't answer the questions that she was asked very well. [[00:38:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2325.34s)]
*  And it's so interesting because it's a bit of a microcosm [[00:38:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2329.2200000000003s)]
*  than to what happened over these next four years in her campaign, quite honestly, [[00:38:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2331.62s)]
*  which you could have taken that window of that feedback. [[00:38:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2335.06s)]
*  And unfortunately for her, it just continued to be very consistent. [[00:38:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2338.46s)]
*  So that was one observation I had because I heard him give the speech. [[00:39:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2342.62s)]
*  I heard her. [[00:39:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2346.22s)]
*  And I had this kind of moment where I was like, wow, two totally different people. [[00:39:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2347.7s)]
*  The second is on the substance of what JD said. [[00:39:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2353.42s)]
*  I said this on Tucker and I'll just simplify all of this into a very basic framework, [[00:39:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2356.14s)]
*  which is if you want a country to thrive, [[00:39:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2360.46s)]
*  it needs to have economic supremacy [[00:39:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2364.7400000000002s)]
*  and it needs to have military supremacy. [[00:39:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2368.2200000000003s)]
*  In the absence of those two things, societies crumble. [[00:39:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2371.38s)]
*  And the only thing that underpins those two things is technological supremacy. [[00:39:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2375.62s)]
*  And we see this today. [[00:39:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2379.34s)]
*  So on Thursday, what happened with Microsoft? [[00:39:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2380.82s)]
*  They had a 24 billion dollar contract with the United States Army [[00:39:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2384.34s)]
*  to deliver some whiz bang thing. [[00:39:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2388.62s)]
*  And they realized that they couldn't deliver it. [[00:39:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2391.2599999999998s)]
*  And so what did they do? They went to Anderil. [[00:39:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2394.3399999999997s)]
*  Now, why did they go to Anderil? [[00:39:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2397.14s)]
*  Because Anderil has the technological supremacy to actually execute. [[00:39:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2398.3399999999997s)]
*  A few weeks ago, we saw some attempts at technological supremacy [[00:40:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2402.66s)]
*  from the Chinese with respect to DeepSeek. [[00:40:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2406.7s)]
*  So I think that this is a very simple existential battle. [[00:40:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2409.3399999999997s)]
*  Those who can harness and govern. [[00:40:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2412.98s)]
*  The things that are technologically superior will win [[00:40:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2415.8199999999997s)]
*  and it will drive economic vibrancy and military supremacy, [[00:40:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2420.2999999999997s)]
*  which then creates safe, strong societies. [[00:40:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2425.1s)]
*  That's it. So from that perspective, JD nailed it. [[00:40:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2428.2999999999997s)]
*  He saw the forest from the trees. [[00:40:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2431.94s)]
*  He said exactly what I think needed to be said [[00:40:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2433.54s)]
*  and put folks on notice that you're either on the ship or you're off the ship. [[00:40:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2437.38s)]
*  And I think that that was really good. [[00:40:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2440.38s)]
*  Yeah. And there was like a little secondary conversation [[00:40:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2441.82s)]
*  that emerged, Sax, that I would love to engage you with, if you're willing, [[00:40:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2446.5800000000004s)]
*  which is this civil war, quote unquote, between maybe MAGA 1.0, MAGA 2.0, [[00:40:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2451.02s)]
*  techies in the MAGA party like ourselves, [[00:40:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2458.42s)]
*  and maybe the core MAGA folks. [[00:41:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2462.34s)]
*  We can pull up the tweet here in JD's own word, [[00:41:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2465.5800000000004s)]
*  and he's been engaging people in his own words. [[00:41:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2468.46s)]
*  It's very clear that he's writing these tweets, [[00:41:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2473.3399999999997s)]
*  a distinct difference between other politicians in this administration. [[00:41:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2475.7s)]
*  And they just tell you what they think. Here it is. [[00:41:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2479.74s)]
*  I'll try and write something to address this in detail. [[00:41:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2483.3399999999997s)]
*  So JD Vance's tweet. [[00:41:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2485.8199999999997s)]
*  But I think this civil war is overstated, though, yes, [[00:41:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2487.3399999999997s)]
*  there are some real divergences between the populace. [[00:41:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2490.9s)]
*  I would describe that as MAGA and the techies. [[00:41:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2493.7s)]
*  But briefly, in general, I dislike substituting American labor for cheap labor. [[00:41:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2496.02s)]
*  My views on immigration and offshoring flow from this, [[00:41:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2500.1s)]
*  I like growth and productivity gains. [[00:41:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2502.78s)]
*  And this informs my view on tech and regulation when it comes to AI. [[00:41:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2505.46s)]
*  Specifically, the risks are number one overstated to your point, [[00:41:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2509.06s)]
*  Neval, or two difficult to avoid. [[00:41:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2513.2599999999998s)]
*  One of my many real concerns, for instance, is about consumer fraud. [[00:41:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2516.38s)]
*  That's a valid reason to worry about safety. [[00:42:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2521.14s)]
*  But the other problem is much worse. [[00:42:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2523.5s)]
*  If a pure nation is six months ahead of the US on AI. [[00:42:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2525.2200000000003s)]
*  Again, I'll try and say more. [[00:42:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2528.94s)]
*  And this is JD going right at, I think, one of the more controversial topics, Saks. [[00:42:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2530.2200000000003s)]
*  That the administration is dealing with and has dealt with [[00:42:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2536.34s)]
*  when it comes to immigration and tech, because these two things are dovetailing [[00:42:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2539.5s)]
*  each other. If we lose millions of driver jobs, which we will in the next 10 years, [[00:42:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2543.6600000000003s)]
*  just like we lost millions of cashier jobs. [[00:42:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2548.94s)]
*  Well, that's going to impact how our nation and many of the voters look at [[00:42:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2551.78s)]
*  the border and immigration. [[00:42:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2557.7000000000003s)]
*  We might not be able to let as many people immigrate here [[00:42:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2559.06s)]
*  if we're losing millions of jobs to AI and self-driving cars. [[00:42:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2562.3s)]
*  What are your thoughts on him engaging this directly, Saks? [[00:42:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2566.1400000000003s)]
*  Well, the first point he's making there is about wage pressure, right? [[00:42:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2569.34s)]
*  Which is when you throw open our borders or you throw open American markets [[00:42:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2573.2200000000003s)]
*  to products that can be made. [[00:42:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2577.06s)]
*  In foreign countries by much cheaper labor that's not held to the same standards, [[00:42:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2579.46s)]
*  the same minimum wage or the same union rules or the same safety standards [[00:43:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2583.62s)]
*  that American labor is and has a huge cost advantage, then you're creating [[00:43:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2587.06s)]
*  wage pressure for American workers. [[00:43:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2590.46s)]
*  And he's opposed to that. [[00:43:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2592.38s)]
*  And I think that is an important point, because I think the way [[00:43:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2593.98s)]
*  that the media or neoliberals like to portray this argument is that somehow. [[00:43:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2597.2200000000003s)]
*  MAGA's resistance to unlimited immigration is somehow based on xenophobia [[00:43:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2602.42s)]
*  or something like that. No, it's based on [[00:43:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2606.82s)]
*  bread and butter kitchen table issues, which is if you have this [[00:43:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2609.22s)]
*  ridiculous open border policy, it's inevitably going to create [[00:43:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2614.18s)]
*  a lot of wage pressure for people at the bottom of the pyramid. [[00:43:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2617.22s)]
*  So I think JD is making that argument. [[00:43:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2620.74s)]
*  But this is point two, he's saying I'm not against productivity growth. [[00:43:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2623.22s)]
*  So technology is good because it enables all of our workers [[00:43:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2627.4599999999996s)]
*  to improve their productivity. [[00:43:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2630.8199999999997s)]
*  And that should result in better wages because workers can produce more. [[00:43:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2632.3399999999997s)]
*  The value of their labor goes up if they have more tools to be productive. [[00:43:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2637.3s)]
*  So there's no contradiction there. [[00:44:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2641.2200000000003s)]
*  And I think he's explaining why there isn't a contradiction. [[00:44:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2642.46s)]
*  A point I would add, he doesn't make this point in that tweet, [[00:44:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2645.5s)]
*  but I would add is that one of the problems that we've had over the last [[00:44:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2648.54s)]
*  30 years is that we have had tremendous productivity growth in the U.S. [[00:44:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2652.94s)]
*  But labor has not been able to capture it. [[00:44:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2656.98s)]
*  All that benefit has basically gone to capital or to companies. [[00:44:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2659.1400000000003s)]
*  And I think a big part of the reason why is because we've had this [[00:44:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2662.86s)]
*  largely unrestricted immigration policy. [[00:44:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2665.9s)]
*  So I think if you were to tamp down on immigration, [[00:44:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2668.7000000000003s)]
*  if you were to stop the illegal immigration, then labor might be able [[00:44:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2672.34s)]
*  to capture more of the benefits of productivity growth. [[00:44:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2675.86s)]
*  And that would be a good thing. [[00:44:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2678.06s)]
*  It'd be a more equitable distribution of the gains from [[00:44:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2679.06s)]
*  productivity and from technology. [[00:44:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2684.34s)]
*  And that, I think, would help. [[00:44:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2686.38s)]
*  Tamp down this growing conflict that you see between [[00:44:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2689.2200000000003s)]
*  technologists and the rest of the country, [[00:44:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2693.34s)]
*  or certainly the heartland of the country. [[00:44:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2695.9s)]
*  Naval, this is, you want to add anything else, David? [[00:44:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2697.78s)]
*  Well, I think just the final point he makes in that tweet is that [[00:45:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2700.78s)]
*  he talks about how we live in a world in which there are other countries [[00:45:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2704.3s)]
*  that are competitive. [[00:45:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2707.7000000000003s)]
*  And specifically, he doesn't mention China, but he says, [[00:45:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2708.42s)]
*  we have a peer competitor and it's going to be a much worse world [[00:45:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2710.7000000000003s)]
*  if they end up being six months ahead of us on AI rather than six months behind. [[00:45:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2715.2200000000003s)]
*  That is a really important point to keep in mind. [[00:45:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2719.38s)]
*  I think that the whole Paris AI Summit took place against the backdrop [[00:45:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2721.62s)]
*  of this recognition, because just a few weeks ago we had deep sea. [[00:45:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2726.02s)]
*  And it's really clear that China is not a year behind us. [[00:45:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2729.62s)]
*  They're hot on our heels or only maybe months behind us. [[00:45:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2732.74s)]
*  And so if we hobble ourselves with unnecessary regulations, [[00:45:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2736.38s)]
*  if we make it more difficult for our AI companies to compete, [[00:45:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2739.9s)]
*  that doesn't mean that China is going to follow suit and copy us. [[00:45:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2743.62s)]
*  They're going to take advantage of that fact and they're going to win. [[00:45:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2745.98s)]
*  All right, Naval, this seems to be one of the main issues of our time. [[00:45:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2748.06s)]
*  Four of the five people on this podcast right now are immigrants. [[00:45:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2751.8199999999997s)]
*  So we have this amazing tradition in America. [[00:45:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2755.42s)]
*  This is a country built by immigrants for immigrants. [[00:45:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2757.74s)]
*  Do you think that should change now in the face of job destruction, [[00:46:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2761.42s)]
*  which I know you've been tracking self-driving pretty acutely. [[00:46:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2765.18s)]
*  We both have an interest there, I think, over the years. [[00:46:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2770.38s)]
*  You know, what's the solution here? [[00:46:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2773.62s)]
*  If we're going to see a bunch of job displacement, [[00:46:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2776.5s)]
*  which will happen for certain jobs, we all kind of know that. [[00:46:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2779.98s)]
*  Should we shut the border and not let the next Naval, Chamath, [[00:46:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2784.2200000000003s)]
*  Saxon, and Friedberg into the country? [[00:46:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2786.7000000000003s)]
*  Well, let me declare my biases up front. [[00:46:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2788.2200000000003s)]
*  I'm a first generation immigrant. [[00:46:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2790.1800000000003s)]
*  I moved here when I was nine years old, rather my parents did. [[00:46:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2791.54s)]
*  And then I naturalized citizen. [[00:46:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2794.58s)]
*  So obviously, I'm in favor of some level of immigration. [[00:46:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2797.38s)]
*  That said, I'm assimilated. [[00:46:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2800.2200000000003s)]
*  I consider myself an American first and foremost. [[00:46:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2801.62s)]
*  I bleed red, white and blue. [[00:46:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2804.82s)]
*  I believe in the Bill of Rights and the Constitution, [[00:46:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2807.22s)]
*  first and second and fourth and all the proper amendments. [[00:46:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2810.62s)]
*  I get up there every July 4th and I deliberately defend the Second Amendment [[00:46:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2814.2599999999998s)]
*  on Twitter, at which point half my followers go bananas. [[00:46:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2817.8199999999997s)]
*  Because you're not supposed to. [[00:47:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2822.8599999999997s)]
*  I'm supposed to be a good immigrant, right? [[00:47:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2823.98s)]
*  And carry the usual set of coherent leftist policies, globalist policies. [[00:47:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2825.8599999999997s)]
*  So I think that legal high skill immigration [[00:47:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2831.54s)]
*  with room and time for assimilation makes sense. [[00:47:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2836.46s)]
*  You want to have a brain drain on the best and brightest coming to the freest [[00:47:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2840.06s)]
*  country in the world to build technology and to help civilization move forward. [[00:47:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2842.86s)]
*  And, you know, as Chamath was saying, economic power [[00:47:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2849.34s)]
*  and military power is downstream of technology. [[00:47:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2852.62s)]
*  In fact, even culture is downstream of technology. [[00:47:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2855.46s)]
*  Look at what the birth control pill did, for example, to culture, [[00:47:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2858.86s)]
*  or what the automobile did to culture, or what radio and television did to culture. [[00:47:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2861.2599999999998s)]
*  And then the Internet. [[00:47:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2865.38s)]
*  So technology drives everything. [[00:47:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2866.42s)]
*  And if you look at wealth, wealth is a set of physical transformations that you can affect. [[00:47:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2868.1s)]
*  And that's a combination of capital knowledge. [[00:47:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2872.54s)]
*  And the bigger input to that is knowledge. [[00:47:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2874.86s)]
*  And so the U.S. has become the home of knowledge creation, [[00:47:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2876.78s)]
*  thanks to bringing in the best and brightest. [[00:48:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2880.1s)]
*  You could even argue deep seek. [[00:48:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2882.06s)]
*  Part of the reason why we lost that is because a bunch of those kids, [[00:48:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2883.38s)]
*  they studied in the U.S., but then we sent them back home. [[00:48:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2886.1800000000003s)]
*  So I think you absolutely. [[00:48:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2888.94s)]
*  Is that actually accurate? [[00:48:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2889.98s)]
*  They were. Yeah, yeah, yeah. [[00:48:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2891.3s)]
*  Some a few of them. Really? [[00:48:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2892.7400000000002s)]
*  Oh, my God, that's like exhibit a. [[00:48:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2894.14s)]
*  Wow. So I think you absolutely have to split skilled, [[00:48:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2896.54s)]
*  assimilated immigration, which is a small set. [[00:48:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2900.94s)]
*  And it has to be both. [[00:48:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2904.2599999999998s)]
*  They have to both be skilled and they have to become Americans. [[00:48:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2905.2599999999998s)]
*  That oath is not meaningless. [[00:48:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2907.5s)]
*  Right. It has to mean something. [[00:48:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2909.2599999999998s)]
*  So skilled, assimilated immigration. [[00:48:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2910.7s)]
*  You have to separate that from just open borders. [[00:48:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2913.1s)]
*  Whoever can wander in just come on in. [[00:48:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2915.3399999999997s)]
*  That latter part makes no sense. [[00:48:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2916.8599999999997s)]
*  If the Biden administration had only been letting in people with 150 IQs, [[00:48:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2918.7s)]
*  we wouldn't have this debate right now. [[00:48:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2923.02s)]
*  The reason why we're having this debate is because they just open the border [[00:48:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2925.14s)]
*  and let millions and millions of people in. [[00:48:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2929.14s)]
*  It was to their advantage to conflate legal and illegal immigration. [[00:48:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2930.7s)]
*  So every time you would be like, well, we can't just open the borders to say, [[00:48:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2934.14s)]
*  well, what about Elon? What about this? [[00:48:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2937.18s)]
*  And they would just parade. [[00:48:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2939.42s)]
*  If they were just letting the Elons and the Jensen's and Friedberg's, [[00:49:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2940.42s)]
*  we wouldn't be having the same conversation today. [[00:49:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2945.46s)]
*  The correlation between open borders and wage suppression is irrefutable. [[00:49:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2947.9s)]
*  We know that data. [[00:49:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2952.78s)]
*  And I think that the Democrats, for whatever logic, [[00:49:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2953.82s)]
*  committed an incredible error in basically undermining their core cohort. [[00:49:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2958.46s)]
*  I want to go back to what you said, because I think it's super important. [[00:49:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2965.86s)]
*  There is a new political calculus on the field. [[00:49:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2968.78s)]
*  And I agree with you. [[00:49:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2972.7000000000003s)]
*  I think that the three cohorts of the future [[00:49:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2974.94s)]
*  are the asset light working in middle class. [[00:49:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2978.86s)]
*  That's cohort number one. [[00:49:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2982.1400000000003s)]
*  There are probably 100 to 150 million of those folks. [[00:49:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2983.5s)]
*  Then there are patriotic business owners. [[00:49:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2989.2200000000003s)]
*  And then there's leaders in innovation. [[00:49:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2992.98s)]
*  Those are the three. [[00:49:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2995.58s)]
*  And I think that what MAGA gets right is they found the middle ground [[00:49:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=2996.7400000000002s)]
*  that intersects those three cohorts of people. [[00:50:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3001.6600000000003s)]
*  And so every time you see this sort of left versus right dichotomy, [[00:50:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3004.66s)]
*  it's totally miscast. [[00:50:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3009.2999999999997s)]
*  And it sounds discordant to so many of us [[00:50:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3010.66s)]
*  because that's not how any of us identify. [[00:50:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3012.8599999999997s)]
*  And I think that that's a very important observation [[00:50:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3015.66s)]
*  because the policies that we adapt [[00:50:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3017.7799999999997s)]
*  will need to reflect those three cohorts. [[00:50:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3019.8599999999997s)]
*  What is the common ground amongst those three? [[00:50:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3021.66s)]
*  And on that point, Naval is right. [[00:50:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3024.1s)]
*  There's not a lot that those three would say is wrong [[00:50:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3026.1s)]
*  with a very targeted form of extremely useful legal immigration, [[00:50:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3029.02s)]
*  very, very, very smart people who agree to assimilate [[00:50:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3034.06s)]
*  and be a part of America. [[00:50:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3038.38s)]
*  I mean, I'm so glad you said it the way you said it. [[00:50:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3039.54s)]
*  Like I remember growing up where my parents [[00:50:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3041.42s)]
*  would try to pretend that they were in Sri Lanka. [[00:50:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3045.9s)]
*  And sometimes I would get so frustrated. [[00:50:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3047.74s)]
*  I'm like, if you want to be in Sri Lanka, go back to Sri Lanka. [[00:50:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3049.14s)]
*  I want to be Canadian because it was easier for me to make friends. [[00:50:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3054.42s)]
*  It was easier for me to have a life. [[00:50:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3058.02s)]
*  I was trying my best. [[00:50:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3059.5s)]
*  I wanted to be Canadian. [[00:51:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3060.7s)]
*  And then when I moved to the United States, [[00:51:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3061.82s)]
*  25 years ago, I wanted to be American. [[00:51:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3063.9s)]
*  And I feel that I'm American now and I'm proud to be an American. [[00:51:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3067.58s)]
*  And I think that's what you want. [[00:51:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3071.5s)]
*  You want people that embrace it. [[00:51:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3072.82s)]
*  Doesn't mean that we can't dress up in a show [[00:51:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3074.26s)]
*  or chemise every now and then. [[00:51:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3076.06s)]
*  But the point is, like, what do you believe? [[00:51:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3077.94s)]
*  And where is your loyalty? [[00:51:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3080.62s)]
*  Freeberg, we used to have this concept of a melting pot [[00:51:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3082.02s)]
*  of this assimilation, and that was a good thing. [[00:51:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3086.1800000000003s)]
*  Then it became cultural appropriation. [[00:51:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3089.1s)]
*  We kind of made a right turn here. [[00:51:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3090.7000000000003s)]
*  Where do you stand on this? [[00:51:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3092.5s)]
*  Recruiting the best and brightest and forcing them to assimilate, [[00:51:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3094.1800000000003s)]
*  making sure that they're down with Jason. [[00:51:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3098.9s)]
*  Like, find the people that care to be here. [[00:51:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3100.78s)]
*  Yeah, let me say that. [[00:51:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3103.5s)]
*  I reject the premise of this whole conversation. [[00:51:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3105.46s)]
*  Wait, hold on. Look, I'm a first generation American [[00:51:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3108.86s)]
*  who moved here when I was five and became a citizen when I was 10. [[00:51:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3112.7000000000003s)]
*  And yes, I'm fully American, and that's the only country I have any loyalty to. [[00:51:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3116.0600000000004s)]
*  But the premise that I reject here is that somehow an AI [[00:52:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3120.7400000000002s)]
*  conversation leads to an immigration conversation [[00:52:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3125.5s)]
*  because millions of jobs are going to be lost. [[00:52:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3127.78s)]
*  We don't know that. That's also true. [[00:52:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3129.66s)]
*  I agree. You're making a huge assumption. [[00:52:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3131.5s)]
*  I completely agree. That's buying into the doomerism. [[00:52:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3133.34s)]
*  That AI is going to wipe out millions of jobs. [[00:52:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3135.58s)]
*  That is not an evidence. [[00:52:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3137.46s)]
*  I think it's going to create more jobs than any of us are imagining. [[00:52:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3139.86s)]
*  Have any jobs been lost by AI? [[00:52:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3141.9s)]
*  Let's be real. [[00:52:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3143.7000000000003s)]
*  We've had AI for two and a half years, and I think it's great. [[00:52:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3144.5s)]
*  But so far, it's a better search engine. [[00:52:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3147.1800000000003s)]
*  And it helps high school kids cheat on their essays. [[00:52:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3149.26s)]
*  I mean, you don't believe that self-driving is coming. [[00:52:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3152.2200000000003s)]
*  Hold on a second, Sachs. [[00:52:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3155.5s)]
*  You don't believe that millions. [[00:52:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3156.6200000000003s)]
*  But hold on. Those driver jobs weren't even there 10 years ago. [[00:52:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3158.38s)]
*  Uber came along and created all these driver jobs. [[00:52:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3162.0600000000004s)]
*  DoorDash created all these driver jobs. [[00:52:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3164.26s)]
*  So what technology does to yes, technology destroys jobs, [[00:52:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3165.9s)]
*  but it replaces them with opportunities that are even better. [[00:52:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3169.82s)]
*  And then either you can go capture that opportunity yourself [[00:52:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3172.7400000000002s)]
*  or an entrepreneur will come along and create something [[00:52:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3175.6600000000003s)]
*  that allows you to capture those opportunities. [[00:52:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3177.74s)]
*  AI is a productivity tool. [[00:53:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3180.1s)]
*  It increases the productivity of a worker. [[00:53:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3182.06s)]
*  It allows them to do more creative work and less repetitive work. [[00:53:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3184.02s)]
*  As such, it makes them more valuable. [[00:53:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3186.7s)]
*  Yes, there is some retraining involved, but not a lot. [[00:53:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3188.8599999999997s)]
*  These are natural language computers. [[00:53:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3191.06s)]
*  You can talk to them in plain English. [[00:53:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3192.4599999999996s)]
*  They talk back to you in plain English. [[00:53:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3193.7799999999997s)]
*  But I think David is absolutely right. [[00:53:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3195.5s)]
*  I think we will see job creation by AI that will be as fast or faster than job destruction. [[00:53:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3197.54s)]
*  You saw this even with the Internet, like YouTube came along. [[00:53:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3203.22s)]
*  Look at all these YouTube streamers and influencers. [[00:53:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3205.54s)]
*  That didn't used to be a job. [[00:53:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3207.54s)]
*  New jobs, really opportunities, because job is a wrong word. [[00:53:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3209.1s)]
*  Job implies someone else has to give it to me and sort of like they're handed out. [[00:53:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3212.62s)]
*  It's a zero sum game. Forget all that. [[00:53:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3216.7s)]
*  It's opportunities. [[00:53:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3218.9s)]
*  After COVID, look at how many people are making money [[00:53:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3220.42s)]
*  by working from home in mysterious little ways on the Internet [[00:53:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3224.3s)]
*  that you can't even quite grasp. [[00:53:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3227.58s)]
*  Here's the way I categorize it. [[00:53:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3229.22s)]
*  OK, is that whenever you have a new technology, you get productivity gains. [[00:53:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3230.98s)]
*  You get some job disruption, meaning that part of your job may go away, [[00:53:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3234.74s)]
*  but then you get other parts that are new and hopefully more elevated, [[00:53:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3239.7799999999997s)]
*  more interesting. And then there is some job loss. [[00:54:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3243.7799999999997s)]
*  I just think that the third category will follow the historical trend, [[00:54:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3246.3799999999997s)]
*  which is that the first two categories are always bigger. [[00:54:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3251.06s)]
*  And you end up with more net productivity and more net wealth creation. [[00:54:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3253.74s)]
*  And we've seen no evidence to date that that's not going to be the case. [[00:54:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3257.58s)]
*  Now, it's true that AI is about to get more powerful. [[00:54:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3260.8199999999997s)]
*  You're going to see a whole new wave of what are called agents this year, [[00:54:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3262.86s)]
*  agentic products are able to do more for you. [[00:54:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3266.2200000000003s)]
*  But there's no evidence yet that those things are going to be completely [[00:54:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3269.5s)]
*  unsupervised and replace people's jobs. [[00:54:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3272.1800000000003s)]
*  So, you know, I think that we have to see how this technology evolves. [[00:54:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3274.46s)]
*  And I think one of the mistakes of, let's call it the European approach, [[00:54:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3278.34s)]
*  is assuming that you can predict the future with perfect accuracy [[00:54:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3282.26s)]
*  or such good accuracy that you can create regulations today [[00:54:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3286.26s)]
*  that are going to avoid all these risks in the future. [[00:54:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3290.66s)]
*  And we just don't know enough yet to be able to do that. [[00:54:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3292.9s)]
*  That's a false level of certainty. [[00:54:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3295.86s)]
*  I agree with you. [[00:54:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3297.54s)]
*  And the companies that are promulgating that view is what Naval said. [[00:54:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3298.5s)]
*  Those that have an economic vested interest in at least convincing [[00:55:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3303.58s)]
*  the next incremental investor that this could be true [[00:55:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3308.18s)]
*  because they want to make the claim that all the money should go to them [[00:55:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3310.66s)]
*  so they could hoover up all the economic gains. [[00:55:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3313.2599999999998s)]
*  And that is the part of the cycle we're in. [[00:55:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3315.78s)]
*  So if you actually stratify these reactions, there's the small startup [[00:55:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3318.02s)]
*  companies in AI that believe there's a productivity leap to be had [[00:55:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3323.18s)]
*  and that there's going to be prosperity. [[00:55:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3326.38s)]
*  Everybody on the sidelines watching. [[00:55:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3328.94s)]
*  And then a few companies that have an extremely vested interest [[00:55:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3330.7400000000002s)]
*  in them being a gatekeeper because they need to raise the next [[00:55:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3334.3s)]
*  30 or 40 billion dollars trying to convince people that that's true. [[00:55:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3337.38s)]
*  And if you view it through that lens, you're right, Sax. [[00:55:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3340.54s)]
*  We have not accomplished anything yet that proves that this is going to be [[00:55:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3342.7s)]
*  cataclysmically bad. [[00:55:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3346.02s)]
*  And if anything right now, history would tell you it's probably going to be [[00:55:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3348.14s)]
*  like the past, which is generally productive and a creative society. [[00:55:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3351.14s)]
*  Yeah. And just to bring it back to JD's speech, which is where we started, [[00:55:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3355.42s)]
*  I think it was a quintessentially American speech in the sense that he said [[00:55:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3358.7400000000002s)]
*  we should be optimistic about the opportunities here, which I think is [[00:56:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3364.06s)]
*  basically right. And we want to lead. [[00:56:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3368.26s)]
*  We want to take advantage of this. [[00:56:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3371.02s)]
*  We don't want to hobble it. [[00:56:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3373.34s)]
*  We don't even fully know what it's going to be yet. [[00:56:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3375.14s)]
*  We are going to send our workers. [[00:56:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3378.62s)]
*  We want to be pro worker. [[00:56:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3380.54s)]
*  And I think that if there are downsides for workers, then we can mitigate [[00:56:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3382.3399999999997s)]
*  those things in the future. [[00:56:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3386.2999999999997s)]
*  But it's too early to say that we know what the program should be. [[00:56:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3387.22s)]
*  It's more about a statement of values at this point. [[00:56:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3391.18s)]
*  Do you think it's too early, Freeberg, given optimists [[00:56:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3393.2599999999998s)]
*  and all these robots being created, what we're seeing in self-driving? [[00:56:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3397.54s)]
*  You've talked about the ramp up with Waymo. [[00:56:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3400.8199999999997s)]
*  To actually say we will not see millions of jobs. [[00:56:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3403.42s)]
*  And millions of people get displaced from those jobs. [[00:56:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3408.06s)]
*  What do you think, Freeberg? I'm curious, your thoughts, because that is [[00:56:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3410.38s)]
*  the counter argument. [[00:56:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3412.86s)]
*  My experience in the workplace is that AI tools. [[00:56:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3414.54s)]
*  That are doing things that an analyst or knowledge worker was doing [[00:56:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3419.7s)]
*  with many hours in the past is allowing them to do something in minutes. [[00:57:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3424.3s)]
*  That doesn't mean that they spend the rest of the day doing nothing. [[00:57:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3428.42s)]
*  What's great for our business and for other businesses like ours [[00:57:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3431.46s)]
*  that can leverage AI tools is that those individuals can now do more. [[00:57:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3434.9s)]
*  And so our throughput, our productivity as an organization has gone up [[00:57:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3440.02s)]
*  and we can now create more things faster. [[00:57:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3444.5s)]
*  So whatever the product is that my company makes, we can now make [[00:57:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3447.22s)]
*  more things more quickly. [[00:57:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3450.3399999999997s)]
*  We can do more development. [[00:57:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3451.58s)]
*  You're seeing it on the ground, correct, Adahala? [[00:57:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3452.58s)]
*  And I'm seeing it on the ground. [[00:57:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3454.62s)]
*  And I don't think that this like transplantation of how big the [[00:57:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3455.7799999999997s)]
*  application of how bad AI will be for jobs is the right framing as much [[00:57:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3460.14s)]
*  as it is about an acceleration of productivity. [[00:57:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3465.18s)]
*  And this is why I go back to the point about GDP per capita and GDP growth. [[00:57:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3467.42s)]
*  Countries, societies, areas that are interested or industries that are [[00:57:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3471.98s)]
*  interested in accelerating output and accelerating productivity, the [[00:57:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3476.38s)]
*  ability to make stuff and sell stuff are going to rapidly embrace these [[00:58:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3480.2999999999997s)]
*  tools because it allows them to do more with less. [[00:58:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3484.3399999999997s)]
*  And I think that's what I really see on the ground. [[00:58:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3487.02s)]
*  And the second point I'll make is the one that I mentioned earlier. [[00:58:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3489.46s)]
*  And I'll wrap up with a third point, which is I think we're underestimating [[00:58:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3491.7400000000002s)]
*  the new industries that will emerge drastically, dramatically. [[00:58:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3495.42s)]
*  There is going to be so much new that we are not really thinking [[00:58:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3498.98s)]
*  deeply about right now. [[00:58:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3502.34s)]
*  That we could do a whole nother two hour brainstorming session on, on [[00:58:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3504.3s)]
*  what AI unlocks in terms of large scale projects that are traditionally [[00:58:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3508.18s)]
*  or typically or today held back because of the constraints on the [[00:58:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3513.66s)]
*  technical feasibility of these projects. [[00:58:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3517.82s)]
*  And that ranges from accelerating to new semiconductor technology to [[00:58:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3519.5s)]
*  quantum computing to energy systems, to transportation, to habitation, [[00:58:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3524.2200000000003s)]
*  et cetera, et cetera. [[00:58:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3528.82s)]
*  There's all sorts of transformations in every industry that's possible [[00:58:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3529.94s)]
*  as these tools come online. [[00:58:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3532.86s)]
*  And that will spurn insane new industries. [[00:58:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3534.5800000000004s)]
*  The most important point is the third one, which is we don't know the [[00:58:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3536.82s)]
*  overlap of job loss and job creation if there is one. [[00:59:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3540.38s)]
*  And so the rate at which these new technologies impact and create new [[00:59:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3543.5400000000004s)]
*  markets, but I think Naval is right. [[00:59:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3547.18s)]
*  I think that what happens in capitalism and in free societies is that [[00:59:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3548.74s)]
*  capital and people rush to fill the hole of new opportunities that [[00:59:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3552.58s)]
*  emerge because of AI and that those grow more quickly than the old bubbles [[00:59:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3556.66s)]
*  deflate. [[00:59:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3560.9s)]
*  So if there's a deflationary effect in terms of job need in other [[00:59:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3561.74s)]
*  industries, I think that the loss will happen slower than the rush to [[00:59:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3565.2999999999997s)]
*  take advantage of creating new things will happen on the other side. [[00:59:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3568.8199999999997s)]
*  So my bet is probably on the order of, I think new things will be [[00:59:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3571.66s)]
*  created faster than old things will be lost. [[00:59:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3575.5800000000004s)]
*  I think as a quick side note to that, the fastest way to help somebody [[00:59:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3577.38s)]
*  get a job right now, if you know somebody in the market who's looking [[00:59:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3582.38s)]
*  for a job, the best thing you can do is say, hey, go download the AI [[00:59:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3585.1800000000003s)]
*  tools and start talking to them. [[00:59:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3589.6200000000003s)]
*  Just start using them in any way. [[00:59:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3590.86s)]
*  And then you can walk into any employer in almost any field and say, [[00:59:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3592.42s)]
*  hey, I understand AI and they'll hire you. [[00:59:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3596.1800000000003s)]
*  Exactly. [[00:59:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3597.86s)]
*  Naval, you and I watched this happen. [[00:59:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3598.7400000000002s)]
*  We had a front row seat to it back in the day. [[01:00:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3601.38s)]
*  When you were doing venture hacks and I was doing open angel for [[01:00:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3604.8999999999996s)]
*  and we had to like fight to find five or 10 companies a month. [[01:00:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3607.8599999999997s)]
*  Then the cost of running these companies went down. [[01:00:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3611.46s)]
*  They went down massively from five million to start a company to two, [[01:00:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3614.02s)]
*  then to 250K, then to 100K. [[01:00:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3617.54s)]
*  I think what we're seeing is like three things concurrently. [[01:00:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3620.74s)]
*  You're going to see all these jobs go away for automation, self-driving [[01:00:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3622.98s)]
*  cars, cashiers, et cetera. [[01:00:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3626.66s)]
*  But we're going to also see static team size at places like Google. [[01:00:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3628.74s)]
*  They're just not hiring because they're just having the existing bloated [[01:00:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3632.18s)]
*  employee base learn the tools. [[01:00:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3634.8999999999996s)]
*  But I don't know if you're seeing this, the number of startups able to get a [[01:00:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3637.2999999999997s)]
*  product to market with two or three people and get to a million in revenue [[01:00:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3640.74s)]
*  is booming. [[01:00:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3644.66s)]
*  What are you seeing in the startup landscape? [[01:00:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3645.2999999999997s)]
*  Definitely what you're saying in that there's leverage. [[01:00:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3648.58s)]
*  But at the same time, I think the more interesting part is that new [[01:00:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3651.06s)]
*  startups are enabled that could not exist otherwise. [[01:00:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3654.3399999999997s)]
*  My last startup, AirChat, could not have existed without AI because we needed [[01:00:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3657.8599999999997s)]
*  the transcription and translation. [[01:01:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3661.14s)]
*  Even the current thing I'm working on, it's not an AI company, but it cannot [[01:01:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3662.8199999999997s)]
*  exist without AI. [[01:01:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3665.7799999999997s)]
*  It is relying on AI. [[01:01:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3666.9s)]
*  Even at AngelList, we're significantly adopting AI. [[01:01:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3668.74s)]
*  Everywhere you turn, it's more opportunity, more opportunity, more opportunity. [[01:01:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3671.7799999999997s)]
*  And people like to go on Twitter or the artist formerly known as Twitter. [[01:01:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3675.54s)]
*  And basically, they like to exaggerate like, oh my God, we've hit AGI. [[01:01:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3680.9s)]
*  Oh my God, I just replaced all my mid-level engineers. [[01:01:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3685.62s)]
*  Oh my God, I've stopped hiring. [[01:01:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3688.18s)]
*  To me, that's like moronic. [[01:01:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3689.78s)]
*  The two valid ones are the one-man entrepreneur shows where there's like one [[01:01:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3691.6200000000003s)]
*  guy or one gal and they're like scaling up like crazy things to AI. [[01:01:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3695.46s)]
*  Phil Kaplan. [[01:01:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3698.26s)]
*  Shout out. [[01:01:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3699.0600000000004s)]
*  Or there are people who are embracing AI and being like, I need to hire. [[01:01:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3699.2200000000003s)]
*  And I need to hire anyone who can even spell AI. [[01:01:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3702.5800000000004s)]
*  Like anyone who's even used AI. [[01:01:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3705.38s)]
*  Just come on in, come on in. [[01:01:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3707.1400000000003s)]
*  Again, I would say the easiest way to see that AI is not taking jobs or [[01:01:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3709.3s)]
*  creating opportunities is go brush up on your AI. [[01:01:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3712.7400000000002s)]
*  Learn a little bit. [[01:01:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3716.1800000000003s)]
*  Watch a few videos. [[01:01:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3716.98s)]
*  Use the AI. [[01:01:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3718.1000000000004s)]
*  Tinker with it and then go reapply for that job that rejected you and watch how they pull you in. [[01:01:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3719.22s)]
*  In 2023, an economist named Richard Baldwin said AI won't take your job. [[01:02:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3724.1s)]
*  It's someone using AI that will take your job because they know how to use it better than you. [[01:02:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3728.18s)]
*  And that's kind of become a meme and you see it floating around X. [[01:02:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3732.2599999999998s)]
*  But I think there's a lot of truth in that. [[01:02:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3735.22s)]
*  As long as you remain adaptive and you keep learning and you learn how to take [[01:02:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3737.2999999999997s)]
*  advantage of these tools, you should do better. [[01:02:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3741.8599999999997s)]
*  And if you wall yourself off from the technology and don't take advantage of it, [[01:02:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3744.74s)]
*  that's when you put yourself at risk. [[01:02:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3748.5s)]
*  Another way to think about it is these are natural language computers. [[01:02:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3749.78s)]
*  So everyone who's intimidated by computers before should no longer be intimidated. [[01:02:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3753.06s)]
*  You don't need to program anymore in some esoteric language or learn some obscure [[01:02:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3757.54s)]
*  mathematics to be able to use these. [[01:02:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3761.86s)]
*  You can just talk to them and they talk back to you. [[01:02:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3763.3s)]
*  That's magic. [[01:02:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3765.46s)]
*  The new programming language is English. [[01:02:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3766.82s)]
*  Chamath, you want to wrap us up here on this opportunity? [[01:02:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3768.5s)]
*  Slash displacement slash chaos. [[01:02:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3771.06s)]
*  I was going to say this before, but I'm pretty unconvinced anymore that you [[01:02:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3774.02s)]
*  should bother even learning many of the hard sciences and maths that we used to as underpinnings. [[01:03:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3780.98s)]
*  I used to believe that the right thing to do was for everybody to go into engineering. [[01:03:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3788.9s)]
*  I'm not necessarily as convinced as I used to be because I used to say, [[01:03:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3793.7s)]
*  well, that's great first principles thinking, et cetera, et cetera. [[01:03:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3797.06s)]
*  And you're going to get trained in a toolkit that will scale. [[01:03:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3799.62s)]
*  And I'm not sure that that's true. [[01:03:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3802.8999999999996s)]
*  I think you can use these agents and you can use deep research and all of a sudden, [[01:03:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3804.5s)]
*  they replace a lot of that skill. [[01:03:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3809.8599999999997s)]
*  So what's left over? [[01:03:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3811.06s)]
*  It's creativity, it's judgment, it's history, it's psychology, [[01:03:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3812.2599999999998s)]
*  it's all of these other sort of like software leadership communication that allow you to [[01:03:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3817.2999999999997s)]
*  manipulate these models in constructive ways. [[01:03:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3821.54s)]
*  Because when you think of the prompt engineering that gets you to great answers, [[01:03:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3823.54s)]
*  it's actually just thinking in totally different orthogonal ways and non-linearly. [[01:03:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3826.8199999999997s)]
*  So that's my last thought, which is it does open up the aperture, meaning [[01:03:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3831.14s)]
*  for every smart mathematical genius, there's many, many, many other people who have high EQ. [[01:03:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3834.98s)]
*  And all of a sudden, this tool actually takes the skill away from the person with just a high IQ [[01:04:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3841.54s)]
*  and says, if you have these other skills now, you can compete with me equally. [[01:04:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3848.2599999999998s)]
*  And I think that that's liberating for a lot of people. [[01:04:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3852.34s)]
*  I'm in the camp of more opportunity. [[01:04:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3854.98s)]
*  I got to watch the movie industry a whole bunch when the digital cameras came out and more people [[01:04:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3857.14s)]
*  started making documentaries, more people started making independent film shorts. [[01:04:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3863.14s)]
*  And then of course, the YouTube revolution, people started making videos on YouTube or podcasts like [[01:04:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3866.98s)]
*  this. And if you look at what happened with like the special effects industry as well, [[01:04:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3871.7799999999997s)]
*  we need far fewer people to make a Star Wars movie, to make a Star Wars series, [[01:04:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3876.66s)]
*  to make a Marvel series. As we've seen, now we can get the Mandalorian, Ashoka and all these other [[01:04:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3882.1s)]
*  series with smaller numbers of people. And they look better than obviously the original Star Wars [[01:04:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3887.7s)]
*  series or even the prequels. So there's going to be so many more opportunities. We're now making [[01:04:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3893.2999999999997s)]
*  more TV shows, more series, everything we wanted to see of every little character. [[01:04:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3897.7s)]
*  That's the same thing that's happening in startups. I can't believe that there is a [[01:05:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3902.74s)]
*  app now, Naval, called Slopes, just for skiing. And there are 20 really good apps for just [[01:05:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3906.66s)]
*  meditation. And there are 10 really good ones just for fasting. Like we're going down this [[01:05:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3915.3s)]
*  long tail of opportunity and there'll be plenty of million to $10 million businesses for us, [[01:05:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3919.62s)]
*  you know, if people learn to use these tools. I love how that's the thing that tips you over. [[01:05:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3925.3s)]
*  Which one? [[01:05:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3931.06s)]
*  You get an extra Marvel movie or an extra Star Wars show. So that tips you over. [[01:05:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3933.7799999999997s)]
*  I think for a lot of people, it feels great. [[01:05:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3938.1s)]
*  I may take over the world, but I'm going to get an extra Star Wars movie. [[01:05:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3941.22s)]
*  I'll be entertained. [[01:05:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3944.8199999999997s)]
*  I mean, are you not entertained? [[01:05:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3945.46s)]
*  One final point on this is, look, I mean, given the choice between the two categories of techno [[01:05:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3947.94s)]
*  optimists and techno pessimists, I'm definitely in the optimist camp. And I think we should be. [[01:05:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3952.5s)]
*  But I think there's actually a third category that I would submit, which is techno realist, [[01:05:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3956.98s)]
*  which is technology is going to happen. Trying to stop it is like ordering the tides to stop. [[01:06:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3963.3s)]
*  If we don't do it, somebody else will. China's going to do it or somebody else will do it. [[01:06:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3969.7s)]
*  And it's better for us to be in control of the technology to be the leader rather than [[01:06:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3974.42s)]
*  passively waiting for it to happen to us. And I just think that's always true. It's better for [[01:06:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3979.94s)]
*  businesses to be proactive and take the lead, disrupt themselves instead of waiting for someone [[01:06:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3985.86s)]
*  else to do it. And I think it's better for countries. And I think you did see this theme [[01:06:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3990.1800000000003s)]
*  a little bit. I mean, these are my own views. I don't want to ascribe them to the vice president, [[01:06:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3994.58s)]
*  but you did see, I think, a hint of the techno realism idea in his speech and in his tweet, [[01:06:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=3999.06s)]
*  which is, look, AI is going to happen. We might as well be the leader. If we don't, [[01:06:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4005.78s)]
*  we could lose in a key category that has implications for national security, for our [[01:06:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4011.14s)]
*  economy, for many things. So that's just not a world we want to live in. So I think a lot of [[01:06:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4017.2200000000003s)]
*  this debate is sort of academic because whether you're an optimist or pessimist, just sort of glass [[01:07:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4022.02s)]
*  half empty, half full, the question is just, is it going to happen or not? And I think the answer is [[01:07:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4028.66s)]
*  yes. So then we want to control it. Let's just boil it down. There's not a tremendous amount [[01:07:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4033.38s)]
*  of choice in this, I think. I would agree heavily with one point and I would just tweak another. [[01:07:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4038.1s)]
*  The point I would agree with is that it's going to happen anyway. And that's what DeepSeek proved. [[01:07:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4043.06s)]
*  You can turn off the flow of chips to them and you can turn off the flow of talent. What do they do? [[01:07:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4047.46s)]
*  They just get more efficient and they exported it back to us. They sent us back the best open [[01:07:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4051.7799999999997s)]
*  source model when our guys were staying closed source for safety reasons. And I think DeepSeek [[01:07:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4056.42s)]
*  exploded the fallacy that the US has a monopoly in this category and that somehow therefore we [[01:07:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4062.5s)]
*  can slow down the train and that we have total control over the train. And I think what DeepSeek [[01:07:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4072.1s)]
*  showed us is no, if we slow down the train, they're just going to win. Yeah. The part where I [[01:07:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4076.5s)]
*  should tweak a little bit is the idea that we are going to win. By we, when you say America, [[01:08:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4080.58s)]
*  the problem is that the best way to win is to be as open, as distributed, as innovative as possible. [[01:08:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4085.86s)]
*  If this all ends up in the control of one company, they're actually going to be slower to innovate [[01:08:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4091.54s)]
*  than if there's a dynamic system. And that dynamic system by its nature will be open. [[01:08:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4095.86s)]
*  It will leak to China. It will leak to India. But these things have powerful network effects. [[01:08:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4100.74s)]
*  We know this about technology. Almost all technologies have network effects underneath. [[01:08:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4105.38s)]
*  And so even if you are open, you're still going to win and you're still going to control. [[01:08:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4109.54s)]
*  And of all, you look at the internet. That was all true for the internet, right? The internet's [[01:08:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4113.94s)]
*  and open technology is based on open source. But who's the dominant companies? All the dominant [[01:08:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4116.9s)]
*  companies are US companies because they were in the lead. Exactly. Right. Exactly. Right. [[01:08:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4121.94s)]
*  Because we embrace the open internet. We embrace the open internet. That was different. Yeah. So [[01:08:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4125.0599999999995s)]
*  there will be benefits for all of humanity. And I think the vice president's speech was really [[01:08:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4128.9s)]
*  clear that, look, we want you guys to be on board. We want to be good partners. However, there are [[01:08:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4132.74s)]
*  definitely going to be winners economically, militarily. And in order to be one of those [[01:08:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4137.54s)]
*  winners, you have to be a leader. Who's going to get to AGI first and of all? Is it going to be [[01:09:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4142.26s)]
*  an open source? Who's going to win? Is it going to be open source or closed source? Who's going [[01:09:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4147.22s)]
*  to win the day? If we're sitting here five, 10 years from now and we're looking at the top three [[01:09:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4151.3s)]
*  language models, which is going to be- I'm going to get in a lot of trouble for this, but I don't [[01:09:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4155.860000000001s)]
*  think we know how to build AGI. But that's a much longer discussion. Okay, put AGI aside. Who's [[01:09:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4158.02s)]
*  going to have the best model five years from now? Hold on. I 100% agree with you. I just think it's [[01:09:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4161.62s)]
*  a different thing. But what we're building are these incredible natural language computers. And [[01:09:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4165.860000000001s)]
*  actually, David, in a very pithy way, summarized the two big use cases. It's search and it's [[01:09:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4169.62s)]
*  homeworks. It's paperwork. It's really paperwork. And a lot of the jobs that we're talking about [[01:09:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4175.38s)]
*  disappearing are actually paperwork jobs. They're paperwork shuffling. These are made up jobs. [[01:09:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4181.14s)]
*  Like the federal government is they're finding out through Doge, a third of it is people digging [[01:09:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4184.98s)]
*  holes with spoons and another third are filling them back up. They're filling out paperwork and [[01:09:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4188.98s)]
*  then burying it in a mine shaft. They're burying it in a mine shaft, Nyer Mountain. Yeah. So I [[01:09:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4192.58s)]
*  think a lot of these made up jobs. And then they're going to go down the mine shaft to get [[01:09:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4197.06s)]
*  the paperwork when someone retires and bring it up. You know what? I'm going to get them some [[01:10:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4200.02s)]
*  thumb drives. We can increase the throughput of the elevator with some thumb drives. It would be [[01:10:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4202.820000000001s)]
*  incredible. What we found out is the DMV has been running the government for the last 70 years. It's [[01:10:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4206.660000000001s)]
*  been a compounding. That's really what's going on. The DMV is in charge. I mean, if the world ends in [[01:10:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4211.3s)]
*  nuclear war, God forbid, the only thing that's left will be the cockroaches and then a bunch of [[01:10:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4218.18s)]
*  like government documents. TPS reports down in a mine shaft. Basically. Yeah. [[01:10:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4222.9s)]
*  Let's take a moment, everybody, to thank our czar. We miss him. We wish he could be here for the [[01:10:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4231.46s)]
*  whole show. Thank you, czar. Thank you to the czar. Good to see you guys. We miss you, little buddy. [[01:10:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4238.259999999999s)]
*  I wish we could talk about Ukraine, but we're not allowed. Get back to work. We'll talk about it [[01:10:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4244.259999999999s)]
*  another time over coffee. I'll see you in the commissary. Thanks for the invite. Bye. [[01:10:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4248.34s)]
*  Man, I'm so excited. I'm Naval. Sax invited me to go to the military mess. I'm going to be in [[01:10:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4254.1s)]
*  the commissary with Sax. No, he didn't, J. Kelly. You invited yourself. Be honest. I did. Yes, [[01:10:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4259.62s)]
*  I did. I put it on his calendar. To keep the conversation moving, let me segue a point that [[01:11:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4263.46s)]
*  came up that was really important into tariffs. The point is, even though the internet was open, [[01:11:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4267.9400000000005s)]
*  the US won a lot of the internet. A lot of US companies won the internet. They won that because [[01:11:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4275.38s)]
*  we got there the firstest with the mostest, as they say in the military. That matters because [[01:11:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4280.74s)]
*  a lot of technology businesses have scale economies and network effects underneath. [[01:11:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4286.02s)]
*  Even basic brand-based network effects. If you go back to the late 90s, early 2000s, [[01:11:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4290.66s)]
*  very few people would have predicted that we would have ended up with Amazon basically owning all of [[01:11:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4296.1s)]
*  e-commerce. You would have thought it would have been a perfect competition and very spread out. [[01:11:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4300.34s)]
*  That applies to how we ended with Uber as basically one taxi service or we end up with- [[01:11:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4304.98s)]
*  Airbnb. [[01:11:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4309.7s)]
*  Meta, Airbnb. It's just network effects, network effects, network effects rule the world around me. [[01:11:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4310.66s)]
*  But when it comes to tariffs and when it comes to trade, we act like network effects don't exist. [[01:11:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4315.0599999999995s)]
*  The classic Ricardian comparative advantage dogma says that you should produce what you're best at. [[01:12:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4320.419999999999s)]
*  I produce what I'm best at and we trade. Then even if you want to charge me more for it, [[01:12:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4325.299999999999s)]
*  if you want to impose tariffs for me to ship to you, I should still keep tariffs down because I'm [[01:12:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4329.7s)]
*  better off. You're just selling me stuff cheaply. Great. Or if you want to subsidize your guys, [[01:12:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4333.86s)]
*  great. You're selling me stuff cheaply. The problem is that is not how most modern businesses work. [[01:12:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4338.099999999999s)]
*  Most modern businesses have network effects. As a simple thought experiment, suppose that we [[01:12:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4342.9s)]
*  have two countries, right? I'm China, you're the US. I start out by subsidizing all of my [[01:12:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4347.219999999999s)]
*  companies and industries that have network effects. So I'll subsidize TikTok. [[01:12:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4353.78s)]
*  I'll ban your social media, but I'll push mine. I will subsidize my semiconductors, [[01:12:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4358.5s)]
*  which do tend to have winner take all in certain categories or I'll subsidize my drones. [[01:12:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4364.0199999999995s)]
*  BYD. [[01:12:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4367.94s)]
*  And then you, exactly BYD, self-driving, whatever. And then when I win, I own the whole market and I [[01:12:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4368.259999999999s)]
*  can raise prices. And if you try to start up a competitor, then it's too late. I've got network [[01:12:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4375.62s)]
*  effects. Or if I've got scale economies, I can lower my prices zero, crash you out of business. [[01:13:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4380.099999999999s)]
*  No one there right mind will invest and I'll raise prices right back up. So you have to understand [[01:13:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4384.099999999999s)]
*  that certain industries have hysteresis or they have network effects or they have economies of [[01:13:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4389.0599999999995s)]
*  scale. And these are all the interesting ones. These are all the high margin businesses. [[01:13:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4393.38s)]
*  So in those, if somebody is subsidizing or they're raising tariffs against you [[01:13:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4396.82s)]
*  to protect your industries and let them develop, you do have to do something. [[01:13:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4400.9800000000005s)]
*  You can't just completely back down. [[01:13:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4405.14s)]
*  S1. What are your thoughts, Jamath, about tariffs and network effects? It does seem like [[01:13:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4406.82s)]
*  we do want to have redundancy in supply chains. So there are some exceptions here. Any thoughts on [[01:13:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4413.46s)]
*  how this might play out? Because, yeah, Trump brings up tariffs every 48 hours and then [[01:13:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4420.42s)]
*  it doesn't seem like any of them land. So I don't know. I'm still on my 72 hour Trump rule, which is [[01:13:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4425.14s)]
*  whatever he says, wait 72 hours and then maybe see if it actually comes to pass. [[01:13:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4431.22s)]
*  Where do you stand on all these tariffs and tariff talk? [[01:13:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4435.7s)]
*  S2. Well, I think the tariffs will be a plug. Are they coming? Absolutely. The quantum of them? I [[01:13:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4438.18s)]
*  don't know. And I think that the way that you can figure out how extreme it will be, it'll be based [[01:14:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4443.7s)]
*  on what the legislative plan is for the budget. So there's two paths right now. Path one, which [[01:14:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4451.3s)]
*  I think is a little bit more likely, is that they're going to pass a slimmed down plan in the Senate [[01:14:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4457.22s)]
*  just on border security and military spending. And then they'll kick the can down the road [[01:14:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4462.34s)]
*  for probably another three or four months on the budget. Plan two is this one big beautiful bill [[01:14:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4468.1s)]
*  that's irking its way through the House. And there they're proposing trillions of dollars of cuts. [[01:14:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4474.26s)]
*  In that mode, you're going to need to raise revenue somehow, and especially if you're giving [[01:14:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4481.54s)]
*  away tax breaks. And the only way to do that is probably through tariffs, or one way to do it is [[01:14:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4486.42s)]
*  through tariffs. My honest opinion, Jason, is that I think we're in a very complicated moment. I think [[01:14:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4490.42s)]
*  the Senate plan is actually on the margins more likely and better. And the reason is because I [[01:14:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4495.62s)]
*  think that Trump is better off getting the next 60 to 90 days of data. I mean, we're in a real [[01:15:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4501.22s)]
*  pickle here. We have persistent inflation. We have a broken Fed. They're totally asleep at the switch. [[01:15:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4508.34s)]
*  And the thing that Yellen and Biden did, which in hindsight now was extremely dangerous, [[01:15:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4518.42s)]
*  is they issued so much short term paper that in totality, we have $10 trillion we need to finance [[01:15:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4524.9800000000005s)]
*  in the next six to nine months. So it could be the case that we have rates that are like five, [[01:15:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4531.780000000001s)]
*  five and a quarter, five and a half percent. I think that that's extremely bad at the same time [[01:15:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4540.02s)]
*  as inflation, at the same time as delinquencies are ticking up. So I think tariffs are probably [[01:15:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4547.22s)]
*  going to happen. But I think that Trump will have the most flexibility if he has time to see what [[01:15:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4555.06s)]
*  the actual economic conditions will be, which will be more clear in three, four, five months. [[01:16:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4565.06s)]
*  And so I almost think this big, beautiful bill is actually counterproductive because I'm not sure [[01:16:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4570.5s)]
*  we're going to have all the data we need to get it right. [[01:16:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4574.9s)]
*  Friberg, any thoughts on these tariffs? You've been involved in the global marketplace, [[01:16:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4577.219999999999s)]
*  especially when it comes to produce and wheat and all this corn and everything. What do you think [[01:16:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4583.86s)]
*  the dynamic here is going to be, or is it saber rattling in a tool for Trump? [[01:16:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4589.46s)]
*  The biggest buyer of US ag exports is China. Ag exports are a major revenue source, major income [[01:16:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4594.42s)]
*  source and a major part of the economy for a large number of states. And so there will be, [[01:16:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4603.3s)]
*  as there was in the first Trump presidency, very likely very large transfer payments made to farmers [[01:16:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4609.7s)]
*  because China is very likely going to tear up imports or stop making import purchases [[01:16:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4616.820000000001s)]
*  altogether, which is what happened during the first presidency. When they did that, [[01:17:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4622.02s)]
*  the federal government, I believe had transfer payments of north of $20 billion to farmers. [[01:17:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4626.34s)]
*  This is a not negligible sum and it's a not negligible economic effect because there's [[01:17:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4630.98s)]
*  then a rippling effect throughout the ag economy. So I think that's one key thing that I've heard [[01:17:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4635.94s)]
*  folks talk about is the activity that's going to be needed to support the farm economy as [[01:17:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4640.82s)]
*  the US's biggest ag customer disappears. In the early 20th century, we didn't have an income tax [[01:17:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4648.58s)]
*  and the federal revenue was almost entirely dependent on tariffs. When tariffs were cut, [[01:17:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4654.5s)]
*  there was an expectation that there would be a decline in federal government revenue, [[01:17:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4659.3s)]
*  but what actually happened is volume went up. So lower tariffs actually increased trade, [[01:17:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4664.02s)]
*  increased the size of the economies. This is where a lot of economists take their basis in, [[01:17:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4668.900000000001s)]
*  hey guys, if we do these tariffs, it's actually going to shrink the economy. It's going to cause [[01:17:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4673.9400000000005s)]
*  a reduction in trade. The counterbalancing effect is one that has not been tested in economics, [[01:17:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4677.78s)]
*  which is what's going to happen if simultaneously we reduce the income tax and reduce the corporate [[01:18:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4683.22s)]
*  income tax and basically increase capital flows through reduced taxation while doing the tariff [[01:18:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4688.82s)]
*  implementation at the same time. So it's a grand economic experiment and I think we'll learn a lot [[01:18:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4695.94s)]
*  about what's going to happen here as this all moves forward. I do think ultimately many of these [[01:18:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4700.66s)]
*  countries are going to capitulate to some degree and we're going to end up with some negotiated [[01:18:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4704.98s)]
*  settlement that's going to hopefully not be too short-term impactful on the economies and the [[01:18:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4709.0599999999995s)]
*  people and the jobs that are dependent on trade. The economy feels like it's in a very precarious [[01:18:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4713.94s)]
*  place. It does to asset holders. Yeah, to asset holders. [[01:18:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4717.94s)]
*  And obviously they've left it in a bad place in the last administration and we shut down [[01:18:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4722.58s)]
*  the entire country for a year over COVID and the bill for that has come due and that's reflected [[01:18:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4726.259999999999s)]
*  in inflation. I think there are a couple other points in tariffs. First is it's not just about [[01:18:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4730.5s)]
*  money. It's also about making sure we have functional middle-class with good jobs because [[01:18:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4735.46s)]
*  if you have a non-tariff world, maybe all the gains go to the upper-class and an under-class [[01:18:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4739.86s)]
*  and then you can't have a functioning democracy when the average person is on one of those two [[01:19:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4744.5s)]
*  extremes. So I think that's one issue. Another is strategic industries. If you look at it today, [[01:19:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4748.5s)]
*  probably the largest defense contractor in the world is DJI. They got all the drones. [[01:19:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4754.74s)]
*  Even in Ukraine, both sides are getting all their drone parts from DJI. Now they're getting it [[01:19:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4759.46s)]
*  through different supply chains and so on, but Ukrainian drones and Russian drones, the vast [[01:19:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4763.86s)]
*  majority of them are coming through China through DJI and we don't have that industry. If we have a [[01:19:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4767.7s)]
*  kinetic conflict right now and we don't have good drone supply chain internally in the US, [[01:19:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4772.9s)]
*  we're probably going to lose because those things are autonomous bullets. That's the future of all [[01:19:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4778.259999999999s)]
*  warfare. We're buying F-35s and the Chinese are building swarms of nanos. [[01:19:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4782.0199999999995s)]
*  At scale. [[01:19:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4786.74s)]
*  At scale. So we do have to re-onsure those critical supply chains and what is a drone supply [[01:19:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4787.7s)]
*  chain? There's not a thing called drone. It's like motors and semiconductors and- [[01:19:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4793.0599999999995s)]
*  Yeah, it's a lot of pieces. [[01:19:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4797.219999999999s)]
*  Optics and lasers and just everything across the board. So I think there are other good arguments [[01:19:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4798.58s)]
*  for at least reshoring some of these industries. We need them and the United States is very lucky [[01:20:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4804.02s)]
*  and that is very autarkic. We have all the resources, we have all the supplies. We can [[01:20:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4809.22s)]
*  be upstream of everybody with all the energy to the extent we're importing any energy. That [[01:20:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4813.54s)]
*  is a choice we made. That is not because fundamentally we lack the energy. [[01:20:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4818.900000000001s)]
*  We have to, right. That's right. [[01:20:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4822.74s)]
*  Yeah, because of between all the oil resources and the natural gas and fracking combined with [[01:20:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4823.62s)]
*  all the work we've done in nuclear fission and small reactors, we should absolutely be [[01:20:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4829.62s)]
*  energy independent. [[01:20:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4833.78s)]
*  We should be running the table on it. We should have a massive surplus. And hey, [[01:20:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4834.34s)]
*  if you're worried about a couple of million of DoorDash Uber drivers losing their jobs [[01:20:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4839.7s)]
*  to automation, like, hey, there's going to be factories to build these parts for these [[01:20:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4844.9s)]
*  drones that we're going to need. So there's a lot of opportunity, I guess, for people. [[01:20:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4849.86s)]
*  And there is a difference between different kinds of jobs. Those kinds of jobs are better jobs, [[01:20:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4853.94s)]
*  building difficult things at scale physically that we need for both national security and [[01:20:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4859.46s)]
*  for innovation. Those are better jobs than paperwork, writing essays for other people to [[01:21:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4864.98s)]
*  read. Yeah. Or even driving cars. [[01:21:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4870.9s)]
*  All right. Listen, I want to get to two more stories here. We have a really interesting [[01:21:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4872.82s)]
*  copyright story that I wanted to touch on. Thompson Reuters just won the first major [[01:21:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4876.74s)]
*  US AI copyright case. And Fair Use played a major role in this decision. This has huge [[01:21:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4880.98s)]
*  implications for AI companies here in the United States. Obviously, OpenAI and the New York Times, [[01:21:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4887.78s)]
*  Getty Images versus Stability. We've talked about these, but it's been a little while because [[01:21:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4894.5s)]
*  the legal system takes a little bit of time. And these are very complicated [[01:21:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4899.46s)]
*  cases, as we've talked about. Thompson Reuters owns Westlaw. If you don't know that, it's kind [[01:21:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4903.62s)]
*  of like LexisNexis. It's one of the legal databases out there that lawyers use to find cases, etc. [[01:21:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4908.34s)]
*  And they have a paid product with summaries and analysis of legal decisions. Back in 2020, [[01:21:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4915.86s)]
*  this is two years before ChatGBT, Reuters sued a legal research competitor called Ross for [[01:22:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4921.38s)]
*  copyright infringement. Ross had created an AI-powered legal search engine. Sounds great. [[01:22:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4926.34s)]
*  But Ross had asked Westlaw if they would pay a license to its content for training. [[01:22:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4931.54s)]
*  Westlaw said no. This all went back and forth. And then Ross signed a similar deal with a company [[01:22:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4935.62s)]
*  called Legal Ease. The problem is Legal Ease's database was just copied and pasted from a bunch [[01:22:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4941.38s)]
*  of Westlaw answers. So Reuters, Westlaw, sued Ross in 2020, accusing the company of being [[01:22:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4946.0199999999995s)]
*  precariously liable for Legal Ease's direct infringement. Super important point. Anyway, [[01:22:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4951.86s)]
*  the judge originally favored Ross in fair use. This week, the judge reversed this ruling and [[01:22:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4956.74s)]
*  found Ross liable, noting that after further review, fair use does not apply in this case. [[01:22:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4962.26s)]
*  This is the first major win. And we debated this. So here's a clip. You heard it here first on [[01:22:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4968.42s)]
*  the All In Pod. What I would say is, when you look at that fair use doctrine, I've got a lot [[01:22:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4975.62s)]
*  of experience with it. The fourth factor test, I'm sure you're well aware of this, is the effect [[01:23:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4980.34s)]
*  of the use on the potential market and the value of the work. If you look at the lawsuits that are [[01:23:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4984.58s)]
*  starting to emerge, it is Getty's right to then make derivative products based on their images. [[01:23:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4989.46s)]
*  I think we would all agree. Stable diffusion, when they use these open web, that is no excuse [[01:23:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=4994.74s)]
*  to use an open web crawler to avoid getting a license from the original owner of that. Just [[01:23:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5000.0199999999995s)]
*  because you can technically do it doesn't mean you're allowed to do it. In fact, the open web [[01:23:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5004.9s)]
*  projects that provide these say explicitly, we do not give you the right to use this. You have to [[01:23:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5008.42s)]
*  then go read the copyright laws on each of those websites. And on top of that, if somebody were to [[01:23:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5014.02s)]
*  steal the copyrights of other people, put it on the open web, which is happening all day long, [[01:23:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5019.14s)]
*  you still if you're building a derivative work like this, you still need to go get it. So it's [[01:23:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5023.780000000001s)]
*  no excuse that I took some site in Russia that did a bunch of copyright violation, and then I index [[01:23:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5027.9400000000005s)]
*  them for my training model. So I think this is going to result. Hey, Freebird, can you shoot me [[01:23:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5032.9800000000005s)]
*  in the face and let me know when this happens? Okay. Oh, great. So the same way. Same way now, [[01:23:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5037.38s)]
*  exactly. I know, me too. Yeah. Okay, good segment. Let's move on. Well, since these guys don't give [[01:24:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5045.62s)]
*  a s*** about copyright holders, Naval, what do you think about, you know, I'm so glad you're here, [[01:24:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5051.3s)]
*  Naval, to actually talk about the topics these two other guys would engage with. I'm going to go out [[01:24:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5057.14s)]
*  and even thinner limb. I'm going to go out and even thinner limb and say I largely agree with you. I [[01:24:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5060.58s)]
*  think it's a bit rich to crawl the open web, hoover up all the data, offer direct substitution [[01:24:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5064.26s)]
*  for a lot of use cases because you know, now you start and end with the AI model. It's not even [[01:24:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5068.820000000001s)]
*  like you link out like Google did. And then you just close off the models for safety reasons. [[01:24:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5072.5s)]
*  I think if you trained on the open web, your model should be open source. [[01:24:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5076.900000000001s)]
*  Yeah, absolutely. That would be a fine thing. I have a prediction here. I think this is all [[01:24:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5080.34s)]
*  going to wind up wind up like the NAPPS or Spotify case. For people who don't know, [[01:24:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5084.900000000001s)]
*  Spotify pays, I think, 65 cents on the dollar to the original underwriters of that content, [[01:24:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5089.86s)]
*  the music industry, and they figured out a way to make a business and Napster is roadkill. [[01:24:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5097.0599999999995s)]
*  I think that there is a non-zero chance like it might be five or 10% that opening eyes going to [[01:25:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5102.339999999999s)]
*  lose the New York Times lawsuit and they're going to lose it hard and they're going to be injunctions. [[01:25:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5108.9s)]
*  And I think it's the settlement might be that these language models, especially the closed ones, [[01:25:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5112.58s)]
*  are going to have to pay some percentage in a negotiated settlement of their revenue, [[01:25:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5117.06s)]
*  half, two thirds to the content holders. And this could make the content industry have a massive, [[01:25:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5123.54s)]
*  massive uplift and a massive resurgence. I think that the problem, there's an example [[01:25:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5131.14s)]
*  on the other side of this, which is that there's a company that provides technical support for [[01:25:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5138.02s)]
*  Oracle, third party company, and Oracle has tried umpteen times to sue them into oblivion [[01:25:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5142.98s)]
*  using copyright infringement as part of the justification. And it's been up [[01:25:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5149.0599999999995s)]
*  all over the stock for a long time. The company's name is Rimini Street. Don't ask me why it's on [[01:25:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5153.62s)]
*  my radar, but I've been looking at it. And they lost this huge lawsuit, Oracle one, [[01:25:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5158.58s)]
*  and then it went to appellate court and then it was all vacated. Why am I bringing this up? [[01:26:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5164.82s)]
*  I think that the legal community has absolutely no idea how these models work, [[01:26:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5170.0199999999995s)]
*  because you can find one case that goes one way and one case that goes the other. And what I would [[01:26:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5174.82s)]
*  say should become standard reading for anybody bringing any of these lawsuits. There's an [[01:26:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5179.7s)]
*  incredible video that Carpathy just dropped that Andre just dropped where he does like this deep [[01:26:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5185.78s)]
*  dive into LLMs and he explains chat GPT from the ground up. It's on YouTube. It's three hours. [[01:26:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5192.0199999999995s)]
*  It's excellent. And it's very difficult to watch that and not get to the same conclusion that you [[01:26:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5198.74s)]
*  guys did. I'll just leave it at that. I tend to agree with this. There's also a good old video [[01:26:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5205.219999999999s)]
*  by Ilya Tsitskover where he was, I believe, the founding chief scientist or CTO of OpenAI. [[01:26:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5210.66s)]
*  And he talks about how these large language models are basically extreme compressors. [[01:26:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5216.82s)]
*  And he models them entirely as their ability to compress. And they're lossy compressors. [[01:27:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5222.339999999999s)]
*  Exactly. Exactly. And Google got sued for fair use back in the day. But the way they managed to [[01:27:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5226.74s)]
*  get past the argument was they were always linking back to you. They provided some value. [[01:27:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5234.34s)]
*  This is lossy compression. It is absolutely I'm now on your page. I hate to say this, Jason. [[01:27:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5240.82s)]
*  I agree with you. You were right. [[01:27:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5249.54s)]
*  Right. That's all I wanted to hear all these years. [[01:27:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5253.38s)]
*  When I saw those videos, because like, oh, man, Jason was right. Jason was right. Oh, my God. [[01:27:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5261.3s)]
*  I've been through this so many times that these I think this is, you know, [[01:27:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5266.82s)]
*  Rupert Murdoch said we should hold the line with Google and not allow them to index our content [[01:27:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5271.46s)]
*  without a license. And Google navigated it successfully. And they were able to not get [[01:27:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5277.94s)]
*  him to stop. I think what's happened now is that the New York Times remembers that they all remember [[01:28:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5284.0199999999995s)]
*  losing their content and these snippets and the one box to Google and they couldn't get that genie [[01:28:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5291.54s)]
*  back in the bottle. I think the New York Times realizes this is their payday. I think the New [[01:28:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5297.78s)]
*  York Times will make more money from licenses from LLMs than they will make from advertising [[01:28:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5302.5s)]
*  or subscriptions eventually. This will renew the model. Almost. I think New York Times content is [[01:28:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5309.3s)]
*  worthless to an LLM. But that's a different story. I think they actually value content. [[01:28:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5314.9s)]
*  Sure. If you don't have political reasons, whatever. But I can tell you as a user, [[01:28:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5318.34s)]
*  I loved the wire cutter. I think you knew Brian and everybody over the wire cutter. [[01:28:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5321.94s)]
*  We that was like such an invariant. Fair enough. Yeah. Wire cutter. What a great product. [[01:28:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5325.78s)]
*  I used to pay for the New York Times. I no longer pay for the New York Times. My main reason was I [[01:28:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5329.38s)]
*  would go to the wire cutter and I would just buy whatever they call me to buy. Now I go to chat. [[01:28:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5333.14s)]
*  Jpt. Which I pay for. Yeah. And chat. Jpt. Tells me what to buy based on the wire cutter. So it's it [[01:28:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5339.14s)]
*  and I'm already paying for it. So I stopped paying for it. I philosophically disagree with all of your [[01:29:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5345.9400000000005s)]
*  nonsense on this topic. All three of you are wrong. And I'll tell you why. Number one, [[01:29:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5350.900000000001s)]
*  if information is out in the open internet, I believe it's accessible and it's viewable. [[01:29:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5356.98s)]
*  And I view an LLM or a web crawler as basically being a human that's reading and can store [[01:29:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5362.74s)]
*  information in its brain. If it's out there in the open, if it's behind a paywall, a hundred percent. [[01:29:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5368.259999999999s)]
*  If it's behind some protected password. Wait, wait, wait, wait, David. In that case, [[01:29:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5372.099999999999s)]
*  can a Google crawler just crawl entire site and serve it on Google? Why can't they do that? [[01:29:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5377.78s)]
*  So here's the fair use. The fair use is you cannot copy, you cannot repeat the content. You cannot [[01:29:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5382.0199999999995s)]
*  take the content and repeat it. That is how the law is currently written. But now what I have is, [[01:29:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5388.34s)]
*  I have a tool that can remix it with 50 other pieces of similar content and I can change the [[01:29:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5392.82s)]
*  words slightly and maybe even translate into different language. So where does it stop? [[01:29:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5397.94s)]
*  Do you know the musical artist Girl Talk? We should have done a Girl Talk track. [[01:30:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5401.219999999999s)]
*  No, he's got weird musical taste this guy. [[01:30:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5405.3s)]
*  Okay. Here we go. [[01:30:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5408.34s)]
*  He basically takes small samples of popular tracks and he got sued for the same problem. [[01:30:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5410.26s)]
*  There was another guy named White Panda, I believe had the same problem. Ed Sheeran got sued for this. [[01:30:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5415.9400000000005s)]
*  Yeah, but their entire sites like Stack Overflow and Wikihow that are basically [[01:30:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5420.9800000000005s)]
*  disappeared now because you can just swallow them all up and you can just spit it all back [[01:30:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5424.66s)]
*  out and chat GPT with slight changes. So I think that the first and fourth test- [[01:30:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5428.1s)]
*  I think the fair use is how much of a slight change is exactly the right question. [[01:30:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5432.26s)]
*  Yeah, yeah. [[01:30:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5435.46s)]
*  Which is how much are you changing? [[01:30:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5435.7s)]
*  Yeah, so that's the question. It actually boils down to the AGI question. [[01:30:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5436.820000000001s)]
*  Are these things actually intelligent and are they learning or are they compressing [[01:30:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5440.5s)]
*  and regurgitating? That's the question. [[01:30:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5443.860000000001s)]
*  I wonder this about humans and that's why I bring up the White Panda, the Girl Talk in audio, [[01:30:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5445.46s)]
*  but also visual art. There was always artists and even in classical music, [[01:30:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5449.860000000001s)]
*  I don't know if you guys are classical music people, but there's a demonstration of how [[01:30:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5453.860000000001s)]
*  one composer learned from the next and that you can actually crack the music as kind of being [[01:30:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5459.94s)]
*  standing on the shoulders of the prior. And the same is true in almost all art forms and almost [[01:31:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5465.0599999999995s)]
*  all human knowledge and media and communication. [[01:31:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5469.299999999999s)]
*  It's very hard to figure that out. [[01:31:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5471.78s)]
*  Well, that's exactly right. That's the hard part. [[01:31:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5473.62s)]
*  It's very hard to figure that out, which is why I come back to there's only one of two stable [[01:31:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5474.82s)]
*  solutions to this and it's going to happen anyway. If we don't crawl it, the Chinese will crawl it, [[01:31:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5478.82s)]
*  right? DeepSeek proved that. So there's only one of two stable solutions. Either you pay the [[01:31:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5482.66s)]
*  copyright holders, which I actually think doesn't work. And the reason is because someone in China [[01:31:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5487.62s)]
*  will crawl it and they just dump the weights, right? So they can just crawl and dump the [[01:31:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5492.0199999999995s)]
*  compressed weights. Or if you crawl, make it open. At least contribute something back to open source. [[01:31:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5495.46s)]
*  You crawled open data, contribute it back to open source. And the people who don't want to be crawled, [[01:31:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5502.82s)]
*  they're going to have to go to a huge lengths to protect their data. Now everybody knows to [[01:31:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5507.94s)]
*  protect the data. There's not a clean solution. [[01:31:51](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5511.62s)]
*  Well, the licensing thing is happening here. I have a book out from Harper Business [[01:31:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5513.38s)]
*  on the shelf behind me and I'm getting 2,500 smackaroos for the next three years for Microsoft [[01:31:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5519.38s)]
*  indexing it. So they're going out and they're licensing this stuff and they're going to book. [[01:32:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5526.1s)]
*  You're getting $2,500. So your book. [[01:32:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5531.54s)]
*  Literally I'm getting $2,500 for three years, a bunch of Harper. [[01:32:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5532.82s)]
*  To go into an LLM. [[01:32:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5536.74s)]
*  To go into Microsoft specifically. And you know what? I'm going to sign it, I decided, [[01:32:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5538.26s)]
*  because I just want to set the precedent. Maybe next time it's 10,000. Maybe next time it's 250. [[01:32:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5542.58s)]
*  I don't care. I just want to see people have their content respected. And I'm just hoping [[01:32:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5547.3s)]
*  that Sam Altman loses this lawsuit and they get an injunction against it. Hey, well, just because [[01:32:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5551.94s)]
*  he's just such a weasel in terms of like making stop open AI into a closed thing. I mean, I like [[01:32:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5557.46s)]
*  Sam personally, but I think what he did was like the super weasel move of all time for his own [[01:32:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5563.46s)]
*  personal benefit. If he, if he, and this whole lying like, Oh, I have no equity. I get healthcare. [[01:32:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5569.14s)]
*  He does it for the love. [[01:32:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5573.700000000001s)]
*  And now I get 10%. [[01:32:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5574.740000000001s)]
*  No bro. He doesn't. [[01:32:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5575.3s)]
*  But he does it for the love. [[01:32:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5576.34s)]
*  What was the statement? He does it for the, I do it for the joy. [[01:32:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5577.62s)]
*  The joy, the benefit. I think he got healthcare. [[01:33:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5580.740000000001s)]
*  I think in open as defense, they do need to raise a lot of money and they got to [[01:33:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5584.02s)]
*  incent their employees, but that doesn't mean they need to take over the whole thing. [[01:33:07](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5587.54s)]
*  The nonprofit portion can still stay in the nonprofit portion and get the lion's share, [[01:33:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5592.18s)]
*  the benefits and be the board. And then he can have an incentive package and employees [[01:33:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5595.78s)]
*  can have an incentive package. [[01:33:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5600.179999999999s)]
*  Yeah. Why don't they get a percentage of the revenue? Just give them like 10% of the revenue [[01:33:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5601.3s)]
*  goes to the team. [[01:33:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5605.7s)]
*  Absolutely. I don't understand why it has to be bought out right now for 40 billion. [[01:33:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5606.34s)]
*  And then the whole thing disappears into a closed system. That part makes no sense to me. [[01:33:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5608.42s)]
*  That's called a shell game and a scam. [[01:33:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5611.86s)]
*  Yeah. I think Sam and his team would do better to leave the nonprofit part alone, [[01:33:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5614.82s)]
*  leave an actual independent nonprofit board in charge, and then have a strong incentive plan [[01:33:39](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5619.0599999999995s)]
*  and a strong fundraising plan for the investors and the employees. So I think this is workable. [[01:33:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5624.74s)]
*  It's just trying to grab it all. It just seems way off, especially when it was built on open [[01:33:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5628.9s)]
*  algorithms from Google, open data from the West and on a nonprofit funding from Elon and others. [[01:33:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5632.98s)]
*  I mean, what a great proposal. We just workshopped here. What if they just, [[01:33:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5638.58s)]
*  what do they make? 6 billion a year? Just take 10% of it, 600 million every year. [[01:34:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5642.58s)]
*  And that goes into a bonus. [[01:34:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5646.98s)]
*  They're losing money, Jason. So they have to. [[01:34:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5649.62s)]
*  Okay. Eventually. [[01:34:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5651.7s)]
*  But even equity, they could give equity to the people building it, but they could still [[01:34:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5652.82s)]
*  leave it in the control of the nonprofit. I just don't understand this conversion. I mean, [[01:34:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5656.82s)]
*  there was a board coup, right? The board tried to fire Sam, and Sam took over the board. Now it's [[01:34:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5660.98s)]
*  his hand picked board. So it also looks like self-dealing, right? And yeah, they'll get an [[01:34:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5665.54s)]
*  independent valuation, but we all know that game. You hire a valuation expert who's going to say [[01:34:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5669.54s)]
*  what you're going to say and they'll check the box. But if you're going to capture the light code of [[01:34:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5673.139999999999s)]
*  all future value or build super intelligence, we know that's worth a lot more. That's why Elon [[01:34:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5676.98s)]
*  just bid 100 billion. [[01:34:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5681.139999999999s)]
*  Exactly. You're saying the things that actually the regulators and the legal community have no [[01:34:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5682.26s)]
*  insight because they'll see a fairness opinion and they think, oh, it says fairness and opinion, [[01:34:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5687.780000000001s)]
*  two words side by side, it must be fair. And they don't know how all of this stuff is gamed. [[01:34:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5692.1s)]
*  So yeah. [[01:34:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5696.66s)]
*  Yeah. Man, I've got stories about 409As that would- [[01:34:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5698.02s)]
*  Exactly. [[01:35:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5702.26s)]
*  As you just wrote, 409As. [[01:35:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5702.820000000001s)]
*  Everything is game. 409As are game. These fairness opinions are game. But the reality is I [[01:35:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5703.62s)]
*  don't think the legal and the judicial community has any idea. [[01:35:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5709.46s)]
*  I mean, imagine if a founder you invested in just as just a total imaginary situation of all [[01:35:12](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5712.9800000000005s)]
*  had like a great term sheet at some incredible dollar amount, didn't take it, ran the valuation [[01:35:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5718.26s)]
*  down to like under a million, gave themselves a bunch of shares and then took it three months [[01:35:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5724.42s)]
*  later. Well, I don't know. What would that be called? Securities fraud? [[01:35:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5728.9s)]
*  Can we wrap up? [[01:35:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5733.94s)]
*  Yeah. Let's wrap on your story. [[01:35:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5734.5s)]
*  Nick, we'll show you the photo. I had an interesting dinner on Monday with Brian Johnson, [[01:35:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5736.74s)]
*  the don't die guy, came over to my house. [[01:35:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5741.219999999999s)]
*  Oh. How's his erection doing overnight? [[01:35:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5743.0599999999995s)]
*  What we talked about is that he's got three hours a night of nighttime erections. [[01:35:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5745.86s)]
*  Wow. Look at this. [[01:35:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5750.82s)]
*  By the way, first of all, I'll tell you, I think that he's- [[01:35:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5752.259999999999s)]
*  Kuhn. [[01:35:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5756.099999999999s)]
*  Wait, which one of those is giving him the erection? [[01:35:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5757.139999999999s)]
*  No, no, no. He measures his nighttime erections. [[01:35:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5759.54s)]
*  I think Kuhn is giving him the erection. [[01:36:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5761.94s)]
*  Oh, he's giving him the erection. [[01:36:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5763.46s)]
*  But he said that when he started ... So by the way, he said he was 43 when he started this thing. [[01:36:05](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5765.3s)]
*  He was basically clinically obese. [[01:36:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5770.1s)]
*  In these next four years has become a specimen. He now has three hours a night of nighttime [[01:36:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5773.3s)]
*  erections, but that's not the interesting thing. At the end of this dinner, by the way, [[01:36:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5778.34s)]
*  his skin is incredible. I was not sure because when you see the pictures online, [[01:36:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5782.58s)]
*  but his skin in real life is like a porcelain doll's. Both my wife and I were like, [[01:36:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5787.06s)]
*  we've never seen skin like this. And it's incredibly soft. [[01:36:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5792.34s)]
*  Wait, wait, wait, wait, wait, wait, wait, wait, wait, wait, wait, wait, wait, wait, wait, wait, [[01:36:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5795.62s)]
*  how do you know his skin is soft? [[01:36:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5797.06s)]
*  You know, you brush your hand against his forearm or whatever, you know, [[01:36:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5798.58s)]
*  gives a hug at the end of the night. I'm telling you the guy's skin is- [[01:36:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5801.78s)]
*  He has supple skin? [[01:36:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5804.58s)]
*  Bro, it's the softest skin I've ever touched in my life. Anyways, that's not the point. [[01:36:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5806.1s)]
*  It was really fascinating dinner. He walked through his whole protocol. [[01:36:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5812.18s)]
*  But at the end of it, I think it was Nikesh, the CEO of Palo Alto Networks, he was just like, [[01:36:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5816.34s)]
*  give me the top three things. [[01:37:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5820.58s)]
*  Top three. [[01:37:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5822.98s)]
*  And of the top three things, what I'll boil it down to is the top one thing, which is like [[01:37:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5823.7s)]
*  80% of the 80%. It's all about sleep. [[01:37:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5829.86s)]
*  I was about to get sleep. [[01:37:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5834.1s)]
*  And he walked through his nighttime routine and it's incredible and it's straightforward. [[01:37:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5835.86s)]
*  It's really simple. It's like how you do a wind down. Anyways, I have tried to- [[01:37:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5839.94s)]
*  Explain the wind down briefly. [[01:37:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5844.5s)]
*  Let's just say that because Brian goes to bed much earlier, so our normal time. Let's just say [[01:37:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5846.98s)]
*  10, 10.30. So my time, I try to go to bed by 10.30. He's like, you need to be in bed. You need to, [[01:37:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5850.66s)]
*  first of all, stop eating three or four hours before. And I do that. I eat at 6.30. So I have [[01:37:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5855.38s)]
*  about three hours. You're in bed by 9.30 or 10. You deal with the self-talk. Like, okay, [[01:37:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5860.900000000001s)]
*  here's the active mind telling you all the things you have to fix in the morning. Talk it out, [[01:37:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5868.900000000001s)]
*  put it in its place, say, I'm going to deal with this in the morning. [[01:37:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5873.62s)]
*  Write it down in a journal, you're saying? [[01:37:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5876.34s)]
*  Whatever you do so that you put it away, you cannot be on your phone. [[01:37:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5877.78s)]
*  That's got to be in a different room. [[01:38:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5882.0199999999995s)]
*  You just got to be able to shut it down and then read a book so that you're actually just [[01:38:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5884.42s)]
*  engaged in something. And he said that he typically falls asleep within three to four [[01:38:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5888.58s)]
*  minutes of getting into bed and starting his routine. [[01:38:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5894.82s)]
*  What? [[01:38:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5896.58s)]
*  I tried it. So I've been doing it since I had dinner with him on Monday. [[01:38:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5897.94s)]
*  Last night, I fell asleep within 15 minutes. [[01:38:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5901.54s)]
*  Hmm. [[01:38:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5904.099999999999s)]
*  The hardest part for me is to put the phone away. I can't do it. [[01:38:25](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5905.299999999999s)]
*  Of course. Of course. What about you, Niv? I'll tell us your one down. [[01:38:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5908.339999999999s)]
*  Oh, yeah. So I know Brian pretty well, actually. And I joke that I'm married to the female Brian [[01:38:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5911.7s)]
*  Johnson because my wife has some of his routines, but she's the natural version, no supplements, [[01:38:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5916.259999999999s)]
*  and she's intense. And I think when Brian saw my sleep score from my [[01:38:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5922.419999999999s)]
*  eight sleep, he was shocked. He was just like, you're going to die. He's like, [[01:38:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5929.86s)]
*  you're literally going to die. [[01:38:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5933.46s)]
*  What do you got, 70, 80? [[01:38:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5934.42s)]
*  No, it's terrible. It's awful. But it's because I don't- [[01:38:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5935.86s)]
*  Tell the truth. What's your number? What's your number? [[01:38:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5938.099999999999s)]
*  It was like his 30s, 40s. [[01:38:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5939.86s)]
*  What? [[01:39:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5941.299999999999s)]
*  Yeah. But it's also because I don't sleep much. I only sleep a few hours a night and I also move [[01:39:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5942.259999999999s)]
*  around a lot in the bed and so on. But it's fine. I never have trouble falling asleep, but I would [[01:39:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5946.259999999999s)]
*  say that Brian's skin care routine is amazing. His diet is incredible. He is a genuine character. [[01:39:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5951.139999999999s)]
*  I do think a lot of what he's saying, minus the supplements, I'm not a big believer in supplements, [[01:39:17](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5957.54s)]
*  does work. I don't know if it's necessarily going to slow down your aging, but you'll look good and [[01:39:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5962.58s)]
*  you'll feel good. Yeah, sleep is the number one thing. In terms of falling asleep, I don't think [[01:39:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5966.74s)]
*  it's really about whether you look at your phone or not, believe it or not. I think it's about what [[01:39:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5971.38s)]
*  you're doing on your phone. If you're doing anything that is cognitively stressful or getting [[01:39:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5975.54s)]
*  your mind to spin, then yes. [[01:39:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5980.42s)]
*  So you think you can scroll TikTok and fall asleep is fine? [[01:39:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5981.7s)]
*  Anything that's entertaining or that is like you can read a book on your Kindle or on your iPad, [[01:39:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5986.18s)]
*  and I think it'd be fine falling asleep. Or you can listen to some meditation video or some [[01:39:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5992.66s)]
*  spiritual teacher or something and that'll actually help you fall asleep. But if you're on X or if [[01:39:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=5997.38s)]
*  you're checking your email, then heck yeah, that's going to keep you up. So my hack for sleep is a [[01:40:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6002.42s)]
*  little different. I normally fall asleep within minutes and the way I do it is you all have a [[01:40:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6006.9800000000005s)]
*  meditation routine. [[01:40:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6013.46s)]
*  You have a set time every night? [[01:40:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6014.9s)]
*  No, I sleep whenever I feel like. Usually around one in the morning, two in the morning. [[01:40:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6016.0199999999995s)]
*  God damn, I'm in bed by 10. Yeah, I need to sleep. [[01:40:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6019.379999999999s)]
*  I'm an owl. But if you want to fall asleep, the hack I've found is everybody has tried some kind [[01:40:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6021.86s)]
*  of a meditation routine. Just sit in bed and meditate. And your mind will hate meditation so [[01:40:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6027.94s)]
*  much that if you force it to choose between the fork of meditation and sleeping, you will fall [[01:40:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6033.86s)]
*  asleep. Works every time. [[01:40:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6038.339999999999s)]
*  Well, okay, so after I had dinner- [[01:40:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6040.0199999999995s)]
*  And if you don't fall asleep, you'll end up meditating, which is great too. [[01:40:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6041.06s)]
*  I like the meditation. I do the body scan. [[01:40:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6044.5s)]
*  Dakota, to this story, was a friend of mine came to see me from the UAE and he was here on [[01:40:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6047.06s)]
*  Tuesday and I was telling him about the dinner with Brian. And he told me the story because [[01:40:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6052.900000000001s)]
*  he's friends with Khabib, the UFC fighter. And he says, you know, when Khabib goes to his house, [[01:40:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6056.5s)]
*  he eats anything and everything, fried food, pizzas, whatever, but he trains consistently. [[01:41:02](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6062.02s)]
*  And my friend, Adala says, how are you able to do that? And how does it not affect your [[01:41:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6068.34s)]
*  physiology? He goes, I've learned since I was a kid, I sleep three hours after I train in the [[01:41:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6073.22s)]
*  morning and I sleep 10 hours at night. And I've done it since I was like 12 or 13 years old. [[01:41:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6078.34s)]
*  That's a lot of sleep. [[01:41:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6083.14s)]
*  It's a lot of sleep. [[01:41:24](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6084.42s)]
*  I, you know, the direct correlation for me is if I do something cognitively, like, you know, [[01:41:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6086.5s)]
*  big heavy duty conversations or whatever, so no heavy conversations at the end of the night, [[01:41:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6093.3s)]
*  no existential conversations in the night. And then if I go rucking, I have the, you know, [[01:41:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6098.26s)]
*  on the ranch, I put on a 35 pound weight vest. [[01:41:43](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6103.22s)]
*  You do that at night before you go to bed? [[01:41:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6105.62s)]
*  No, no, no. If I do it anytime during the day, typically do it in the morning or the afternoon, [[01:41:47](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6107.3s)]
*  but the one to two mile rock with the 35 pounds, whatever it is, it just tires my whole body out. [[01:41:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6110.9800000000005s)]
*  So that when I do lay down. [[01:41:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6117.22s)]
*  Is that why you don't prepare for the punt? [[01:41:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6119.38s)]
*  You know, I mean, this pot is the top 10 pot in the world, Chema. Do you think it's an accident? [[01:42:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6123.3s)]
*  Freeberg, what's your, what's your sleep routine? Can you just go to bed? You just like, [[01:42:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6129.9400000000005s)]
*  when I take a warm bath and I send Jay Cali picture of my feet. [[01:42:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6133.54s)]
*  Oh, wait till Jay Cali's done. I do take a nice warm bath. [[01:42:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6138.34s)]
*  I nailed it. [[01:42:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6142.820000000001s)]
*  But you do, you do it every night, a warm bath? [[01:42:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6143.7s)]
*  I do. Yeah. I do a warm bath every night. [[01:42:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6146.26s)]
*  With candles too. [[01:42:28](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6148.34s)]
*  And do you do it right before you go to bed? [[01:42:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6149.78s)]
*  Yeah. I usually do it after I put the kids down and I'll basically start to wind down for bed. [[01:42:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6151.9400000000005s)]
*  I do watch TV sometimes, but I do have the problem and the mistake of looking at my phone [[01:42:36](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6156.1s)]
*  probably for too long before I turn the lights off. [[01:42:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6161.3s)]
*  So do you have a consistent time where you go to bed or no? [[01:42:44](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6164.02s)]
*  Usually 11 to midnight and then up at six 30. [[01:42:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6168.02s)]
*  Man, I need, I need eight hours. Otherwise I'm a mess. [[01:42:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6174.02s)]
*  I'm trying to get eight. I hit between six and seven consistently. I try to go to bed [[01:42:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6177.06s)]
*  at 11 to 1 AM window and get up the seven to eight window. [[01:43:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6181.06s)]
*  My problem is if I have work to do, I'll get on the computer or my laptop. And then when I start [[01:43:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6184.900000000001s)]
*  that after in my evening routine, I can't stop. And then all of a sudden it's like three in the [[01:43:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6189.620000000001s)]
*  morning and I'm like, oh no, what did I just do? And then I still have to get up at six 30. [[01:43:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6194.42s)]
*  So that does happen to me. [[01:43:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6198.660000000001s)]
*  So last night was unusual for me, but it was kind of funny anyway. I thought, [[01:43:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6199.860000000001s)]
*  oh, I should go to bed early because I'm an all in. [[01:43:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6203.22s)]
*  But I ended up eating ice cream with the kids late. [[01:43:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6206.18s)]
*  What was the brand? You said you went for another brand. I want to know the brand. [[01:43:31](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6211.06s)]
*  I think it's Van Lewin or something like that. [[01:43:34](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6214.42s)]
*  The holiday cookies and cream. Oh my God. So good. [[01:43:40](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6220.18s)]
*  Then I was like, oh, I probably ate too much to go to bed. So I better work out. [[01:43:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6225.38s)]
*  So I did a kettlebell workout. [[01:43:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6228.900000000001s)]
*  You sound like Shaman. [[01:43:52](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6232.18s)]
*  What did you say? [[01:43:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6233.620000000001s)]
*  I have eight kettlebells right here. [[01:43:55](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6235.700000000001s)]
*  Right. This is called working out. [[01:43:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6236.98s)]
*  And then while I'm doing my kettlebell suitcase carry, I was texting with an entrepreneur friend [[01:44:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6243.459999999999s)]
*  so you can tell how intense my workout was. And he's in Singapore. So it was in the middle of the [[01:44:08](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6248.66s)]
*  night for me and early for him. And then it was time to go to bed. I was like, okay, now I've got [[01:44:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6253.139999999999s)]
*  to get to bed. How do I get to bed? My body's all amped up. I've got food in my stomach. [[01:44:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6258.259999999999s)]
*  I have some kettlebells. My brain is all amped up and all in podcasts tomorrow. And what time is it? [[01:44:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6262.98s)]
*  It's 1 30 in the morning. I better get to bed. So I put on like a little one of those spiritual [[01:44:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6270.0199999999995s)]
*  videos to calm me down. And then I just, and then I got in bed and I was like, there's no way I'm [[01:44:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6275.86s)]
*  falling asleep. And I started meditating and five minutes later I was asleep. [[01:44:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6281.0599999999995s)]
*  You know, actually the Dalai Lama has these great, on his YouTube channel, [[01:44:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6285.299999999999s)]
*  he's got these great like two hour discussions. You get about 20, 30 minutes into that. You will [[01:44:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6289.14s)]
*  fall asleep. Well, yeah, but my learning is, you know, watch any Dharma lecture from the SSN center. [[01:44:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6294.02s)]
*  Exactly. And my lesson is, my learning is that the mind will do anything to avoid meditation. [[01:44:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6299.780000000001s)]
*  Yes. By the way, did you guys see just before we wrapped, did you see all the confirmations? [[01:45:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6306.900000000001s)]
*  RFK Jr. confirmed. Brook Rowland's confirmed. By the way, if you look at Polymarket, Polymarket [[01:45:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6310.58s)]
*  had it all right a couple of weeks ago. Like, of course. There was a moment where [[01:45:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6316.26s)]
*  Tulsi fell to like 56%. There was a moment when RFK fell to 75%, but then they bounced back and [[01:45:20](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6320.820000000001s)]
*  it was done. You could have bought that. You could have made money. Yeah. And the media was like, [[01:45:27](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6327.06s)]
*  no way he's getting confirmed. This is not going to happen. But Polymarket knows it's so interesting. [[01:45:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6332.1s)]
*  Well, I saw a very insightful tweet and I forget who wrote it. So I'm sorry. I can't give credit, [[01:45:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6337.06s)]
*  but the guy basically said, look, Trump has a narrow majority in the house and the Senate. [[01:45:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6342.58s)]
*  And he can get everything he wants as long as the Republicans stay in line. So all the pressure and [[01:45:48](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6348.98s)]
*  all the anger that all the mega movement is doing against the left is pointless. It's all about [[01:45:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6354.26s)]
*  keeping the right wing in line. So it's all the people saying to the senators, hey, I'm going to [[01:46:00](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6360.74s)]
*  primary you. It's Nicole Shanahan saying, I'm going to primary you. It's Scott Pressler saying, [[01:46:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6366.66s)]
*  I'm moving to your district. That's the stuff that's moving the needle and causing the [[01:46:10](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6370.82s)]
*  confirmations to go through. That's how you get cash Patel. That's how you get Tulsi Gabbard, [[01:46:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6374.5s)]
*  DNI. That's how you get RFK. You worry about any of these. Do you think any of them are too spicy [[01:46:19](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6379.0599999999995s)]
*  for your taste or you just like the whole burn it down, put in the crazy like outsiders and [[01:46:23](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6383.94s)]
*  Jason, that's such a bad characterization. That's not a fair characterization. I mean, whatever. [[01:46:29](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6389.78s)]
*  I mean, the outsiders. Honestly, it's like, I never thought I'd see it, but I think between Elon and [[01:46:33](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6393.139999999999s)]
*  Sachs and people like that, we actually have builders and doers and financially intelligent [[01:46:37](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6397.46s)]
*  people and economically intelligent people in charge. And despite all the craziness, [[01:46:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6402.5s)]
*  Elon's not doing this for the money. He's doing it because he thinks it's the right thing to do. [[01:46:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6406.58s)]
*  Of course. He moved into the Roosevelt building for the next four months. [[01:46:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6409.86s)]
*  I think like many of us, I had bought into the great forces of history mindset where it's just [[01:46:53](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6413.38s)]
*  like, okay, it's inevitable. This is what's happening. Government always gets bigger, [[01:46:58](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6418.66s)]
*  always gets slower. And we just have to try and get stuff built before they just shut everything [[01:47:01](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6421.94s)]
*  down and we turn into Europe. But the thing that happened then was, you know, Caesar crossed the [[01:47:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6426.58s)]
*  Rubicon. The great man theory of history played out and we're living in that time. And it's an [[01:47:11](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6431.3s)]
*  inspiration to all of us, despite Sam Altman and Elon's current fighting. I know Sam was inspired [[01:47:16](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6436.82s)]
*  by Elon at one point, and I think all of us are inspired by Elon. I mean, the guy can be the [[01:47:21](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6441.78s)]
*  Diablo player and do Doge and run SpaceX and Tesla and boring and Neuralink. I mean, [[01:47:26](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6446.5s)]
*  it's incredibly impressive. It makes us, that's why I'm doing a hardware company now. It makes [[01:47:32](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6452.34s)]
*  me want to do something useful with my life. Elon always makes me question, am I doing something [[01:47:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6455.86s)]
*  useful enough with my life? It's why I don't want to be an investor. Peter Thiel, ironically, [[01:47:41](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6461.38s)]
*  he's an investor, but he's inspirational in that way too, because he's like, yeah, the future [[01:47:45](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6465.62s)]
*  doesn't just happen. You have to go make it. So we get to go make the future. And I'm just glad [[01:47:49](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6469.38s)]
*  that Elon and Doge and others are making the future that I'm living. [[01:47:54](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6474.74s)]
*  Is this a consumer hardware? What do we got going on here? Give us a little hinty coat. [[01:47:57](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6477.62s)]
*  Maybe I'll reveal it on the All In podcast in a couple of months, but it's really difficult. [[01:47:59](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6479.62s)]
*  I'm not sure I can pull it off. So let me try. Let me just make sure it's viable. [[01:48:03](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6483.86s)]
*  Is it drone related? Is it self-driving related? [[01:48:06](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6486.82s)]
*  Drones are cool, but no, it's not. Maybe All In podcast should be an angel investor. [[01:48:09](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6489.62s)]
*  Oh yeah. Let's do a syndicate. No syndicate, Jason. [[01:48:13](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6493.94s)]
*  Just our money. You know how I learned about syndicates was Naval. The first syndicate I [[01:48:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6498.58s)]
*  ever did on AngelList, I think is still the biggest, I don't know, 5%. And Naval's my partner on this [[01:48:22](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6502.9s)]
*  forcom.com. I think you'll love what I'm working on if I pull it off. I think you guys will love it. [[01:48:30](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6510.66s)]
*  I'd love to show you a demo. Let us know where to send the check. Get that black cherry chip, [[01:48:35](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6515.139999999999s)]
*  Van Lewin. I love you guys. What have we learned? I gotta go. [[01:48:38](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6518.9s)]
*  Okay. Big shout out to Bobby and to Tulsi. That's a huge, huge, huge win for America. [[01:48:42](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6522.0199999999995s)]
*  I'm stoked about both of them. Congratulations. [[01:48:46](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6526.58s)]
*  I love me some Bobby Kennedy. Let's get Bobby Kennedy back on the pod. Let's get Bobby, [[01:48:50](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6530.259999999999s)]
*  Bobby, come back on the pod. Four, the czar, David Sacks, your Sultan of Science, David Freyberg, [[01:48:56](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6536.179999999999s)]
*  the chairman dictator, Chamath Palihapitiya, and Namaste Navar. I am the world's greatest moderator. [[01:49:04](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6544.66s)]
*  See you next time on the All In Pod. Namaste, bitches. [[01:49:15](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6555.0599999999995s)]
*  Bye-bye. [[01:49:18](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6558.179999999999s)]
*  All in. [[01:50:14](https://www.youtube.com/watch?v=AI5qI6ej-yM&t=6614.98s)]
