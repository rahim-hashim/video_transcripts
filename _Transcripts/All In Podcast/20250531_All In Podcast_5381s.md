---
Date Generated: June 01, 2025
Transcription Model: whisper medium 20231117
Length: 5381s
Video Keywords: ['chamath', 'david sacks', 'david friedberg', 'jason calacanis', 'all in podcast', 'tech', 'news', 'politics', 'big tech', 'antitrust', 'election', 'covid', 'quarantine', 'stocks', 'stock market', 'tech stocks', 'palihapitiya', 'government']
Video Views: 283494
Video Rating: None
Video Description: (0:00) Bestie intros!
(1:25) The AI Doomer Ecosystem: goals, astroturfing, Biden connections, effective altruist rebrand, global AI regulation
(25:17) Doom vs Boom in AI: Job Destruction or Abundance?
(52:44) Big, Beautiful Bill cleanup and upside: DOGE angle, CBO issues
(1:17:14) US Steel/Nippon Steel deal: national champions and golden votes
Follow the besties: 
https://x.com/chamath
https://x.com/Jason
https://x.com/DavidSacks
https://x.com/friedberg
Follow on X:
https://x.com/theallinpod
Follow on Instagram:
https://www.instagram.com/theallinpod
Follow on TikTok:
https://www.tiktok.com/@theallinpod
Follow on LinkedIn: 
https://www.linkedin.com/company/allinpod
Intro Music Credit:
https://rb.gy/tppkzl
https://x.com/yung_spielburg
Intro Video Credit:
https://x.com/TheZachEffect
Referenced in the show:
https://nypost.com/2025/05/28/business/ai-could-cause-bloodbath-for-white-collar-jobs-spike-unemployment-to-20-anthropic-ceo
https://polymarket.com/event/us-enacts-ai-safety-bill-in-2025
https://www.aipanic.news/p/the-ai-existential-risk-industrial
https://www.semafor.com/article/05/30/2025/anthropic-emerges-as-an-adversary-to-trumps-big-bill
https://x.com/nypost/status/1760623631283954027
https://www.telegraph.co.uk/news/2024/02/23/google-gemini-ai-images-wrong-woke
https://www.thefp.com/p/ex-google-employees-woke-gemini-culture-broken
https://www.campusreform.org/article/biden-admins-new-ai-executive-order-prioritizes-dei/24312
https://x.com/chamath/status/1927847516500009363
https://www.cnbc.com/2025/05/13/microsoft-is-cutting-3percent-of-workers-across-the-software-company.html
https://x.com/DavidSacks/status/1927796514337746989
https://x.com/StephenM/status/1926715409807397204
https://x.com/neilksethi/status/1926981646718206243
https://thehill.com/opinion/finance/5320248-the-bond-market-is-missing-the-real-big-beautiful-story
https://x.com/chamath/status/1928536987558105122
https://x.com/chamath/status/1927373268828266795
https://fred.stlouisfed.org/series/FYFRGDA188S
https://fred.stlouisfed.org/series/FYONGDA188S
https://www.cnbc.com/2025/01/03/biden-blocks-us-steel-takeover-by-japans-nippon-steel-citing-national-security.html
https://truthsocial.com/@realDonaldTrump/posts/114558783827880495
#allin #tech #news
---

# AI Doom vs Boom, EA Cult Returns, BBB Upside, US Steel and Golden Votes
**All In Podcast:** [May 31, 2025](https://www.youtube.com/watch?v=O_AfZ6J0ToE)
*  All right, everybody. Welcome back to the All In Podcast, the number one podcast in the world. [[00:00:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=0.0s)]
*  You got what you wanted, folks. The original quartet is here live from DC with a great shirt. [[00:00:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4.96s)]
*  Is that is your Habit-Dash? You're making that shirt or is that a Tom Ford? That white shirt is [[00:00:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=12.16s)]
*  so crisp, so perfect. David Sachs, you're- Are you talking about me? [[00:00:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=16.4s)]
*  You're czar. You're czar-y. I'll tell you exactly what it is. I'll tell you what it is. You can [[00:00:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=20.0s)]
*  tell me if it's right. Brioni. Yes, of course, Brioni. [[00:00:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=24.080000000000002s)]
*  Being Brioni spread collar. Look at that. How many years have I spent being rich? [[00:00:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=26.959999999999997s)]
*  When a man turns 50, the only thing he should wear is Brioni. The stitching is- [[00:00:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=32.0s)]
*  Looks very luxurious. That's how Chamath knew, right? Chamath, [[00:00:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=36.64s)]
*  how did you figure it out? The stitching? It's just how it lays with the collar. [[00:00:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=39.44s)]
*  To be honest with you, it's the button catch. Brioni has a very specific style of button catches. [[00:00:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=42.64s)]
*  If you don't know what that means, it's because you're a fucking ignorant, [[00:00:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=47.84s)]
*  malcontent yourself. I'm looking it up right now. [[00:00:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=50.48s)]
*  All right, everybody, the All In Summit is going into its fourth year, September 7th [[00:01:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=74.47999999999999s)]
*  through 9th. The goal is, of course, to have the world's most important conversations. [[00:01:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=77.52s)]
*  Go to allin.com slash yada, yada, yada to join us at the summit. [[00:01:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=81.92s)]
*  All right. It's a lot in the docket, but there's kind of a very unique thing going on in the world, [[00:01:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=85.67999999999999s)]
*  David. Everybody knows about AI, doomerism, basically people who are concerned, rightfully [[00:01:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=90.08s)]
*  so, that AI could have some significant impacts on the world. Dario Amodei said he could see [[00:01:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=95.75999999999999s)]
*  employment spike to 10 to 20% in the next couple of years. They're 4% now, as we've always talked [[00:01:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=103.28s)]
*  about here. He told Axios that AI companies and government needs to stop sugarcoating what's [[00:01:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=107.44s)]
*  coming. He expects a mass elimination of jobs across tech, finance, legal and consulting. Okay, [[00:01:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=112.0s)]
*  that's a debate we've had here. And entry level workers will be hit the hardest. He wants lawmakers [[00:01:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=117.28s)]
*  to take action and more CEOs to speak out. Polymarket thinks regulatory capture via this AI [[00:02:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=123.2s)]
*  safety bill is very unlikely. The US enacts AI safety bill in 2025 currently stands at a 13% [[00:02:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=128.88s)]
*  chance. But, Sachs, you wanted to discuss this because it seems like there is more at work than [[00:02:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=134.16s)]
*  just a couple of technologists with, I think we'd all agree, there are legitimate concerns about job [[00:02:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=140.16s)]
*  destruction or job and employment displacement that could occur with AI. We all agree on that. [[00:02:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=146.56s)]
*  We're seeing robo taxis start to hit the streets. I don't think anybody believes that being a cab [[00:02:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=152.48s)]
*  driver is going to exist as a job 10 years from now. So there seems to be something here about AI [[00:02:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=156.96s)]
*  doomerism, but it's being taken to a different level by a group of people maybe with a different [[00:02:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=162.88s)]
*  agenda. Yeah. Well, first of all, let's just acknowledge that there are concerns and risks [[00:02:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=168.48000000000002s)]
*  associated with AI. It is a profound and transformative technology. And there are [[00:02:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=174.16s)]
*  legitimate concerns about where am I lead? I mean, the future is unknown and that can be kind of [[00:03:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=180.24s)]
*  scary. Now, that being said, I think that when somebody makes a pronouncement that says something [[00:03:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=185.76s)]
*  like 50% of white collar jobs are going to be lost within two years, that's a level of specificity [[00:03:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=193.12s)]
*  that I think is just unknowable and is more associated with an attempt to grab headlines. [[00:03:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=199.12s)]
*  And to be frank, if you go back and look at Anthropics announcement or Dario's announcement, [[00:03:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=205.12s)]
*  there is a pattern of trying to grab headlines by making the most sensationalist version [[00:03:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=213.04s)]
*  of what could be a legitimate concern. If you go back three years ago, they created this concern [[00:03:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=218.96s)]
*  that AI models could be used to create bio weapons. And they showed what was supposedly a sample, [[00:03:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=225.36s)]
*  I think of Claude generating an output that can be used by a bioterrorist or something like that. [[00:03:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=233.76s)]
*  And on the basis of that, it actually got a lot of play. And in the UK, Rishi Sunak got very [[00:03:59](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=239.44s)]
*  interested in this cause. And that led to the first AI safety summit at Bletchley Park. So that sort [[00:04:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=246.88s)]
*  of concern really drove some of the initial AI safety concerns. But it turns out that that [[00:04:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=252.56s)]
*  particular output was discredited. It wasn't true. I'm not saying that AI couldn't be used [[00:04:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=258.0s)]
*  or misused to maybe create a bio weapon one day, but it was not an imminent threat in the way that [[00:04:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=264.32s)]
*  it was portrayed. There have been other examples of this. Obviously, people are concerned about [[00:04:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=269.84s)]
*  could the AI develop into a super intelligence that grows beyond our control? Could it lead to [[00:04:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=275.04s)]
*  widespread job loss? I mean, these are legitimate things to worry about. But I think these concerns [[00:04:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=280.0s)]
*  are being hyped up to a level that there's simply no evidence for. And the question is why. And I [[00:04:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=285.68s)]
*  think that there is an agenda here that people should be concerned about. [[00:04:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=292.0s)]
*  Steve McLaughlin So let's start with maybe [[00:04:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=297.12s)]
*  Freiburg. Things that we all agree on here. There are millions of people who drive trucks and [[00:05:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=300.0s)]
*  Ubers and lifts and door dashes. You would, I think, agree the majority of that work [[00:05:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=306.88s)]
*  in but five to 10 years, just to put a number on it, will be done by self-driving robots, cars, [[00:05:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=313.6s)]
*  etc. trucks. Yeah, Dave. Dave I think it's that might be the wrong way to look at it, or [[00:05:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=320.64s)]
*  I wouldn't look at it that way. And maybe I'll just frame it a different way. [[00:05:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=326.24s)]
*  Please. If I'm deploying capital, let's say I'm a CEO of a company, and I can now have software [[00:05:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=330.08s)]
*  that's written by AI, does that mean that I'm going to fire 80% of my software engineers? [[00:05:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=341.68s)]
*  Basically, it means one software engineer can output, call it 20, 50 times as much software [[00:05:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=347.04s)]
*  as they previously could by using that software generation tool. So the return on the invested [[00:05:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=353.44s)]
*  capital, the money I'm spending to pay the salary of that software engineer, is now much, much higher. [[00:06:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=360.88s)]
*  I'm getting much more out of that person because of the unlocking of the productivity because of [[00:06:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=366.88s)]
*  the AI tool than I previously could. So when you have a higher ROI on deployed capital, [[00:06:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=372.32s)]
*  do you deploy more capital or less capital? Suddenly, you have this opportunity to make [[00:06:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=379.52s)]
*  20 times on your money versus two times on your money. If you have a chance to make 20 times on [[00:06:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=384.56s)]
*  your money, you're going to deploy a lot more capital. And this is the story of technology [[00:06:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=389.2s)]
*  going back to the first invention of the first technology of the caveman. When we have this [[00:06:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=394.48s)]
*  ability to create leverage, humans have a tendency to do more and invest more, not less. [[00:06:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=401.04s)]
*  And I think that's what's about to happen. I think we see this across the spectrum. People assumed, [[00:06:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=407.76000000000005s)]
*  oh my gosh, software can now be written with one person. You can create a whole startup. You don't [[00:06:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=413.44s)]
*  need to have venture capital anymore. In fact, what I think we're going to see is much more venture [[00:06:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=417.44s)]
*  capital flowing into new tech startups, much more capital being deployed because the return on the [[00:07:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=421.6s)]
*  invested capital is so much higher because of AI. So generally speaking, I think that the premise [[00:07:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=426.16s)]
*  that AI destroys jobs is wrong because it doesn't take into account the significantly higher return [[00:07:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=433.20000000000005s)]
*  on invested capital, which means more capital is going to be deployed, which means actually [[00:07:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=438.64000000000004s)]
*  far more jobs are going to be created. Far more work is going to get done. [[00:07:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=442.08000000000004s)]
*  And so I think that the counterbalancing effect is really hard to see without taking that zoomed out [[00:07:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=445.36s)]
*  perspective. To respond to Sachs's point, I do think anytime you see a major change socially, [[00:07:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=449.76s)]
*  societally, there's a vacuum. How's the system going to operate in the future? [[00:07:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=456.32s)]
*  And anytime there's a vacuum in the system, a bunch of people will rush in and say, [[00:07:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=460.48s)]
*  I know how to fill that vacuum. I know what to do because I am smarter, more educated, [[00:07:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=464.71999999999997s)]
*  more experienced, more knowledgeable, more moral. I have some superiority over everyone else. And [[00:07:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=470.15999999999997s)]
*  therefore I should be in a position to define how the new system should operate. And so there's a [[00:07:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=475.44s)]
*  natural kind of power vacuum that emerges anytime there's a major transition like this. And there [[00:08:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=480.48s)]
*  will be a scrambling and a fighting and a whole bunch of different representation. Typically, [[00:08:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=485.52s)]
*  fear is a great way of getting into power and people are going to try and create new control [[00:08:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=489.12s)]
*  systems because of the transition that's underway. Okay, it's around the world. [[00:08:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=492.88s)]
*  Yeah, I mean, so Trimoth, it's pretty clear, you know, Freberg didn't answer this question [[00:08:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=496.96s)]
*  specifically, so I'm going to give it to you again. You would agree jobs like driving things [[00:08:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=503.52s)]
*  are going to go away. If we had to pick a number somewhere between five and 10 years, the majority [[00:08:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=509.2s)]
*  of those would go away. He's positioning, hey, a lot more jobs will be created because there'll be [[00:08:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=513.52s)]
*  all these extra venture capital and opportunities, et cetera. But job displacement will be very real. [[00:08:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=517.12s)]
*  And we're seeing, I think, job displacement. Now you had a tweet recently, you know, you were [[00:08:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=523.76s)]
*  talking about entry level jobs and how that seems to be going away in the white collar space. So [[00:08:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=527.28s)]
*  where do you land on job displacement? Freberg's already kind of given the big picture here, [[00:08:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=533.68s)]
*  but let's step back to for people who are listening who have relatives who drive Uber or a truck, [[00:08:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=538.24s)]
*  or are graduating from college and want to go work at a, you know, I don't know, the Magnificent 7 [[00:09:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=544.4s)]
*  or in tech and they're not hiring. And we know the reason they're not hiring because they're [[00:09:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=550.72s)]
*  leaning into AI. So let's talk about the job displacement in the medium term. [[00:09:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=554.88s)]
*  I'm going to ignore your question. And I'm going to answer. Why should you be any [[00:09:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=560.56s)]
*  different than the other? So I'm now content on this podcast. Hi. [[00:09:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=564.48s)]
*  There's two people not wanting to answer the question about job displacement. Interesting [[00:09:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=569.12s)]
*  trend. No, no, no, we'll go back to that. Let me start by just saying that it seems that these [[00:09:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=573.04s)]
*  safety warnings tend to be pretty coincidental with key fundraising moments in Anthropics Journey. [[00:09:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=577.2s)]
*  So let's just start with that. And if you put that into an LLM and try to figure out if what [[00:09:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=584.48s)]
*  I just said was true, it's interesting, but you find it's relatively accurate. I think that there [[00:09:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=590.32s)]
*  is a very smart business strategy here. And I've said a version of this about the other companies [[00:09:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=594.88s)]
*  at the foundational model layer that aren't Meta and Google, because Meta and Google, frankly, [[00:10:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=601.2s)]
*  sit on these money gushers where they just generate so much capital that they can fund these things to [[00:10:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=606.64s)]
*  infinity. But if you're not them, so if you're open AI, or if you're Anthropic, you have to find [[00:10:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=612.72s)]
*  an angle. And I think the angles are slightly different for both. But I think what this suggests [[00:10:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=618.32s)]
*  is that there's a pattern that exists. And I think that that explains some of the framing of what we [[00:10:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=624.32s)]
*  see in the press, Jason, and why we get these exaggerated claims. Perfect. So there are people [[00:10:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=630.72s)]
*  who are doing this for nefarious reasons is I guess where you're sort of getting at here. It's [[00:10:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=638.56s)]
*  a way to pump up the market. It's smart. It's smart. If you fall for it, it's up to you. [[00:10:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=643.76s)]
*  Okay. Yeah. Okay. Well, there's also an industrial complex, according to some folks that are [[00:10:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=648.64s)]
*  backing this. If you've heard of effective altruism, that was like this movement of a bunch of, [[00:10:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=657.28s)]
*  I don't know, I guess they consider themselves intellectual sacks. And they were kind of backing [[00:11:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=663.84s)]
*  a large swath of organizations that I guess we would call in the industry, astroturfing, [[00:11:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=671.04s)]
*  or what do they call it when you make so many of these organizations that they're not real in [[00:11:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=678.16s)]
*  politics and flooding the zone, perhaps. So if you were to look at this article here, Nick, [[00:11:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=683.6s)]
*  I think you have the AI existential risk industrial complex graphic there. It seems like a group of [[00:11:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=688.88s)]
*  people, according to this article, have backed to the tune of 1.6 billion, a large number of [[00:11:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=696.24s)]
*  organizations to scare the bejesus out of everybody and make YouTube videos, TikToks, [[00:11:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=702.0s)]
*  and they've made a map of it. There's some key takeaways here from that article where it says [[00:11:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=708.4s)]
*  here that it's an inflated ecosystem. There's a great deal of redundancy, same names, acronyms, [[00:11:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=713.84s)]
*  logos with only minor changes, same extreme talking points, same group of people just with [[00:11:59](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=719.6800000000001s)]
*  different titles, same funding source. There's a funding source called Open Philanthropy, [[00:12:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=724.08s)]
*  which was funded by Dustin Moskovitz, who is one of the Facebook billionaires. [[00:12:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=728.64s)]
*  Tomathy worked with him, right? I mean, he was, wasn't he like Zuck's roommate at Harvard or [[00:12:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=732.96s)]
*  something and was one of the first engineers who made a lot of money. So he was, he's an EA, [[00:12:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=737.44s)]
*  and he funded this group called Open Philanthropy, which then has become the feeder for essentially [[00:12:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=743.44s)]
*  all of these other organizations, which are almost different fronts to basically the same underlying [[00:12:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=748.8800000000001s)]
*  EA ideology. And what's interesting is that the guy who set this up for Dustin, Holden Karnofsky, [[00:12:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=754.32s)]
*  who is a major effective altruist and was doling out all the money, he's married to Dario's sister. [[00:12:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=761.6s)]
*  She's, I guess, associated with EA and she was one of the co-founders of Anthropic. [[00:12:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=767.9200000000001s)]
*  So these are not coincidences. I mean, the reality is there's a very specific [[00:12:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=772.6400000000001s)]
*  ideological and political agenda here. Now, what is that agenda? It's basically global [[00:12:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=777.44s)]
*  AI governance, if you will. They want AI to be highly regulated, but not just at the level of [[00:13:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=783.84s)]
*  the nation state, but let's say internationally, supernationally. To what end? [[00:13:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=790.08s)]
*  Well, if you just do a quick search on global compute governance, it'll tell you what the key [[00:13:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=795.44s)]
*  aspects are. So number one, they want regulation of computational resources. This includes [[00:13:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=802.4s)]
*  access to GPUs. They want AI safety and security regulation. They want international, you call them [[00:13:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=808.4s)]
*  globalist agreements. And they want ethical and societal considerations or policy built into this. [[00:13:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=815.52s)]
*  Now, what does that sound like? That sounds a lot to me, like what the Biden administration [[00:13:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=822.32s)]
*  was pursuing. Specifically, we had that Biden executive order on AI, which was 100 pages of [[00:13:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=826.5600000000001s)]
*  Bernsen regulation that was designed to promote AI safety, but had all these DEI requirements. [[00:13:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=833.12s)]
*  So it led to OK, I remember when Google launched Black George Washington, so forth. They had the [[00:13:59](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=839.12s)]
*  Biden diffusion rule, which created this global licensing framework to sell GPUs all over the [[00:14:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=846.32s)]
*  world. So extreme restrictions on proliferation of servers, of computing power. They created [[00:14:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=851.28s)]
*  what's called the AI Safety Institute. And they, again, fostered these international AI summits. [[00:14:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=858.88s)]
*  So if you actually look at what the Biden administration was tangibly doing in terms [[00:14:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=865.1999999999999s)]
*  of policy, and you look at what EA's agenda is with respect to global compute governance, [[00:14:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=870.72s)]
*  they were pushing hard on these fronts. And now if you look at the level of personnel, [[00:14:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=877.04s)]
*  there were very, very powerful Biden staffers who now all work at Anthropic. [[00:14:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=881.76s)]
*  So probably the most powerful Biden staffer on AI over the past four years was a lawyer named [[00:14:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=888.16s)]
*  Tarun Chhabra. And he now works at Anthropic for Dario. Elizabeth Kelly, who was the founding [[00:14:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=894.48s)]
*  director of the AI Safety Institute in the government, now works at Anthropic. Like I [[00:15:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=901.76s)]
*  mentioned, Dario's sister is married to Holden Karnofsky, who doles out all the money to these [[00:15:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=907.76s)]
*  EA organizations. So if you were to do something like create a network map, you would see very [[00:15:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=914.16s)]
*  quickly that there's three key nodes here. There's the effective altruist movement, of which Sam [[00:15:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=919.4399999999999s)]
*  Bankman Fried is the most notable member, but which I think Dustin Mosvitz is now the main funder. [[00:15:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=925.04s)]
*  There's the Biden administration and the key staffers, and then you've got Anthropic. [[00:15:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=929.92s)]
*  And it's a very tightly wound network. Now, why does this matter? [[00:15:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=935.04s)]
*  Well, let's get, yeah, also the goals, I think is- [[00:15:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=939.5999999999999s)]
*  Yes. Well, the goal, like I said, is global compute governance. It's basically establishing [[00:15:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=942.24s)]
*  national and then international regulations of AI. Now- [[00:15:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=947.5999999999999s)]
*  But they would claim, which is positive for a minute, they would claim the reason they're doing [[00:15:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=952.0799999999999s)]
*  it. And so we'll say if we believe this or not, but they are concerned about job destruction in [[00:15:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=955.92s)]
*  the short term. They're also concerned, as science fiction as it is, that the AI, when we get to [[00:16:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=963.8399999999999s)]
*  like a sort of generalized super intelligence, is going to kill humanity. That this is a non-zero [[00:16:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=969.28s)]
*  chance. Elon has said this before. They've sort of taken it to a, almost like a certainty. [[00:16:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=974.56s)]
*  Yes. We're going to have so many of these [[00:16:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=979.28s)]
*  general intelligences- Isn't it odd that they only believe that when they're raising money? [[00:16:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=982.0s)]
*  Well, that's what I'm sort of getting at. Like, so- [[00:16:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=986.16s)]
*  I think they believe it all the time, but maybe the press releases are time for the fundraisers. [[00:16:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=987.92s)]
*  But yet they're building- But let me answer that. [[00:16:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=991.76s)]
*  Really great product. So, Jacob- [[00:16:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=993.68s)]
*  Right? Yeah. [[00:16:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=994.7199999999999s)]
*  Yeah. Look, I mean- [[00:16:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=995.5999999999999s)]
*  It is a great product. Claude kicks us. [[00:16:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=996.8s)]
*  I'm more interested in the political dimension of this. I'm not bashing a specific product or [[00:16:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=998.3199999999999s)]
*  company. But look, I think that there is some non-zero risk of AI growing into a super intelligence [[00:16:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1002.16s)]
*  that's beyond our control. They have a name for that. They call it X-risk or existential risk. [[00:16:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1009.1999999999999s)]
*  I think it's very hard to put a percentage on that. I'm willing to acknowledge that is a risk. [[00:16:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1015.0400000000001s)]
*  I think about that all the time, and I do think we should be concerned about it. But there's two [[00:17:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1020.1600000000001s)]
*  problems, I think, with this approach. Number one is, X-risk is not the only kind of risk. [[00:17:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1024.0s)]
*  I would say that China winning the AI race is a huge risk. I don't really want to see [[00:17:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1028.96s)]
*  a CCP AI running the world. And if you hobble our own innovation, our own AI efforts in the [[00:17:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1033.92s)]
*  name of stomping out every possibility of X-risk, then you probably end up losing the AI race to [[00:17:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1041.2s)]
*  China because they're not going to abide by those same regulations. So again, you can't optimize for [[00:17:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1046.32s)]
*  solving only one risk while ignoring all the others. And I would say the risk of China winning [[00:17:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1052.48s)]
*  the AI race is, it might be like 30%. Whereas I think X-risk is probably a much lower percentage. [[00:17:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1058.32s)]
*  So there are other risks to worry about. And I do think that they are single-mindedly focused on [[00:17:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1066.32s)]
*  scaring people with some of these headlines around, first it was the bioweapons, then it was the [[00:17:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1072.9599999999998s)]
*  superintelligence. Now it's the job loss. And I think it's a tried and true tactic of people [[00:17:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1077.52s)]
*  who want to give more power to the government to scare the population. Because if you can scare [[00:18:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1084.1599999999999s)]
*  the population and make them fearful, then they will cry out for the government to solve the [[00:18:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1089.6s)]
*  problem. And that's what I see here is that you've got this elaborate network of front [[00:18:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1094.4s)]
*  organizations, which are all motivated by this EA ideology. They're funded by a hardcore leftist. [[00:18:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1100.4s)]
*  And by the way, I became aware of Dustin's politics because of the Chase Aboudin recall. I found out [[00:18:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1106.88s)]
*  that he was a big funder of Chase Aboudin. Remember this? Yeah. Yeah. Yes, and Mosmas and [[00:18:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1113.2800000000002s)]
*  Kerry Tuna, his wife. Also, Reed Hastings just joined the board of Anthropic. Remember when he, [[00:18:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1116.8s)]
*  back in 2016, tried to drive Peter Thiel off of the board of Facebook for supporting Trump. [[00:18:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1125.2s)]
*  So these are committed leftists. They're Trump haters. But the point is that these are people [[00:18:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1132.48s)]
*  who fundamentally believe in empowering government to the maximum extent. More government. Yeah. [[00:18:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1138.72s)]
*  And empowering government to the maximum extent. Now, my problem with that is I actually think [[00:19:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1144.56s)]
*  that probably the single greatest dystopian risk associated with AI is the risk that government uses [[00:19:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1149.12s)]
*  it to control all of us. To me, you end up in some sort of Orwellian future where AI is controlled by [[00:19:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1157.04s)]
*  the government. And out of all the risks we've talked about, that's the only one for which I've [[00:19:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1165.6s)]
*  seen tangible evidence. So in other words, if you go back to last year when we had the whole [[00:19:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1169.68s)]
*  woke AI, there was plenty of evidence that the people who were creating these products were [[00:19:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1175.44s)]
*  infusing their left-wing or woke values into the product to the point where it was lying to all of [[00:19:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1181.1200000000001s)]
*  us and it was rewriting history. And there was plenty of evidence that the Biden EO was trying to [[00:19:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1187.76s)]
*  enshrine that idea, was basically trying to require DEI be infused into AI models. And [[00:19:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1193.68s)]
*  it wanted to anoint two or three winners in this AI race. So I'm quite convinced that prior to [[00:20:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1200.6399999999999s)]
*  Donald Trump winning the election, we were on a path of global compute governance where two or [[00:20:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1207.04s)]
*  three big AI companies are going to be anointed as the winners. And the quid pro quo is that they [[00:20:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1211.2s)]
*  were going to infuse those AI models with woke values. And there was plenty of evidence for that. [[00:20:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1215.12s)]
*  You look at the policies, you look at the models, this was not a theoretical concern. [[00:20:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1220.08s)]
*  This was real. And I think the only reason why we've moved off of that trajectory is because of [[00:20:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1224.48s)]
*  Trump's election, but we could very easily be moved back onto that trajectory. If you were to [[00:20:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1230.56s)]
*  look at all three opinions here and put them together, they could all be true at the same time. [[00:20:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1234.96s)]
*  You've got a number of people, some might call useful idiots, some might call just, you know, [[00:20:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1238.8s)]
*  people with God complexes who believe they know how the world should operate. Effective altruism [[00:20:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1243.36s)]
*  kind of falls into that. Oh, we can make a formula that that's their kind of idea, [[00:20:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1248.24s)]
*  where we can tell you where to put your money, rich people in order to create the most good. And, [[00:20:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1252.08s)]
*  you know, where are these enlightened individuals with the best view of the world? They might be, [[00:20:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1256.72s)]
*  who knows, maybe they're the smartest kids in the room, but they're kind of delusional. [[00:21:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1260.0s)]
*  The second piece I'll do here is, I think you're absolutely correct, Jamath, that there are people [[00:21:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1263.04s)]
*  who have economic interests, who are then using those useful idiots and or delusional people with [[00:21:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1267.6s)]
*  God complexes to serve their need, which is to be one of the three winners. And then SAC [[00:21:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1273.6s)]
*  inherent to all of that is they have a political ideology. So why not use these people with [[00:21:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1279.04s)]
*  delusions of grandeur in order to secure the bag for their companies, for their investments, [[00:21:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1285.52s)]
*  and secure their candidates into office, so that they can block further people from getting H-100, [[00:21:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1291.12s)]
*  because they literally want to- By the way, that's the part that's very smart about what they're [[00:21:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1297.1999999999998s)]
*  doing, because, you know, it's not like they're illiquid. They're full of liquidity in the sense [[00:21:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1301.2s)]
*  that you're bringing in people that are very technically capable, and you're setting up these [[00:21:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1306.72s)]
*  funding rounds where a large portion goes right back out the door via secondaries. And so there's [[00:21:51](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1311.6000000000001s)]
*  all these people that are making money having this worldview. And so to your point, Jason, [[00:21:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1316.8s)]
*  it's going to cement that worldview, and then they are going to propagate it even more aggressively [[00:22:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1321.6000000000001s)]
*  into the world. So I think the threshold question is, should you fear government over regulation, [[00:22:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1326.24s)]
*  or should you fear autocomplete? And I would say you should not be so afraid of the autocomplete [[00:22:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1332.0s)]
*  right now. It may get so good that it's an AGI, but right now it's an exceptionally good autocomplete. [[00:22:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1338.24s)]
*  Yeah, and I just think that, again, it's a tried and true tactic of people who want to [[00:22:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1345.28s)]
*  give immeasurably more power to the government to try and make people afraid, [[00:22:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1351.04s)]
*  and they stampede people into these policies. Right. And it gives them power. Exactly. Now, [[00:22:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1355.12s)]
*  why do I think this is important to talk about? On last week's show, I talked about the trip to [[00:22:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1360.2399999999998s)]
*  the Middle East and how we started doing these AI acceleration partnerships with the Gulf states [[00:22:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1363.9199999999998s)]
*  who have a lot of resources, a lot of money, and they're intensely interested in AI. And the Biden [[00:22:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1368.8s)]
*  administration was pushing them away. It basically said, you can't have the chips, you can't build [[00:22:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1373.52s)]
*  data centers. And it was pushing them into the arms of China. The thing that I thought was so bizarre [[00:22:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1377.04s)]
*  is that the various groups and organizations and former Biden staffers who wrote this policy have [[00:23:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1382.0s)]
*  been agitating in Washington, and they've been trying to portray themselves as China hawks. [[00:23:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1387.76s)]
*  And I'm like, wait, this doesn't make any sense because this policy, again, there's basically [[00:23:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1393.36s)]
*  two camps in this new Cold War. It's US versus China. You can pull the Gulf states into our orbit [[00:23:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1397.68s)]
*  or you can drive them into China's orbit. So this, to me, just didn't make any sense. And what's [[00:23:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1402.32s)]
*  happened is that frankly, you've got this EA ideology that's really motivating things, [[00:23:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1406.72s)]
*  which is a desire to lock down compute, right? They're afraid of proliferation. They're afraid [[00:23:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1412.32s)]
*  of diffusion. That's really their motivation. And they're trying to rebrand themselves as China [[00:23:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1418.48s)]
*  hawks because they know that in the Trump administration, that idea is just not going to [[00:23:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1423.68s)]
*  get much purchase, right? And your position as czar is a level playing field. People compete [[00:23:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1427.6000000000001s)]
*  and the good guys, the West should be supported to hit artificial general intelligence as fast as [[00:23:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1435.92s)]
*  possible. So the bad guys, China don't get it first. That's a open competition. [[00:24:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1444.0800000000002s)]
*  I don't know if I would frame it around AGI specifically, but what I would say is that, [[00:24:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1450.72s)]
*  look, I think our policy should be to win the AI race because the alternative is that [[00:24:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1454.24s)]
*  China wins it and that would be very bad for our economy and our military. [[00:24:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1458.48s)]
*  How do you win the AI race? You got to out innovate. You got to have innovation. That [[00:24:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1462.0s)]
*  means we can't have over regulation red tape. We got to build out the most AI infrastructure, [[00:24:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1465.8400000000001s)]
*  data centers, energy, which includes our partners. And then third, I think it means AI diplomacy [[00:24:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1470.0800000000002s)]
*  because we want to build out the biggest ecosystem. We know that biggest App Store wins, [[00:24:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1475.3600000000001s)]
*  biggest ecosystem wins, right? And the policies under the Biden administration were doing the [[00:24:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1479.04s)]
*  opposite of all those things. But again, you have to go back to what was driving that. And it was [[00:24:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1483.2s)]
*  not driven by this China hawk mentality. That is now a convenient rebranding. It was driven by this [[00:24:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1487.68s)]
*  EA ideology, this doomerism. And so this is why I'm talking about it is I want to expose it because [[00:24:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1493.92s)]
*  I think a lot of people on the Republican side don't realize where the ideology is really coming [[00:25:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1500.3200000000002s)]
*  from and who's funding it. They're obviously Trump haters and they need to be loomer quite frankly. [[00:25:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1505.52s)]
*  They need to be loomer. I mean, you know, [[00:25:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1511.04s)]
*  Freiburg, I want to come back around again, because I respect your opinion on, you know, [[00:25:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1517.84s)]
*  how close we are to turning certain corners, especially in science. So I understand big [[00:25:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1524.56s)]
*  picture you believe that the opportunity will be there. Hey, we got people out of fields, [[00:25:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1530.3999999999999s)]
*  you know, in the agricultural revolution, we put them into factories, industrial revolution, [[00:25:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1534.96s)]
*  then we went to this information revolution. So your position is we will have a similar transition [[00:25:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1538.48s)]
*  and it'll be okay. But do you not believe that the speed because we've talked about this privately [[00:25:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1543.84s)]
*  and publicly on the pod, that this speed the velocity at which these changes are occurring, [[00:25:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1552.24s)]
*  you would agree are faster than the industrial revolution, much faster than the information [[00:25:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1557.1200000000001s)]
*  revolution. So let's one more time talk about job displacement. And I think the real concern here [[00:26:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1561.6s)]
*  for a group of people who are buying into this ideology is specifically unions, job displacement. [[00:26:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1567.52s)]
*  This is something the EU cares about. This is something the Biden administration cares about. [[00:26:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1573.36s)]
*  If truck drivers lose their jobs, just like we went to bat previously for coal miners, [[00:26:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1577.6s)]
*  and there were only 75,000 or 150,000 in the country at the time, but it became the national [[00:26:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1583.04s)]
*  dialogue. Oh my God, the coal miners, how fast is this going to happen? One more time on drivers [[00:26:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1587.44s)]
*  specifically. Okay, coders, you think there'll be more code to write, but driving, there's not going [[00:26:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1594.48s)]
*  to be more driving to be done. So is this time different in terms of the velocity of the chain [[00:26:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1599.3600000000001s)]
*  and the job displacement in your mind, Friedberg? The velocity is greater, but the benefit will be [[00:26:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1605.28s)]
*  faster. So the benefit of the industrial revolution, which ultimately drove lower price products and [[00:26:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1610.96s)]
*  broader availability of products through manufacturing was one of the key outputs of that revolution, [[00:26:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1616.08s)]
*  meaning that we created a consumer market that largely didn't exist prior. Remember, prior to [[00:27:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1622.32s)]
*  the industrial revolution, if you wanted to buy a table or some clothes, they were handmade. They [[00:27:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1626.8799999999999s)]
*  were kind of artisanal. Suddenly the industrial revolution unlocked the ability to mass produce [[00:27:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1631.52s)]
*  things in factories, and that dropped the cost and the availability and the abundance of things [[00:27:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1636.56s)]
*  that everyone wanted to have access to, but they otherwise wouldn't have been able to afford. [[00:27:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1641.76s)]
*  So suddenly everyone could go and buy blankets and clothes and canned food and all of these [[00:27:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1645.84s)]
*  incredible things that started to come out of this industrial revolution that happened at the time. [[00:27:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1651.52s)]
*  And I think that folks are underestimating and under realizing the benefits at this stage [[00:27:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1656.16s)]
*  of what's going to come out of the AI revolution and how it's ultimately going to benefit people's [[00:27:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1660.72s)]
*  availability of products, cost of goods, access to things. So the counterbalancing force J-Cal [[00:27:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1666.8799999999999s)]
*  is deflationary, which is let's assume that the cost of everything comes down by half. [[00:27:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1672.0s)]
*  That's a huge relief on people's need to work 60 hours a week. Suddenly you only need to work [[00:27:59](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1679.04s)]
*  30 hours a week and you can have the same lifestyle or perhaps even a better lifestyle than you have [[00:28:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1686.32s)]
*  today. So the counter argument to your point, and I'll talk about the pace of change and specific [[00:28:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1692.24s)]
*  jobs in a moment, but the counter argument to your point is that there's going to be this [[00:28:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1696.8s)]
*  cost reduction and abundance that doesn't exist today. Give an example. Let's give like some [[00:28:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1702.72s)]
*  examples that we could say automation and food prep. So we're seeing a lot of restaurants [[00:28:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1707.84s)]
*  install robotic systems to make food and people are like, Oh, job loss, job loss. [[00:28:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1712.72s)]
*  But let me just give you the counter side. The counter side is that the cost of your food drops [[00:28:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1717.4399999999998s)]
*  in half. So suddenly, you know, all the labor costs that's built into making the stuff you want [[00:28:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1721.6799999999998s)]
*  to pick up, everyone's freaking out right now about inflation. Oh my God, it's $8 for a cup [[00:28:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1725.6s)]
*  of coffee. It's $8 for a latte. This is crazy, crazy, crazy. What if that dropped down to two bucks? [[00:28:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1728.8799999999999s)]
*  You're going to be like, man, this is pretty awesome with good service and good experience [[00:28:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1733.28s)]
*  and don't make it all dystopian. But suddenly there's going to be this like incredible [[00:28:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1736.96s)]
*  reduction or deflationary effect in the cost of food. And we're already starting to see automation [[00:29:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1740.96s)]
*  play its way in the food system to bring inflation down. And that's going to be very powerful for [[00:29:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1745.44s)]
*  people. Shout out to eat, set cloud kitchens and cafe X. We all took swings at the bat at that exact [[00:29:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1749.1200000000001s)]
*  concept is that it could be done better, cheaper, faster. One of the amazing things of these [[00:29:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1754.8s)]
*  vision action models that are now being employed is you can rapidly learn using vision systems and [[00:29:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1759.3600000000001s)]
*  then deploy automation systems in those sorts of environments where you have a lot of kind of [[00:29:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1765.84s)]
*  repetitive tasks that the system can be trained and installed in a matter of weeks. [[00:29:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1770.24s)]
*  And historically that would have been a whole startup that would have taken years to figure out [[00:29:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1774.9599999999998s)]
*  how to get all these things together and custom program and custom code it. So the flip side is [[00:29:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1777.84s)]
*  like when Uber hit, those people were not drivers. Think about the jobs that all those people had [[00:29:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1781.6s)]
*  prior to Uber coming to market. And then the reason they drove for Uber is they could make [[00:29:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1786.8s)]
*  more money driving for Uber or now driving and the flexibility or door dash and the flexibility. [[00:29:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1790.72s)]
*  So their lifestyle got better. They had all of this more control in their life. [[00:29:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1795.12s)]
*  Their incomes went up. And so there's a series of things that you are correct, [[00:29:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1798.7199999999998s)]
*  won't make sense in the future from a kind of standard of work perspective. But the right way [[00:30:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1803.52s)]
*  to think about it is opportunity gets graded, new jobs emerge, new industry, new income, costs go [[00:30:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1809.12s)]
*  down. And so I keep harping on this that it's really hard today to be very prescriptive to [[00:30:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1815.4399999999998s)]
*  Sax's point about what exactly is around the corner. But it is an almost certainty that what [[00:30:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1820.32s)]
*  is around the corner is more capital will be deployed. That means the economy grows. [[00:30:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1825.6799999999998s)]
*  That means there's a faster deployment of growth of new jobs, new opportunities for people to make [[00:30:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1830.32s)]
*  more money, to be happier in the work that they do. And on the flip side being things are going [[00:30:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1835.04s)]
*  to get cheaper. So I mean, we're waxing philosophical here, but I think it's really key because you can [[00:30:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1838.6399999999999s)]
*  focus on the one side of the coin and miss the whole other. And that's what a lot of journalists [[00:30:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1844.3999999999999s)]
*  wonder commentators and fear mongers do is they miss that other side. Got it. Well said, [[00:30:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1849.28s)]
*  Friedberg. Well said. I think I've heard Satya turn this question around about job loss saying, [[00:30:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1854.24s)]
*  well, do you believe that GDP is going to grow by 10% a year? Because what are we talking about [[00:30:59](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1859.92s)]
*  here? In order to have the kind of disruption that you're talking about, where I don't know, [[00:31:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1865.76s)]
*  10 to 20% of knowledge workers end up losing their jobs, AI is going to be such a profound [[00:31:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1870.56s)]
*  force that it's going to have to create GDP growth like we've never seen before. [[00:31:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1876.24s)]
*  That's right. So it's easier for people to say, oh, well, 20% of people are going to lose their [[00:31:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1879.84s)]
*  jobs. But wait, are we talking about a world where the economy is growing 10% every year? [[00:31:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1883.76s)]
*  Like, do you actually believe that's going to happen? That's more income for everyone. That's [[00:31:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1887.6799999999998s)]
*  new jobs being created. It's an inevitability. We've seen this in every revolution. Prior to [[00:31:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1890.8799999999999s)]
*  the Industrial Revolution, 60% of Americans worked in agriculture. And when the tractor came around [[00:31:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1896.56s)]
*  and factories came around, those folks got to get out of doing manual labor in the fields where [[00:31:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1901.36s)]
*  they were literally, you know, tilling the fields by hand. And they got to go work in a factory where [[00:31:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1906.24s)]
*  they didn't have to do manual labor to move things. Yeah, they did things in the factory with their [[00:31:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1912.08s)]
*  hands. But it wasn't about grunt work in the field all day in the sun. And it became a better standard [[00:31:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1915.6799999999998s)]
*  of living. It became you just and today we came about five day work week. It went from a seven day [[00:32:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1921.04s)]
*  work week to five. 100 hours a week to 45, 50 hours a week. And now I think the next phase is [[00:32:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1925.2s)]
*  we're going to end up in less than 30 hours a week with people making more money and having [[00:32:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1931.52s)]
*  more abundance for every dollar that they earn with respect to what they can purchase and the [[00:32:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1935.68s)]
*  lives they can live. That means more time with your family, more time with your friends, more time to [[00:32:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1940.0s)]
*  explore interesting opportunities. So, you know, we've been through this conversation a number of [[00:32:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1944.64s)]
*  times. I know I'm not being too prescriptive. It's important to bring it up, I think, and really unpack it [[00:32:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1948.48s)]
*  because the fear is peaking now, Sachs. People are using this moment in time to scare people that, [[00:32:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1953.12s)]
*  hey, the jobs are going to go away and they won't come back. But what we're seeing on the ground, [[00:32:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1958.56s)]
*  Sachs, is I'm seeing many more startups getting created and able to accomplish more tasks and hit [[00:32:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1962.8799999999999s)]
*  a higher revenue per employee than they did in the last two cycles. So it used to be, you know, [[00:32:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1969.04s)]
*  you try to get to a quarter million in revenue per employee than 500. Now we're regularly seeing [[00:32:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1973.84s)]
*  startups hit a million dollars in revenue per employee, something that was rarefied air previously, [[00:32:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1977.52s)]
*  which then speaks to your point, Freeberg, that there'll be more abundance. There'll be more [[00:33:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1982.48s)]
*  capital generated, more capital deployed. Because yes, more capital deployed for more opportunities, [[00:33:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1986.8000000000002s)]
*  but you're going to need to be more resilient, I think. Yeah. I think it's actually very hard to [[00:33:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1993.04s)]
*  completely eliminate a human job. The ones that you cited, and Jake, how you keep signing the same [[00:33:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=1997.8400000000001s)]
*  ones, because I actually don't think there's that many that fit in this category, the drivers and [[00:33:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2003.52s)]
*  maybe level on customer support, because those jobs are so monolithic. But when you think about [[00:33:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2007.68s)]
*  even like what a salesperson does, right, it's like, yes, they spend a lot of time with prospects, [[00:33:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2013.04s)]
*  but they also spend time negotiating contracts and they spend time doing post-sale implementation [[00:33:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2018.24s)]
*  and follow up and they spend time learning the product and giving feedback. I mean, [[00:33:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2023.68s)]
*  it's a multifaceted job and you can use AI to automate pieces of it, but to eliminate the whole [[00:33:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2027.8400000000001s)]
*  job is actually very hard. And so I just think this idea that, boom, 20% of the workforce is [[00:33:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2034.08s)]
*  going to be unemployed in two years, I just don't think that it's going to work that way. But look, [[00:33:59](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2039.52s)]
*  if there is widespread job disruption, then obviously the government's going to have to react [[00:34:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2043.6s)]
*  and we're going to be in a very different societal order. But my point is you want the government to [[00:34:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2047.84s)]
*  start reacting now before this actually happens. Yeah, we don't need to be precox and predict it. [[00:34:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2053.2s)]
*  Yeah. It's a total power grab. It's a total power grab to give the government and these [[00:34:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2057.7599999999998s)]
*  organizations more power before the risk is even manifested. And let me say this as well, [[00:34:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2062.88s)]
*  with respect to all these regulations that were created, the 100 page by NEO and the 200 page [[00:34:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2068.08s)]
*  diffusion rule, none of these regulations solve the ex-risk problem. None of these things actually [[00:34:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2072.08s)]
*  would prevent the most existential risks that we're talking about. They don't sign for alignment. [[00:34:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2078.7200000000003s)]
*  They don't sign for the kill switch. None of that. Yeah. When someone actually figures out how to [[00:34:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2083.76s)]
*  solve that problem, I'm all ears. Look, I'm not cavalier about these risks. I understand that they [[00:34:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2087.68s)]
*  exist, but I'm not in favor of the fear mongering. I'm not in favor of giving all this power to the [[00:34:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2093.3599999999997s)]
*  government before we even know how to solve these problems. Chamath, you did a tweet about entry [[00:34:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2098.8799999999997s)]
*  level jobs being toast. So I think there is a nuance here and both parties could be correct. [[00:35:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2105.04s)]
*  I think the job destruction is happening as we speak. I'll just give one example and then [[00:35:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2109.9199999999996s)]
*  drop to you, Chamath. One job in startups that's not driving a car or a super entry level was [[00:35:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2114.64s)]
*  people would hire consultants to do recruitment and to write job descriptions. Now, I was at a [[00:35:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2120.24s)]
*  journalist last night talking to a bunch of founders here in Singapore and I said, [[00:35:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2125.12s)]
*  how many people have used AI to write a job description? Everybody's hand went up. I said, [[00:35:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2127.92s)]
*  how many of you with that job description, was that job description better than you could have [[00:35:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2131.44s)]
*  written or any consultant? And they all said, yes, 100% AI is better at that job. That was a job, [[00:35:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2136.08s)]
*  a high level HR recruitment job or an aspect of it, Zach. So that was half the job, a third of the [[00:35:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2141.36s)]
*  job to your point, the chores are being automated. So I do think we're going to see entry level jobs, [[00:35:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2147.28s)]
*  Chamath, the ones that get people into an organization, maybe they're going away. And [[00:35:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2152.2400000000002s)]
*  was that your point of your tweet, which we'll pull up right here? [[00:35:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2158.1600000000003s)]
*  If a GPT is a glorified autocomplete, how did we used to do glorified autocomplete in the past? [[00:36:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2160.6400000000003s)]
*  It was with new grads. New grads were our autocomplete. And to your point, the models [[00:36:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2167.76s)]
*  are good enough that it effectively allows a person to rise in their career without the need of [[00:36:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2175.5200000000004s)]
*  new grad grist for the mill, so to speak. So I think the reason why companies aren't hiring [[00:36:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2183.5200000000004s)]
*  nearly as many new grads is that the folks that are already in a company can do more work with [[00:36:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2189.2000000000003s)]
*  these tools. And I think that that's a very good thing. So you're generally going to see [[00:36:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2194.8s)]
*  OpEx as a percentage of revenue shrink naturally. And you're going to generally see revenue per [[00:36:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2199.76s)]
*  employee go up naturally. But it's going to create a tough job market for new grads in the established [[00:36:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2207.04s)]
*  organizations. And so what should new grads do? They should probably steep themselves in the tools [[00:36:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2215.2000000000003s)]
*  and go to younger companies or start a company. I think that's the only solution for them. [[00:37:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2220.0800000000004s)]
*  The most important thing for whether there are jobs available for new grads or not is whether the [[00:37:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2224.96s)]
*  economy is booming. So obviously, in the wake of a financial crisis, the jobs dry up because [[00:37:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2231.04s)]
*  everyone's cost cutting. And those jobs are the first ones to get cut. But if the economy is [[00:37:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2236.24s)]
*  booming, then there's going to be a lot more job creation. And so again, if AI is this driver and [[00:37:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2242.16s)]
*  enabler of tremendous productivity, that's going to be good for economic growth. And I think that [[00:37:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2249.36s)]
*  will lead to more company formation, more company expansion at the same time that you're getting [[00:37:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2253.2799999999997s)]
*  more productivity. Now, to give an example, one of the things I see a lot discussed online about [[00:37:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2257.52s)]
*  these coding assistants is that they make junior programmers much better. Because if you're already [[00:37:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2264.24s)]
*  like a 10x programmer, very experienced, you already knew how to do everything. And you could [[00:37:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2270.56s)]
*  argue that the people who benefit the most are the entry-level coders who are willing to now [[00:37:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2275.36s)]
*  embrace the new technology and it makes them much more productive. So in other words, it's a huge [[00:38:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2282.0s)]
*  leveler and it takes an entry-level coder and makes them 5x or 10x better. So look, this is an argument [[00:38:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2286.56s)]
*  I see online. The point is just, I don't think we know how this cuts yet. I agree. And I just think [[00:38:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2293.36s)]
*  there's like this, this doomerism is premature. And it's not a coincidence that it's being funded [[00:38:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2298.48s)]
*  and motivated by this hardcore ideological element. I'll tell you my hiring experience. [[00:38:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2305.36s)]
*  We have about 30 people at 80, 90. And the way that I found it to work the best is you have [[00:38:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2312.48s)]
*  senior people act as mentors, and then you have an overwhelming corpus of young, very talented people [[00:38:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2318.08s)]
*  who are AI native. And if you don't find that mix, what you have instead are L7s from Google and [[00:38:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2323.6800000000003s)]
*  Amazon and Meta who come to you with extremely high salary demands and stock demands. And they [[00:38:51](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2331.92s)]
*  just don't thrive. And part of why they don't thrive is that they push back on the tools and [[00:39:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2340.0s)]
*  how you use them. They push back on all these things that the tools help you get to faster. [[00:39:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2345.04s)]
*  This is why I think it's so important for young folks to just jump in with two feet and be AI [[00:39:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2349.76s)]
*  native from the jump because you're much more hireable, frankly, to the emergent company. [[00:39:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2353.76s)]
*  And the bigger companies, you'll have a lot of these folks that see the writing on the wall, [[00:39:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2359.28s)]
*  may not want to adapt as fast as otherwise. Another way, for example, that you can measure [[00:39:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2364.88s)]
*  this is if you look inside your company, on the productivity lift of some of these coding [[00:39:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2369.84s)]
*  assistants, for people as a distribution of age, what you'll see is the younger people leverage [[00:39:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2374.88s)]
*  it way more and have way more productivity than older folks. And I'm not saying that as an ageist [[00:39:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2379.76s)]
*  comment. I'm saying that it's an actual reflection of how people are reacting to these tools. [[00:39:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2385.44s)]
*  Aaron Powell What you're describing is a paradigm shift. [[00:39:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2390.0s)]
*  Ramesh Parakhs It is a big leap. [[00:39:51](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2391.7599999999998s)]
*  Aaron Powell It is. You know. [[00:39:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2392.7999999999997s)]
*  Ramesh Parakhs It's like when I went to college, [[00:39:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2393.52s)]
*  when I took computer science, it was object oriented programming. It was like C++. It was [[00:39:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2395.04s)]
*  compiled languages. It was gnarly. It was nasty work. And then you have these high level abstracted [[00:40:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2400.24s)]
*  languages. And I used to remember at Facebook, I would just get so annoyed because I was like, [[00:40:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2406.4s)]
*  why is everybody using PHP and Python? This is like not even real. But I was one of these [[00:40:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2410.4s)]
*  old light lights who didn't understand that I just had to take the leap. And what it did was it grew [[00:40:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2414.32s)]
*  the top of the funnel of the number of developers by 10x. And as a result, what you had were all of [[00:40:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2419.92s)]
*  these advancements for the internet. And I think what's happening right now is akin to the same [[00:40:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2425.52s)]
*  thing, where you're going to grow the number of developers upstream by 10x. But in order to [[00:40:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2429.36s)]
*  embrace that, you just have to jump in with two feet. And if you're very rigid in how you think [[00:40:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2434.7200000000003s)]
*  a job should be done technically, I think you're just going to get left behind. [[00:40:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2439.76s)]
*  Just a little interesting statistic there. Microsoft announced 6,000 job layoffs, about [[00:40:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2443.04s)]
*  3% of their workforce, while putting up record profits, while being in an incredible cash position. [[00:40:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2448.16s)]
*  That would be something. It's like total confirmation bias. It's like now every time there's a layoff [[00:40:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2453.2s)]
*  announcement, people try to tie it to AI to feed this Doomer story. I don't think that's an AI story. [[00:40:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2457.04s)]
*  I don't think it's an AI story. I think it is because the people they're eliminating are [[00:41:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2463.44s)]
*  management. And I think the management layer becomes less necessary. Five seconds ago you were [[00:41:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2466.96s)]
*  saying it was entry level employees. Now you're saying it's management. This is total confirmation. [[00:41:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2470.64s)]
*  No, no, I think those are two areas that specifically get eliminated. Entry level, [[00:41:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2475.52s)]
*  it's too hard. It's too hard to give them the grunt work. And then for the managers who are old, [[00:41:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2479.8399999999997s)]
*  it's not been there for 20 years. Hold on, let me finish. Though for those people, I think they are [[00:41:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2484.7999999999997s)]
*  unnecessary in this new AI monitoring world. What are you talking about? What is the AI agent that's [[00:41:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2490.16s)]
*  doing management right now in companies? Oh, this theory doesn't even make sense. [[00:41:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2495.68s)]
*  Oh, no, it totally does. There are tools now that are telling you this is these are the most [[00:41:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2500.16s)]
*  productive people in the organization from off just outlined who's shipping the most, [[00:41:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2505.12s)]
*  et cetera, who's using the tools. And then people are saying, well, why do we have all these highly [[00:41:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2508.48s)]
*  priced people who are not actually shipping code who are L7s, et cetera? So they're totally falling [[00:41:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2513.04s)]
*  for some sort of narrative here. This makes no sense. I don't think I am. Yeah. Let me be very [[00:41:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2517.04s)]
*  clear what I'm saying. What I am saying is AI natives are extremely productive. They use these [[00:42:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2522.4s)]
*  tools. They're very facile with them. I think it's very reductive, but what you see is the older or [[00:42:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2528.32s)]
*  more established in your career you are in technical roles. What I see is that it's harder [[00:42:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2534.88s)]
*  and harder for folks like that to embrace these tools in the same way. Now, how does it play out [[00:42:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2539.6s)]
*  in terms of jobs? I think that just these tools are good enough where the net new incremental task [[00:42:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2544.8s)]
*  oriented role that would typically go to a new grad, a lot of that can be defrayed by these models. [[00:42:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2553.28s)]
*  That's what I'm saying very clear specifically. And I don't think that speaks to management. [[00:42:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2558.7200000000003s)]
*  I agree with Sachs. It has nothing to do with management. [[00:42:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2562.48s)]
*  But Sergey said, Freeberg, when he came to our F1, that management would be the first thing to go. [[00:42:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2564.0s)]
*  I was talking to some entrepreneurs last night, again, here in Singapore, [[00:42:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2570.32s)]
*  and they are taking all the GitHub and Jira cards and things that have been submitted, [[00:42:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2573.52s)]
*  plus all the Slack messages in their organization, and they're putting them into an LLM and having [[00:42:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2578.8s)]
*  it write management reports of who is the most productive in the organization. And in the new [[00:43:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2583.6800000000003s)]
*  version of Windows, it's monitoring your entire desktop, Freeberg. Management is going to know [[00:43:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2588.0s)]
*  who in the organization is actually doing work, what work they're doing, and what the result of [[00:43:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2592.88s)]
*  that work is through AI. That is the future of management. And you take out all bias, all loyalty, [[00:43:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2598.48s)]
*  and the AI is going to do that. I couldn't disagree with you more, Sachs, on that. But Freeberg, [[00:43:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2605.68s)]
*  do you want to wrap this up here on this topic? That wasn't my point. My point is that AI, [[00:43:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2610.16s)]
*  managers are not losing their job because AI is replacing them. I didn't say that AI wouldn't be [[00:43:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2614.32s)]
*  a valuable tool for managers to use. Sure, AI will be a great tool for managers, but we're not [[00:43:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2619.6s)]
*  anywhere near the point where managerial jobs are being eliminated because they're getting [[00:43:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2625.52s)]
*  replaced by AI agents. We're still at the chatbot stage of this. Literally, Sergey said he took [[00:43:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2630.32s)]
*  their internal Slack, went into a dev conversation, said, who are the underrated people in this [[00:43:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2635.6s)]
*  organization who deserve a raise? And it gave him the right answer. Right. That doesn't allow you [[00:44:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2640.48s)]
*  to cut 6,000 people. I think it's happening as we speak. It's just not over. You fell for this [[00:44:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2643.68s)]
*  narrative. You grasped onto this Microsoft restructuring where they eliminated 6,000 roles, [[00:44:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2649.36s)]
*  and you're trying to attribute that to AI now. I think it has to do with AI. I think management [[00:44:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2655.2000000000003s)]
*  is looking at it saying we are going to replace these positions with AI. We might as well get rid [[00:44:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2659.36s)]
*  of them now. It is in flux. We'll see who's right in the coming months. Can I make another comment? [[00:44:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2663.76s)]
*  Freeberg, wrap this up here so we can get on to the next topic. This is a great topic. [[00:44:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2668.56s)]
*  I want to make one last point, which I think, and Sachs, you may not appreciate this, so we can have [[00:44:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2673.92s)]
*  a healthy argument about this. I think in the same way that all of these jobs are going to get lost [[00:44:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2678.88s)]
*  to AI fear-mongering, there's a similar narrative that I think is a false narrative around there's a [[00:44:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2684.64s)]
*  race in AI that's underway between nation states. And the reason I think it's false is if I asked [[00:44:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2690.56s)]
*  you guys the question who won the Industrial Revolution, the Industrial Revolution benefited [[00:44:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2696.96s)]
*  everyone around the world. There are factories, and there's a continuous effort and continuous [[00:45:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2702.32s)]
*  improvement in manufacturing processes worldwide. That is a continuation of that revolution. [[00:45:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2706.48s)]
*  Similar, if I asked who won the internet race, there are businesses built out of the US, [[00:45:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2711.68s)]
*  businesses built out of China, businesses built out of India and Europe that have all created [[00:45:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2716.16s)]
*  value for shareholders, created value for consumers, changed the world, etc. And I think the same is [[00:45:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2720.56s)]
*  going to happen in AI. I don't think that there's a finish line in AI. I think AI is a new paradigm [[00:45:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2725.6s)]
*  of work, a new paradigm of productivity, a new paradigm of business, of the economy, of livelihoods, [[00:45:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2731.6s)]
*  of pretty much everything, every interaction humans have with ourselves and the world around us [[00:45:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2738.3199999999997s)]
*  will have in its substrate AI. And as a result, I think it's going to be this continuous process [[00:45:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2744.08s)]
*  of improvement. So I'm not sure, look, there are different models, and you can look at the performance [[00:45:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2748.96s)]
*  metrics of models, but you can get yourself spun up into a tizzy over which model is ahead of the [[00:45:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2752.96s)]
*  others, which one's going to quote, get to the finish line first. But I think at the end of the [[00:45:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2757.44s)]
*  day, the abundance and the economic prosperity that will arise from the continuous performance [[00:46:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2761.2000000000003s)]
*  improvements that come out of AI and AI development will benefit all nation states and actually could [[00:46:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2766.88s)]
*  lead to a little bit more of a less resource constrained world where we're all fighting over [[00:46:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2771.92s)]
*  limited resources. And there's nation state definitions around who has access to what and [[00:46:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2776.96s)]
*  perhaps more abundance, which means more peace, and less of this kind of resource driven world. [[00:46:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2781.28s)]
*  Sacks your thought on the Kumbaya theory, exposed by Freebird. [[00:46:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2787.04s)]
*  Yeah, exactly. [[00:46:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2791.04s)]
*  I'll partially agree in the sense that I don't think the AI race is a finite game. It's an infinite [[00:46:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2792.4s)]
*  game. I agree that there's no finish line, but that doesn't mean there's not a race going on. [[00:46:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2799.68s)]
*  So for example, an arms race would be a classic example of a competition between countries [[00:46:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2804.96s)]
*  to see who is stronger to basically amass power and they might be neutralizing each other. The [[00:46:51](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2811.92s)]
*  balance of power may stay in equilibrium, even though both sides feel the need to constantly [[00:46:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2817.36s)]
*  up level their arms, their power. And so I think that to use the term that Mearsheimer used at the [[00:47:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2822.4s)]
*  All In Summit, we are in an iron cage. The US and China are the two leading countries in the world, [[00:47:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2828.5600000000004s)]
*  economically, militarily, technologically. They both care about their survival. The best way to [[00:47:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2835.28s)]
*  ensure your survival in a self-help world is by being the most powerful. And so these are great [[00:47:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2842.2400000000002s)]
*  powers who care a lot about the balance of power and they will compete vigorously with each other [[00:47:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2849.6000000000004s)]
*  to maintain the greatest balance of power between them. And high tech is a major dimension of that [[00:47:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2855.28s)]
*  competition. And within high tech, AI is the most important field. So look, there is going to be an [[00:47:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2860.72s)]
*  intense competition around AI. Now, the question is, how does that end up? I mean, it could end up [[00:47:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2865.8399999999997s)]
*  in a tie or in, it could end up in a situation where both countries benefit, maybe open source [[00:47:51](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2871.2s)]
*  wins, maybe neither side gains a decisive advantage, but they're absolutely going to compete [[00:47:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2877.52s)]
*  because neither one can afford to take the risk that the other one will develop a decisive advantage. [[00:48:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2882.48s)]
*  Prisoners dilemma. Nuclear proliferation is a good analogy. I would argue nuclear deterrence [[00:48:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2888.0s)]
*  led to a more peaceful world in the 20th century. I mean, is that fair to say, Sachs, that ultimately... [[00:48:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2893.36s)]
*  Well, what happened with nuclear is that the actual underlying technology hit an asymptote. [[00:48:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2898.08s)]
*  Right. It plateaued, right? And so we ended up in a situation where, in the case of the United [[00:48:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2903.52s)]
*  States versus Soviet Union, where both sides had enough nukes to blow up the world many times over. [[00:48:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2908.48s)]
*  And there wasn't really that much more to innovate. So, you know, the underlying [[00:48:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2913.68s)]
*  technological competition had ended. The dynamic was more stable and they were able to reach an [[00:48:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2918.24s)]
*  arms control framework to sort of control the arms race. Right? I think AI is a little different. [[00:48:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2922.96s)]
*  We're in a situation right now where the technology is changing very, very rapidly. [[00:48:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2930.08s)]
*  And it's potentially on some sort of exponential curve. And so therefore being a year ahead, even [[00:48:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2934.7999999999997s)]
*  six months ahead, could result in a major advantage. I think under those conditions, [[00:49:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2940.08s)]
*  both sides are going to feel the need to compete very vigorously. I don't think they can sign up. [[00:49:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2944.4s)]
*  But this is a system of productivity, right? For an agreement to slow each other down. I just don't... [[00:49:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2948.72s)]
*  But nuclear was not a system of productivity. It was not a system of economic growth. It was a [[00:49:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2952.96s)]
*  system of literally destruction. And this is quite different. This is a system of making more with [[00:49:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2956.72s)]
*  less, which unleashes benefits to everyone in a way that perhaps should be calming down the conflict [[00:49:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2962.08s)]
*  and attention between nations. You've got to admit that there is a potential dual use here. [[00:49:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2969.2s)]
*  There's no question that the armies of the future are going to be drones and robots and they're [[00:49:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2972.96s)]
*  going to be AI powered. And as long as that's the case, these countries are going to compete [[00:49:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2976.72s)]
*  vigorously to have the best AI. And they're going to want their leaders or national champions or [[00:49:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2980.7999999999997s)]
*  starps and so forth to win the race. What's the worst case, Sax, if China wins the AI race? [[00:49:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2986.3999999999996s)]
*  What is the worst case scenario? Ask what it means first. Ask what it means. [[00:49:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2992.7999999999997s)]
*  That's literally what I'm asking. What would that scenario be? Would they invade America [[00:49:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=2996.56s)]
*  and they dominate us forever? And what does it mean to lead? What does it mean to win? [[00:50:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3000.7200000000003s)]
*  To me, it would mean that they achieve a decisive advantage in AI such that we can't leapfrog them [[00:50:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3005.76s)]
*  back. And an example of this might be something like 5G, where Huawei somehow leapfrogged us, [[00:50:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3012.4s)]
*  got to 5G first and disseminated it through the world. They weren't concerned about diffusion. [[00:50:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3019.52s)]
*  They were interested in promulgating their technology throughout the world. [[00:50:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3025.28s)]
*  So if the Chinese win AI, they will sell more products and services around the globe than the [[00:50:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3028.8s)]
*  US. This is where we have to change our mindset towards diffusion. I would define winning as the [[00:50:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3033.52s)]
*  whole world consolidates around the American tech stack. They use American hardware in data centers [[00:50:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3037.92s)]
*  that again are fundamentally powered by American technology. And just look at market share. If we [[00:50:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3045.2000000000003s)]
*  have like 80 to 90% market share, that's winning. If they have 80% market share, then we're in big [[00:50:51](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3051.36s)]
*  trouble. So it's very simple. It means- Yeah, but if the market grows up by 10X, it doesn't matter [[00:50:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3056.48s)]
*  because the world will have- every individual in every country will now have more. They will have [[00:51:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3062.08s)]
*  a more prosperous life. And as a result, it's not necessarily the framing about if we don't get there [[00:51:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3066.2400000000002s)]
*  first, we are necessarily going to lose. I get that there's an edge case of conflict or what have [[00:51:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3071.84s)]
*  you. But I do think that there's a net benefit where the whole world suddenly is in this more [[00:51:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3076.88s)]
*  prosperous state. And- This is a classic example of a dual use technology where there are both [[00:51:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3080.88s)]
*  economic benefits and there are military benefits. Yes. GPS would come to mind in this example, [[00:51:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3086.2400000000002s)]
*  right? Like my summary point is just that it's not all about a losing game with respect to this [[00:51:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3092.96s)]
*  quote race with other nation states. But at the end of the day, yes, there is risk. But I do think [[00:51:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3098.8s)]
*  that if the pace of improvement stays on track like it is right now, holy s**t, I think we're in [[00:51:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3104.24s)]
*  a pretty good place. That's just my point. Okay. Some positivity. Okay. Look, I hope that the AI [[00:51:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3110.0s)]
*  race stays entirely positive and it's a healthy competition between nations and the competition [[00:51:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3114.7999999999997s)]
*  spurs them on to develop more prosperity for their citizens. But as we talked about the AI summit, [[00:52:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3120.64s)]
*  there's two ways of looking at the world. There's kind of the economist way that Jeffrey Sachs was [[00:52:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3126.08s)]
*  talking about. And then there's the balance of power way, a realist way, which Mirschaumer was [[00:52:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3130.24s)]
*  talking about. And when economic prosperity and survival or balance of power come into conflict, [[00:52:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3134.8799999999997s)]
*  it's the realist view of the world that it's the balance of power that gets privileged. [[00:52:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3144.24s)]
*  And I just think that's the way that governments operate is that prosperity is incredibly [[00:52:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3148.4799999999996s)]
*  important. We want economic success, but power is ultimately privileged over that. And this is why [[00:52:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3153.12s)]
*  we're going to compete vigorously in high tech. That's why there is going to be an AI race. [[00:52:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3160.16s)]
*  Okay. Perfect segue. We should talk a little bit about what was the topic of discussion. [[00:52:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3163.8399999999997s)]
*  Yesterday I had a lunch with a bunch of family offices and capital allocators, [[00:52:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3169.3599999999997s)]
*  government folks here in Singapore, and they were talking about our discussion last week [[00:52:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3173.68s)]
*  about the big, beautiful bill and the debt here in the United States. It's permeating everywhere. [[00:52:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3178.48s)]
*  The two conversations at every stop I've made here is the big, beautiful bill and the balance [[00:53:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3184.48s)]
*  sheet of the United States as well as tariffs. So we need to maybe revisit our discussion last week. [[00:53:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3191.6s)]
*  Chamath you had in Freiburg did an impromptu call with Ron Johnson over the weekend, which then [[00:53:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3197.68s)]
*  spurred him going on 20 other podcasts to talk about this. Stephen Miller from the administration [[00:53:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3203.52s)]
*  has been tweeting some corrections or his perceived corrections about the bill. And Saxa, [[00:53:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3210.32s)]
*  I think you've also started tweeting this. Where do we want to start? Maybe... [[00:53:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3216.16s)]
*  Well, I think there are just a couple of facts that should be cleaned up because... [[00:53:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3220.72s)]
*  Okay. So facts from the administration, their view of our discussion. [[00:53:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3224.48s)]
*  Well, even though I was defending the bill last week on the whole, I wasn't saying it was perfect. [[00:53:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3229.2s)]
*  I was just saying it was better than the status quo. [[00:53:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3233.52s)]
*  Yeah, you were clear about that. [[00:53:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3235.2799999999997s)]
*  Yeah. But even I in doing that was conceding some points that I think were just factually [[00:53:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3236.56s)]
*  wrong. And the big one was that I said I was disappointed that the Doge cuts weren't included [[00:54:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3242.8799999999997s)]
*  in the big, beautiful bill. What Stephen Miller's pointed out is that reconciliation bills can only [[00:54:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3248.08s)]
*  deal with what's called mandatory spending. They can't deal with what's called discretionary [[00:54:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3254.0s)]
*  spending. And since the Doge cuts apply to discretionary spending, they just can't be [[00:54:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3258.08s)]
*  dealt with in a reconciliation bill. They have to be dealt with separately. There can be [[00:54:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3262.72s)]
*  a separate rescission bill that comes up, but it can't be dealt with in this bill. [[00:54:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3266.0s)]
*  And just to be very clear, look, if the Doge cuts don't happen through rescission, [[00:54:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3270.16s)]
*  I'm going to be very disappointed in that. I really want the Doge cuts to happen. But [[00:54:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3274.96s)]
*  it's just a fact that the Doge cuts cannot happen in the big, beautiful bill. It's not that kind of [[00:54:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3278.4s)]
*  bill. And I think it's therefore wrong to blame big, beautiful bill for not containing [[00:54:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3284.24s)]
*  Doge cuts when the Senate rules don't allow that. It all goes back to the Bird rules. [[00:54:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3289.6s)]
*  There are only specific things that can be dealt with through reconciliation, which is this [[00:54:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3294.72s)]
*  50 vote threshold. And it has to be quote unquote mandatory spending. [[00:55:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3300.08s)]
*  Discretionary cuts are dealt with in annual appropriations bills that require 60 votes. [[00:55:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3304.0s)]
*  Now look, this is kind of a crazy system. I don't know exactly how it evolved. I guess [[00:55:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3308.24s)]
*  Robert Bird is the one who came up with all this stuff and maybe they need to change the system. [[00:55:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3312.72s)]
*  But it's just wrong to blame the big, beautiful bill for not containing the Doge cuts. That's [[00:55:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3316.7999999999997s)]
*  just a fact. So the other thing is that the BBB does actually cut spending. It's just not scored [[00:55:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3320.3199999999997s)]
*  that way because when the bill removes the sunset provision from the 2017 tax cuts, [[00:55:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3326.64s)]
*  the CBO ends up scoring that as effectively a spending increase. [[00:55:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3334.08s)]
*  But tax rates are simply continuing at their current level. In other words, at this year's [[00:55:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3338.64s)]
*  level. So if you used the current year as your baseline, and then compared it to spending [[00:55:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3344.08s)]
*  next year, it would score as a cut in spending. So it's just not correct to say the bill [[00:55:51](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3351.44s)]
*  increases spending. It does actually result in a mandatory spending cut, but it's not getting [[00:55:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3358.16s)]
*  credit for that because we're continuing the tax rates at the current year's rates. [[00:56:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3364.56s)]
*  Aaron Ross Powell Do you believe, [[00:56:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3369.92s)]
*  Sachs, that this administration, which you are part of, in four years will have balanced the budget? [[00:56:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3371.36s)]
*  Will it have reduced the deficit or the deficit continue to grow at two trillion a year? What is [[00:56:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3378.88s)]
*  your belief? Because there's a lot of strategies going on here. [[00:56:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3384.4s)]
*  David Tenenbaum My belief is that President Trump came into [[00:56:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3387.36s)]
*  office inheriting a terrible fiscal situation. I mean, basically, what happened- [[00:56:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3390.08s)]
*  Aaron Ross Powell That he created and that Biden created. [[00:56:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3394.08s)]
*  David Tenenbaum I don't think he created it. [[00:56:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3396.64s)]
*  Aaron Ross Powell They both put a trillion on the debt. [[00:56:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3397.44s)]
*  David Tenenbaum Okay. It's a big difference to add to the [[00:56:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3399.04s)]
*  deficit when you're in the emergency phase of COVID. And there's emergency spending. [[00:56:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3402.16s)]
*  Aaron Ross Powell Okay, give him a mulligan for that. Sure. [[00:56:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3406.08s)]
*  David Tenenbaum It's emergency spending. It was never supposed to be permanent. And then somehow, [[00:56:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3406.88s)]
*  Biden made it permanent. And he wanted a lot more. Remember Bill Back Better? He wanted a lot more. [[00:56:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3410.56s)]
*  So, you know, it's tough when you come into office with a, what is, two trillion dollar [[00:56:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3415.36s)]
*  annual deficit. Aaron Ross Powell [[00:57:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3420.1600000000003s)]
*  Okay. So to my original question- David Tenenbaum [[00:57:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3420.8s)]
*  Now look, hold on. Would I like to see the deficit eliminated in one year? Yeah, [[00:57:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3422.0s)]
*  absolutely. But there's just not the votes for that. Aaron Ross Powell [[00:57:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3426.32s)]
*  Well, I asked you for four years. David Tenenbaum [[00:57:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3428.08s)]
*  There's a one vote margin here in the House. And the Democrats aren't cooperating in any way. So, [[00:57:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3428.88s)]
*  I think that the administration is getting the most done that it can. This is a mandatory spending [[00:57:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3434.8s)]
*  cut. And I think the Doge cuts will be dealt with hopefully through rescission in a subsequent bill. [[00:57:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3441.04s)]
*  David Tenenbaum I'm asking you about four years from now. [[00:57:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3446.32s)]
*  Will we be sitting here in four years? Will Trump have cut spending by the end of this term in [[00:57:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3448.4s)]
*  another three and a half years? Will we be looking at a balanced budget? Potentially? Is that the [[00:57:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3453.92s)]
*  goal of the administration? Or will we be at $42, $44, $45 trillion at the end of Trump's second term? [[00:57:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3458.8s)]
*  Aaron Ross Powell Listen, if you want that level of specificity, [[00:57:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3466.08s)]
*  you're going to have to get Scott Besson on. This is just not my area. I'm not going to pretend to [[00:57:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3468.56s)]
*  have that level of detailed answers. But what I believe is that the Trump administration's policy [[00:57:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3472.24s)]
*  is to spur growth. I think that these tax policies will spur growth. I think that AI will also be a [[00:57:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3477.52s)]
*  huge tailwind. It'll be a productivity boost. I think let's stop being do-mers about it. We [[00:58:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3484.0s)]
*  need that productivity boost. And I think that the net result of those things will be to improve the [[00:58:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3488.7999999999997s)]
*  fiscal situation. Do I want more spending cuts? Yeah. But look, we're getting more than was [[00:58:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3493.84s)]
*  represented last week. Let's put it that way. Will Duffie Okay, fair enough, Sax. Thank you [[00:58:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3498.8s)]
*  for the cleanup there. Chamath, our bestie, Elon, was on the Sunday shows. And he said, hey, the [[00:58:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3501.76s)]
*  bill can be big, or it can be beautiful. It can't be both. He seems to be, I'll say, displeased, [[00:58:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3506.8s)]
*  or maybe not as optimistic about balancing the budget and getting spending under control. [[00:58:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3513.6800000000003s)]
*  But he still believes in Doge, obviously, and hopefully Doge continues. You seemed a little [[00:58:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3519.44s)]
*  bit concerned last week. A week's passed. You've heard some of Stephen Miller's opinions. Where do [[00:58:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3525.52s)]
*  you net out seven days from our big, beautiful budget bill debate last week? Or we could I mean, [[00:58:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3532.32s)]
*  I think Stephen's critique of how the media summarized the reaction to the bill is accurate. [[00:58:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3538.5600000000004s)]
*  And I think it's probably useful to double click into one thing that Sax didn't mention, [[00:59:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3549.52s)]
*  but that Stephen did. A lot of this pivots around the CBO, which is the Congressional Budget Office, [[00:59:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3554.0s)]
*  and how they look at these bills. And there's a lot of issues with how they do it. [[00:59:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3559.36s)]
*  In one specific case, which Sax just mentioned, and Stephen talked about is that they have these [[00:59:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3568.0s)]
*  arcane rules about the way that they score things. And what they were assuming is that [[00:59:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3573.6s)]
*  the tax rates would flip back to what they were before the first Trump tax cuts, which obviously [[00:59:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3581.7599999999998s)]
*  would be higher than where they are today. What that would mean in their financial model is we [[00:59:51](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3591.36s)]
*  were going to get all that money. Now to maintain the tax cuts where we are, [[00:59:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3598.4s)]
*  they now then would look at that and say, oh, hold on, that's a loss of revenue. [[01:00:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3604.1600000000003s)]
*  Why are all of these things important? I downloaded the CBO model, went through it. And what I would [[01:00:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3608.56s)]
*  say is, at best, it's Spartan. Which means that I don't think a financial analyst, or somebody that [[01:00:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3614.96s)]
*  controls a lot of money, will actually put a lot of stock in their model. I think what you'll have [[01:00:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3623.12s)]
*  happen is people will build their own versions, bottoms up. Do you trust it, the CBO's version [[01:00:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3628.96s)]
*  of this? Or do you largely trust it? I don't think the CBO really knows what's going on, [[01:00:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3635.3599999999997s)]
*  to be totally honest with you. Okay. I think that there are parts of what they do, [[01:00:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3638.96s)]
*  which they're also opaque on. Nick, I sent you a tweet from Goldman Sachs. So here's what Goldman [[01:00:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3644.7999999999997s)]
*  put out. Now, the point is, when you build a model, what you're trying to do is net out all [[01:00:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3652.56s)]
*  of these bars. Okay, you're trying to add the positive bars and the negative bars, and you [[01:00:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3657.2s)]
*  figure out what is the total number at the end of it. Now, in order to do that, when you see the [[01:01:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3660.48s)]
*  bars on the far right, that's a 2034 dollar. That's very different than a 2025 dollar. [[01:01:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3665.6s)]
*  The CBO doesn't disclose how they deal with that. They don't disclose the discount rate. So you can [[01:01:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3671.68s)]
*  question what that is. The CBO makes these assumptions that, as Stephen pointed out, [[01:01:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3677.12s)]
*  are very brittle with respect to the tax plan. That's not factored in here. [[01:01:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3682.08s)]
*  So those are the issues with the way the CBO scores it. So you have to do it yourself. [[01:01:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3686.48s)]
*  Now, Peter Navarro published an article, which I think is probably the most [[01:01:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3691.92s)]
*  pivotal article about this whole topic. Peter Navarro of Tariff fame. Yeah. Yeah. Here, [[01:01:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3695.84s)]
*  I think he nails it right in the bullseye, which is the bond market needs to make a decision [[01:01:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3702.72s)]
*  on one very critical assumption when they build their own model. Okay, so let's ignore the CBO's [[01:01:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3709.2799999999997s)]
*  brittle math and the Excel that they post on their website. People are going to do their own because [[01:01:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3716.64s)]
*  they're talking about managing their own money. But Navarro basically points to the critical thing, [[01:02:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3721.52s)]
*  which is, listen, those CBO assumptions also include a fatal error, which is they assume [[01:02:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3726.24s)]
*  these very low levels of GDP. What you're probably going to see in Q2 is a really hot GDP print. [[01:02:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3731.52s)]
*  If I'm a betting man, which I am, I think the GDP print is going to come in above three, [[01:02:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3739.84s)]
*  not quite four, but above three. And so what Peter is saying here is, hey, guys, you're estimating [[01:02:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3744.08s)]
*  1.7% GDP. Why don't you assume 2.2? Or why don't you assume 2.7? Or any number? Or really, what he's [[01:02:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3750.16s)]
*  saying is, why don't you build a sensitivity so that you can see the implications of that? [[01:02:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3758.08s)]
*  And I think that that is a very important point. Okay, so where do I net out a week later, Jason? [[01:02:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3762.64s)]
*  It's pretty much summarized in the tweet that I posted earlier today. So over the last week, [[01:02:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3768.88s)]
*  as people have digested it, I think that there are small actors in this play and big actors. [[01:02:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3776.4s)]
*  The biggest actor is obviously President Trump, but the second biggest actor is the long end of [[01:03:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3781.84s)]
*  the bond market. These are the central bankers, the long bond holders, and these macro hedge funds. [[01:03:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3786.0s)]
*  Why? Because they will ultimately determine the United States' cost of capital. How expensive [[01:03:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3791.44s)]
*  will it be to finance our deficits, irrespective of whatever the number is? It could be a dollar [[01:03:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3797.68s)]
*  or it could be a trillion dollars. That doesn't matter right now. The point is, what is going [[01:03:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3802.96s)]
*  to be our cost of capital? And what's happened over the last little while is that they've [[01:03:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3806.32s)]
*  steepened the curve and they've made it more expensive for us to borrow money. That's just [[01:03:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3812.32s)]
*  the fact. So how do we get in front of this? I think the most important thing, if you think [[01:03:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3817.36s)]
*  about what Peter Navarro said is, this plan and the bill can work if we get the GDP right. [[01:03:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3824.7200000000003s)]
*  So how do you get the GDP right? And this is where I have one very narrow set of things that I think [[01:03:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3834.56s)]
*  we need to improve. And the specific thing that I'll go back to is today, America is at a supply [[01:04:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3841.28s)]
*  demand trade-off on the energy side. What does that mean? We literally consume every single [[01:04:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3847.84s)]
*  bit of energy that we make. We don't have slack in the system. We are growing our energy demands [[01:04:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3854.4s)]
*  on average about 3% a year. So I think the most critical thing we need to do is to make sure the [[01:04:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3862.96s)]
*  energy markets stay robust. Meaning there's a lot of investment that people are making. [[01:04:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3871.04s)]
*  On Tuesday, I announced a deal that I did building a one gigawatt data center in Arizona. [[01:04:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3878.56s)]
*  This is a lot of money. This is little old me, but there are lots of people ripping in huge, [[01:04:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3883.84s)]
*  huge, huge checks, hundreds of billions of dollars. I think the sole focus has to be to make sure that [[01:04:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3887.68s)]
*  the energy policy of America is robust and it keeps all the electrons online. If there's any [[01:04:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3893.28s)]
*  contraction, I think it'll hit the GDP number because we won't have the energy we need. And [[01:05:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3900.32s)]
*  that's where things start to get a little funky. So I think where I am is I think President Trump [[01:05:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3906.0800000000004s)]
*  should get what he wants. I think the bill can work, narrowly address the energy provisions, [[01:05:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3910.6400000000003s)]
*  and I think we live to fight another day. So Friedberg, cynical approach might be, [[01:05:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3916.56s)]
*  we're working the refs here. The CBO is not taking into GDP. This GDP has a magical unicorn in it. [[01:05:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3921.44s)]
*  AI and energy is going to spur this amazing growth, but the bond markets don't believe it either. [[01:05:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3928.64s)]
*  So are we looking at just a GOP, a party, I'll put the administration aside, that is just as [[01:05:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3935.2s)]
*  recklessly spending as the Democrats and they want to change the formula by which they're judged [[01:05:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3943.6s)]
*  in the future that there's going to be magically all this growth and growth solves all problems. [[01:05:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3949.2799999999997s)]
*  And what we really need to do, to your point, I think two weeks ago, that this is just disgraceful [[01:05:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3953.92s)]
*  to put up this much spending and we have to have austerity and we need to increase maybe the [[01:06:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3960.08s)]
*  discipline in the country and both parties have to be part of that. I'm asking you from the cynical [[01:06:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3965.36s)]
*  perspective, maybe to represent or still me on the other side here. We had a conversation with [[01:06:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3970.1600000000003s)]
*  Senator Ron Johnson after we recorded the pod last week and he was very clear in a key point, [[01:06:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3976.08s)]
*  which is that this bill addresses mandatory spending. Just to give you a sense, 70% of [[01:06:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3984.08s)]
*  our federal budget is mandatory spending. 30% falls into that discretionary category. [[01:06:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3991.52s)]
*  The mandatory spending is composed of the interest on the debt, which is now well over a trillion [[01:06:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=3996.24s)]
*  dollars a year on its way to a trillion five, almost a trillion a year, Medicare, Medicaid, [[01:06:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4001.68s)]
*  social security, and some other income security programs. And as Ron Johnson shared with us, [[01:06:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4006.72s)]
*  over the years, more and more programs have been put into the mandatory spending category. [[01:06:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4013.04s)]
*  And so you can get past the filibustering in the Senate to be able to get budget adjustments done. [[01:06:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4017.68s)]
*  The key thing he's focused on and Rand Paul is focused on, and I've talked about, is the spending [[01:07:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4023.8399999999997s)]
*  level of our mandatory programs. The big, beautiful bill proposes a roughly $70 billion per year cut [[01:07:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4029.12s)]
*  in Medicaid. Okay. And that sounds awful. How could you do that to people in 2019, the year before [[01:07:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4036.7999999999997s)]
*  COVID Medicaid spending was $627 billion. 2024 it was 914 billion. So the $70 billion cut gets you [[01:07:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4043.68s)]
*  down to 840. You're still roughly call it 40% above where you were in 2019. So is that the [[01:07:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4053.2799999999997s)]
*  right level? And fundamentally the opportunity to cut those mandatory programs, which I know [[01:07:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4058.8s)]
*  sounds awful to cut social security and cut Medicaid, but the reality is they're not just [[01:07:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4065.2000000000003s)]
*  being cut from a low level. They're being cut from a level that's 60 plus percent higher than they were [[01:07:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4069.2000000000003s)]
*  in 2019. I gave you another example, which is the snap program, the food stamp program. [[01:07:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4077.04s)]
*  Again, $15 billion of the 120 a year that we spend on food stamps is being used to buy soda. [[01:08:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4081.6800000000003s)]
*  And a whole nother chunk of that 120 is being used to buy other junk food. [[01:08:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4088.56s)]
*  So they have proposed in this bill to cut snap down to 90. And it was 60 in 2019. So it's still [[01:08:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4092.6400000000003s)]
*  50% above where it was in 2019. So the key point that's being made by Ron Johnson and others [[01:08:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4099.360000000001s)]
*  is that the spending on these mandatory programs, which account for nearly three quarters of our [[01:08:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4105.92s)]
*  federal budget are still very elevated relative to where we were in 2019. And we are not going [[01:08:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4110.8s)]
*  to get out of our deficit barring a massive increase in GDP without changes to the spending [[01:08:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4116.72s)]
*  level. Now I don't put the blame on the White House. This bill passed with one vote in the House, [[01:08:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4122.240000000001s)]
*  one vote. And so a key point to note, and I've said this from day one, and every time I've gone [[01:08:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4128.400000000001s)]
*  to DC and every time we've talked about Doge, I've said there's no way any of this stuff's [[01:08:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4134.8s)]
*  going to change without legislative action from the Congress. And here we are seeing Congress, [[01:08:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4138.400000000001s)]
*  for whatever reason, you can listen to Ron Johnson, you can listen to Rand Paul, you can [[01:09:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4143.92s)]
*  listen to others say, you know what, we can't cut that deep, it is going to be too harmful to our [[01:09:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4146.88s)]
*  constituents. We need to keep the programs at their current levels, or make no changes at all, [[01:09:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4152.16s)]
*  or only modest changes. And that's where we are. That's the reality. Now I do think that Navarro [[01:09:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4158.0s)]
*  did an excellent job in his op ed for whatever criticism we may want to lay on Navarro for many [[01:09:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4163.84s)]
*  other things. He pointed out that the CBO projections in 2017 for the next year's GDP [[01:09:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4168.56s)]
*  growth numbers was 1.8 to 2%. And it actually came in at 2.9%, a full one point higher because of the [[01:09:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4175.120000000001s)]
*  Tax and Jobs Act that was passed by the Trump administration in 2017. So the additional money [[01:09:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4181.68s)]
*  that goes into investments because lower taxes are being paid fueled GDP growth. This is what some [[01:09:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4187.4400000000005s)]
*  people call trickle down economics. People ridicule it, they say it doesn't work, it's not real. But in [[01:09:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4193.200000000001s)]
*  this particular instance, they cut taxes and the GDP grew much faster than was projected or estimated [[01:09:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4198.08s)]
*  by the economists at the CBO. So the argument that's being made is that we are not capturing [[01:10:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4204.08s)]
*  many of the upsides in the GDP numbers that are being projected. And I will be honest about this, [[01:10:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4210.64s)]
*  I don't think anyone knows how much the GDP is going to grow. We don't know the economic benefit [[01:10:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4216.4s)]
*  and effects of AI. We don't know the economic benefits and effects of the work that's being [[01:10:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4222.96s)]
*  done to deregulate. Another key point, which is not talked about by Navarro or anywhere else, [[01:10:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4229.84s)]
*  there's a broad effort to deregulate standing up new energy systems, deregulate industry and pharma, [[01:10:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4234.72s)]
*  deregulate banking. Besant talked about this in our interview with him. [[01:10:42](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4242.72s)]
*  All of those deregulatory actions theoretically should drive more investment dollars because if [[01:10:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4246.08s)]
*  you can get a biotech drug to market in five years instead of 10, you'll invest more in developing [[01:10:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4252.08s)]
*  new biotech drugs. If you can stand up a new nuclear reactor in seven years instead of 30, [[01:10:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4256.08s)]
*  you'll build more nuclear reactors, money will flow. If you can get a new factory working, [[01:11:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4261.2s)]
*  because it's a lot easier and faster to build the factory and cheaper, you'll build more factories [[01:11:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4267.6s)]
*  and production will go up. People were really taken by the way by your comment that you would [[01:11:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4272.16s)]
*  shut up about the deficit if we had a really great energy policy. We were dumping a lot on top of it. [[01:11:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4276.32s)]
*  I want to build on the point that both Jamatha and Friedberg made about growth rates. [[01:11:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4283.5199999999995s)]
*  There's a very important chart here from Fred. This is the Federal Reserve of St. Louis. This [[01:11:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4287.599999999999s)]
*  is federal receipts. Basically, it's federal tax revenue as a percent of GDP. This goes all the [[01:11:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4291.759999999999s)]
*  way back to the 1930s, 1940s. If you look in the post-World War II period, you can see, [[01:11:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4298.72s)]
*  just eyeballing it, that there's a lot of variation around this, but the line is around 17.5% [[01:11:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4305.84s)]
*  plus or minus 2%. The interesting thing is that this chart reflects radically different tax rates. [[01:11:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4312.400000000001s)]
*  For example, during some of these periods, we've had 90% top marginal tax rates. We've had 70% [[01:12:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4321.84s)]
*  top marginal tax rates. Under Jimmy Carter, the top marginal tax rate was, I think, 70%. [[01:12:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4329.04s)]
*  We've had tax rates under Reagan or Clinton in the 20s. The point is that the tax rate that you [[01:12:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4336.08s)]
*  have and what you actually collect as a percentage of GDP don't correlate. The most important thing [[01:12:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4344.32s)]
*  by far is just how the economy is doing. If you look at the top tick, it's around 2000 there. If [[01:12:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4350.24s)]
*  you just mouse over it- 1999 to 2000, yeah. Yeah, we get just under 20% of federal receipts as a [[01:12:35](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4355.36s)]
*  percent of GDP. Tax rates were quite low back then. The reason why is we had an economic boom. [[01:12:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4361.36s)]
*  The point is, the most important thing in terms of tax revenue is having a good economy. This is why [[01:12:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4367.599999999999s)]
*  you don't just want to have very high tax rates because they clobber your economy. This point [[01:12:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4374.08s)]
*  that Navarro was making in that article, it actually makes sense. 1.7% is a pretty tepid [[01:12:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4378.72s)]
*  growth assumption. We should be able to grow a lot faster. If we have a favorable tax policy, [[01:13:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4385.12s)]
*  you can grow a lot faster. Now, if you go to spending, can you pull up the Fred chart on [[01:13:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4390.4800000000005s)]
*  spending? What you see here is that it's been going up, but let's say that since the mid-1970s [[01:13:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4394.88s)]
*  or so, federal net outlays as a percent of GDP. Basically, spending was around 20% of GDP. [[01:13:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4401.52s)]
*  Then what happened is during COVID, it went crazy. It went all the way up to 30%. Now, [[01:13:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4408.320000000001s)]
*  it's back down to low 20s, but it's still not back down to 20. What we need to do is grow [[01:13:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4412.0s)]
*  the economy. We have to grow GDP to the point where federal net outlays are back around 20%. [[01:13:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4420.4800000000005s)]
*  If you could get tax revenue to the historical mean of around 17.5% or 17%, you get spending to 20%, [[01:13:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4426.240000000001s)]
*  then you have a budget deficit of 3%, which is much more tolerable. I think that's best [[01:13:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4433.52s)]
*  target under his 333 plan, right? As you get GDP growth back up to 3% and you get the budget [[01:13:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4437.5199999999995s)]
*  deficit down to 3%. All right, Chamath, you had some charts you wanted to share. [[01:14:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4444.0s)]
*  Well, I think what's amazing is if you take last week and now again this week, [[01:14:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4448.96s)]
*  we're all converging on the same thing. The path out of this is through GDP growth. [[01:14:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4454.4s)]
*  And I just want everybody to understand where we are. And this is without judgment. This is just [[01:14:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4462.879999999999s)]
*  the facts. What this chart shows in gray is the total supply of power in the United States. And [[01:14:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4469.759999999999s)]
*  the blue line is the utilization. So what you build for is what you think is a premium above [[01:14:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4479.36s)]
*  the demand, right? You'd say if there's one unit of demand, let's have 1.2 units of supply, [[01:14:49](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4489.76s)]
*  we'll be okay. But as it turns out historically in the United States, we've had these cycles where [[01:14:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4494.400000000001s)]
*  we didn't really know what the demand curve would look like. And so over the last number of years, [[01:15:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4501.68s)]
*  we've stopped really building supply in power. But what happened with things like AI and all of these [[01:15:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4508.0s)]
*  other things is that the demand just continued to spike. And so what this chart shows is we are at [[01:15:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4516.08s)]
*  a standstill sitting here today in 2025. On margin, we're actually short power, which is to say, [[01:15:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4521.6s)]
*  sometimes there are brownouts, sometimes there's lack of power, because we didn't add enough [[01:15:29](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4529.68s)]
*  capacity. So that's where we are today. So then we talk about all of these new kinds of energy. [[01:15:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4534.96s)]
*  And this is just meant to ground us in the facts. If you tried to turn on a project today, [[01:15:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4540.24s)]
*  sitting here in May of 2025, here's what the timelines are. We all talk about SMRs, [[01:15:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4548.32s)]
*  small modular reactors. The reality is that if you get everything permitted, and you believe [[01:15:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4556.88s)]
*  the technology can be de-risked, you're still in a 2035 plus timeframe, you're a decade away. [[01:16:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4563.92s)]
*  If you have an unplanned Nat gas plant today, the fastest you could get that on is four years from [[01:16:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4570.719999999999s)]
*  now. If we tried to restart a mothballed nuclear reactor, of which there are only three we can [[01:16:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4576.719999999999s)]
*  restart, that's a 2027 to 2030 timeframe. So let's give us the benefit of the doubt. That's two years [[01:16:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4584.08s)]
*  away. If we needed a planned Nat gas plant, there's already 24 gigawatts in the queue, [[01:16:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4590.639999999999s)]
*  which can't get turned on. So where does this end up? And this is where I think we need to strip [[01:16:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4597.6s)]
*  away all the partisanship and understand what we're dealing with. We have ready supply of renewable [[01:16:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4603.2s)]
*  and storage options today. It's the fastest thing that you can turn on. It allows us to turn on [[01:16:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4610.96s)]
*  supply to meet the demand and utilization. So I just think it's important to understand that we [[01:16:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4618.64s)]
*  must not lose energy. We cannot lose the energy market because that is the critical driver of [[01:17:04](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4624.64s)]
*  all the GDP. All right, Nippon Steel and the U.S. Steel merger got cleared by President Trump. [[01:17:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4630.240000000001s)]
*  This was something that was being blocked by Biden, obviously, for national security reasons. [[01:17:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4635.68s)]
*  Nippon is going to acquire your steel for 14.9 billion. Biden blocked that, as we had discussed. [[01:17:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4640.88s)]
*  On Friday, Trump cleared the deal to go through calling it a partnership that will create 70,000 [[01:17:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4645.92s)]
*  jobs in the U.S. And on Sunday, Trump called the deal an investment saying it's a partial [[01:17:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4650.16s)]
*  ownership, but it will be controlled by the USA. Tramop, there seems to be a reframing of this deal [[01:17:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4654.8s)]
*  and that the United States is going to benefit from it, but it's not a sale. [[01:17:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4661.28s)]
*  Let's set some context. The United States is always on the wrong side of these deals. [[01:17:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4664.72s)]
*  Okay. We've been on the wrong side for 20 years, meaning we show up when an asset is stranded or [[01:17:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4670.24s)]
*  completely run into the ground. For example, we did the auto bailouts at the end of the [[01:17:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4676.4s)]
*  great financial crisis. If it's not a company and there's toxic assets, we set up something [[01:18:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4682.32s)]
*  called TARP. What do we get? Not much in return. In this, it's the opposite. And I think that this [[01:18:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4687.36s)]
*  strategy has worked for many other countries really well. So if you look at Brazil, companies [[01:18:14](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4694.96s)]
*  like Embraer and Vale, which are really big Brazilian national champions, have a partnership, [[01:18:22](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4702.32s)]
*  a pretty tight coupling with the Brazilian government. The Brazilians have a golden vote. [[01:18:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4707.36s)]
*  If you look inside of the UK, there's a bunch of aerospace and defense companies, including Rolls [[01:18:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4711.2s)]
*  Royce, that have a very tight coupling with the UK government, they have a golden vote. If you look [[01:18:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4716.32s)]
*  in China, companies like ByteDance and CATL have a very tight coupling with the Chinese government [[01:18:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4721.84s)]
*  and the Chinese government has a golden vote. And so what are all of those deals? Those deals are [[01:18:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4730.08s)]
*  about companies that are thriving and on the forward foot. And so I think this is a really [[01:18:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4736.4800000000005s)]
*  important example of things that we need to copy. I've said this before, but one part of China that [[01:19:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4741.360000000001s)]
*  I think we need to pay very close attention to is Hu Jintao in 2003 laid out a plan and he said, [[01:19:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4746.320000000001s)]
*  we are going to create 10 national champions in China, in all the critical industries that are [[01:19:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4753.04s)]
*  going to matter for the next 50 years, including things like batteries and rare earths and AI. [[01:19:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4758.4s)]
*  And they did it. But for those companies that allowed them to thrive and crush it. And I think [[01:19:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4763.76s)]
*  that we need to do that and compete with those folks on an equal playing field. So- [[01:19:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4768.96s)]
*  In all industries or in very specific strategic ones? Because that would seem like- [[01:19:33](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4773.36s)]
*  There's clearly- [[01:19:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4778.0s)]
*  Corrupting capitalism and free markets would be the steel man. [[01:19:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4778.4s)]
*  Yeah. There's 10 industries that matter. [[01:19:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4781.599999999999s)]
*  And you could probably- Give us some of them. Steel is one, okay. [[01:19:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4783.92s)]
*  I think the precursors for pharmaceuticals are absolutely critical. [[01:19:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4786.32s)]
*  Got it. [[01:19:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4792.4s)]
*  I think AI is absolutely critical. I think the upstream lithography and EV deposition [[01:19:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4792.8s)]
*  and chip making capability, absolutely critical. I think batteries are absolutely critical. And I [[01:19:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4798.8s)]
*  think rare earths and the specialty chemical supply chain, absolutely critical. If you have those five, [[01:20:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4805.5199999999995s)]
*  you are in control of your own destiny in the sense that you can keep your citizens healthy, [[01:20:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4812.96s)]
*  and you can make all the stuff for the future. So I think if the president is creating a more [[01:20:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4818.08s)]
*  expansive idea beyond US deal with this idea of US support, maybe there'll be preferred capital [[01:20:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4824.799999999999s)]
*  in the future to US deal. But if he creates a category by category thing across five or six of [[01:20:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4831.12s)]
*  these critical areas of the future, I think it's super smart and we should do more of it. [[01:20:37](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4837.12s)]
*  Sax, what do you think? Interventionism, putting your thumb on the scale, golden votes, [[01:20:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4843.04s)]
*  a good idea for America in very narrow verticals or let the free market decide? What are your [[01:20:46](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4846.88s)]
*  thoughts on this golden vote, having a board seat, et cetera? [[01:20:52](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4852.799999999999s)]
*  Well, it depends what the free market, so to speak, produced. And the reality is over the [[01:20:56](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4856.799999999999s)]
*  past 25 years is we exported a lot of this manufacturing capacity to China. And I don't [[01:21:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4861.679999999999s)]
*  think it was a free market because they had all these advantages under the WTO that we talked [[01:21:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4867.04s)]
*  about in a previous podcast. They were able to subsidize their national champions while [[01:21:10](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4870.8s)]
*  still remaining compliant with the WTO rules because supposedly they were a developing [[01:21:16](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4876.64s)]
*  country. It was totally unfair. And what they would do is through these subsidies, [[01:21:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4879.92s)]
*  they would allow these national champions to essentially dump their products in the global [[01:21:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4884.56s)]
*  market and drive everyone else out of business. They became the low cost producers. [[01:21:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4888.96s)]
*  I think that as the president just said recently, not every industry has to be treated as strategic. [[01:21:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4892.88s)]
*  Clothes and toys, we don't necessarily have to reshore in the United States, but steel production [[01:21:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4898.56s)]
*  is definitely strategic. Steel, aluminum, and I'd say the rare earths, we have to have that [[01:21:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4903.52s)]
*  capacity. We cannot be completely dependent on China for our supply chain. So some of these [[01:21:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4908.72s)]
*  industries have to be reshored. And if you need subsidies to do it, I think that you do it for [[01:21:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4913.360000000001s)]
*  national security reasons first and foremost. There are other industries where the private [[01:21:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4918.08s)]
*  market works just fine. And what we need to do to help those companies is simply not get in their [[01:22:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4923.92s)]
*  way with unnecessary red tape and regulations. So I would say empower the free market when [[01:22:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4928.72s)]
*  America is the winner. And then in other areas where they're necessary for national security, [[01:22:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4935.28s)]
*  then you have to be willing to basically protect our industries. [[01:22:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4941.36s)]
*  Aaron Norris Freeberg, it seems like the great innovation here might also be the American [[01:22:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4944.24s)]
*  public getting upside when we gave loans to [[01:22:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4948.48s)]
*  Solyntra and Tesla and Fisker and a bunch of people for battery powered energy under Obama. [[01:22:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4952.639999999999s)]
*  We just got paid back in some cases by Elon, other people defaulted, but we didn't get equity. [[01:22:39](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4959.04s)]
*  What if we had instead of getting our 500 million back in the loan from Elon, which he paid back [[01:22:44](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4964.32s)]
*  early and with interest, if we got half back and we got half in equity, RSUs, whatever, stock [[01:22:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4968.879999999999s)]
*  options warrants, this would be an incredible innovation. So what are your thoughts here? [[01:22:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4974.08s)]
*  Because people look to this podcast as, hey, the free market podcast, but this does seem to be a [[01:22:57](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4977.76s)]
*  notable exception here of maybe we should get involved and do these golden, you know, share [[01:23:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4983.2s)]
*  votes, board seats, you know, maybe more creative structures in order to win faster. What are your [[01:23:09](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4989.84s)]
*  thoughts, Freeberg? I don't like it. I don't like the government [[01:23:17](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=4997.68s)]
*  in markets. Keep the government out of the markets. It creates a slippery slope. First of all, [[01:23:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5001.12s)]
*  I think markets don't operate well. If government's involved, it gets inefficient [[01:23:26](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5006.64s)]
*  and that hurts consumers. It hurts productivity. It hurts the economy. Second, I think it's a [[01:23:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5011.04s)]
*  slippery slope. You do one thing now. If government non-intervention results in [[01:23:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5016.320000000001s)]
*  all of the steel production moving offshore, if it results in all the rare earth processing [[01:23:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5021.92s)]
*  and the rare earth magnet casting industries moving offshore, in fact, not just moving offshore, [[01:23:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5028.56s)]
*  but moving to an adversarial nation such that they can just switch off our supply chain for [[01:23:55](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5035.28s)]
*  pretty much every electric motor. Is that an outcome of the quote unquote free market that [[01:24:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5042.32s)]
*  we should accept? Well, then I think that's where the government can play a role in trade deals [[01:24:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5046.719999999999s)]
*  to manage that effect. So you can create incentives that'll drive [[01:24:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5051.679999999999s)]
*  onshore manufacturing by increasing the tariff or restricting trade with foreign countries so that [[01:24:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5055.12s)]
*  there isn't a cheaper alternative, which is obviously one of the plays that this Trump [[01:24:21](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5061.68s)]
*  administration's trying to do. I'd rather have that mechanism than the government making actual [[01:24:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5065.04s)]
*  market-based decisions and business decisions. You know how inefficient government runs. You know how [[01:24:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5070.400000000001s)]
*  difficult it is to assume that that bureaucracy is actually ever going to act and pick any best [[01:24:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5074.56s)]
*  interest or any good interest at all. They're just going to get all up. So I'd rather keep the [[01:24:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5078.88s)]
*  government entirely out of the market, create a trade incentive where the trade incentive basically [[01:24:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5083.360000000001s)]
*  will drive private markets, private capital to build that industry onshore here because there [[01:24:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5087.84s)]
*  isn't one and there's demand for it because you've restricted access to the foreign market. That I [[01:24:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5093.76s)]
*  think would be the best general solution, Sachs. And then I think it's a slippery slope because [[01:24:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5098.4800000000005s)]
*  then you could always rationalize something being strategic, something being security interests in [[01:25:01](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5101.92s)]
*  the United States. So then every industry suddenly gets government intervention and [[01:25:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5105.52s)]
*  government involvement. And then the third thing is I don't want the government making money [[01:25:08](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5108.88s)]
*  that the Congress then says, hey, we've got more money. We've got more revenue. Let's spend more [[01:25:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5112.56s)]
*  money because then they'll create a bunch of waste and nonsense that'll arise from having [[01:25:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5115.76s)]
*  increased revenue. One side, and I will say one thing where I do think we do a poor job, [[01:25:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5120.4800000000005s)]
*  is we don't do a good job to answer your question, J Cal, of investing the retirement funds that [[01:25:25](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5125.84s)]
*  we've mandated through social security. We should be taking the four and a half trillion dollars [[01:25:30](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5130.400000000001s)]
*  that our social security beneficiaries have had deducted from their paychecks over many, many years. [[01:25:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5134.400000000001s)]
*  And those social security future retirees or current retirees are getting completely ripped [[01:25:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5140.0s)]
*  off because their money is being loaned to the federal government. It's not being invested. [[01:25:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5145.28s)]
*  It's been loaned to the government to spend money and run a deficit and ultimately inflate away the [[01:25:48](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5148.719999999999s)]
*  value of the dollar. We should have been investing those dollars in some of these strategic assets. [[01:25:53](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5153.12s)]
*  So if ever there were to be shares or investment that the government does, it should be done [[01:25:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5158.32s)]
*  through strategic investing through the Social Security or Retirement Program, similar, by the [[01:26:02](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5162.5599999999995s)]
*  way, to what's done in Australia, where these supers have created an extraordinary surplus [[01:26:06](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5166.719999999999s)]
*  of capital, same in Norway, same in the Middle East countries, incredible sovereign wealth funds [[01:26:13](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5173.36s)]
*  that benefit the retirees and the population at large. That's where the dollars should be [[01:26:19](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5179.04s)]
*  invested from. I do think the fundamental focus priority right now should be reforming social [[01:26:23](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5183.04s)]
*  security while we still have the chance. We have until 2032 when social security will be [[01:26:27](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5187.92s)]
*  functionally bankrupt and everyone's going to get overtaxed and kids are going to end up having to [[01:26:32](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5192.719999999999s)]
*  pay through inflation for the benefits of the retirees of the last generation. [[01:26:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5196.719999999999s)]
*  Friedberg's right. We're on a seven year shock clock to when social security is not funded. [[01:26:41](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5201.5199999999995s)]
*  And by the way, this opportunity to fix mandatory spending, it was an opportunity to introduce some [[01:26:45](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5205.759999999999s)]
*  structural reform in social security. Another reason why I think that there is a degree of [[01:26:50](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5210.16s)]
*  disgracia in this bill, particularly with how Congress had acted and not addressing what is [[01:26:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5214.24s)]
*  becoming a critical issue because everyone wants to get reelected in the next 12 months, 18 months. [[01:26:58](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5218.879999999999s)]
*  They've got elections coming up. So everyone's scrambling to not mess with that because you [[01:27:03](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5223.44s)]
*  can't touch it. It's like, you know what, guys, this is bankrupt in seven years. It's going to [[01:27:07](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5227.12s)]
*  cost us five, 10 times as much when we have to deal with it. When everyone runs out of money, [[01:27:11](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5231.36s)]
*  deal with it now. Fix the problem. And by the way, we should flip all that money, four and a half [[01:27:15](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5235.92s)]
*  trillion dollars into an investment account for the retirees where they can own equities and they [[01:27:20](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5240.0s)]
*  can make investments in the markets and they can participate in the upside of American industry and [[01:27:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5244.88s)]
*  the GDP growth that's coming. Instead, they're getting paid 3.8% or four and a half percent [[01:27:28](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5248.96s)]
*  average from treasuries that they own that by the way are now have a lower credit rating than [[01:27:34](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5254.16s)]
*  they've ever had. You know, it's crazy. I'm in complete agreement with you. And I think [[01:27:38](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5258.5599999999995s)]
*  it's a lack of leadership on Trump's part. If Trump is going to criticize Taylor Swift and [[01:27:43](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5263.28s)]
*  Zelensky and Putin and everybody, you know, all day long on truth social, he can criticize Congress [[01:27:47](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5267.5199999999995s)]
*  and the Democrats and the Republicans on not cutting spending. I think he should speak up. [[01:27:54](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5274.08s)]
*  I think he was elected to do that. It was a big part of the mandate. And he should tone down the [[01:28:00](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5280.32s)]
*  tariff chaos and tone up the and lean into intelligent immigration, you know, recruiting [[01:28:05](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5285.36s)]
*  great talent to this country. And he should be pushing to make these bills control spending. [[01:28:12](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5292.96s)]
*  That's just one person's belief for the chairman dictator to mouth by hapitya, your czar, David [[01:28:18](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5298.639999999999s)]
*  Sachs, and that Chris Brioni white shirt, very beautiful. And the Sultan of science deep in his [[01:28:24](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5304.0s)]
*  Wally era. I am the world's greatest moderator and as freeburg will tell you executive producer [[01:28:31](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5311.04s)]
*  for life here at the all in pockets. We'll see you all next time. Bye bye, Jason, at all in love, [[01:28:36](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5316.56s)]
*  you boys. [[01:28:40](https://www.youtube.com/watch?v=O_AfZ6J0ToE&t=5320.24s)]
