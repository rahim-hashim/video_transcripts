---
Date Generated: January 10, 2025
Transcription Model: whisper medium 20231117
Length: 5749s
Video Keywords: ['chamath', 'david sacks', 'david friedberg', 'jason calacanis', 'all in podcast', 'tech', 'news', 'politics', 'big tech', 'antitrust', 'election', 'covid', 'quarantine', 'stocks', 'stock market', 'tech stocks', 'palihapitiya', 'government']
Video Views: 498239
Video Rating: None
Video Description: (0:00) Bestie intros: In Memoriam
(6:43) OpenAI's $150B valuation: bull and bear cases
(24:46) Will AI hurt or help SaaS incumbents?
(40:41) Implications from OpenAI's for-profit conversion
(49:57) Meta's impressive new AR glasses: is this the killer product for the age of AI?
(1:09:05) Blue collar boom: trades are becoming more popular as entry-level tech jobs dry up
(1:20:55) Risk of nuclear war increasing

Follow the besties: 
https://x.com/chamath
https://x.com/Jason
https://x.com/DavidSacks
https://x.com/friedberg

Follow on X:
https://x.com/theallinpod

Follow on Instagram:
https://www.instagram.com/theallinpod

Follow on TikTok:
https://www.tiktok.com/@theallinpod

Follow on LinkedIn: 
https://www.linkedin.com/company/allinpod

Intro Music Credit:
https://rb.gy/tppkzl
https://x.com/yung_spielburg

Intro Video Credit:
https://x.com/TheZachEffect

Referenced in the show:
https://www.reuters.com/technology/artificial-intelligence/openais-stunning-150-billion-valuation-hinges-upending-corporate-structure-2024-09-14/
https://www.bloomberg.com/news/articles/2024-09-25/openai-cto-mira-murati-says-she-will-leave-the-company
https://x.com/chiefaioffice
https://openai.com/our-structure
https://x.com/unusual_whales/status/1658664383717978112
https://x.com/elonmusk/status/1839121268521492975
https://www.politico.com/news/2024/08/26/zuckerberg-meta-white-house-pressure-00176399
https://appleinsider.com/articles/12/12/28/early-apple-prototypes-by-frog-designs-hartmut-esslinger-featured-in-upcoming-book
https://www.cnbc.com/2024/09/16/the-toolbelt-generation-why-teens-are-losing-faith-in-college.html
https://www.wsj.com/tech/tech-jobs-artificial-intelligence-cce22393
https://layoffs.fyi
https://educationdata.org/college-enrollment-statistics
https://www.bloomberg.com/news/articles/2024-09-20/zelenskiy-to-push-us-for-nato-invite-weapons-guarantees

#allin #tech #news
---

# OpenAI's $150B conversion, Meta's AR glasses, Blue-collar boom, Risk of nuclear war
**All In Podcast:** [September 27, 2024](https://www.youtube.com/watch?v=43Rd-y2xe84)
*  Alright everybody, let's get the show started here. [[00:00:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=0.0s)]
*  Wait, Jason, why are you wearing a tux? What's going on there? [[00:00:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2.64s)]
*  Oh, well, it's time for a very emotional segment we do here on the All In podcast. [[00:00:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5.6000000000000005s)]
*  I just got to get myself composed for this. [[00:00:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=12.32s)]
*  Jason, are you okay? [[00:00:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=16.080000000000002s)]
*  I'm going to be okay, I think. [[00:00:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=17.6s)]
*  It looks like you're fighting back a tear. [[00:00:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=19.28s)]
*  Yeah, this is always a tough one. This year, we tragically lost giants in our industry. [[00:00:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=21.6s)]
*  These individuals bravely honed their craft at OpenAI before departing. [[00:00:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=28.959999999999997s)]
*  Ilya Suskever, he left us in May. [[00:00:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=35.04s)]
*  Jan Lajka, also left in May. [[00:00:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=40.96s)]
*  John Schulman, tragically left us in August. [[00:00:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=45.599999999999994s)]
*  Wait, these are all OpenAI employees? [[00:00:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=50.56s)]
*  Yes. Zaharad Zof, left on Wednesday. [[00:00:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=52.959999999999994s)]
*  Bob McGrew, also left on Wednesday. [[00:00:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=56.48s)]
*  Too short. [[00:00:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=59.92s)]
*  Too short. [[00:01:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=60.56s)]
*  And Mira Marotti, also left us tragically on Wednesday. [[00:01:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=61.6s)]
*  You lost Mira too? [[00:01:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=66.48s)]
*  Yeah. And Greg Brockman is on extended leave. [[00:01:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=67.92s)]
*  The enforcer? He left too? [[00:01:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=71.92s)]
*  Thank you for your service. Your memories will live on as training data. [[00:01:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=74.08s)]
*  And may your memories be a vesting. [[00:01:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=80.88s)]
*  We'll let your winners ride. [[00:01:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=85.68s)]
*  Rain Man, David Sack. [[00:01:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=88.48s)]
*  And instead, we open sourced it to the fans and they've just gone crazy with it. [[00:01:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=92.80000000000001s)]
*  Love you, S.I.N.E. Queen of Kin Wands. [[00:01:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=96.64000000000001s)]
*  Sorry, guys. [[00:01:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=102.16000000000001s)]
*  Goodness, all those losses. Wow. [[00:01:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=102.72s)]
*  I know. Three in one day. [[00:01:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=105.28s)]
*  Three in one day. My goodness. I thought OpenAI was nothing without its people. [[00:01:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=107.2s)]
*  I mean, well, I mean, this is a great. Whoa, we lost them. [[00:01:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=110.88s)]
*  Whoa. What's happening? [[00:01:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=118.0s)]
*  Oh, wait, what? [[00:01:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=119.52s)]
*  Whoa. This is like the photo. [[00:02:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=121.67999999999999s)]
*  It's like the photo and back to the future. [[00:02:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=124.96s)]
*  Wow. They're just all gone. Wait. Oh, no, don't worry. He's replacing everybody. [[00:02:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=126.96s)]
*  Here we go. Let's replace it with G700, a Bugatti. [[00:02:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=129.76s)]
*  And I guess Sam's got mountains of cash. So don't worry. He's got a backup plan, Jamaz. [[00:02:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=133.35999999999999s)]
*  Anyway, as an industry and as leaders in the industry, the show sends its regards to Sam [[00:02:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=138.16s)]
*  and the OpenAI team on their tragic losses. And congratulations on the 150 billion dollar valuation [[00:02:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=143.2s)]
*  and your 7 percent. Sam now just cashed in 10 billion dollars, apparently. [[00:02:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=150.07999999999998s)]
*  So congratulations to fan of a friend of the pod, Sam Oman. [[00:02:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=154.96s)]
*  That's all repeatedly out of some article, right? That's not like [[00:02:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=159.92s)]
*  confirmed or anything. [[00:02:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=163.6s)]
*  Is all of that done? [[00:02:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=164.88s)]
*  I mean, it's reportedly allegedly that he's going to have 7 percent of the company and we can jump [[00:02:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=165.84s)]
*  right into our first story. I mean, what I'm saying is, has the money been wired in the docksman side? [[00:02:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=170.24s)]
*  According to reports, this round is contingent on not being a nonprofit anymore and sorting that all [[00:02:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=175.52s)]
*  out. They have to remove the profit cap and do the C Corp. There's some article that reported this, [[00:03:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=183.76s)]
*  right? None of us. It's Bloomberg. It's not some articles. Bloomberg and it got a lot of traction [[00:03:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=188.24s)]
*  and it was re reported by a lot of places and I don't see anyone disputing it. [[00:03:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=193.68s)]
*  So is mainstream media? [[00:03:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=198.0s)]
*  We trust the mainstream media in this case. [[00:03:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=200.24s)]
*  I think that when we could do a good bit. Yeah, that's mine. [[00:03:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=204.24s)]
*  No, I think that Bloomberg Bloomberg reported it based on obviously talks that are ongoing [[00:03:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=206.72s)]
*  with investors who have committed to this round. Yeah. And no one's disputing it. [[00:03:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=211.68s)]
*  Has anyone said it's not true? [[00:03:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=215.84s)]
*  This has been speculated for months. The $150 billion valuation raising something in the range [[00:03:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=217.2s)]
*  of six to seven billion. If you do the math on that and Bloomberg is correct that Sam Altman got [[00:03:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=226.16s)]
*  his 7 percent. I guess that would be 10 billion. The reality is you can't raise $6 billion without [[00:03:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=232.32s)]
*  probably meeting with a few dozen firms and some number of junior people in those few dozen firms [[00:03:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=237.51999999999998s)]
*  are having a conversation or two with reporters. So you can kind of see how it gets out. [[00:04:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=242.72s)]
*  All right. And before we get to our first story there about open AI, [[00:04:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=248.16s)]
*  congratulations to Chamath. Let's pull up the photo here. He was a featured guest [[00:04:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=252.56s)]
*  on the Alex Jones show. No, sorry. I'm sorry. That would be Joe Rogan. Congratulations on coming [[00:04:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=258.4s)]
*  to Austin and being on Joe Rogan. What was it like to do a three hour podcast with Joe Rogan? [[00:04:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=265.76s)]
*  It's great. I mean, I loved it. He's really awesome. He's super cool. It's good to do long [[00:04:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=272.24s)]
*  form stuff like this so that I can actually talk. Clearly is the limitation of this podcast is the [[00:04:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=278.96s)]
*  other three of us. Finally, you have found a way to make it about yourself. Somebody commented like, [[00:04:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=282.96s)]
*  oh, wow. It's like amazing to hear Chamath expand on topics without the constant eruptions. [[00:04:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=290.88s)]
*  I thought that was funny. The amount of trash talking in Rogan's YouTube comments, it's next [[00:04:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=295.44s)]
*  level. It is the wild wild west in terms of the comment section on YouTube. [[00:05:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=312.15999999999997s)]
*  Yeah. A bunch of comments asking, Jake, how, why do you call it Alex Jones? Is that because [[00:05:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=319.59999999999997s)]
*  it's just a Texas short podcast short and stout and they look similar. So it's just a, [[00:05:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=324.88s)]
*  but I mean, it looks like Alex Jones, uh, started lifting weights actually. No, they're both [[00:05:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=330.79999999999995s)]
*  the same height and yeah, both are awesome. 25 years ago doing standup. I have a photo with him [[00:05:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=336.71999999999997s)]
*  at the club. It was like a small club in San Francisco and we hung out with him afterwards. [[00:05:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=341.91999999999996s)]
*  He was just like a nobody back in the day. It was like a standup guy, right? Now he's [[00:05:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=346.64s)]
*  media, Uber star. Well, you have to go back pretty far for Joe Rogan to be a nobody. I mean, [[00:05:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=351.28s)]
*  he had a TV show for a long time and two of them. In fact, it was more like a standup comic for a [[00:05:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=356.08s)]
*  while. It was a standup comic standup comic. Yeah. Fear factor. That's right. That's what [[00:06:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=360.88s)]
*  didn't also do survivor or one of those. Like, so I think, and then the UFC, I mean, this guy's got [[00:06:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=364.96s)]
*  four, four distinct careers. UFC. Yeah. Yeah. Well, I mean, I think he got the UFC out of fear [[00:06:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=371.04s)]
*  factor and being a UFC fighter and a comedian. And there's like a famous story where like [[00:06:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=377.6s)]
*  Dana White was pursuing him and he was like, I don't know. And then Dana White's like, I'll [[00:06:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=382.8s)]
*  send a plane for you. You can bring your friends. It's like, okay, fine. I'll do it. He did it for [[00:06:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=388.16s)]
*  free. And then Dana White pursued him heavily to become the voice of the UFC. And yeah, obviously [[00:06:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=391.20000000000005s)]
*  it's grown tremendously and it's worth billions of dollars. Okay. [[00:06:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=397.76s)]
*  So how was open AI worth $150 billion? Can anyone apply? Well, why don't we get into the topic? [[00:06:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=403.68s)]
*  Should we make the bull case and the bear case? All right. Open AI, as we were just joking in the [[00:06:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=410.0s)]
*  opening segment is trying to convert into a for profit benefit corporation. That's a B Corp. It [[00:06:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=414.56s)]
*  just means I will explain B Corp later. Sam Altman is reportedly. I thought they're converting to a [[00:07:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=421.12s)]
*  C Corp. No, it's the same thing. B Corp doesn't really need a corporation is a C corporation [[00:07:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=425.92s)]
*  variant that is not a nonprofit, but the board of directors, Saks is required not only to be a [[00:07:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=431.84000000000003s)]
*  fiduciary for all shareholders, but also for the stated mission of the company. That's my understanding [[00:07:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=438.88s)]
*  of a B Corp. Am I right? Freeberg external stakeholders. Yeah. So like the environment [[00:07:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=444.8s)]
*  or society or whatever, but it all from all other kinds of legal tax factors, it's the same as a C [[00:07:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=449.91999999999996s)]
*  Corp. And it's a way to, I guess, signal to investors, the market employees that you care [[00:07:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=456.47999999999996s)]
*  about something more than just profit. So famous, most famous B Corp, I think is Tom's. Is that the [[00:07:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=463.35999999999996s)]
*  shoe company? Tom's that's a famous B Corp. Somebody will look it up here. Patagonia. Yeah. [[00:07:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=470.32s)]
*  Falls into that category. So for profit with a mission. Reuters has cited anonymous sources [[00:07:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=474.56s)]
*  close to the company that the plan is still being hashed out with lawyers and shareholders. And the [[00:08:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=480.64s)]
*  timeline is uncertain. But what's being discussed is that the nonprofit will continue to exist as a [[00:08:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=486.08s)]
*  minority shareholder in the new company. How much of a minority shareholder, I guess, is the [[00:08:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=492.88s)]
*  devil's in the detail there to the own 1% or 49% the very much discussed freeburg 100 x profit [[00:08:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=499.03999999999996s)]
*  cap for investors will be removed. That means investors like Vinod friend of the pod and Reid [[00:08:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=506.71999999999997s)]
*  Hoffman also friend of the pod could see a hundred x turn into 1000 x or more. According to the [[00:08:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=512.56s)]
*  Bloomberg report, Sam Walton is going to get his equity finally 7% that would put him at around [[00:08:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=519.28s)]
*  10.5 billion if this is all true. And opening I could be valued as high as $150 billion. [[00:08:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=524.48s)]
*  We'll get into all the shenanigans. But let's start with your question freeburg. And since you [[00:08:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=532.24s)]
*  asked it, I'm going to boomerang it back to you make the bull case for $150 150 billion valuation. [[00:08:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=537.36s)]
*  The bull case would be that the moat in the business with respect to model performance [[00:09:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=546.48s)]
*  and infrastructure gets extended with the large amount of capital that they're raising, [[00:09:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=553.1999999999999s)]
*  they aggressively deploy it, they are very strategic and tactical with respect to how [[00:09:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=558.0799999999999s)]
*  they deploy that infrastructure to continue to improve model performance and as a result, [[00:09:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=563.36s)]
*  continue to extend their advantage in both consumer and enterprise applications, [[00:09:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=568.4s)]
*  the API tools and so on that they offer. And so they can maintain both kind of model and [[00:09:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=573.52s)]
*  application performance leads that they have today across the board, I would say like the [[00:09:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=580.24s)]
*  one model, their voice application Sora has not been released publicly, but if it does, [[00:09:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=585.44s)]
*  and it looks like what it's been demoed to be, it's certainly ahead of the pack. [[00:09:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=590.88s)]
*  So there's a lot of aspects of of open AI today that kind of makes them a leader. And if they [[00:09:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=594.5600000000001s)]
*  can deploy infrastructure to maintain that lead and not let Google, Microsoft, Amazon, and others [[00:10:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=600.96s)]
*  catch up, then their ability to use that capital wisely keeps them ahead. And ultimately, as we all [[00:10:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=605.44s)]
*  know, there's a multi trillion dollar market to capture here, making lots of verticals, [[00:10:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=611.9200000000001s)]
*  lots of applications, lots of products. So they could become a true kind of global player here, [[00:10:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=615.84s)]
*  plus the extension into computing, which I'm excited to talk about later. When we get into [[00:10:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=621.2s)]
*  this computing, so sax, here's a chart of open areas, revenue growth, that has been piecemeal [[00:10:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=625.2s)]
*  together from various sources at various times. But you'll see here they are reportedly [[00:10:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=631.52s)]
*  as of June of 2024 on a $3.4 billion run rate for this year, after hitting 2 billion in 23, [[00:10:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=639.84s)]
*  1.3 billion in October of 23. And then back in 2022, which reported they only had 28 million [[00:10:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=647.68s)]
*  in revenue. So this is a pretty big shrink here in terms of revenue growth, I would put it at [[00:10:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=656.08s)]
*  50 times top line revenue, $150 billion valuation, you want to give us the bear case maybe or the [[00:11:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=662.1600000000001s)]
*  bull case? Well, so the whisper numbers I heard was that their revenue run rate for this year was in [[00:11:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=667.84s)]
*  the four to six billion range, which is a little higher than that. So you're right, if it's really [[00:11:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=673.6800000000001s)]
*  more like 3.4, this valuation is about 50 times current revenue. But if it's more like 5 billion, [[00:11:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=679.76s)]
*  then it's only 30 times. And if it's growing 100% year over year, it's only 15 times next year. [[00:11:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=686.64s)]
*  So depending what the numbers actually are, the $150 billion valuation could be warranted. I don't [[00:11:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=692.3199999999999s)]
*  think 15 times forward ARR is a high valuation for a company that has this kind of strategic [[00:11:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=698.08s)]
*  opportunity. I think it all comes down to the durability of its comparative advantage here. [[00:11:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=706.32s)]
*  I think there's no question that OpenAI is the leader of the pack. It has the most advanced AI [[00:11:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=713.44s)]
*  models, it's got the best developer ecosystem, the best APIs, it keeps rolling out new products. [[00:11:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=719.12s)]
*  And the question is just how durable that advantage is, is there really a moat to any of this? [[00:12:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=725.44s)]
*  For example, Meta just announced Lama 3.2, which can do voice. And this is roughly at the same time [[00:12:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=731.0400000000001s)]
*  that OpenAI just released its voice API. So the open source ecosystem is kind of hot on [[00:12:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=738.1600000000001s)]
*  OpenAI's heels. The large companies, Google, Microsoft, so forth, they're hot on their heels [[00:12:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=744.88s)]
*  too, although it seems like they're further behind where Meta is. And the question is just, [[00:12:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=753.0400000000001s)]
*  can OpenAI maintain its lead, can it consolidate its lead, can it develop some moats? If so, [[00:12:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=758.48s)]
*  it's on track to be the next trillion dollar big tech company. But if not, it could be eroded [[00:12:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=764.5600000000001s)]
*  and you could see the value of OpenAI get commoditized. And we'll look back on it as [[00:12:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=770.08s)]
*  kind of a cautionary tale. Okay, Chamath, do us a favor here. If there is a bear case, what is it? [[00:12:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=774.96s)]
*  Okay, let's steel man the bear case. Yes, that's what I'm asking, please. [[00:13:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=780.5600000000001s)]
*  So one would just be on the fundamental technology itself. And I think the version of that story [[00:13:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=784.3199999999999s)]
*  would go that the underlying frameworks that people are using to make these models great [[00:13:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=792.8s)]
*  is well described and available in open source. On top of that, there are at least two viable [[00:13:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=800.9599999999999s)]
*  open source models that are as good or better at any point in time than OpenAI. So what that would [[00:13:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=809.6s)]
*  mean is that the value of those models, the economic value basically goes to zero and it's [[00:13:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=818.0s)]
*  a consumer surplus for the people that use it. So that's very hard theoretically to monetize. [[00:13:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=825.04s)]
*  I think the second part of the bear case would be that specifically Meta becomes much more aggressive [[00:13:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=833.92s)]
*  in inserting Meta AI into all of the critical apps that they control because those apps really are [[00:14:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=842.72s)]
*  the front door to billions of people on a daily basis. So that would mean WhatsApp, Instagram, [[00:14:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=851.12s)]
*  Messenger, the Facebook app and threads gets refactored in a way where instead of [[00:14:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=858.4s)]
*  leaving that application to go to a chat GPT like app, you would just stay in the app. [[00:14:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=865.1999999999999s)]
*  And then the companion to that would be that Google also does the same thing with their version in [[00:14:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=872.24s)]
*  front of search. So those two big front doors to the internet become much more aggressive in [[00:14:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=881.6s)]
*  giving you a reason to not have to go to chat GPT because A, their answers are just as good and B, [[00:14:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=887.76s)]
*  they're right there in a few less clicks for you. So that would be the second piece. [[00:14:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=894.0s)]
*  The third piece is that all of these models basically run out of viable data to differentiate [[00:15:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=900.48s)]
*  themselves and it basically becomes a race around synthetic information and synthetic data, which is [[00:15:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=908.08s)]
*  a cost problem. Meaning if you're going to invent synthetic data, you're going to have to spend money [[00:15:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=914.48s)]
*  to do it. And the large companies, Facebook, Microsoft, Amazon, Google, Apple, have effectively [[00:15:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=920.16s)]
*  infinite money compared to any startup. And then the fourth, which is the most quizzical one, [[00:15:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=926.72s)]
*  is what does the human capital thing tell you about what's going on? It reads a little bit [[00:15:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=934.08s)]
*  like a telenovela. I have not in my time in Silicon Valley ever seen a company that's [[00:15:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=940.32s)]
*  supposedly on such a straight line to a rocket ship have so much high level churn. [[00:15:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=947.0400000000001s)]
*  But I've also never seen a company have this much liquidity. [[00:15:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=954.4000000000001s)]
*  And so how are people deciding to leave if they think it's going to be a trillion dollar company? [[00:15:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=959.9200000000001s)]
*  And why when things are just starting to cook, would you leave if you are technically enamored [[00:16:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=966.24s)]
*  with what you're building? So if you had to construct the bear case, I think those would be [[00:16:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=972.1600000000001s)]
*  the four things. Open source, front door competition, the move to synthetic data, and all of the [[00:16:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=976.6400000000001s)]
*  executive turnover would be sort of why you would say maybe there's a fire where there's all this smoke. [[00:16:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=984.8000000000001s)]
*  Okay, I think this is very well put. And I have been using chat GPT and Claude and Gemini [[00:16:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=991.92s)]
*  exclusively, I stopped using Google search. And I also stopped sacks asking people on my team to do [[00:16:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1000.64s)]
*  stuff before I asked chat GPT to do it specifically freebird the oh one version. And the oh one [[00:16:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1007.36s)]
*  version is distinctly different. Have you gentlemen been using oh one for like on a daily basis? [[00:16:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1014.4s)]
*  Yes, we can have a really interesting conversation here. I did something on my other podcasts this week [[00:16:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1019.84s)]
*  in startups that I'll show you right now. That was crazy yesterday. One is a great is a game changer. [[00:17:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1025.28s)]
*  Yes, it's the first real it's the first real chain of thought production system. Yes, that I think [[00:17:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1030.56s)]
*  we've seen. Are you using Oh, one preview or Oh, one mini? I am using Oh, one preview. Now let me [[00:17:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1036.64s)]
*  show you what I did here. Just just so the audience can level set here. If you're not watching us go [[00:17:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1043.2s)]
*  to YouTube and type in all in and you can you can watch us we do video here. So I was analyzing, [[00:17:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1047.6s)]
*  you know, just some early stage deals and cap tables. And I put in here, hey, a startup just [[00:17:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1055.12s)]
*  raised some money at this valuation. Here's what the friends and family invested the accelerator, [[00:17:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1060.0s)]
*  the seed investor, etc. In other words, like the history, the investment history in a company, [[00:17:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1064.9599999999998s)]
*  what Oh, one does distinctly differently than the previous versions and the previous version I felt [[00:17:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1069.6s)]
*  was three to six months ahead of competitors. This is a year ahead of competitors. And so here, [[00:17:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1074.96s)]
*  Chamath, if you look, it said it thought for 77 seconds. And if you click the down arrow, [[00:18:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1080.72s)]
*  sacks, what you'll see is, it gives you an idea of what its rationale is for interpreting and [[00:18:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1086.64s)]
*  what secondary queries it's doing. In order to give you this is called chain of thought, [[00:18:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1093.2s)]
*  and this is the underlying mega model that sits on top of the LLMs. And the mega model effectively, [[00:18:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1099.28s)]
*  the chain of thought approach is the model asks itself the question, how should I answer this [[00:18:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1106.72s)]
*  question? Right. And then it comes up with an answer. And then it says, now based on that, [[00:18:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1114.4s)]
*  what are the steps I should take to answer the question? So the model keeps asking itself [[00:18:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1118.72s)]
*  questions related to the structure of the question that you asked. And then it comes up with a [[00:18:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1123.44s)]
*  series of steps that it can then call the LLM to do to fill in the blanks, link them all together [[00:18:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1129.12s)]
*  and come up with the answer. It's the same way that a human train of thought works. And it really [[00:18:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1135.36s)]
*  is the kind of ultimate evolution of what a lot of people have said these systems need to become, [[00:18:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1139.76s)]
*  which is a much more call it intuitive approach to answering questions rather than just predictive [[00:19:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1145.36s)]
*  text based on a single statement you made. And it really is changing the game. And everyone is [[00:19:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1151.52s)]
*  going to chase this and follow this. It is the new paradigm for how these AI kind of systems will [[00:19:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1156.0s)]
*  work. And by the way, what this did was what prompt engineers were doing or prompt engineering [[00:19:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1162.64s)]
*  websites were doing, which was trying to help you construct your question. And so if you look to [[00:19:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1168.16s)]
*  this one, it says listing disparities, I'll compile a cap table with investments and valuations, [[00:19:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1172.88s)]
*  building the cap table, accessing the share evaluation, breaking down ownership, breaking [[00:19:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1178.16s)]
*  down ownership, et cetera, evaluating the terms, and then it checks its work a bit. It weights [[00:19:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1181.28s)]
*  investment options. And you can see this is a this is fired off like two dozen different queries [[00:19:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1185.6s)]
*  to as Friberg correctly pointed out, you know, build this chain. And it got incredible answers, [[00:19:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1193.6s)]
*  explain the form is so it's thinking about what your next question would be. And this when I [[00:20:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1200.8799999999999s)]
*  share this with my team, it was like a super game changer. Sachs, you had some thoughts here. [[00:20:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1206.6399999999999s)]
*  Sachs Well, yeah, I mean, this is pretty impressive. And just to build on what [[00:20:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1212.48s)]
*  Friberg was saying about chain of thought, where this all leads is to agents, where you can actually [[00:20:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1217.28s)]
*  tell the AI to do work for you, you give it an objective, it can break the objective down into [[00:20:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1222.4s)]
*  tasks, and then it can work each of those tasks. And OpenAI at a recent meeting with investors said [[00:20:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1228.8s)]
*  that PhD level reasoning was next on its roadmap. And then agents weren't far behind that. [[00:20:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1236.64s)]
*  They've now released the at least the preview of the PhD level reasoning with this one model. [[00:20:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1241.6s)]
*  So I think we can expect an announcement pretty soon about agents. Yeah. And so [[00:20:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1247.1999999999998s)]
*  that if you think about if you think about business value, we think a lot about this is like, [[00:20:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1252.08s)]
*  where's the SAS opportunity in all this, the software as a service opportunity, is going to [[00:20:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1255.6799999999998s)]
*  be an agent's I think we'll ultimately look back on these sort of chat models as a little bit of a [[00:21:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1261.4399999999998s)]
*  parlor trick compared to what agents are going to do in the workplace. If you've ever been to a call [[00:21:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1266.96s)]
*  center, or an operation center, they're also called service factories. It's assembly lines of people [[00:21:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1272.72s)]
*  doing very complicated knowledge work. But ultimately, you can unravel exactly what the [[00:21:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1278.96s)]
*  chain is there the chain of thought that goes into their decisions. It's very complicated. [[00:21:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1285.6000000000001s)]
*  That's why you have to have humans doing it. But you can imagine that once system integrators or [[00:21:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1291.52s)]
*  enterprise SAS apps go into these places, go into these companies, they integrate the data, [[00:21:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1298.8s)]
*  and then they map out the workflow, you could replace a lot of these steps in the work with [[00:21:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1304.16s)]
*  agents. Yeah, by the way, it's not just it's not just call centers. I had a conversation with [[00:21:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1309.92s)]
*  I'm on the board of the company with the CEO the other day. And he was like, well, we're going to [[00:21:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1315.8400000000001s)]
*  hire an analyst that's going to sit between our kind of retail sales operations and do the and [[00:21:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1319.84s)]
*  figure out what's working to drive marketing decisions. And I'm like, No, you're not. Like, [[00:22:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1325.6799999999998s)]
*  I really think that that would be a mistake. Because today you can use O one and describe, [[00:22:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1330.32s)]
*  just feed it the data and describe the analysis you want to get out of that data. And within a [[00:22:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1336.8799999999999s)]
*  few minutes, and I've now done this probably a dozen times in the last week with different [[00:22:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1342.0s)]
*  projects internally at my company, it gives you the entire answer that an analyst would have taken [[00:22:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1345.6s)]
*  days together for you. And if you think about what an analyst job has been historically, [[00:22:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1350.6399999999999s)]
*  is they take data, and then they manipulate it. And the big evolution in software over the last [[00:22:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1355.4399999999998s)]
*  decade and a half has been tools that give that analysts leverage to do that data manipulation [[00:22:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1360.08s)]
*  more quickly, like Tableau and, you know, are and all sorts of different toolkits that are out there. [[00:22:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1366.48s)]
*  But now you don't even need the analyst because the analyst is the chain of thought. It's the [[00:22:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1371.28s)]
*  prompting from the model. And it's completely going to change how knowledge work is done. [[00:22:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1375.52s)]
*  Everyone that owns a function no longer needs an analyst. The analyst is the model that's sitting [[00:23:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1380.8799999999999s)]
*  on the computer in front of you right now. And you tell it what you want. And not days later, [[00:23:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1386.0s)]
*  but minutes later, you get your answer. It's completely revolutionary in ad hoc knowledge [[00:23:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1390.72s)]
*  work as well as kind of this repetitive structured knowledge. This is such a good point, Freeberg, [[00:23:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1398.96s)]
*  the ad hoc piece of it. When we're processing 20,000 applications for funding a year, we do 100 [[00:23:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1403.28s)]
*  plus meetings a week, the analysts on our team are now putting in the transcripts and key questions [[00:23:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1409.44s)]
*  about markets. And they are getting so smart so fast that, you know, when somebody comes to them [[00:23:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1416.32s)]
*  with a marketplace in diamonds, their understanding of the diamond marketplace becomes so rich, so fast [[00:23:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1422.08s)]
*  that we can evaluate companies faster than we're also seeing Chamath. Before we call our lawyers, [[00:23:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1429.12s)]
*  when we have a legal question about a document, we start putting in, you know, let's say the standard [[00:23:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1436.1599999999999s)]
*  note template or the standard safe template, we put in the new one. And there's a really cool project [[00:24:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1441.04s)]
*  by Google called notebook LL, LM, where you can put in multiple documents, and you can start asking [[00:24:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1447.1999999999998s)]
*  questions. So imagine you take every single legal documents, acts that Yammer had when you had [[00:24:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1452.1599999999999s)]
*  Chamath as an investor, I'm not sure if he's on the board. And you can start asking questions [[00:24:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1457.68s)]
*  about the documents. And we have had people make changes to these documents, and it immediately [[00:24:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1461.52s)]
*  finds and explains them. And so everybody's just getting so goddamn smart, so fast using these tools [[00:24:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1466.5600000000002s)]
*  that I insisted that every person on the team when they hit Ctrl tab, it opens a chat GPT four window [[00:24:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1473.3600000000001s)]
*  in a one, and we burned out our credits immediately. Like, it stopped us and said, you're you're you're [[00:24:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1479.1200000000001s)]
*  you have to stop using it for the rest of the month. Chamath, your thoughts on this? [[00:24:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1485.12s)]
*  We're seeing it in real time. In 8090. What I'll tell you is, what SAC said is totally right. There's [[00:24:48](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1488.3999999999999s)]
*  so many companies that have very complicated processes that are a combination of well trained [[00:24:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1498.1599999999999s)]
*  and well meaning people and bad software. And what I mean by bad software is that [[00:25:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1506.16s)]
*  some other third party came in, listened to what your business process was, and then wrote this [[00:25:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1515.28s)]
*  clunky deterministic code, usually on top of some system of record, charged you 10s or 100s of [[00:25:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1520.3200000000002s)]
*  millions of dollars for it and then left and will support it only if you keep paying them millions [[00:25:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1527.92s)]
*  of dollars a year. That whole thing is so nuts because the ability for people to do work, I think, [[00:25:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1532.72s)]
*  has been very much constrained. And it's constrained by people trying to do the right thing using [[00:25:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1537.6000000000001s)]
*  really, really terrible software. And all of that will go away. The radical idea that I would put [[00:25:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1543.44s)]
*  out there is I think that systems of record no longer exist because they don't need to. [[00:25:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1549.52s)]
*  And the reason is because all you have is data and you have a pipeline of information. [[00:25:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1555.76s)]
*  Explain to people what system of record is. [[00:26:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1560.5600000000002s)]
*  So inside of a company, you'll have a handful of systems that people would say are the single [[00:26:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1562.88s)]
*  source of truth. They're the things that are used for reporting compliance. An example would be [[00:26:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1567.44s)]
*  for your general ledger. So to record your revenues, you'd use NetSuite or you'd use [[00:26:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1576.3200000000002s)]
*  Oracle GL or you'd use Workday Financials. Then you'd have a different system of record for [[00:26:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1583.3600000000001s)]
*  all of your revenue generating activities. So who are all of the people you sell to? How are sales [[00:26:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1589.52s)]
*  going? What is the pipeline? There's companies like Salesforce or Sugar CRM. Then there's a [[00:26:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1595.36s)]
*  system of record for all the employees that work for you, all the benefits they have. What is their [[00:26:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1601.52s)]
*  salary? This is HRIS. So the point is that the software economy over the last 20 years, and this [[00:26:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1606.32s)]
*  is trillions of dollars of market cap and hundreds of billions of revenue, have been built on this [[00:26:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1614.0s)]
*  premise that we will create the system of record. You will build apps on top of the system of record [[00:27:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1620.24s)]
*  and the knowledge workers will come in and that's how they will get work done. And I think that [[00:27:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1627.44s)]
*  Saks is right. This totally flips that on its head. Instead, what will happen is people will [[00:27:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1632.96s)]
*  provision an agent and roughly direct what they want the outcome to be and they'll be [[00:27:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1638.4s)]
*  process independent. They won't care how they do it. They just want the answer. [[00:27:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1644.24s)]
*  So I think two things happen. The obvious thing that happens in that world is systems of record [[00:27:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1648.3200000000002s)]
*  lose a grip on the vault that they had in terms of the data that runs a company. You don't [[00:27:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1655.52s)]
*  necessarily need it in the same reliance and primacy that you did five and ten years ago. [[00:27:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1662.88s)]
*  That'll have an impact to the software economy. And the second thing that I think is even more [[00:27:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1669.0400000000002s)]
*  important than that is that then the atomic size of companies changes because each company will get [[00:27:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1676.16s)]
*  much more leverage from using software and few people versus lots of people with a few pieces of [[00:28:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1683.5200000000002s)]
*  software. And so that inversion I think creates tremendous potential for operating leverage. [[00:28:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1688.96s)]
*  HOFFMAN All right. Your thoughts Saks, you operate in the SaaS space with System of Records and [[00:28:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1694.56s)]
*  investing in these type of companies. Give us your take. [[00:28:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1698.56s)]
*  SAKS Well, it's interesting. We were having a version of this conversation last week on the [[00:28:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1700.64s)]
*  pod and I started getting texts from Benny Alphys. He was listening to it and then he called me and [[00:28:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1706.32s)]
*  I think he got a little bit triggered by the idea that systems of record like Salesforce are going [[00:28:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1712.64s)]
*  to be obsolete in this new AI era. And he made a very compelling case to me about why that wouldn't [[00:28:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1717.92s)]
*  happen. HOFFMAN Which is? [[00:28:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1723.44s)]
*  SAKS Well, first of all, I think AI models are predictive. I mean, at the end of the day, [[00:28:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1724.48s)]
*  they're predicting the next set of texts and so forth. And when it comes to like your employee [[00:28:48](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1728.96s)]
*  list or your customer list, you just want to have a source of truth. You don't want it to be [[00:28:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1734.4s)]
*  98% accurate. You just want to be 100% accurate. You want to know if the federal government asks [[00:28:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1739.2s)]
*  you for the tax ID numbers of your employees, you just want to be able to give it to them. [[00:29:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1743.3600000000001s)]
*  If Wall Street analysts ask you for your customer list and what the gap revenue is, [[00:29:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1747.52s)]
*  you just want to be able to provide that. You don't want AI models figuring it out. So you're [[00:29:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1751.92s)]
*  still going to need a system of record. Furthermore, he made the point that you still need databases. [[00:29:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1755.92s)]
*  You still need enterprise security. If you're dealing with enterprises, you still need compliance. [[00:29:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1762.72s)]
*  You still need sharing models. There's all these aspects, all these things that have been built on [[00:29:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1766.72s)]
*  top of the database that SaaS company has been doing for 25 years. And then the final point that [[00:29:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1771.44s)]
*  I think is compelling is that enterprise customers don't want to DIY it. They don't want to have to [[00:29:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1776.24s)]
*  figure out how to put this together. And you can't just hand them an LLM and say, here you go. There's [[00:29:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1782.48s)]
*  a lot of work that is needed in order to make these models productive. And so at a minimum, [[00:29:48](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1788.96s)]
*  you're going to need system integrators and consultants to come in there, connect, hold on, [[00:29:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1796.64s)]
*  just connect all the enterprise data to these models, map the workflows. [[00:30:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1801.2s)]
*  You have to do that now. How is that different from how this clunky software is sold today? [[00:30:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1805.6s)]
*  I mean, look, I don't want to take away from the quality of the company that Mark has built and [[00:30:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1810.9599999999998s)]
*  what he's done for the cloud economy. So let's just put that aside. But I wish this is what we [[00:30:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1817.04s)]
*  could have actually all been on stage and talked about when he was at the summit. Because I disagree [[00:30:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1821.9199999999998s)]
*  with basically every premise of those three things. Number one, systems integrators exist today to [[00:30:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1828.32s)]
*  build apps on top of these things. Why do you think you have companies like Viva? How can a [[00:30:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1833.44s)]
*  20 billion dollar plus company get built on top of Salesforce? It's because it doesn't do what it's [[00:30:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1837.76s)]
*  meant to do. That's why. App stores are a great way to allow people to build on your platform and [[00:30:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1843.1200000000001s)]
*  cover those niche cases. The point I'm trying to make is that's no different than the economy [[00:30:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1852.8s)]
*  that exists today is just going to transform to different groups of people. Number one. [[00:30:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1856.88s)]
*  Well, by the way, he said he's willing to come on the pod and talk about this very issue. [[00:30:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1859.92s)]
*  But just with you? No, no, no, no, no. He'll talk to all of us now. Great. He'll come on the [[00:31:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1862.96s)]
*  pod and discuss whether AI makes SaaS obsolete. A lot of people are asking that question. [[00:31:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1869.2s)]
*  Let's talk about it next year at the summit. Can you talk about his philanthropy first? [[00:31:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1873.6000000000001s)]
*  Okay. Let's get back to focusing. Let's get focused everybody. [[00:31:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1877.6000000000001s)]
*  Love you, Mark. Who's coming to dream for us? Raise your hand. [[00:31:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1882.96s)]
*  The second point is that when you have agents, I think that we are overestimating [[00:31:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1887.6000000000001s)]
*  what a system of record is. David, what you talked about is actually just an encrypted file, [[00:31:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1892.64s)]
*  or it's a bunch of rows in some database, or it's in some data lake somewhere. You don't need to [[00:31:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1897.2s)]
*  spend tens or hundreds of millions of dollars to wrap your revenue in something that says it's a [[00:31:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1903.0400000000002s)]
*  system of record. You don't need that actually. You can just pipe that stuff directly from Stripe [[00:31:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1911.0400000000002s)]
*  into Snowflake and you can just transform it and do what you will with it and then report it. [[00:31:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1916.8000000000002s)]
*  You could do that today. It's just that- That's an interesting point. [[00:32:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1922.08s)]
*  Through steak dinners and golf outings and all this stuff, we've sold CIOs this idea that you [[00:32:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1925.12s)]
*  need to wrap it in something called a system of record. All I'm saying is when you confront the [[00:32:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1932.3999999999999s)]
*  total cost of that versus what the alternative that is clearly going to happen in the next five [[00:32:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1937.6799999999998s)]
*  or 10 years, irrespective of whether any of us build it or not, you just won't be able to justify [[00:32:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1944.0s)]
*  it. It's just going to cost a fraction of the price. [[00:32:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1950.72s)]
*  There's probably also an aspect of this that we can't predict what is going to work with respect [[00:32:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1953.6s)]
*  to data structure. Right now, all of the tooling for AI is on the front end. We haven't yet [[00:32:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1959.84s)]
*  unleashed AI on the backend, which is if you told the AI, here's all the data ingest I'm going to [[00:32:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1967.92s)]
*  be doing from all these different points in my business, figure out what you want to do with all [[00:32:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1973.68s)]
*  that data. The AI will eventually come up with its own data structure and data system. [[00:32:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1978.88s)]
*  No, that's happening. That will look nothing like- [[00:33:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1984.96s)]
*  No, no. That's already happening. [[00:33:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1987.2s)]
*  Right. That's nothing like what we have today. In the same vein that we don't understand how [[00:33:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1989.2s)]
*  the translation works in an LLM, we don't understand how a lot of the function works. [[00:33:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1993.68s)]
*  A lot of the data structure and data architecture, we won't understand clearly because it's going to [[00:33:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=1997.92s)]
*  be obfuscated by the model driving the development. There are open source agentic frameworks that [[00:33:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2001.6000000000001s)]
*  already do Freeberg what you're saying. It's not true that it's not been done. It's already- [[00:33:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2007.28s)]
*  No, no. Yeah, sure. Maybe it's being done. Right. It hasn't been fully implemented to replace the [[00:33:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2011.84s)]
*  system record. Right. There are companies, I'll give you an example of one, like Mechanical Orchard. [[00:33:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2016.48s)]
*  They'll go into the most gnarliest of environments. What they will do is they will launch these agents [[00:33:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2021.76s)]
*  that observe, it's sort of what I told you guys before, the IO stream of these apps and then [[00:33:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2027.2s)]
*  reconstruct everything in the middle automatically. I don't understand why we think that there's a [[00:33:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2032.32s)]
*  world where customer quality and NPS would not go sky high for a company that has some old legacy [[00:33:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2039.6s)]
*  Fortran system and now they can just pay Mechanical Orchard a few million bucks and they'll just [[00:34:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2045.6s)]
*  replace it in a matter of months. It's going to happen. Right. Yeah, that's the very interesting [[00:34:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2051.44s)]
*  piece for me is I'm watching startups working on this. The AI first ones, I think, are going [[00:34:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2056.16s)]
*  to come to it with a totally different cost structure. The idea of paying for seats, [[00:34:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2062.24s)]
*  and I mean, some of these seats are 5,000 per person per year. [[00:34:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2066.8799999999997s)]
*  You nailed it a year ago when you were like, oh, you mentioned some company that had flat pricing. [[00:34:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2070.3199999999997s)]
*  At first, by the way, when you said that, I thought this is nuts, but you're right. It actually makes [[00:34:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2076.0s)]
*  a ton of sense because if you have a fixed group of people who can use this tooling to basically [[00:34:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2081.8399999999997s)]
*  effectively be as productive as a company that's 10 times as big as you, [[00:34:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2089.7599999999998s)]
*  you can afford to flat price your software because you can just work backwards from what [[00:34:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2094.72s)]
*  margin structure you want and it's still meaningfully cheaper than any other alternative. [[00:34:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2099.6s)]
*  A lot of startups now are doing consumption based pricing. So they're saying, you know, how many, [[00:35:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2104.88s)]
*  how many sales calls are you doing? How many are we analyzing as opposed to how many sales [[00:35:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2111.12s)]
*  executives do you have? Because when you have agents, as we're talking about, those agents [[00:35:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2116.24s)]
*  are going to do a lot of the work. So we're going to see the number of people working at companies [[00:35:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2121.6s)]
*  become fixed. And I think the static team size that we're seeing at a lot of large companies is [[00:35:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2126.08s)]
*  only going to continue. It's going to be down into the right. And if you think you're going to get a [[00:35:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2131.8399999999997s)]
*  high paying job at a big tech company and you have to beat the agent, you're going to have to beat the [[00:35:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2135.8399999999997s)]
*  maestro who has five agents working for them. I think this is going to be a completely different [[00:35:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2141.8399999999997s)]
*  world. Chema, I want to get back to open AI with a couple of other pieces. So let's wrap this up [[00:35:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2146.3199999999997s)]
*  so we can get to the next one. Last word for you. Last word. So look, I think that on the whole, [[00:35:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2152.3199999999997s)]
*  I agree with Benioff here that there's more net new opportunity for AI companies, whether they be [[00:35:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2159.7599999999998s)]
*  startups or, you know, existing big companies like Salesforce that are trying to do AI, then there is [[00:36:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2165.6s)]
*  disruption. I think there will be some disruption. It's very hard for us to see exactly what [[00:36:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2172.24s)]
*  AI is going to look like in five or 10 years. So I don't want to discount the possibility that [[00:36:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2175.92s)]
*  there will be some disruption of existing players. But I think on the whole, there's more net new [[00:36:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2181.28s)]
*  opportunity. For example, the most highly valued public software company right now in terms of ARR [[00:36:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2185.84s)]
*  multiple is Palantir. And I think that's largely because the market perceives Palantir as having a [[00:36:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2191.52s)]
*  big AI opportunity. What is Palantir's approach? The first thing Palantir does when they go into [[00:36:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2198.2400000000002s)]
*  a customer is they integrate with all of its systems and they're dealing with the largest [[00:36:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2203.28s)]
*  enterprises. They're dealing with the government, the Pentagon, Department of Defense. The first [[00:36:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2207.6000000000004s)]
*  thing they do is go in and integrate with all of these legacy systems and they collect all of the [[00:36:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2211.6000000000004s)]
*  data in one place. They call it creating a digital twin. And once all the data is in one place with [[00:36:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2218.7200000000003s)]
*  the right permissions and safeguards, now analysts can start working it. And that was their historical [[00:37:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2224.0800000000004s)]
*  value proposition. But in addition, AI can now start working that problem. So anything that the [[00:37:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2229.2s)]
*  analysts could work, now AI is going to be able to work. And so they're in an ideal position [[00:37:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2234.72s)]
*  to master these new AI workflows. So what is the point I'm making? It's just that you can't just [[00:37:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2239.68s)]
*  throw an LLM at these large enterprises. You have to go in there and integrate with the existing [[00:37:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2245.3599999999997s)]
*  systems. It's not about ripping out the existing systems because that's just a lot of headaches [[00:37:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2250.96s)]
*  that nobody needs. It's generally an easier approach just to collect the data. [[00:37:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2255.12s)]
*  Except when the renewal comes. What happens when you have to spend a billion dollars on something [[00:37:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2259.04s)]
*  and then you're going to renegotiate it? You're going to spend a billion dollars again five years [[00:37:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2264.88s)]
*  from now? It just doesn't seem very likely. There's going to be a lot of hardcore negotiations going [[00:37:48](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2268.3199999999997s)]
*  on, Chamath. People are going to ask for 20% off, 50% off, and people are going to have to be more [[00:37:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2272.7999999999997s)]
*  competitive. That's all. I suspect palantirers go to market. When they start to release scale, [[00:37:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2277.7599999999998s)]
*  they'll be able to under price a bunch of these other alternatives. [[00:38:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2282.16s)]
*  I think that when you look at the impacts and pricing that all of these open source and close [[00:38:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2286.72s)]
*  source model companies have now introduced in terms of the price per token, what we've seen is [[00:38:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2297.04s)]
*  it's just a massive step function lower. It is incredibly deflationary. The things that sit on top [[00:38:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2302.48s)]
*  are going to get priced as a function of that cost, which means it will be an order of magnitude [[00:38:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2311.52s)]
*  cheaper than the stuff that it replaces. Which means that a company would almost have to purposely [[00:38:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2317.44s)]
*  want to keep paying tens of millions of dollars when they don't have to. They would need to make [[00:38:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2323.6000000000004s)]
*  that as an explicit decision. I think that very few companies will be in a position to be that [[00:38:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2329.1200000000003s)]
*  cavalier in five and 10 years. You're either going to rebase the revenues of a bunch of these [[00:38:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2336.08s)]
*  existing deterministic companies, or you're going to create an entire economy of new ones that have [[00:39:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2343.04s)]
*  a fraction of the revenues today, but a very different profitability profile. I just think [[00:39:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2348.24s)]
*  that that's the cycle. I think whenever you're dealing with a disruption as big as this current [[00:39:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2354.56s)]
*  one, I think it's always tempting to think in terms of the existing pie getting disrupted and [[00:39:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2359.92s)]
*  shrunk, as opposed to the pie getting so big with new use cases that on the whole, the ecosystem [[00:39:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2366.32s)]
*  benefits. I suspect that's what's going to happen. I agree with that. My only point is that the pie [[00:39:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2373.28s)]
*  can get bigger while the slices get much, much smaller. Right between the two of you, I think, [[00:39:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2380.2400000000002s)]
*  the truth because what's happening is if you look at investing, it's very hard to get into these [[00:39:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2390.0s)]
*  late stage companies because they don't need as much capital. Because your point, Shamoff, [[00:39:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2395.28s)]
*  when they do hit profitability with 10 or 20 people, the revenue per employee is going way up. [[00:40:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2400.48s)]
*  If you look at Google, Uber, Airbnb, and Facebook meta, they have the same number or less employees [[00:40:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2407.2000000000003s)]
*  than they did three years ago, but they're all growing in that 20 to 30% a year, which means [[00:40:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2413.76s)]
*  in but two to three years, each of those companies has doubled revenue per employee. [[00:40:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2418.88s)]
*  So that concept of more efficiency, and then that trickles down, [[00:40:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2423.84s)]
*  Sachs, to the startup investing space where you and I are. I'm a pre-seed seed investor, [[00:40:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2428.2400000000002s)]
*  you're a seed series A investor. If you don't get in in those three or four rounds, I think it's [[00:40:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2431.92s)]
*  going to be really expensive and the companies are not going to need as much money downstream. [[00:40:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2436.56s)]
*  Speaking of investing in late stage companies, we never closed the loop on the whole open AI thing. [[00:40:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2441.28s)]
*  What did we think of the fact that they're completely changing the structure of this [[00:40:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2446.56s)]
*  company? They're changing into a corporation from the nonprofit, and Sam's now getting a [[00:40:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2452.16s)]
*  $10 billion stock package. He's not in it for the money. He has health insurance, Sachs. [[00:40:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2457.2s)]
*  But we never just- Congress? I don't need money. I've got enough money. I just needed the health [[00:41:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2464.0s)]
*  insurance. Pull the clip up, Nick. Pull the clip up. I mean, it's the funniest clip ever. [[00:41:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2468.4s)]
*  I just spit my coffee out when I tried out Rogan Clip. No, this is Congress. Watch this. [[00:41:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2472.7999999999997s)]
*  You make a lot of money, do you? I make- No, I'm paid enough for health insurance. I have no [[00:41:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2479.44s)]
*  equity in open AI. Really? That's interesting. You need a lawyer. I need a what? You need a [[00:41:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2483.8399999999997s)]
*  lawyer or an agent. I'm doing this because I love it. Thank you. He's the greatest. Look at me, [[00:41:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2489.52s)]
*  believe him. Can I ask you a question there, Sachs? Are you doing this venture capital where [[00:41:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2496.3999999999996s)]
*  you put the money in the startups because you love it or because you're looking to get another home [[00:41:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2504.3199999999997s)]
*  in a coastal city and put more Jeff fuel in that plane? I need an answer for the people of the [[00:41:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2510.72s)]
*  sovereign state of Mississippi. No, Louisiana. That's Senator John Kennedy from Louisiana. [[00:41:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2515.2799999999997s)]
*  He's a very smart guy, actually, with a lot of common folk wisdom. [[00:42:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2521.68s)]
*  He got that simple talk. He's a sterile, actually. He's very funny, but- [[00:42:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2528.3999999999996s)]
*  He's very funny. If you listen to him, he knows how to slice and dice his opponents. [[00:42:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2535.9199999999996s)]
*  You might need to get yourself one of them fancy agents from Hollywood or an attorney from the [[00:42:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2541.3599999999997s)]
*  Wilson Suncini Corporation to renegotiate your contract, son, because you're working a lot more [[00:42:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2547.2799999999997s)]
*  from what I can gather in your performance today than just some simple healthcare. I hope you took [[00:42:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2552.64s)]
*  the Blue Cross Blue Shield. I would like to make two semi-serious observations. Let's go. Please [[00:42:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2558.72s)]
*  get us back on track. I think the first is that there's going to be a lot of people that are [[00:42:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2564.7999999999997s)]
*  looking at the architecture of this conversion because if it passes muster, everybody should do [[00:42:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2569.2799999999997s)]
*  it. Think about this model. Let's just say that you're in a market and you start as a nonprofit. [[00:42:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2574.56s)]
*  What that really means is you pay no income tax. For a long time, you put out a little bit of the [[00:43:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2581.2799999999997s)]
*  percentage of whatever you earn, but you can now outspend and outcompete all of your competitors. [[00:43:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2588.7999999999997s)]
*  Then once you win, you flip to a corporation. That's a great hack on the tax code. [[00:43:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2597.2799999999997s)]
*  You let the donators get first bite of the apple if you do convert because remember, [[00:43:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2604.08s)]
*  Vinod and Hoffman got all their shares on the conversion. The other way will also work as well [[00:43:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2609.44s)]
*  because there's nothing that says you can't go in the other direction. Let's assume that you're [[00:43:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2614.72s)]
*  already a for-profit company, but you're in a space with a bunch of competitors. [[00:43:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2619.68s)]
*  Can't you just do this conversion in reverse, become a nonprofit? Again, you pay no income tax, [[00:43:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2624.72s)]
*  so now you are economically advantaged relative to your competitors. Then when they wither and die [[00:43:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2631.12s)]
*  or you can outspend them, you flip back to a for-profit again. I think the point is that [[00:43:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2638.4s)]
*  there's a lot of people that are going to watch this closely. If it's legal and it's allowed, [[00:44:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2645.04s)]
*  I just don't understand why everybody wouldn't do this. [[00:44:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2653.6s)]
*  Yeah. That was Elon's point as well. [[00:44:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2656.16s)]
*  The second thing, which is just more of like [[00:44:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2658.96s)]
*  cultural observation is, and you brought up Elon, my comment to you guys yesterday and I'll just [[00:44:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2663.52s)]
*  make the comment today. It's a little bit disheartening to see a situation where Elon [[00:44:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2669.36s)]
*  built something absolutely incredible, defied every expectation, and then had the justice system [[00:44:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2676.16s)]
*  take $55 billion away from him. His payment package you're referring to at Tesla. [[00:44:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2685.1200000000003s)]
*  His payment package, the options at Tesla. And then on the other side, [[00:44:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2691.04s)]
*  Sam's going to pull something like this off, definitely pushing the boundaries, [[00:44:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2695.92s)]
*  and he's going to make $10 billion. And I just think when you put those two things in contrast, [[00:45:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2701.36s)]
*  that's not how the system should probably work, I think is what most people would say. [[00:45:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2708.6400000000003s)]
*  Friedberg, you've been a little quiet here. Any thoughts on the transaction, the non-profit to [[00:45:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2712.88s)]
*  for-profit? If you were looking at that in what you're doing, do you see a way that Ohalo could [[00:45:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2717.44s)]
*  take a non-profit status, raise a bunch of money through donations for virtuous work, [[00:45:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2722.7200000000003s)]
*  then license those patents to your for-profit? Would that be advantageous to you? And do you [[00:45:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2728.32s)]
*  think this could become a new model? I have absolutely zero idea. I have no idea [[00:45:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2733.36s)]
*  what they're doing. I don't know how they're converting a non-profit to a for-profit. None [[00:45:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2737.44s)]
*  of us have the details on this. There may be significant tax implications, payments they need [[00:45:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2740.56s)]
*  to make. I don't think any of us know. I certainly don't. I don't know if there's actually a real [[00:45:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2745.2s)]
*  benefit here. If there is, I'm sure everyone would do it. No one's doing it. So there's probably a [[00:45:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2749.84s)]
*  reason why it's difficult. I don't know. It's been done a couple times. The Mozilla Foundation [[00:45:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2754.32s)]
*  did it. We talked about that in a previous episode. Sachs, you want to wrap this up here [[00:45:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2758.96s)]
*  on the corporate structure? Any final thoughts? I mean, Elon put in $50 million. I think he [[00:46:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2762.32s)]
*  gets the same as Sam. Don't you think he should just chip off 7% for Elon? Not that Elon needs [[00:46:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2767.28s)]
*  the money where he's asking, but I'm just wondering why Elon doesn't get the 7% and get, or you know, [[00:46:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2772.96s)]
*  if they're going to redo this. Did Elon actually put in $50 million? Did he put in $50 million? [[00:46:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2779.28s)]
*  $50 million is the report, right? And they have a non-profit. Hoffman put in 10. [[00:46:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2782.4s)]
*  Look, I said on a previous show that this organizational chart of OpenAI was ridiculously [[00:46:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2786.88s)]
*  complicated, and they should go clean it up. They should open up the books and straighten everyone [[00:46:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2792.4s)]
*  out. And I also said that as part of that, they could give Sam Altman a CEO option grant, [[00:46:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2796.64s)]
*  and they should also give Elon some fair compensation for being the seed investor who put in [[00:46:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2802.48s)]
*  the first $50 million and co-founder. And what you're seeing is, well, they're kind of doing [[00:46:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2807.6s)]
*  that. They're opening up the books. They're straightening out the corporate structure. [[00:46:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2813.04s)]
*  They're giving Sam his option grant, but they didn't do anything for Elon. And I'm not saying [[00:46:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2817.52s)]
*  this as Elon's friend. I'm just saying that it's not really fair to basically go fix the original [[00:47:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2822.88s)]
*  situation. You're making it into a for-profit. You're giving everyone shares, but the guy who [[00:47:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2830.1600000000003s)]
*  puts in the original seed capital doesn't get anything. That's ridiculous. And you know, [[00:47:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2835.36s)]
*  what they're basically saying to Elon is, if you don't like it, just sue us. I mean, that's basically [[00:47:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2840.96s)]
*  what they're doing. And I said that they should go clean this up, but they should make it right [[00:47:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2846.08s)]
*  with everybody. So how do you not make it right with Elon? I haven't talked to him about this, [[00:47:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2851.2s)]
*  but he reacted on X saying, this is really wrong. It appeared to be a surprise to him. I doubt he [[00:47:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2855.68s)]
*  knew this was coming. So the company apparently made no effort to make things right with him. [[00:47:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2860.8799999999997s)]
*  And I think that that is a bit ridiculous. If you're going to clean this up, if you're going to [[00:47:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2867.4399999999996s)]
*  change the original purpose of this organization to being a standard for-profit company where the CEO [[00:47:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2871.9199999999996s)]
*  who previously said he wasn't going to get any compensation is now getting $10 billion of [[00:48:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2880.64s)]
*  compensation. How do you do that? And then not clean it up for the co-founder who put in the first [[00:48:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2885.12s)]
*  $50 million? That doesn't make sense to me. And when Reid was on our pod, he said, well, [[00:48:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2890.0s)]
*  Elon's rich enough. Well, that's not a principled excuse. I mean, does Vinod ever act that way? [[00:48:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2895.92s)]
*  Does Reid ever act that way? Do they ever say, well, you don't need to do what's fair for me [[00:48:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2901.2799999999997s)]
*  because I'm already rich? That's not a principled answer. The argument that I heard was that Elon [[00:48:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2906.4s)]
*  was given the opportunity to invest along with Reid, along with Vinod, and he declined to [[00:48:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2912.08s)]
*  participate in the for-profit investing side that everyone else participated in. Reid made that [[00:48:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2918.08s)]
*  argument, and I think it's the best argument the company has. But let's think about that argument. [[00:48:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2922.8s)]
*  Maybe Elon was busy that week. Maybe Elon already felt like he had put all the money that he had [[00:48:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2927.2000000000003s)]
*  allocated for something like this into it because he put in a $50 million check, whereas Reid put in [[00:48:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2932.64s)]
*  10. We don't know what Elon was thinking at that time. Maybe there was a crisis at Tesla and he [[00:48:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2937.3599999999997s)]
*  was just really busy. The point is, Elon shouldn't have been obligated to put in more money into this [[00:49:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2942.72s)]
*  venture. The fact of the matter is they're refactoring the whole venture. Elon had an [[00:49:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2949.6s)]
*  expectation when he put in the 50 million that this would be a nonprofit and stay a nonprofit. [[00:49:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2954.48s)]
*  They're changing that. If they change it, they have to make things right with him. It doesn't [[00:49:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2959.2799999999997s)]
*  really matter whether he had a subsequent opportunity to invest. He wasn't obligated [[00:49:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2963.12s)]
*  to make that investment. What he had an expectation of is that his $50 million would be used for a [[00:49:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2968.7999999999997s)]
*  philanthropic purpose. Clearly, it has not been. In fairness to Vinod, he bought that incredible [[00:49:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2975.44s)]
*  beachfront property and donated it to the public trust so we can all surf and have our Halloween [[00:49:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2981.04s)]
*  party there. It's all good. Thank you, Vinod, for giving us that incredible beach. I want to [[00:49:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2985.04s)]
*  talk to you guys about interfaces that came up Chamath in your headwinds or your four-pack of [[00:49:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2990.48s)]
*  reasons that OpenAI, when you steal men, the bear case could have challenges. Obviously, [[00:49:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=2996.96s)]
*  we're seeing that and it is emerging that Metta is working on some AR glasses that are really [[00:50:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3003.12s)]
*  impressive. Additionally, I've installed iOS 18, which is Apple intelligence that works on 15 [[00:50:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3010.32s)]
*  phones and 16 phones. 18 is the iOS. Did any of you install the beta of iOS 18 yet and use Siri? [[00:50:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3017.28s)]
*  It's pretty clear with this new one that you're going to be able to talk to Siri as an LLM like [[00:50:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3023.92s)]
*  you do in chat GPT mode, which I think means they will not make themselves dependent on chat GPT and [[00:50:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3029.36s)]
*  they will siphon off half the searches that would have gone to chat GPT. So I see that as a serious [[00:50:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3034.88s)]
*  thing. Siri's not very good, J. Kelly. And you know this because when you were driving me to [[00:50:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3039.52s)]
*  the airport yesterday- We tested it and it didn't work. [[00:50:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3043.12s)]
*  He tries to execute this joke where he's like, hey, Siri, send Chamath Palihapitiya a message. [[00:50:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3046.88s)]
*  And it was a very off-color message. I'm not going to say what it is. [[00:50:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3052.72s)]
*  Spicy joke. [[00:50:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3055.7599999999998s)]
*  And then it's like, okay, great. Sending Linda blah, blah, blah. [[00:50:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3056.56s)]
*  Don't send that joke to her. [[00:51:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3061.68s)]
*  It hallucinates and almost sends it to some other, you know, some woman in his contact. [[00:51:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3063.28s)]
*  It would have been really damaging. [[00:51:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3067.6s)]
*  It's not very good, Jason. It's not very good. [[00:51:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3069.28s)]
*  But what I will say is there are features of it where if you squint a little bit, you will see [[00:51:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3071.12s)]
*  that Siri is going to be conversational. So when I was talking to it with music and, you know, [[00:51:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3077.36s)]
*  you can have a conversation with it and do math like you can do with the chat GPT version. [[00:51:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3082.96s)]
*  And you have Microsoft doing that with their co-pilot and now Meta is doing it at the top [[00:51:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3087.92s)]
*  of each one. So everybody's going to try to intercept the queries and the voice interface. [[00:51:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3093.44s)]
*  So chat GPT four is now up against Meta, Siri, Apple, and Microsoft for that interface. [[00:51:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3098.88s)]
*  It's going to be challenging, but let's talk about these Meta glasses here. [[00:51:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3105.6s)]
*  Meta showed off the AR glasses that Nick will pull up right now. [[00:51:48](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3108.96s)]
*  These aren't goggles. Goggles look like ski goggles. [[00:51:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3113.04s)]
*  That's what Apple is doing with their Vision Pro. [[00:51:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3116.4s)]
*  Or when you see the Meta Quest, you know how those work. Those are VR [[00:51:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3119.8399999999997s)]
*  with cameras that will create a version of the world. [[00:52:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3124.4s)]
*  These are actual chunky sunglasses like the ones I was wearing earlier when I was doing the bit. [[00:52:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3127.12s)]
*  So these let you operate in the real world and are supposedly extremely expensive. [[00:52:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3133.44s)]
*  They made a thousand prototypes. They were letting a bunch of influencers and folks [[00:52:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3140.08s)]
*  like Gary Vaynerchuk use them and they're not ready for prime time. [[00:52:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3144.4s)]
*  But the way they work, Freeberg, is there's a wristband that will track your fingers [[00:52:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3150.96s)]
*  and your wrist movement. So you could be in a conversation like we are here on the pod [[00:52:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3155.1200000000003s)]
*  and below the desk, you could be, you know, moving your arm and hand around to be doing [[00:52:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3159.28s)]
*  replies to, I don't know, incoming messages or whatever it is. What do you think of this AR [[00:52:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3163.6000000000004s)]
*  vision of the world and Meta making this progress? [[00:52:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3169.1200000000003s)]
*  Well, I think it ties in a lot to the AI discussion because I think we're really [[00:52:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3172.56s)]
*  witnessing this big shift from, and this big transition in computing, probably the biggest [[00:52:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3178.8s)]
*  transition since mobile. You know, we moved from mainframes to desktop computers. Everyone had kind [[00:53:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3185.04s)]
*  of this computer on their desktop, but you used a mouse and keyboard to control it to mobile, [[00:53:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3191.1200000000003s)]
*  where you had a keyboard and clicking and touching on the screen to do things on it. [[00:53:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3195.2000000000003s)]
*  And now to what I would call this kind of ambient computing method. And, you know, [[00:53:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3199.2799999999997s)]
*  I think the big difference is control and response in directed computing. You're kind of telling the [[00:53:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3205.04s)]
*  computer what to do. You're controlling it. You're using your mouse or your keyboard to [[00:53:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3211.3599999999997s)]
*  go to this website. So you type in a website address, then you click on the thing that you [[00:53:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3216.16s)]
*  want to click on and you kind of keep doing a series of work to get the computer to go access [[00:53:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3220.0s)]
*  the information that you ultimately want to achieve your objective. But with ambient computing, [[00:53:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3224.96s)]
*  you can more kind of cleanly state your objective without this kind of directive process. You can [[00:53:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3229.92s)]
*  say, Hey, I want to say I want to have dinner in New York next Thursday at the Michelin star [[00:53:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3235.2s)]
*  restaurant at five 30 book me something and it's done. And I think that there are kind of [[00:54:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3240.4s)]
*  five core things that are needed for this to work, both in control and response, it's voice control, [[00:54:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3245.44s)]
*  gesture control and eye control or kind of the control pieces that replace mice and clicking [[00:54:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3252.0s)]
*  and touching and keyboards. And then responses, audio and kind of integrated visual, which is the [[00:54:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3257.52s)]
*  idea of the goggles, a voice control works. Have you guys used the open AI voice control system [[00:54:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3263.2000000000003s)]
*  lately? I mean, it is really incredible. I had my earphones in and I was like doing this exercise. [[00:54:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3268.1600000000003s)]
*  I was trying to learn something. So I told open AI to start quizzing me on this thing. And I just [[00:54:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3273.52s)]
*  did a 30 minute walk. And while I was walking, it was asking me quiz questions and I would answer [[00:54:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3278.64s)]
*  it and tell me I was right or wrong. It was really this incredible dialogue experience. [[00:54:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3282.24s)]
*  So I think the voice controls there. I don't know if you guys have used Apple vision pro, [[00:54:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3285.8399999999997s)]
*  but gesture control is here today. You can do single finger movement with Apple vision pro, [[00:54:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3289.3599999999997s)]
*  it triggers actions. And eye control is incredible. You look at the letters you want to have kind of [[00:54:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3294.16s)]
*  spelled out or you look at the thing you want to activate and it does it. So all of the control [[00:54:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3298.72s)]
*  systems for this ambient computing are there. And then the AI enables this kind of audio response [[00:55:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3303.2s)]
*  where it speaks to you. And the big breakthrough that's needed that I don't think we're quite [[00:55:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3307.6s)]
*  there yet, but maybe Zuck is highlighting that we're almost there and Apple vision pro feels [[00:55:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3312.0s)]
*  like it's almost there except it's big and bulky and expensive is integrated visual, [[00:55:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3316.08s)]
*  where the ambient visual interface is always there. And you can kind of engage with it. [[00:55:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3320.08s)]
*  So there's this big change. I don't think that mobile handsets are going to be around in 10 [[00:55:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3324.4s)]
*  years. I don't think we're going to have this like phone in our pocket that we're like, [[00:55:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3328.08s)]
*  pressing buttons on and touching and telling it where on the browser to go to the browser [[00:55:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3331.8399999999997s)]
*  interface is going to go away. I think so much of how computing is done, how much how we integrate [[00:55:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3336.08s)]
*  with data in the world, and how the computer ultimately fetches that data and does stuff with [[00:55:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3340.7999999999997s)]
*  it for us is going to completely change to this ambient model. So I'm, I'm pretty excited about [[00:55:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3345.2799999999997s)]
*  this evolution. But I think that what we're seeing with Zuck, what we saw with Apple vision pro, [[00:55:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3351.52s)]
*  and all of the open AI demos, they all kind of converge on this very incredible shift in computing [[00:55:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3355.2799999999997s)]
*  that will kind of become this ambient system that exists everywhere all the time. And I know folks [[00:56:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3361.7599999999998s)]
*  have kind of mentioned this in the past, but I think we're really seeing it kind of all come [[00:56:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3365.84s)]
*  together now with these five key things. Jamoth, any thoughts on Facebook's progress with AR, [[00:56:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3369.04s)]
*  and how that might impact computing and interfaces when paired with language models? [[00:56:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3377.6000000000004s)]
*  I think David's right that there's something that's going to be totally new and unexpected. [[00:56:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3386.08s)]
*  So I agree with that part of what Freebrook says. I am still not sure that glasses are the perfect [[00:56:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3392.32s)]
*  form factor to be ubiquitous. When you look at a phone, a phone makes complete sense for literally [[00:56:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3400.6400000000003s)]
*  everybody, right? Man, woman, old, young, every race, every country of the world. It's such a [[00:56:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3409.44s)]
*  ubiquitously obvious form factor. But the thing is that initial form factor was so different than [[00:57:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3420.72s)]
*  what it replaced, even if you looked at flip phones versus that first generation iPhone. [[00:57:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3430.16s)]
*  So I do think, Freebrook, you're right, that there's this new way of interacting that is ready to [[00:57:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3434.96s)]
*  explode onto the scene. And I think that these guys have done a really good job with these guys. [[00:57:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3444.16s)]
*  I mean, I give them a lot of credit for sticking with it and iterating through it and getting it [[00:57:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3450.2400000000002s)]
*  to this place. It looks meaningfully better than the Vision Pro, to be totally honest. [[00:57:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3455.44s)]
*  But I'm still not convinced that we've explored the best of our creativity [[00:57:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3461.44s)]
*  in terms of the devices that we want to use with these AI models. [[00:57:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3466.1600000000003s)]
*  You need some visual interface. I think the question is, where is the visual interface? [[00:57:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3469.76s)]
*  But do you? [[00:57:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3473.28s)]
*  Is it in the wall? [[00:57:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3473.92s)]
*  No, but do you? [[00:57:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3475.1200000000003s)]
*  When you're asking, I want to watch Chamath on Rogan. I don't just want to hear, I want to see. [[00:57:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3476.4799999999996s)]
*  When I want to visualize stuff, I want to visualize it. I want to look at the food I'm [[00:58:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3482.24s)]
*  buying online. I want to look at pictures of the restaurant I'm going to go to. [[00:58:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3486.08s)]
*  But how much of that time, when you say those things, [[00:58:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3488.8799999999997s)]
*  are you not near some screen that you can just project and broadcast that onto? [[00:58:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3492.24s)]
*  I mean, maybe that's the model. [[00:58:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3496.24s)]
*  If the use case is, I'm walking in the park and I need to watch TV at the same time, [[00:58:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3498.3999999999996s)]
*  I don't think that's a real use case. [[00:58:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3503.12s)]
*  I think you're on this one wrong, Chamath, because I saw this revolution in Japan [[00:58:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3504.64s)]
*  maybe 20 years ago. They got obsessed with augmented reality. There were a ton of startups [[00:58:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3510.8799999999997s)]
*  right as they started getting to the mobile phones. [[00:58:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3515.7599999999998s)]
*  The use cases were really very compelling and we're starting to see them now in education. [[00:58:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3518.4s)]
*  When you're at dinner with a bunch of friends, how often does picking up your phone and looking at [[00:58:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3522.72s)]
*  a message disturb the flow? Well, people will have glasses on. They'll be going for walks. [[00:58:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3529.8399999999997s)]
*  They'll be driving. They'll be at a dinner party. They'll be with their kids. [[00:58:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3533.84s)]
*  And you'll have something on like focus mode, you know, whatever the equivalent is in Apple. [[00:58:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3536.88s)]
*  And a message will come in from your spouse or from your child, [[00:59:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3541.2000000000003s)]
*  but you won't have to take your phone out of your pocket. [[00:59:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3544.6400000000003s)]
*  And I think once these things weigh a lot less, you're going to have four different ways to [[00:59:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3546.56s)]
*  interact with your computer in your pocket, your phone, your watch, your AirPods, whatever you [[00:59:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3551.6000000000004s)]
*  have in your ears and the glasses. And I bet you glasses are going to take like a third of the [[00:59:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3556.1600000000003s)]
*  tasks you do. I mean, what is the point of taking out your phone and watching the Uber come to you, [[00:59:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3560.16s)]
*  but seeing that little strip that tells you the Uber is 20 minutes away, 15 minutes away, [[00:59:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3565.04s)]
*  or what the gate number is. I don't have that anxiety. [[00:59:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3569.2799999999997s)]
*  Well, I don't know if it's anxiety, but I just think it's ease of use. [[00:59:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3573.04s)]
*  All those times. 10 minutes. That's the, that's the definition. [[00:59:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3575.52s)]
*  I think it adds up. I think taking your phone out of your pocket 50 times a day. [[00:59:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3578.3999999999996s)]
*  Those are all useless notifications. The whole thing is to train yourself to realize that [[00:59:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3582.7999999999997s)]
*  it'll come when it comes. Okay. [[00:59:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3586.8s)]
*  Sack, you have any thoughts on this impressive demo or the demo that people who've seen upset is [[00:59:48](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3588.4s)]
*  pretty, pretty darn compelling. I think it does look pretty impressive. [[00:59:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3593.84s)]
*  I mean, you can wear these meta Orion glasses around. [[00:59:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3597.36s)]
*  And look like a human. I mean, you might look like Eugene Levy, but you'll still look like [[01:00:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3602.88s)]
*  a semi normal person. Whereas you can't wear the Apple vision pro. I mean, you can't wear that [[01:00:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3607.6000000000004s)]
*  around. They don't look good. You don't like them. Nick, can you please find the picture of [[01:00:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3612.88s)]
*  Eugene Levy? I mean, it seems like a major advancement, certainly compared to Apple vision [[01:00:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3617.36s)]
*  pro. I mean, you don't hear about the Apple vision pros anymore at all. I mean, those things [[01:00:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3624.8s)]
*  came and went. It's pretty funny. It seems to me that who's that? Metta is executing extremely [[01:00:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3630.32s)]
*  well. I mean, you had the very successful cost cutting, which Wall Street liked. [[01:00:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3642.64s)]
*  Zuck published that letter, which I give him credit for regretting the censorship that Metta [[01:00:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3647.52s)]
*  did, which was at the behest of the deep state. They made huge advancements in AI. I don't think [[01:00:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3652.08s)]
*  they were initially on the cutting edge of that, but they've caught up. And now they're leading [[01:00:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3658.72s)]
*  the open source with Lama 3.2. And now it seems to me that they're ahead on augmented reality. [[01:01:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3662.72s)]
*  Ever since Zuck grew out the hair, don't ever cut the hair. It's like Samson. I mean, [[01:01:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3669.92s)]
*  you've been- It's like Samson. Based Zuck is the best Zuck. He does not give a f. [[01:01:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3675.92s)]
*  I want to be clear. I think these glasses are going to be successful. My only comment is that [[01:01:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3682.0s)]
*  I think that when you look back 25 and 30 years from now and say that was the killer AI device, [[01:01:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3687.2000000000003s)]
*  I don't think it's going to look like something we know today. That's my only point. [[01:01:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3694.7200000000003s)]
*  And maybe it's going to be this thing that Sam Altman and Johnny Ive are baking up. That's [[01:01:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3699.04s)]
*  supposed to be this AI infused iPhone killer. Maybe it's that thing. I doubt that will be a [[01:01:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3703.92s)]
*  pair of glasses or a phone or a pin. If you think about- So take the constraints on, [[01:01:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3711.36s)]
*  I don't need a keyboard because I'm not going to be typing stuff. I don't need a normal browser [[01:01:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3717.84s)]
*  interface. You could see a device come out that's almost smaller than the palm of your hand that [[01:02:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3723.76s)]
*  gives you enough of the visuals and all it is is a screen with maybe two buttons on the side. [[01:02:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3730.0800000000004s)]
*  It's all audio driven. You put a headset in and you're basically just talking or using gesture [[01:02:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3735.0400000000004s)]
*  or looking at it to describe where you want things to go. It can create an entirely new [[01:02:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3739.92s)]
*  computing interface because AI does all of these incredible things with predictive text, [[01:02:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3743.6800000000003s)]
*  with gesture control, with eye control, and with audio control. Then it can just give you what you [[01:02:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3748.48s)]
*  want on a screen and all you're getting is a simple interface. So Chamath, you may be right, [[01:02:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3753.6s)]
*  it might be a big watch or a handheld thing that's much smaller than an iPhone and just all it is is [[01:02:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3756.48s)]
*  a screen with nothing. I really resonate when you talk about voice only because I think [[01:02:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3761.52s)]
*  it's like- I think there's a part of social decorum that all of these goggles and glasses violate. [[01:02:48](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3768.7999999999997s)]
*  And I think we're going to have to decide as a society whether that's going to be okay. And [[01:02:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3777.92s)]
*  then I think when you go trekking in Nepal or you're going to encounter somebody wearing AR [[01:03:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3781.68s)]
*  glasses, I think the odds are pretty low. But you do see people today with a phone. So what do they [[01:03:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3789.04s)]
*  replace it with? And I think voice as a modality is- I think it's more credible that that could be [[01:03:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3793.52s)]
*  used by 8 billion people. I think social fabric's more affected by people staring at their phones [[01:03:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3800.7999999999997s)]
*  all the time. You sit on a bus, you sit at a restaurant, you go to dinner with someone and [[01:03:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3804.96s)]
*  they're staring at their phone. Like spouses, friends, we all deal with it where you feel like [[01:03:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3808.0s)]
*  you're not getting attention from the person that you're interfacing with in the real world [[01:03:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3813.2s)]
*  because they're so connected to the phone. If we can disconnect the phone, but still take away this [[01:03:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3817.6s)]
*  kind of addictive feedback loop system, but still give you this computing ability in a more ambient [[01:03:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3822.24s)]
*  way that allows you to remain engaged in the physical world. I think everyone can say it. [[01:03:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3827.2s)]
*  You could say it, it hurts your feeling when he's playing chess and not paying attention. [[01:03:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3830.56s)]
*  I'll be playing chess on my AR glasses while pretending to listen to you. [[01:03:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3834.3199999999997s)]
*  You idiot. He's buying them. He got version one. [[01:03:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3838.72s)]
*  One point I want to just hit on is that the reason why these glasses have a chance of working is [[01:04:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3844.64s)]
*  because of AI. I mean, Facebook initially made- That's exactly my point. That's exactly my point. [[01:04:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3849.8399999999997s)]
*  Facebook or Meta made these huge investments before AI was a thing. And in a way, I think they've [[01:04:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3854.8799999999997s)]
*  gotten lucky because what AI gives you is voice and audio. So you can talk to the glasses or [[01:04:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3860.32s)]
*  whatever the wearable is. It can talk to you. That's the perfect natural language. And [[01:04:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3867.28s)]
*  computer vision allows it to understand the world around you. So whatever this device is, [[01:04:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3873.04s)]
*  it can be a true personal digital assistant in the real world. And that's the opportunity. [[01:04:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3877.36s)]
*  If you guys play with Apple Vision Pro, have any of you actually used it to any extent? [[01:04:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3882.4s)]
*  No, I used it for a day or a night when we were playing poker and I've never used it again since. [[01:04:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3887.36s)]
*  Right. Which I get, but I do think that it has these tools in it, similar to the original [[01:04:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3894.7200000000003s)]
*  Macintosh had these incredible graphics editors like MacPaint and all these things that people [[01:04:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3899.84s)]
*  didn't get addicted to at the time, but they became this tool that completely revolutionized [[01:05:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3905.44s)]
*  everything in computing later and fonts and so on. But this, I think has these tools, [[01:05:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3911.76s)]
*  Apple Vision Pro with gesture control and the keyboard and the eye control, those aspects of [[01:05:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3916.6400000000003s)]
*  that device highlight where this could all go, which is these systems can be driven without [[01:05:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3923.44s)]
*  keyboards, without typing, without moving your finger around, without clicking on buttons. [[01:05:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3929.28s)]
*  I think that's the key observation. I really agree with what you just said. It's this idea [[01:05:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3934.88s)]
*  that you're just liberated from the hunting and pecking and tapping. [[01:05:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3939.76s)]
*  You don't need to control the computer anymore. The computer now knows what you want. [[01:05:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3945.2000000000003s)]
*  And then the computer can just go and do the work. [[01:05:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3949.84s)]
*  This is the behavior change that I don't think we're fully giving enough credit to. So today, [[01:05:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3954.0800000000004s)]
*  part of what Jason talked about, what I call the anxiety, is because of the information architecture [[01:05:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3959.36s)]
*  of these apps. That is totally broken. And the reason why it's broken is when you tell an AI [[01:06:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3964.32s)]
*  agent, get me the cheapest car right now to go to XYZ place. It will go and look at Lyft and Uber [[01:06:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3968.88s)]
*  and whatever. It'll provision the car and then it'll just tell you when it's coming. And it will [[01:06:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3976.6400000000003s)]
*  break this cycle that people have of having to check these apps for what is useless filler [[01:06:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3981.84s)]
*  information. And when you strip a lot of that notification traffic away, I think you'll find [[01:06:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3987.28s)]
*  that people start looking at each other in the face more often. And I think that that's a net [[01:06:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3992.8s)]
*  positive. So will Meta sell hundreds of millions of these things? I suspect probably. [[01:06:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=3997.28s)]
*  But all I'm saying is if you look backwards 30 years from now, what is the device that sells [[01:06:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4004.2400000000002s)]
*  in the billions? It's probably not a form factor that we understand today. [[01:06:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4009.1200000000003s)]
*  I just want to point out the form factor you're seeing now is going to get greatly reduced. [[01:06:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4013.84s)]
*  These were some of the early Apple, I don't know if you guys remember these, but Frog Design made [[01:06:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4019.6800000000003s)]
*  these crazy tablets in the 80s that were the eventual inspiration for the iPad, [[01:07:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4025.6s)]
*  25 years later, I guess. And so that's the journey we're on here right now. This clunky, [[01:07:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4032.72s)]
*  and these are not functional prototypes. The Apple Newton is like, and then it turns out, [[01:07:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4039.04s)]
*  hey, you throw away the stylus and you got an iPhone, right? And everything gets a million X [[01:07:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4044.56s)]
*  better. The other subtle thing that's happening, which I don't think we should sleep on is that [[01:07:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4049.12s)]
*  the AirPods are probably going to become much more socially acceptable to wear on a 24 by 7 [[01:07:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4053.36s)]
*  basis because of this feature that allows it to become a useful hearing aid. And I think as it [[01:07:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4060.6400000000003s)]
*  starts being worn in more and more social environments and as the form factor of that [[01:07:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4066.1600000000003s)]
*  shrinks, that's when I really do think we're going to find some very novel use case, which is [[01:07:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4071.76s)]
*  you know, very unobtrusive. It kind of blends into your own physical makeup as a person without it [[01:07:57](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4077.6s)]
*  really sticking out. I think that's when you'll have a really killer feature. But I think that [[01:08:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4084.32s)]
*  the AirPods as hearing aids will also add a lot. So Meta's doing a lot, Apple's doing a lot, [[01:08:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4088.0s)]
*  but I don't think we've yet seen the super killer hardware device yet. [[01:08:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4094.08s)]
*  And there was an interesting waypoint. Microsoft had the first tablet. Here's the Microsoft tablet, [[01:08:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4097.68s)]
*  for those of you watching that came, you know, I don't know, this was the late 90s or early 2000s, [[01:08:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4104.64s)]
*  Friedberg, if you remember it, these like incredibly bulky tablets that Bill Gates was [[01:08:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4109.76s)]
*  probably like all the events. 99 2000. Yeah, so you get a lot of false starts. They're spending, [[01:08:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4115.92s)]
*  I think close to $20 billion a year on this ARV or so anyway, we're definitely on this path to ambient [[01:08:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4122.56s)]
*  computing. I don't think I don't think this whole like, hey, you got to control a computer thing is [[01:08:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4127.4400000000005s)]
*  anything my kids are going to be doing in 20 years. This is this is the convergence of like [[01:08:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4130.88s)]
*  three or four really interesting technological waves. All right, just dovetailing with tech jobs [[01:08:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4134.64s)]
*  and the static team size. There is a report of a blue collar boom, the tool belt generation [[01:09:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4140.08s)]
*  is what Gen Z is being referred to as a report in the Wall Street Journal reports, hey, tech jobs [[01:09:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4147.52s)]
*  have dried up. We all we're all seeing that. And according to indeed developer jobs down more than [[01:09:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4153.92s)]
*  30% since February of 2020 pre COVID, of course, if you look at layoffs that FYI, you'll see all the [[01:09:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4158.56s)]
*  tech jobs that have been eliminated since 2022, over a half million of them, bunch of things at [[01:09:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4166.400000000001s)]
*  play here. And the Wall Street Journal notes that entry level tech workers are getting hit the [[01:09:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4172.400000000001s)]
*  hardest, especially all these recent college graduates. And if you look at historical college [[01:09:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4178.56s)]
*  enrollment, let's pull up that chart neck, you can see your undergraduate graduate and total with [[01:09:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4185.44s)]
*  the red line, we peaked at 21 million people in either graduate school or undergraduate in 2010. [[01:09:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4189.679999999999s)]
*  And that's come down to 8.6 million at the same time. Obviously, in the last 12 years, you've had [[01:09:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4196.96s)]
*  the population has grown. So this is even, you know, if it was a percentage basis would be even [[01:10:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4202.5599999999995s)]
*  more dramatic. So what's behind this a poll of 1000 teens this summer found that about half believe [[01:10:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4206.879999999999s)]
*  a high school degree, trade program or two year degree best meets their career needs and 56% said [[01:10:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4214.4s)]
*  real world on the job experience is more valuable than obtaining a college degree. Something you've [[01:10:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4220.5599999999995s)]
*  talked about with your own personal experience, Chamath at Waterloo doing apprenticeships, [[01:10:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4225.28s)]
*  essentially your thoughts on Generation Tool Belt. Such a positive trend. I mean, there's so many [[01:10:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4230.5599999999995s)]
*  reasons why this is good. I'll just list a handful that come to the top of my mind. The first and [[01:10:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4237.12s)]
*  probably the most important is that it breaks this stranglehold that the university education [[01:10:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4242.16s)]
*  system has on America's kids. We have tricked millions and millions of people into getting [[01:10:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4250.32s)]
*  trillions of dollars in debt on this idea that you're learning something in university that's [[01:11:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4261.04s)]
*  somehow going to give you economic stability and ideally freedom. And it has turned out for so many [[01:11:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4266.16s)]
*  people to not be true. It's just so absurd and unfair that that has happened. So if you can go [[01:11:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4274.88s)]
*  and get a trade degree and live a economically productive life where you can get married and [[01:11:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4282.24s)]
*  have kids and take care of your family and do all the things you want to do, that's going to put an [[01:11:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4287.44s)]
*  enormous amount of pressure on higher ed. Why does it charge so much? What does it give in return? [[01:11:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4291.2s)]
*  That's one thought. The second thought, which is much more narrow, Peter Thiel has that famous [[01:11:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4297.44s)]
*  saying where if you have to put the word science behind it, it's not really a thing. And what we [[01:11:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4302.639999999999s)]
*  are going to find out is that that was true for a whole bunch of things where people went to school, [[01:11:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4309.679999999999s)]
*  like political science and- Social science, yeah. [[01:11:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4314.08s)]
*  Social science. But I always thought that computer science would be immune, but I think he's going [[01:11:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4316.8s)]
*  to be right about that too because you can spend two or $300,000 getting in debt to get a computer [[01:12:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4322.16s)]
*  science degree, but you're probably better off learning JavaScript and learning these tools [[01:12:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4328.400000000001s)]
*  in some kind of a boot camp for far, far less and graduating in a position to make money right away. [[01:12:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4332.72s)]
*  So those are just two ideas. I think that it allows us to be a better functioning society. So I am [[01:12:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4338.320000000001s)]
*  really supportive of this trend. It's actually your thoughts on this generation tool belt [[01:12:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4345.04s)]
*  where we're reading about and the combination with static team size that we're seeing in technology, [[01:12:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4349.92s)]
*  companies keeping the number of employees the same or trending down while they grow 30% year over year. [[01:12:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4357.92s)]
*  Oh my God, I'm so sick of this topic of job loss or job disruption. I got in so much trouble [[01:12:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4364.24s)]
*  last week. You asked a question about whether the upper middle class is going to sell their [[01:12:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4369.92s)]
*  jobs, or whether the lower middle class is going to suffer because they're all going to be put out [[01:12:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4374.639999999999s)]
*  of work by AI. And I just kind of brush it off, not because I'm advocating for that, but just [[01:12:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4378.0s)]
*  because I don't think it's going to happen. This whole thing about job loss is so overdone. There's [[01:13:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4383.5199999999995s)]
*  going to be a lot of job disruption. But in the case of coders, just as an example, I think we can [[01:13:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4388.799999999999s)]
*  say that coders, depending on who you talk to, are 10%, 20%, 30% more productive as a result of these [[01:13:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4394.24s)]
*  jobs. But we still need coders. You can't automate 100% of it. And the world needs so many of them. [[01:13:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4401.12s)]
*  The need for software is unlimited. We can't hire enough of them at Glue. By the way, shout out if [[01:13:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4406.72s)]
*  you're a coder who is afraid of not being able to get a job, apply for one at Glue. Believe me, [[01:13:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4412.64s)]
*  we're hiring. I just think that this is so overdone. There's going to be a lot of disruption [[01:13:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4417.599999999999s)]
*  in the knowledge worker space. We talked about the workflow at call centers and service factories. [[01:13:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4424.24s)]
*  A lot of change. But at the end of the day, I think there's going to be plenty of work [[01:13:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4431.04s)]
*  for humans to do. And some of the work will be more in the blue collar space. And I agree with [[01:13:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4435.44s)]
*  Jamal that this is a good thing. I think there's been perhaps an overemphasis on the idea that [[01:14:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4440.48s)]
*  the only way to get ahead in life is to get a fancy degree from one of these universities. [[01:14:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4446.88s)]
*  And we've seen that many of the universities, they're just not that great. They're overpriced. [[01:14:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4451.76s)]
*  You end up graduating with a mountain of debt, and you get a degree that [[01:14:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4456.88s)]
*  may be even far worse than computer science. This is completely worthless. So if people learn more [[01:14:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4462.08s)]
*  vocational skills, if they skip college because they have a proclivity to do something that doesn't [[01:14:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4467.6s)]
*  need that degree, I think that's a good thing. And that's healthy for the economy. [[01:14:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4473.4400000000005s)]
*  Friedberg, is this like just the pendulum swung too much and education got too expensive, [[01:14:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4476.32s)]
*  spending $200k to make $50,000 a year distinctly different than our childhoods or I'm sorry, [[01:14:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4480.72s)]
*  adolescence when we were able to go to college for 10k a year, 20k a year, graduate with some [[01:14:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4485.84s)]
*  low tens of thousands in debt. If you did take that and then your entry level job was 50, 60, [[01:14:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4491.68s)]
*  70k coming out of college. What are your thoughts here? Is this a value issue with college? [[01:14:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4496.56s)]
*  Well, yeah, I think the market's definitely correcting itself. I think for years, [[01:15:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4501.360000000001s)]
*  as Chumak said, there was kind of this belief that if you went to college, there was [[01:15:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4504.72s)]
*  regardless of the college, there was this outcome where you would make enough money [[01:15:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4508.4800000000005s)]
*  to justify the debt you're taking on. And I think folks have woken up to the fact that that's not [[01:15:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4514.24s)]
*  reality. Again, if there was a free market, remember, most people go to college with student [[01:15:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4521.12s)]
*  loans, and all student loans are funded by the federal government. So the cost of education has [[01:15:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4526.32s)]
*  ballooned. And the underwriting criteria necessary for this free market to work has been completely [[01:15:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4533.04s)]
*  destroyed because of the federal spending in the student loan program. There's no [[01:15:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4539.6s)]
*  discrimination between one school or another. You can go to Trump University, or you could go to [[01:15:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4545.76s)]
*  Harvard, it doesn't matter, you still get a student loan. Even if at the end of the process, you don't [[01:15:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4551.120000000001s)]
*  have a degree that's valuable. And so I think folks are now waking up to this fact and the market is [[01:15:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4556.160000000001s)]
*  correcting itself, which is good. I'll also say that I think that there's this premium with [[01:16:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4561.200000000001s)]
*  generally mass production and industrialization of the human touch. And what I mean is, if you [[01:16:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4568.32s)]
*  think about, hey, you could go to the store and buy a bunch of cheap food off of the store shelves, [[01:16:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4577.759999999999s)]
*  you could buy a bunch of Hershey's chocolate bars. Or you can go to a Swiss chocolatier in downtown [[01:16:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4583.28s)]
*  San Francisco, pay $20 for a box of handmade chocolates, you'll pay that premium for that [[01:16:28](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4588.32s)]
*  better product. Same with clothes. There's this big trend in kind of handmade clothes and high-end [[01:16:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4594.0s)]
*  luxury goods. Bespoke, artisanal is the word. Artisanal, handmade. And similarly, I think that [[01:16:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4598.56s)]
*  there is a premium in human service in the partnership with a human. It's not just about [[01:16:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4606.48s)]
*  blue collar jobs. It's about having a waiter talk to you and serve you. If you go to a restaurant, [[01:16:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4612.16s)]
*  instead of having a machine spit out the food to you, there's an experience associated with that [[01:16:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4619.28s)]
*  that you'll pay a premium for. There's hundreds and hundreds of microbreweries in the United [[01:17:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4624.24s)]
*  States that in aggregate outsell Budweiser and Miller and even Modelo today. And that's because [[01:17:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4628.5599999999995s)]
*  they're handcrafted by local people and there's an artisan craftsmanship. So while technology and AI [[01:17:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4634.32s)]
*  are going to completely reduce the cost of a lot of things and increase the production [[01:17:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4641.28s)]
*  and productivity of those things, one of the complementary consequences of that is that there [[01:17:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4646.48s)]
*  will be an emerging premium for human service. And I think that there will be an absolute burgeoning [[01:17:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4652.0s)]
*  and blossoming in the salaries and the availability and demand for human service in a lot of walks of [[01:17:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4656.959999999999s)]
*  life. Certainly there's all the work at home, the electricians and the plumbers and so on, but also [[01:17:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4664.24s)]
*  fitness classes, food, personal service around tutoring and learning and developing oneself. [[01:17:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4669.599999999999s)]
*  There's going to be an incredible blossoming, I think, in human service jobs and they don't need [[01:17:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4676.08s)]
*  to have a degree in poli sci to be performed. I think that there will be a lot of people that [[01:17:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4679.44s)]
*  will be very happy in that world. How do you see the differentiation the person makes free [[01:18:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4683.84s)]
*  Berg in doing that job versus the agent or the AI or whatever? Well, these are in-person human jobs. [[01:18:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4688.32s)]
*  So if I want to do a fitness class, do I want to stare at the tonal? This is what I'm asking you. [[01:18:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4694.4s)]
*  Yeah, I think that there's an aspect of it. Look, it's like you're Laura Piana. You talk about [[01:18:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4699.44s)]
*  the story of Laura Piana. Where is the vicua coming from? How's it made? Who's involved in it? [[01:18:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4707.2s)]
*  Don't stop, free Berg. I could give you truffle flavoring out of a can, but you love the white [[01:18:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4717.2s)]
*  truffles. You want to go to Italy, you want the storytelling. There's an aspect of it. [[01:18:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4721.92s)]
*  Yes. And I think that there's an aspect of humanity that we pay a premium that we do and [[01:18:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4725.04s)]
*  will look at. See crushes. I don't know how much stuff you guys buy an Etsy. I love buying from [[01:18:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4731.44s)]
*  Etsy. I love finding handmade stuff on my underwear for tech. You don't do you really? Yes, I do. [[01:18:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4735.12s)]
*  Yeah. Handcrafted. Yeah. Handmade. So I think that there's an aspect of this that, [[01:19:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4740.64s)]
*  in a lot of walks of life. I mean, I have so many jokes right now. I've never used that seat, [[01:19:06](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4746.0s)]
*  but I'm going to try it. Have you guys taken music lessons lately? You know, I started, [[01:19:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4752.64s)]
*  my kids do piano lessons. And so last year I started ducking in to do a [[01:19:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4756.56s)]
*  45 minute piano lesson with the piano teacher. There's just like a great aspect to paying for [[01:19:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4760.56s)]
*  these services to getting. Oh, here we go. You can play the harmonica. Really? I've just, [[01:19:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4764.8s)]
*  why do you have that? I want to play some Zach Brian songs and he's got a couple of songs I like [[01:19:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4773.04s)]
*  with a harmonica in them. So I just got a harmonica, my daughter and I have been playing [[01:19:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4777.04s)]
*  harmonica. Yeah. Are you teaching yourself? Let's hear it. What's your answer? I'll play [[01:19:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4780.24s)]
*  it next week. I'm deep in the laboratory. It's not a bit. It could be a bit, but I'll write your song [[01:19:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4785.36s)]
*  next week. The shy, he's a little shy. No, no, I'll do, I'll write a song for you. I'll do the, [[01:19:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4791.76s)]
*  the trials and tribulations of Donald Trump and I'll do a little Bob Dylan send up song for you. [[01:19:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4798.639999999999s)]
*  The most interview with, with Bob Dylan. I don't know what it was recently about how [[01:20:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4805.04s)]
*  that clip. Oh, that's amazing. That Bradley clip about magic. Yeah. Well, you know, [[01:20:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4813.679999999999s)]
*  some of those songs, I don't know how I wrote them. They just came out in the best. [[01:20:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4818.719999999999s)]
*  He's like, no, but I did it once. No, but I did it once. What an incredible, [[01:20:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4826.5599999999995s)]
*  that means something. Yeah. That's really grounding. It's really grounded. You understand [[01:20:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4831.04s)]
*  too soon. There is no chance of dying. Yeah. That's an incredible clip. All right. You guys want [[01:20:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4837.6s)]
*  to wrap or you want to keep talking about more stuff? We were at 90 minutes. Let me just say, [[01:20:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4843.2s)]
*  tell you something. I think there's going to be a big war. I think by the time the show airs, [[01:20:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4847.04s)]
*  Israel's incursion into Lebanon is going to get bigger. It's going to escalate. [[01:20:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4851.28s)]
*  And by next week we could be in a full blown multinational war in the middle East. And if I am, [[01:20:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4855.28s)]
*  you know, a betting man, I would bet that the odds are, you know, more than 30, 40% that this [[01:21:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4863.04s)]
*  happens before the election, that this, this conflict in the middle East escalates. Thank you [[01:21:08](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4868.16s)]
*  for bringing this up. I am not asking anybody to go listen to what I, my interview with Rogan. [[01:21:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4872.5599999999995s)]
*  But I will say this part of why I was so [[01:21:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4881.68s)]
*  excited to go and talk to him in a long form format was this issue of war is I think the [[01:21:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4887.44s)]
*  existential crisis of this election and of this moment. And I really do agree with you, [[01:21:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4894.08s)]
*  Freeberg. There is a non-trivially high probability, the highest it's ever been [[01:21:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4901.12s)]
*  that we are just bumbling and sleepwalking into a really bad situation we can't walk back from. [[01:21:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4906.96s)]
*  I really hope you're wrong. And here's the, here's the situation. I really hope you're wrong. [[01:21:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4914.56s)]
*  If Israel incurs further in, into Lebanon, going after Hezbollah and Iran ends up getting involved [[01:21:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4919.76s)]
*  in a more active way, does Russia start to provide supplies to Iran? Like we are supplying to Ukraine [[01:22:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4927.28s)]
*  today. Does this sort of bring everyone to align? Just to give you a sense, you know, of the scale [[01:22:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4935.2s)]
*  of what Israel could then respond with. Iran has 600,000 active duty military, another 350,000 in [[01:22:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4940.8s)]
*  reserve. They have dozens of ships. They have 19 submarines. They have a 600 kilometer range missile [[01:22:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4947.12s)]
*  system. Israel has 90,000, sorry, 170,000 active duty and half a million reserve personnel, 15 [[01:22:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4952.8s)]
*  warships, five submarines, potentially up to 400 nuclear weapons, including a very wide range of [[01:22:39](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4959.92s)]
*  tactical sub one kiloton nuclear weapons, small, small payload. You could see that if Israel [[01:22:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4966.32s)]
*  starts to feel incurred upon further, they could respond in a more aggressive way with what is, [[01:22:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4973.76s)]
*  you know, by far and away, you know, the most significantly stocked arsenal and military force [[01:23:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4981.6s)]
*  in the Middle East. Again, we've talked about what are these other countries going to do? What is [[01:23:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4989.68s)]
*  Jordan going to do in this situation? How is the Saudis going to respond? What is Russia going to do? [[01:23:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=4993.92s)]
*  Well, the Russia Ukraine thing, meanwhile, still goes on. And we saw in our group chat, one of our [[01:23:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5000.72s)]
*  friends posted, but Russia basically said any more attacks on our land, you know, we reserve all [[01:23:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5005.76s)]
*  rights, including nuclear response. That is insane. Well, you know, so just to give you a sense, [[01:23:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5012.0s)]
*  it's insane. How are we here? Yeah. So the nuclear bombs that were set off during World War II, [[01:23:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5017.44s)]
*  I just want to show you how crazy this is. Do you see that image on the left? [[01:23:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5026.32s)]
*  That all the way over on the left, that's a bunker buster. You guys remember those from Afghanistan [[01:23:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5033.6s)]
*  and the damage that those bunker buster bombs caused? Hiroshima is a 15 kiloton nuclear, and you [[01:23:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5038.32s)]
*  can see the size of it there on the left. That's a zoom in of the image on the right. [[01:24:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5045.52s)]
*  And the image on the right starts to show the biggest ever tested was a Tsar Bomba by the [[01:24:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5051.68s)]
*  Soviets. This was a 50 megaton bomb. It caused shockwaves that went around the earth three times. [[01:24:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5056.88s)]
*  They could be felt as seismic shockwaves around the earth three times from this one detonation. [[01:24:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5066.0s)]
*  Today, there are a lot of 0.1 to 1 kiloton nuclear bombs that are kind of considered these [[01:24:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5070.64s)]
*  tactical nuclear weapons that kind of fall closer to between the bunker buster and the Hiroshima. [[01:24:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5077.280000000001s)]
*  And that's really where a lot of folks get concerned that if Israel or Russia or others [[01:24:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5084.240000000001s)]
*  get cornered in a way and there's no other tactical response, that that is what then gets pulled out. [[01:24:48](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5088.64s)]
*  Now, if someone detonates a 0.1 or 1 kiloton nuclear bomb, which is going to look like a [[01:24:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5095.76s)]
*  mega bunker buster, what is the other side and what's the world going to respond with? [[01:25:00](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5100.88s)]
*  That's how on the brink we are. And there's 12,000 nuclear weapons with an average payload of 100 [[01:25:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5105.2s)]
*  kilotons around the world. The US has a large stockpile. Russia has the largest. Many of these [[01:25:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5111.84s)]
*  are hair trigger alert systems. China has the third largest. And then Israel and India and so on. [[01:25:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5119.12s)]
*  It is a very concerning situation because if anyone does get pushed to the brink that has a [[01:25:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5127.12s)]
*  nuclear weapon and they pull out a tactical nuke, does that mean that game is on? And that's why I'm [[01:25:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5132.32s)]
*  so nervous about where this all leads to if we can't decelerate. It's very scary because you [[01:25:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5136.4s)]
*  can very quickly see this thing accelerating. I am the most objectively scared I've ever been. [[01:25:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5141.04s)]
*  And I think that people grossly underestimate how quickly this could just spin up out of control. [[01:25:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5146.08s)]
*  And right now, not enough of us are spending the time to really understand why that's possible. [[01:25:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5152.96s)]
*  And then also try to figure out what's the offering. And I think it's just incredibly [[01:25:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5159.84s)]
*  important that people take the time to figure out that this is a non-zero probability. And this is [[01:26:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5165.44s)]
*  probably for many of us the first time in our lifetime where you could really say that. [[01:26:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5171.44s)]
*   Well, I think Friedberg's right that we're at the beginning stages of, I think what will soon [[01:26:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5175.44s)]
*  be referred to as the Third Lebanon War. The first one was in 1982. Israel went into Lebanon and [[01:26:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5180.24s)]
*  occupied it until 2000. Then it went back in 2006, left after about a month. And now we're in the [[01:26:27](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5187.84s)]
*  Third War. It's hard to say exactly how much this will escalate. The IDF is exhausted after [[01:26:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5194.48s)]
*  the war in Gaza. There's significant opposition within Israel and within the armed forces to [[01:26:42](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5202.96s)]
*  a big ground invasion of Lebanon. So far, most of the fighting has been Israel using its [[01:26:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5209.44s)]
*  air superiority of roaming firepower against Southern Lebanon. And I think that if Israel [[01:26:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5216.32s)]
*  makes a ground invasion, they're giving Hezbollah the war that Hezbollah wants. I mean, [[01:27:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5224.639999999999s)]
*  Hezbollah would love for this to turn into a guerrilla war in Southern Lebanon. So I think [[01:27:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5230.24s)]
*  there's still some question about whether Netanyahu will do that or not. At the same time, [[01:27:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5234.799999999999s)]
*  it's also possible that Hezbollah will attack Northern Israel. Nasrallah has threatened to [[01:27:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5240.64s)]
*  invade the Galilee in response to what Israel is doing. So there's multiple ways this could [[01:27:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5250.240000000001s)]
*  escalate. And if Hezbollah and Israel are in a full-scale war with ground forces, [[01:27:37](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5257.4400000000005s)]
*  it could be very easy for Iran to get pulled into it on Hisbollah side. And if that happens, [[01:27:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5265.76s)]
*  I think it's just inevitable that the United States will be pulled into this war. So yeah, [[01:27:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5270.88s)]
*  look, I think we are drifting and we have been drifting into a regional war in the Middle East [[01:27:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5275.12s)]
*  that ideally would not pull in the US. I think the US should try to avoid being pulled in, [[01:28:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5281.84s)]
*  but I think very likely will be pulled in if it escalates. And then meanwhile, [[01:28:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5287.84s)]
*  in terms of the war in Ukraine, I've been warning about this for two and a half years, [[01:28:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5293.76s)]
*  how dangerous this situation was. And that's why we should have availed ourselves of every [[01:28:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5297.360000000001s)]
*  diplomatic opportunity to make peace. And we now know because there's been such universal reporting [[01:28:23](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5303.12s)]
*  that in Istanbul in the first month of the Ukraine war, there was an opportunity to make a deal with [[01:28:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5309.52s)]
*  Russia where Ukraine would get all this territory back. It's just that Ukraine would have to agree [[01:28:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5315.04s)]
*  not to be part of NATO, it would have to agree to be neutral and not part of the Western military [[01:28:40](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5320.08s)]
*  bloc that was so threatening to Russia. The Biden administration refused to make that deal. They [[01:28:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5324.72s)]
*  sent in Boris Johnson to scuttle it. They threw cold water on it. They blocked it. They told [[01:28:49](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5329.76s)]
*  Zelensky, we'll give you all the weapons you need to fight Russia. Zelensky believed in that. It has [[01:28:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5334.16s)]
*  not worked out that way. Ukraine is getting destroyed. It's very hard to get honest reporting [[01:28:59](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5339.04s)]
*  on this from the mainstream media. But the sources I've read suggest that the Ukrainians are losing [[01:29:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5344.64s)]
*  about 30,000 troops per month. And that's just KIA. I don't even think that's wounded that [[01:29:12](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5352.0s)]
*  on a bad day, they're suffering 1200 casualties. It's more than even during that failed counteroffensive [[01:29:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5357.92s)]
*  last summer that Ukraine had. During that time, they were losing about 20,000 troops a month. [[01:29:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5364.96s)]
*  So the level of carnage is escalating. Russia has more of everything, more weapons, more firepower, [[01:29:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5369.6s)]
*  air superiority, and they are destroying Ukraine. And it's very clear, I think that Ukraine, [[01:29:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5378.160000000001s)]
*  it could be in the next month, it could be the next two months, it could be the next six months. [[01:29:45](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5385.52s)]
*  I think they're eventually going to collapse. They're getting close to being [[01:29:48](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5388.72s)]
*  combat incapable. And in a way, that poses the biggest danger because [[01:29:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5392.320000000001s)]
*  the closer Ukraine gets to collapse, the more the West is going to be tempted to intervene directly [[01:29:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5395.92s)]
*  in order to save them. And that is what Zelensky was here in the US doing over the past week, [[01:30:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5401.2s)]
*  is arguing for direct involvement by America in the Ukraine war to save him. How did he propose [[01:30:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5407.2s)]
*  this? He said, we want to be directly admitted to NATO immediately. That was his request. And he [[01:30:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5413.84s)]
*  called this the victory plan. So in other words, his plan for victory is to get America to be [[01:30:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5420.4s)]
*  is to get America involved in the war and fighting it for him. But that is the only [[01:30:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5425.2s)]
*  chance Ukraine has. And it is possible that the Biden-Harris administration will agree to do that, [[01:30:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5429.44s)]
*  or at least agree to some significant escalation. So far, I think Biden, to his credit, has resisted [[01:30:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5435.84s)]
*  another Zelensky demand, which is the ability to use America's long range missiles and British [[01:30:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5441.76s)]
*  long range missiles, the Storm Shadows against Russian cities. That is what Zelensky is asking [[01:30:47](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5447.92s)]
*  for. Zelensky wants a major escalation of the war because that is the only thing that's going to [[01:30:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5452.16s)]
*  save him, save his side and maybe even his neck personally. And so we're one mistake away from [[01:30:56](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5456.24s)]
*  the very dangerous situation that Chamath and Freiburg have described. If a President Biden, [[01:31:04](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5464.48s)]
*  who is basically senile, or a President Harris, agree to one of these Zelensky requests, [[01:31:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5470.96s)]
*  we could very easily find ourselves in a direct war with the Russians. [[01:31:17](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5477.44s)]
*  The waltz into World War III is what it should be called. [[01:31:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5481.839999999999s)]
*  And the reason why this could happen is because we don't have a fair media that's fairly reported [[01:31:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5485.679999999999s)]
*  anything about this war. I mean, Trump is on the campaign trail making, I think, very valid points [[01:31:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5489.92s)]
*  about this war, that the Ukrainian cause is doomed, and that we should be seeking a peace deal [[01:31:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5495.599999999999s)]
*  and a settlement before this can spiral into World War III. That is fundamentally correct. [[01:31:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5501.599999999999s)]
*  But the media portrays that as being pro-Russian and pro-Putin. And if you say that you want peace, [[01:31:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5506.16s)]
*  you are basically on the take from Putin and Russia. That is what the media has told [[01:31:51](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5511.599999999999s)]
*  the American public for three years. The definition of liberalism has always been [[01:31:55](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5515.599999999999s)]
*  being completely against war of any kind and being completely in favor of free speech of all kinds. [[01:32:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5521.5199999999995s)]
*  That's what being a liberal means. We've lost the script. And I think that people need to understand [[01:32:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5527.76s)]
*  that this is the one issue where if we get it wrong, literally nothing else matters. [[01:32:14](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5534.8s)]
*  And we are sleepwalking and tiptoeing into a potential massive world war. [[01:32:20](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5540.88s)]
*  Pete Slauson Jeffrey Sachs said it perfectly. You don't [[01:32:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5549.68s)]
*  get a second chance in the nuclear age. All it takes is one big mistake. [[01:32:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5552.0s)]
*  Peter T. Leeson You do not get a second chance. And for me, [[01:32:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5555.04s)]
*  I have become a single issue voter. This is the only issue to me that matters. We can sort [[01:32:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5558.4s)]
*  everything else up. We can figure it all out. We can find common ground and reason. [[01:32:46](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5566.719999999999s)]
*  Should taxes go up? Should taxes go down? Let's figure it out. Should regulations go up? Should [[01:32:52](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5572.879999999999s)]
*  regulations go down? We can figure it out. But we are fighting a potential nuclear threat on three [[01:32:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5578.639999999999s)]
*  fronts. How have we allowed this to happen? Russia, Iran, China. You cannot underestimate [[01:33:07](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5587.12s)]
*  that when you add these kinds of risks on top of each other, something can happen here. [[01:33:16](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5596.56s)]
*  And I don't think people really know. They're too far away from it. There are too many generations [[01:33:22](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5602.4s)]
*  removed from it. War is something you heard maybe your grandparents talk about now, and you just [[01:33:26](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5606.4s)]
*  thought, okay, whatever. I lived it. It's not good. [[01:33:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5611.44s)]
*  Peter T. Leeson Tomas, you're right. I mean, during the [[01:33:36](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5616.08s)]
*  Cuban Missile Crisis, all of America was huddled around their TV sets, worried about what would [[01:33:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5618.879999999999s)]
*  happen. There is no similar concern in this day and age about the escalatory wars that are happening. [[01:33:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5623.839999999999s)]
*  There's a little bit of concern, I think, about what's happening in the Middle East. There's [[01:33:50](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5630.879999999999s)]
*  virtually no concern about what's happening in Ukraine, because people think it can't affect them, [[01:33:53](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5633.2s)]
*  but it can. And one of the reasons it could affect them is because we do not have a fair [[01:33:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5638.48s)]
*  debate about that issue in the US media. The media has simply caricatured [[01:34:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5642.799999999999s)]
*  any opposition to the war as being pro-Putin. So I would say that when every pundit and every [[01:34:09](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5649.04s)]
*  person in a position to do something about it says, you have nothing to worry about, [[01:34:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5658.16s)]
*  you probably have something to worry about. And so when everybody is trying to tell you, [[01:34:25](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5665.44s)]
*  everybody, that this is not a risk, it's probably a bigger risk than we think. [[01:34:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5671.2s)]
*  Yeah, they're protesting too much. How can you say it's not a risk? [[01:34:38](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5678.4800000000005s)]
*  Me think thou doth protest it. [[01:34:41](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5681.44s)]
*  Right. [[01:34:43](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5683.52s)]
*  All right. Love you boys. Bye-bye. [[01:34:44](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5684.4800000000005s)]
*  I'm going all in. [[01:34:54](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5694.96s)]
*  And instead, we open source it to the fans, and they've just gone crazy with it. [[01:34:58](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5698.0s)]
*  Love you, Westies. [[01:35:01](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5701.84s)]
*  The queen of Kinloch. [[01:35:02](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5702.64s)]
*  I'm going all in. [[01:35:03](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5703.84s)]
*  What? [[01:35:05](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5705.84s)]
*  Besties are gone. [[01:35:10](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5710.72s)]
*  I'm going 13. [[01:35:11](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5711.76s)]
*  That's my dog taking a notice in your driveway. [[01:35:13](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5713.28s)]
*  Sex. [[01:35:15](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5715.4400000000005s)]
*  Oh, man. [[01:35:18](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5718.400000000001s)]
*  My half-adash will meet me at the end. [[01:35:19](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5719.12s)]
*  We should all just get a room and just have one big huge orgy because they're all just [[01:35:21](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5721.12s)]
*  useless. It's like this sexual tension that they just need to release somehow. [[01:35:24](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5724.32s)]
*  What? [[01:35:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5729.12s)]
*  You're the bee. [[01:35:29](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5729.4400000000005s)]
*  Bee. [[01:35:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5730.400000000001s)]
*  What? [[01:35:30](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5730.96s)]
*  You're the bee. [[01:35:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5731.360000000001s)]
*  Where? [[01:35:31](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5731.92s)]
*  You're a bee. [[01:35:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5732.0s)]
*  Bee. [[01:35:32](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5732.56s)]
*  What? [[01:35:33](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5733.28s)]
*  Why didn't you get merged? [[01:35:34](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5734.4s)]
*  Besties are gone. [[01:35:35](https://www.youtube.com/watch?v=43Rd-y2xe84&t=5735.44s)]
