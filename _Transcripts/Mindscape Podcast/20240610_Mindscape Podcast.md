---
Date Generated: June 10, 2024
Transcription Model: whisper medium 20231117
Length: 4557s
Video Keywords: []
Video Views: 1329
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2024/06/10/278-kieran-healy-on-the-technology-of-ranking-people/

We claim to love all of our children, friends, and students equally. But perhaps deep down you assign a ranking to them, from favorite to not-so-favorite. Ranking and quantifying people is an irresistible human tendency, and modern technology has made it ubiquitous. In this episode I talk with sociologist Kieran Healy, who has co-authored (with Marion Fourcade) the new book The Ordinal Society, about how our lives are measured and processed by the technological ecosystem around us. We discuss how this has changed how relate to ourselves and the wider world.

Kieran Healy received his Ph.D. in sociology from Princeton University. He is currently a professor of sociology at Duke University, and a member of the Kenan Institute for Ethics. As an undergraduate at University College Cork he won the Irish Times National Debating competition. He has a longstanding interest in data visualization.
Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll

#podcast #ideas #science #philosophy #culture
---

# Mindscape 278 | Kieran Healy on the Technology of Ranking People
**Mindscape Podcast:** [June 10, 2024](https://www.youtube.com/watch?v=EnUiR_b2Zrw)
*  Hello everyone, welcome to the Mindscape Podcast. I'm your host Sean Carroll. I
*  wanted to start today's podcast by reading a paragraph from a new book
*  called The Ordinal Society by Marion Fourcade and Kieran Healy. So it goes
*  like this, the idea of modernity has long been seen as having two contending
*  aspects. On one side, the side of social organization, is the domain of
*  rationalization and control. This is the modernity of bureaucracy, science,
*  technology, and planning. It is the technocratic, sans-simonian vision of a
*  society run on rational principles and devoted to the elevation of humanity in
*  the abstract. Here the administrative task of modern organizations is to know
*  and manage their subjects. On the other side, the side of the individual, is the
*  domain of experience and expression. This is the modernity of the romantics,
*  of the full and authentic realization of the self and all its powers. Here the
*  existential task of modern individuals is to know and create themselves. I like
*  this paragraph because you know there's a little bit of historical resonance
*  there, but also the contrast or the dilemma here is very real between the
*  organizational systems oriented view of the world and how that can bring about
*  tremendous real benefits versus the romantic individual, you know, ignoring
*  the system and going their own way. I think that for whatever reason in the
*  modern world we prefer to personally identify with the romantic individual,
*  but you know as we will talk about in this podcast, the modern world offers all
*  sorts of conveniences and services that are only available to us if we kind of
*  do agree to participate in the broader system. You know, I recently noticed
*  when you go to the Apple App Store and you want to download an app, they tell
*  you what information the app gathers about you, your location data, you know,
*  your information from other websites or whatever, and where it sends it to. So in
*  principle you could just not download any app that collected information about
*  you that you didn't want it to. I'm betting that in practice most people go
*  ahead and just download the app, right, because the app is useful. It's not like
*  there's no point to it. I bet that most people use Google Maps when they want to
*  go somewhere, even if that means Google knows where they're going. I've noticed
*  that Google Maps will sometimes tell me where I parked my car. That's on the one
*  hand a little weird that Google's keeping track of where I parked my car,
*  on the other hand super convenient because I am often not very good at
*  keeping track of where I parked my car. So today's guest is Kieran Healy. He's
*  one of the co-authors of the new book, and the idea is the ways in which the
*  modern world not just keeps track of us, but classifies us, right? The
*  ordinal society is one in which people are characterized and ranked in all
*  sorts of different ways. Ranking people has been something that has been going
*  on forever, of course, but technology has enabled it to happen at an enormous
*  rate, from very simple things like a credit score to hyper finely divided
*  ways like what ads you get served up when you go to Amazon or Google or
*  YouTube or what have you. And these forces are somewhat invisible but all
*  pervasive and apparently they really matter to our lives. You know, a lot of
*  people are, when you buy a new dishwasher, you buy a smart dishwasher and it sends
*  information to the dishwasher company about how often you're washing your
*  dishes. And where do we draw the line? Where do we decide how much convenience
*  is worthwhile versus how much individuality and romantic experience is
*  worthwhile? I think these are questions we're gonna have to be struggling with
*  more and more because these systems of surveillance and classification are not
*  going away anytime soon. So let's go.
*  Here in Healy, welcome to Blindscape Podcast. Delighted to be here. I think we gotta
*  start with a question you will find embarrassingly simple. What is the word
*  ordinal mean to you? You have it in the title of your book.
*  Yes, I know. And I get, you know, it's funny, I've gotten kind of when I've been
*  talking about the book online or to other people, you know, immediately the
*  mathematicians and the physicists come out and I get a lot of, you know, quite
*  abstruse jokes. Right, what does this mean? Yeah, so in this case, it's
*  fundamentally focused on the idea of ranking, although it's twofold, right? So
*  first of all, and most importantly, it's the idea that, you know, we live in a
*  world where the pairing of kind of massive data sets with various
*  processes, you know, algorithmic, broadly conceived, statistical, you know,
*  mathematical written in code of some kind, have made inroads into every social
*  institution. And techniques of optimization and data collection are
*  deployed to kind of streamline and organize processes across those
*  institutions, a whole wide range of things. And, and the way they work is to
*  is to take kind of information or data in computationally and spit out scores
*  and especially rankings, orderings out the other side. And so fundamentally,
*  the idea of ordinality or an ordinal society is, is one that's based around
*  and justified by the idea of kind of measurement and ranking. I will say too
*  that there's a second piece to it a little bit, which comes from Marion
*  Foucault, like, who co-authored this book with me, you know, is French.
*  Originally, she teaches in Berkeley now, but in French, the word for computer is
*  ordinateur. And, and, and the reason that it is that word is when in in 1956 or so,
*  the IBM launched the IBM 650, which was its first kind of really mass produced
*  machine, it surprised them how much the demand, you know, for it was amongst
*  businesses. And when IBM France came to sell it, they had to, they had to decide
*  what to call it, like what to call this class of device. And the natural choice
*  would have been calculateur, which is the direct calculation, you know,
*  direct translation of computer. But they had a they consulted in a very French
*  way, you know, you have to be careful about what word things are going to call
*  they consulted with a guy, Jack Perry, who is a professor of Latin at the Sorbonne.
*  And, and he objected, and he said, What about ordinateur? It's a he said, it's a
*  correctly formed word, it's in the dictionary. And, and he thought, and it's
*  ultimate root is to do with ordination, the word ordination, like a religious
*  sense of a God who brings order to the world. And he says, but that theological
*  usage isn't frequent. So you could call it an ordinateur. And, yeah, and so that
*  was his, that's what IBM picked. And so the idea of kind of calculation as a as
*  an ordering in the ordinality as an ordering in the in the kind of just
*  ordinary mathematical sense of first, second, third, fourth, but then also as a
*  device that that brings order to the world. That's what that's what we have in
*  I love the idea of Google consulting a Latin professor before, you know,
*  very much so. So, but of course, we have ranked people and classified them all the
*  time. I mean, you and I are academics, we live in a world where half of our time is
*  spent deciding who's better than, you know, who else so you're specifically
*  focusing on how much better we at it, we are at it now because exactly of the
*  computer age,
*  or how much more pervasive it is. Yeah, the one of the things we do want to kind
*  of emphasize in the book is that it's not the case that like the fact of, of
*  ranking and ordering people is a sort of fundamental aspect of human social
*  organization. And we do that whenever there's differentiation, you implicitly
*  have the chance of some sort of ordering or ranking of classes or categories of
*  people comes out. So that is not new at all. In fact, it's kind of an endemic
*  feature of just how human societies are organized. And then there's also a long
*  history of kind of devices and methods and techniques that we have for for
*  doing this, that goes all the way back, there's lots, you know, to the very, you
*  know, the beginnings of all the way back to double entry bookkeeping, or, you know,
*  that bring a an ordering of things to businesses to sort of mundane devices
*  like the filing cabinets or the card index in the 19th century, which really
*  were kind of revolutionary in their way. But what's new now is, and what's really
*  sort of transformed, not just in sort of scale, but also in scope over the last
*  50 years or so is that this, the ability to do this has both become much more
*  fine grained, and, and, and much more widespread, that the scope that we can
*  it, the degree to which we can sort of apply these ideas and processes is sort
*  of much wider, a whole range of kind of forms of social life that we're just not
*  within reach of any kind of measurement, let it certainly not any kind of real
*  time measurement has really expanded, and then the degree of kind of granularity
*  that has also been transformed as well.
*  I will mention for those of you who are just listening over audio that Karen in
*  the background has an original Apple Macintosh computer here, and is it a
*  working model?
*  Oh, absolutely. It works. Yeah.
*  So when we talk about the history here, you know, you and I both lived through a
*  lot of it anyway, and you know,
*  yeah, no, we're in that, we're in that sort of, I think, just about in that
*  intermediate generation that is cursed to explain computers both to people older
*  than us and people younger than us.
*  There are worse curses than that.
*  And so just so the audience gets in mind what we're talking about here, it's not
*  just rankings that you're concerned with in the book.
*  I mean, it's just the very, it's kind of a classification ability as well.
*  Yeah.
*  Yeah. Yeah.
*  So on those two things are very kind of closely connected, right?
*  That there's two, two processes to before you can rank things, you, you, you must
*  name them first, right?
*  And so there's, so there's a process of classification that, that takes place,
*  which is sort of identifying categories and, and deciding which things fall into
*  which, which categories.
*  So the sort of nominalizing thing that this, this is, this is an instance of
*  that. This, this, this other thing is an instance of this, of the second thing.
*  So that's sort of, you know, so we say, as we say in the book, you know, machines
*  classify because people do in the same way as them and they rank because, because
*  people do.
*  And but there's always this kind of there's always a very strong tendency then
*  for, for, for nominal classifications, which should be unordered or which, you
*  know, which are, which are not, which are often unordered to turn into rankings
*  and, and, and then positioning people within those things.
*  You know, Plato famously said that one of the jobs of philosophy is to carve
*  nature at its joints.
*  Right.
*  So we're handing that job over to our computers now in some way.
*  Yeah.
*  I mean, to a large degree and certainly kind of the, the, the one of the, we're
*  handing it over to them and they're extremely powerful and fast and, and the
*  legitimacy that we invest or that these things, these systems often come to, to
*  have drives in part from this idea that they are in fact, you know, that this is
*  a real, that you're really picking up on something real in the world and that
*  you're doing it with a degree of precision and accuracy that hasn't been,
*  hasn't been possible in the, in the past.
*  And of course we know like anybody who's worked with data of any kind in a, in a
*  quantitative form, it is going to be well aware of just how difficult it is to kind
*  of cleanly collect information that truthfully reflects the way things are.
*  And then with social data in particular, there's, you know, all kinds of additional
*  complexities about the degree to which you're imposing your, your framework.
*  When I, in talks with this stuff, I do have to go back to the carving nature at
*  the joints thing, I have a, I sometimes refer to that, to that idea.
*  And I have a little slide from an American cookbook that I have and a French one
*  showing the very different cuts of beef that exists in different, in France and
*  the United States.
*  And so, you know, even, you know, butchers carve nature at the joints quite
*  differently.
*  So there's, you know, there's a, so there's heterogeneity, even if ultimately
*  there's still a cow under there.
*  There are, there are different ways to cut it up.
*  I don't know if you noticed just today, and I think it was in Vox, they had an
*  analysis of the U S house of representatives.
*  And, you know, to your point of the data are hard to sometimes get and therefore,
*  you know, you can get best results.
*  But also we have the categories that we testify to, that we claim we're members
*  of, and then we have the categories that are actually born out by our actions.
*  Right?
*  So in this article, they went through all the voting patterns of different members
*  of Congress and grouped them into eight groups on the basis of affinity of that,
*  of that voting.
*  So on the flip side, you can actually reveal categories that were there all
*  along, but we didn't mention them.
*  Yeah.
*  Yeah.
*  And, and that's, that's one of the main sources of the kind of power and
*  legitimacy of these kinds of classifications and methods of data
*  collection and analysis, because like I say, for, for the longest time,
*  organizations of all kinds, whether it's businesses or most, or in the longer
*  term, the state have been very interested in, in, in discovering information about
*  either the customers that they have or the, the citizens that make up or the
*  people who they, whom they govern.
*  And, but it's, it, but it turns out, you know, for a long time, it was extremely
*  difficult to do this in any kind of, reasonable, at any kind of reasonable speed.
*  And so you have a census every 10 years, or you, maybe you collect sort of sample
*  surveys and indeed the idea of statistics, the word stat in there is closely related
*  to the, to the state as a, it's, you know, it's, it's information about a population.
*  The promise and the, of, of these new methods is that with the expansion of all
*  of these methods of data collection, initially kind of on the desks and then
*  ultimately in your pocket of, you're getting a record increasingly of individual
*  and social activity that isn't, that isn't just dependent to the promises that isn't,
*  it isn't just about kind of asking people what it is they think or what it is that
*  they, you know, how it is that they would want to want to be classified.
*  You also get this essentially, the promise of essentially behavioral data about
*  people, which you want to say is kind of more truthful.
*  And, and so that leads immediately to this idea that there's a, you know, at the
*  level of the classifiers, a lot of legitimacy associated with, look, I'm capturing
*  what you're actually doing.
*  You know, if I ask you how many steps you walked today, you might tell me one
*  number, maybe you're bad at guessing it, or maybe you prefer to think it was a
*  little higher than it is, but your, but your watch on your wrist knows.
*  So that, and so that, that behavioral data is both very valuable and it does kind of
*  capture something that's much more accurate in some sense about what people
*  are actually doing, but then it also provides this kind of tremendous legitimacy
*  to the classifications that you develop from it.
*  And, and it, and it introduces the possibility of saying, well, you know, the
*  things that are, that, that flow from you being in one of these categories are
*  really, you know, your own fault or, or, or your own virtue, depending on what,
*  you know, if you're well classified, you experience it as being kind of a virtuous
*  and sort of sense of that, you know, you're correctly, you're correctly classified.
*  And if you're in a, if you're in a sort of poor, if you're in a poorer category,
*  the, the idea is that then you're to blame for your own, you know, for your
*  own social situation.
*  Well, there's, there's definitely an idea lurking in the background of the book.
*  I mean, maybe you say very explicitly, and I just sort of glossed over, but we,
*  we have an idea in the modern liberal world that we forge ourselves, right?
*  That we create who we are and we have an image of ourselves and maybe we don't
*  always live up to it, but okay, we're trying, you know, good for us.
*  And what, what you're driving home is that every corporation, you know, Amazon
*  and Apple and Facebook and whatever, ever has an image of us.
*  Like they know who we are in maybe a very different way.
*  And it's disconcerting to think both that they have that and that it's
*  not who we think we are.
*  Yeah.
*  And, and also, and then the, and then there's that point where those two things
*  coincide, right?
*  And, and so that the, so, so yes, like one distinctive feature of, you know,
*  modernity of the idea of existing in the world, kind of, you know, that we're in
*  now is, is the idea that people are, that individuals are kind of autonomous agents
*  with their own preferences and rights, who make their own decisions in the world,
*  who are going about sort of choosing to do things and are kind of empowered,
*  active, agentic is the word often that sociologists will use, you know, imbued
*  with this kind of sense of look, a busy little person going around and, and, and,
*  and, you know, making their own choices.
*  And, and then on the other hand, you have this, this idea of kind of that, this,
*  this sea of recorded information about us yields this sort of set of digital
*  traces that produce this kind of shadow of ourselves, a data double of ourselves, if
*  you like, that that's a phrase that Dan book is a historian coins that, that, that
*  kind of represents us truthfully in some sense.
*  And, and that, and that kind of organizations can know about us.
*  And so our sense of agency or sense of being a kind of active person in the
*  world is very closely bound up with our feelings of authenticity, like a being
*  exactly true to ourselves, you know, this kind of romantic conception of, of being,
*  of being true to ourselves.
*  But then the measurement and the representations in, in numbers and records
*  that exist of us is very closely connected to the, to sort of our need to be
*  authenticated, you know, formally by organ and those two processes kind of coincide
*  that, you know, the, the, the world we're in, kind of on the one hand, you're
*  enjoined to be really yourself in the, you know, at the authenticity sense.
*  But then also there's organizations are very concerned to know whether you're
*  really who you say you are that is in the, in the sense of kind of that, that,
*  that it's necessary that you be authenticated as you as an identity rather
*  than as somebody, you know, as, as a, as a, have somebody impersonating you or,
*  and so on.
*  And maybe the scale of this kind of operation makes it hard for people to
*  visualize what's going on.
*  I mean, if I worked at Amazon, I mean, clearly somewhere buried in the bowels
*  of a data center is some list of correlations of all the things I've ever
*  purchased or shopped for or whatever, but could a person working at Amazon sit at
*  a terminal and call up a profile of somebody?
*  It seems impractical.
*  There's a lot of customers out there.
*  There are a lot of customers out there.
*  Yeah.
*  And that's, I mean, I ultimately, they probably could, whether they're, you
*  know, somebody can that that's there.
*  I mean, the, the, the, it is true though, that sort of the, it's not a question.
*  Most of the time organizations are not specifically interested in you or me.
*  Right.
*  We, you know, we're not, we're not particularly interesting or important
*  enough and so, which is one of the reasons perhaps that you're, you know,
*  your Amazon recommendations might be weird or, you know, or governed by other
*  things, it's not, you know, one promise of all of this stuff is that, that, that
*  again, speaking to the language of kind of personal authenticity and tailoring
*  that everything could be personalized to you and that the recommendations that
*  Sean Carroll gets on Amazon will be, would just be perfect.
*  But then it's very common for us to have this experience of like saying, Oh, I've
*  been an Amazon customer or a customer of some other similar organization for a
*  couple of decades and they recommend these things to me and I don't know why.
*  I get them.
*  So again, this is the, the actual kind of, the demands of doing this
*  practically are quite, are quite strong.
*  Organizations know and very strongly feel that they should be collecting
*  this kind of level of granular data about you and they will boast sort of
*  internally or they will, they will organize themselves.
*  We call this kind of the data imperative.
*  Like they, we, they know that this is something they should be doing and, and
*  there's a whole infrastructure, there's a whole set of occupations of people who
*  tend data lakes and who manage, you know, data infrastructures about, about
*  individuals and as Matthew Cieglowski has said, you know, the whole, the whole
*  imagery of that, the metaphorical imagery of it is like a kind of accident waiting
*  to happen, you know, this, this, this, this data lake is dammed up behind a, a
*  barrier that could crack at any time or be overflowed and you get a, you know,
*  released into the world.
*  So it's, so on the one hand, it's very difficult in practice to, to get that kind
*  of granularity and ease of access to data about a particular person, have it be
*  useful.
*  On the other hand, there are the leading edge of this or the best institutionalized
*  versions of these scores really do exist and are used all the time.
*  The credit score is the most obvious one where you have in the United States, where
*  you have exactly that kind of a single number that characterizes your behavior in
*  a, in a, in a, in a way that you are sort of morally responsible for, you know, that
*  reflects your actual behavior when it comes to paying your debts or not.
*  And that any shop assistant can call up and decide whether to make, you know, you
*  a, a, a store credit offer or something like that.
*  Or can, and, and, and, and who's, who's initial usage in relatively restricted
*  circumstances has blossomed out into kind of much like the driver's license, you
*  know, becomes an effectively a national identity card, a credit score becomes a
*  gateway to, to having a harder or easier time in areas where it was never really
*  initially designed to be applied at all.
*  Well, let's, this is, yeah, this says so many juicy things to talk about here that
*  we've leapt ahead, but you do open the book with some history and it's, it's
*  fascinating, you know, in the halcyon early days of computers and the internet
*  and so forth.
*  The expectations of where these capacities would go were very different
*  than where they ended up ending up.
*  Yes, very much so.
*  I mean, there's this period beginning, you know, the prehistory of this in the, in
*  the 1960s and seventies when computing is, is as we know it is kind of becoming
*  established and just getting off the ground is this strange fusion on the one
*  hand of kind of what we think of as the more Dr.
*  Strangelove almost elements of, you know, computers come out of the war of code
*  breaking of, of defense systems and, you know, command and control methods for
*  missiles and, and all of that kind of stuff.
*  And at the same time, really from the beginning, you also have this kind of like
*  hacker culture amongst engineers who want to tinker and experiment and mess around
*  with, you know, in that, in that sort of familiar kind of scientifically sort of
*  let's see, let's push this and see where it can go.
*  That's quite flat and sort of libertarian in its way, you know, that where people
*  just want to be left alone and mess blue sky research type stuff, just want to be
*  left alone and do their thing.
*  And as, as computers take their kind of modern form through the hobbyist era of
*  the 1970s into their kind of expansion into business and society at large in the
*  1980s and 1990s, those two tendencies kind of continue to coexist.
*  And, and, and so by the nineties, when the internet and the worldwide web in
*  particular becomes kind of starts to is developed and becomes widely available as
*  a protocol, the web, there is this kind of, that's the sort of high watermark in
*  a lot of ways of excitement about the, the kind of pure freedom associated with just
*  setting out on your own, setting up your, your website, you know, you know, these
*  homestead dreams we call them, you know, and that, that language of kind of digital
*  homesteading, Howard Brian Gold was a, you know, use that term at the time.
*  People just kind of, this is a place where we can be free of all of the, in
*  effect, all of the, of the world of ranking and of the world of, of local status and
*  of the, the suffocating kind of what John Perry Barlow calls the weary giants of
*  flesh and steel, right?
*  That, that, you know, where did the sort of, they had this image of, of, of
*  cyberspace sort of being a kind of free for all, a new frontier where the, the,
*  the dead hand of kind of post-war suburban industrial society would no longer touch
*  you and you could just be yourself again, the, again, the romantic image of, of a
*  homestead are empowered by technology.
*  And that was really kind of the beginning of, yeah, that's where we started a very
*  different kind of a set of associations having to do with what this new
*  networking technology, what this new, these new protocols would enable.
*  Well, and it's very common that people trying to predict what the impact of a
*  new technology is going to be, get it wildly wrong.
*  And, you know, maybe it's just because of wishful thinking or whatever, but
*  looking back on examples of this and with some sociological wisdom in the
*  background, you know, are there systematic ways that people get these
*  futuristic scenarios wrong or should we be better at predicting?
*  Is there some equilibrium we're always going to go to?
*  Yeah.
*  I mean, as, as, as the, as the kind of conventionalism goes correctly, there's
*  you know, nothing defines an era better than its vision of the future.
*  And, and, and, and, and there are moments when, yeah, the sense of kind of a set
*  of possibilities that existed and then were in some sense closed off or that's
*  not how things turned out.
*  It's, it's extremely, it's, it's, it's, it's extremely common.
*  It's a common story.
*  It is a very common story.
*  And the main thing that happens, I suppose, is, you know, people project
*  their own desires about what an ideal world would be onto whatever the sort
*  of social change, often a technological change, but not always, you know, what
*  that seems to enable.
*  And, and then as it sort of, as it, as it goes on and things don't quite work out
*  that way, one of the things that can happen is that the initial, especially
*  for the sort of utopian visions of things, there can be a kind of immense
*  disappointment amongst the utopian vanguard with everyone else and their failure.
*  The rest of the world let us down.
*  Yeah, I think that's a very common feature.
*  Sort of revolutionaries end up with kind of a disappointment verging on contempt
*  for the peasants that they have liberated.
*  And, you know, one of the things that happened in the, in the development of
*  the worldwide web was this, was this transition to, from the kind of homestead
*  era, people sort of said, well, this is great.
*  I love being online.
*  I love talking to my friends.
*  I love, I love being able to, you know, be in touch with people who are like me.
*  I didn't know there were often, you know, people just like me and lots of them.
*  Then I can, you know, that, that really was a kind of liberating feature of
*  these kinds of technologies.
*  However, I would, I don't want to run my own website or I would rather not
*  administer my own servers or, you know, could you just, I need to find people
*  more quickly and more effectively.
*  Can someone take care of that for me?
*  And there is a, there is a sort of tendency to think, and this is something
*  that's, it's, it's out in the world, but it's also kind of a feature of kind of
*  social criticism of, and theorizing about kind of the internet.
*  There is this tendency to think that the, that the kind of much more suburbanized,
*  centralized, you know, perhaps hierarchical internet that we ended up with was
*  imposed on people very much against their will.
*  It was certainly imposed on some people against their will, the original
*  homesteaders, but a lot of it was very much kind of demand driven and people,
*  where people kind of preferred the convenience of somebody else taking care
*  of these things for them in order to get what they wanted, which was often the kind
*  of sheer sociability, but not all of the associated kind of, you know, system
*  administration, and they would prefer people to take care of that.
*  And so it is, it's tempting to think that, you know, oh, we could have had nice
*  things, but then the corporations came along and, and, and sort of made this world
*  terrible for us.
*  Now it's not like, it's not that there's nothing to that critique, but it is the
*  case that, you know, people do want different things.
*  And, and one of the things people really wanted was, was convenience and the
*  ability to just get to the kind of fun social part, which, which in part led to
*  the concentration of infrastructure that we kind of now have with a small number of
*  companies and platforms facilitating just that sort of thing.
*  And there were many cases where, you know, companies tried to impose their way of
*  doing things on, on an individual and failed.
*  And, and we have this a lot of, a lot of failed giants in the first dot-com era
*  and, and afterwards.
*  So it's not that people are duped, but it's a more complicated process because on
*  the one hand, people, companies are trying to guess what people want.
*  But on the other hand, people that are always tend to tend to kind of overflow or do
*  things with technologies that, that the, that the people seeking to kind of run
*  them don't expect a lot of the time.
*  Well, clearly we're at another moment right now with LLMs and artificial
*  intelligence, where there's a new set of utopians coming in to promise us things.
*  And so I'm just trying to figure out like, how do we avoid making the same
*  mistakes again?
*  Clearly one feature of humanity is that there will be a bunch of rapacious
*  capitalists or whatever the version of, you know, people who want to accrue
*  power to themselves.
*  And on the other hand, there's going to be a large number of people who will vote
*  for convenience over freedom every time.
*  And, and so does that help us guess what kind of future AI will bring about?
*  I think that there's a lot of similarities to, I mean, open AI is its own,
*  or open AI, the specific company, but the large language models and artificial
*  intelligence generally are, are its own, is its own sort of technology with its
*  own distinctive features.
*  And so nothing, things don't, things don't happen exactly the same way.
*  But, but the way that, the way that things are rolling out with a lot of this
*  stuff is, is quite similar to things that have happened, things that have
*  happened before.
*  And so we get sort of, one of the, one of the main ways this tends to happen as
*  that this transition to, to, from, from a world of initial technology with
*  seemingly infinite possibilities to one where, you know, there's a, there's a
*  smaller group, where those possibilities seem to narrow and then we're stuck
*  with things that, you know, we have difficulties with is that the sort of
*  the initial technology really is amazing and delightful and, and, and astonishing
*  to people.
*  And I think, again, this is sort of something that's easy to underplay.
*  If you're a cranky social critic, who's, you know, who's sort of just sick of
*  that, that, you know, we get, we, we start with somebody, you know, someone
*  our age might think of the first time that they used the worldwide web or
*  first time that they saw a webpage load.
*  If in my personally, in my case, it was as a, as an undergraduate in my, in my
*  friend Owen's physics lab, he was a master student and they had a deck alpha
*  running, running NCSA mosaic, and we downloaded pictures of Mars from the,
*  from the JPL and like, we didn't have any, we didn't have any reason.
*  I didn't have any reason to, I was a social science student.
*  I didn't have any reason to, I didn't need pictures of Mars, but just the
*  fact that you could do it, that there was this, you could talk to this computer
*  in Pasadena and it would serve up these, these, these things to you.
*  You know, that was incredible.
*  And then similarly, you know, a decade or a decade later, it's, you know, you
*  have a, a phone in your pocket that can render a map of your current location
*  and show you things around.
*  And it's just, you're just holding it.
*  That's, that's amazing.
*  And a decade after that, you take this, a descendant of that phone out of your
*  pocket and you touch the buttons and you can summon a car to take you wherever
*  you want to go.
*  And, and now it's kind of like, oh, you know, you, you take that same device out
*  of your pocket and you ask it a question and it speaks to you or it can generate
*  sort of texts.
*  So, you know, I don't underestimate at all or discount that, that degree of kind
*  of delight, something else will be this in another 10 years, you know, something
*  else will have that effect on us.
*  Um, now how does, how do those things kind of play out then?
*  How does that, how does that moment become kind of the infrastructure that we,
*  that we end up with, uh, whether it's the web, the web or, uh, everybody in the
*  world who can afford a smartphone owning one or the, you know, the, the
*  platformized world of labor for Uber drivers, you know, which with all its
*  exploitative dimensions and undertones and the, you know, entrenched ratings.
*  And now again, with kind of artificial intelligence, well, the first thing that
*  happens is that we get given this for free as a gift, so to speak, uh, that
*  it's given away to us.
*  And that, and so one of the reasons that it's delightful is that it's sort of
*  given to us as a, uh, and, and as any sociologist or anthropologist will tell
*  you, gifts set up these expectations of, of a return.
*  And what we give in return is information about ourselves.
*  And, uh, and we give information about ourselves, our location, you know, or,
*  or behavior, uh, um, or who we're interacting with, uh, what we want to know.
*  Um, what we, and the questions that we ask and so on.
*  And it's from there then that, uh, these, these organizations then seek to take
*  that information and, um, and make it profitable or take that knowledge and
*  make the profitable and at the beginning of the, and the web is with the web,
*  especially that first stage with things like Google search.
*  And that was a real revelation.
*  Like it took a while for people to figure that out, that, that, that they,
*  you know, um, that the, that the, the digital traces and the logs of, uh, left
*  behind was actually kind of potentially tremendously, uh, valuable.
*  And, and so with open AI now, uh, and, and similar companies, the world of
*  large language models, um, yeah, the question is kind of, I would expect the
*  same sort of the thing that tends to keep happening is the same sort of
*  concentration of service provision amongst, you know, that you just get a
*  couple of competitors, you know, really not, maybe not directly competing, but
*  we, we, we saw that with, you know, smartphones, like with you just, you
*  have Apple and the Google Android platform and that's kind of it.
*  Um, and, and, and we, we see, we see it with these other platforms as well.
*  The thing that's distinctive about, um, the, the world of artificial
*  intelligence or one of the things that's distinctive about its most widespread use
*  cases is that they're, um, they're now kind of having, having trained themselves
*  on the free gift of everything that is the, the worldwide web and all its, all
*  its content that was available.
*  Um, now they're in the process of kind of emitting, you know, the effluvia of,
*  of AI generated output back into that environment.
*  Oh yeah.
*  It's not clear to me what's going, what's going to happen.
*  Um, because, because again, one of the things that, one of the things that
*  happened with, you know, a lot of the early, a lot of the sort of, you know,
*  the first 20 years of social activity on the web has gradually declined in terms
*  of its kind of public accessibility.
*  And there's still just as much social activity more than ever really taking
*  place broadly speaking online, but much of it has retreated either to with
*  platforms where you can't see unless you're, you know, or, uh, whether it's,
*  you know, with things like messaging or, or, or content, but, you know,
*  down to things as mundane as having a sub stack rather than a, a website, um,
*  being, um, in a discord or a Slack rather than, um, in a, in a web forum or
*  blog comments and so on, you know, and so the, if all that's left in public is
*  the sort of slop of, uh, uh, of, of AI output that might pose problems for,
*  um, uh, for this technology in the future.
*  Maybe, maybe I think we, we skipped ahead a lot to talk about this data collection
*  and its implications just because we all know that our data is being collected.
*  We've all seen Amazon serve up, uh, its recommendations, but you've thought about
*  this a lot more carefully than most of us.
*  I mean, what, what is your, um, uh, overview of the ways in which the
*  data is being collected?
*  Some of them are obvious, but probably some of them are less so to the people
*  who aren't thinking about it all the time.
*  Yeah.
*  There's a couple of different dimensions to this.
*  Like the, so the, what's happening?
*  There's, there's, there's such a volume of data that's available, uh, to, uh,
*  to, to, to companies, uh, now just because of the gradual expansion of kind of all
*  of these ways for monitoring and, and tracking individuals, um, that's often
*  kind of presented, um, just in terms of surveillance, let's say, you know, that,
*  that it's that, and that it's just people spying on you, but I think that sort of
*  tends to underestimate that degree to which kind of social life in general as a
*  whole is actually is taking place in these environments where you're being
*  kind of monitored.
*  So it's not, it's not quite that kind of, you know, it's not like street cameras,
*  although that's a part of it too, you know, like spying on, on, on a real world
*  social activity that's taking place and then kind of, you know, collecting data
*  about it, it's, it's more that the social life itself is now kind of, um, taking
*  place mediated through these technologies.
*  And that's tremendously kind of powerful and, uh, and, and a kind of
*  qualitatively different, um, qualitatively different feature of how the world is now.
*  So that, because there have always been, or for a long time, there have been kind
*  of specific sort of settings where that kind of, you know, whatever is happening
*  is being, is essentially happening through as a flow of numbers or as a flow of data,
*  uh, in things like financial markets, for example, you know, stock trading, but
*  usually, or for the first, you know, a hundred years of, uh, of, of technology
*  along these lines, those were tremendously specialized, uh, narrow, um,
*  environments, right?
*  That, that the idea of capturing kind of every conversation or every joke, uh, every,
*  uh, every sort of interaction seemed both kind of pointless and was impossible.
*  And so that's, that's changed.
*  So the breadth of data has really sort of expanded.
*  Um, then the, the, the degree to which kind of people, uh, that, that, that's
*  changed a couple of things.
*  And one is that at the level of individuals, um, it's, it's, it's changed how
*  people kind of think about themselves and their public, their public visibility or
*  their visibility to others.
*  Right.
*  And so there's a whole question, set of questions along, along those lines about
*  kind of how we think of ourselves as having an identity, um, uh, online.
*  And again, I think this, this stratifies quite a lot by, by age, probably.
*  Um, we know less about this than I would like actually, that, you know, that again,
*  there's a kind of naive, um, version of this that says, oh, there's old fuddy
*  duddies and there's digital natives.
*  Um, and, um, but often the digital natives, what makes them kind of native is not
*  their deep understanding of how these technologies work, but more that they're
*  kind of comfortable swimming around in this environment, like fish in the sea
*  without thinking too much about water and how it, uh, and how it works.
*  Um, so that's, so that's one set of issues.
*  And then the, and then on the other side, organizations, um, companies and states
*  have also been sort of transformed by what they're doing or what this data or
*  what they seek to do with this.
*  Um, and just to pick one kind of classic example, um, one thing that's happening
*  a lot with the kind of embedding of software and data collection devices in,
*  um, in everything is that, uh, it pairs very well with the kind of this sort of
*  broader logic of financialization.
*  Um, this idea that kind of what we're interested in doing, what businesses are
*  interested in doing is turning kind of every potential transaction into a stream
*  of, uh, of, of income, uh, and, uh, and that, uh, uh, a rent as economists would
*  call it, right.
*  That, uh, and so to think, you know, in practice, what does that mean?
*  Well, you know, in a, in a simpler way of doing things, if you buy something, the
*  transaction, you buy a refrigerator, uh, or a car or, you know, a tractor, uh, and,
*  um, you buy the thing and, um, and then you're done, right.
*  You, you, now you own the thing and, uh, maybe, yeah, and, and, uh, but, um, and
*  maybe, you know, maybe there, maybe the first step is to sort of think, well, uh,
*  if we, again, the, some of these things go back a long way, the company says,
*  well, we could, we could maintain a relationship by selling you a warranty
*  or by, um, or by giving you a loan, right.
*  To, to do it.
*  And so again, these ideas are not new in that sense, right.
*  That we have, we want, because what the company is interested in is sort of some
*  ongoing stream of income, um, that it can then turn around to its own shareholders
*  and say, here's the steady, you know, we don't have to, we know that we're going
*  to be getting this every month for the next five years from the customer with
*  the arrival of, um, data collection, you know, that now there's like a little
*  computer in your car or your fridge, uh, or your, or your tractor, then suddenly
*  this whole range of, uh, possibilities gets opened up, uh, that connect very
*  nicely with what things like financial markets are interested in.
*  Um, again, the simplest case is, well, now if we're, if we're lending, uh, you
*  know, if we've leased the car to, uh, or we've, we have a loan to, to, to you,
*  Sean, and you, uh, stop paying your, uh, your monthly fees, well, maybe we can
*  just kind of remotely turn it off.
*  Uh, and, um, and, and so this is not something that is, um, uh, happening
*  right now, but you see, you see Ford and others have filed patents, kind of
*  incorporate, you know, combining, um, a kill switch, uh, with, uh, with data.
*  And you just connect that to the financial records and you just like, well,
*  you know, you, you were, and so you could cut off your car in the same way that
*  you could cut that your cable service could be cut off, uh, something that we
*  just take for granted if you stop, if you stop paying every month, um, the next
*  step up from, from that would be, well, how good a driver are you?
*  Um, and you're, you know, your car knows much more about that now in the past to
*  get car insurance, uh, you're the, you might get asked a polite series of
*  questions, you know, uh, you will buy, by an insurance agent saying, you know,
*  is how much driving do you do?
*  Uh, what kind of driving?
*  Um, and, and then a couple of crude measures of, um, predictors essentially
*  of, uh, you know, are you over 25?
*  Uh, are you know, are you a man or woman?
*  Um, which part of the country do you live in?
*  Um, what's the weather like there?
*  You know, that sort of thing.
*  But now, um, cars are talking to, uh, we'll talk to, um, uh, their, their
*  manufacturers all the time they'll, and you may have, if you have a relatively
*  late model car, um, you may already have been, I don't know if you have you ever
*  been scolded by your car for not keeping your hands on the wheel, for example, or
*  that's the thing that, uh, you know, if I don't wear my seatbelt or if I'm coming
*  too close to the car in front of me, which is partly helpful, but a little bit
*  annoying sometimes.
*  Yeah.
*  Yeah.
*  And so you'll get, and so, so those things can all become kind of inputs into an
*  individualized price for, uh, for insurance, um, in, uh, in your case.
*  Um, so that's the sort of second level, which trans, which itself transforms kind
*  of what insurance is conventionally, right?
*  Because for insurance to work, you have a pool of people of varying degrees of
*  risk, and then you spread that risk across, uh, individuals.
*  Uh, but if you have individualized data on people, well, then you can kind of
*  have a different version of an efficient market where you, uh, can price
*  discriminate perfectly, uh, ideally at the limit.
*  Um, and, uh, and so then it becomes, it's, it's, it's more like, um, it's bad
*  insurance, it's more like dental insurance, you know, where, where, where,
*  cause like health, there's, there's health insurance or in a, uh, you know, in
*  more civilized countries, the self where you have a full, full displacement of,
*  uh, of risk across the population, but in sort of American dental insurance, it's
*  not really insurance, you're just prepaying for something that they know
*  you're going to do.
*  And, and so car insurance might become like that, which would transform the
*  insurance market.
*  So that's a sort of second level, but then there's like, that's just the
*  beginning with the, with this world of kind of data, because then I said
*  tractors earlier for a reason, like John Deere, uh, has been prepping its
*  shareholders, uh, for a while for the idea that like, look, we sell these
*  combine harvesters, we sell this fleet of tractors, sure.
*  We have a kind of, um, a business, um, with a leasing company and we, and, and
*  loans and so on, but look, we know now when these farmers are going out and
*  plowing and when they're planting, we know kind of a whole range of things.
*  Well, that means we could become sort of a provider of market intelligence, um,
*  to, to people, you know, that we could become a sort of, we could take this
*  information and not just use it to sort of serve our direct customers, but
*  bundle it up and sell it to people who might be interested in it, you know, not
*  just advertisers, but people interested in, um, you know, in futures markets for,
*  for various products.
*  And so this tendency, um, to, uh, to individually make, make data collection
*  more and more granular fits really nicely with this tendency for finance to
*  want to make sort of products that are more and more abstracted layered and
*  layered up, uh, to the, and homogenized so that, so that every, in potentially
*  kind of every manufacturer becomes, um, a software company and every software
*  company, uh, becomes, uh, a provider of software as a service, and then every
*  service becomes something that can be sliced up and bundled where you can, you
*  know, look at tranches or categories or classes of, of, of users, uh, and, and
*  then sell their information or sell information either about them directly or
*  sell the information they are generating to interested parties.
*  And so it's a, you know, and this is something we see kind of right across
*  again, everything from your smart fridge, uh, through, and so in some cases, like.
*  In, in some settings, this seems sort of ridiculous to us now, like the idea of,
*  uh, your fridge, for example, knowing what's inside it and, and first telling
*  you, you need, you need to order more milk.
*  It's been in here for two weeks.
*  You know, it's, it might be, you know, your fridge having
*  moral objections to what you're eating.
*  Uh, that seems silly, but with the car market, we see this just perhaps
*  beginning to happen where car manufacturers are like, wow, we could
*  really transform our finance branch, which is, which is in many cases, the
*  most profitable part of the, uh, the company, and then there's areas where
*  we already take it for granted, like, um, game consoles, for example.
*  Um, where, you know, you are, you know, you're signed up, you have a PlayStation
*  or an X-Box and you buy a piece of software, but in order for the software
*  to run at all, it's, it's a multiplayer game, it's talking to, uh, servers.
*  You have a, it's a subscription service.
*  There are seasons for, for, for games and, um, the company is collecting the people
*  running all kinds of data about you.
*  Some of which is used in a way that you like some of which is explicitly
*  ranked, like for example, if you're playing some multiplayer game, um, they
*  all run, you know, some ELO like, uh, ranking system to make sure that you're
*  matched against people who are kind of competitive with you, but who won't
*  destroy you in games or who won't be too easy for you to defeat.
*  So in that sense, the rankings are just like super useful for you as a, as a way
*  to enjoy your, your service, but then also provide like a global view of the
*  whole system about who plays the most, what kind of people and, uh, and so on.
*  Right.
*  So this, this is already here for certain kinds of products, and then it's
*  continually expanding from many others.
*  Is it true that if I have a late model refrigerator that it will know what's
*  inside and will it send that info to the refrigerator manufacturer?
*  Uh, no, but, or at least there are, um, smart fridges.
*  I need to get back to the, I need to look more carefully like, uh, at, uh,
*  at specific cases, but yeah, Samsung and others have started to, you can buy
*  fridges that have a little camera in them and try to identify, you know,
*  uh, and help you with your, with your shopping by kind of paying attention to
*  what you're buying, uh, and, uh, and, and, and, um, deciding what it is that you
*  need.
*  Well, one interesting question about those too is the extent to which behind
*  the scenes, and I haven't seen anything specific about this particular case, but
*  the thing that, that occurs to me right away is, you know, if you have a fridge
*  that has kind of a monitoring capability, perhaps through a camera, um, is this
*  fully sort of machine learning or is there somebody in, you know, India or
*  the Philippines who's looking inside your fridge and helping you as we saw
*  recently with Amazon, right?
*  That with their, um, with their just walk out, um, stores and so on where,
*  uh, the, they shut that down, but it, you know, initially it was, it was all
*  this hype about it being AI, but then it just turned out to be a bunch of people.
*  Uh, it poorly paid overseas, uh, who were kind of tagging everybody to make
*  sure.
*  So that's the kind of thing that happens.
*  I do remember in your, in your book, you mentioned this fact that I had seen
*  before the General Motors is mostly a bank.
*  Now they make more money out of their auto loans than they do off their autos.
*  Yeah, right.
*  Exactly.
*  The finance division of, again, the financialization of products generally,
*  and of, uh, you know, we think of it extends to companies that we think of as,
*  um, manufacturing hardware of consumer goods, but really, um, where the profit
*  lies is, um, is in their financing divisions.
*  And that's true.
*  Like, you know, take, I'm sitting in front of an Apple computer.
*  Apple is probably the last, you know, it's the last kind of major Valley company
*  that's Silicon Valley company that surviving from the seventies that makes
*  primarily is about making its own hardware, right?
*  That it, you know, that it makes a software, but it sells, makes most of its money,
*  you know, from, from selling, um, from selling hardware, but it too, over the,
*  over the, over the last decade in particular has both, you know, increasingly,
*  um, get, has been getting most of its growth from the rise of services of
*  various kinds subscriptions and, um, and deals with Google and others.
*  And then also has been expanding into an Apple credit card, uh, um, the,
*  the general expansion into kind of, um, uh, you know, paying for anything
*  companies want to get a little piece of that and one way or another, or, or
*  whether, whether they're, if they don't manage it directly, they want to, you
*  know, get a cut for, uh, for, for providing the customer that, but that really is
*  where, um, a lot of the, um, a lot of the long-term sort of stable profit, a
*  stream of income, uh, that, that, that, that you can differentiate by categories
*  of consumer in terms of how much money you can make from them.
*  That's the way that's, that's where the, you know, that's where the profit is.
*  I know you're not, um, mostly a self-help book here, but is it of any use at all
*  to turn off cookies and, um, you know, not, not to, not to, not to, not to
*  not let Google keep my search history and things like that, or is that just
*  a little window dressing?
*  Well, I think that it's important for people to think about these things.
*  Uh, I, we're in the book mostly concerned with kind of how it is that
*  in a big picture way, how sort of the phenomenon of social order generally is
*  being kind of created and the rise of kind of categories of people are being
*  kind of maintained across institutions.
*  Um, one feature of that is that there, that, that the tendency, uh, to think
*  about how people, how people think about these problems at all is also
*  relentlessly individualizing and that it comes down to questions.
*  People naturally ask these questions.
*  Well, what can I do to, you know, to protect my own data, to, uh, to make
*  sure to opt out of these, um, of these, of these systems, uh, to make sure
*  that, uh, things remain private for me and so on, and those are all very
*  reasonable questions.
*  Um, but to the extent to which that, that becomes the terrain on which
*  most debate about this is happening.
*  Well, then you're kind of losing sight of the broader kind of institutional
*  phenomena so that like, um, and this comes out in kind of policy debates
*  in various ways, like in the EU, for example, you know, one of the main,
*  you know, the main kind of with the GDPR regulation a few years ago, their idea
*  was exactly let's empower individuals to have the choice to, um, accept or
*  reject cookies or tracking, uh, in, um, uh, in, in the, in the websites that
*  they visit and, and so what we're doing is putting in the hands of individuals,
*  uh, disability to, uh, to, to make those exactly those kinds of decisions and
*  sort of, uh, you know, to, to think of their own kind of, um, internet hygiene
*  or search hygiene in that way.
*  And similarly, um, if you live in California, you'll see, you know, or even
*  if you don't, you'll see the, you know, do, you know, do not sell my information
*  button on many websites.
*  Now, what that does, of course, in practice is it leads to people just
*  automatically clicking accept all, or, uh, and you know, just, just the, the,
*  the fact that the choices, yeah, the choice is constantly kind of given to you.
*  Or they, or they install a, uh, you know, they, we just have the kind of, okay, I
*  have to click the button here and then they click it.
*  Um, so, so yeah, at that level, that that's the sort of wrong way to think
*  about the broader, um, uh, questions.
*  And then the other thing that happens is that people who are really serious
*  about, um, avoiding all of this stuff, uh, can try effectively to, um, eliminate
*  all of this stuff from their lives.
*  And I know people who do this and, you know, it's not easy.
*  And, and one of the consequences of it is that, um, you're in danger of kind of
*  exiling yourself from your own society, um, and your own culture, which is, which
*  is a price, some people are happy to pay, right?
*  Because they have nothing but contempt for it.
*  It's not, it's a, it's a thing that you can do, but it does, but it's
*  not kind of without its costs.
*  So trying to become invisible, the, the logic of all of these systems, this
*  goes back to what I was saying earlier about authenticity and authentication.
*  The logic of all of these systems is, is to incorporate in that sense, they're
*  democratic, like in that sense, they're, they're expansive and inclusive.
*  They're there.
*  It's not about, it's not a world where we're saying there are these people who,
*  who are not worth paying attention to.
*  And we must, we just ignore them.
*  We deny their existence as social beings, right?
*  It's not that kind of classification system where you just had nothing, but
*  content, you know, you just ignore their existence.
*  Instead, the idea is to sort of incorporate and then stratify and, and to
*  incorporate, you must measure and track.
*  And, and, and then you can sort of justly rank, right.
*  And, and, and properly classify the individuals once they're in.
*  And so, and then, so to be outside of that sort of system then is to be at a kind
*  of double disadvantage because you're not even kind of classifiable as amongst,
*  you know, and, and, and you end up kind of, you know, it'd be like.
*  There's an irony here, kind of, it's, it's, it's like sort of trying to pay
*  everything, you know, trying to pay for cash, trying to use cash for everything
*  is increasingly difficult, you know, because you, because you're not
*  incorporated into the banking system.
*  And for many years, for much of the 20th century, one of the big policy problems
*  that people, you know, was this question of kind of exclusion because people were
*  unbanked and such people still exist.
*  But in, in, in the United States in particular, but there's this massive
*  expansion of the banking system beginning the 1970s that incorporates and that was,
*  and that was driven by very laudable kind of ideas about, you know, being able
*  to let people into the system that they had previously been excluded from.
*  But what happened, the system that replaced it was one where banks
*  essentially figured out how to make money from poor people through things like,
*  you know, late fees and, and overdraft fees.
*  And so, so this, yeah, so, so this is a real tension, you know, that you can walk
*  away perhaps if you have the means.
*  But even, but even that is increasingly difficult because, because of the being
*  invisible in that way has all kinds of consequences that many people don't want to bear.
*  Well, I do want to talk about the sort of implications of all this for our social
*  orders, since that is after all, what the book, what the book is about.
*  I mean, in some sense, if I'm now classified by thousands of different
*  companies in all these invisible to me classification schemes, why do I care?
*  Why does that affect my life?
*  It affects your life chances, as sociologists would say.
*  It affects, it affects the, the, the, the opportunities that are offered to you.
*  And, and what those things will cost, so to speak.
*  Right.
*  And so, yeah, so one feature of, of this whole world is, as you're saying that it
*  is very, it's very highly differentiated, like what it means your, your stock, so to
*  speak of, we call it Eigen capital in the book, this, you know, this, this, this
*  digital representation of you through data, what it means varies according to
*  mark the market that we're talking about, or the setting that we're, that we're,
*  that we're talking about.
*  So it's not that like, we're not sort of arguing in the book that everybody is
*  just reduced to a number, a single number, and that, that this determines your entire
*  life, it's more that, you know, the principle of the basic sort of logic of social order
*  and, and the creation of social structure is increasingly mediated by these, and
*  carried out through these, these processes.
*  And so the reason that you care then as a result is that the kind of person
*  socially that you are, that it will, is very closely tied to how you are
*  classified by these institutions.
*  And for some things you say, you may reasonably say, I don't care in the
*  sense of like, if, if this or that company classes me as a good or bad
*  customer or something like that.
*  But, but for other institutions where these scores are also, and these methods
*  are also increasingly being used in healthcare, in the law, the legal system,
*  and education, and in hiring practices and so on, you may very much care.
*  And you, and people increasingly have kind of come to, accustom themselves, both
*  to very, with varying degrees of, you know, voluntary, ascent to being
*  subject to this kind of data collection and classification as a condition of
*  entry or membership in society, broadly speaking, but in specific, in specific
*  cases. And so then that range, you know, so the, so the range of kind of reasons
*  to care come, come, start directly from how much will this cost me right now?
*  You know, if I, if, will I, will I be charged an additional fee because I've
*  failed a credit check or, or, or failed to, you know, meet a threshold in some, in,
*  in some check to get a, to get a phone and sold, to get internet service, to, to, to
*  sign a rental agreement and so on, right?
*  That, that kind of thing really does matter for a kind of stratification and where
*  people end up in life. All the way through to sort of, you know, what if I feel like
*  I'm misclassified or how can I, you know, if, if, if an institution is seeing me in
*  a way that I strongly disagree with what resources are at my disposal to, to fight
*  that or to, and, and is it just a matter of kind of the only option is to exit the
*  system and, and thus pay the price of that?
*  Or are there, are there ways that I can, you know, are there ways that I can kind
*  of change my classification?
*  And, and those things are, those are hard questions because the very, the very kind
*  of basis or logic of a lot of this stuff is nominally, even if, even if the systems
*  don't really work this way, even if they're laden with error or they're badly
*  implemented as, as, you know, as statistical measures or, or that they reflect
*  bias in all kinds of terrible ways, the, the kind of cultural logic of them is very
*  much that you're getting what you deserve, you know, because it's, because it's
*  your behavior, your decisions, you know, it's not just, it's those are the things
*  look at what happens is that those get parsed as choices that you made, right?
*  As decisions that you took.
*  And so in one sense, kind of all of the things that sociologists and social
*  scientists generally conventionally think of as social structure, where you came
*  from, what your opportunities were growing up, like what you're, what you're,
*  what you're, what is constraining you in the world, you know, people's opinions of
*  you and so on.
*  Those all tend to get stuffed through, if you like the behavioral channel, like
*  they get recorded as choices that, and, and then you get judged on the basis of
*  those choices you apparently made, even if at the time you may have felt, well, I
*  didn't really have an option here, I had to do this, or this was, this was a
*  constraint that I faced that really wasn't my, you know, of my own doing, or
*  on the, on the, on the flip side, you know, the same thing applies in reverse to,
*  um, uh, to people who benefit from these things, where they, you know, the, the
*  idea of like being born on third base, thinking you hit a triple, uh, you know,
*  that, that, that you, you take upon yourself all of those virtues, you think
*  that you, you, you take up, you take up all those advantages become sort of
*  experienced by you as personal virtues, uh, of, of similar choices could, you
*  know, that you made beginning with your excellent choice of parents.
*  Just what you deserve.
*  Yeah.
*  And, and yeah, I mean, you emphasize in the book how even if you thought of all
*  of this classification and ranking systems as purely objective, uh, and
*  quantified, it bleeds over into normative questions.
*  You do get judged as better or worse, like it or not.
*  Yeah, definitely.
*  Yeah.
*  There's the, and there's even if they get, there's very, there were, and even,
*  even if you think of them as, as, you know, classification schemes that are not
*  intrinsically, that are not trying to rank you, so to speak, that if it's, that
*  you're just trying to classify, there are very few cases of sort of, uh, nominal
*  classifications, unordered classifications that people don't try to, uh, to then
*  turn into rankings people in part, because I mean, people, you, you might
*  ask like, why, why is it that that happens again, where there's
*  differentiation, there's stratification in, in, in human societies.
*  But then also, um, people find these like, it's a two-sided process, you know,
*  if you're being judged by these systems, if you're being classified by them, that
*  can be a very unpleasant experience.
*  If you're on the sharp end of them, it can be very gratifying if you're, you
*  know, if you're, if you're well classified, but, but on the other side,
*  if you're looking to make a decision, if you're trying to organize something,
*  these technologies are just tremendously powerful because they, they just are
*  as heuristics, they, they, they, they simplify decision-making immensely, and
*  they make it possible to do things.
*  Uh, and, and so people want, you know, demand in that sense, you know, the,
*  the ability to make these kinds of decisions, to rely on these rankings or
*  to rely on these scores, because they just cut through, they really are
*  extremely powerful methods in that sense.
*  It's just that then we would also not be sub we would prefer not to be subject
*  to them ourselves, uh, a lot of the time.
*  And a lot of the social struggle that goes on around these things is exactly
*  who is it that's predominantly, you know, taking advantage of these measures.
*  And then who is it that, uh, gets to avoid being, uh, subject to them, um,
*  at key moments, uh, in their lives.
*  You know, in a recent solo podcast, I sort of offhandedly speculated about how
*  a lot of the modern condition, um, was affected by the fact that because of.
*  The connectivity of the world we're connected everywhere.
*  So the structures we're dealing with are very, very big, right?
*  It's not like our local coffee shop.
*  It's an international chain and they have all this data that they can, um, turn
*  into action very, very quickly.
*  The efficiency of extraction of our, you know, wealth, et cetera, becomes super high.
*  And it becomes, so I speculated that like, this just makes us sad because we
*  can't ever feel like we're getting a good deal, like we're, you know, we're paying
*  as much as we would possibly be willing to pay for everything we do and we can't
*  get any human response from the systems we're stuck in.
*  Um, I don't know.
*  I'm not, this is not even a question, but like, you know, is that kind of what's
*  going on?
*  I think that's an excellent point.
*  I think it comes out of different ways.
*  One is the, the, you know, the, if in so far as these systems do reach their
*  limit of efficiency in that sense, the result economically is exactly what you
*  described, which is, which is in its way, a perfectly efficient market, just not
*  the, just not the kind that it's not the traditional kind where, you know, supply
*  and demand groped their way towards a kind of balance and there's a single price
*  that clears the market.
*  It's, it's a perfectly price discriminated market where everybody pays exactly what
*  they're willing to pay or, you know, in the, in the, and, and so that means then,
*  yeah, that, that sense of kind of, Hey, I got what the economists would call
*  consumer surplus, like the sense that, Hey, I got a good deal here because I
*  really would have paid more than this.
*  Uh, you know, if, if I had to for this, for this thing can, um, can evaporate.
*  Uh, and yeah, it's, it's a, that's, that's really something that, um, that, that,
*  that feeling is quite, um, is quite real.
*  Uh, and it's also, um, it comes out in a more social way too, I think that another
*  way it makes you sad, uh, is, is that, um, that, that freedom in the book, we call
*  this, um, interstitial liberties that, that, that there's, there's a kind of
*  freedom that comes from the institutions that organize our lives being sort of
*  relatively poorly connected to one another, that they're not really able to,
*  uh, to transfer information efficiently or to communicate with each other, that
*  they get stuck with, you know, in the old older times, like, you know, that there's
*  a file over here that needs to, you know, that's out of date or that needs to be
*  sent in the post or, you know, the bureaucracy's mesh poorly.
*  And, and so the freedom that comes with that, that kind of freedom, this
*  interstitial liberty that kind of bubbles up out of the cracks between
*  organizations was the freedom to move somewhere else and not have anybody know
*  who you were or be able to find out, you know, to start a new life somewhere, you
*  know, with a clean slate or something, or just, just to move through society
*  without this sense of that.
*  There's a, the possibility that everything about you relevantly could be known
*  easily, and as these systems have sort of expanded the benefits that you get
*  is supposedly are, are the ones that have to do with kind of an experience tailored
*  to you and that, you know, personally, and, but like, well, and you think, oh,
*  that'd be nice, but that's, but that's a bit like being asked, you know, if I could
*  go back and live at any time in history, what would it be?
*  People think of themselves, well, I would be the king, right?
*  Of course it would be great.
*  And so, so maybe what, what's tailored to you, what the system thinks you deserve
*  may not be what you think you deserve.
*  And so you get, you get a sort of benefit, but, but then you also lose this, this
*  freedom kind of that came with the friction that previously existed between
*  institutions that, that, that people, yeah, you had more opportunities in that sense
*  because there was so much more, there was so much more of, of, of, there were gaps,
*  there were cracks that you could sort of live in, in a way that's increasingly
*  difficult now.
*  So, so sadly we're winding up on a relatively downbeat note here.
*  I'm wondering, you know, projecting.
*  What's that, what's that joke that, that, you know, I should, you should add on a
*  positive note.
*  I don't have a positive note.
*  Would you take two negative notes?
*  But, you know, can we project into the future?
*  I mean, everything that you're describing seems to me to be everything.
*  These things are definitely happening, but I can imagine them happening even way more.
*  So I'm guessing that none of this is going to go away.
*  Yeah.
*  So, so the, so it is, there is a, it is a little pessimistic in that sense.
*  I would say though, that one of the key, one of the main, you know, commitments in
*  the book, or one of the main sort of feelings that we have in the book are at
*  that, and that we think we, that that's kind of come out empirically over and
*  over again, is that, that people, just, just because a system is pervasive, right?
*  Just because the way that life is organized is, is everywhere now.
*  It doesn't mean it's totalizing in the sense that like it completely dominates
*  and, and, and, and fully dictates every aspect of your, of everyone's existence.
*  Right?
*  So a thing can be like the world we're describing, we think is, is real in the
*  sense that it really is kind of expanding and, and, and, and, expanding in its scope
*  and scale in the way that we describe.
*  But, but it's also true that any system, any human system, any sort of social
*  and set of social institutions is intrinsically sort of people, it's,
*  people tend to overflow the boundaries of their, of the systems built, you know,
*  to, to, to enclose them or that we build to enclose ourselves.
*  And because social life is messy, things happen kind of at random, there's
*  noise in the system, things break.
*  So, so, so there's always this possibility, it's inevitable really, you know, that,
*  that things just don't go according to plan, things sort of spin out and, and,
*  and when they do, it isn't always a bad thing, you know, and the very things that
*  kind of helped create this whole system were exactly that it was sort of people
*  creatively overusing early web form, you know, early web discussion forums suddenly
*  become kind of communities where people discovered each other.
*  You know, sometimes those communities were, were wonderful.
*  We, we might judge normatively and others, it turns out that, oh, look, you know,
*  all the white supremacists can find the exit, you know, can meet up as well.
*  So, so it's not, it really is a truly messy process in the sense that it's not
*  kind of, there isn't a kind of nice moral story about how everybody is wonderful
*  deep down or anything like that.
*  But, but it is the case that like these systems, they're not, they don't exist
*  forever and, and so there's both kind of good old solid kind of policy.
*  We can kind of architect these a little bit in ways that can push them in one
*  direction or another, but there's also just the sheer fact of kind of human
*  sociality and the randomness, you know, intrinsic and messiness of, of, of human
*  social existence that tends to kind of overflow whatever boundaries get, get
*  put on it sooner or later.
*  What happens after that?
*  What's next?
*  Is it, I don't believe in the idea that it's necessarily better, but it's not
*  inevitable that we're stuck, like we're never stuck forever in a, in a particular
*  way of organizing things, new things come along.
*  I guess, I guess that's a good, slightly positive note.
*  Good.
*  Thank you for at least trying there.
*  I appreciate the effort.
*  Uh, you know, look, I will note that, uh, I've noticed that on YouTube, the ads
*  that I get, um, served up are just terrible.
*  They're just like, Todd Reed, no relationship to me.
*  And I clicked like trying to ban an ad and it said, well, you've turned off your
*  search history so we can't target your ads.
*  And I'm like, yeah, well,
*  that's exactly the kind of, that's one of the ways like that's, that's an exact,
*  it is a very good example of, of like the price you pay for, for, for, for, for
*  one, for not wanting to be incorporated, right.
*  Because, uh, and the price you pay for not wanting to be incorporated is, is that
*  you get the worst they're like, they're like, okay, we'll have to serve you up
*  the lowest common denominator.
*  And, and, and so it's like on, you know, I don't, I'm not on Twitter anymore, but
*  you know, anytime I go back there now and it's like, oh, it's just like liver
*  King, you know, these weird weirdos who are, and, and, and it's the same sort of
*  thing. It's like, well, I turned off all of my, you know, information you don't,
*  you don't give this is what we call the most Ian Bergen, right?
*  You don't, you don't give to the system.
*  And so it doesn't give back to you.
*  Uh, and so, yeah, so you have to then to the extent that you're still watching
*  YouTube, you have to suffer through these terrible ads because you didn't give
*  back in the way that it wanted you to.
*  It's a first world problem, but it's a problem that I care about.
*  So that's what I have to deal with.
*  Uh, Kieran Healy, thanks so much for being on the Mindscape Podcast.
*  Thank you, Sean.
