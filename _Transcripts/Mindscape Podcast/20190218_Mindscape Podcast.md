---
Date Generated: June 10, 2024
Transcription Model: whisper medium 20231117
Length: 4245s
Video Keywords: ['cruelty', 'emotions', 'empathy', 'morality', 'psychology', 'rationality', 'reason']
Video Views: 14681
Video Rating: None
Video Description: Blog post with show notes, audio player, and transcript: https://www.preposterousuniverse.com/podcast/2019/02/18/episode-34-paul-bloom-on-empathy-rationality-morality-and-cruelty/

Patreon: https://www.patreon.com/seanmcarroll

Within every person’s mind there is on ongoing battle between reason and emotion. It’s not always a battle, of course; very often the two can work together. But at other times, our emotions push us toward actions that our reason would counsel against. Paul Bloom is a well-known psychologist and author who wrote the provocatively-titled book Against Empathy: The Case for Rational Compassion, and is currently writing a book about the nature of cruelty. While I sympathize with parts of his anti-empathy stance, I try to stick up for the importance of empathy in the right circumstances. We have a great discussion about the relationship between reason and emotion.

Paul Bloom received his Ph.D. in cognitive psychology from MIT. He is currently the Ragen Professor of Psychology and Cognitive Science at Yale University. His research ranges over a variety of topics in moral psychology and childhood development. He is the author of several books and the recipient of numerous prizes, including the $1 million Klaus J. Jacobs Research Prize in 2017.
---

# Episode 34: Paul Bloom on Empathy, Rationality, Morality, and Cruelty
**Mindscape Podcast:** [February 18, 2019](https://www.youtube.com/watch?v=K-36CFogxbw)
*  Hello everyone and welcome to the Mindscape Podcast. I'm your host, Sean Carroll. And
*  a few months ago I went on Twitter and took a brave contrarian stance that empathy is
*  a good thing. Many people, of course, would agree with this automatically, but many other
*  people have read a book by today's guest, Yale psychology professor Paul Bloom, which
*  is entitled Against Empathy, which I admit is a completely awesome book title. And Paul
*  and I actually discussed this on Twitter. He's an extremely reasonable, thoughtful guy. And we do,
*  in fact, disagree. His point is that empathy, the ability to think about things from someone
*  else's point of view, to put yourself in their shoes, sounds good. And maybe it makes us nice
*  people on a personal level, but it gets in the way of being rational, moral thinkers. We tend
*  to empathize with people close by, with people like ourselves, rather than being purely rational
*  about how to be the best people, how to live in the world correctly. I, on the other hand,
*  tend to emphasize the fact that people who think that they're being rational will often take things
*  into account that make perfect sense from their point of view, while perhaps not paying as much
*  attention to things that are front and center to people who are living very different lives
*  than them. To me, if you're really going to be rational, it is absolutely crucial that you
*  are empathetic, that you try to understand what other people who have very different experiences
*  than you have been going through. So Paul and I talk about this on the podcast. I don't think we
*  are necessarily coming to any agreement, but on the other hand, I don't think we disagree that much
*  either. We're trying to emphasize different aspects of a problem. And Paul's an extremely
*  interesting guy. I think you'll get a lot out of this conversation and hopefully we'll all be more
*  moral and good to each other at the end of it. So as always, please check out the Mindscape webpage
*  at preposterousuniverse.com slash podcast, where you'll find links to Patreon and PayPal,
*  and keep the podcast going. Also, you'll find transcripts so you get to see all the words and
*  you can even search through all the archives to see what cool stuff previous Mindscape guests
*  have said. And with that, let's go.
*  Paul Bloom, welcome to the Mindscape podcast.
*  Thanks for having me here.
*  I want to actually thank you especially because a few months ago, I was having dinner with our
*  mutual friend, Carl Zimmer, who was a previous Mindscape guest. And Carl mentioned that every
*  time he runs into you, you say like, boy, I was just on another podcast. There's just so many of
*  these things. So I presume that you're quite in demand in this medium.
*  Well, yeah, but there's a couple that stand out and yours is one of them.
*  Oh, that's good to hear.
*  Good.
*  I know of you through Carl and through your popular books. And so I'm just totally thrilled to be here.
*  And you and I have had a run-in on Twitter, if I remember.
*  Yeah, if you want to call that a run-in. Yeah, I mean, I've had run-ins. That didn't seem like
*  a run-in from my perspective. It was a nice little chat.
*  A nice little chat. But that sort of sets the stage for us to talk in person.
*  Yeah, that's right. So there's lots of things to talk about, obviously. I mean, psychology,
*  it's a pretty broad area and you've done work in a lot of areas. Let me float a hypothesis and you
*  can either shoot it down or sharpen it up. A lot of your work seems to deal with what we might
*  think of as the boundary between reason and emotion or almost the battle lines between those
*  two things. Is that a fair characterization? It really is. I mean, particularly my recent work,
*  I've always been interested in how much of our natures are based on emotion, feelings,
*  and gut reactions. And to what extent could rational liberation play a role? So this
*  cuts across a lot of my research. Yeah, so what's the answer? How rational can human
*  beings be? I think this is actually a more involved topic than just a simple yes or no answer.
*  Yeah, but I'll go for it. I think we're a lot more rational than most of my colleagues think we are.
*  I don't doubt that a lot of our feelings, our judgments, really our moral judgments
*  are influenced by our emotions. We're often very irrational indeed, certainly politically. I think
*  politics brings out the worst in us. But I also think we have a tremendous capacity for rational
*  liberation. And in fact, you see this at its best in the sort of your day job in science.
*  In actual science, it shows that humans can, under optimal circumstances, be rational and
*  deliberative and come to real insights about the world. And I would make the stronger claim
*  that we can do this when it comes to morality, when it comes to politics, and in our everyday lives.
*  Good. So this is a perfect starting point for the conversation because as I have grown older,
*  and whether or not wiser, my faith in human rationality has only diminished over time.
*  So I'm very happy if you are going to be able to convince me otherwise. Why don't we start just,
*  you know, it's a broad audience from a lot of backgrounds. Most people probably think of
*  themselves as pretty rational. What are the reasons that we've had from psychology and elsewhere to
*  start to doubt that we're perfectly rational beings?
*  It's a good way to begin. There's a lot of sort of striking demonstrations from psychology that we
*  aren't as smart as we think we are. And I think the foundations of this work come from the
*  psychologist, Danny Kahneman and Amos Svirsky. And Kahneman eventually won the Nobel Prize for
*  his work in economics. And what those two did was put together a really impressive body of work
*  showing that we're highly susceptible to cognitive illusions and cognitive biases.
*  We are biased. We make mistakes. We depart from logical norms, mathematical norms,
*  in such ways that we could often be tricked and people could exploit us.
*  And so there's a lot of those demonstrations. There tend to be sort of more mathematical,
*  logicky demonstrations, but some of them are quite striking. For instance, one typical one is we
*  radically overestimate the odds of the likelihood of infrequent yet very salient events like
*  terrorist attacks or being bitten by a shark. And we radically underestimate the relative likelihood
*  of pretty frequent events like heart conditions and dying of a coronary. So that's one tradition.
*  And then the second tradition is more recent and is associated with people like Jonathan Haidt
*  who argue when it comes to our moral reasoning and political reasoning, we might think that we
*  have arguments. You might think your views on abortion and the death penalty and Donald Trump
*  are because you're a deliberating being, but there's a lot of demonstrations suggesting that
*  actually your views on these things were determined by other factors and the reasons you give are
*  after-the-fact justification. So that's why a lot of my colleagues are skeptical about the power of
*  reason. Yeah, I think that that fits in with the very first episode we had of Mindscape where I
*  talked to Carol Tavris who's a social psychologist who has done some work on cognitive dissonance.
*  And she wrote a wonderful book with Elliot Aaronson called Mistakes Were Made But Not By Me,
*  all about how we justify the decisions we make. And even if the making of the decision was
*  rational, the justification of it would go forward whether or not that original decision was rational.
*  Yes, that's right. That's right. And there's all these sort of laboratory demonstrations,
*  everyday demonstrations, suggesting that in some way we don't live our life as
*  comic book scientists running experiments in the world and coming up with theories.
*  Rather, we're kind of like to use Jonathan Heitstern, we're like lawyers. We have to explain
*  something. We have to make a case for something after it happened. That's right. We have to
*  justify it. And in fact, in the science fiction realm, we caricature Mr. Spock in Commander Data
*  and the examples of people without emotions perfectly rational. They're always the ones
*  learning from we human beings because we're wise and we have our gut instincts and our emotions
*  are very helpful. Yeah, I mean, science fiction, I think even good science fiction really bungles
*  emotions. So you know, so part of you capture one part of it, which is somehow data and Spock are
*  fatally flawed in some way, which they need to touch the spark of emotion that only a Captain
*  Kirk has that humans have. On the other hand, I think that they terribly miss out on the importance
*  of emotions as motivators. If Spock and Data really had no emotions, why would they get out of bed?
*  Why would they do things? Why wouldn't they just sit in a lump in a fetal position and think
*  thoughts? Well, as David Hume said, reason is the slave of the passions, right? We need some emotion
*  to give us goals and then reason should tell us how to achieve those goals, roughly speaking, right?
*  That's right. And even, you know, people like me who want to push the importance of reason
*  would argue that you need to kick in the pants of emotion. Right. I've argued that we're often much
*  better when it comes to morality, when we try to think our way through and not follow our gut.
*  But even I would admit that if we didn't have gut motivations to care about other people,
*  you could come to all the wise moral decisions you want. You wouldn't do anything.
*  Well, good. But I think that so that is an important fact about the role of rationality
*  is that when we invoke it, it's in the cause of some goal, which arguably is given to us by emotions.
*  But what you're saying about rationality is something a little bit different, I guess,
*  which is you're saying that despite these social science studies saying all the different ways in
*  which human beings justify ourselves and make logical mistakes, you're optimistic about the
*  extent to which we're reasonable. That's right. And I'm optimistic for all sorts of reasons.
*  One reason is we have certain domains where rationality has, you know, proven to be very
*  powerful and very useful. Science and technology being one example. If we really were such stupid
*  creatures and so reflective and so biased, how did we come over time to have such a rich understanding
*  of the universe of domains that we were not evolutionarily prepared to know about yet,
*  somehow we managed to figure it out. I think more controversially, morality is another domain.
*  We're a lot better people than we were a thousand years ago. And part of it is,
*  I think, to exercise a reason over time. Yeah. So good. Let's dig into this a
*  little bit because I like doing science first. I think that science is the perfect example that
*  psychologists and philosophers should take care of because if we can't figure out how science works,
*  then it's hopeless. Science is the most straightforward thing that we have. It's
*  much easier than morality. And as you say, the power of reason has taken us pretty far in science
*  and understanding the world. But then, you know, a lot of people on the streets are not very good at
*  science, right? We human beings need to invent all sorts of tricks and double-blind studies to
*  prevent ourselves from giving into our biases. So is there any way of quantifying whether or not we're
*  overall rational or irrational? Yeah. In some way, I push back a little bit. Science is in some way,
*  a very strange domain. I mean, for the reasons you gave, it's very unnatural. It's this bizarre thing
*  maybe we stumbled onto and has turned out to be of extraordinary use. And I think science illustrates
*  something which I think brings together your observation of demand on the street with my
*  pushing of reasoning, which is that reason will flourish in social institutions where it's valued.
*  And often we're sensitive enough to, of our own weaknesses, that we could intelligently create
*  institutions and mechanisms and procedures like refutation and experiment and blind review and so
*  on that can lead us to do much better. And I think we see this in other domains as well. So, you know,
*  if I'm aware of my racial biases, I could choose to use a procedure like blind review
*  or a quota system or something to override them. If I'm aware that I love my kids more than I love
*  other people and would favor them, I could support a system which bans nepotistic hiring.
*  And so this is sort of a very human story where we have these weaknesses, but we're also smart
*  enough to think our way through and override them. And science is this great example of how people
*  manage to do that. Yeah. No, I think, I mean, part of it maybe is not that there's any disagreement
*  or even difference going on here, but just a choice to emphasize one thing or another, right? Like,
*  in some sense, we are burdened with some level of irrationality, but we are blessed with enough
*  rationality. We can overcome that when it's really helpful. That's right. And then where you draw the
*  line and emphasis you put on things, you know, matters a lot. So a lot of my colleagues emphasize
*  their rationality of our political behavior, our voting behavior. My temptation is to be
*  more skeptical about these claims of irrationality and argue, for instance, that a lot of people's
*  political behavior seems irrational because psychologists miss out on the fact that people
*  aren't actually aspiring towards the truth. You know, if I really support the Red Sox and I share
*  them on and you just say, well, that's not rational. They're not favored to win. Then you're kind of
*  missing the point. My cheering them on is not, you know, this objective assessment or being right
*  matters. My cheering them on might have to do with the community I'm with and who my friends are
*  and who I want to support. And that seems to be very compatible with what I've read about
*  political allegiances, right? That a lot of times even if we're asked factual questions,
*  we give answers because in our minds, subconsciously or consciously, those are the right answers to
*  give given our political side. That's right. So you take somebody who has a view left or right,
*  say about climate change, and you say, oh, well, isn't it crazy this person doesn't know what
*  they're talking about and they just have the view that other people have. But your average person
*  doesn't have much stake in being right about climate change or any one of the other political
*  issues. They have very little say in what happens. Whether I have the right view or wrong view will
*  have no influence on my life or anyone else's life. But it will matter a lot for my friendships and
*  my relationships if I hold a certain view. And so people see, I think people think of politics,
*  maybe not unreasonably, as akin to sports. And so they cheer on their team, they boo the other team.
*  For a while, I'll take one example. Years ago, there was a lot of polling that found a lot of
*  Republicans said they believed that Obama was born in Kenya. Right. Turns out there's actually
*  polling where they've asked people where was Trump born? And a lot of Democrats say Trump was born
*  outside the United States. Okay. And we're saying is, they're saying I haven't studied these issues,
*  I'm saying boo Obama, boo Trump. Right. And there's even studies where if you like offer them a nickel
*  for getting the right answer, suddenly their answers change, right? Exactly. When you shift
*  incentive structure and make it that it's actually for once important to be right, then people start
*  behaving differently. And I actually think when it comes to local politics, people are much smarter.
*  They might vote their self-interest, but they're actually genuinely curious and engaged in the
*  facts because they matter. Whether or not you put a stop sign on a corner or you put in sidewalks,
*  or you pay more for snow removal. Well, that's the sort of thing where it actually does matter
*  to my life and my views do matter. And then I become more aligned to the truth. But let me see,
*  if I've read, I think most of Kahneman's book, Thinking Fast and Slow, which is one of those
*  wonderful books that once you read it, it changes the way you think about the world.
*  And the impression I get from it is that not being a trained psychologist, I think a lot of
*  us have a vision of a human being or at least ourselves as like it or not a little homunculus
*  inside our brain, right? Pushing around the levels, the levers to make us do things. And that's not a
*  very good picture because what's inside the homunculus is brain. But the more psychologically
*  accurate picture is that there's lots of competing sub processes going on and there's
*  lots of heuristics and shortcuts and, and, you know, common sensical rules of thumb that we use
*  rather than using the full force of our reason to get a right answer and then give it in a single,
*  unified consciousness. I think that's very much right though. Though Kahneman himself has long
*  defended a view that says that there are two general systems and each system probably composed
*  is composed of many systems. So one system is what you're talking about now. It's a series of
*  gut instincts and emotional responses, heuristic and bias, heuristics and biases.
*  But the second system is a deliberator is a slow, careful reasoner. Right. And, and much of life,
*  we use the quick emotional system. You know, in a fractions of a second, we make judgments,
*  we let our biases go, but we can slow it down. You know, when given a puzzle,
*  a bat and a ball cost together a dollar 10. The bat costs 10 cents more than the ball.
*  How much does the ball cost? Right. Have you done that one? No, but I could do it. I know,
*  I read the book, right? So I know how to like slow down and get it right.
*  I realized under this pressure, I probably mangled the example, but there's all sorts of things like
*  that where there's an immediate answer. And then there's a slow and reflective answer. That's right.
*  And, and you know, to get back to what you were saying before people do differ, there are people
*  who are very reflective in their lives and people who tend to go more for their gut. But I think that
*  which one you are depends in part on your nature, but also depends on the environment you're in and
*  your upbringing and so on. But, but this illustrates that that in addition to the sort of
*  hodgepodge of heuristics and biases that you're talking about, there's also something else in our
*  heads that's closer to an ideal reasoner, at least in principle. Well, right. So in this picture,
*  you know, condiment, I think if I'm getting the numbers right, it's system one, which is all the
*  heuristics and biases and system two, which is the deliberator, the cognitive part, are you, are you,
*  is what you're trying to say that we're more system two than we give ourselves credit for,
*  or that system two is more powerful when we choose to use it?
*  Both. Okay. And I think system two is a really important part of the story. Psychologists like
*  to say, look, people, people make all sorts of dumb mistakes. And we talk all about these dumb
*  mistakes. But what's, I call it, you know, so one example I saw is that, I think it was Burger King
*  opened up in response to the quarter pounder, they had a third pounder.
*  Yes. And then the idea was nobody bought it because they figured a third pounder must have
*  less meat than the quarter pounder because three is less than four. So, you know, we love that stuff.
*  So we, you know, but, but here's what we're missing. We're missing the fact that I could tell it to you
*  and we could laugh about it because there's another part of ourselves that knows that's a mistake.
*  Right. And, and so we're put in kind of an odd position of almost, you know, laughing at people
*  and ourselves for our stupid mistakes and forgetting about the fact that we know they're stupid mistakes.
*  Yeah. And, and, and this is not, it's not a minor problem. I think, I think our psychologist focus
*  on the irrational has left us largely unprepared to explain things like moral and scientific and
*  social progress, which often work on deliberation. And even if system two, the rationalizer only works
*  1% of the time, it's a very important 1%. Sure. And is this, is this, you know, pushback that you
*  want to give, you know, the pro power of reason kind of thing, is that based on studies or
*  experiments that you're doing, or are you just sort of surveying the existing art there?
*  So in my own work, I've been most interested in this in the domain of morality. And, and, and the,
*  the basis for my critique, my critique of my, my, basically my descriptive claim is we're capable
*  of moral reasoning much more than many of us think. And then my normative claim, my claim
*  at how we should live our lives as we really do better as we were better people, morally better
*  when we rely on our reasoning rather than our gut feelings. Yeah. And so I try in my other work,
*  I've sort of argued against that emotions like disgust lead us morally astray. More recently,
*  I've argued this about empathy, arguing that empathy could lead us, often leads us to make bad
*  and immoral choices. And the basis for my argument is to some extent philosophical,
*  arguments and examples from philosophers showing the limitations of empathy, and to some extent,
*  experimental. There's some very clever experiments by Dan Batson and many others showing how
*  illustrating very sharp terms, how relying on our feelings leads to terrible and immoral mistakes.
*  Right. Yeah. So that's a, you wrote a book against empathy, one of the great titles of the history
*  of books. Thank you. I have some influence about my title. It's, it's a, it catches people's eye,
*  but it's had no end of trouble. You know, I, it took me a while to learn the lesson of being an
*  author that the title is the purpose of the title is not to summarize the book. It's to sell the
*  book, to get to people to read it. And I think that it worked for your book. Yes. I'll let
*  you hear what my title seems to be to provoke people to send me unhinged emails. Well,
*  sorry to hear that. Yeah, that's too bad. But if they do that after buying the book, then their,
*  their job here is done. Unbalanced. I don't regret it. Good. So I do. And I do think, so this is
*  where we started to disagree on Twitter and I think we still disagree. But again, I'm going
*  to be open up here to you changing my mind once and for all. Same here. Tell me how, for,
*  let's be systematic, how you define empathy and why you think that we give it too much credit.
*  Yeah. I mean, one of the worst things about this topic is I'm forced to start in the most boring of
*  all ways by defining my terms. I know people use them empathy in all sorts of ways. And a lot of
*  people think empathy just means goodness and kindness and morality. Right. And if, you know,
*  if they're using term that way, I'm not against it. And, and I, I'm all in favor of being good
*  and kind and moral. I, I'm meaning in a reasonably narrow sense, but it's how a lot of psychologists
*  and philosophers use it, which is getting in another person's shoes of feeling what they feel,
*  seeing the world through their eyes, feeling their pain. And this seems like a very good thing. And
*  there's all sorts of examples where it could be a good thing. But the problem is when you,
*  when you, you come to your moral views and your moral decisions based on zooming in on, on through
*  the perspective of another person, several things happen. For one thing, it's very biased. I'm much
*  more likely to feel empathy for you, a fellow professor, maybe same age, same ethnicity than I
*  am to feel empathy for somebody who is a different color skin or a woman or lives in a far off land,
*  speaks a different language. So there's that kind of bias. I'm more likely to feel empathy for the
*  attractive than the ugly for the safe than the scary. Empathy is a enumerate. And so empathy
*  draws us to the fate of the one, but leaves us neutral or ignoring the fate of the hundred.
*  And just to kind of wrap it up, because empathy is sort of so, so biased and can be focused,
*  it's often used as a tool for, for what I think is our unpleasant ends. Last night, our president
*  gave a speech to the nation where he argued for a border wall. Now putting aside,
*  that, you know, it's, it's not a topic for here, whether the argument is a good one or bad one,
*  but putting that aside, what you'll notice is Donald Trump uses empathic arguments all the time.
*  He talks about victims. He talks all the time of victims and people who are murdered and people
*  who are raped. And this is a tried and true method to generate animosity towards a group.
*  So when some people think of empathy, they think of charity. I tend to think of war.
*  Empathy is just used, can be weaponized and often is, and certainly is in these times.
*  Yeah, that actually hearkens back to a podcast I did with Yasha Monk, where he talks about the
*  word populism. And you might think that populism is, would be a good thing. We have a democracy,
*  you should do what the people want. But in practice, populism is all about defining some
*  people as not the people, right? As outside the set of people who really matter.
*  I think that's right. I think there are all sorts of things that, that feel good. But if you look
*  at how they're used in everyday life, they are, they have terrible ends.
*  Yeah. And again, this might end up being one of those things where in fact we're in complete
*  agreement, but are just choosing to emphasize different things. But let's get, play that out
*  and get on the table. So I think I understand your argument. And in some sense, much of what you say
*  is just obviously true, right? I mean, clearly we are more empathetic for people who are like
*  ourselves and therefore that causes trouble. Is it safe to say that what you would like to
*  emphasize instead of empathy is a more strictly rational approach to morality?
*  Yeah, I, I, I think that there are always going to be, I'm not pretending that I have the solution
*  to moral problems. I don't know whether I'm utilitarian or deontological. There's, there's
*  a whole lot of problems I'm not pretending to solve. But when we rid ourselves of making
*  decisions based on, on empathic pull, it, it, it leads to changes in our moral judgments that
*  I think everybody would agree are, are better. I think there's nobody who would defend the idea
*  that an attractive person's life is worth more than an ugly person or that one life is worth
*  more than a hundred. So yeah, my, my claim would be that the alternative to empathy in that regard
*  is thinking through, realizing what your moral goals are and trying to figure out what's the
*  best way to achieve them. Okay, good. So two concerns or two thoughts in my mind. First is,
*  I can't help but think that the problem that you're raising is not that we have empathy,
*  but that we don't always do it right. Or almost that we don't have enough empathy for the right
*  people, right? Like if, if it's true that I have a lot of empathy for a small child drowning in the
*  pond that I'm walking by and I don't have empathy for starving millions of people in Africa, then
*  wouldn't an alternative, a different strategy just be, well, train yourself to have more empathy for
*  the people who are in Africa. Yeah, I, I, I think that's very reasonable. There are two issues with
*  it. One is I think there's some problems with empathy, which really are intrinsic to empathy.
*  So empathy by its very nature zooms you in on single individuals. So empathy is not a mental
*  system that deals with numbers. And to the extent that some moral judgments should deal with numbers,
*  that a thousand lives are worth more than 10, empathy leaves you silent. In fact, it's kind
*  of worse because empathy prioritizes a single individual you zoom in on. Um, and at the expense
*  of faceless individuals who you don't. Now you could imagine, you know, if God tried to make
*  decisions through empathy and God could empathize with a billion creatures at the same time,
*  maybe it would be less of a problem. Yeah. But we're, we're, we're limited. Um, and, and empathy is
*  for us a spotlight and spotlight, spotlights shine brightly on, on, on spaces, but, but they have their
*  limits. And then just the second point is it's true if we could apply empathy in an unbiased
*  fashion. Um, it would be many of the problems I'm talking about wouldn't arise, but we can't.
*  It's, it's sort of, it's sort of like I said, look, you have to decide on, on a graduate student or,
*  or a new faculty member to hire, just choose the one you like the most, but try to make it so your
*  liking isn't biased. Well, if your liking wasn't biased, if your liking was fully on the merits
*  and liking is a good measure, but, but that's not how people work. You're going to like somebody who,
*  who kind of is charming and it acts and is interested in you and it comes from a similar
*  place. So a better system is trying to make it so that you don't use liking, use more objective
*  criteria. Right. I mean, in some sense, you know, we, we started with this discussion of the
*  relationship between reason and emotions and how emotions sort of provide a starting point for reason
*  to then say, okay, here's our, here's our program. Let's carry it out. Uh, couldn't there be a similar
*  situation with empathy where empathy gives us a starting point, then reason takes over and says,
*  well, wait a minute, it's a little bit unfair just to be empathetic with this person. Let's take the
*  thing that we started with and be more rational about it. It could, I mean, empathy could be a
*  spark for good actions. You could see somebody suffering, feel their pain and then move to help
*  them. And you're helping them could be mindful of other people. It could be, it could be, uh,
*  respectful. It could have none of the problems I worry about. I don't doubt that that could happen.
*  On the other hand, you could feel empathy for a group of people and it could lead you towards
*  violence towards another group of people. Yeah. Um, I think, I think that the point that you make
*  that empathy tends to be singular, that it's easier to have this response with, with, you know,
*  a person with a face and a description and so forth. That's a very good point. And that's,
*  there are very few sensible moral systems that say that's, that should be our motivation.
*  That's right. That's right. So I sometimes, you know, people say, well, are you pushing,
*  you know, a Peter Singer like consequentialism or is there a certain moral position then I have my
*  biases, but to see that empathy leads you astray, I think you could make the case that no matter
*  what your morality is within a certain reasonable range, you say, Hey, that's not the right way to
*  do it. Right. But you know, to go back to your point, I, you're entirely right. And I would,
*  would happily concede that empathy could spark you towards good moral actions. So too for anger.
*  Anger is a very interesting emotion. Anger sometimes gets a bad rap. And I think we could
*  do better than be motivated by anger, but anger at an injustice could really motivate you to do
*  really good stuff as well. I think in general though, I try to push this, the subtitle on my
*  book, which is less in your face than the title is the, is the case for rational compassion.
*  Right. And I think, you know, what, what people call compassionate, general desire to improve
*  people's lives. I think that's a better motivator than, than either empathy or anger or disgust or
*  shame or guilt. But again, I wouldn't, I don't disagree that I can alter the case of where
*  empathy as well as anger, disgust, shame or guilt led to good action. Yeah. No, that's perfectly
*  fair. You know, the, it doesn't, I don't want to say it doesn't matter, but there's all sorts of
*  starting points for good things that we, that we can get to. That's right. I mean, I mean, suppose
*  you and I probably don't like racism very much. Racism is bad. Yeah. That's a physical mind.
*  We're not going to edit this one out. So racism is bad, but, but it's a trivial exercise to think of
*  cases where racism could have a good effect. You know, if you, if you think, for instance,
*  if there's a horrible politician and somebody uses racist appeals to keep anybody from electing this
*  horrible politician, and as a result, the world was so much better. Well, racism did some good,
*  but still you'd say, yeah, but in general, it's a bad way to do things. It's not, it's not sort of
*  attuned to morally relevant features that you want to focus on. Good. This is very clarifying. I think
*  that, you know, there certainly is a lot of truth here and the connotations of the word empathy are
*  just so positive. I mean, this is why against empathy is such a great book title, right? That
*  it deserves a little bit of pushback just so we can, you know, even if it's only to think of it
*  properly overall. I think it is. It goes back to what you started with, which is I kind of want to
*  make the case for reason and against emotions and other work. I tried to argue that, look, disgust
*  is a very unreliable way to make moral decisions, but what I found was everybody agreed with me.
*  I mean, sort of liberal milieu of people who read these kinds of books and I went, oh, that makes
*  total sense. Yeah. So I want to say, well, what sort of emotion would you think would be good?
*  And, but, but, and I can make the case that even for that, you're better off with more rational
*  approaches. So that, that brought me to empathy. Right. So let me get onto my second point then,
*  which is actually where we started on Twitter. Cause I tried to make a, I said that I forget
*  exactly what I said, but I think the point was that empathy is a crucial part of rationality
*  in a very real sense. And so this is what I really want to get your opinion on. Cause I don't think
*  that we quite got there on Twitter. I, because I am skeptical about human beings ability to be
*  rational, but as a trained scientist, I know that we can get there by using, you know, tricks and
*  strategies to make ourselves seem more rational. I think that one of the most important tricks and
*  strategies is the need to try to empathize with people unlike ourselves. And what I see over and
*  over again in people who are, well, self described as extremely rational and to be fair, often are
*  rational, but they're choosing to look at certain things going on in the world and just not paying
*  attention to other things going on in the world. And I would argue it's because they are very
*  different than the people that that's happening to. So they just discount these bad things. I just,
*  just this morning read an article in the Paris review by R. O. Kwok about, you know, how difficult
*  it is for her to read novels by male authors describing female characters. Cause they just
*  don't get the fear that women live in walking down the streets at night by themselves. And I think
*  that one of the major tricks that a person trying to be rational should use if they want to get a
*  theory of morality and justice and how to arrange society is doing everything they can to empathize
*  with people very unlike themselves. Yeah, I think there's a lot of truth to that. And that kind of
*  brings us a little bit of different senses of empathy. So one sense of empathy isn't a matter
*  of feeling what another one feels. I actually think among other things, we're not very good at it.
*  So for me to say to, well, to a woman in that position, for instance, who, oh, I could really
*  get to understand and feel what it's like to be in your situation seems arrogant.
*  And, but I do think, and I think you're right. I think we should make an effort
*  to try to understand the lives of people very different from us. It makes us better people.
*  It makes us understand the world more. It's fascinating. I mean, so much of the best
*  literature and movies and books is exhilaration of trying to understand a world different from
*  your own. Yeah, I think, but I want to be a little bit further than that. You know, I think that,
*  because as a scientist, as a physicist, you know, I know all of the strategies that we use. Like
*  when I had Kip Thorne on the podcast, we talked about this fact that the LIGO experiment that
*  detected gravitational waves, they had a whole protocol by which a little subcommittee would
*  inject fake signals into the data. And then the entire rest of the collaboration would have to
*  pretend, well, they would, they would not know whether it was a real signal or fake. So they
*  would analyze the data, write a paper, the whole bit, because that was the only way to be fair.
*  And I think that, you know, likewise, when we're talking about, you know,
*  racism, we all agree racism is bad, but there's lots of people who think that racism is,
*  racism is basically over, that there aren't really bad effects from racism. And I think that those
*  people, whether whatever conclusions they reach, they have an obligation to really try very, very
*  hard to make sure they are seeing things from the perspective of people who are suffering from
*  racism. And that seems to me to be the definition of empathy. I would agree with that, but I think
*  it's important to get the causality right. So it's not like I'm a guy who just doesn't care about
*  other races. I just care about myself and I think there's no problem race and so on. And then, I
*  mean, in case example, and then I somehow find myself empathizing with somebody from a far off
*  land or, or, you know, a racial minority in my community, and that expands my moral circle.
*  I don't think that's actually how it happens. I don't think we find ourselves almost by accident
*  empathizing people whose lives are very different from ours. We're often very good at keeping our
*  empathy close, close in, closed in. I think what happens is, is people come through rationality
*  and other means to a broader worldview, a more cosmopolitan view, say, and then because of this,
*  they choose to empathize with others and try to understand the lives of others.
*  And, you know, I, I, I hate to be too agreeable, but, but I, I, I do think if, if I'm in a, you know,
*  it was when running a diverse lab with people with different backgrounds, I might have a
*  fundamentalist Christian, I might have someone who is, has a severe hearing disability and so on.
*  In order to run this well with both practically and also trying to be a good person, I should try
*  my best to, to know what it's like to be these other people. I do think though, that the best
*  way to find out isn't to go through some empathic exercise. It's mostly usually to ask them.
*  Hmm. I feel-
*  That's always very good advice. I agree.
*  You know, I, I think there's somewhat of an arrogance to say that somebody like you or
*  somebody like me could, could feel what it's like to be in a very different situation. We try,
*  there's a pleasure in trying, that's what literature, movies and so on. But if I really
*  want to know what it's like to be, to have, you know, a severe disability or, or come from a very
*  different culture or be, be a fundamentalist in a, in a very secular society, I don't think empathy
*  itself in the sense of sort of gritting my teeth and trying to put myself in a person's shoes is
*  the way to go. I think what you do is you talk to the person, you treat them as, as, and, and you,
*  you, you come to conclusion at the end, maybe say, look, I'm actually not going to end up knowing
*  what it's like to be a woman in a sexist society. I'm really not. I'm never going to really feel it,
*  but I could listen to people in that situation, talk to them, what's fair, what's decent,
*  what satisfies principles of justice and morality and follow that. So maybe I am actually being,
*  being disagreeable. I would, I would argue that somebody with no capacity for empathy in any
*  interesting sense who was willing to listen to people and who had, who, who honored principles
*  of justice and morality and fairness could be like a great moral person and could do very well
*  in the world. While someone who, who really wanted to feel what it's like to be other people,
*  I actually think is, is running all sorts of sort of moral and practical risks.
*  Good. Actually, I like, I love that even though that's just sort of a final emphasis, I think
*  that really crystallizes what I take to be the heart of what you're saying that I am very happy
*  to agree with. It's interesting, the thought experiment of someone who had no empathy,
*  I could agree that as long as we somehow gave them the right moral starting point, they could
*  be a very moral person. And then I would say, just to be troublesome about it, that since none of us
*  are that person and we do have empathy that, and we do have other emotions discussed and tribal
*  identification and so forth, that empathy, that the combination of rationality and empathy aimed
*  at the right people is a crucial tool in overcoming our first most primitive instincts. There you go.
*  Well, that's not that actually. You know, the book's long been out, so I'm willing to
*  concede some points. But let me put it this way, and I'm curious whether you'd agree or disagree.
*  I think that suppose you are, just take the example that we're both familiar with,
*  you're running a large and diverse lab with a lot of people or department or something
*  with a lot of people. I actually think high levels of empathy are more likely to be a
*  hindrance than a help. They will do good in exactly the way you're talking about. It'll
*  give you the person the possibility of feeling what it's like to be somebody who's very different
*  but as is typically utilized, the person of high empathy will just feel a lot about the fates of
*  people who standardly elicit empathy. It takes a lot of effort to shift empathy from the usual targets
*  and focus them to people who aren't the usual targets. It's like any sort of bias. There's
*  this underlying bias towards the familiar and the friendly and the people like you that mean
*  people of high empathy, I think people of high feelings in general, will just naturally direct
*  these feelings towards those who are like them. Yeah, they have the capacity to do otherwise,
*  but 90% of the time they'll be zooming in on that person who was just like them when they were in
*  graduate school. How could you not understand that person's struggles and difficulty? Well,
*  there's this weird person in the corner with the funny clothes and the funny accent.
*  I can imagine what it's like to be them, but it's a lot of work.
*  Good. I think at this point we're slicing the baloney of our differences very thinly
*  and most people get it. You want to correctly, I think, point out that giving into the empathy
*  that we naturally have can lead to just as many deleterious consequences as good ones. I want to
*  emphasize the fact that trying to have empathy for people, unlike ourselves, is a useful corrective.
*  Good. People can choose their own balance there. You can have a Twitter poll.
*  Yeah, but you're not done. You're not done writing books. You're moving on to other things. I've
*  noticed that you're interested in cruelty these days. I'm very much hoping that the sequel to
*  Against Empathy will be in favor of cruelty. That would be a great book title.
*  Leaning into the contrarian part of the show.
*  I'm actually quite against cruelty.
*  I will satisfy your appetite for the controversial. I have heterodox views about dehumanization.
*  Which is good. Maybe my book could be in favor of dehumanization, or at least
*  dehumanization is not the problem you think it is.
*  It's related to the empathy thing. Putting ourselves in the shoes of somebody else,
*  and now you're turning that on its head a little bit. How do we
*  perceive or think about the people who are not being nice to?
*  That's right. It stems from my empathy work, which is a really sensible challenge to me.
*  If you didn't have empathy, you wouldn't really fully see the humanity of other people.
*  When you don't see the humanity of other people, they argue, you dehumanize them. You don't think
*  of them as fully human. Once you do that, that's terribly. That's morally terrible.
*  If you really know what it's like to be another person, you really feel what it's like to be them,
*  you treat them as full humans, you have to treat them with respect and love.
*  This is the conventional point of view, right?
*  I think every word of it's wrong. Dehumanizing is awful. To treat somebody as less than human is
*  to make a moral and factual mistake. I've been convinced by a lot of people, really smart thinkers
*  on this, like Quame Anthony Appiah and Kate Mann and others, that some of the worst things we do
*  to other people are in full recognition of their humanity. This is a very depressing conclusion,
*  I have to say. It's a very depressing conclusion. The dehumanization thesis is so cheerful.
*  It basically says, look, all the evil in the world, it's based on a mistake. People confusingly
*  think the Jews or the blacks or the gays or the women aren't fully human. Once they come to their
*  senses and realize that they're real people, then all this cruelty and nasty stuff will go away.
*  It's so cheering, but I think when you look at atrocities and everyday violence and cruelty,
*  often it's motivated by a full appreciation of others' humanity.
*  Those are the case studies. Kate Mann makes the case regarding gendered violence,
*  like domestic abuse of women by men. She says, look, when this guy hates women or beats up on his
*  spouse, it's not that he's thinking of them, oh, they're non-human. They're just things. They're
*  just objects. If you thought that, why would you want to make people suffer? Why would you be so
*  angry at them? Rather, he's responding in a way one responds to people. People could be a source
*  of delight and love and transcendence, but people could really make you mad.
*  Sean, if I wanted to make you suffer, the way that would happen is if somehow I felt you were
*  humiliating me, or you had done some horrible moral wrong, or you were this deep threat to me,
*  all very human things. If I thought of you as just an object or a machine or an animal, well,
*  then maybe I wouldn't treat you kindly, but I'd have no interest in hurting you.
*  Yeah. We don't go out of our way to abuse chairs and tables. We go out of our way to abuse people.
*  Exactly. Exactly. Now, again, dehumanization is terrible because we also don't go out of our way
*  to treat chairs and table with any respect or any kindness. A lot of mass exterminations often say,
*  well, they're just vermin. But torture, degradation, humiliation, both at the atrocity
*  level but also at the individual level, seem to involve the supposition that you're dealing
*  with people. There's some laboratory work on this, finding that sometimes when you view somebody as
*  morally wrong, a morally bad individual, you in fact, you exaggerate their human traits
*  as if to make their evilness more salient and to give you more of an invitation to hurt them.
*  Can you give me an example of that? Yeah. This is work by Tage, Ray, and his colleagues.
*  Very nice research where you give people scenarios where you ask them to do different things to
*  people. It's all hypothetical, pen and paper stuff. In one condition, you say, what if I gave you a
*  large sum of money to break this guy's thumb? Right. In another condition, so imagine that.
*  So much money you can't help but do it. Then another condition is this guy is a serial rapist.
*  Give a great detail. Now, suppose you decide on this grounds to break his thumb. If you're willing
*  to do it, it shifts your feelings towards him in different ways. If you're hurting him as
*  instrumental, you'll tend to dehumanize him. You'll say, oh, it doesn't matter. He's not much of a
*  person anyway. But if you're hurting of him is sort of moralistic. Ray studies moralistic violence.
*  You tend to accelerate his human traits. Similarly, if you want to get somebody to
*  hurt somebody for money, you'll do better by saying, oh, they're just a thing. They don't
*  feel much. But if you want to get somebody to hurt somebody else in response to something that that
*  person did, if you focus on their moral traits, you'll do better. So, you know, and again, this
*  has political resonance. Think how you would act if you want people to lash out on immigrants,
*  what you would say about the immigrants. And it depends the sort of, if you want them to ignore
*  the immigrants or just treat them as dispensable or disposable, you'd say one thing. If you wanted
*  them to really hate them, you would say another. Right. And so what does this teach us about human
*  psychology? I mean, in some sense, is it a little bit too glib to say we don't want to go around
*  hurting people? So if, you know, just for instrumentally, we're paid money, we want to
*  dehumanize them. But there's this countervailing punishment reflex or cruelty reflex?
*  Punishment, moralization. A lot of people pointed out that when we're cruel to one another,
*  we don't think of ourselves as villains. We don't say, oh my God, I'm such a terrible person for
*  wanting that person to suffer. Rather, we're often proud of ourselves. We think of ourselves as moral
*  agents. Again, you see this in the political realm. You see the incredibly, I'm on Twitter a lot,
*  too much. Well, it's an experimental lab for cruelty. You know, it's as good as any.
*  It's all data. And you see the extraordinary nastiness directed towards some groups of people
*  against other groups of people because they're, you know, people that hatred directed towards,
*  I don't know, social justice warriors on the one hand versus, you know,
*  men's rights activists on the other hand. And the people directing this hatred and cruelty
*  don't think, God, I'm such a terrible person for doing this. Rather, they're proud of themselves
*  because, you know, Harvey Weinstein or Donald Trump or Bernie Sanders, whoever their target is,
*  they have it coming. They're bad people and they have it coming. And what this suggests is,
*  in general, and which I think is true, is that our moral feelings towards other people
*  are have multiple consequences. It drives compassion and love and kindness,
*  but also drives cruelty and reprisal and punishment. And so seeing somebody as a person
*  has all sorts of consequences. Yeah. So do we conclude that in some sense, we have natural
*  tendencies, proclivities toward reward and punishment with respect to other people? We
*  think some people should be rewarded. Some people just should be punished. That's the right,
*  valorous, just thing to do. We do. And I think this is universal. And in my own day job, I've done
*  work studies with children and babies. And we have research suggesting that by a child's first
*  birthday, they have some moral intuitions. They distinguish good guys from bad guys.
*  They favor good guys over bad guys. You look at about 18 month olds,
*  18 month olds will reward good guys and punish bad guys by giving treats or taking away treats.
*  A few years later, you get the emergence of so-called altruistic punishment,
*  where they'll actually give up resources to make another one suffer.
*  And there's big cultural differences in this and it changes across in age and gender and society.
*  But I think what you're talking about, the desire to reward the good and punish the bad
*  is actually part of our human nature. And it's not just casual cruelty to people we meet. It
*  sounds like it has important implications for the criminal justice system, for example.
*  It does. It does. And so, take one example. There's a lot of people think victims' impact
*  statements are wonderful things, where the victim talks about the trauma he or she has had,
*  but the death of being raped or being assaulted or the death of a child or something.
*  And then the jury or the judge now, based on that, determines the punishment.
*  And I could see, I know why people favor this, giving the victim a voice is very powerful.
*  But this seems to have all the worst features of empathy and our punitive desire.
*  Right. Among other things, for instance, that means if a victim is an attractive,
*  articulate person, there'll be a greater punishment towards the perpetrator than if the victim is
*  ugly and solid. Right. But so, yeah, this is very much along this theme of the relationship
*  between reason and emotion. The victim statement is blatantly appealing to emotion. It's not saying,
*  well, this person did the following things that will plug into an algorithm and figure out
*  how to treat them. In the criminal justice system, it's saying, no, what they did is really
*  emotionally resonant, so they should be treated worse. And what you're saying is
*  that's no way to run a justice system. I am. That's exactly right. Just like I think
*  empathy is no way to guide who we're kind to or what we do for charity, our punitive impulses,
*  which often feed off of empathy, are a terrible way to run a criminal justice system. For all
*  sorts of reasons of bias, depending on who the individual is, but also because the question of
*  how much something offends our gut is actually not a really good way to decide how to meet
*  out punishment. Right. And I think here I'm more or less completely on board. I think the anti-cruelty
*  is an easier sell than the anti-empathy bandwagon. But just for purposes of conversation,
*  let me push back a little bit. We did start by saying there is this relationship between emotion
*  and reason. Isn't there something to be said for letting some of our emotional resonance
*  into our decision-making process, even if that emotional resonance is this person is bad,
*  they should be punished, they should be treated badly?
*  Yeah. I think it's sort of a question of where and when. I don't think much of the claim,
*  and I don't think this is what you're arguing for, that because of our emotions about somebody who
*  did a horrible crime, prison rape becomes this amusing matter to us, where the idea of somebody
*  being raped in prison is a source of amusement and pleasure. I think that that's sort of allowing
*  us to exercise the worst aspects of ourselves. On the other hand, I think you're raising an
*  important point, which is to have a rich life is to have a life that includes emotions. And emotions
*  play an important role regulating our feelings towards others. So I'm not against being biased
*  towards your friends over other people, your family, or other people. I'm not against feeling
*  empathy for those you love in sort of intimate personal ways. And I'm not even against some degree
*  of retribution or punitive aspects towards people in everyday interactions. If you write a savage
*  review of my book, well, we are human. String them up.
*  Okay. Well, you said that, but yeah. I've had book reviews. I know what it's like.
*  That's where I go. Just for a little while, you could exercise the fantasy of-
*  Proportionate response. Yes. Well, can we learn anything? Good. So there's a realization that
*  an element of being cruel comes not from dehumanization, but from humanization.
*  Is that actionable intelligence? Can we learn to be less cruel people by appreciating that fact?
*  I think so. I think in general, I didn't often be quite skeptical about what psychology tells us
*  about how to live our everyday lives. But I think this is one case where simply knowing it
*  makes a difference. And this comes up in cases. It actually has come up in issues of international
*  relations where it used to be thought, for instance, that if the Israelis only knew what it was like to
*  be Palestinian, then peace would reign and so on. And there's been sophisticated psychologists
*  that looked at this and often find that increased intimacy and understanding of other people
*  minds and what goes on in there often makes things worse and not better. If you really know
*  what it's like to be in the head of somebody who hates you, then it's not a good thing. And maybe
*  treating them as a little bit less of an individual and more as a problem to be solved and something,
*  and a negotiation partner is actually better off. I think it teaches us in general to be a bit more
*  cautious about the idea that getting close to another person will make us kinder to them.
*  Well, I certainly do think having had some conversations about the nature of morality and
*  justice and things like that, plenty of people are willing to just stop being rational about these
*  things and say, no, that's just wrong. That's just right. I don't need to justify it anymore. And
*  I'm certainly on board in taking moral behavior or just behavior as being subject to rational
*  analysis, just like everything else. That's right. And it's complicated in all sorts of
*  interesting ways. For one thing, I think in the end, you were talking to me and talked about Hume
*  at the beginning, there's going to be some moral intuitions, just like there's some scientific
*  intuitions that are sort of rock bottom. If you don't agree with me, then you're going to be
*  hurting people. It's not clear we have much more to talk about. But if you say to me, well,
*  we've got to have open borders. And I say, oh, why do you think that? And you just say,
*  it's a fundamental moral view. And you know, stomp your feet. Well, that's not very productive.
*  Yeah. It doesn't sound like something that should qualify as a fundamental. Even if it's the right
*  view, whether or not it's not fundamental, it should be derived from something a little bit more.
*  That's right. I mean, I've had arguments about charter schools where somebody said,
*  this is a fundamental moral position. And they're like, what, really?
*  And in some way, if you think of the function of political moral arguments,
*  sometimes when people do that, it's not that they appreciate that you could actually argue
*  about these things. What they're saying is it's immoral to do so. What they're saying is actually,
*  given the kind of person I am, I want to be seen and see myself as somebody who draws the line here.
*  Well, you noted earlier that you were not trying to take a certain stance toward what is the once
*  and for all correct moral theory, right? But can I just ask, you know, for contextual purposes,
*  are you would you qualify yourself as a moral realist? Do you think there is ultimately right
*  and wrong? Or is it more constructed by individual people in societies?
*  Yeah, I'm definitely a moral realist. I think that there are facts that matter as to what's
*  right and what's wrong. Now, I don't think moral truths are the same as physical truths. I think
*  if there were no people, there'd be no morality. If there was no, if people were constituted
*  differently, our morality would be differently. But given how people are constituted, I think
*  there are things you say are moral truths, or at least moral universals. So, you know, there's a
*  lot of philosophy here, some of it that goes to meta ethics, some of it goes over my head. But
*  I would think that there are, you could point to another culture of humans and say, they're doing
*  things badly. And if they came up to you and said, well, we agree, we've all all of us, we like
*  slavery, or we like the oppression of women. I think one could say, well, you're just mistaken.
*  If you thought harder, you'd realize you shouldn't be doing things that way.
*  Yeah, it's tough to say, because it's like, like you already admitted, it's not the same kind of
*  mistake as if they thought that the earth was the center of the universe, right? Like, it's not a
*  mistake you can disprove by doing some experiment. That's right. That's right. So it is, it is harder.
*  You can't just say, well, if only you had better telescopes or paid more attention, I thought
*  things through, you simply know this. On the other hand, and here I'm kind of borrowing an argument
*  from Sam Harris, who I don't fully agree with on this, but, but, but his argument strikes me as good,
*  which is because they're human, you're human, you guys share certain premises,
*  unnecessary suffering is bad. And you could sort of, if you spend enough time with them
*  and they're rational, which they would be given enough time, you could persuade them the way you're
*  doing things, say slavery doesn't work. It doesn't, it doesn't respect people. What you think should
*  be respecting, it doesn't maximize what you think should be maximized. So I'm not like coming in as
*  a 21st century American saying, you're doing things wrong by my lights. Rather, what I'm doing is I'm
*  saying to them, say, Nazi Germany or whatever I'm saying, you're doing things wrong by your lights.
*  If you thought about this long enough, you'd realize that that, that the way you're doing things
*  violates your own intuitions of how it should be done. Yeah. I mean, we're not going to solve this
*  here and it's a little bit off topic, but it just, I just need to get in my disagreement with Sam
*  about exactly this point, which is, I think it's kind of, it might very well be true. And then as
*  a matter of practice, I'm very willing to believe that it is true, that I can reason with very
*  different people doing very different things on the basis of common moral intuitions. But I think
*  it's a huge mistake to then leap from that to say, we need to be more realists. We don't need to
*  be more realists. We just have to find that common ground and reason from there. And I think that as
*  a matter of ontology, I'm not a moral realist. I think that we can, you can just accept the reality
*  that morals are constructed by human beings and go from there. For the purposes here, I will agree
*  with that. Yeah. More, more realism is another step. Exactly. That's right. And, and, and, and it's,
*  and I'm tentative about making that step, but at the same time, you would sort of ask whether I'm a
*  moral realist or moral relativist. Moral relativism is typically associated with the position that,
*  well, if enough people in a society are happy with some way of doing things, then that's fine by them.
*  And you and I are both universalists in a sense that we think there's a fundamental human nature,
*  so some groups can do it right. Some groups can do it wrong. That's enough for me.
*  Yeah. I'm, we're not, like I said, we're not going to, I'm not, I'm not even a universalist.
*  I'm a constructivist, but that's okay. It doesn't make any difference to how you act in the world.
*  Okay. That's what my only point right now. As long as you can disapprove of other people.
*  That's right. Those people, boy, until I have them on the podcast and then we'll, they'll get their
*  say. But speaking of Sam, you wrote a very provocative, just to wrap things up, you wrote
*  a provocative little piece with him about robots and artificial intelligence. Let's, let's start
*  torturing the robots. Is that a bad thing? You know, do you, should we extend some of the
*  considerations we've had here to non-biological intelligences? What is your, where do you come
*  down there? You know, it was, it was a hugely fun article with Sam. It grew out of a, a,
*  actually a podcast discussion I had with him and, and it was focusing on Westworld,
*  the example of Westworld, which was, which was showing at the time we were talking,
*  we were both watching it. And I'm sure you know, but so many, some people don't, with the, the,
*  the story of Westworld, originally a movie than an HBO series is there's a, in the near future,
*  they create this wild Western fantasy, which you could visit. And it contains incredibly
*  realistic robots who are indistinguishable from people. And some of the guests take advantage of
*  this to kill, to rape, to torture and so on. And so-
*  Because they're just robots, right?
*  Pardon me? Yes, that's right.
*  Because they're just robots. Who cares?
*  That's right. And so, so you describe, it was a fun article to write. It was surprisingly
*  uncontroversial. You never know, but, but so what we said is you shouldn't do that. You shouldn't,
*  you shouldn't rape and torture and, and kill robots like that. And our argument was twofold.
*  One, one part of it was that you don't know they might be conscious. And if they were conscious
*  and could feel pain, then you definitely shouldn't do that for the same reason you
*  shouldn't do it for a person. And, and then the second part of it is even if you can know for sure
*  that they weren't conscious, it, it, it seems likely to us at least that doing this to things
*  that were indistinguishable from people would affect your relationships with people.
*  So it's like Kant's position about being cruel to animals, which is he thought animals, there's
*  nothing wrong with being cruel to animals, but said if you were, it would make you cruel to people.
*  Right. I mean, these are two very different arguments that you're presenting. So
*  the first one I take it is, is not very controversial.
*  Yeah. But although you made me think that I really missed a chance when I
*  interviewed David Chalmers on the podcast, because we talked about two topics, which I
*  consider to be more or less separate. One was the nature of consciousness and the other is,
*  can we live in a simulation? And he thinks that consciousness is not reducible to the physical,
*  that there's some mental properties over and above physical properties, but he also believes
*  that the things that happen in a simulation are just as real as things that happen in the so-called
*  real world. But I didn't quite prod him on whether or not there was tension there. You know, if I
*  simulate an intelligence, but without the consciousness awareness properties that we
*  human beings have, is it still torture to do bad things to it? And I think you are going to be
*  pretty down to earth and say, sure, it's just as bad. Yeah. I would say, I would say that there's
*  often a fact of the matter. I mean, if I, I don't know, if I put a happy face on my laptop
*  and scream at it and try to verbally humiliate it, I'm just doing something foolish. I'm not doing
*  something wrong. But same if I yell at my Alexa or my Siri, which many people do. But so there's a
*  fact of the matter as to whether someone is conscious or not. And then the second part of
*  argument is that even if it isn't, if it's perfectly, I'm sorry, my, my, my Alexa just spoke up.
*  There we go. The, the, even if it's not conscious, it would still be bad. And this was kind of a funny
*  argument for me to make. Cause I think that the claims that violent video games make people worse
*  and violent to humans is actually, are actually mistaken. There's so little evidence for it and
*  so much evidence against it. On the other hand, if you could go and beat a child to death with your
*  hands, knowing it's not a child, but a machine that's indistinguishable, what would that do to
*  you? And I think the answer is nothing good. Well, and I think that it's a West world is a
*  wonderful example to use, but I think that it's very realistic that in the very short term,
*  this kind of problem is going to show up. Right? I mean, we have sex dolls that are looking very
*  realistic. We have things like Siri and Alexa that can talk to us and, and, you know, express
*  emotions, even if they're not conscious by anyone's definition, the idea that it seems to us just like
*  we are torturing or harming something that is like a person is going to become frighteningly plausible.
*  It is going to, it is going to happen sooner or later. The trend is going to go towards
*  increasingly complex and realistic machines, including sex robots. And, you know, what seems
*  like kind of a fun, goofy science fiction example now could be quite serious in a decade now. I mean,
*  what would you put an estimate on how far we are from a machine that's indistinguishable from a
*  person? I think that this is a great question. It depends a lot on how careful you are about
*  distinguishing. I think that we're not that far from machines that you could be tricked into
*  thinking you're human if you didn't try that hard. Right? I think, I think we're there. I think that,
*  you know, there's been these artificial intelligence programs that can, you know,
*  do call center kind of things. And, and ordinary humans don't tell the difference. But if you
*  really put your mind to it and trying to give them the Turing test, they would still, I think you're
*  still very far from being able to pass that. I think so too. I think, I think it's much harder
*  than people say. And I think it just may be possibly as with self-driving cars,
*  it's the last 5% that's going to kill us. Yeah, that's right. Good. So let's be nice to the robots.
*  Let's be nice to each other and let's empathize with some people in the right circumstances and
*  mostly be driven by our rationality. How about that? I think that's a fine way to end. All right,
*  Paul Bloom, thanks so much for being on the podcast. This is very helpful and a lot of fun.
*  Thanks for having me. This was great.
