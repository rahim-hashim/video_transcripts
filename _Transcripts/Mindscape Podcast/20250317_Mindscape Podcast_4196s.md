---
Date Generated: March 24, 2025
Transcription Model: whisper medium 20231117
Length: 4196s
Video Keywords: []
Video Views: 6321
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2025/03/17/308-alison-gopnik-on-children-ai-and-modes-of-thinking/

We often study cognition in other species, in part to learn about modes of thinking that are different from our own. Today's guest, psychologist/philosopher Alison Gopnik, argues that we needn't look that far: human children aren't simply undeveloped adults, they have a way of thinking that is importantly distinct from that of grownups. Children are explorers with ever-expanding neural connections; adults are exploiters who (they think) know how the world works. These studies have important implications for the training and use of artificial intelligence.

Alison Gopnik received her D.Phil in experimental psychology from Oxford University. She is currently a professor of psychology and affiliate professor of philosophy at the University of California, Berkeley. Among her awards are the Association for Psychological Science Lifetime Achievement Award, the Rumelhart Prize for Theoretical Foundations of Cognitive Science, and a Guggenheim Fellowship. She is a past President of the Association for Psychological Science. She is the author of The Scientist in the Crib, The Philosophical Baby, and The Gardener and the Carpenter, among other works.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll

#podcast #ideas #science #philosophy #culture
---

# Mindscape 308 | Alison Gopnik on Children, AI, and Modes of Thinking
**Mindscape Podcast:** [March 17, 2025](https://www.youtube.com/watch?v=WHbMIpNrY64)
*  Hello everyone and welcome to the Mindscape Podcast. I'm your host, Sean Carroll. So here's [[00:00:00](https://www.youtube.com/watch?v=WHbMIpNrY64&t=0.0s)]
*  a question. Given a problem, how do you find the solution to that problem? This is one [[00:00:04](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4.5600000000000005s)]
*  of those questions that sounds deep or profound or something like that, but in fact you might [[00:00:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=10.76s)]
*  worry it is a little bit too abstract. How can we hope to understand how in perfect generality [[00:00:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=14.92s)]
*  to find the answer to a problem if you haven't given me a bit more information about what [[00:00:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=21.16s)]
*  kind of problem it is you're talking about? But it's not so abstract that we can't make [[00:00:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=24.72s)]
*  some progress. You know, in general, how do we in fact go about solving problems? Sometimes, [[00:00:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=29.36s)]
*  hopefully indeed, you'll find a problem that resembles another problem, a problem that [[00:00:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=35.88s)]
*  you've seen before, so you can either use or maybe adapt the kind of solution that you [[00:00:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=41.16s)]
*  already knew about. Other times you know nothing about the context of a problem, so maybe you'll [[00:00:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=46.379999999999995s)]
*  just try some things randomly, sort of flail about, just get some information. These kinds [[00:00:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=51.44s)]
*  of questions, as abstract as they are, turn out to be frighteningly relevant to things like [[00:00:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=57.72s)]
*  building artificial intelligence, right? When you turn on the computer and there's no software on [[00:01:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=63.2s)]
*  it yet, the computer doesn't have any pre-existing strategies for solving problems. You have to [[00:01:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=68.8s)]
*  choose how to build them in. So how should we go about figuring out the best way in different [[00:01:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=74.8s)]
*  contexts to solve problems? Well, one thing to do is to look at what actual human beings actually [[00:01:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=80.48s)]
*  do. The lesson of today's conversation with Alison Gopnik is that human beings use different [[00:01:26](https://www.youtube.com/watch?v=WHbMIpNrY64&t=86.84s)]
*  ways to solve problems in different life stages. There's a way that we do it when we're adults, [[00:01:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=94.52000000000001s)]
*  when we're flourishing in the prime of life, and there's a different thing that we do when [[00:01:39](https://www.youtube.com/watch?v=WHbMIpNrY64&t=99.88000000000001s)]
*  we're children or babies. Very roughly speaking, babies are a little bit more creative, a little [[00:01:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=105.04s)]
*  bit more free-flowing. They just try a whole bunch of things. Their attention is hard to pin [[00:01:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=111.84s)]
*  down. You might have noticed that if you've ever dealt with babies, and that's a feature, not a [[00:01:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=117.0s)]
*  bug. The fact that babies have trouble focusing their attention on something is a reflection of [[00:02:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=122.24000000000001s)]
*  the fact they're trying to learn about the world by interacting with it in many different ways. [[00:02:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=128.76s)]
*  Whereas adults are optimized for something different. Hopefully by the time you're an adult, [[00:02:13](https://www.youtube.com/watch?v=WHbMIpNrY64&t=133.24s)]
*  you're in your 30s, you've learned a lot about problem-solving strategies, and you're more [[00:02:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=138.88s)]
*  about perfecting the methods that you already know rather than flailing around randomly and [[00:02:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=144.20000000000002s)]
*  learning new ones. Not that you can't do it, not that it's impossible, but you're better at some [[00:02:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=151.04000000000002s)]
*  techniques than others. Maybe, who knows, we sort of brush upon the possibility in the conversation [[00:02:37](https://www.youtube.com/watch?v=WHbMIpNrY64&t=157.56s)]
*  that later in life, once you're past your prime reproductive cycle, for example, you can go back [[00:02:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=165.44s)]
*  to being less hidebound. I mean, maybe that would be ideal. We all know people who don't quite live [[00:02:52](https://www.youtube.com/watch?v=WHbMIpNrY64&t=172.4s)]
*  up to that, but you serve different purposes. I guess the overarching lesson here is that there's [[00:02:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=178.72s)]
*  a division of labor, not only between different human beings working in groups, but even between [[00:03:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=185.16s)]
*  different life stages of single human beings. And as we'll talk about, we do in fact learn some [[00:03:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=191.04000000000002s)]
*  lessons that might be very, very relevant to AI and programming computers and thinking about how [[00:03:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=197.20000000000002s)]
*  we should best approach understanding the world. That's what we're here to do here at Mindscape, [[00:03:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=204.52s)]
*  so let's go. [[00:03:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=209.64000000000001s)]
*  Alison Gopnik, welcome to the Mindscape Podcast. [[00:03:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=220.8s)]
*  Happy to be here. [[00:03:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=229.16000000000003s)]
*  So one of the things I guess we could start with from your work that I've derived is the idea that [[00:03:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=230.68s)]
*  little children, kids, babies, whatever, maybe shouldn't just be thought of as unformed adults, [[00:03:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=237.12s)]
*  right? That they actually think in a different way. Is that an okay way to put it? [[00:04:04](https://www.youtube.com/watch?v=WHbMIpNrY64&t=244.48000000000002s)]
*  Yeah, that's exactly the right way to put it. So I think a lot of people have always thought about [[00:04:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=250.48000000000002s)]
*  the 35-year-old psychologist or philosopher as sort of the height of all of intelligence, [[00:04:16](https://www.youtube.com/watch?v=WHbMIpNrY64&t=256.88s)]
*  and then we just build up to that amazing person as we get older, and then we fall off as we [[00:04:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=263.76s)]
*  get older. But of course, that doesn't make very much sense from an evolutionary perspective. And [[00:04:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=270.56s)]
*  in fact, I think what's become clearer and clearer is that children are really fundamentally a [[00:04:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=275.68s)]
*  different kind of intelligence than typical adults are. And there's also some interesting [[00:04:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=281.36s)]
*  questions about elders having a different kind of intelligence as well. So it's more like a kind of [[00:04:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=288.88s)]
*  trade-off between different kinds of intelligences than it is having one magic thing, which is called [[00:04:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=293.76s)]
*  intelligence that we have more of or less of and that we have less of to begin with and more of [[00:05:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=301.12s)]
*  later on. And an idea that I've been working on a lot is an idea that actually comes from computer [[00:05:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=306.0s)]
*  science, which is the idea of a trade-off between different kinds of intelligences, [[00:05:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=312.16s)]
*  and in particular, a trade-off between what's called exploit intelligence and explore intelligence. [[00:05:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=317.84000000000003s)]
*  And what I've argued is that childhood is really about this kind of exploration intelligence, [[00:05:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=323.84000000000003s)]
*  which is not just different from, but even intention with exploit intelligence. And now, [[00:05:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=328.8s)]
*  I have to say, when I first started making these sets of arguments, I was, as you could tell from [[00:05:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=334.64s)]
*  that last comment, I was a little snarky about those 35-year-old philosophers and psychologists [[00:05:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=340.71999999999997s)]
*  sitting and thinking that they were the apex of intelligence. But since my own children have [[00:05:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=349.03999999999996s)]
*  gotten older and I have more grandchildren, now I sort of reverse that. My main feeling now is, [[00:05:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=354.08s)]
*  oh my God, those poor 35-year-olds, the children and the grandmoms are getting to do all the really [[00:05:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=358.24s)]
*  fun human stuff. One of my other slogans is that we're basically human up till puberty and after [[00:06:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=365.12s)]
*  menopause and in between. We're sort of glorified primates. We're doing the things that all the [[00:06:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=371.76s)]
*  primates do. We're finding our way in the dominance hierarchy and we're mating and we're getting [[00:06:16](https://www.youtube.com/watch?v=WHbMIpNrY64&t=376.48s)]
*  resources and all that stuff. And it's only when we're little and we're old that we get to do [[00:06:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=380.48s)]
*  things like theory of mind and discovery about the world and causal inference and cultural [[00:06:26](https://www.youtube.com/watch?v=WHbMIpNrY64&t=386.08s)]
*  transmission and large-scale storytelling, all the things that really make us human. So now, [[00:06:32](https://www.youtube.com/watch?v=WHbMIpNrY64&t=392.15999999999997s)]
*  I feel like, okay, we grandmoms and kids should just keep quiet the fact that we're having all [[00:06:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=398.47999999999996s)]
*  the fun and then the 35-year-olds are having to do all the work. And so, this is going to be a preview [[00:06:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=404.88s)]
*  for what's to come in the conversation, but that's basically because we're in that exploratory phase [[00:06:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=411.12s)]
*  early on and in what is nominally thought of as the prime of our adult lives, we're more focused, [[00:06:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=417.68s)]
*  right? We have tasks and we're very good at doing those tasks, but we're less good at being flexible [[00:07:04](https://www.youtube.com/watch?v=WHbMIpNrY64&t=424.16s)]
*  and creative about things. So there's this idea that comes from computer science about trying to [[00:07:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=428.48s)]
*  solve, what happens when you're trying to solve what's called a high-dimensional task? That means [[00:07:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=435.84000000000003s)]
*  a problem that has lots of different possible solutions that vary along a lot of different [[00:07:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=440.4s)]
*  dimensions. And one thing you can do is you can just kind of tweak what you're already doing a [[00:07:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=444.72s)]
*  little bit and see if that makes things a bit better. And that's a very efficient, effective way [[00:07:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=448.88s)]
*  of trying to solve the problem. So just change where you are a little bit, see if that makes [[00:07:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=454.72s)]
*  it better. If it does, then try something else. And that's the essential exploit strategy. That's [[00:07:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=458.56s)]
*  the grownup strategy. Here's the thing that I need to do. I'm going to focus on trying to do it. [[00:07:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=466.32s)]
*  But of course, the problem with that is that there might be another solution that's much [[00:07:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=470.71999999999997s)]
*  further out in this space that's, as it were, in the far reaches of the box, at least, if not [[00:07:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=475.28s)]
*  actually out of the box. And if you just keep making these little tweaks, you're never going [[00:08:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=481.2s)]
*  to get there. So what you could do is you could bounce around, try lots of things, sort of [[00:08:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=485.68s)]
*  independent of whether you think they're going to be useful or not. Just try things. Just see [[00:08:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=492.0s)]
*  how the world works. And in computer science, they talk about this as the difference between [[00:08:16](https://www.youtube.com/watch?v=WHbMIpNrY64&t=496.16s)]
*  a low temperature search. Think about it. Your audience will get this analogy, right? Think [[00:08:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=502.08000000000004s)]
*  about it as if it was like a molecule of air that's just either going very slowly or bouncing [[00:08:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=508.48s)]
*  randomly around in this space. And the interesting solution that comes out of computer science is [[00:08:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=513.6800000000001s)]
*  that the best strategy... So these two things trade off against each other, right? Like you [[00:08:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=521.12s)]
*  can't do both at the same time. So which should you do? And it turns out the best strategy is [[00:08:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=524.64s)]
*  start out with a big bouncy, random, wild search, even though, of course, that's going to take a [[00:08:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=529.4399999999999s)]
*  lot longer and you're going to spend a lot of time thinking about things that actually aren't going [[00:08:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=535.52s)]
*  to help you, and then gradually cool off to the more focused search. And people in computer science [[00:08:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=538.8s)]
*  talk about this as simulated annealing. It's like what happens when you heat up... Again, your [[00:09:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=548.16s)]
*  audience should know this. So what happens when you heat up metal and cool it to make it more [[00:09:13](https://www.youtube.com/watch?v=WHbMIpNrY64&t=553.2s)]
*  robust. And what I think is that childhood is essentially evolution's way of doing simulated [[00:09:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=557.6800000000001s)]
*  annealing. So if you think about those two descriptions, there's one way that's focused [[00:09:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=563.6800000000001s)]
*  and oriented towards outputs, and then there's this noisy, bouncy, random kind of behavior. [[00:09:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=569.0400000000001s)]
*  You can sort of pretty immediately think which one fits your four-year-old better. [[00:09:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=574.72s)]
*  Yeah. And the thought is that even though that might look from some perspectives as if it's [[00:09:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=578.48s)]
*  a deficit because the kids are saying weird, crazy things, they're off in strange pretend land, [[00:09:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=585.36s)]
*  they do things that don't seem to make sense at first, if you're in explore mode, then that's [[00:09:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=591.0400000000001s)]
*  really the thing that you want to do more than anything else. So of course, in some ways, [[00:09:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=595.84s)]
*  what this means, and we've actually shown this empirically, is that children are more creative [[00:10:00](https://www.youtube.com/watch?v=WHbMIpNrY64&t=600.32s)]
*  than grownups, at least sometimes. So for instance, we've done a bunch of studies where [[00:10:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=606.16s)]
*  we give children and grownups a problem that either has a pretty obvious... There's an obvious [[00:10:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=610.88s)]
*  solution you could try, or a much less obvious hypothesis, one that to start out with is less [[00:10:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=617.36s)]
*  likely. And what we've discovered is that when the solution is the more likely, the more obvious one, [[00:10:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=622.7199999999999s)]
*  as you might expect, the grownups are better at getting to the solution. But when it's the [[00:10:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=628.0799999999999s)]
*  unlikely hypothesis, four-year-olds are actually better than say college undergraduates [[00:10:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=631.76s)]
*  at getting to the right solution. So in some ways, the four-year-olds are more creative than adults, [[00:10:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=636.56s)]
*  but the trouble is if you look at what we think of when we think about creativity in adults, [[00:10:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=644.24s)]
*  it's really got two pieces, so it's not really easy to compare. So if you look at what a creative [[00:10:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=648.64s)]
*  solution for an adult, the first part is generate lots of possibilities. And then the second part [[00:10:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=655.84s)]
*  pick out the one that's good, pay attention to the ones that are good and not the ones that aren't. [[00:11:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=662.4s)]
*  And that first part, generate lots of solutions, think of lots of possibilities, that's where the [[00:11:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=666.4799999999999s)]
*  kids really excel. But for adults, you also have to have the part about choosing the right solution [[00:11:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=671.68s)]
*  in the end. And that's the part where those executive exploit capacities seem to be more [[00:11:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=680.88s)]
*  useful. So the great philosopher, John Locke, Sean, I know you have the chair of natural [[00:11:26](https://www.youtube.com/watch?v=WHbMIpNrY64&t=686.8s)]
*  philosophy who was a great natural philosopher, said that there were two faculties for human [[00:11:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=694.0799999999999s)]
*  intelligence. One was the faculty of wit and one was the faculty of judgment. So the faculty of [[00:11:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=700.88s)]
*  wit was generate lots of new ideas and the faculty of judgment was pick out which ones were actually [[00:11:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=705.92s)]
*  good ones. And kids seem to have a tremendous amount of the faculty of wit, not quite so much [[00:11:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=711.04s)]
*  at the faculty of judgment. Fair enough. But okay, if we're giving evolution credit for coming up [[00:11:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=716.08s)]
*  with this, you know, nice division of temporal labor over our lifetimes, let's face up to the [[00:12:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=722.48s)]
*  fact that kids are pretty helpless, like human babies, they take a long time to be able to fend [[00:12:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=729.12s)]
*  for themselves. Could you talk a little bit about how that fits in with what we know about other [[00:12:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=734.8000000000001s)]
*  species and whether or not it's like an accident or actually optimizing something? Yeah, it's [[00:12:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=739.2s)]
*  interesting because if you look across an incredibly wide range of species, even including [[00:12:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=744.48s)]
*  insects, and there's some arguments that this is true even for plants, but certainly true for all [[00:12:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=750.8000000000001s)]
*  the primates and for mammals in general, you see this really striking correlation between how smart, [[00:12:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=755.9200000000001s)]
*  perhaps from a human perspective, but how good an animal is at learning, how large its brain is, [[00:12:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=764.32s)]
*  how much it uses its brain, and how long a childhood it has. So you see it, the first context [[00:12:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=770.72s)]
*  in which people notice this was with birds. So if you look at birds like corvids or crows, very, [[00:12:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=778.0s)]
*  very smart birds, they spend as long as a year or two being fledglings, needing to be taken care of. [[00:13:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=783.9200000000001s)]
*  Whereas if you think about like the domestic chicken, chickens are mature within a couple of [[00:13:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=790.24s)]
*  weeks. And although this gets me in trouble with chicken lovers, everywhere they're not very bright [[00:13:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=794.4s)]
*  there. Or a better way of putting it is they're extremely good at doing the things that they do [[00:13:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=801.04s)]
*  well, like pecking for grain, and they're very good at doing those from the time they're born. [[00:13:25](https://www.youtube.com/watch?v=WHbMIpNrY64&t=805.4399999999999s)]
*  They're not so good at learning. And if you think about it from this sort of explorer-sploit [[00:13:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=809.04s)]
*  perspective, that kind of makes sense. So if you're going to be a creature that lives in a [[00:13:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=814.0799999999999s)]
*  changing, unpredictable environment that has to do lots of new things, you're going to need a period [[00:13:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=820.8s)]
*  to be able to do that exploration before you can exploit. And that means that in that period, [[00:13:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=828.0799999999999s)]
*  you're going to be really bad at doing things. You're going to be helpless. And you're going to [[00:13:52](https://www.youtube.com/watch?v=WHbMIpNrY64&t=832.9599999999999s)]
*  need other, you're going to need the other adult members of the species to look after you, make [[00:13:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=836.24s)]
*  sure you stay alive, make sure you have enough calories to fuel all of this [[00:14:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=841.8399999999999s)]
*  ferocious learning that's going on. And that seems to be sort of the evolutionary strategy. [[00:14:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=850.32s)]
*  The calories are kind of a nice part of this, because it turns out that if you look at how [[00:14:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=855.7600000000001s)]
*  many, what percentage of your calories your brain uses up, even as an adult, 20% of your calories [[00:14:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=862.0s)]
*  are going to your brain, which means that your brain is an expensive computing gadget. But when [[00:14:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=870.08s)]
*  you were four, 60%, in fact, almost 70% of your calories were going to your brain. [[00:14:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=876.08s)]
*  So basically, your average four-year-old is like something out of Doctor Who or science fiction. [[00:14:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=882.88s)]
*  It's basically this giant, hungry brain that's going around the world, hypnotizing us into [[00:14:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=888.88s)]
*  feeding it both a bunch of peanut butter sandwiches so its brain can work and a bunch of data so its [[00:14:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=894.96s)]
*  brain can work. So that's interesting, because you're pointing to an explanation that is not [[00:15:00](https://www.youtube.com/watch?v=WHbMIpNrY64&t=900.24s)]
*  purely physical or even mostly physical. It's not about brain size or anything like that, but that [[00:15:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=906.08s)]
*  if we allow ourselves to poetically attribute forces of natural design, [[00:15:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=912.88s)]
*  intelligent design rather, to evolution, this sort of planned difficulty in taking care of oneself [[00:15:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=921.04s)]
*  is actually serving the purpose of letting the kids explore, be creative, and that's supposed [[00:15:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=929.68s)]
*  to pay off later in life. That's right. So the thought is, and you know, of course, [[00:15:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=935.04s)]
*  as always in biology and evolution, it's complicated and it's connected to other [[00:15:39](https://www.youtube.com/watch?v=WHbMIpNrY64&t=939.68s)]
*  kinds of aspects of animals. And there are smart animals who don't have a long childhood, like [[00:15:43](https://www.youtube.com/watch?v=WHbMIpNrY64&t=943.5999999999999s)]
*  cephalopods, octopuses, for example. Different kinds of animals seem to solve this explore-exploit [[00:15:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=949.36s)]
*  problem in different ways. Sometimes insects, for instance, seem to do it by a kind of division of [[00:15:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=956.4s)]
*  labor among some ants and bees are explorers or scouts and some of them are workers who are [[00:16:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=962.72s)]
*  actually doing things. So there's different ways of solving it. But it does seem like this is a [[00:16:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=970.1600000000001s)]
*  strikingly general and common solution among a very, very wide range of species. And that [[00:16:13](https://www.youtube.com/watch?v=WHbMIpNrY64&t=973.9200000000001s)]
*  suggests that it's got this adaptive value. Is this division of labor thing a general feature? [[00:16:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=980.24s)]
*  I think I remember it was Michael Muthakrishna who I had on the podcast and who mentioned this [[00:16:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=989.36s)]
*  experiment, which I guess is famous among psychologists, where human children and chimpanzees [[00:16:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=993.8399999999999s)]
*  were asked to poke sticks into a box and get a reward. And then when it's revealed that one [[00:16:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1000.8s)]
*  of the sticks isn't doing anything, the children didn't learn. Sorry. Yeah, the children didn't [[00:16:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1006.64s)]
*  learn and the chimpanzees did because the children were trusting the grownups. [[00:16:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1013.44s)]
*  Right. Yeah. And of course, that's another dimension of having this long childhood and [[00:16:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1018.8000000000001s)]
*  having this particular kind of intelligence, which is that we are also social and cultural learners. [[00:17:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1025.04s)]
*  So we pass on information from one generation to another in a way that other animals do it [[00:17:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1031.04s)]
*  more simply, but we do more of it than any other animal does. And again, a lot of that social [[00:17:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1038.24s)]
*  transmission is taking place in the context of caregivers, people who are moms and dads who are [[00:17:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1044.08s)]
*  helping the kids. But it's interesting because that is a famous experiment. But it's worth pointing [[00:17:32](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1052.0s)]
*  out that, again, there's this trade off. So if you just imitate what the other people around you are [[00:17:37](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1057.52s)]
*  doing, then there's kind of no point because you're not going to make any progress. So somebody [[00:17:43](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1063.92s)]
*  along the line has to actually innovate as well as imitating. And there's a bunch of work we've [[00:17:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1069.6000000000001s)]
*  done, some of it and other people have as well, that shows that children are, when they're imitating, [[00:17:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1076.0800000000002s)]
*  they're kind of balancing, well, what do I think about how this actually works? And what do I think [[00:18:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1081.68s)]
*  about the person who's actually demonstrating it to me? So for example, there's a lovely experiment [[00:18:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1086.8000000000002s)]
*  where if you have the experimenter says, I'm going to show you how this works, the children are much [[00:18:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1092.48s)]
*  more likely to do the kind of over imitation that you've described. So they'll just do what the [[00:18:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1099.04s)]
*  experimenter did. But if the experimenter says, gee, look at this, I don't know how this works. [[00:18:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1103.92s)]
*  Do you know how this works? Then the children are much more likely to explore, including exploring [[00:18:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1108.0s)]
*  in these kind of unlikely ways. And vice versa, we did some experiments that showed that if you [[00:18:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1113.3600000000001s)]
*  actually show, get, let children discover something about a machine, for instance, a lot of our [[00:18:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1118.8s)]
*  experiments depend on this wonderfully simple, inexpensive machine, the blicket detector. It's [[00:18:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1124.56s)]
*  a little box that lights up and plays music when you put some things on it and not others, then it [[00:18:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1130.32s)]
*  costs like, I don't know, 29.99 or something. It's nice, nice, nice from the grant perspective. [[00:18:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1135.2s)]
*  And it's been extremely productive. So if you do something like [[00:19:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1141.76s)]
*  present the child with a little box, let them play with it. And they see that say, red blocks make it [[00:19:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1145.92s)]
*  go. And then you have an adult who says, oh, blue blocks make the detector go. The children, it's [[00:19:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1152.24s)]
*  interesting. They'll just exactly split the difference between what they see themselves [[00:19:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1158.16s)]
*  and what the adult says. So they won't just rely on what they do see themselves. They won't just [[00:19:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1163.3600000000001s)]
*  rely on the adult, but they'll produce one solution or another kind of in-person [[00:19:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1168.4s)]
*  in proportion to the probability of those two solutions. So I do think the fact that we're social [[00:19:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1175.92s)]
*  beings, but that in the course of cultural and social evolution, Michael might have talked about [[00:19:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1182.0800000000002s)]
*  this, we have to balance imitation and innovation. And it's quite complicated to do that. I think [[00:19:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1186.64s)]
*  that also plays a role in the special intelligence of children. Well, it makes me think very much of [[00:19:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1193.44s)]
*  being an advisor to students, right? Especially graduate students where you want to say, look, [[00:19:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1198.4s)]
*  please do be creative and come up with new ideas, but please also read some of the literature. And [[00:20:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1203.84s)]
*  there's a balance there. You don't want to just slavishly follow what other people have already [[00:20:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1208.56s)]
*  done. Yeah. I mean, I think that one of the interesting things that we're working on now [[00:20:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1212.08s)]
*  is thinking about caregiving, thinking about what happens as you take care of someone else. And [[00:20:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1218.8s)]
*  that's been very, and particularly thinking about the intelligence of caregiving, thinking about how [[00:20:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1224.08s)]
*  hard it is to figure out what you should do as a teacher or a therapist or a parent that will allow [[00:20:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1230.4s)]
*  the person you're caring for to become autonomous, right? You don't want them to just imitate what [[00:20:39](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1239.68s)]
*  you do. You don't want them to just do the same thing, but you also don't want them to get into [[00:20:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1244.96s)]
*  trouble. You don't want them to do stupid or dangerous things. And how I think it's really [[00:20:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1249.44s)]
*  interesting about how caregivers manage to walk that line, no matter what kind of context they're [[00:20:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1254.56s)]
*  in, whether you're thinking about being a grandmother of a two-year-old or you're thinking about being a [[00:21:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1261.28s)]
*  supervisor or postdocs, it's fundamentally the same problem. And it's having those caregivers [[00:21:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1268.3999999999999s)]
*  that enables a lot of that cultural transmission to take place. One of the interesting things that [[00:21:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1274.0s)]
*  has come out that I've been writing and thinking about recently is that actually grandmothers [[00:21:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1279.6s)]
*  seem to be playing a, grandmothers and grandfathers, I always talk about grandmothers [[00:21:25](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1285.6799999999998s)]
*  egocentrically, seem to be playing a particularly important role in that kind of cultural [[00:21:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1291.12s)]
*  transmission. So there's quite a bit of anthropological evidence that when you look at, [[00:21:37](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1297.36s)]
*  who gives the songs, who gives the stories, who tells you the big aspects of the culture? [[00:21:43](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1303.6000000000001s)]
*  It's more likely to be older people than parents. So the parents are kind of trying to deal with [[00:21:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1310.48s)]
*  the everyday, keep the kids alive, keep them fed. And it's actually the grandparents who are, [[00:21:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1316.64s)]
*  in my case, telling, reading Narnia books and singing old Broadway show tunes and doing things [[00:22:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1322.88s)]
*  that are especially designed to serve this function of cultural transmission. And of course, [[00:22:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1332.0800000000002s)]
*  just as we have this exceptionally long childhood, we also have this long postmenopausal [[00:22:16](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1336.16s)]
*  grandmotherhood, elderhood, which is not characteristic of other animals, except, [[00:22:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1342.64s)]
*  interestingly, for orcas. So orcas are one of the few examples of a mammal that also continues to [[00:22:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1349.04s)]
*  live for some substantial period of time after menopause and has grandmothers that live with a [[00:22:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1356.08s)]
*  pod. And what the grandmothers do is pass on information about what to eat and how to function. [[00:22:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1361.9199999999998s)]
*  So especially when things get short, the grandmothers are the ones who lead the pod out to, [[00:22:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1368.56s)]
*  oh, OK, I remember 20 years ago, there was krill in this site and help to help the [[00:22:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1374.24s)]
*  grandchildren, the children and grandchildren to survive. And I think that's another really nice [[00:23:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1381.28s)]
*  sense of a kind of intelligence that's different from what we think of as the standard grown up [[00:23:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1387.12s)]
*  intelligence. That sounds almost too adorable to be true. How sure are we that the killer whales [[00:23:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1391.84s)]
*  really put so much responsibility in the grandmothers' hands? Well, what I like about [[00:23:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1397.12s)]
*  this is what it shows is the really important thing to pass on is recipes, right? That's the [[00:23:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1403.36s)]
*  thing that the grandmothers, that's the thing that the grandmothers are designed by evolution to do. [[00:23:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1408.72s)]
*  And the, I just, again, with the advisor thing, just as it's on my mind, we can be egocentric a [[00:23:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1415.76s)]
*  little bit, that's OK. I do think a very, very common mistake in dealing with students is that [[00:23:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1422.8s)]
*  the older wise folks are sometimes too good at saying why a good, why a new idea won't work. [[00:23:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1430.08s)]
*  Right. And I mean, are you hinting that maybe I'll get better at that as I get older? I'll be more open [[00:23:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1436.96s)]
*  to the exploration? Well, I think that's definitely one of the features of elders that seems to be [[00:24:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1442.3999999999999s)]
*  important. And, you know, again, to use the analogy of the students, I think part of the reason for that [[00:24:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1454.0s)]
*  is that the 35-year-old caregiver also has their own agenda, right? So they want to make sure that [[00:24:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1459.84s)]
*  they get the results that they need for the grant. And the more the older person can sort of say, OK, [[00:24:26](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1466.56s)]
*  I've gotten what I need. I can be more open to the possibility that this younger generation is [[00:24:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1473.44s)]
*  actually going to do well. Now, of course, there's big individual differences among grownups about [[00:24:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1480.32s)]
*  how likely they are to do that or not. But it's interesting that even if you, [[00:24:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1485.36s)]
*  there's a little bit of evidence that even if you look at adult scientists, and, you know, [[00:24:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1490.1599999999999s)]
*  one of my other slogans is that it's not that children are little scientists, it's that [[00:24:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1494.1599999999999s)]
*  scientists are big children. And I almost always get a round of applause, you know, if I say this [[00:24:59](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1499.44s)]
*  at Fermilab or, you know, Lawrence Berkeley Lab, everybody sort of agrees with that. And one of the, [[00:25:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1505.2s)]
*  there's a little bit of empirical evidence that shows, for instance, that the labs that get the [[00:25:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1514.24s)]
*  Nobel prizes are the ones where something unexpected happens. So what happens when you do your [[00:25:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1518.32s)]
*  experiment and what comes out is like totally weird, not what you expected at all. And you [[00:25:25](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1525.6s)]
*  could say, OK, something strange happened, let's go back to the grant. Or you could say, huh, [[00:25:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1529.84s)]
*  like, why did that happen? And it turns out that the labs where when something unexpected happens, [[00:25:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1534.24s)]
*  they follow up and try and figure it out, do better in the long run than the labs where [[00:25:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1540.56s)]
*  you're doing the thing that you were supposed to do. OK, we'll try to let go of graduate students [[00:25:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1544.8799999999999s)]
*  as an example here and think more about the actual human babies. Tell us more about how they [[00:25:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1549.52s)]
*  get their picture of the world. I know that one crucial step is when they figure out that other [[00:25:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1556.1599999999999s)]
*  people have opinions or beliefs that are different than their own. Yeah. So the big idea about child [[00:26:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1561.04s)]
*  development, which now I and other developmentalists have been arguing for for the last, I don't know, [[00:26:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1569.52s)]
*  20, 25 years, is that you should think about development as being like theory formation in [[00:26:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1575.84s)]
*  science. And at first, that idea seems sort of unlikely. I mean, little kids, are they not like [[00:26:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1583.6s)]
*  really smart scientists? But when you look carefully at the way they understand the world, [[00:26:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1590.4s)]
*  it looks a lot like the kinds of theories and the changes in theories that adults, [[00:26:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1594.96s)]
*  that scientists have. And what that suggests is that from a kind of computational perspective, [[00:26:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1600.24s)]
*  that's just a really good way of getting information about the world. So what we've shown is that from [[00:26:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1605.8400000000001s)]
*  the time they're very, very little, children are looking for causal relationships, for example, [[00:26:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1611.3600000000001s)]
*  which is one of the things that's really important in a theory. And we can show again, with our little [[00:26:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1617.7600000000002s)]
*  blick of detector, these little machines that have where they have unexpected causal properties, [[00:27:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1623.44s)]
*  we can show that even toddlers are doing the right kinds of inferences about how those kinds of [[00:27:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1629.44s)]
*  systems work. So they seem to develop these causal models, these kind of what are sometimes called [[00:27:16](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1636.96s)]
*  intuitive theories. And then they get new data and they change the theories depending on the data. [[00:27:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1642.0s)]
*  And we can show that really systematically. So we can, we can, for instance, show them information, [[00:27:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1647.8400000000001s)]
*  data about how that little machine works, the little blick of detector works, and then we can [[00:27:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1653.2s)]
*  see what kinds of inferences do they make. And to a remarkable degree, they make the inferences that [[00:27:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1661.52s)]
*  you should make if you're trying to, if you were being a good scientist. But of course, you know, [[00:27:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1665.6000000000001s)]
*  figuring out how machines work is fine. But the thing that's most important in all of our lives, [[00:27:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1670.4s)]
*  arguably, is figuring out how the people around us are working. So way back in the 80s, I and others, [[00:27:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1675.92s)]
*  did develop what's come to be called theory of mind, which is figuring out what is it in babies [[00:28:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1683.76s)]
*  minds that enables them to understand your mind. And what we found out, which is sort of typical [[00:28:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1690.9599999999998s)]
*  of what we found out is that babies both know more to begin with than we would have thought, [[00:28:16](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1696.2399999999998s)]
*  but they also learn more. So between say, one and two, for instance, they seem to start learning that [[00:28:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1701.36s)]
*  people could want different things. I want one thing, you can watch another between four and six, [[00:28:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1708.48s)]
*  they seem to start understand between three and six, they start to understand that I could think [[00:28:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1714.16s)]
*  something different than you do. And those are really, really deep, important things to understand. [[00:28:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1718.16s)]
*  But more recently, one of the things that I think has been very interesting is the development of [[00:28:43](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1723.1200000000001s)]
*  work on children's intuitive sociology. So they're also figuring things out like, [[00:28:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1729.2s)]
*  oh, when people are allies, they'll behave this way. [[00:28:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1734.56s)]
*  Ah, the next level, good. [[00:28:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1737.68s)]
*  Yeah, right. When they're enemies, then they'll behave this other way. And if one creature is [[00:29:00](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1740.08s)]
*  dominant is larger than the other, then they can get their way. And what we're just trying to do [[00:29:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1746.48s)]
*  now, again, to go back to this caregiving point is figure out, what do they actually think about [[00:29:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1751.68s)]
*  caregiving? And there's a little bit of evidence that even babies already are identifying, okay, [[00:29:16](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1756.32s)]
*  this is what it looks like for someone to take care of someone else. This is a good potential. [[00:29:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1762.4s)]
*  This is a good potential caregiver for me. So there's this lovely kind of back and forth [[00:29:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1767.68s)]
*  between that helplessness that I talked about. And then the fact that if you are that kind of [[00:29:32](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1772.0s)]
*  helpless creature, learning about other people, learning about love, learning about what other [[00:29:37](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1777.2s)]
*  people are like, is going to be really important for your your survival. And of course, as adults, [[00:29:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1782.96s)]
*  that's still the most important thing that we learn about. [[00:29:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1788.24s)]
*  I want to get the in the audience's mind, the idea of those blanket detector is clearly is [[00:29:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1791.6000000000001s)]
*  playing a big role in your psychology experiments. Is this something you buy off the shelf? Or do you [[00:29:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1797.92s)]
*  make them? Yeah, it's funny, we started out when we started doing this 20 years ago, we actually [[00:30:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1801.76s)]
*  made them. So we had in those days in the psychology department, you had a shop, which we [[00:30:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1808.8s)]
*  don't have anymore. But we had a shop. And we went to the folks in the shop and said, [[00:30:13](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1813.28s)]
*  okay, well, look, here's what we want. What this little it's just it's very simple. It's a little [[00:30:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1818.4s)]
*  box, you put different things on top. And sometimes it lights up and plays music. And sometimes it [[00:30:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1822.5600000000002s)]
*  doesn't. And then we had various other kinds of variants of this. So we had one with gears where [[00:30:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1827.52s)]
*  you flick a switch, and then the gears go and then that makes something else happen. So they're kind [[00:30:32](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1832.48s)]
*  of like a little Rube Goldberg machines that we'd, we'd, we'd put together. Now, at the time that [[00:30:37](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1837.52s)]
*  this is a kind of interesting, anecdotal observation, at the time that we first did this, [[00:30:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1845.12s)]
*  we thought, gee, this would be so much easier to do if we just had screens and a computer, [[00:30:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1850.1599999999999s)]
*  and you could do it that way. The kids didn't want to have anything to do with it when it was a [[00:30:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1854.48s)]
*  screen. They really needed to have the real thing. But now what we're finding is that even like three [[00:30:59](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1859.36s)]
*  and four year olds, and I think the big difference is now screens are interactive. So three and four [[00:31:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1865.92s)]
*  year olds have the idea. And in fact, again, if you have a baby, you know, really love the idea that [[00:31:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1872.24s)]
*  they can act on, they can touch something, they can talk to it, they can swipe it, and then figure [[00:31:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1878.32s)]
*  out what the outcome is supposed to be. Although it still looks like we need the real things for [[00:31:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1884.96s)]
*  the, for the younger kids. But for the older kids, the older kids now sort of have the idea, oh, okay, [[00:31:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1890.24s)]
*  a screen is something that has causal powers as well as a little machine does. [[00:31:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1896.72s)]
*  But still you have these little, you still doing the little boxes? I just like the idea that it's [[00:31:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1902.0s)]
*  a rite of passage in the Gopnik lab for graduate students to build a little box that lights up [[00:31:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1906.4799999999998s)]
*  under different circumstances. Well, that's, that's exactly right. And we have a lab culture about [[00:31:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1910.9599999999998s)]
*  where we get the doorbells that go in it. And one of the funny, a funny story about this, when we [[00:31:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1917.28s)]
*  first started doing it, when we first started doing it, we actually had the folks in the shop who were, [[00:32:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1923.9199999999998s)]
*  who were putting these things together. And at one point, one of the machines that we had broke, [[00:32:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1930.4s)]
*  and my brilliant graduate student and I went in and asked, said, look, it's not working the, you [[00:32:16](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1936.0800000000002s)]
*  know, the gear is not making the other gear go. And they said, Oh, no, that's not how it works. [[00:32:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1942.0800000000002s)]
*  We just programmed it. So it does this specific thing when you, so there's no, there's actually [[00:32:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1947.52s)]
*  no physics behind it at all. It's just, it's like a, you know, it's like a Tesla car, it's just a [[00:32:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1953.2800000000002s)]
*  computer masquerading as a, a real physical artifact. And we were, I have to say we were a [[00:32:39](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1959.6s)]
*  bit crushed about this. It actually works most of the time in the lab is that there's a graduate [[00:32:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1966.48s)]
*  student who's sitting and pressing a button underneath the table that's determining what it [[00:32:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1973.4399999999998s)]
*  does. So from the kids perspective too, it's not there. They have the illusion of actually doing [[00:32:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1978.7199999999998s)]
*  physics, but what they're actually chewing is doing experiments. It feels like the Wizard of [[00:33:04](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1984.08s)]
*  Oz here. I feel like I've been fooled about all this stuff going on. Okay. So if you say things [[00:33:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1988.4s)]
*  like, you know, a child under one year old doesn't have this theory of mind and a two year old does, [[00:33:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=1995.2s)]
*  so do we know of certain benchmarks or phase transitions and the growth of a child where [[00:33:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2001.68s)]
*  their cognitive view of the world expands a bit? Yeah. So as I say, from the very beginning, [[00:33:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2007.6000000000001s)]
*  I mean, literally from the time they're born, babies are doing things like paying special [[00:33:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2014.32s)]
*  attention to faces and interpreting them from very early on. They're imitating other people in a way [[00:33:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2018.56s)]
*  that other primates don't seem to, which suggests that there's something about understanding other [[00:33:43](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2023.84s)]
*  people. That's really important. By the time they're nine months old, they're doing things like [[00:33:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2028.72s)]
*  pointing to communicate and a nine month old will point. And if you don't follow the point, they'll [[00:33:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2034.1599999999999s)]
*  get antsy and go, dare, dare, dare. So that suggests that they know something about [[00:34:00](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2040.72s)]
*  the fact that other people are looking at the same thing that they are. So sometimes what happens is [[00:34:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2049.2000000000003s)]
*  that people say, oh, you don't get theory of mind until you're four or five, but that's not right. [[00:34:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2055.44s)]
*  You just get different theories the same way you would if you thought about physics. There's [[00:34:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2059.76s)]
*  different kinds of theories about different parts of the mind. But very characteristically, [[00:34:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2064.24s)]
*  you see these changes coming at roundabout a particular age. So about nine months, [[00:34:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2071.8399999999997s)]
*  you see this big revolution. And some of it may just be maturation, but I think something that is [[00:34:37](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2077.9199999999996s)]
*  increasingly important and that we haven't thought about enough is just how active learners, even [[00:34:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2086.3199999999997s)]
*  these very young children are, just how much what they're doing is not just observing statistics, [[00:34:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2093.6s)]
*  although of course they do that, but also actively experimenting on the world. And if you think about [[00:34:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2098.72s)]
*  even a newborn, they're looking at you, they're smiling, they're seeing what the effects of their [[00:35:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2105.36s)]
*  actions are. And by the time you're talking about a toddler, that's like their whole lives. They're [[00:35:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2110.7999999999997s)]
*  just constantly, constantly doing experiments, except when they do it, we call it getting into [[00:35:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2118.0s)]
*  everything. When physicists do it, we call it being a good experimental physicist. [[00:35:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2123.52s)]
*  And I think it's really under, so one of the things that we've been doing a lot recently is trying to [[00:35:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2130.08s)]
*  think about how the children's learning compares to the learning of machines, for example, something [[00:35:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2135.28s)]
*  like the large models that have had so much play. So what's the relationship between what AI is [[00:35:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2142.08s)]
*  doing and what these very little kids are doing? And I think one of the really big dimensions that [[00:35:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2150.16s)]
*  makes the kids different from the AI systems is that they are going out and actively trying to [[00:35:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2155.2s)]
*  get information about the world and then changing what they think based on the information they get, [[00:36:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2162.4s)]
*  as opposed to the large models, for example, that are basically just, it's interesting to think [[00:36:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2167.2s)]
*  about this in terms of cultural transmission, the large models, I've argued, really what they do is [[00:36:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2172.56s)]
*  just pick out patterns in all the things that other people have already figured out. So they're just [[00:36:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2178.16s)]
*  doing the imitation part of cultural transmission. But the kids are actually going out there and [[00:36:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2184.3999999999996s)]
*  finding out things that are new and experimenting and seeing new outcomes. And we think that may be [[00:36:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2190.16s)]
*  really the crucial thing that lets them learn as much as they do as quickly as they do and with [[00:36:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2195.92s)]
*  as few calories as they do compared to the AI systems. So it is a little bit like the distinction [[00:36:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2200.2400000000002s)]
*  in causal reasoning between simply finding correlations versus being interventionist about [[00:36:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2208.0s)]
*  things, right? Going outside the data set and saying, if I did this, what would happen next? [[00:36:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2215.84s)]
*  Yeah, that's exactly right. And we've for 20 years, we've been collaborating with actually [[00:37:00](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2220.4s)]
*  philosophers of science and computer scientists who've been trying to figure out how do we do [[00:37:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2227.5200000000004s)]
*  causal inference in science. And one of the really basic ideas is that you can't, or it's very [[00:37:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2232.6400000000003s)]
*  difficult to do it just by looking at patterns of statistics or correlation that you want to make [[00:37:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2241.0400000000004s)]
*  causal inferences. Well, what makes a causal inference different from just a correlation? [[00:37:26](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2246.88s)]
*  This is an old philosophical problem back to Hume. And I think the idea that's become most [[00:37:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2250.96s)]
*  prominent in philosophy of science and seems intuitively and in science itself is, well, [[00:37:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2256.88s)]
*  okay, if you want to really make the causal inference, you have to do an experiment. [[00:37:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2261.6s)]
*  You have to actually intervene, do something in the world, see what the outcome is. That's what [[00:37:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2265.12s)]
*  makes something causal. And I think we've been doing some work on this, but I think if you look [[00:37:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2270.08s)]
*  at even quite young babies, if you think about something like a busy box, a busy box is a toy [[00:37:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2276.4s)]
*  that you use for little babies. They're called busy boxes. A busy box is a thing that has lots [[00:38:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2283.92s)]
*  of causal possibilities where you can do lots of experiments. It's cheaper than your standard [[00:38:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2290.7200000000003s)]
*  cyclotron, but it has the same kind of character for babies. It's a way of actually [[00:38:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2298.1600000000003s)]
*  being able to do the kinds of experiments that you need to figure out how the world works. [[00:38:26](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2306.32s)]
*  And of course, as I point out, since theory of mind and intuitive psychology is so important, [[00:38:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2311.1200000000003s)]
*  they have a great experimental subject there all the time, which is the caregiver. [[00:38:37](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2317.6000000000004s)]
*  So if you think about them as being little scientists, little psychologists, we're the [[00:38:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2322.0s)]
*  lab rats. So a lot of what babies do in the terrible twos, for example, is doing something [[00:38:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2326.32s)]
*  and then looking to see how we react to it. We had Judea Pearl on the podcast at one point. [[00:38:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2334.0s)]
*  At one point he said literally, haven't you ever seen a baby? All a baby is doing is touching [[00:39:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2342.48s)]
*  things and making a causal map of the world. And I understood what he was saying and agreed with it, [[00:39:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2347.68s)]
*  but I guess I didn't realize it was quite as literal as apparently it is. [[00:39:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2352.8s)]
*  No, absolutely. So what we've done is taken some of the formalisms that Pearl developed, [[00:39:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2357.36s)]
*  causal basenets, and then show how the ways that children are solving these causal problems are [[00:39:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2362.16s)]
*  just like what you'd expect from causal graphical models. So essentially what the children, [[00:39:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2369.6s)]
*  I think we can say that we've demonstrated this, what the children are doing is constructing [[00:39:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2374.64s)]
*  causal graphical models from data and then using them to determine their interventions. [[00:39:39](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2379.28s)]
*  Now, the thing is that both for Judea and for the whole world of causal inference and for us, [[00:39:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2384.8s)]
*  it's still a kind of unsolved problem about, and for scientists, right? How do you decide [[00:39:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2393.2000000000003s)]
*  which experiment is really the right experiment to do? So what something like Judea's framework [[00:39:59](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2399.84s)]
*  lets you do is say, okay, if you get this result, here's the causal graph you should have. But how [[00:40:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2407.2000000000003s)]
*  do you decide what you should test in the first place? And I think one interesting thing that's [[00:40:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2412.8s)]
*  coming out is that a lot of the sort of old chibileths about how you do experiments, you [[00:40:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2419.1200000000003s)]
*  have to keep everything constant, you can only vary one thing at a time, that's not true for [[00:40:25](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2425.76s)]
*  babies and it may not be the best way of doing science either. And I think this is like a [[00:40:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2430.5600000000004s)]
*  wonderful open question about how do you decide what kind of experiments to do? How do you decide [[00:40:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2436.24s)]
*  how to explore? And we've started doing this with kids and AI agents. What we've done is put them in [[00:40:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2446.3999999999996s)]
*  the same kind of general environment. Minecraft is one of the ones that we use, if you know mine, [[00:40:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2454.9599999999996s)]
*  I imagine your audience will know Minecraft, although there's a bit of a funny story about [[00:41:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2463.44s)]
*  this, which is that I originally started doing this work about how you explore the Minecraft [[00:41:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2467.2s)]
*  environment because my grandson was mad about Minecraft and I figured, well, at least this will [[00:41:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2472.88s)]
*  make me cool, right? If I can tell him that grandma's doing stuff about Minecraft. Then I gave a big [[00:41:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2478.32s)]
*  talk about this, I got something called the Rummelhart Prize, it's a big deal and my grandchildren [[00:41:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2484.64s)]
*  were in the audience and I said, well, I did this because I wanted to impress Augie. And he came up [[00:41:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2489.12s)]
*  to me very sweetly after the talk and said, grandma, that was a little embarrassing because [[00:41:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2494.16s)]
*  nobody cool plays Minecraft anymore, we all play Fortnite. So it isn't really cool to be involved [[00:41:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2501.68s)]
*  in Minecraft if you're a 13 year old. So I wasn't keeping up with the changes. But in any case, [[00:41:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2510.16s)]
*  Minecraft is a great game, it continues to be a great game for grownups and for 11 year olds. [[00:41:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2516.64s)]
*  What we've done is put kids in that environment and then put AI agents in that environment [[00:42:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2526.72s)]
*  and just said, figure out what's going on, explore. And even relatively young kids will explore that [[00:42:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2532.3199999999997s)]
*  environment in a rational way. They're not just randomly trying things, they're doing things in a [[00:42:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2538.7999999999997s)]
*  way that lets them figure out how the environment works. And they're much, much, much better at it [[00:42:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2543.68s)]
*  than AI agents are. Interesting. Well, the thing you said about traditional scientific methodology [[00:42:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2551.04s)]
*  asking us to keep all but one thing constant and changing that one thing and seeing what the [[00:42:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2558.24s)]
*  effective, I mean, that makes that sound sensible to me. But is it just because it's simpler to [[00:42:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2562.24s)]
*  keep track of what's going on, but maybe it's ultimately less effective than kind of poking [[00:42:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2568.72s)]
*  things in concert? Yeah, so that's a really interesting technical formal question about when [[00:42:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2573.3599999999997s)]
*  you know that it is true that if you did that, that's a simple formative rule about what to do. [[00:42:59](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2579.4399999999996s)]
*  But sometimes actually doing trying to vary different things at once can be more informative [[00:43:04](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2584.9599999999996s)]
*  than, because as you can imagine, it's really hard to keep everything else constant and just [[00:43:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2591.52s)]
*  change one thing. And that, I think, thinking about what the kids are doing can be very, [[00:43:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2595.84s)]
*  because the kids, some, the kids are often trying lots of different things in different ways, [[00:43:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2601.6000000000004s)]
*  if you think about the two-year-old with the busy box. And yet they seem to be such good learners. [[00:43:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2608.4s)]
*  So it's a really interesting question, I think, for AI, for science, for developmental psychology, [[00:43:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2613.6000000000004s)]
*  about how that's possible. And how literally true is it to describe these very young children as [[00:43:39](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2619.68s)]
*  good Bayesians? Yeah, I think it is literally true. What we've done is take various kinds of [[00:43:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2626.56s)]
*  ideas from Bayesian inference. And what we can do is give kids information, for instance, about the [[00:43:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2635.3599999999997s)]
*  baseline probability of a hypothesis, and then we can give them information that will let them [[00:44:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2642.24s)]
*  update that hypothesis. And they'll do the right kind of updating in the right kind of way. [[00:44:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2647.28s)]
*  Another kind of discovery that was in my lab, but also even more in labs like Richard Islund's and [[00:44:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2654.0800000000004s)]
*  Jenny Safran's back in the 90s, was that children are quite good at doing statistics, which you [[00:44:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2660.4s)]
*  might be really surprised at, because after all, grownups are notoriously bad at doing probabilities. [[00:44:26](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2666.4s)]
*  But if you do something like show the children that one blicket works eight out of ten times, [[00:44:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2671.76s)]
*  and the other one works four out of ten times, they'll pick the one that has a higher probability [[00:44:39](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2679.36s)]
*  of activate. And then this is with 18-month-olds. And then you say, OK, which one will you use here, [[00:44:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2685.44s)]
*  make the machine go? They'll pick the one that has the higher statistical probability. In fact, [[00:44:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2691.28s)]
*  they'll do it even if it's like two thirds versus eight tenths. So they seem to be able to kind of [[00:44:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2695.92s)]
*  do the math implicitly, obviously, and unconsciously to figure out what how probabilities work. [[00:45:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2701.76s)]
*  But again, this has led to this puzzle, which is they really seem to be doing something like [[00:45:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2710.2400000000002s)]
*  Bayesian inference. And yet we know that Bayesian inference ideally is sort of impossible [[00:45:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2715.84s)]
*  computationally. So if you have a big set of hypotheses, then it's going to take you, [[00:45:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2722.0s)]
*  you know, if you the Bayesian ideas, you take a hypothesis, you generate a pattern of evidence, [[00:45:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2727.92s)]
*  you check it against the data that you've got, you figure out which hypothesis would have been [[00:45:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2734.08s)]
*  most likely to generate that pattern of data. And the problem is, if you have a big space of [[00:45:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2738.96s)]
*  hypotheses, that's just going to take forever, because you're going to have to try each one of [[00:45:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2745.36s)]
*  the hypotheses separately. It's called the search problem. And nobody's really quite solved that [[00:45:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2749.2s)]
*  problem either in statistics or in AI or in childhood. And the children do seem to be able [[00:45:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2755.52s)]
*  to solve that problem because they end up, you know, finding out about the world. And it's a [[00:46:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2761.7599999999998s)]
*  really interesting question about how they solve it. And my guess at the moment is that something [[00:46:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2765.52s)]
*  about this active inference might be part of the solution, that it isn't just that you're sort of [[00:46:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2770.16s)]
*  sitting back having data float over you and then trying to update your hypotheses, you're actually [[00:46:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2777.04s)]
*  out there being an experimenter and figuring things out. Which should make at least the I know [[00:46:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2783.2799999999997s)]
*  that in physics, there's always a bit of a tension between the theoreticians and the experimentalists. [[00:46:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2790.96s)]
*  So I think from the developmental perspective, we're we're team experimentalists. That's the [[00:46:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2795.84s)]
*  the fair enough. That's that's that looks like that's really the secret. [[00:46:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2802.3999999999996s)]
*  And how much do we know about the neuroscience of this kind of thing? I mean, are these [[00:46:47](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2807.52s)]
*  ideas that babies sort of get better at different kinds of reasoning as they grow older, [[00:46:52](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2812.64s)]
*  mirrored in ways that the brain is wiring itself? Yeah, it's quite neat, because one of the oldest [[00:46:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2818.3999999999996s)]
*  developmental neuroscience findings, which is consistent with what we've we've seen to this day [[00:47:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2826.7999999999997s)]
*  is that early in development, what you see is lots of new synapses, lots of new connections [[00:47:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2831.44s)]
*  being formed. And then there's a point, a kind of tipping point where the ones connections that [[00:47:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2840.16s)]
*  have been formed are strengthened, they're myelinated, they become more effective, [[00:47:26](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2846.4s)]
*  the ones that haven't been formed are pruned. So the weaker ones just kind of disappear. [[00:47:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2850.48s)]
*  So you have this early brain that is very, very flexible, very good at changing in the [[00:47:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2855.28s)]
*  light of new experience, very plastic, as neuroscientists say, and then but not very [[00:47:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2861.04s)]
*  effective, right, not very good at actually doing anything. And then you have this later brain that's [[00:47:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2866.88s)]
*  very good at doing things, but much less good at changing much less with much less plasticity. [[00:47:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2871.2799999999997s)]
*  And again, this is like another version of this explorer exploit trade off. And empirically, [[00:47:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2877.52s)]
*  if you look at brain development, you can see that depending on the domain that you're in, [[00:48:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2882.32s)]
*  you see this pattern of very early, early proliferation and then later pruning. So if [[00:48:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2886.64s)]
*  you look at the visual system, for instance, you see this tipping point at around 18 months. [[00:48:13](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2893.52s)]
*  So the visual system is getting set in that early period, and then it kind of settles in, [[00:48:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2898.48s)]
*  which is why if you have vision problems, it's really important to correct them in a baby, [[00:48:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2903.68s)]
*  it's really important to correct them early. If you look at the language areas, it's like [[00:48:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2908.72s)]
*  five or six where you start seeing this, you start seeing this transition. So it's when you've [[00:48:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2913.6s)]
*  developed a language that then it becomes harder for you to learn another, learn a new language. [[00:48:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2920.0s)]
*  And if you look at what's sometimes called the executive function, the prefrontal part of the [[00:48:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2926.72s)]
*  brain, that's the latest one. And that's not completely getting set until adolescents, for [[00:48:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2931.04s)]
*  example. Okay, so you see this, but you do see this general pattern of start out with lots and [[00:48:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2936.16s)]
*  lots of connections, and then at some point, start strengthening and pruning. [[00:49:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2942.0s)]
*  And I just hate to bring it back to academia once again, but this comports with the idea that, you [[00:49:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2948.08s)]
*  know, like the energetic young idea creators are the young faculty in postdocs, right? Not the [[00:49:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2954.56s)]
*  older senior faculty who've been successful for many decades. [[00:49:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2960.32s)]
*  Yeah. I mean, I think it's an obvious question that lots of people have asked is, well, [[00:49:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2963.36s)]
*  are there things that grownups could do that would make them as creative as the children? [[00:49:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2969.28s)]
*  And the first thing to say is, even if you're thinking about a lab, if you want to get grant [[00:49:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2974.96s)]
*  money, it's really good to have people who are really, really practiced and know how that system [[00:49:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2981.28s)]
*  works and are really good at it. And even if you forget about grant money, just, you know, [[00:49:47](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2987.2000000000003s)]
*  actually doing the experiments. If you're a physicist, for example, is a giant enterprise. [[00:49:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2991.6800000000003s)]
*  It really takes a lot of focus and executive energy to be able to get the experiments to run. [[00:49:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=2998.32s)]
*  So I don't think you'd want, you know, like you don't want your department chair to be this wildly [[00:50:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3005.84s)]
*  creative person who's thinking up strange ideas all the time, right? You want them to be focused. [[00:50:13](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3013.04s)]
*  Nevertheless, I think it's interesting and relevant to this Explore Exploit trade-off that [[00:50:18](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3018.6400000000003s)]
*  when adults want to, adults often will kind of have social institutions that allow them to [[00:50:25](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3025.12s)]
*  switch back and forth between this Explore and Exploit. So sabbaticals, I think, are a great [[00:50:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3033.3599999999997s)]
*  example in the academic context, right? So we don't sort of expect scientists to be able to just do [[00:50:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3038.96s)]
*  this on their own. What we think is going off to a retreat, going off to a sabbatical, going off to [[00:50:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3044.7999999999997s)]
*  a workshop. Those are all ways that you can kind of pull yourself out of the context that you're [[00:50:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3051.76s)]
*  already in and allow yourself to do greater exploration. So, you know, it's a pain that we [[00:50:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3057.36s)]
*  all spend so much time traveling as scientists, but I do think there's a bit of an argument that [[00:51:04](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3064.7200000000003s)]
*  being in a different place, being in a different context, often doing interdisciplinary work where [[00:51:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3069.2000000000003s)]
*  you're forced to think about things in really different ways because now you're [[00:51:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3074.5600000000004s)]
*  looking at biologists instead of physicists. All those seem to be ways that grown-ups [[00:51:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3080.08s)]
*  set themselves up to be more creative. And does it, you've mentioned already several times the [[00:51:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3084.48s)]
*  connection between these ideas and AI, large language models, etc. How operationalizable [[00:51:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3091.12s)]
*  are these insights? Can we imagine building better AI models using this, [[00:51:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3098.88s)]
*  the lessons we've learned from development? Well, that's kind of what we've been doing. So [[00:51:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3104.0s)]
*  I'm part of the Berkeley AI research group and what we're trying to do is take some of these [[00:51:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3110.2400000000002s)]
*  ideas, ideas about active learning, ideas about social learning, ideas about causal model building, [[00:51:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3115.84s)]
*  and actually implement them in AI systems. And, you know, to a certain extent what's happened is [[00:52:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3122.88s)]
*  that because the large models have been so effective in lots of ways, there's a tendency [[00:52:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3130.32s)]
*  to sort of say, okay, well, they worked before, we'll just keep making, we'll just, you know, [[00:52:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3137.6800000000003s)]
*  pour more compute into them and they'll get bigger and they'll use up more energy and then [[00:52:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3142.1600000000003s)]
*  they'll get better and better and we'll have this mythical thing called AGI. And one of the things [[00:52:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3148.96s)]
*  when I talk to AI groups, which I do a lot now, I have a slide where I say there's no such thing [[00:52:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3154.08s)]
*  as general intelligence, artificial or natural, which always leads sharp intake of breath from [[00:52:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3164.08s)]
*  the audience because it just isn't. The ideology, the model, oh, okay, there's this one, this gets [[00:52:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3170.3199999999997s)]
*  back to our very first conversation. The model that there's this one thing called intelligence, [[00:52:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3178.4s)]
*  some people have more of it, some people have less of it. If you have more and more of it, [[00:53:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3183.2799999999997s)]
*  then you're going to be more and more effective. That's not the model that comes out of cognitive [[00:53:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3187.04s)]
*  science at all. What comes out of cognitive science is that we have these trade-offs between [[00:53:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3191.8399999999997s)]
*  different kinds of cognitive capacities. So if we could design, sorry, so LLMs don't rather [[00:53:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3195.68s)]
*  strikingly have any of these capacities. They're not going out in the world and doing experiments. [[00:53:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3204.72s)]
*  They're not creating abstract causal models that then they can use to generalize. And you can see [[00:53:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3210.0s)]
*  the difference between the amount of data that the children have and how good they are at generalizing [[00:53:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3216.48s)]
*  it to new situations and the large models. The large models need enormous amounts of data and [[00:53:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3220.96s)]
*  they're not very good at generalizing, especially to what's called out of distribution cases, cases [[00:53:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3226.48s)]
*  that weren't there in their training. The kids with much less data are very good at doing that. [[00:53:52](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3232.4s)]
*  So the question is, what are the kids doing and could that make more effective AI? And I think [[00:53:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3237.12s)]
*  the thing to say at the moment is, if you start thinking about the comparison to kids, we're very, [[00:54:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3242.48s)]
*  very far away. So the kids are orders and orders of magnitude better than any of the current AI [[00:54:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3248.32s)]
*  systems that we have. But I think that's the direction that we might want to go in. [[00:54:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3257.44s)]
*  Well, it's a difficult conversation to have sometimes because the AI, the people who worry [[00:54:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3262.48s)]
*  that we're close to super intelligence any moment now will say, look, we can beat the best human [[00:54:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3268.8s)]
*  beings at playing chess or playing Go or whatever. And you try to make the point, as you just did, [[00:54:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3274.88s)]
*  that there are other aspects of intelligence that they're not good at, but they seem a little bit [[00:54:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3281.76s)]
*  fuzzier, right? It's a little bit harder to put a benchmark on it. Is that something that we're [[00:54:47](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3287.04s)]
*  trying to make progress on? Well, I mean, one thing is that, for example, if you look at robotics, [[00:54:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3291.28s)]
*  notoriously, the AIs are better at playing chess, but they're terrible at actually picking up the [[00:54:59](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3299.92s)]
*  pieces. If you made part of the game B that you had to pick up, find the pieces that have spilled [[00:55:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3306.2400000000002s)]
*  on the floor and put them back in exactly the right places, they're really quite bad at doing [[00:55:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3312.2400000000002s)]
*  that, especially if you had, say, a new chess set that was like an Alice in Wonderland chess [[00:55:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3317.76s)]
*  set or something where you couldn't just identify them from your previous training. [[00:55:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3323.6000000000004s)]
*  And this is the famous Moravitch's paradox. This goes back to the beginnings of AI, that [[00:55:29](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3329.6000000000004s)]
*  things that look really hard for human chess and Go turn out to be relatively easy for AI and things [[00:55:34](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3334.8s)]
*  that look really easy, like perception and action and movement and the kinds of things that kids do [[00:55:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3341.28s)]
*  when they figure out how the little blick of detector works turn out to be really hard for [[00:55:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3348.0800000000004s)]
*  AI. I think the whole conversation about intelligence in AI is fundamentally misguided [[00:55:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3353.1200000000003s)]
*  because really the reason why these systems are as effective as they are is because they're taking [[00:56:00](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3360.96s)]
*  advantage of hundreds of thousands of humans who've done things like put text on the web and [[00:56:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3368.96s)]
*  in some ways, like with reinforcement learning from human feedback, have [[00:56:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3379.12s)]
*  trained up the systems. My latest metaphor about this is, do you know the story of Stone Soup, [[00:56:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3383.52s)]
*  the old children's story of Stone Soup? This is a wonderful children's story. This is another [[00:56:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3391.84s)]
*  advantage of being a developmental psychologist. You have wisdom of the stories that grandmothers [[00:56:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3396.88s)]
*  have told in the past. So this turns out to be a very, very widespread bit of folklore. [[00:56:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3404.32s)]
*  And here's the story. There's these visitors who come to a village and they say, we want some food, [[00:56:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3410.0s)]
*  and the villagers say, oh, sorry, we don't have any. We can't share any with you. And the visitors [[00:56:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3415.84s)]
*  say, that's okay. We're going to make Stone Soup. We have magic stones. So they get a big cauldron. [[00:57:00](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3420.56s)]
*  They put this couple of stones in the cauldron. It starts boiling. They say, see, we're just going [[00:57:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3425.6s)]
*  to make Stone Soup. It's so good. You know, it would be even better if we had an onion and a carrot [[00:57:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3430.48s)]
*  that we could put in it. But I guess if we don't have it, we don't have it. So one of the villagers [[00:57:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3435.68s)]
*  says, I think I have an onion and a carrot somewhere. They go and put it in. They say, oh, [[00:57:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3440.4s)]
*  that's great. Like, oh, see how well this soup is working. When we made it for the king, we put a [[00:57:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3444.7999999999997s)]
*  chicken in. And that was really great. So could you go and, and of course, you can guess what [[00:57:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3450.72s)]
*  happens. The villagers all contribute their bit of food. And then at the end, the villagers say, [[00:57:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3455.2s)]
*  this is amazing. This is magic. We got all this soup just from a stone. And I think if you think [[00:57:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3462.08s)]
*  about a version of that, where you said there were the computer people, the tech guys who went to the [[00:57:47](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3467.3599999999997s)]
*  universe of computer users and said, oh, we have AGI. We can do it just with, you know, three [[00:57:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3474.56s)]
*  algorithms, gradient descent and transformers. And we'll have AGI any minute now. But, you know, [[00:57:59](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3479.44s)]
*  we really need a lot of data to make this AGI work. And the user said, oh, okay, we have all of our [[00:58:05](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3485.76s)]
*  text and pictures that we put on the internet, all of our books, all of our newspapers. We could [[00:58:13](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3493.12s)]
*  give you that to make the intelligence. And then the villagers, the tech guys say, oh, that's really [[00:58:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3499.68s)]
*  great. But like if we could do reinforcement, our AGI is still saying stupid things. So if we could [[00:58:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3507.44s)]
*  get reinforcement learning from human feedback and get people to give us feedback about whether [[00:58:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3513.68s)]
*  our AGI is doing well or not, that would make it even better. And the people said, oh, okay, [[00:58:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3518.96s)]
*  like there's whole villages in Kenya who could do this. And finally, the tech guys said, oh, [[00:58:43](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3523.68s)]
*  that's really, we're getting really good intelligence. But if we could do prompt engineering, [[00:58:47](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3527.92s)]
*  so we could figure out what exactly what prompt to use, that would make it even more intelligent. [[00:58:52](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3532.88s)]
*  Could you do that? And the user say, oh, yeah, we could think a lot about that. And then of course, [[00:58:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3537.84s)]
*  in the end, what happens is that the tech guys say, see, we told you we made AGI just from a couple [[00:59:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3542.0s)]
*  of algorithms. And it's ignoring the fact that the reason why it works is not because of the [[00:59:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3549.76s)]
*  algorithms, but because of the data. And that data comes from a bunch of humans who are doing the kind [[00:59:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3555.2000000000003s)]
*  of exploratory creative intelligence that four year olds do. I do presume that there are other [[00:59:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3561.04s)]
*  angles on building AI systems that that are more oriented towards making causal models of the world, [[00:59:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3568.96s)]
*  even intervening, putting them in robots, I really, I really don't know. Yeah, that's one of the things [[00:59:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3576.16s)]
*  that people have thought about. But as I say, it's hard. So you know, trying to do the Bayesian [[00:59:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3581.36s)]
*  inference is hard because the search problem is hard. There's what's called reinforcement learning [[00:59:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3586.16s)]
*  and reinforcement learning, old idea in psychology is the and actually take actions and then see if [[00:59:51](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3591.6s)]
*  the actions make you better off or not. So, you know, the mouse who runs through the maze and [[00:59:59](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3599.6s)]
*  gets cheese sometimes, but gets a shock other times, right, and learns to go towards the [[01:00:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3607.04s)]
*  cheese and away from the shock. So that's a technique that, for example, in the go solution, [[01:00:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3612.32s)]
*  reinforcement learning played a really important role in trying to solve that problem. So the chess [[01:00:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3619.92s)]
*  agent is playing against itself over many, many trials to try and figure out what the [[01:00:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3627.76s)]
*  what the best reinforcement learning is. But the problem with reinforcement learning is that [[01:00:32](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3632.88s)]
*  it it's too narrow. Like if you just end up on you could, since all you're thinking about is, [[01:00:37](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3637.04s)]
*  am I better off or not, you're not going to be able to do the kind of exploration that you need [[01:00:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3642.72s)]
*  to really figure out how the world works. And so the idea that I think is most promising and we've [[01:00:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3648.2400000000002s)]
*  been working on is an idea that should be very familiar from science, which is an idea that you [[01:00:54](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3654.96s)]
*  could do learning. But instead of instead of trying to calculate whether you've got, you know, [[01:01:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3662.16s)]
*  higher usefulness or utility or not, or whether you've got more cheese, what you're calculating [[01:01:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3668.96s)]
*  is, did I get more information? Did I find out more about the world? Or did I find out more about [[01:01:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3674.24s)]
*  the system when I when I did this action versus this other action? And the result is that you are [[01:01:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3679.3599999999997s)]
*  going to do again, to go back to the point we made before, you're going to do the things that will [[01:01:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3687.04s)]
*  tell you something about how the world works, even if they don't make you any better off in the [[01:01:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3691.28s)]
*  in the short run. And there are ideas in an idea I really like and that we've been working on [[01:01:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3696.0s)]
*  is the idea of a kind of intrinsic reward, like the kind of reward you get as a scientist when you [[01:01:42](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3702.4s)]
*  when you just are doing it because it's so cool when things work out the way that you want. [[01:01:47](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3707.76s)]
*  So I think the solution to the problem means having a kind of reinforcement learning [[01:01:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3713.44s)]
*  agent, but one where the reward isn't cheese or utility or winning the game, it's finding out [[01:01:59](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3719.2799999999997s)]
*  something new, figuring out more about how the world works. And there's been a lot of interesting [[01:02:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3726.64s)]
*  attempts both in development and in AI to figure out how you could make that happen, what kind of [[01:02:11](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3731.68s)]
*  signal would tell you that as a result of this action, you've learned more. And one that we're [[01:02:16](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3736.8s)]
*  working on now that I think is really interesting is something called empowerment. And the idea [[01:02:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3741.04s)]
*  behind empowerment is that you get rewarded when you do something and it has a predictable effect [[01:02:26](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3746.16s)]
*  on the world. So what you do is try to do as many things as you can where varying the action that [[01:02:32](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3752.56s)]
*  you take will vary what happens out there in the world. And when you do that, that's really [[01:02:38](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3758.7200000000003s)]
*  exciting. That's really cool. That is something you're going to be likely to try again. But you [[01:02:43](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3763.28s)]
*  also want as many different kinds of actions, as many different relationships like that as you can. [[01:02:47](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3767.92s)]
*  So if you find one, after a while you'll get bored and you'll try and find another one. [[01:02:52](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3772.48s)]
*  And I think that's very closely related to the causal learning that I talked about before. So [[01:02:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3778.0s)]
*  if you think about what you mentioned, Sean, that causation is all about intervention, right? [[01:03:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3783.52s)]
*  So really what you're learning with this empowerment reward is I'm going to learn how [[01:03:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3789.6s)]
*  to intervene. I'm going to learn how doing things out there in the world ends up having effects. [[01:03:13](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3793.76s)]
*  And we have a little bit of evidence that even tiny babies, if you take literally a two or three [[01:03:21](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3801.36s)]
*  month old and you put a ribbon between their foot and a mobile so that they can actually control [[01:03:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3807.92s)]
*  what happens to the mobile, they'll sit there and try all sorts of different patterns of kicking [[01:03:35](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3815.2000000000003s)]
*  to try and see what the consequences are going to be for the mobile. So they really are like little [[01:03:40](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3820.32s)]
*  and they'll smile and they'll giggle and they'll go back to doing it. It just seems to be an [[01:03:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3825.6s)]
*  incredibly satisfying enterprise for them. And of course they're doing the same thing with mom [[01:03:49](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3829.76s)]
*  when they're doing all sorts of funny faces and seeing if mom gives funny faces back again. [[01:03:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3836.7200000000003s)]
*  So I think that might be a really, really important part of the solution. And again, [[01:04:03](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3843.6800000000003s)]
*  it speaks to science because going back to what we were saying before about how systematic your [[01:04:08](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3848.7200000000003s)]
*  experiments have to be. One of the things that I've noticed is that the powers that be always say, [[01:04:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3854.08s)]
*  well, you don't want to just have a fishing expedition, right? This ground is just a fishing [[01:04:20](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3860.24s)]
*  expedition. But a lot of times what you actually end up doing is doing a fishing expedition. You [[01:04:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3864.32s)]
*  try something and then kind of unexpectedly it has this particular systematic result. And that's the [[01:04:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3871.04s)]
*  way the gold is rather than the causation that you already know about. And empowerment is kind [[01:04:39](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3879.12s)]
*  of a way of saying, yeah, keep that fishing expedition going. Well, and there are better [[01:04:44](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3884.56s)]
*  and worse ways to go fishing. Right. Exactly. You know, we did have Carl Friston also on the podcast [[01:04:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3888.88s)]
*  and he has these ideas of the free energy principle and the Bayesian brain. And part of the [[01:04:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3896.48s)]
*  sort of aspect that gives people pause is he seems to be saying that our brains try to minimize [[01:05:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3902.7999999999997s)]
*  being surprised. And you might think that therefore you should just sit in a dark room and never do [[01:05:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3909.6s)]
*  anything. But if I understand correctly, he was saying, no, actually we want to minimize the net [[01:05:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3915.44s)]
*  surprise over our lives and therefore we better explore around and do weird things now so we can [[01:05:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3923.2s)]
*  anticipate what's coming. Yeah, that's exactly like the exploration exploitation trade-off that I was [[01:05:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3928.32s)]
*  talking about. So it's interesting if you think about something like empowerment or all of these [[01:05:33](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3933.76s)]
*  kinds of intrinsic rewards, the failure cases are you just sit there and do the same thing over and [[01:05:39](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3939.6800000000003s)]
*  over again. And maybe those are human failure cases too. So what you need to do is to be able to [[01:05:45](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3945.44s)]
*  want to have a coherent story about what's going on around you. You don't want to just [[01:05:52](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3952.0s)]
*  be you don't want to just be paying attention to random stuff that's happening, [[01:05:56](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3956.2400000000002s)]
*  even though that might give you something that's new and surprising. But you also don't want to [[01:06:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3961.84s)]
*  just do the same thing over and over again. And we've been looking at comparing, for instance, [[01:06:07](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3967.36s)]
*  what do children think when you give them a machine that just randomly does different things [[01:06:12](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3972.4s)]
*  like our our plicot detector, but a kind of random plicot detector versus one where there's a [[01:06:17](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3977.84s)]
*  systematic relationship between what you do and what comes out, even if what comes out is surprising, [[01:06:22](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3982.48s)]
*  versus one that just does something obvious that you know about beforehand. And they really seem [[01:06:27](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3987.44s)]
*  to like to play with a machine that that is surprising, but surprising in a systematic way. [[01:06:31](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3991.52s)]
*  And I think that's true about scientists too. The world has some structure and we do take advantage [[01:06:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=3996.96s)]
*  of that. And I think this is something that we haven't quite as philosophers, physicists, [[01:06:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4001.6800000000003s)]
*  AI researchers, whatever, learned how to systematize perfectly. Yeah, I mean, one of the [[01:06:46](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4006.56s)]
*  things that that always strikes me, I mean, the reason why I started doing this work in the first [[01:06:52](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4012.48s)]
*  place back when I was a philosophy student, completely a philosophy student is, if you think [[01:06:57](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4017.44s)]
*  about, you know, going back to Plato and Aristotle, one of the deep philosophical questions is this [[01:07:02](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4022.88s)]
*  question of knowledge. It's how we know that there's a world out there. It has structure, [[01:07:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4029.12s)]
*  not only does it have, it has, you know, quarks and minds and all sorts of things that we can't [[01:07:13](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4033.92s)]
*  immediately observe in it. And yet all that reaches us from that world is a bunch of [[01:07:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4039.44s)]
*  disturbances of air at our eardrums and photons at our eyes. How do we ever at any point manage [[01:07:25](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4045.6s)]
*  to reconstruct that world from that data? And I think going back to Plato and Aristotle, [[01:07:32](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4052.08s)]
*  the two ways of trying to answer that question have been to say, well, okay, it just looks as [[01:07:37](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4057.76s)]
*  if we're understanding that world from data. It's really there all along. So it's really some kind [[01:07:43](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4063.6s)]
*  of innate, there's some kind of innate evolved structure that's responsible for this. And that's [[01:07:48](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4068.48s)]
*  been one, that's Plato's approach. That's one of the approaches. The other approach, going back to [[01:07:53](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4073.68s)]
*  Aristotle, which is the approach of the most recent version of AI, like the LLMs is, it just looks as [[01:07:58](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4078.72s)]
*  if we're really understanding the structure. All we're doing is pulling out correlations between [[01:08:04](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4084.48s)]
*  those photons and those disturbances of air. So all we're doing is just taking the data and pulling [[01:08:09](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4089.6s)]
*  out correlations. And we think that that's telling us something about structure, but we have no [[01:08:14](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4094.3199999999997s)]
*  particular reason to think that. And the great thing about development is that if you look at [[01:08:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4099.92s)]
*  actual babies and children actually learning, they don't seem to fit either of those pictures. They [[01:08:24](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4104.88s)]
*  seem to be able to learn really, and I think also if you look at science, we seem to be able to learn [[01:08:30](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4110.4s)]
*  really radically new things about the world, whether it's learning that I might like broccoli [[01:08:36](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4116.08s)]
*  and you don't, or whether it's learning about corks and leptons. And yet it doesn't look as if [[01:08:41](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4121.6s)]
*  all we're doing is just pulling together the finding statistical correlations in the data. [[01:08:50](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4130.48s)]
*  It looks as if we're genuinely developing theories that go beyond just the correlations in the data. [[01:08:55](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4135.68s)]
*  I don't think we have a good, even though we've been doing this for a thousand years, [[01:09:01](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4141.84s)]
*  we still don't have a good formal model, computational model, good understanding of [[01:09:06](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4146.400000000001s)]
*  how that's possible. And I think looking at the kids who are clearly doing it is a really good [[01:09:10](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4150.88s)]
*  route to answering that philosophical question. And that's what I've spent my whole career doing. [[01:09:15](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4155.4400000000005s)]
*  You know, sometimes looking at what actually happens in the world does help us understand [[01:09:19](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4159.84s)]
*  it better. Alison Gopnik, thanks so much for being on the Mindscape Podcast. [[01:09:23](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4163.92s)]
*  Well, thanks so much for having me, Sean, a great conversation. [[01:09:28](https://www.youtube.com/watch?v=WHbMIpNrY64&t=4168.56s)]
