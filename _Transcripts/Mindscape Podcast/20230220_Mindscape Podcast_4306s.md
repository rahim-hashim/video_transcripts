---
Date Generated: June 07, 2024
Transcription Model: whisper medium 20231117
Length: 4306s
Video Keywords: []
Video Views: 7283
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2023/02/20/227-molly-crockett-on-the-psychology-of-morality/

Most of us strive to be good, moral people. When we are doing that striving, what is happening in our brains? Some of our moral inclinations seem pretty automatic and subconscious. Other times we have to sit down and deploy our full cognitive faculties to reason through a tricky moral dilemma. I talk with psychologist Molly Crockett about where our moral intuitions come from, how they can sometimes serve as cover for bad behaviors, and how morality shapes our self-image.

Molly J. Crockett received her Ph.D. in Experimental Psychology from the University of Cambridge. She is currently Associate Professor of Psychology and University Center for Human Values at Princeton University. She is a Fellow of the Association for Psychological Science and the Society for Experimental Social Psychology.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll

#podcast #ideas #science #philosophy #culture
---

# Mindscape 227 | Molly Crockett on the Psychology of Morality
**Mindscape Podcast:** [February 20, 2023](https://www.youtube.com/watch?v=kjBImouennY)
*  Hello everyone, welcome to the Mindscape Podcast. I'm your host Sean Carroll, and I don't know about you, but most people I know
*  think of themselves as good people, as
*  the good guys in the cosmic struggle between good and evil. Most of us think that we're trying to be good, right?
*  I mean, this is a flaw in many movie villain scenarios is that they're
*  Dr. Evil types. They're trying to be evil, whereas most people don't think of themselves as evil. People think of themselves as good, and yet
*  they end up disagreeing about what it means to be good and how one should act if one is good.
*  So there's a philosophy question here, obviously.
*  What does it mean to be good, to be moral, to do the right thing? And we've had discussions about
*  moral objectivity versus constructivism or what-have-you. There's also a
*  psychological and neuroscientific question about why people want to be good and what is happening in them
*  psychologically when they think they are being good. That's where we are today. In today's conversation,
*  we're talking to Molly Crockett, who is a psychologist and neuroscientist who studies
*  morality as it is actually practiced in human beings. So not necessarily trying to decide what you should do,
*  but understanding why people are trying to do the things that they should do, or how they come up with the idea of what
*  it is to do the right thing. Is it ingrained in us? Do we learn it? Is it something where there are
*  evolutionary explanations for this? And very importantly, how can we change our personal views on morality?
*  You know, we do learn things as we grow up.
*  Maybe there are things that when we were kids we thought were perfectly moral behaviors, and now we've changed our minds.
*  And as Molly points out, there's a very crucial modern question about how
*  technology and communication in the digital age is changing the way that we think about morality.
*  We're faced with a set of circumstances in an environment that we were not evolved to understand,
*  where things are very, very rapid in how they appear to us and how we can respond to them, and they are
*  manipulated by politicians and algorithms and so forth ginning up outrage or, for that matter,
*  bringing us together in different ways. So there's a mixture of not just morality, but
*  empathy, ethics,
*  politics, and so forth. So again, it's a very, very
*  mindscapie kind of set of questions that come together when you say, what does it mean to say that we are moral?
*  Why are we doing that? How does it actually play out? And
*  Molly is not just a psychologist who collects data from a lot of different ways,
*  you know, psychology experiments, watching people in the field and so forth,
*  but also has a bit of a philosophical background. In fact,
*  we met at a philosophy conference, even though neither one of us has a degree in doing philosophy, because philosophy brings
*  everything together, so there's going to be some talk about that as well. So let's go!
*  Molly Crockett, welcome to the Mindscape Podcast.
*  Thank you. It's a pleasure to be here.
*  So you think about morality, but rather than the philosophers we sometimes talk to,
*  you're mostly a psychologist. I know that you hang with philosophers.
*  That's the way you think about it.
*  So I'm going to start with Molly Crockett.
*  Molly, you're a philosopher.
*  You're a philosopher.
*  You're a philosopher.
*  You're a philosopher.
*  You're a philosopher.
*  You're a philosopher.
*  You're a philosopher.
*  You're a philosopher.
*  I know that you hang with philosophers. That's okay.
*  That's good.
*  So therefore, I would presume that you're more interested in how we reason morally as a matter of fact, rather than how we should reason.
*  Like, what is the ultimate true theory of what is right and wrong?
*  I mean, I'm interested in both, and I think that, ideally, the work can find how the data can inform the theory and vice versa.
*  But yeah, I think that mostly I'm in the business of the description as opposed to prescription.
*  And so how does it work?
*  You know, it boots on the ground, as it were.
*  Are you experimenting? Are you going into people's brains? Are you giving them psychology tests?
*  We use a lot of different methods in our research, ranging from asking people to read about hypothetical scenarios and make judgments about them to experiments where people are making real decisions that have material consequences for themselves and other people.
*  To naturalistic observation studies on the Internet, like how people express moral outrage on Twitter.
*  To going into the field and looking at how people's moral cognition changes at festivals like Burning Man and other types of transformative experiences.
*  So really the whole range.
*  Okay, I mean, you have to give us a little bit of a hint about how people's moral judgments change if they're at Burning Man than if they're at home.
*  Well, in that line of work, we have been interested in a phenomenon we call moral expansion, which is about the orientation of morality.
*  Is it directed towards your near and dear or is it expanded to encompass all of humanity?
*  And what we find is that with every passing day that people spend at an event like Burning Man, the more they feel transformed and the more expanded their moral circle is to encompass, you know, everyone.
*  Wow, that's actually very interesting.
*  I mean, is that what do we attribute that to the sort of common feeling of being in the group at some kind of festival or is it more there's certain substances one imbibes in these instances that change how you think?
*  We don't have a very precise answer yet.
*  And of course, there are any number of factors that can contribute to moral expansion at multi-day mass gatherings like Burning Man that we've studied.
*  You know, the sociologist Emile Durkheim coined the term collective effervescence to describe the feelings of, you know, really joyful, exuberant, expansive connection that we feel when we come together in large groups for a common purpose.
*  And we think that that has to be part of it.
*  It is true that people do consume mind-altering substances at Burning Man and other mass gatherings like this, but not as much as you might think, in fact.
*  And in our studies, we really carefully controlled for the substances that people reported using.
*  And what we find is that, yes, as you would expect, people are more likely to report having a transformative experience after recently using psychedelic substances over and above any type of substance use.
*  We find that the more time people spend at these collective gathering events, they feel transformed and positive emotions and so on.
*  We should mention, because you're using the phrase transformative experience, that we did a podcast interview with Lori Paul back in the day.
*  So anyone who wants to really dig into the philosophy of that can check that out.
*  But I like what you're saying here, even though this is not at all what I planned to get into first.
*  But we have this feeling, I guess, that there's a mob mentality that can take over and usually that has negative connotations.
*  So in some sense, you're giving us the positive side of that communal feeling that we can get.
*  Yeah. And I think that what we can learn when we take together our research and other similar research on the positive effects of mass gatherings,
*  as well as the dark side of mass gatherings ranging from mobs, as you say, to Nazi rallies in the Third Reich to more recent rallies on the right that we've seen in the US.
*  We are story creatures. We are really, really responsive to the narratives that we tell ourselves and others about human nature.
*  And I think of mass gatherings as amplifiers. So whatever the story that's being told, the culture of a mass gathering in terms of how we treat each other, what is our view of humanity?
*  Is it basically good? Is it basically evil?
*  Whatever that story is being promoted, the mass gathering is going to amplify it and that builds a culture that is going to profoundly shape people's thoughts, feelings and behaviors.
*  That's a very interesting point. We also recently had Michael Tomasello on the podcast.
*  And of course, he pushes this idea that the social abilities of human beings is really what sets them apart or enables all the other things that set us apart.
*  And I guess morality is part of that. I'm guessing. What do I know? I'm a physicist.
*  But we can feel connected to other human beings in special ways due to those social capacities.
*  Absolutely.
*  And OK, with that on the table, that was very interesting. I just couldn't help but ask.
*  But let's back up and be a little bit more basic. What do we mean when we talk about morality?
*  Do we even agree on what that's supposed to mean?
*  Oh, no. God, no.
*  That was a leading question.
*  I hate that question actually because I don't have a good answer for it.
*  And actually, morality is a more specific term.
*  Oftentimes, I am shifting more towards favoring the term norm psychology or normativity, which concerns how people think about what is appropriate or inappropriate,
*  what is allowed or disallowed within a society. And of course, these are all social constructions.
*  And I know from research on the continuity between social cognition and animals and what we have as humans,
*  which Michael Tomasello is one of the leading scholars on that, that there are like you can trace a line between what you might call moral sentiments in humans
*  and things like empathy, care and concern in other mammals.
*  But aside from those really, really basic domain, general building blocks of normativity or morality,
*  there's tremendous variation within and across cultures in terms of like how we think about what is right and wrong, how we talk about it, how we enforce it, how we learn.
*  And so I'm really, really interested increasingly in that social construction, that cultural side of norms and where do they come from and do we have control over them?
*  And crucially, how is technology changing the way that we think about right and wrong, the way that we enforce moral norms on other people and internalize those to regulate our own behavior?
*  That's good, because we're going to answer all of those questions in the next hour. So I'm glad that you have raised them.
*  But it's a very good point to switch from sort of morality talk to norm talk, because morality talk does kind of presume we know what is moral and what is not.
*  And people disagree about that. I mean, is the disagreement, I guess, where does it all start in development when we're kids?
*  Are we born somewhat moral creatures or at least with something we would recognize as norms or those taught to us?
*  I mean, there's still a lot of debate about this. We are born with a capacity to learn, particularly to learn in a social sense.
*  So learn through observation and learn from social feedback. So, you know, if you ask scholars of human nature, like what is most distinctive about humans?
*  It's not necessarily morality or norms, but rather our unbelievable capacity to learn socially and not just to learn and adapt within our lifetime, but to transmit through culture, knowledge from generation to generation.
*  And I think that it's not a coincidence that we are such norm focused creatures because, you know, social cohesion is really important for survival.
*  Cooperation gives us an advantage over, you know, other species. Many people have written about this, and this is not directly what I work on.
*  But I think in particular, the fact that we care so much about what others think of us and our well-being is, you know, for most people is really, really tied to our sense of like, how am I fitting into the social world?
*  What is my social standing? And so, you know, our ability to represent and learn about norms is a really crucial part of that calculus that we are all making all the time.
*  Am I doing the right thing? Am I fitting in? Where we get into trouble is where the question, am I doing the right thing, gets disconnected from actual flourishing and welfare of humans and other species.
*  And I think in particular, what we're seeing today as there's just massive amounts of normative discourse on social media, what we're seeing in real time is this really, really almost rapid cycling of proposals about new things we share about, backlash to those proposals, backlash to the backlash, backlash to the backlash, to the backlash, to the backlash, to the backlash, and so on, ad infinitum.
*  And so I'm really interested in this process, starting from the seeds of moral cognition that we can see not just in babies, but also in other mammals, empathy and altruism, but then the layers that get put on top of us as we learn and grow and talk to each other and talk to each other about what we're talking about and so on.
*  And it's fascinating and also deeply troubling.
*  So, you know, it's a really intense time to be studying this kind of thing.
*  You know, there's always some time lag between when we record these and when they're released. But as we're recording this, the thing that is going crazy on Twitter is gas stove discourse.
*  I don't know if you've listened in on gas stove discourse, but there's this idea that...
*  I have not.
*  The government is going to ban gas stoves in our houses. They're not, of course, really, but they have pointed out, some people have pointed out, that there are health challenges, that you can have deleterious health effects from having gas stoves.
*  And so maybe we should try to minimize them or try to control them or whatever. And so this is ginned up outrage because people are like, you're never going to, you'll drag the gas stove out of my cold dead hands.
*  I'm sure that'll be forgotten.
*  This is such a good example of how the way that social media algorithms are designed, which is first and foremost to grab our attention in order to keep us online for longer in order to make the most money.
*  And by definition, the stuff that captures our attention is information that's really extreme, that provokes outrage, even if that information is super far fetched or not representative at all of how most people think
*  or what's likely to happen in the future. And so then you have this discourse and meta discourse around pieces of information that may be very, very divorced from things that will actually affect our lives.
*  And I'm really interested in understanding more about why this happens and can we do something about it? And if so, what should we do about it? Because I get the question all the time, and I'm going to preempt you asking me this question, which is like, how should we redesign social media?
*  And it's like, it's a hard question because it is a should question. It's a prescriptive norm kind of question. And to answer that question, you need to not only understand the dynamics of how social media as it is currently designed is shaping discourse and behavior, which we still, you know, this is such a new area of research, but then also like, what are, you know, what is your meta ethical theory of like, what is what is the right way that society should be designed?
*  And that's all really, really tricky stuff.
*  That is a difficult one. And I will add in there to the difficulty, the fact that these features of social media can be weaponized by political actors, right? I mean, they will exaggerate the extent to which a certain bad thing is happening because it gets their base outrage. That's what they want.
*  Yeah. Okay, so there was something, there's a bunch of things that went by there in your very nice discussion of that about, you know, you're talking about morality in a way that as a psychologist gets down to how people act and how they talk about how they act, etc. Not in some objective moral realist sense. I mean, probably. Well, let's put it this way. It makes perfect sense that norms develop over time, right? Through evolution and things like that.
*  And we give them the label of being moral rights and wrongs. Do you feel a need to take a stance on moral realism versus relativism or constructivism or something like that?
*  I mean, I do feel a need to take a stance and I also feel under educated in the ability to take a stance. I'm not trained in philosophy. I wish I was. I actually, you know, philosophy when I was in high school, I dreamed of going to university to take philosophy and I signed up for a philosophy class my first semester.
*  I think it was a philosophy of mind class. I don't remember who the professor was. I went the first day and I was like, what is this? I want something real to grasp onto. Where is the data? So I majored in psychology and neuroscience and have been really at home in those fields.
*  But increasingly gravitating towards questions around morality and normativity. And as my career has progressed, I have come to increasingly identify as a philosopher.
*  And I think I'm reading as much philosophy now as I'm reading psychology and neuroscience and I just find it really, really rich and helpful.
*  And so, you know, one of my sort of like to do items that I hope to have time for at some point is to like audit a moral philosophy course or seminar because I really like my knowledge is not top down. It's like it's very it's magpie-ish.
*  I like have these little like bits and pieces of understanding, but I don't feel like I am educated enough to take a firm stance, but I want to be more educated to be able to move towards that.
*  Have you heard of, and this is very unfair given what you just said, but have you heard of what is called the evolutionary challenge to moral realism?
*  I think so. Yes. I think so. Yes.
*  Basically the idea that we would, through evolution, develop norms that and, you know, think that there are certain right things and wrong things to do. And wouldn't it be weird if those just happened to coincide with some objective moral reality?
*  Like that seems like too much of a coincidence. Right. Yeah.
*  But anyway, you personally don't need it, right? You don't need to care whether or not there are objective moral standards out there because if what you're just interested in are how people think about morality themselves and how they justify it, I'm guessing.
*  Well, yes and no. I used to think that. And I am increasingly becoming skeptical of this divide that exists between science on the one hand and values on the other hand.
*  It's a pretty common sentiment in moral psychology that like, oh, our work cannot speak to normative questions.
*  Like we're doing the description. You can't get a not from an is and so on. And like at a surface level, that's true.
*  But also our values in in fact, the way that we choose to ask questions, the questions that we ask.
*  So, you know, just to give a concrete example, a very popular area in in moral and political psychology right now is how can we get Democrats and Republicans in the U.S.
*  to talk to each other more? And how do we bridge these divides? And, you know, can we get people to meet in the middle and compromise? How do we get people to do that?
*  And that is a project that, you know, has values in it in the sense that there is a there is a goal to get people to meet in the middle.
*  Right. And on the surface, that seems like a really great goal. And in many, many, many cases, it is a really important goal.
*  And what if what if that goal is applied to getting Nazis and liberal Democrats to meet in the middle? Like, like, no, if one side is just right, then meeting in the middle is not the right thing to do.
*  So, you know, I mean, I just think about like, especially when you're studying questions of of morality and ethics, it's really important that we understand how our own values shape the science that we do.
*  And we are not trained to do this in science. We are told through our training in science that science is objective and science is free from values.
*  And like, we are humans. And so, of course, it is. And so, you know, a lot of a lot of the work that I'm thinking about now is like, how should we be thinking about the scientific enterprise in a time where values are so, you know, they've always been important.
*  But, you know, increasingly, science is is looking at questions that are very related with values. And so, you know, I like it's a it's a challenge.
*  Well, you know, I think this is a really good point, because a lot of the times we say, well, we're objective, you know, we're not depending on this or that values.
*  But really, what we mean is, I know what the right values are, and I'm going to use them. Right. And most people agree with me. So I think I can get away with it.
*  Wow. Yeah.
*  So do people is there. So I think that you've put your finger on this distinction we draw between values and objective truth and so forth. There's a bunch of distinctions out there that I wanted to ask you about.
*  I mean, one is this idea that morality serves as a check on how we would really like to act. Right. Like as a psychologist, is it accurate to think of people as like these bundles of terrible impulses that morality sort of sits on top of and prevents us from doing all these terrible things?
*  No.
*  Okay, that's an easy that's an easy answer. And, you know, I like that's not to say that we are, you know, fundamentally angelic either.
*  You know what, what we are fundamentally is social learners and the the beliefs that we have about other people, our group, our culture really impact the way that we comport ourselves intentionally and deliberately, which is, you know, on top of or in concert with basic instincts that we have,
*  which include a basic instinct towards empathy and altruism. And so, you know, there's some really beautiful work by my colleagues, Julia Marshall and Paul Bloom. And this this goes back to the sort of universalism versus more parochial morality.
*  And if you look at very, very young children versus older children versus adults, and how people show favoritism in terms of thinking there's an obligation to help family and friends more than strangers.
*  That's something that develops with age. So very, very, very young children think you are equally obligated to help a stranger versus a friend or family member and need.
*  But it's it's you know, this favoritism towards people who are more close to us isn't something we're born with. It's something that we learn from our culture.
*  And so that's just one of many examples of like, there is a basic goodness that people have. We learn through interacting with others and from our culture that, you know, there are other ways of being.
*  But you know, this this myth of selfishness, this idea that, you know, homo economicus, like people are basically selfish, everything can be explained in terms of self interest.
*  This is this is a narrative that is not grounded in science. And I will add is like very convenient for capitalism.
*  I noticed that. Yes.
*  What is the point of caring about other people if no one else cares? And, you know, it's it's really easy to fall into these self serving narratives about human nature.
*  And I worry about the broader implications of those narratives. Like what if we're telling stories about human nature that A are like oversimplified and not really grounded in in scientific data and B create self fulfilling prophecies, whereas like, oh, everyone is selfish.
*  So like, there's no point in me like wasting my time to, you know, join a movement or demand better treatment for people who are less well off than me and so on.
*  Well, I have absolutely heard and familiar with the idea that we're not inherently selfish. Like that's pretty clear. We have selfish impulses. We also have altruistic impulses.
*  But I think that your claim that or your idea, maybe I don't know how much of it is your work and how much you were quoting other people.
*  But our sort of sphere of caring shrinks a little bit as we as we learn and age.
*  I mean, Peter Singer talks about the expanding circle as we get smarter. We care about more people.
*  Nicholas Christakis was on the podcast and has an idea that it is the social beings naturally have an in-group bias.
*  But you're saying that, I mean, how dramatic is this claim? Is there no in-group bias when we're born? Is that all given to us by culture or is that something we don't know?
*  So I'm glad you asked because I think there's a nuance here that's really important.
*  The work that I'm referencing, I think, is concerning sort of how people feel about social obligations towards close versus distant others, like within a group.
*  There is also separately an in-group bias that is naturally, that seems to be pretty universal and is detectable from a young age.
*  And so I think that the puzzle or the challenge as we are in a global society where the challenges that we face, pandemics, climate change, et cetera, are global in nature.
*  Like, how do we conceive of humanity as a giant in-group? And that is a challenge.
*  And I guess this leads right into something I also wanted to ask, which is how much do our moral impulses, I don't even know what to call them, moral inclinations, impulses, intuitions, not quite our sort of formal philosophy class moral systems, but our feelings.
*  How much do they change over time and how much can we change them intentionally by thinking, oh, my morality was wrong, I got to change it?
*  Great question. And I think there are a lot of different directions we could go in answering it.
*  So the short answer is that I think we come with a sort of a basic toolkit of moral sentiments like empathy, vicarious joy, attunement to the pleasures and pains of other people.
*  And the learning that takes place on top of that is like, how do we direct or tune or shape those basic sentiments to the social context?
*  So like, we are not born knowing who is in that group. This is something that we learn, although there is some evidence for sensitivity to basic cues like language and appearance and so on.
*  But, you know, political hatred, for example, is certainly something that is learned and we learn to direct our empathy more towards in-group versus out-group members on the basis of ideology, for example.
*  And I do think that there is scope for changing the cognitive mechanisms of normativity, of morality, like on a cultural scale.
*  And I think that two mechanisms through which this would work or two channels might be what we could call representation and reinforcement learning.
*  So representation, right, like we are conformists in the sense that like we learn through observation when other people are doing stuff, we also feel inclined to do stuff.
*  And one thing I've been thinking about in our work on social media discourse is like, if algorithms promote a particular type of moral frame, and that's what everyone is seeing disproportionately in their feeds, can that influence the way that we think about, you know, over time, moral situations?
*  So, for example, if there are archetypes of villains where stories of, you know, particular types of people committing, you know, bad deeds are more likely to be elevated and we all see that, do we then lower the threshold in our own lives for, you know, seeing villainy from those types of people because that's what we're used to seeing in our feeds?
*  And the reinforcement learning side is like, to the extent that we participate in that discourse, and then the algorithms reward us for that, that form of discourse like outrage, the more outrage we express, the more likes and retweets we get.
*  And also, of course, the algorithms are learning to show the content that we post to the audiences that are most likely to comment on it.
*  And so, you know, what we have now that we've never had before is algorithms intervening on social learning processes and cultural evolution in a way that I think is new.
*  And, you know, in sort of discussions of technology, there's always a question like, is this really new though? Like, what about the printing press? What about mass media?
*  And like, yes, a lot of the effects that we're seeing are more of the same. And it's really important to consider all the scholarship in media studies that predates the internet age.
*  And I think that what is happening now with algorithmic intervention on the discourse that we are having with one another is something that's new and is something that I worry about because if you have an algorithm designed to make money for tech companies that is rewarding certain types of expressions,
*  that's rewarding certain types of stories that we tell about right and wrong in our culture, then it seems obvious that through reinforcement learning, which is a really basic process that like even sea slugs have, like, we're going to change our behavior over time.
*  And from generation to generation, like, what is it that we are teaching new generations about how to think about right versus wrong? And what does that mean for the future of politics and, you know, our ability to cooperate and solve all of these like really thorny challenges that we face? So these are the things that keep me up at night.
*  Yeah. And even maybe this is just too obvious, but even just the speed of the interactions, right? I mean, when I put a tweet up within half an hour, I know what the reaction is. When I write a book, it's going to be months. This is very frustrating.
*  Yeah.
*  Yeah. And the speed is a really, really interesting aspect of it. And I think that the speed has contributed to two things that are in opposition to one another. On the one hand, you have a rapid cycling of, you know, what you might call moral learning or, you know, moral evolution, where someone identifies a harm that hasn't been identified before.
*  Maybe it's gas stoves. Maybe it's maybe it's something else. And then there's discord about it. And if that were taking place over a typical, you know, like a pre-internet age timescale, like there would be time to sort of digest and reflect.
*  And what we have now instead is like, whoa, what is happening? Like, it's really important to me to not be a shitty person and to know how to avoid harming others. And there's this constant bombardment of new things that we need to know about.
*  And I think that one reaction is just, this is illegitimate. I think there is a backlash that comes from the speed because we are used to, you know, social or moral progress or change happening over a course of decades.
*  And what we are seeing now is a much, much faster timescale. And I think that there are some people who are just responding to this as if this is illegitimate.
*  And like whether the question of like the question of whether it is legitimate or illegitimate is sort of separate. But like, I think that a lot of the backlash against like, oh, this is just woke cancel culture.
*  Like this is like this is a very common refrain, right? Like, this is not real. This is just woke cancel culture. Like, let's unpack that. Like, what do you mean?
*  I mean, like, like, I think that there is something happening that I want to understand better, where there's this like nihilistic kind of attitude towards new proposals about how to treat each other better.
*  It's like, I just learned about it yesterday. Therefore, like, this can't be real. And I think that's really interesting. Like, question to ponder.
*  Yeah, this I mean, the speed and the algorithms. These are two things working in concert in the social media world that are things that we did not evolve to understand and deal with very well. Right.
*  So it will be interesting to see where we go forward. There is a related question there. I mean, basically, what I'm going to say is there's something that I've said many times, and I don't know whether it's right or not.
*  So I'm going to ask the fact check myself with you, which is, as someone who is not a moral objectivist, a moral realist, I identify more as a moral constructivist. I think that we have moral inclinations.
*  But then I also claim that and what what morality is, is just sort of a systematization of those moral intuitions and inclinations. But then I also claim that we can think about it.
*  We can do cognition. We can rationally reflect and we can update and adapt our moral inclinations.
*  So even though the the wellspring of our morality is something built into us or learned at such a young age that we can't think about it, that doesn't stop us from being rational about it as we mature and hopefully think more wisely.
*  Yeah, I think that that that is reasonable. I think that the project of cognitive science is really to understand, like, what are the constraints on reasoning and learning that can align or disalign a goal to progress?
*  And, you know, how you define that is is is is tricky and it's broad. But I think a lot of times we think we're reasoning when actually it's it's motivated.
*  Right. So, you know, how do you how do you separate the the process that that I think most people have, which is like, I want to learn and I want to act in a way that is, you know, compatible with my own flourishing and the flourishing of people I care about.
*  And also, you know, the world in general, like, how does that goal get shaped in ways that we can't see by systems of power that trace back generations and act invisibly and act in ways that are in many ways designed for us not to see them.
*  Right. So like, I think a lot about how our our whole moral cognitive apparatus seems to be really set up to identify victims and villains and all of the research in moral psychology is about how we judge the rightness or wrongness of individual actions.
*  And all of the stories that we consume in the media about wrongdoing are pretty much like, here's a bad person who did a bad thing and is bad and this is, you know, they should be punished and so on.
*  But like, what about systems? What about systems that constrain people's choices such that they they can't help but act in ways that cause harm to themselves and others? Like, how do you blame a system? Like, we are not like our minds are not really designed.
*  I think design is the wrong word. But like, like, we don't really like we don't have a good like conceptual system for doing that. But like, it seems increasingly and I think the pandemic is a really good example of this.
*  There was an article by Ezra Klein that came out, I think, you know, sometime in the first year of the pandemic that that really influenced me.
*  The title of the article was There are no good choices. And like, you know, within psychology, we had been talking a lot about about like, how do we get people to social distance more? How do we get people to like wear masks?
*  How do we get people to individually behave in ways that can like not infect other people and prolong the pandemic? And it was this very individualistic focus of like, individuals are bad if they don't wear masks and if they don't socially distance.
*  But like, that's totally ignoring the fact that like, our society was not set up to deal with a pandemic and our governments did not give us any good choices to live our lives during this phase.
*  And so like, I think a lot of the questions that we focus on disproportionately in moral psychology and in ethics are like a red herring.
*  Like, a lot of this is not about individuals, it's about systems. And so like, how can we think more about that integration?
*  It's a fascinating point because it's parallel to the discourse about effective altruism.
*  You know, we had Wilma Caskell on the podcast and my initial attitude is, well, if I'm going to be an altruist, I would rather be an effective one than an ineffective one, right?
*  Like that just seems to make sense. But I do feel the strength of a critique that says they're putting all of their emphasis on, you know, charitable donations and individual good actions and things like that.
*  And even if you agree with it, it is distracting or covering up the much more severe systematic problems that we might imagine dealing with.
*  Yep. Yep.
*  And maybe it's even, is there a dark side of morality? Is morality something that is purposed to cover up things that we might argue are bad?
*  I mean, you mentioned sort of retribution as something that is part of our moral calculus in some way, punishment for evil deeds.
*  And I've read you say that it's interesting, people will say we need to punish this person to prevent them from doing something bad again or from deterring others.
*  But really, we kind of like the punishment. We kind of like the idea that these people are being punished.
*  Yeah. Yeah. I mean, there are so many fascinating questions in thinking about motives for punishment.
*  And we've done a lot of work on this in various guises.
*  But, you know, the broader point from the study you mentioned is that like some of like most of our behaviors are multiply determined, right?
*  Like we do something and there are multiple motives that are guiding us towards a particular choice.
*  And then when we explain that choice afterwards, there are social forces that incentivize us to pick the reason that's the most like socially desirable to explain our behavior.
*  And I think over time, this creates narratives that can be self-serving.
*  So, you know, in the case of punishment, like we do have a taste for revenge.
*  It is something that I think evolved in order to, you know, at the group level, like keeps the social norm machine grinding along.
*  But for individuals, it's not clear that revenge and retribution are helpful either for like teaching people in the long term to change their behavior for the better or for individual well-being.
*  So like, you know, there's this idea that revenge is sweet and it's satisfying.
*  But actually there's data showing that like if you hold on to grudges and revenge, like that's harmful to your well-being as well.
*  And so, you know, we did these experiments where basically we gave people the opportunity to punish someone and they would never know that they had been punished.
*  It was sort of like the economic game equivalent of waiters spitting in a rude customer's food in the kitchen before they bring it out.
*  So in this, like people are willing to do that.
*  They will pay money to reduce the payoff of somebody who's behaved unfairly towards them, even if they never find out.
*  But then when you ask them to report afterwards, like, oh, why did you punish?
*  A lot of people are like, oh, I wanted to teach a lesson, even though, like in some of these cases, like there is no lesson being transmitted.
*  And in the case of in the case of a lot of altruistic behavior, there's there's evidence from our lab and other labs and just like looking out in the world.
*  Like people launder ill-gotten gains to make themselves feel better.
*  So, you know, the Sackler family donated a bunch of money that was earned in the fairest ways.
*  And I think I think also, you know, in the domain of climate, like greenwashing is such a prevalent issue where you have these fossil fuel companies who really should be like reinvesting their resources into like away from fossil fuels.
*  But instead, they're like spending a lot of money on public relations campaigns like, oh, we really care about the climate.
*  We really care about the environment.
*  But meanwhile, behind the scenes are still very much like trying to extract as much carbon from the earth and burn it as possible.
*  And like the science tells us that like we just can't do that like full stop.
*  Like, no.
*  So, you know, there's there there are a lot of ways in which moral narratives are used to strategically direct people's moral judgments or reputation about narrators away from the realities of the consequences of their choices.
*  And we're we're interested in in how moral narratives are essentially a kind of an epistemic power move, because what they do is they impose the narrators preferred structure of causation and moral responsibility into the audience.
*  And in many times, the audience doesn't even know that that is happening.
*  OK, I'm totally stealing the phrase epistemic power move.
*  I like that so much.
*  That is absolutely capturing something real.
*  And part of what is capturing is even at just an individual level.
*  Forget about the corporations or whatever.
*  People like to be a little judgy of other people.
*  Right.
*  And maybe that's a tawdry impulse that we have.
*  But if you can sort of dress it up as being morally righteous, then that makes you feel better.
*  Right.
*  Absolutely.
*  And, you know, there's there's some really nice work by Jill Jordan and colleagues showing that when you condemn other people, you are seen as more trustworthy.
*  So there is a way in which moral judgments and punishments act as a signal to other people that you yourself would not behave that way.
*  OK, I can't believe that we've gotten this far into the podcast without mentioning the words deontology and consequentialism.
*  Right. Like these are the first words I always say when we talk about morality.
*  We had Josh Green on the podcast and he has this idea that basically intuitively we're deontologists.
*  Right.
*  There are rules that we think govern right and wrong behavior.
*  But he says when you get smart and you become more cognitive and rational about it, you always become a consequentialist and you think through the consequences of your actions.
*  I don't I find that a little bit hard to believe, a little bit too, Pat.
*  I'm probably oversimplifying a very complex story here.
*  But but is there some way in which these categories of moral philosophy map on to the ways that we think about it?
*  I think that question is hard to answer because, you know, it's sort of a question that's that's begged by the design of the moral psychology literature.
*  I mean, up until fairly recently, the vast majority of research in moral psychology has been looking at how people reason about, you know, utilitarian versus deontological approaches to moral dilemmas, largely thanks to Josh, who like, you know, was a pioneer in this field.
*  And like he found this really, really tantalizing question that was very tractable to the existing methods in psychology and neuroscience.
*  And I think that's a completely different view to Josh, which is that I think that there's good evidence to suggest that the deontological reasoning is is is highly rational in a social sense in that deontological reasons and decisions are seen as more trustworthy by social partners.
*  So if you think about if you think about the demands of social relationships, especially close relationships and the importance for relation, like the importance of relationships for our well-being and our ability to sort of function socially, you know, most people don't want their spouse or their best friends to treat them just the same as any other person.
*  And like kind of the entire premise of close relationships is a kind of prioritization.
*  And so what we find in our studies is that especially when it comes to close relationship partners, people overwhelmingly prefer deontological reasoners over utilitarians.
*  Now that's slightly different when it comes to like leaders or people who are in a role where it's their job to treat everyone equally.
*  So we did some studies during the pandemic looking at trust in leaders who endorse deontological or utilitarian approaches to moral dilemmas that arose during the pandemic.
*  And here what we find is an interesting distinction.
*  So utilitarianism can be divided into sort of like a positive, positive dimension and a negative dimension.
*  So the positive dimension we call impartial beneficence.
*  It's the idea that everyone's welfare counts equally.
*  And the negative side is instrumental harm.
*  The idea that it's that it's acceptable to harm one person in order to save many other people.
*  And what we find is that across across 22 countries that we surveyed during the pandemic, people prefer leaders who endorse impartially beneficent solutions to dilemmas around resource distribution.
*  So, you know, we contrast a leader who says we should keep at home medical supplies, vaccines and so on.
*  And the utilitarian leaders like we should send those resources around the world where they're needed most.
*  And across these 22 countries, people trust the utilitarian leader more, the one who says we should have this sort of universalist approach to resource distribution during the pandemic.
*  But when it comes to instrumental harm, it flips.
*  So in dilemmas like like allocating limited ventilators towards younger people versus elderly elderly people or imposing lockdowns that will that will sort of trade off the welfare of different groups of people.
*  We find that people distrust utilitarian leaders who say it's okay to sacrifice the welfare of one group of people in order to save others.
*  So there's this nuance where it's not the case that utilitarianism is like broadly preferred in leaders.
*  It depends on the nature of the dilemma.
*  But I mean, going back to the question about like is is dantological reasoning irrational?
*  I don't think that it's necessarily the case.
*  And especially if we think about rational rationality in an ecological sense, like I think of I think of dantological intuitions as something that evolved as a way to to, you know, strengthen the fabric of society.
*  Via close relationships.
*  That's fascinating that we tend to trust people who are dantological thinkers or actors at the personal level, maybe not the leadership level.
*  There was a funny tweet that went around a little while ago about someone who said, I'm really looking forward to a superhero movie where the hero is a consequentialist, not a dantological.
*  Because you always see, you know, in the movies, it's like, yes, I will save you even though it means the universe might be destroyed.
*  And I'm always sitting there. Maybe I'm overtrained if I'm sitting there in the audience going, no, actually, you should you should let your friend die because the universe might be destroyed.
*  But that's not how we that's not our impulses at a very basic level.
*  Yeah.
*  But it's not just our views of other people that matter here.
*  Right. One of the things that you've been thinking about is how morality affects our self image.
*  Right. Like no one thinks that they're immoral.
*  Do they? Like I tend to think that everyone thinks they're moral and maybe they make mistakes and then justify it after the fact.
*  But that it has to interplay with our image of ourselves as trying to be good people in the world.
*  How does that work?
*  Well, so, I mean, I think that on the one hand, we know a lot about this.
*  And on the other hand, there's a lot we we still don't know.
*  So, I mean, what we do know is that morality is really crucial for our sense of self.
*  Nina Sturminger has some nice studies where you ask people, you know, hypothetical cases where someone has lost their sense of morality or whether they have lost their memories.
*  And are they are they still the same person?
*  And what they find is that is that, you know, people are more likely to say, oh, that's a different person now if their morality has dramatically changed compared to if they've lost their memory.
*  So we know that like memory is really integral to our our sense of identity.
*  And, you know, as I was saying earlier in this discussion, like getting excluded from the group is is, you know, deadly, you know, you know, it you know, in in our ancestral environment, it was literally deadly.
*  Like you couldn't survive without the group.
*  And nowadays it's still deadly like like, you know, depression and and and suicide and and and all sorts of of of health problems are associated with loneliness and social isolation.
*  Right. So, like, it is it is deeply, deeply important to be seen as moral by other people.
*  Here's where I think that we are really stuck with how our culture talks and thinks about morality.
*  We have this narrative template of like there are good guys and there are bad guys and, you know, bad guys do bad stuff to good guys.
*  And, you know, if you take together, if you take if you juxtapose, there are good guys and bad guys and you must be one of the good guys.
*  Like, you can't be a bad like you cannot know and put themselves in that category.
*  You know, we have so many defense mechanisms to prevent ourselves from thinking of ourselves as the bad guy.
*  And suffering happens like shit happens.
*  Right. So those three things are incompatible because if if if I am never the bad guy and yet suffering is happening sometimes because of me.
*  Like, how do we deal with that? So I think that we're really we we we are epistemically under resourced to solve conflicts in our society, both like both at the interpersonal level and at the societal level.
*  And it doesn't have to be this way.
*  And, you know, I'm I'm Buddhist and I I have spent many years studying meditation and Buddhist philosophy and then, you know, there are alternative ways of thinking about the self and thinking about social responsibility.
*  This goes back to what we were talking about earlier around like social structures as opposed to individuals being responsible for bad outcomes.
*  And and so, you know, I am really, really like early in this project, but I'm very excited to think about the implications of changing the way we view the structure of the self and moral responsibility for, you know, interpersonal conflict and well-being and so on.
*  Because I think I think that the the nut that we need to crack, so to speak, is like the cycle that we're stuck in where like, oh, something bad happened.
*  Got to find a villain. I'm not the villain. So you must be the villain.
*  And that just this vicious cycle that creates these intractable conflicts, both like in, you know, close relationships, but then also, you know, at, you know, between social groups and and and, you know, in politics and so on.
*  And so like, we have to find a way to loosen the grip of like the moral self and binary views of good guys and bad guys if we're going to solve these really, really complex problems that involve systems and a lot of suffering that like we all really want to trace to one person so we can blame them and punishment them and it will all be better.
*  But like, that's not actually necessarily going to going to solve the problem.
*  And blaming the president for the price of gas, right? Like sometimes, not only is it good guys and bad guys, but just the idea that there is a person to blame for things that happen is not always accurate.
*  Exactly. Exactly.
*  And it. Yeah, but okay, that's a big project to fix that. That sounds like something that is deeply embedded in human psychology. I was going to say the ancients could at least rely on mischievous gods and spirits to blame for bad things that happened.
*  But I mean, maybe maybe that's a better system.
*  Well, part of it is that we're not good at dealing with randomness either, right? Like some bad things happen that's nobody's fault, not even the system's fault.
*  Yeah. Is that something we can train ourselves to be better? I mean, if you're interested in the practical side of things as a psychologist, like how much do psychologists come up with ways that human beings can train themselves to be better at avoiding some of these mistakes?
*  I mean, we should do more of it. I think that the incentive structure of academia is tilted more towards coming up with your own pet theory and promoting it and getting lots of other people to believe in it than like actually solving problems.
*  That's one of the flawed systems, yes.
*  But education. Education is, I think, the best tool we have. And I recently had the mind-boggling, still-can't-really-believe-it-happen privilege to meet His Holiness the Dalai Lama at his residence in Dharamsala.
*  And we talked about all this stuff, the challenges that we're facing, perpetual conflict, and why is it that we are so stuck in views of us versus them when really we are all in this together?
*  And one of his main agendas, it seemed, from those few days was like education is everything. Like we really need, you know, with each new generation, there is an opportunity, again, because we are such prodigious social learners and because culture, you know, just as much maybe even more than nature and nurture is going to shape our behaviors and attitudes towards one another.
*  And so with every new generation, there are opportunities to give people the tools and resources to think about themselves and others and problems in the world and morality in ways that might be better than what we have now.
*  But the problem, of course, is that that discourse is shaped by systems that are not optimizing for well-being, they're optimizing for profit. And so like, how do we break free of that? That's like, you know, that is a very, very thorny question.
*  Probably need a sabbatical to really tackle that one comprehensively. But it also, you know, there's a reflection of a problem we talked about at the very beginning of thinking of science as completely objective and so forth. I mean, I'm entirely on board with saying that education is good and there should be more of it. But there's education and there's education. Like, what are we educating people about? It's not just the existence of education, but our educational system doesn't always prioritize the kinds of things I think that you're pointing at that would help people.
*  Navigate these situations. And it also doesn't get enough money in this country. Well, that's also true. Yeah. You know, it's like, like severely underfunded. And that's, you know, that is outside of my expertise. But clearly, clearly a problem. Well, near the end of the podcast, we always let ourselves be a little bit more speculative and wild. So you already mentioned. Have I not been speculative and wild this whole time? I kind of feel like I have.
*  Well, you were we glanced at this. I wanted to come back to it. The idea of psychoactive substances. I mean, you mentioned that an injury, a brain injury can change a person's memory, but also their sense of morality. So can drugs or maybe even diet or something like that? I mean, what is that? How should we feel about that if taking a certain drug? Well, first, I should ask you the question. Can taking certain drugs change our views of morality?
*  Yes, but it's not clear how long the effects last and how large the effect is. So, you know, there are there are many lab experiments, some of which I have done that show you can sort of shift around people's moral judgments and behaviors if you change their, you know, their neurochemistry acutely. But of course, our neurochemistry is being affected all the time by things like stress and, you know, like, our diet, things like that.
*  And it brings out in the world. So, you know, it's a moving target. I think there's an important distinction between like what these substances are doing to the brain in real time versus the type of knowledge you can gain or like in, as Lori Paul would say, like an epistemic transformation that can occur during an experience with a with a mind altering substance, especially, you know, psychedelics, I think are the prime example of this.
*  Where they dissolve your sense of that they can dissolve your sense of self, they can open up a really profound, you know, sense of love and connectedness and boundlessness with the entire universe.
*  And many people who have this kind of experience report that it is epistemically transformative. It changes the way that you see yourself in relation to others and then, you know, following on from that, it's personally transformative in that like, it can change your values.
*  And so those effects are lasting well after the acute effects of the substance have worn off. And that's what I think is really exciting about the potentiality of psychedelic substances is unlike other pharmacological treatments in psychology, like, you know, in psychiatry, like if you're depressed, you'll get prescribed an SSRI and you have to keep taking that drug indefinitely to, you know, experience the effects, which, you know, is what's happening.
*  Arguably, or maybe even not what they're cracked up to be. But like with a with a psychotherapy assisted with a psychedelic substance, like there can be changes to the narrative of the self and the way that you understand reality that have potential, I think, to carry on well beyond the time that you're high.
*  So that's extremely interesting. And I'm certainly very willing to believe that even after, you know, the neurological effects of the drugs have worn off, you report a different sense of self or whatever. But I want to question the self-reportedness of that. Is there evidence that people actually act differently long after they've done this? I mean, maybe I'm just being overly cynical here.
*  But I have this question about meditation and mindfulness. You know, I know people who have been very into this and they claim is very, very transformative. To me, they act the same as they always did. Maybe I am not actually as perceptive. And so you're the expert here.
*  Yeah, so I mean, you're right that quite a lot of the research that has been done thus far on psychedelics in meditation and, you know, attending mass gatherings like burning it like a lot of that is relying on self-report. And a lot of the work that we are doing in the lab is, is bridging the self-report with behavioral measures that some people might take as more valid or or
*  convincing. So there's less data on this. But so far, the data does not seem to be dramatically divergent from from self-report data, although like it is much easier to say that you think you've changed than to actually demonstrate change. And what one one new line of work where we're doing this is actually about the ability to
*  introspect. So quite a lot of quite a lot of work suggests that meditation improves your ability to to understand the inner workings of your mind. But the way that that has been measured has been like self-report questionnaires, like, how well do you understand your own mind? And after people go through meditation training, they say, better, but like, how do you verify that? And so in my lab,
*  there are several folks who are working on developing more objective measures of introspective accuracy. So we have people make a series of decisions, and we can use computational models to extract the processes that they use to make those decisions. And then separately, we ask people to
*  So I think that it's a really exciting time in cognitive science, because there are lots of new methodological avenues for verifying the link between self-report and and behavior. And I think actually that self-report, I'm just going to come out and say I think that self-report is underrated.
*  Okay, good.
*  And, and I think that, you know, it has been very popular in the behavioral sciences to not trust it. But I think that that is an oversimplified view. And I think that that we have data that that will be coming out that that calls that view into question. And I think I think the really interesting question is like, like, how, how can we bridge the very, very rich
*  reports that people can make about themselves and their understanding of the world with, you know, what what we might call more objective measures, but like, understanding this relationship between subjectivity and objectivity is something that I'm really, really curious about. So
*  So at least tentatively, you are willing to believe that people who practice mindfulness or meditate are actually better at introspection than those who are not.
*  We have not run those studies.
*  Okay. But it believes it fits in with the fact that the idea that the self reporting is somehow accurate, if that's true.
*  Yeah, well, and also, like the, you know, the entire premise of clinical psychology is that, you know, psychotherapy is helpful, and that people are able to report on their thoughts and feelings and, and, and learn to reason about them. And, and in particular, learn to recognize when thought patterns are
*  divorced from, from experience. So, so yeah, I think, I think it's a really interesting set of question.
*  I guess maybe I'm spoiled by or, you know, prejudice, maybe is a better word.
*  By being very convinced that psycho psychedelics and so forth can have great therapeutic effects and, you know, help with depression and PTSD. But then also, I hear people claim to get insights into the fundamental nature of the universe and cosmology and physics. I know that those are all just kind of nonsense.
*  I had to be a little bit skeptical of these overarching claims.
*  Maybe, maybe what they mean by that is different from how you understand it and how you're understanding the structure of the universe and cosmology is informed by your, your training and research as a physicist. And maybe what people mean when they say they understand the nature of the universe is, is more about.
*  Like, how do I fit into this and what is the meaning of my life and what is the point of it all? So, you know, I think, I think there's room for both.
*  Thank you for both. That's a very good. Can't argue with that. That's a very good place to end. So Molly Crockett, thanks very much for being on the Mindscape podcast.
*  Thank you so much. This was a really fun conversation.
