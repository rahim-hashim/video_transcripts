---
Date Generated: June 10, 2024
Transcription Model: whisper medium 20231117
Length: 4209s
Video Keywords: ['aliens', 'altruism', 'poker', 'probability', 'rationality']
Video Views: 29030
Video Rating: None
Video Description: https://www.preposterousuniverse.com/podcast/2018/07/23/episode-6-liv-boeree-on-poker-aliens-and-thinking-in-probabilities/

Poker, like life, is a game of incomplete information. To do well in such a game, we have to think in terms of probabilities, unpredictable strategies, and Bayesian inference. These are ideas that play a central role in physics and rationality as well as in poker, which makes Liv Boeree such a great person to talk about them. Liv is a professional poker player who studied physics as a university student, and maintains an active interest in science generally and astrophysics in particular. We talk about poker, probability, the likelihood that aliens exist elsewhere in the universe, and how to be rational when it comes to charitable giving. 

Liv Boeree earned a First Class Honours degree in Physics from the University of Manchester, before becoming a professional poker player. She has won well over $3 million on the poker circuit, including taking First Place at the 2010 European Poker Tour Main Event in San Remo, Italy. She is the co-founder of the charity organization Raising for Effective Giving, which has raised millions of dollars (largely from fellow poker players) for good causes.
---

# Episode 6: Liv Boeree on Poker, Aliens, and Thinking in Probabilities
**Mindscape Podcast:** [July 23, 2018](https://www.youtube.com/watch?v=y2dHXdD13ug)
*  Hello everyone and welcome to the Mindscape Podcast. I'm your host, Sean Carroll. Before jumping
*  into today's episode, let me just talk about some meta-commentary, the state of the podcast. As we
*  all know, this is a new project for me. We're all learning what's going on. I'm having fun. I hope
*  that you're having fun. But we're still propagating the podcast out there in different ways. I
*  certainly appreciate any efforts that you folks make to get the word out through Twitter or
*  recommending it to your friends. iTunes reviews make me just as happy as any other podcaster.
*  Some of you might know that Libsyn, the host that I use for the actual podcast episodes,
*  has an automatic thing where they will put the podcast on YouTube. It's just a still image. It's
*  not really a video. It's just the Mindscape banner logo there, but the audio is the same on
*  YouTube as you would get on the podcast. So for those of you listening to it, if for whatever
*  reason you would like to watch it on YouTube, go ahead. There's no video there. There probably
*  never will be any video. I know people say video would be better. Joe Rogan does video. Joe Rogan
*  also makes millions of dollars off of his podcast. And so far I am putting money into it and not
*  getting any out. Maybe someday I will get some out. I would like to at least pay for the microphones
*  and so forth. I don't know what that would eventually mean. Maybe just some kind of
*  Patreon page or something like that. That would be ideal. If it comes to ads, then that's fine
*  because you can get money and I like money. But we'll have to see. It's not going to be something
*  that happens right away. For those of you who are watching on YouTube already, just so you know,
*  it's also available on audio in the usual ways. On iTunes Stitcher, it finally got onto Google Play.
*  Google Play was having a problem with Libsyn feeds. So you don't need to have your YouTube
*  open there. You can just click on the links that are in the description of each video on YouTube.
*  It will take you to the podcast website where you can just listen to the audio or download it on
*  your apps, on your phone, whatever you want. There's even a subreddit, a Sean Carroll subreddit
*  that you can check out if you want to discuss further. The YouTube comments have been awesome,
*  but a more centralized place to go is on Reddit where people are talking about these things.
*  I think that's all that I wanted to say for the commentary stuff. Let's get into today's episode,
*  the theme of which is that we don't know everything as we go through life, but we still have to make
*  choices. We still have to act in the world somehow, but we live in a situation of incomplete
*  information. We don't know what's going to happen in the future. We also don't even know everything
*  about the world right now. So what we do is we attach probabilities to things. We say there's
*  a certain chance that something's going to happen. Accredence is how much weight we put on one
*  possibility versus another, and then we act accordingly. Formalizing this idea of placing
*  probabilities on things and then acting accordingly is called betting. And nowhere is the idea of
*  betting made more explicit and formalized than in the game of poker. Poker is one of my favorite
*  games. It's a game of skill that has luck involved because you don't know what the other players have,
*  but you can make choices and some of those choices you can win. There are people who make money over
*  the long term very regularly playing poker. Those are called professional poker players. They really
*  exist. There's no professional slot machine players because there you're just losing money overall.
*  But poker is a game of skill and today's guest, Liv Boree, is a perfect person to talk to about
*  this stuff. Liv was a physics major as an undergraduate at the University of Manchester
*  and she was quite good at that, but she decided instead to add a little spice of excitement to
*  her life by becoming a professional poker player and she's done pretty well. I can't say it was a
*  bad choice. She's made almost four million dollars in winnings at the poker table, and so we're going
*  to talk about what you learn from being a poker player, what that helps you do in terms of your
*  everyday life, making choices about one thing to do or another in conditions of incomplete
*  information where probabilities are central. Liv is also still remains interested in science and is
*  developing TV projects to help popularize science. She also has become interested in altruism and
*  charitable giving within the umbrella of effective altruism, trying to use empirical data to maximize
*  our impact as charitable givers. She's the co-founder of an organization called Raising
*  for Effective Giving, which funnels money to organizations that have shown that they really
*  have gotten good bang for their buck in terms of the charitable dollars. So we're going to talk
*  about poker, we're going to talk about altruism, we're also going to talk about how to think about
*  the existence of aliens. Whether or not aliens exist out there in the world turns out to be
*  something that's at the intersection of science and also probability. How do you
*  reason about something like that when you have so little data? So let's go.
*  Liberee, welcome to the Mindscape Podcast. Thank you very much. So now you were trained,
*  at least undergraduate education wise, as a physicist, astrophysicist. Yes.
*  Now you are a professional poker player. Correct. So just to set the stage, I think for a lot of
*  people, if you say professional poker player, they know exactly what that means. I bet a lot
*  of people in the audience are unclear that there are such a thing as professional poker players.
*  Is that even legal? Are you like in downstairs? Is it like rounders? Are you getting in trouble?
*  What is the situation? What is your lifestyle like? How does this work being a professional
*  poker player? So it depends, obviously from person to person. There are different types
*  of professional poker players, but I for the most part play a type of poker called tournament poker,
*  where everyone puts up an equal amount of money and in exchange for that you'll get a certain
*  amount of chips and basically everyone keeps playing until someone, until everyone else is
*  knocked out and one person has all the chips and wins either all the money or certain sort of
*  distribution of the prize pool. It's like capitalism. Exactly. Yes. A very aggressive,
*  zero-sum form of capitalism. And yeah, so I got into it in a very random way. As you said,
*  I studied physics. I fully intended to carry on in physics. I loved it. But at the same time,
*  I had been in education. I was 21. I also had ambitions of being a rock star. I was very into
*  heavy metal and disturbing my neighbours late at night playing guitar. And so I was like,
*  you know what, I'm going to take the summer off after my graduation and start, I need to make
*  some money somehow. So I'm going to apply for TV game shows. Because I felt like that made a-
*  As a contestant. As a contestant. I always liked playing games. Long story short, I learned to play
*  poker on one of these game shows and I loved the game. And I was like, you know what, I think I
*  want to take a few years and throw myself into this game. I think I have an aptitude for it.
*  It seems like a lot of fun. I want to travel the world and get some life experience. Still in the
*  back of my mind saying, I'll come back to physics. Right. Once we've made our pile, we can-
*  Yeah, once we've made some money, pay back my student debt, et cetera. And now 10 years later,
*  still here. The debt has long since been refilled.
*  Yeah, exactly. Well, things just turned out pretty well in the poker sense. And yeah, so in terms of
*  lifestyle, it's a lot of, for me, at least traveling to different tournaments. So there's a big stop in
*  Barcelona every August, or there's a big stop in Vegas, which I've just come from, the World Series.
*  And you also travel around to these- It's not the pro tour because anyone can play them.
*  But the professionals tend to like, that's their lifestyle, going from event to event and playing
*  in these tournaments. So literally anyone listening right now, as long as they have the right amount
*  of money, can show up, day of the tournament, say, here I am. And want to play. It's not like
*  a golf tournament or basketball. Anyone is welcome. And it's a meritocracy once you're there. Exactly.
*  Yeah, so anyone can play. It doesn't mean you necessarily should play. But if you want to and
*  you have the money and the desire, then you absolutely can. And I mean, I think that's what
*  obviously separates poker a little bit from something like golf, because golf is, the results
*  of a golfer are very closely correlated to their skill level. Whereas with poker, particularly over
*  a small sample size of maybe 10, even 100 tournaments, the worst players could be
*  vastly outperforming the best players. And so to say, oh, well, we're only going to let in the
*  people who've had the best results over the last six months. That's stupid. And people would just
*  get very annoyed with it because A, first of all, everyone thinks they're the best. That's why poker
*  exists. But B, it wouldn't actually be correlated to necessarily being the best players getting in.
*  And C, the ones who are good would like the money from the people who are not good to be in the tournament pool.
*  Exactly. Yeah. Yeah. It's this constant battle between, well, I want to be playing against the
*  best. I'm going to say I'm the best. But at the same time, I don't want to scare people off.
*  And so yeah, you need the weaker players you want to be playing against in an ideal world.
*  But it is a game of, it's a combination of luck and skill, right? I mean, like everything in life.
*  But it's not just luck. There's a certain element of randomness. You're dealt the cards,
*  but then you play them in a certain way. So it's not like playing blackjack or craps where there's
*  really no way to win without some kind of cheating. Yeah, exactly. I mean, with those games,
*  yeah, the casino, you know, it's built its big golden halls and amazing rooms and spaces because
*  they have this small edge that over time they make money from. And the longer you play, unless you
*  know how to count cards, which again, the casinos will kick you out for doing, you can't make money
*  playing blackjack and roulette. Whereas poker, because you're playing against other people,
*  and the casino host it basically because I think casinos don't really want to host poker.
*  They're not really making great money from it, basically, just like a small percentage of each
*  part. But yeah, with poker, you're playing against other people. And so if you are consistently
*  making better decisions than your opponents, then you are going to be making a profit in the long
*  run. I do get the feeling though, that the casinos enjoy having poker players around. Some of them
*  are very good at playing poker, but then are perfectly willing to go blow it at the baccarat
*  table. That's a very, very correct observation. Yeah. I mean, I've known many, many poker players
*  who were some of the best in the world and yet had no money to their name because they were the
*  worst in the world at walking past the roulette table. It's just, it's just another game, just
*  walking past it. Yeah. You just, who's the best at walking past it. And they know that they should
*  lose on average. Yeah, but they just love it. Like that's, you know, it's, yeah. I mean, there's,
*  I think to be a good poker player, you have to obviously have a willingness to,
*  you cannot be a risk averse human. Like you have to be willing to gamble, to take risks, to have
*  those like heart and the throat moments. But at the same time, you need to be able to do that in
*  an intelligent, moderated way. And some, but certainly not the best players you see around
*  now. Most of them actually don't have what we call sort of the degenerate gambler streak in them as
*  much, but there are still some who do struggle with it. And it's, it's quite a tragedy to see
*  someone who's like worked so hard at being so good at one particular game, but then have this sort of
*  life, we call it a life leak, a leak in the bottom of their pocket, which is some other form of
*  gambling. But I mean, it makes for great stories though. It does. And it also contributes to this
*  aura that the game has of being slightly disreputable, right? No matter how much money
*  and TV exposure and everything. And you still to this day do, as you allude to hear stories of some
*  of the world's best players just disappearing, like they're hiding, or they come back, oh, they
*  just lost $5 million over the weekend, you know, and it's, it therefore must be a very different
*  lifestyle than maybe you thought you were signing up for when you went to university as a physics
*  major. Yeah, I mean, like, I've seen this sort of, I had some insights, I've been lucky enough to
*  have some insights into like the world of, you know, the top chess players, for example. And
*  it is for the most part, a very different sort of social dynamic, because the best chess players,
*  like they really have to, I mean, they just study and study and study and study. And I mean, they're
*  brilliant, obviously, at what they do. But I don't know, like many, I think, I think poker
*  players have a little bit more of the wild, the sort of not free spirit, but you know what I mean,
*  like this, this wildness to them, that they, you know, there's this, these urges, I guess,
*  that they want to fulfill, they get thrills from many other things as well, as well as chess players
*  tend to, you know, they have to be so laser focused on what they do. So, but also, but sorry, but
*  continue exactly in that line. The thing that you're doing when you're playing poker is
*  fundamentally different than the thing that you're doing when you're playing chess. When you're
*  playing chess, both players see the board, right? 100%. When you're playing poker, you don't know
*  what the other person's cards are. And so they put out a big bet, they go, all right, here it is,
*  this is all your stack, this is for your tournament life. You have a pretty good hand, but not the
*  metaphysically perfect hand. And you need to, I mean, ideally say, well, there's a certain chance
*  that they're bluffing, there's a certain chance that they're not, and I'm just gonna risk it.
*  Yeah, exactly. I mean, with chess, you have all the information out there. There is no hidden
*  information. I mean, sure, you can't directly see into the other person's brain to see what specific
*  strategies, but you usually have a pretty good idea. And there's not like a very definite bits
*  of information that you don't have. Whereas poker, yeah, it's incomplete. And so that's why you have
*  to think probabilistically. And yeah, so then it becomes sort of this, I mean, largely a science
*  of being able to quantify these uncertainties that you have. Like, okay, well, what is the range of
*  hands that they could conceivably be playing here? Okay, it's from pocket twos to ace kings,
*  something like that. And also what is the, but then I have the piece of information that they
*  bet this particular card, but not this one, and they bet this size. And then on top of that,
*  there's even harder to quantify things like, oh, the pulse in their neck seems to be going really,
*  really strongly here when I wouldn't expect it to. This is inconsistent with the story they're
*  telling with their chips. So, you know, what do I do with that? And so it's this,
*  there's all these like little bits of variables of information, of some of which
*  are you're extremely confident about and others you're really not. And you've got to sort of
*  evaluate all of these somehow and put them together to kind of come out to one answer that is
*  most likely to be the correct decision that you make.
*  I don't know, you know, Ed Whitten, the physicist?
*  Who?
*  Ed Whitten, the famous string theorist.
*  I've heard of him, yes.
*  Yeah, he is, you know, he would probably win the poll if you ask most theoretical physicists
*  in the world today, who's the smartest theoretical physicist.
*  Oh, really?
*  He doesn't like poker because he says like, I don't know what the other person has,
*  like in chess, I could out-think everybody, but in poker, you have to make up these
*  what he-
*  Like heuristics, basically.
*  Heuristics, models, right, of the opponent. And of course, the counter to that would be that
*  John von Neumann helped invent game theory because he wanted to become a better poker
*  player, literally, right? He was playing poker.
*  I'm surprised, Ed Whitten, then it doesn't like it so much because, I mean,
*  it's still ultimately a mathematical game.
*  It is, but there's also psychology, so I'm sure one of the classic questions you're asked is,
*  what is the balance of doing math versus doing psychology when you're literally at the table?
*  So the answer to that is it entirely depends, but to throw, I hate throwing like probabilities
*  out there when there's, it really does wildly depend. I would say like 90%.
*  If I say, for example, I wanted to make you into the very best poker player in the world,
*  I would want to sit with you and make sure that you have,
*  put 90% of our effort into making sure that you understand the game theory.
*  The math, right, yeah.
*  The math, the actual, like, the building blocks of the game so that your strategies are built
*  upon that because it's ultimately a mathematical game. Then on top of that, if I can teach you
*  some of the like, the psychology and the harder to quantify parts, you know, these like sort of
*  build your intuitions up so that you are able to sort of intuit from people's behaviors what
*  they're thinking. But that's just more really just a matter of experience, I think, ultimately.
*  Some people are more inclined, you know, are just better at reading people than others naturally,
*  but I still think it's ultimately a learnable skill. And again, some of the best poker players
*  still find ways to almost like quantify their uncertainty about these like very psychological
*  human characteristics. You know, you'll know what the correct, you know, I should be calling
*  40% of the time according to game theory. And then I have a piece of evidence that suggests
*  that actually the opponent's bluffing very, like, far more rarely than that. Well, how confident am
*  I in that? And then I might waver the needle to say, so I'm down to 35% or call instead.
*  But it's still something that you can quantify.
*  Yeah, I once went to a movie premiere with a bunch of people and one of the people was Phil
*  Locke, the poker player, right, famous poker player, calls himself a time scientist,
*  a time scientist. I did not know that. We didn't talk about that. But we're like chit chatting a
*  whole bunch of us in the lobby before the movie starts. And Phil suddenly says, there's an 83%
*  chance that I'm going to have to pee before the movie ends. So I should go to the bathroom right
*  now. And I didn't know whether or not that that sort of silly precision of 83% was a joke or
*  whether he's just that good at estimating things. Knowing Phil, he is pretty good. He does
*  like to think in terms of probabilities, but that degree of granularity, I would estimate.
*  He's just having fun.
*  He's just having fun. Yeah.
*  So obviously, there's math in the sense of, okay, I need a heart to come down only have one card.
*  There's some elementary math. What is the percentage chance a heart will come down?
*  Right. But there's also higher level math. In particular, the game theory situation with sort
*  of optimal strategies and dominant strategies and exploitative strategies. Do you study that as part
*  of your education training as a professional poker player?
*  Yeah. Ideally, you want to familiarize yourself with. So I mean, well, you're lucky in this day
*  and age, there are these solvers out there that you can basically run Monte Carlo simulations
*  in different. You can go, okay, what should I do with Jack Nine suited on a 10, 7, 4,
*  one suit board of the same suit? Or similar scenarios like that. Put them into the solver,
*  let it run for a few hours, and it'll show you what the game theory optimal strategies with
*  the range of hands that you would conceivably have in that situation would be. So there would
*  usually be like a percentage of those hands that you would want to check raise because they're
*  really good, for example, because they have a lot of equity. But there's a percentage that you would
*  want to check call because they're kind of in the middle of the road. And then there's a percentage
*  that you would then want to bluff because you need to balance out your range. You can't just check
*  raise with the strongest hands. You need to have some bluffs in there so that you can get called.
*  You need to have the appearance of having a balanced range of hands, bluffs and weak hands,
*  when you make an aggressive action. And so anyway, you can literally find out what is
*  mathematically close to the perfect game theory optimal solution is now in these different
*  scenarios. And so the very best players will sit and work with these solvers. You can't use them
*  in real time, but you can go away and just study for hours and try to basically build a mental
*  model that emulates these game theory optimal solutions. And then once you have this mental
*  model of game theory optimal, then you can go out there and play using this style as a base
*  but then you would then deviate from it as and when you come across an opponent who is playing
*  not in a game theory optimal style because a good way to think about it is like if you and I were
*  to play rock paper scissors and you don't know anything about me, what would you be the strategy,
*  the best strategy that you would employ? I believe the best strategy is randomly do one third, one
*  third, one third. Exactly. Yeah, exactly. You want to perfectly randomize because you don't have any
*  information about me. So in response to that, the best case that I can do is to also randomize
*  perfectly because if I don't do anything on that, you're going to be exploiting,
*  you'll be taking advantage of me. So that's like an Nash equilibrium basically. Sorry,
*  explain what that is for the people out there in podcast land. So a Nash equilibrium is basically
*  a state strategy where it's unprofitable for either competitor or any competitor, it can be
*  multiple competitors as well, like more than two, to deviate from that strategy. If you deviate
*  from it, you're only going to be losing on average in the long run. So it's the equilibrium where
*  everyone is doing as best they can. As best they can and breaking even in this situation, you're
*  breaking even against each other. Like if we both play zero sum games. Exactly. Yes. However,
*  if you now notice that I start throwing rock, I know every time. Yeah. Should you continue
*  playing this? I could beat you then. I could have a better strategy. Exactly. You wouldn't want to
*  be stupid to carry on just playing this perfect 33% randomized thing. No, you'd want to start
*  playing paper far more often or like 100%. And so that is what you'd call then an exploit. You
*  exploit my bad play by deviating from the previous game theory optimal. And so that same kind of
*  thing applies in poker. You'll start off maybe ideally playing this game theory optimal strategy
*  and if your opponent's equally good, they'll hopefully try and match that and you'll be
*  in the long run breaking even against each other. But because basically no human in the world can
*  play perfectly game theory optimal, there are these rooms you want to see over the course of
*  time. You'll observe what these mistakes are people are playing. And so you'll deviate and
*  start exploiting those. I was highly amused to learn that there were competitive rock, paper,
*  scissors leagues. I did not know that they exist. They do because people are not good at randomizing.
*  And in fact, this is a very educational moment for me also. The New York Times had an app
*  where you could go and play rock, paper, scissors against the app. And basically it had trained
*  as an AI sort of thing on millions of real life human being rock, paper, scissors players and
*  realized what the tendencies were, what the deviations from randomness were, and it would
*  beat you. And I went in there. What kind of edge over? It was small, it was not large,
*  but noticeable. Like sub 5%? Over 20 hands, you could definitely tell you were losing.
*  Really? Yeah, that was my experience. But then what I realized, so I went in there cocky,
*  I'm like, I know how this is working, I'm going to beat it. And it destroyed me. So then I realized
*  there was something that I felt I should be doing. I played rock two times in a row,
*  I should play scissors or something like that. And I would tend to do that and I was losing.
*  You don't do these same thing in a row many times.
*  Yeah, that's right. That's hard to do because you don't realize how many times those sequences
*  come up randomly. But what I realized was if I figured out what my impulse was and had the
*  strategy that the New York Times app would probably play a dominant strategy against my
*  tendency, then I should play the one that would beat that. And suddenly I kicked its ass.
*  I really did. So it's just a matter of- Over how many iterations?
*  It's not the most exciting game in the world, right? So dozens, but not hundreds of iterations.
*  Let's put it that way. I want to do that.
*  We can find that. And another thing that I, along these lines, I remember the first time I learned
*  about in the realm of Nash equilibrium and game theory, the fact that in games like this,
*  mixed strategies will generally be the dominant or the equilibrium, optimal strategies. In other
*  words, there's no one action you should ever take every time in that situation. And it's perfectly
*  obvious in rock, paper, scissors. It's also true in poker. If you have pocket aces in some position,
*  the best possible strategy is not to do the same thing every time no matter what you have. It's
*  almost always true there. And then, so you have to, if the strategy is to do one thing 90% of the time
*  and something else 10% of the time, it's really hard to ever do that 10% thing. You know you're
*  not doing the best thing, right? Right. Well, so what some of the, again,
*  the top players have started doing now, because everyone knows that you need to be able to basically
*  be a perfect randomizing machine to have these, not only to remember what these ratios you need
*  to have in certain situations where you want to be bluffing with say 10% of your hands and betting
*  for value with 90%. How do you randomize that? Well, people have started looking like watches
*  like yours, you've taken it off, but with the second hand, right? Old analog watches have
*  become popular again. Why? Because it's a really good randomizer. If you're if you go, okay,
*  you just use the where the second hand is on the clock face. Okay, if it's between zero and if you
*  know you want to check raise 25% of the time, is it between zero and 15? Oh, yes, it is. Okay,
*  this is a check raise situation. If it's not, okay, I check call. Do you do that? Not as much
*  as I should. I've done it a few times. But a, I always forget my watch. Other players do it by
*  actually just like shuffling their chips all the time, because usually the chip will have,
*  you know, the word written on it and just where it lands. You know, again, yeah, that's that's a way.
*  And even if you're, this is a thing people think, oh, you need to then keep it secret that you're
*  doing this. No, even if your opponent knows, they just go, oh, shit, the optimal strategy,
*  they're playing GTO against me. Okay, that's I need to, it just, it's just an unsettling thing
*  to know, basically. Yeah. Yeah. But part of me thinks that it's less important to actually play
*  the game theoretical optimal strategy than to make your opponent think you're playing it, right,
*  because they're not perfect optimizers or randomizers either. So if you're supposed to
*  do something two thirds of the time and something else, one third of the time, and your randomizer
*  makes you do the one third of the time thing three times in a row, then I would definitely do
*  the other thing no matter what the randomizer told me the next time, because I'm not actually
*  my opponent is not building the correct model of me. That is true to an extent. Yes. But at the same
*  time, if your opponent is also then playing this perfectly sort of, you know, randomized in the
*  right way style, their style will not be losing out to the because they're playing this, this
*  unexploitable style, then arguably, you're going to still been playing less, less perfectly than
*  they are. And so in the long run, again, it's always down, you know, in the long run, you'll
*  still be playing less, a less profitable style than them, or sorry, a more exploitable style than them.
*  But when it comes to poker at a table with six or 10 people, we don't know the game theoretical
*  optimal. No, poker has not been solved. And in fact, as far as like, no, artificial intelligence
*  cannot win at a 10 hand 10 player table. There's been the AI that successfully beat humans heads
*  up one on one. But I don't even know if anyone's trying to do the three person and higher game,
*  because I mean, the game tree just gets ridiculous. Yeah, the decision tree. And yet we poor humans do
*  it. Exactly. Yeah, we're really, really good at building these sort of heuristics these these.
*  I don't know why we're so good at it. But it's we're able to sort of condense this down into these
*  rules of thumb that work out really well. I mean, I think it kind of makes sense that that's that is
*  what we're good at, right? The thinking fast and slow. Daniel Kahneman would explain, you know, we
*  don't think in terms of rational logical choices. Generally, we think in terms of heuristics, we
*  think in terms of rules of thumb, and we're really good at coming up with models of the world that
*  are pretty good. Yes, good approximations that get us by. Yeah. Yeah. I mean, do you use
*  Bayesian analysis or something like that very much? Why don't we explain what Bayesian analysis is?
*  Sure. So Bayesian analysis, Bayesian analysis is basically updating our model of the world based
*  upon new information, incorporating new evidence based on sort of the weight, the strength of this
*  evidence, whether it's proving or disproving our beliefs. And then, you know, when we see when we
*  see that thing happen, we'll go, OK, well, this means I should change my mind by this amount.
*  It's like shifts the needle. You know, if you think all trees are green, all leaves are green,
*  you'll go around. But then if you see, you'll go around assuming that. But then if you see a
*  tree with purple leaves, well, now that's evidence to suggest that's not so true. So you now shift
*  towards, OK, maybe not all trees are green, et cetera. And there's a way you can actually
*  model that mathematically using Bayes theorem. Do I do it mathematically in game? Absolutely not.
*  I don't have likelihood ratios and so on in my head. But no, I mean, ultimately, our brains are
*  Bayesian machines, right? That's what we're doing naturally without really realizing it.
*  And I mean, at least to me, it seems like it's a sort of fundamental law of,
*  not a physical law, but it is, you know, it's what do you call it? A psychological law? It's
*  it is some kind of law of the world we live in, right? Bayes' theorem? I mean, it's a math theorem.
*  It's the correct way to update your model of the world, I think. Yeah, it seems like it.
*  It's a rational way to behave. Yeah. And so my impression is this is my amateur poker player's
*  way of thinking about it. You can tell me whether it makes sense. You know, you sit down at the
*  table and you more or less assume everyone is the same in some way. And then as you see how they
*  play, your model of each individual player becomes more sophisticated. Yes. So we have
*  ways in poker of sort of describing that, right? There are tight players and loose players and
*  aggressive players and so forth. And maybe then you say, well, oh, this person is tight before
*  the flop and then they become loose afterward. And is that more or less what's going through your mind?
*  Yeah, I mean, not that I would ever advocate stereotyping people at all. But when you sit
*  down at a poker table, like I just played the World Series of Poker Main Event, for example,
*  where it's generally against a lot of amateur players who, you know, pony up their $10,000
*  once a year. And it's, you know, it's the best tournament of the year. It's really good.
*  It was profitable for you, right? Yeah, it worked out pretty well this time. And so when you first
*  sit down, I will immediately look around the table and create, based literally off first
*  impressions of how someone looks, you know, literally their gender, their age, the way they're
*  sitting in their chair, the clothes they're wearing, the way they look at me, you know,
*  their appearance of confidence or not confident. And so I'll immediately create a sort of some
*  kind of stereotype. A prior. A prior, exactly. A prior. But then in an ideal world, I'll still just
*  try and, you know, not let that influence my play too much, just a little bit. But as soon as you
*  start getting real information after like 20, 30 hands, well, now I've seen, okay, this person
*  hasn't played a single hand over 30 hands. Did I think they were tight beforehand? Actually, yes.
*  And does the evidence continue to confirm that? Yes, it does. Okay, so I can shift the needle a
*  little bit more to strengthen that belief. But if I notice actually the person who, you know, like
*  the old guy who seemed kind of conservative and timid has played every single hand and is raising
*  and re-raising everyone, okay. Better update. Better. It's time to update. This is very strong
*  evidence. Let's shift the needle more towards a he's an aggressive player. And so yeah, you
*  you'll sort of start building these models of people. And then by the end of the day, if you've
*  been at the same table, now you've got probably multiple hundreds of hands of where you've seen
*  a lot of information of people's tendencies with increasing degrees of nuance. And so you'll build
*  up a very accurate mental model of players over a given period of time. So do you take this way of
*  thinking, mixed strategies, game theory, optimal, etc. Bayes' theorem and updating your priors,
*  do you extend it from poker to the rest of your life? Has being a professional poker player
*  changed how you go about buying a house or getting a boyfriend or choosing where to go for dinner?
*  Yeah, I would say so. In terms of just like, thinking about things in terms of probabilities
*  and uncertainties, you know, beforehand, I was very black and white in my thinking,
*  it'll either happen or it won't. Or, you know, I certainly wasn't comfortable with any kind of
*  granularity. And now I'll sort of look at something and be like, okay, do I think, you know, am I
*  going to make it in time to for this podcast, judging by the LA traffic? Doesn't seem to. Yeah,
*  the probability has gone down. And I'll, you know, estimate at least mentally, and hopefully,
*  I'll try and communicate it to people as well, what I think the likelihood is in terms of a
*  percentage. I'll be I'm 30% to be there on time. That kind of thing. And I mean, in terms of
*  picking boyfriends, well, yeah, I mean, Igor, you picked a poker player. It's hard when you're
*  playing on the poker circuit, not to also, you know, have a significant other who's sharing the
*  same lifestyle. But yeah, funny story, Igor and I actually, what Igor asked me now about half a
*  year ago, randomly, he said, What do you think the likelihood is that we'll, we'll still be
*  together in three years time? Because we were like talking about moving cities and should be by a
*  house. And he said, Well, what do you think the likelihood is we'll actually be together in three
*  years time? I was like, Good question. That is sorry, that's the question that would only be
*  asked by number one, a poker player, and number two, someone who is pretty secure in the relationship.
*  Yeah, I well, yes. Well, yeah, that's, that's a reasonable thing to assume. And luckily,
*  our numbers came out fairly similarly. I think it was like 92 and 94% or something like that.
*  Excellent. Yeah, because there's a nonlinearity there. Like getting the wrong answer could change
*  the problem. Absolutely. Yeah, there can be but at the same time, it's it's really useful to know,
*  even if you don't end up being honest with each other, the fact that it asks you to reflect on
*  that, right? And you come away and think, Oh, actually, the number 60%. But I found myself the
*  word 90% coming out my mouth. Well, if nothing else, that's information for yourself. That's
*  right. Right? Like, oh, there's there's something not quite right here. Fortunately, like I did
*  genuinely I was like, No, I think it's, it's definitely over 90%. It's definitely under 100%.
*  You know, stuff can still happen. Therefore, and luckily, we were pretty much aligned.
*  The Yeah, so it definitely, I found it has bled into my thinking in all sorts of ways. And in
*  general, you just you take you just become more strategic. I don't know. I mean, I don't think
*  that's a bad thing. I know that people sometimes when people ask, Well, what do you do? And I
*  particularly if I'm in some kind of negotiation, they're like, Oh, you're a poker player. Well,
*  I don't believe anything you say. And it's like, Oh, come on.
*  Because I think poker is all about massive crazy bluffs, right? Not about strategic thinking.
*  Exactly. Yeah, it's like, No, it's about it's about choosing when to bluff your to actually
*  minimizing your risk when you bluff. Like I've found that like bluffing is stressful.
*  Like it can be very fun when you get away with it. But it's really not fun when you get caught.
*  Oh, yeah. And having you know, when you poker players know what it's like to get your bluffs
*  caught be caught in a lie. It's a it's embarrassing and be actually just financially hurts and it and
*  it can knock your confidence and so on. And so away from the table, I don't like lying isn't
*  really very fun. Like I get I get to scratch that itch at the table and it just creates
*  complications and you know, unless there's really, really, really good reason for it.
*  It's tend to try and avoid it. And it is embarrassing even at the poker table,
*  but it shouldn't be right. I mean, you're just playing the game theoretical optimal strategy.
*  Why? Yes. Yes. I be sad about my bluff called. Yeah, no, I that's that's definitely a thing.
*  I tried to you know, any anyone I'm teaching poker, I say like the first time you get caught
*  in a bluff, turn those cards over and slam them down and have a big smile on your face
*  and be proud of yourself. That's a big part of the game. And you have to get used to that sort of
*  getting your fingers caught in the cookie jar. Because if you don't ever get caught,
*  then you're not probably not doing it often enough. So yeah, there's like there's so many
*  like different facets of the game that sort of bleed over into life. I mean,
*  just the emotional control part of it. You're poker you learn to get used to bad luck.
*  Very fast because I mean, you play 10,000 hands in a week, you're going to have one percenters,
*  you know, where you should win the hand 99% of the time, but you don't have multiple of those
*  happen, then they really sting. Yeah. But, you know, probabilities, they compound over time.
*  And if there's many, many instances of bad luck, things that can happen, then eventually one of
*  those will happen to you. And so if you sort of remember that, I find you, you get less
*  emotionally attached. It's less of a shock. Yeah, I mean, what you said about the granularity
*  of probabilities, I think is very true. I mean, I have this idea that almost everyone
*  thinks there are only three probabilities for anything. It's either 0%, 100% or 50%.
*  The idea of something being 70 30 is just really hard for human beings to latch on to. And maybe
*  this is those heuristics that we grew up with in the wild, in the veldt of Africa, like you better
*  make a decision right away under conditions of stress and you don't get to do things over and
*  over again. But so you would really say that your experience as a poker player has given you a better
*  ability to correctly handle those 70 30 situations. Yeah, I think so. I think you, you know, I mean,
*  you're familiar with the term scope and sensitivity in terms of you. Humans, we evolved
*  in sort of tribes of probably up to 150 or so people. And so beyond that numbers weren't that
*  useful. We didn't have to count much beyond that. And you know, the classic example of,
*  oh, there's there's 1000 birds dying in oil, dying from an oil spill somewhere, you'll feel
*  some degree of sadness about that. If I say there's a million birds dying from oil, you don't feel
*  1000 times sadder, you feel probably a little bit sadder, but not 1000 times. And so we have this
*  like our brains aren't intuitively equipped to, to think accurately around really large numbers or
*  really, really small numbers, we just work on this sort of little macroscopic level that's in our
*  everyday lives. And so that I would say that's very into in realms of probability that sorts us out
*  between the sort of 30% is in the 70% is but beyond that, things just feel really, oh, it's,
*  it happens 10% of the time. Oh, that's a never. Yeah, that's a never. And 85% time, I pretty much
*  always. And I don't know, like, I think on the most part, you don't have, we don't have an intuitive
*  understanding of what actually like a 5% feels like or a 7% or 10%. But poker, you play enough,
*  you will like I find my emotions genuinely correlate with like, when I turn the cards up
*  on the flop, you know, we get a big all in, and I'm a, I'm a 12% underdog. So I'm Yeah,
*  I only got a 12% chance to win. Well, I'm just not going to get excited. I'm like, okay, I've lost.
*  Yeah. And, and, or if I have a 1% chance of winning, then my emotions are even less, you know,
*  I just don't feel anything. I mean, I'm just annoyed that I got it in so bad. And, but if it's
*  a coin flip, my heart will genuinely be racing, because I'm like, wow, I will win this 50% of the
*  time. And who knows what's going to happen. And so yeah, you sort of become well calibrated
*  to what these actually these these probabilities mean, because we've just seen, we've seen these
*  situations so many times over. Does that therefore apply to the everyday world? I mean, yeah, like,
*  if I'm someone says, oh, you're, I don't know, 10% to, to make a flight, I think, if I can figure
*  out that I'm roughly 10% to make a flight, then I will be, I, you know, I would be extremely
*  pleasantly surprised if I did make it. Whereas I think, but at the same time, I don't think I'm
*  that well calibrated as I am in poker. It's hard. Yeah, it's hard. So just to change gears a little
*  bit. I was pleased to see that you had an article in Vox recently, you went back to your sort of
*  astrophysics training. And it was a story about the application of probabilities to interesting
*  questions about the nature of the universe. So why don't you fill us in on what that was?
*  Yeah. So recently, some of this, the researchers at the Future of Humanity Institute,
*  and in Oxford, published a paper on called dissolving the Fermi paradox,
*  which I imagine most viewers know what the Fermi paradox is. Let's not imagine that. Let's tell
*  them what it is. Okay, Fermi paradox is basically, well, Enrico Fermi back in when was it 1960 ish,
*  53. 50s. Yeah, he, he didn't live into the 60s. He was very radioactive. Yeah.
*  But yeah, basically, he, you know, he looks up, he was like, wait, there seemed to be
*  billions, if not trillions of stars out there. And we know that the universe is
*  somewhere around 14 billion years old. If there's so many possible sites for life, why are we not
*  at least, you know, we've been releasing radio waves now for a few decades, like, relatively
*  easily, surely we should be least hearing or picking up trace signals from other worlds.
*  We're seeing aliens all the time. Like the universe is so old, there should, there must be at least
*  a few other thousand civilizations out there that have got a big head start on us. So where,
*  where is everybody? And so that's the like famous Fermi paradox, like the, the contradiction between
*  the size and age of the universe and the lack of observed alien life. And so this paradox has
*  seemingly only gotten stronger with time as, as, you know, we've become more spacefaring.
*  And we've discovered more and more exoplanets. And, you know, it seems like there are, you know,
*  universes even sort of more, more capable of hosting life than we imagined.
*  Certainly a lot of places out there where it could be.
*  Right. And, and yet, and yet we've still seen nothing. And we've been, you know, really looking
*  hard. And anyway, so this paper that they published uses the Drake equation, which was sort of this
*  equation that sort of is the best way we could try and estimate the number of intelligent
*  civilizations within the Milky Way. And it does a sort of novel form of analysis on it that hadn't
*  been really done before. And the answers that sort of came out the back of that is that we are
*  somewhere around 75% to be the only intelligent civilization within the galaxy and somewhere
*  around a coin flip about 50-50 to be the only intelligent civilization in the entire observable
*  universe, which is pretty, pretty astonishing stuff. Right. Counterintuitive to many people.
*  Extremely counterintuitive. Agreed. Also quite disappointing because I'd love there to be
*  some aliens out there. I mean, at least from a curiosity standpoint. But yeah, nonetheless,
*  pretty groundbreaking claim. And so the article was sort of discussing how they came to that
*  claim, what the actual processes that they did, the methods of analysis. But then I wanted to make
*  a sort of larger point from that, which is, okay, well, we don't know for certain that this is
*  actually the case, but let's assume that it is based upon our current best state of knowledge.
*  It seems like we're, if nothing else, life is extremely, intelligent life is extremely rare in
*  the universe. What does that mean, philosophically speaking, for us, if we really are the only
*  intelligent civilization out there and may well be for the rest of the universe's future,
*  what does that mean? Should we do anything with that information? Should we change any of the
*  behaviors that we're currently exhibiting and the trajectories that we seem to be putting ourselves
*  onto? And I think yes, I think it speaks that we have a greater responsibility to not blow
*  ourselves up. I do want to get into that. But first, I want to dig into this probability stuff,
*  because the Drake equation is something that has been batted around ad nauseam, right? Like people
*  are talking about the Drake equation. And so for the two of you out there in podcast land who have
*  not heard about it, the Drake equation is a way of estimating the number of intelligent civilizations
*  by saying, well, how many planets are there times? What's the fraction of planets on which life
*  develops times? What's the fraction on which the life becomes intelligent? It's a different
*  ways of breaking it down. But as far as I can tell, there's quite two things in the new paper that
*  are kind of interesting. One is they take seriously the idea of rather than finding just our best fit
*  number for the fraction of times life comes into existence and then becomes multicellular.
*  They say, what's the uncertainty or what is the probability distribution? So taking those
*  probabilities a bit more seriously. And secondly, it is a matter of being good Bayesians and updating
*  our priors, right? I mean, they're not saying just based on the laws of physics, we're probably the
*  only intelligent civilization in the galaxy. They're saying based on the fact that we haven't seen
*  it yet, right? That in some sense, Fermi was right. It would have been very, very easy to run into
*  another civilization if they were out there. We haven't seen them. They don't seem to be out there.
*  And therefore, from that, we draw the conclusion that probably the simplest explanation is they're
*  just not there. Maybe it's just way more unlikely that intelligent civilizations exist and continue
*  to exist than we thought it might have been. Right, exactly. The fact that we haven't found
*  any evidence of aliens is evidence unto itself and should be incorporated into sort of the
*  Bayesian model that we have of the situation. Were they able to pinpoint one of the factors
*  and say this is probably the tiny one? In terms of which one has the...
*  The smallest probability? Is it that light doesn't usually form?
*  Yeah, so the one that has the biggest number of range of uncertainty on it is a fraction of
*  planets that develop life. Okay, which makes perfect sense. What do we know about that?
*  Exactly. We still haven't really figured out how life started on Earth. The process of
*  A by Genesis is just really not well understood yet. And so the difficulty that we've had with
*  the Drake equation is that before we're sort of plugging in numbers like the rate of stellar
*  Genesis within the number of stars that develop per year, that's an astronomical number. We have
*  a reasonably accurate number for that. We have data on that.
*  Exactly. We have data for that. But then something like the fraction of planets that develop life,
*  it could literally be the uncertainties. They have like 200 orders of magnitude of uncertainty.
*  Oh my goodness. Okay.
*  It's that much. And the thing is, is that because any number between that is actually
*  completely plausible by saying, oh, well, yeah, but let's ignore the fringe parts of it. That's
*  making a statement. That's making a claim of knowledge that we can't make. Say, oh, well,
*  it's probably somewhere in the middle. No, it's as conceivable. The probability distribution is
*  fat-tailed all the way down. And so to cut these off is just doing bad math, basically.
*  Yeah. I'm glad the paper came out because I've run into great resistance. I've always felt
*  basically this, we don't know how likely it is that life's going to exist. The other obvious
*  bottleneck is multicellular life, which again, we don't know how that exists. I tend to think
*  that once we get multicellular life, intelligence is probably not far behind, but both the existence
*  of life itself and multicellularity seem like very mysterious. Maybe the chances are just
*  10 to the minus 100, right? And people say, there are so many planets out there and like,
*  there's no number N such that I cannot find another number that multiplies it and gives
*  us a small number. Tiny, tiny, tiny number. Exactly. Yeah. I mean, there's sort of the idea of
*  this great filter where there's some kind of insurmountable barrier that exists somewhere
*  in the chain of evolution that for whatever reason, most planets can't get past. And for
*  some reason, Earth managed to get past it. I hate to even hazard a guess at where it is, but
*  intuitively, not that intuitions really apply to this, it feels to me that it's somewhere
*  in the step from singular, sorry, prokaryotic to eukaryotic life, somewhere around there.
*  But again, that's just- That's true. So not just multicellularity,
*  but just the idea of having a nucleus. Exactly. Having a nucleus within a cell.
*  That's fair. That's probably more important. That seems to be somewhere around that. And
*  there's some other work that Future of Humanity Institute are doing right now on the similar
*  analysis, but looking at the transitionary time, the rates it takes to go from each step to each
*  step. And it just seems quite likely that the reason why life isn't everywhere is because
*  it just takes such a long time for it to actually get to the stage where intelligent civilizations
*  then actually spring up. We made it on Earth five, six of the way through Earth's lifespan.
*  In about 750 million years- Life came into being relatively quickly,
*  but then it sat around in this boring- Nothing stayed for ages and then suddenly
*  there was this explosion where evolution got kickstarted faster and interesting things
*  started appearing. But that wasn't basically until five, six of the way through of Earth's lifespan.
*  Had it just been a little bit longer, we would not have existed because Earth would have been
*  gobbled up by the sun. And so that's a reasonably plausible explanation as to why life is incredibly
*  rare. I suspect that's the right explanation. My other favorite one is that there are plenty of
*  civilizations. They all become highly advanced. They upload their consciousness into computers,
*  and then they become bored and they don't go space traveling anymore. Yes, that's a good one. Also,
*  the Aestivation Hypothesis. You know that one? I don't know that one. You'll be better to explain
*  the exact reason why. But because computation is expensive in higher temperatures, and you would
*  expect a rational civilization that would want to maximize the number of computations it can do
*  over time. So it would make sense for them to hibernate or astivate until the general temperature
*  of the universe, until far, far in the future and the ambient temperature of the universe is much
*  lower and therefore it's much cheaper. And I think it's something like 10 to the 30 more
*  computations a second you could achieve or something like that. I can't remember.
*  Anders Sandberg has a very fun paper on it. I've never heard of that one. I like the audacity of it.
*  I don't believe it. No, I don't. So I'll tell you why I don't believe it. Because the temperature
*  of the universe goes down. That's fair. But also the free energy of the universe goes down. The
*  energy that we have available to run our computation goes down. So I presume someone
*  smarter than me has actually done the calculation and said it's still better to wait. But there's
*  clearly a competition. Yeah, I'm pretty sure he factors that in. But I'm not versed enough to
*  explain why. Nonetheless, again, it was one that felt intuitive. It was very fun, but intuitively
*  I'm like, nah. Probably because it only takes one, you know, plucky counter example, right? Only one
*  civilization has to not buy into that. Yeah. But it does remind me of John Wheeler used to say,
*  when he mixed cream into coffee, he always felt sad because he was increasing the entropy of the
*  universe irretrievably. But you do bring up this question of what does it mean? What do we what
*  implications? So what if we are the only civilization, only intelligent life forms,
*  it makes you think, you know, for better or for worse, but making you think is good?
*  Why are we here? What is the point? So and you actually been thinking about things like this,
*  right? Yeah, I mean, I mean, I was just having a having conversation with my partner Igor about
*  sort of moral moral realism. I know that you're very much a non moral moral realist in terms of
*  human constructivist. Yes. Yes. And I'm of the same same mindset. But that said,
*  it if you want to sort of, if nothing else, maintain optionality.
*  I'm also going extinct is definitely going against that. Like, now the options have
*  disappeared to zero. And that seems it definitely appears like there is a very real risk that we
*  can go extinct by even 2100. And by real risk estimates somewhere between anywhere between like
*  two and 20%. I'm a moral constructivist. But the morals I construct do say that human extinction
*  will be bad. Yes. That's okay. I don't need an objective story to tell myself about it. Right.
*  Exactly. And, and, yeah, it just seems like it would be a terribly big shame if you know, all this,
*  these little pockets of low entropy have managed to appear us, you know, basically going against
*  the second law of thermodynamics to a degree. Are we actually going against the second law of
*  thermodynamics? We're not. Nothing goes against the second law of thermodynamics. So how this is what
*  I've never wrapped my head around. How do pockets of low entropy so successfully exist?
*  Well, it's actually an outgrowth of the second law of thermodynamics. Because if we think about it,
*  if it weren't, what would it mean to not have the second law of thermodynamics? Right? What would
*  it mean is that we were already in thermal equilibrium, right? We were already at our
*  maximal entropy state, right? Once you say the early universe started with low entropy,
*  that's all you need to say, then entropy increases. And that's the second law. The only way out of
*  that is to say you were already in high entropy and then there would never be any life. There would
*  never be any complex structures. There would never be anything like that. We are not creating pockets
*  of low entropy. We are leeching off of the fact that the early universe had an extraordinarily
*  low entropy. We're increasing the entropy of the universe willy-nilly, right? We were,
*  there's a separate question, related but separate, which is why are we complicated? Why are there
*  complex structures in the universe? And that's something that it makes sense that complexity
*  develops along the way from low entropy to high entropy, but the details of how it actually
*  happens is an ongoing fun research problem. And life is certainly just an example of exactly that.
*  Right. And so, yeah, I think it would be arguably a tragedy on a universal scale in terms of just
*  lost utility and lost potential and lost optionality if, you know, even from just
*  the expected, looking from an expected value standpoint, if we were to go extinct, even if
*  it's a 0.001% chance, there's still going to be 10 to the, I don't know how many possible lives,
*  you know, and possibly very happy lives in the future. I have met people who argue that the
*  human race should go extinct. That it would be a moral good. That the rest of the planet would be
*  better off without us. Right. Or they're, I assume they're extreme negative utilitarians in terms of
*  the thing. No, no, no. It's just that the utility goes to the plants and the animals, not to us.
*  We're a net negative, they claim. I don't believe them. I'm just saying, you know, it is out there.
*  What's their main argument as to why we are a net negative? Just because we create suffering upon?
*  Yeah, we're highly distorting the ecosystem and, you know, so much of the biomass is devoted to
*  keeping us happy and it's not a natural state of being. Right. Define natural. Well, yes. That's
*  the thing. Now I get into the semantics of that. I don't want to defend this. I'm just laying it out
*  there. No, I mean, it's definitely an interesting viewpoint to discuss. And I have to say,
*  intuit my intuitions are very, you know, I grew up in nature. I like, I love nature more than anything
*  and nothing upsets me more than seeing like images of the rainforest, you know, this millions and
*  millions of years old, beautiful, unbelievably complex rainforest, you know, a tree being cut
*  down into planks of wood, something that's so unbelievably complex and sustains this intricate
*  framework of an ecosystem around it. All the insects and animals and fungi and everything
*  that grows off it and relies upon it is reduced to planks of wood that people then put, you know,
*  we put on coffee tables, you know, that's put down into this complicated ecological, sorry,
*  economic system out of this complex. And I think they're two very different things,
*  complex ecological systems. So like intuitively, it seems like a huge tragedy that we are doing
*  that. Nonetheless, I also think intuitively is a huge tragedy that this, you know, human
*  consciousness that does seem, I don't know, inherently special, but there's definitely
*  something inherently unique that is not, we're not seeing elsewhere in the natural world
*  as much and for that to go out. And the thing is, is if we go extinct, well, chances are probably
*  all the other, most of the other big animals will go extinct too, as well. I just wanted on the record
*  that we are having this conversation at a concrete table, not a rainforest wood table.
*  With metal legs. Yes, very good.
*  So we're very morally correct in our living room here. But it doesn't, we probably don't really
*  think that it affects that calculation, whether or not we're the only civilization. I mean, maybe it
*  makes it more poignant, right? Right.
*  But we still don't want human beings to go extinct, even if there's 100 million others out there. I
*  mean, there are plenty of people who think that there are 100 million others out there, and they're
*  waiting for us to grow up a little bit, right? Right.
*  I have my suspicions that that's crazy also, but it is at least one of the options on the table.
*  Yeah, it's definitely, I mean, you can't rule anything out, that's the thing, when we're dealing
*  with something of such uncertainty like this. And certainly humanity has a lot of growing up to do.
*  But that said, there's a lot of beauty and goodness in the things that we are doing.
*  Right. And it would be nice if we were given the opportunity to try and grow up.
*  And you have put your money where your mouth is, quite literally, becoming interested not only in
*  these philosophical questions, but the applied questions of how to be better people, how to make
*  the world a better place in the effective altruism movement in particular. And you don't just talk
*  it, but you've like started an organization? Yeah. So tell people what effective altruism even is.
*  Yeah. So effective altruism is basically the combining the head and the heart when it comes
*  to philanthropy and doing good. We all, the vast majority of us, we want to do good in the world.
*  If we see someone suffering, we will try and help them. You see someone passed out in the street,
*  the natural human instinct is to usually go and check on them or a dog yelping or whatever it is,
*  someone screaming fire. We're all, for the most part, naturally altruistic.
*  And that's a great thing. But at the same time, there will also be different ways. There'll be
*  some ways which are more effective at getting a certain problem alleviated. And so effective
*  altruism is basically applying science to philanthropy, to altruism, doing good as
*  effectively and efficiently as possible. And so I remember hearing about this, this is a
*  I wanted to give money to, for example, environmental charities, but I often just felt lost. I was like,
*  well, where do I start? I'm concerned about climate change. I'm concerned about
*  biodiversity loss, et cetera, et cetera, all these different things, which
*  how do I weigh these off against each other? When I give my money to one charity, that means
*  I'm actively not giving my money to another. We only have limited resources ever to give.
*  And so it's imperative that we do as much research we can, or at least consult people
*  who've done the research to figure out where we can get, have the biggest positive impact with
*  whatever we give, whether it's not just money as well, time, if you choose to work for a charity,
*  you want to make sure that it's the actions that you are taking in your line of work are
*  achieving the most good, because you won't get those hours back, time is also a scarce resource.
*  And so after hearing all these arguments, I was like, oh, this makes a lot of sense. And
*  a team of full-time effective altruists, they suggested, well, look, we think poker players
*  will get this. They're very used to thinking in numbers about uncomfortable things. They're
*  comfortable with the idea of thinking about expected value and uncertainty. Variance,
*  quantifying things. And they're also, poker players, I think, are willing to, despite the
*  impression that we're all dark, degenerate money grabbing gamblers, actually,
*  like, I think a lot of poker players are aware of sort of a unique position that they have in terms
*  of we have sort of time and we can make good money and it would be nice to contribute to
*  society in some way. And so we decided to start this organization called Raising for Effective
*  Giving, reg-charity.org. Raising is a pun? Raising, exactly, pun on the whole chips thing.
*  Igor and I have many arguments about who came up with the name.
*  But yeah, it's definitely me, but anyway. That's why there's a 4% chance that it's not going to happen.
*  Yeah, well, no one will ever know. And yeah, so four of us poker players started it alongside these
*  Swiss Effective Altruists. And yeah, we were encouraging, originally we were encouraging
*  poker players to give 2% of their profits, sorry, 2% of their net, no, gross winnings every quarter.
*  And some people sort of continue on that model, others just sort of, because poker's a very
*  all or nothing kind of game often, you'll have a big win followed by months of losing.
*  And so generally people just tend to donate when they have a big win, a percentage. And yeah,
*  it's been extraordinarily well received. I had no idea that poker players would get it as much
*  as they did, and it's raised over $6 million now. And so the charities are specifically,
*  we either use GiveWell, who you might know, GiveWell.org, which is a very-
*  GiveWell's usually where I go when I have $2 to throw in.
*  Yeah, they're fantastic. In terms of human suffering reduction, they are the go-to in terms
*  of you want to find out how you can help human lives right now as best as possible. So we use
*  their top three recommended charities, which are almost always Against Malaria Foundation,
*  and sort of something deworming, and Direct Poverty Alleviation with GiveDirectly.
*  And that's because the cost to save a human life, like it or hate it, unfortunately, is just
*  many hundreds of times cheaper, around 100 times cheaper in the developing world than it is here,
*  say, in the US or in the UK. In the US, the government will spend up to around a million
*  dollars to save a life, if you look at sort of cross-health care and that kind of thing.
*  And yet you can demonstratively save a life in some parts of sub-Saharan Africa for around $7,000.
*  So that's a huge, huge difference. And even if you think that an American life is worth more than
*  someone, say, from Malawi, do you really think that they're worth 100x? Would you press that
*  button to say, I will kill 100 Malawians to save one random American? And it's not all about an
*  American you know, like someone random from America you've never been to. Would you really
*  say they're worth 100 mothers worth one mother here? No. And so, yeah, it's about this sort of
*  idea. Unfortunately, you do, you have to put a price effect. It's not putting a price on a human
*  life. But it's about saying, my actions, I can help someone with the money that I give. And so
*  I want to help as many people as possible with that. And so, yeah, so we've got some, we've got
*  the best charities in human suffering alleviation, the best ones in animal suffering alleviation.
*  By best, I mean most cost effective. And the animal ones almost always are to do with
*  anti factory farming. Yep. Just because it's pretty tragic what's going on out there. And it's very,
*  very cheap just to save very sentient animals from the life of misery. And then we also have
*  neglected research areas, specifically ones looking into things like global catastrophic risk.
*  So yeah, like people looking into risk from bioterrorism, because even if it's a tiny chance,
*  Exactly. Yes, even as it's a point 1% chance, you know, if you factor that over the 100 billion or
*  so lives that are going to exist over the next century, that's roughly what the number is.
*  Even over the next century, that's a lot of people. I mean, it seems kind of obvious that we should
*  try to be efficient and spend our charitable giving as effectively as possible. But there has
*  been pushback, right? I mean, some people don't like it. I mean, personally, I'll confess, I'm not
*  a utilitarian. I think that it's hard to be a consistent utilitarian. But still, I take the
*  effective altruism to be a good nudge in the right direction, right? I mean, we certainly do
*  value the things we see right in front of our eyes more than the things we know are going on
*  out there in the world. And this is an excellent reminder that there's ways to make a huge impact
*  elsewhere in the world that might not be quite as obvious to us. Exactly. It's not just it's taking
*  it's not saying that if you react to something immediately happening in front of you, that that's
*  not a good way of doing good. Of course it's good. It's there. And a big part of when you do good,
*  you're trying to do something altruistic and help, it's fine to also feel good about it. I think
*  people go, oh, you shouldn't have any positive emotions that come out of it, or you shouldn't
*  be doing it that way. I think that's silly. No, you want to do whatever continues to motivate you.
*  Yeah, get that dopamine from giving it to you. Absolutely. And so it's about, like I said,
*  it's about balancing not just the head, but also the heart. The heart is a big part of any kind of
*  charity giving and so on. And I think it's a mistake to try and remove that out of it. But at
*  the same time, we have to be aware that just purely acting emotionally, when we know that we
*  have these big biases in terms of like, we randomly will sort of value people who happen to live in
*  the same town as from someone who lives in a town a hundred miles away, even though we don't know
*  either of them, just because that's just the way human intuitions are sort of built. And that can
*  then be a mistake in terms of our sort of narrow resources that we have to allocate. I mean, maybe
*  from what we said earlier, there'd be a good charity that could give everyone free poker lessons,
*  because it would help them think in probabilistic ways about the world.
*  I wouldn't specifically say that. But yeah, I mean, like there is a charity who, I mean,
*  they're at least a sort of 5013C, but who train young people in applied rationality. So quantifying
*  things, which is basically applied poker, doesn't at all talk about poker, but they training
*  promising young people who are looking to get into sort of research, politics, you name it,
*  the art of rationality, which is incredibly important, because these are going to be
*  the future leaders. And I think we want leaders who are aware of human biases and aren't afraid
*  to think in sort of scientific terms, and to give them the tools to understand their own emotions,
*  and so on, and therefore be better equipped decision makers. And I think that's an incredibly
*  valuable thing. And that's one, these kind of organizations that are looking into teaching
*  rationality classes in schools, I think these are incredibly promising area to donate to,
*  because they can create a, there's definitely a huge lack in our current education system.
*  Like how many kids are taught to think through their feelings, for example, or
*  oh, it's okay to be uncertain. Let's see if we can estimate our probabilities. Like these basic
*  rationality tools that you and I take for granted, like we only know them because we learned them as
*  adults, either through poker or through another means. But imagine if you were just taught these
*  basic things, or like learning to think through the counterfactuals, something like that. I wish
*  I learned that when I was 10, it would save me so much time. Yeah, just like looking up the probabilities
*  of I used to be a huge hypochondriac. The amount of worrying time I've spent, you know,
*  going always my head ached brain tumor, if I just learned to like do a bit of Bayesian updating,
*  that would have saved me a lot of misery over, you know, my in my late teens. And so,
*  yeah, it's, it's, I think it's a big shame that these these areas are neglected.
*  Well, that I think it's a perfect place to end because you've basically encapsulated the mission
*  statement of this podcast, trying to get people to think a little bit more rationally, a little bit
*  more cognizantly of their biases and a little bit thinking in different ways than they usually do.
*  So Liv Boree, thanks so much for coming on the podcast.
