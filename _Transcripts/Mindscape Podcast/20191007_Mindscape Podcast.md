---
Date Generated: June 10, 2024
Transcription Model: whisper medium 20231117
Length: 4379s
Video Keywords: ['entropy', 'complexity', 'biology', 'evolution', 'cosmology']
Video Views: 26381
Video Rating: None
Video Description: Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2019/10/07/67-kate-jeffery-on-entropy-complexity-and-evolution/

Patreon: https://www.patreon.com/seanmcarroll

Our observable universe started out in a highly non-generic state, one of very low entropy, and disorderliness has been growing ever since. How, then, can we account for the appearance of complex systems such as organisms and biospheres? The answer is that very low-entropy states typically appear simple, and high-entropy states also appear simple, and complexity can emerge along the road in between. Todayâ€™s podcast is more of a discussion than an interview, in which behavioral neuroscientist Kate Jeffery and I discuss how complexity emerges through cosmological and biological evolution. As someone on the biological side of things, Kate is especially interested in how complexity can build up and then catastrophically disappear, as in mass extinction events.

There were some audio-quality issues with the remote recording of this episode, but loyal listeners David Gennaro and Ben Cordell were able to help repair it. I think it sounds pretty good!

Kate Jeffery received her Ph.D. in behavioural neuroscience from the University of Edinburgh. She is currently a professor in the Department of Behavioural Neuroscience at University College, London. She is the founder and Director of the Institute of Behavioural Neuroscience at UCL.
---

# Mindscape 67 | Kate Jeffery on Entropy, Complexity, and Evolution
**Mindscape Podcast:** [October 07, 2019](https://www.youtube.com/watch?v=uyZ2pjFvzdE)
*  Hello everyone and welcome to the Mindscape Podcast. I'm your host, Sean Carroll. We have yet another
*  experimental kind of podcast today. Our guest is Kate Jeffrey, who is literally an experimentalist, an experimental
*  neuroscientist at University College London, where she studies the cognitive map within the brain, how we find
*  where we are in the universe and how that triggers certain neurons in our brains.
*  But we're not going to be talking about neuroscience for the most part. Kate and I were both participants
*  in a workshop in Costa Rica, a Kavli workshop on space, time, and the brain, on this general idea of
*  relating space and time to how they're represented in brains. I gave a talk while I was there on
*  complexity and its relationship to entropy, and Kate, hearing the talk,
*  responded to it in her own talk talking about the evolution of complexity in a
*  biological and environmental
*  context, where things are much more subtle and nuanced and there's a lot of details that as a physicist I could gloss over.
*  So together we thought that it would be fun, rather than just me interviewing her about her stuff,
*  to talk about this area of the relationship between entropy and complexity,
*  how complex structures come to be over time, whether it's cosmologically,
*  here on Earth, or even within a social domain, and then how complexity goes away. There can be catastrophes, right?
*  There are extinction events. There's the ultimate equilibration of the universe.
*  So this is more than any other podcast I've ever had.
*  I think I am doing just as much of the talking as my official guest.
*  It's possible that I'm doing more of the talking than Kate did. But anyway, we're both sort of trying to learn things.
*  This is neither one of us laying down the law from on high.
*  It's a true interdisciplinary exploration, and I think you're going to find it's a lot of fun. So let's go.
*  Kate Jeffrey, welcome to the Mindscape Podcast.
*  Thank you.
*  So this is an unusual but fun episode, I think, in the sense that we're going to try to make it a two-way conversation, right?
*  You know, some people, some podcasters just make a lot of fun podcasts,
*  and they're going to try to make it a two-way conversation.
*  So I think that's a great way to start.
*  I think that's a great way to start.
*  We're going to try to make it a two-way conversation, right?
*  You know, some people, some podcasters just make every one of their conversations a two-way conversation.
*  I do try to let the guest do most of the talking, but we're going to be a little bit more balanced here.
*  To maybe explain why that's the case, why don't you give us some of your background,
*  where what you do for a living in your respectable part of your day job?
*  So I'm not a physicist at all.
*  So I have to start with an immediate disclaimer here.
*  I'm a neuroscientist, and I'm interested in how the brain makes an internal representation of the world,
*  so how it creates knowledge structures.
*  And I do that by implanting electrodes into the brains of rats and mice and listening to the signals,
*  and then trying to correlate what we can pick up with what the animal, with its sensory inputs, its behaviour.
*  And we're really trying to understand how it comprehends space and forms memories of its experiences and all of that kind of thing.
*  So that sort of led me to thinking about space and time and what that actually means and thinking of some bigger questions.
*  And that's how I kind of started straying into your domain to some extent.
*  Right. Well, we were at a conference together, a Calvary workshop in Costa Rica on space, time and the brain.
*  So those are three big topics, obviously.
*  And I gave a talk where I gave part of my usual spiel about entropy and complexity, and I can rehearse that here.
*  But then you gave a talk that sort of built on that in some way.
*  Were you already thinking along these lines? You must have been. You seem pretty prepared.
*  Yes. So I had come along to that meeting prepared to talk about how the brain makes a map of three dimensional space.
*  But my talk was on the last day.
*  By the time we had got to that point and the physicists and the neuroscientists had exchanged a few conversations,
*  I felt that I had less to contribute that was going to be useful about my research and more to contribute about some other things that I've been thinking a lot about.
*  And so I had never actually formalized those things before.
*  So I had to kind of sit down and construct from scratch as an assemblage of my ideas.
*  But what I had been thinking about for the last few months is how the nervous system has really come to be in the course of the evolution of the universe and the evolution of life and how it's managed to navigate the various bumps in the road along the way.
*  So there have been a number of major extinctions, for example, in the evolution of life.
*  And of course, we're facing another one at the moment, which has been occupying my thoughts a lot.
*  And so I've just been thinking about the fact that life seems to be inherently unstable.
*  And yet we've seen more and more of it accumulate as the universe has gone on.
*  And I just got curious about the dynamics of that. Why does that happen?
*  So it was fantastic to be able to talk to the physics guys with all your thermodynamic kind of understanding.
*  And when you talked about complexity and entropy and all of that, I just had so many questions.
*  So I thought, well, I'm going to lay out some of my questions and then we can talk.
*  Yeah. And here we are. This is sort of the culmination of that.
*  Cool. So how should we do this? You want me to start with my, like I said, my conventional spiel about entropy and complexity, and then we can build on that?
*  Because, you know, I think that you've your take on it is in many ways a lot more nuanced.
*  Like I'm just doing the simplest physics thing where we try to get the everything is a spherical cow and everything is very simple.
*  And as someone who cares about life and biospheres and things like that, you are very correctly saying it's a bit more complicated than that when we get to the real world.
*  Yeah. So, yeah, I think you should start definitely.
*  OK. So this is something where I became interested in it because I became interested in entropy.
*  You know, entropy for those out there who somehow have escaped me talking about this is a way of talking about how disorderly or how disorganized things are.
*  And more particularly, if you have a set of tiny little constituents, atoms or molecules or cells or whatever, and there are different ways to arrange them macroscopically.
*  And you can see certain features of those macroscopic arrangements.
*  So, like, you look at my favorite example is a cup of coffee with cream being mixed into it.
*  You see where the cream is, you see where the coffee is, but you don't see where the individual molecules are.
*  Right. So Ludwig Boltzmann in the 1870s said entropy is basically a way of counting how many ways there are to arrange the microscopic microscopic constituents to give you that macroscopic look.
*  So in other words, we coarse grain the description in terms of what we can see about it macroscopically.
*  And we just count the number of microscopic states that would contribute to that way of being.
*  And there's a rule, the second law of thermodynamics, that says that typically the entropy increases because very naturally, if you start in a configuration where there's only a small number of arrangements that look that way,
*  just by natural evolution without any direction, you will move toward a situation where you're in a higher entropy state because there are more ways to be high entropy than to be low entropy.
*  That's a very quick second law of thermodynamics intro, but that makes sense, right?
*  Yeah.
*  Do you use the second law of thermodynamics a lot as a working psychologist, biologist?
*  Not me personally. More theoretical neuroscientists think about it in terms of free energy and information theory and that type of thing.
*  I just tend to encounter it when I mess things up in an experiment or knock things out.
*  Entropy is part of our daily lives. That's certainly true.
*  But so can I just ask you a bit more about this notion?
*  Because I understand how it works for a box of gas molecules, let's say.
*  But I start to run into difficulties of understanding when I think about, for example, the entropy in a molecule of DNA.
*  Right.
*  So it seems to me that the number of microscopic states that correspond to that macroscopic state, there's more than one set of numbers, if you like.
*  So one of them is the number of microscopic states that would just lead you to a coiled molecule.
*  And one of them is the number of microscopic states that would lead you to the genome for cyanobacterium, let's say.
*  So macroscopically, they look exactly the same.
*  It's a spiral molecule.
*  But the functioning of that molecule in the bigger picture is completely different.
*  So I struggle with saying that the entropy of those two molecules is the same.
*  But my understanding is that a physicist would say, well, it is.
*  Well, I think that a careful physicist would say it depends in the sense that, you know,
*  you put your finger on one of the longstanding controversial aspects about the Boltzmannian statistical mechanical way of talking about entropy,
*  which is that it seems to involve some human choices in the definition of things.
*  Right.
*  I mean, I tried to make it sound pretty objective by saying the macroscopic features that you can observe are how you coarse grain microscopic states into macroscopic ones.
*  But someone could say, well, who's doing the observing?
*  Does a better observer see a different entropy than a worse one?
*  To a large extent in practice, that's not a big worry because the laws of physics make certain features macroscopically observable to us and not others.
*  So when we see the cream in the coffee, for example, even if you built a robot or even if you met an alien or whatever,
*  none of them is going to be able to see the individual molecules and their positions in momenta.
*  They're basically going to see the same things that a human being sees.
*  So there is something robust about nature that suggests certain ways of coarse graining into macrostates.
*  But when you get to the edge cases where there's not a lot of moving parts, you know, we're used to having Avogadro's number of molecules and you're used to having a much smaller number than that.
*  So in a DNA molecule versus some other sort of polymer of some sort, yeah, how what exactly you count as the microscopic constituents and how you coarse grain them into macrostates can matter, can be different.
*  And it might depend on functionality, I think, which is which is what you're getting at.
*  Right. Like two molecules that might look the same physically from just a sort of if your coarse graining is just how long is it?
*  How stretchy is it? You know, how bendy is it?
*  Two molecules might look the same. But if you're asking what is its function in the cell, those same two molecules might look very different.
*  I think that my answer is use whatever one you want.
*  Just be consistent once you start using it.
*  So I don't think that the right physics answer is to say, no, you have to ignore the detailed differences between DNA and some other long molecule.
*  I think that it just depends on what context you're working in.
*  And I think also that's OK. I don't think that's a flaw.
*  I just think it's something to recognize.
*  But are you saying that entropy is a subjective thing and that it's context dependent?
*  It is subjective in a sense.
*  It's but it's in the following sense.
*  This is the same thing is true. I would say about any emergent phenomenon.
*  Right. Whenever we have a microscopic description, which is highly accurate, perhaps perfectly precise, and there's a macroscopic description in different terms, which is only a good approximation.
*  It's always the case where we don't have to use that macroscopic approximation.
*  Right. Like if we were Laplace's demon, if we knew the location of every molecule,
*  Freeman coffee in the in the cup and could do the calculations in our head, we wouldn't need to coarse grain at all.
*  But nevertheless, there is something real and useful about the coarse graining.
*  Right. There's certain ways of coarse graining that would make no sense.
*  Like we coarse grain the coffee by saying in every little region of space, we'll count the number of coffee molecules and cream molecules or whatever.
*  We don't say, you know, we'll average the number of molecules over here and then a number of molecules at a completely different place for some arbitrary, crazy reason.
*  Right. And the reason why is because coarse graining in that way would give a description that has no simple dynamics.
*  Right. It's not robust.
*  The nice thing about emergence is you throw away an enormous amount of information, the locations and velocities of every individual molecule.
*  But what you keep is still somehow representing a true pattern in the in the dynamics.
*  Right.
*  Yes, I kind of get that. But I still feel there's a fundamental issue.
*  So if you take a stretch of DNA that is meaningful, so it's genes for some organism, then.
*  As time goes by and mutations occur and the DNA degrades, the molecule will have the same macroscopic properties, but it will be degraded within the bigger picture.
*  So in some senses, the information content, which which I kind of feel is somehow associated with entropy, the information content has gone down, even though the macroscopic qualities at that moment haven't changed.
*  But where the macroscopic properties have changed is when you look at what happens to that molecule in time, because after the mutation, it's going to build a very degraded, funny looking organism instead of a normal looking one.
*  So I'm struggling really with this notion of what is meant by macroscopic properties.
*  Are they just slices in the here and now?
*  Or do you need to consider the entire history of that system over time as well as within the space?
*  Well, certainly the usual way of doing it, the history over time wouldn't matter.
*  Like that's that's if it does matter, then your physical description is enormously more complicated.
*  It's not that it's impossible, but that we we very much like in physics to think in Markovian terms in the set.
*  Markovian just in the simple sense that what happens at one moment depends on what happened in the immediate,
*  previous moment, but not the entire history of the past.
*  And likewise, the future is predictable from right now, not from information in the past.
*  But what kind of prediction you're making is certainly relevant when you decide what is the information that you use that you take into account when you make your macrostates.
*  Right. So if you care about the function of that molecule within the cell,
*  then I certainly think that there are features of the cell that would go into your course,
*  features of the molecule that would go into your course graining, like a slightly degraded DNA molecule that didn't do its biological function.
*  It would be completely legit to count as a different macrostate than one that looked pretty much physically the same, but did its function perfectly well.
*  But then you have taken time into account because function is a thing that happens in time.
*  Well, I would say that what I'm taking into account is counterfactual statements like would the molecule act differently even right now if different things were happening to it.
*  I think that's OK to take into account.
*  But I don't need to actually see into the future to see what will happen to this actual example of the molecule.
*  But you wouldn't be able to distinguish degraded DNA from a well-formed DNA molecule in that sense until you had seen what happened to it in the future.
*  Or knew the gene sequence.
*  Yeah, you wouldn't be able to tell just by looking at it, I guess is what you're saying, right?
*  Or, you know, by using the immediately macroscopic available information to you, you would not be able to distinguish between them.
*  Yeah, and indeed it has no meaning until you consider its future.
*  Yeah, I think that this is a subtle edge case where you have there's a whole discussion.
*  There are people who know a lot more about this than I do.
*  But there's a whole discussion about hidden states within some macrostates.
*  So ordinarily in statistical mechanics, your hope is that all the microstates within a macrostate not only look the same, but for the most part, they will act the same.
*  Now, you know that that's not exactly true, right?
*  Like within some macrostate of a glass of water, there are some individual microstates where suddenly it will the water will heat up except an ice cube will form in the water.
*  That's extremely, extremely unlikely.
*  And it's a very, very tiny number of microstates.
*  But they exist and you would never know just by looking at the glass of water.
*  But we get around that by saying, well, there's just so few of those we can ignore them.
*  And again, when you get down to a small number of moving parts, you might not be able to ignore that.
*  So I think that, you know, a lot of it just comes down to the fact that you might not be able to reliably use some of these statistical mechanical ideas in regimes where,
*  cellular biology or nanoscale physics really matter.
*  That seems like a big statement.
*  Because the second law of thermodynamics, is that not supposed to govern the unfolding of the universe, including living with things?
*  Well, yes, but the universe has a lot of moving parts in it.
*  And look, if you have three moving parts, there's no such thing as the second law of thermodynamics, right?
*  It's just a waste.
*  If you have a hundred, then there's a reasonable approximation to it.
*  And if you have ten to the ten, then it's really, really, really good.
*  So that's we've got to accept that.
*  Right. I mean, fluctuations and unlikely events are hugely important at the level of cellular biology.
*  They're completely irrelevant at the level of what goes on in your internal combustion engine.
*  Yeah. So I guess the thing that's been bothering me about entropy has been this apparent subjectivity.
*  Yeah.
*  The other thing I've struggled with is the way in which it requires space to be meaningful,
*  because all of the descriptions of entropy at the thermodynamic level involve space and involve things being in one part of the space or the other.
*  Is that a fair statement?
*  Well, it's a fair statement in physics generally that space is really important,
*  in the sense that space is I'm thinking I'm talking slowly because as a physicist,
*  I'm trying to answer questions about like, why is there space in the first place?
*  Right. Which you're not worried about heavily for.
*  And we're not worried about for this conversation.
*  But roughly speaking, space is the arena in which interactions between physical systems look local.
*  Right.
*  Two objects will interact with each other when they are at the same or almost the same location in space in a way that they won't interact with each other.
*  They don't interact with each other if they have the same velocity but are in very different locations in space.
*  Right. So space is very, very special for exactly that reason.
*  And I think that that should be true even for biology.
*  But you sound like maybe you're worried about it.
*  Well, I am a little I don't know if worried is the right word.
*  But in thinking about entropy at the thermodynamic level, it seems to be to do with probability of, for example,
*  being in a particular part of the space that has gotten woven in with my thinking about evolution and why evolution has proceeded the way it has and why life has slowly increased in complexity the way it has.
*  And it seems to be that space is a very fundamental part of that process.
*  And what's happening as life evolves is that life forms are discovering new ways of extending the operation of their activities in bigger spaces or over bigger times.
*  And that opens up new possibilities for entropy to flow.
*  Halloween is on the way, the time for ghosts and devils and demons and witches.
*  But perhaps scariest of all is the idea of shopping for life insurance.
*  It can be very intimidating with all the different choices out there.
*  You're not an expert. How many times in your life do you go around shopping for life insurance?
*  So if you're scared by that idea, try policygenius.com.
*  Policygenius is an easy way to shop for life insurance online.
*  It's basically an educational tool that you can figure out what all of the different options are.
*  And you can compare quotes from the top insurers to get your best price.
*  Furthermore, when you do apply, the Policygenius team handles all the paperwork, all the red tape that gets in the way of making it a straightforward process.
*  And it's not just life insurance. Policygenius does car insurance, home insurance, and so forth.
*  So this October, take the scariness out of buying life insurance with Policygenius.
*  Go to policygenius.com, get the quotes, and you can apply in minutes.
*  Or you can just do the whole thing on the phone right now.
*  Policygenius.com.
*  Yeah, no, I think that's exactly right.
*  So maybe I can sort of build on the little spiel I gave about the second law and talk about complexity a little bit.
*  Because again, I'm thinking about it at the most very basic physicist level.
*  But we want to get a little bit more nuanced during our conversation here.
*  So if you believe that the history of our universe, the last 14 billion years, has been a history of increasing entropy, of increasing disorderliness and randomness,
*  then it's perfectly OK to wonder how complicated organized structures like you and me or the biosphere or whatever came into existence.
*  There's a sort of bad creationist argument that says it couldn't have happened because the biosphere is very organized and the second law says things just become more disorganized.
*  That's obviously wrong because the second law only says that entropy increases in closed systems.
*  And the Earth and its biosphere are nowhere near a closed system.
*  We are getting wonderfully low entropy energy from the sun.
*  We are increasing the entropy of that energy and we're sending it back to the universe with much higher entropy.
*  So the net effect of the Earth on the entropy of the universe is certainly to increase it in complete accord with the second law of thermodynamics.
*  But that just says it's OK.
*  It's allowed that complex structures such as life appeared on Earth that doesn't explain why it should happen.
*  So with Scott Aronson and some other folks, some students and postdocs, Lauren Willett and Brett Burness, we studied this question and we proposed the following thing,
*  which apparently is not completely new, but it's a little bit new, but it's related to older ideas.
*  As entropy increases in a closed system, if you think about it carefully, when entropy is really, really low, things are organized.
*  Things are even though that's what it means for entropy to be low, but not only they organize, they're simple.
*  There's not that many ways to be really, really low entropy.
*  So if all the cream is on the top of the cup and all the coffee is on the bottom, that's low entropy and simple.
*  Whereas when things are high entropy, when all the cream and coffee are mixed into each other, things are simple again.
*  Right. Everything is mixed together. That's very, very simple.
*  It's in between that complex structures are allowed to exist.
*  And then you can ask the question, is it actually the case that in the course of physical evolution, complex structures do come to exist?
*  So do the cream and coffee simply smoothly blend into each other and everything is simple all along the way?
*  Or is it more like you're stirring with a spoon and you get some complicated fractal patterns in it?
*  And so we did some simple simulations and we showed that you can get either one, you can get either kind of behavior.
*  And in cases where you wanted to get complex structures forming, that was allowed as long as there were correlations in how the cream and coffee mixed into each other.
*  So our hypothesis is number one, that as entropy goes up, complexity starts low, grows and then fades away again.
*  And number two, there are situations in which that will happen and situations in which it won't.
*  And at least one of the ingredients you need for it to happen are correlations in the evolutions.
*  It can't just be that one thing interacts with the thing right next to it.
*  There has to be like some rigidity or some long range forces that are pushing things together in concert so that structure forms on all sorts of different scales.
*  So the lesson that we take from that, which is not nearly justified by the work we did, but I think is the extrapolation of it, is that the formation of complex structures like the biosphere and individual organisms here on Earth is not just
*  despite the fact that entropy is increasing, it's because of entropy increasing.
*  If it weren't for entropy increasing, we'd be in equilibrium.
*  We have high entropy already and there would be no living structures.
*  So our existence as organized low entropy creatures is actually part of the general tendency of things in the universe to increase in entropy overall.
*  But what is driving the temporal unfolding of the increase in complexity followed by the decrease in complexity?
*  What is the thing that's shaping that evolution of complexity?
*  Right. Well, so I think again, there's two things. There's a simple thing that it's allowed.
*  Right. Like really, it's not allowed to be complex when entropy is super, super low and it's not allowed to be complex when entropy is super, super high.
*  The only place that complexity could exist is in between.
*  And then the only question is, does it, as a matter of fact, come into existence?
*  And that's the complicated one. So we gave this really, really simple, very kind of village idiot kind of answer, which is that you need some long range correlations or long range structures.
*  Now, when you so I think the correct thing to do, like the next step is for me to hand it over to you and say, you know, in the real world, how did it happen?
*  And what lessons does that give us for the larger physics questions of how might it happen in principle?
*  Yeah. So when I listened to you talk about this in Costa Rica, I had an aha moment when you talked about these correlations in space across space and time.
*  Because that suddenly seemed to me to explain why life becomes more complex, because what happens as life has evolved is that with each step in evolution, something has happened that has suddenly enabled organisms to become much more correlated over bigger areas.
*  And we have known for a long time that evolution has taken place in these kind of step transitions.
*  So, for example, for a billion years or so, they were just cyanobacteria and everything was very boring.
*  Yeah. And then, you know, suddenly, suddenly things happen.
*  You know, for example, suddenly, 500 million years ago, multicellular life evolved.
*  Suddenly, organisms were able to do a lot more than they could, because once clusters of cells were able to interact and were able to correlate their activity, they were able to do tricks.
*  You know, for example, they could divide up tasks between them.
*  One end could be for gathering food and one end could be for squeaking food, all that kind of stuff.
*  And there are a number of such transitions.
*  The evolution of the nervous system is another one.
*  Suddenly, an organism could convey a message from one side of the cluster of cells to the other side.
*  And so they could coordinate their activities.
*  They could do things like contract muscles and move.
*  And then when they became able to move, they could move out of one patch of food into a new patch of food and just opened up all sorts of amazing things.
*  And, you know, there have been a number of these.
*  And with each step, suddenly, organisms have managed to extend their reach and become much more complex.
*  And humans, I think, are a fantastic example of that.
*  We're now extending our reach out across space and out across time and into higher dimensions and amazing stuff that we do.
*  Yeah. And I think that one of the features here is that complexity can build upon itself.
*  I mean, this is certainly the lesson, both of the origin of life and of the origin of multicellularity,
*  that there's only so many things that can happen if there's no life around or if all the life is unicellular.
*  And the space of possibilities becomes enormously bigger as this phase transition happens.
*  Right. So physicists think about these transitions as phase transitions where this sort of one type of thing happening.
*  And then suddenly a little bit of something new comes on the scene and can take over because it's so much more advantageous.
*  And again, the biology needs to be a little bit richer and more nuanced here than the physics does because so, OK, fine.
*  There can be a phase transition and you can explore different parts of the possibility space.
*  But how exactly does that happen?
*  And, yeah, you know, physicists are allowed to think of things happening in arbitrary numbers of dimensions or arbitrary amounts of time.
*  But you want to think of things happening in the real world.
*  And it matters, you know, chemistry matters as well as biology.
*  Right. What molecules can you build and how can they interact with each other?
*  And it's certainly I think it's it's uncontroversial to say that the origin of multicellularity opened up a huge space.
*  And in fact, 500 million years later, we're not anywhere near done exploring it.
*  Right. Things are still changing very rapidly.
*  The invention of technology has opened up a whole new set of dimensions of space, of possibility space, of not space space.
*  But do you have a feeling for sort of what general lessons we can learn from these transitions or the existence of them?
*  Well, one of the things that's quite notable, if you look over the evolution of complex life,
*  is that there have been periods of time when there's been a sudden decrease in complexity as well.
*  So there have been several major extinctions where suddenly things have gone backwards in very large steps.
*  And indeed, life has nearly been obliterated several times.
*  So, for example, when organisms discovered how to photosynthesize and suddenly reach out in space to grab the energy of the sun, if you like,
*  they used it as a byproduct of that activity oxygen and the oxygen levels in the atmosphere rose very high.
*  And of course, oxygen is very toxic.
*  And there was a what they call the great oxygenation catastrophe, this big sudden fall in biodiversity.
*  And there have been other things. So, for example, when organisms did discover how to move,
*  they discovered how to burrow through the substrate that they were living in, in the bottom of the ocean.
*  And that allowed mixing of the water in the ocean with the substrate underneath and completely changed the chemistry.
*  And again, there was a big extinction and a lot of life forms disappeared.
*  They didn't all disappear. And of course, the ones that were left then gave rise to what came after.
*  And in fact, there was a huge explosion of life after that.
*  We've had these several extinctions and life has managed to recover.
*  But there is this feeling when you look at it that it might not have done,
*  that it might have been the case that the extinction had been total.
*  And I can't see anything in thermodynamics that rules out that possibility.
*  And of course, the situation that we're in right now,
*  where we have extended our complex reach over space and time further than any life forms ever have before,
*  that also opens up more possibilities for extinction than life has ever had before.
*  Yeah, no, absolutely.
*  And I think that there is no thermodynamic guarantee that we couldn't extinguish all of life.
*  But let's, you know, for the non-biologists out there, including myself,
*  let's dig into this statement that it was almost extinguished.
*  I mean, is that in terms of a number of species or the number of organisms?
*  I would think that there's still going to be some unicellular organisms that would, you know, tough it out even in these big events.
*  But maybe I'm wrong.
*  Well, I mean, the ones that have happened up to now have indeed left a lot of life, you know, still going,
*  both in terms of number of species and in terms of numbers of genomes, if you like, individuals.
*  But, you know, it's not necessarily the case.
*  For example, if we manage to turn the Earth into Venus or, you know, cover it in radioactivity, then perhaps we could obliterate all life.
*  So we don't know that life, which when you look at it, life seems to be very dynamic and inherently unstable.
*  And, you know, rapidly changes into wonderful complexity, but it does feel like it could also rapidly run into a wall.
*  So something I've been thinking about a lot is, are we about to do that?
*  Yeah. If we are, can we stop it?
*  So I think that thermodynamics gives us no solace here.
*  I do think that this is an important difference between the very simple example that we looked at with cream and coffee,
*  where the complexity just smoothly went up and then smoothly went down, roughly speaking, because it was kind of it was kind of featureless.
*  Like there's only two things or the cream molecules, as it were, in our simulation and coffee molecules.
*  There was not a lot of room for different kinds of things.
*  But I think what you're what you're getting at is that in this specific case of life, there's sort of mechanisms for this complexity that are very specific, right?
*  That there's certain biological channels for order to be created, for complexity to be created.
*  And in some sense, they're fragile, right?
*  Like there's sort of unique ways or almost unique ways for complexity to come into existence and build upon itself.
*  And that and I'm not characterizing that feature as perfectly as I could.
*  But maybe you know what I mean and maybe you can do it better.
*  But then this opens up the possibility for catastrophe, right?
*  Like it's it's good that it builds this complexity so effectively, but it's bad because it also opens the possibility for being wiped out.
*  Yes. Yeah, I think it's very much a double edged sword.
*  But given that, it strikes me as interesting that nevertheless, complexity has increased steadily over the evolution of the universe.
*  And so although in theory it can be a sawtoothed increase, nevertheless, it has generally gone up.
*  But something that you said in your talk, which made me kind of pause and contemplate the future grimly,
*  is that complexity inevitably as the universe unfolds over the next billion years is going to go down again.
*  And if I understand you correctly, the reason is to do with entropy.
*  But I'm not fully sure I have a handle on why.
*  So can you unpick that a bit more?
*  Sure. I think that, you know, this is not the kind of thing that makes us change our life insurance policies or even change our ecological policies worldwide.
*  But it is true that this idea that complexity grows is one that can't last forever.
*  At least it's true in the universe as we know it.
*  Our universe is very young in some sense.
*  OK, it's 14 billion years old, which sounds old.
*  And usually when you watch a TV show like Cosmos, which explains you the history of the universe,
*  it treats the Big Bang as the beginning and today as the end, right?
*  Like we're December 31st.
*  Of course, that's not true.
*  The universe is going to keep going.
*  And you can ask, how does the last 14 billion years compare to what comes next?
*  We discovered in 1998 that the universe is not only expanding, but expanding faster and faster.
*  So there's no reason to think it will ever stop expanding.
*  It will probably just keep expanding forever.
*  But the part of the universe we can see is only finite in size because the universe is accelerating.
*  There's a horizon around us, past which you will never be able to see.
*  So there's a finite amount of stuff in the universe and there's an infinite amount of time for it to evolve.
*  So like the cream in the coffee, it will reach equilibrium.
*  It will reach a point where everything is smoothed out into its highest entropy configuration.
*  Now, this takes a very long time.
*  The oldest stars will burn or the longest live stars, I should say, will burn for trillions of years.
*  We've only been around for 14 billion years and stars will still be shining a trillion years from now.
*  But eventually they will use up all their nuclear fuel.
*  That's a feature of using up entropy.
*  We'll use up all the hydrogen and helium that we had to burn in the stars.
*  And so the universe will become dark, but it still won't be done yet.
*  There will still be a difference between black holes and planets and stars.
*  But eventually even that difference will be smoothed out because all the stars and planets will fall into black holes.
*  So we'll have the universe with nothing but black holes in it.
*  And eventually even that will go away because Hawking showed in the 1970s that black holes evaporate.
*  So the black holes will evaporate into nothingness over a time scale of about 10 to the 100 years, one Google years in old fashioned terminology.
*  And then there'll be nothing but empty space literally forever.
*  So there's no room for complexity in the heat death of the universe 10 to the 100 years from now.
*  Maybe there'll be some tiny ephemeral life forms that form in the evaporating black hole atmospheres.
*  I don't know. That seems very unlikely to me and very unsatisfying.
*  It's certainly very different than what we have right now.
*  But yeah, in some very real sense, we are in the part of the history of the universe and in the few billion years of the history of the universe where stars are forming and shining and acting as really robust entropy, low entropy energy sources that allow life to exist.
*  But that is in some sense a very temporary condition.
*  So that's I mean, that's a very grim prospect.
*  It's quite depressing.
*  I don't know why, because I'm going to be longer on myself.
*  Millions of years, trillions of years.
*  Still the idea that it can it cannot last forever.
*  But again, it seems to be very woven up with space, because if you think that the driver for complexity is the ability of of systems to reach out in space and kind of
*  grab entropy, if you like, from around themselves, it seems like space is expanding faster than they can do that and eventually will expand beyond the realms of the possibility.
*  So, for example, even if we manage to become a super civilization that could harvest energy from all around us and manage to stop ourselves from going extinct and all the rest of it, eventually the universe will be able to expand.
*  That we couldn't find any of the energy anyway.
*  It's too far away and too little of it.
*  Is that?
*  Yeah, no, that's completely true.
*  I mean, the way the way you can you can say it, I'm not sure that space is crucial in this particular case.
*  What's crucial is entropy again, in the sense that we have not reached the maximum of entropy that we can reach.
*  So as long as we're not at our maximum entropy, we're not going to be able to reach the maximum entropy that we can reach.
*  So if we're not at our maximum entropy state, there's still room for something interesting to happen, right, for some complex structure to be there and persist and think and love and care and die and write poetry.
*  But as you get closer and closer to maximum entropy, there's less and less room for anything complex and interesting to happen.
*  So that's the ultimate fuel crisis of the world, right?
*  So, you know, entropy is conserved, but entropy is not entropy goes up.
*  And so the difference between where we are and thermal equilibrium just decreases with time.
*  And so you're right.
*  Eventually, there'll be no more room left.
*  We'll have used up all of our what we call free energy.
*  That's the technical term.
*  The free energy will go to zero.
*  Yeah.
*  And life will be over.
*  And not only will there be no more living creatures, there'll be no memory of you having ever existed.
*  That's really a shame.
*  Is there no way we can stop this?
*  Like, could an advanced technological civilization somehow stop this in theory?
*  So I think the answer is no.
*  And even in theory, you can't.
*  You could imagine building something, a record, right?
*  So I don't think it's actually possible, but it's within the realm of conceivability that you could make an artifact that recorded your greatest deeds, right?
*  And lasted for an arbitrarily long period of time.
*  But what would be impossible is for anyone to read that artifact because the act of reading and remembering increases the entropy of the universe.
*  And if you're at maximum entropy, that can't happen.
*  So consciousness itself, you know, thought and life cannot exist once you've reached equilibrium.
*  But that's assuming that the second law is completely unchangeable.
*  But is that is that the case?
*  Yeah.
*  Could we ever wind the clock back?
*  My money's on the second law.
*  Yeah, no, I don't.
*  You know, there is something called the recurrence theorem that if you wait long enough, if you live in a universe where there's only a finite number of things that can happen,
*  truly finite number of things that can happen, not just that we can observe, then you will fluctuate back into a low entropy state.
*  But that that causes all sorts of problems with things like Boltzmann brains and things like that.
*  And it doesn't it seems to very clearly not be the universe we actually live in.
*  So I don't think that that, you know, not only is it not the universe we live in,
*  but it wouldn't really ameliorate your problem because you couldn't send messages from one part of time to another through the point of equilibrium.
*  So not a lot of room for talking to your future friends.
*  Could we find a way to borrow from here into an adjacent universe that's still in a very low entropy state and borrow some of their entropy?
*  Not according to any laws of physics that we know about them.
*  I mean, this is good to think about.
*  You know, if you want to this is very long term planning, you know, the long now would be embarrassed about how short term their thinking can be.
*  I'm grasping at straws here.
*  Yeah, no, I know. But it's as far as I know. No.
*  I mean, so what is possible is that a new universe will be born from ours, right?
*  That a baby universe will be born. Again, no information will be conveyed from us to them.
*  But it's possible that what we think of as the universe is just part of a bigger multiverse and more universes are constantly created.
*  And the way that those universes are created naturally starts them in a low entropy state from which they can grow and things can happen.
*  And in fact, it's very possible. In fact, I proposed a theory in which this is true that our universe came from a preexisting universe in exactly that way.
*  But again, they can't talk to each other as far as anyone knows. That's the downside.
*  Yeah.
*  Yeah.
*  If you haven't had enough of listening to my voice or hearing me talk about quantum mechanics, audible.com is the place to go to get even more.
*  My new book, Something Deeply Hidden is now out.
*  I spent four days of my life recording the audiobook for something deeply hidden.
*  So maybe it will be a good way for you to catch up on your quantum mechanics.
*  You can download it from Audible today. And it's not just my book.
*  If you want to get a copy of my book, they have other books as well. Audible is a wonderful way to get books as well as updates from the New York Times, the Wall Street Journal and so forth delivered right to your favorite audio device.
*  As a member of Audible, every month you can choose one audiobook, regardless of price, as well as two Audible originals and also unlimited access to exclusive guided fitness and meditation programs.
*  So, let's start with a 30 day Audible trial with one audiobook and two originals absolutely free by visiting audible.com slash mindscape or texting mindscape to 500 500.
*  That's audible.com slash mindscape or texting the word mindscape to 500 500. Start listening today.
*  So can I ask you another question then something I've been trying to understand.
*  A lot of these processes that we've talked about, for example, the cream and the coffee or the converse, which seems to be a creation of order, which is oil separating from water.
*  These changes in complexity.
*  Linked with entropy seem to depend on gravity.
*  And in fact, everything seems to depend on gravity.
*  So the formation of of stars and planets and life like it's all dependent on gravity.
*  To what extent is gravity a fundamental part of this or is it not?
*  Well, I think that it's part of a fundamental part.
*  Let me let me very briefly mention that oil and water separating actually increases entropy as that happens, which it must because entropy increases.
*  But it's that's because of detailed chemistry properties of, you know, hydrophilic and hydrophobic molecules in the oil that it's actually a higher entropy configuration for them to be not mixed than for them to be mixed.
*  Sure, but it didn't need gravity for the oil to be on the surface.
*  Well, even if you didn't have gravity, the oil and water was still separate from each other.
*  But yeah, there'd be there'd be globules.
*  Right. So gravity does have that effect of sort of segregating or stratifying or whatever it is, things in certain ways.
*  But it's only because there's also other forces.
*  Right. So I think that what is important is not gravity per se, but the fact that there are different forces that work in different directions.
*  So there can be a competition between them. Right.
*  That's when things can become interesting when you're looking for an equilibrium between some push and pull of gravity trying to push things together and let's say electromagnetism pushing them apart.
*  That's the fact that we have these two forces that both act over long ranges in the universe.
*  Gravity electromagnetism seems to be a minimal requirement for really interesting complex structures to form.
*  OK, so again, that's that being able to reach out in space and time is a prerequisite for complexity.
*  And I guess you could think of the role of gravity as being to bring things together, to move things through space so they can interact in ways that they couldn't have otherwise.
*  Yeah, absolutely. But, you know, gravity is subtle.
*  Also, like this is I mean, even even at the physics level, which I keep saying correctly is way more simple minded than the biological level.
*  On the one hand, gravity pulls things together.
*  On the other hand, it's also the expansion of the universe.
*  It counts as gravity. Right. That's part of the geometry of space time, which Einstein told us is what we think of as gravity.
*  So the fact that the universe is accelerating and eventually pushing things apart is also gravity.
*  So it's the thing we don't understand cosmologically is why the universe started in such a low entropy state with 10 to the 88th particles stuck into a region the size of a cubic centimeter, which seems absurd.
*  And then everything expanded and cooled from there to be billions of light years across.
*  But it's all gravity that does both those things.
*  So gravity is your friend for a little while, but then it's ultimately your enemy if you want to be a complex structure.
*  OK. I didn't know that gravity is driving the expansion of the universe.
*  Can you explain that to?
*  Yeah, I mean, there's two senses in which that's true.
*  One is just the very, very blunt sense in which the size of the universe changing over time one way or the other is a gravitational phenomenon.
*  Einstein back in 1915 explained that what gravity is, is the curvature of space time.
*  And in a universe that is more or less uniform through space, one of the features of what we call the curvature of space time is the changing size of the spatial universe.
*  The scale factor, as we call it in general relativity, that tells us the relative distance between distant galaxies.
*  So the fact that galaxies are moving apart from each other, they're not moving through space.
*  Space is growing. And that is a phenomenon due ultimately to general relativity, which is the theory of gravity.
*  There you go. But then there's the extra new feature that, at least in the old days, even though the expansion of the universe was part of our gravitational theory, general relativity, at least gravity was attractive.
*  At least it was slowing down. But in 1998, when we discovered the acceleration of the universe, we realized that there is probably something that we call the vacuum energy, the cosmological constant, which is pushing things away.
*  It's still gravity. It's not a new force. Sometimes people say we discovered a new force of nature, but that's not right.
*  It's the old force, gravity, the first force we ever discovered.
*  But there's a new kind of stuff, the vacuum energy, whose gravitational effect is to push things apart.
*  So there you go. Even gravity can have tricks up its sleeve.
*  So try to link this to entropy then. So I still kind of think of entropy as somewhat bound up with space.
*  So for example, it's the gas molecules that are in half the box versus the whole box and the probability of finding one of those molecules in a particular place and so on and so on.
*  So if you suddenly doubled the size of the box and all the particles were on the one side, then as entropy unfolded, they would spread out across the box.
*  And naively, it feels to me that the more space you've got, the more microscopic configurations are possible.
*  So does that mean expansion of space is somehow tied up with how much entropy is possible?
*  Yeah, well, it's slightly tricky. I want to say yes, but I want to then put a footnote.
*  The thing that is a little bit hard to internalize is that the expansion of space is part of the physical system.
*  So when you say how much entropy is possible, you really shouldn't fix space at a certain size.
*  This is just a feature of general relativity. You can always make space bigger. That's one of the things that can happen.
*  So unlike good old classical physical mechanics, when you would talk about putting gas in a box and fixing the boundaries of the box, if your box is the universe, you have to allow the box to expand.
*  That's just part of the dynamics. So when we say that in the early universe, there was a cubic centimeter where all the particles that we now see in the universe were somehow confined in a relatively smooth distribution,
*  it's not quite legit to say, let's calculate all the ways we could arrange those 10 to the 88th particles inside a cubic centimeter and compare them to how many ways we could arrange the particles today and say that the possible entropy has gone up.
*  Because among the weird things about that initial condition is that it was small, right? That it was within a cubic centimeter.
*  So you can't separate out the arrangements of the particles inside the box from the size of the box itself.
*  So the lesson is still true that yes, the entropy was very low back then. It is much larger now.
*  But it's not that the allowed entropy went up. It's just that we weren't ever coming close to accessing the allowed entropy at that early time.
*  So what determines the allowed entropy then? If that doesn't change, if you can't, you seem to be saying that it's not meaningful to say that, to talk about the number of ways that you can arrange all of those particles in that centimeter.
*  Well, you can talk about that, but you can't say that's the maximum entropy, right? Because you could say, well, but I can make the box bigger and there's even bigger entropy allowed to me, right?
*  But if you... Okay, I see the problem. So I'm thinking I have two reference frames in my head at the same time.
*  One is the centimeter squared universe with all the particles jammed in and unable to move. So therefore low entropy because you can't rearrange them.
*  Where can they go? Yeah.
*  And then the other one is the large universe where they could be all over the place. And that feels like there's a lot more ways that you could do that. And that's a very high entropy.
*  Yeah.
*  But you're saying you can't have those two reference frames at the same time.
*  Well, you can't... What you can't say... Sorry, there's yet another subtlety here. Here's the yet other subtlety.
*  When matter is extremely densely packed, as it was in the early universe, gravity, not just over the expansion of the universe scales, but gravity, the gravitational pull of the particles on each other was really important.
*  Right? I mean, it's very densely packed. That makes perfect sense.
*  When matter is very densely packed, high entropy doesn't mean smooth anymore. Right? In a box of gas, a high entropy configuration is a smooth uniform configuration.
*  But when gravity, when the mutual gravity between the particles becomes important, you increase entropy by making things lumpier.
*  Like in the current universe, you could make a black hole. The black hole, the center of our galaxy has more entropy than all the particles in the known universe.
*  Right? So the fact that the entropy was very... The configuration was very smooth at early times is itself a low entropy fact.
*  Right? It's not only that everything was packed into a tiny region of space, which is true, and low entropy, but also it was smooth, which is low entropy.
*  So cosmologists, some of my best friends, professional cosmologists, have this idea, which is 100% false, that the early universe had high entropy.
*  Because they say, you know, look, it was smooth and it was hot and it was glowing like a black body. It looks like it was thermal equilibrium. It looks like a box of gas.
*  And that's entirely wrong because both it was a very small box of gas and because it was smooth even though gravity was important.
*  So it was an anomalously low entropy state from any way you slice it.
*  Right.
*  So then it's been increasing ever since and we're going to keep increasing.
*  And it's fascinating and it's full employment for, I think, physicists and biologists to study the specifics of the ways in which it's increasing.
*  So cosmologists will talk about forming black holes and then evaporating.
*  And biologists will talk about all of these complex structures acting as entropy engines.
*  Right. I mean, that's what life does in some sense.
*  Yeah. Yeah. I mean, life, you know, I was introduced to Schrodinger's idea of life as being a sort of temporary reversal of entropy.
*  I came across that concept a long time ago and it's always struck me as, I mean, obviously wrong.
*  I think he didn't accept it either.
*  But at the same time, it did always plant this idea.
*  Well, you know, why does life do that?
*  Why is it the universe not just not just drift out and diffuse?
*  And not only has it formed, but it continues to do more and more and more and more crazy and interesting things.
*  I just think that's amazing.
*  Well, I think, you know, here's one way of that I think about it, but this is very primitive and we should be able to do better.
*  The space of possibilities is really large.
*  Right.
*  When you have a lot of particles and there's a lot of places they could be in the universe and there's a lot of ways they could interact with each other and so forth.
*  There's a lot of things that can happen.
*  And the journey from the early universe where entropy was low to the very, very late universe where we're in equilibrium is one of exploring that space.
*  Right. Because in equilibrium, by definition, there's sort of an equal probability to be in any configuration.
*  But just because the set of configurations is so big, you're not actually even in the 10 to the 100 years that it takes the universe to equilibrate, you're not going to come close to actually exploring every single arrangement of stuff within that universe.
*  So it's easy to say, sure, you explore more and more of the allowed phase space or whatever it is.
*  But the way in which that happens specifically is the crucial question when it comes to life and complexity and things like that.
*  And they're like, I think you keep correctly emphasizing space matters because life is, you know, an organized by itself low entropy thing that can exist only because it's increasing entropy elsewhere in space.
*  Yeah, yeah. I mean, the reason that life can do that is because of the spatial properties of the carbon atom.
*  So, you know, because of its three dimensional symmetrical structure, it's able to build these amazing molecules that can reach out and make these, you know, as you noted, these interactions across space and time.
*  So without carbon, we wouldn't have one of those.
*  And I find myself often wondering whether this has ever happened anywhere else.
*  I used to assume that it must have in many places in the universe.
*  But as time has gone on, I started to think, actually, maybe maybe it's never happened anywhere else.
*  Maybe this is really unique, the particular conditions that have allowed carbon based life to form and remain stable.
*  Maybe that's so unusual as to be unique.
*  Well, I think I've had that thought also.
*  And my attitude is that we don't have any data here, right?
*  We don't have a lot of data about the fraction of other planets or other environments that have life on them.
*  So we should be very open minded.
*  Maybe within our observable universe, the Earth is the only planet that ever had life form on it.
*  There's certainly another option, right?
*  I think that since life seemed to catch on pretty quickly on Earth,
*  but multicellular life took a very long time to form or eukaryotic life or something like that took a long time to form.
*  Maybe those are the hard parts.
*  And when we visit other planets, there'll be, you know, some sort of cyanobacteria all over the place, but nothing more interesting.
*  Yeah. Well, they probably think they're interesting.
*  And they've been a lot more successful than we look like we're going to be.
*  Maybe, maybe.
*  But you bring up this question of the necessity of carbon.
*  So I wondered about that too.
*  I mean, obviously carbon is crucial for life as we know it.
*  But are we just chauvinistic about that?
*  If the chemistry of carbon were completely different,
*  I'm open to the possibility that life could have formed in some very bizarre to us, but very different way.
*  Yeah, I don't know enough biochemistry.
*  I think there are one or two other atoms that might have the structure,
*  the ability to form the tetrahedral bonds and so on.
*  But it's these long, stable polymers that carbon can form that enables us to grow these incredibly complex little machines that constitute all the enzymes.
*  If we were very advanced, if we were Max Teigmark, we would wonder about, you know,
*  could life exist if space were one dimensional versus two dimensional versus three dimensional versus four dimensional?
*  And which is fine to do, which is fun.
*  But the answer always is that it can only happen when it's three dimensional.
*  And I just really worry that we're being blinded by our noses in front of our faces when it comes to that.
*  Like, we know how it works in this case.
*  We can't see how it would work in other cases.
*  But I'm a little bit more skeptical that it couldn't just because we don't know how it would.
*  Yeah. I mean, one thing we do know is we don't see any signs of it when we look into the cosmos.
*  So if there is other life, it's not got sufficiently advanced to be able to make signals that we can detect.
*  That's right. We wouldn't know.
*  The current, correct me if I'm wrong, but the current state of the art is we wouldn't know if all the exoplanets we've ever seen are covered in cyanobacteria, right?
*  I'm not sure. Why would we not know that?
*  Just the current state of the art doesn't give us a lot of information.
*  So we don't have enough spectroscopic information?
*  I think that's it. Yeah. I think that the planets are faint compared to their stars.
*  But before we get too crazy in our speculations, I do want to bring things a little bit down to Earth again,
*  because it's easy for me to say that complexity comes and then goes.
*  And I think you very correctly want to emphasize the non-smoothness of that evolution over time in the real world.
*  Can you say a little bit more about the origin of these catastrophes?
*  I mean, I know there's specific catastrophes that we know about.
*  Are there general features of catastrophes that decrease the complexity of a system, at least biologically, if not more generally?
*  Well, I think the catastrophes that have occurred for life on Earth, in fact, there have been quite a few.
*  Paleobiologists have identified five major extinctions, but actually, I mean, extinctions are happening all the time.
*  And sometimes extinction rate increases and decreases.
*  But there have been a few really big ones.
*  Some of these have been contributed by changes in the Earth itself, so massive volcanic activity and so on.
*  But the ones that interest me are the ones that were due to life,
*  something that happened in evolution that suddenly changed the distribution of life.
*  So I think probably the first really notable one was the Great Oxygenation Event that really completely changed the chemistry of Earth.
*  And then there was the Cambrian Substrate Revolution that I mentioned when life forms discovered how to move and then how to burrow through the substrate.
*  And so another big one that was quite surprising to me is that when life came out of the oceans and onto land and trees formed,
*  suddenly there was a massive increase in photosynthesis and pulling of carbon dioxide out of the air.
*  And that plummeted the temperature of the Earth and created an ice age.
*  And then, of course, there's the one that we're doing now.
*  We're completely changing the chemistry of the planet and we're seeing massive extinction.
*  And again, that's because we've managed to proliferate enough to have global effects on the planet's chemistry.
*  So I find those quite interesting, worrying but interesting.
*  Because life exploring the parameter space and then every now and then it finds itself in a dead end.
*  Yeah, I think that the lesson of all your examples is that these catastrophes were all driven by progress, right?
*  Like life discovered a new way to do something exciting and fun and did it a little bit too enthusiastically, right?
*  And then led to the extinction of a whole bunch of other life forms.
*  Yeah, yeah. So, you know, you can, when you develop a new ability to extend your reach in space and time,
*  some that'll lead you on all sorts of paths and some of those paths will lead you to bigger and greater things,
*  but other paths will lead you to catastrophe.
*  You know, evolution is full of dead ends and we can't tell in advance which are going to be the dead ends and which are not.
*  But we're particularly interesting because we, as far as we know, are the first species that have been able to know this
*  and to contemplate our future and the possible regions of the space that we can explore and to make choices theoretically.
*  But the question is, does the dynamics of our interactions among ourselves allow those choices to be made?
*  Or are we condemned to, you know, just follow this path that's going to lead us off a cliff?
*  And I don't know the answer.
*  Yeah, I mean, I think one way of thinking about the evolution of life is not only an evolution of complexity in terms of the structures
*  that make the physical organism, but an evolution of the sophistication with which we deal with information, right?
*  The first RNA or DNA molecules actually carried some information and that was crucial, obviously.
*  And then there was this sort of differentiation of information when you got to eukaryotic life
*  and there's mitochondrial DNA and nuclear DNA and so forth.
*  And then multicellular life, there's more differentiation.
*  And then when the brain came along in the nervous system, you could think and you could have self-awareness.
*  And now that we have language, you can think symbolically.
*  And these are all, you know, information processing leaps forward.
*  So I think this is another wonderful frontier in science is to think about insights from information theory
*  and how they relate to physical evolution, both of the universe and of the biology within it.
*  Yeah, yeah.
*  One of the things that fascinates me about that is the equivalence that's been made between entropy and information.
*  In some sense, these information processing engines, if you like, brains,
*  are performing their own kind of entropic manipulations by virtue of how they operate in different domains,
*  at the chemical level, but also at this kind of more abstract level, which I think is fascinating.
*  Yeah, no, I think it's absolutely, like I said, it's going to be full employment for future scientists
*  because in some sense, the way I like to think of it is, well, let me back up a little bit because people get confused
*  when you talk about entropy and information because information theorists define the relationship
*  between entropy and information in exactly the opposite way to how physicists define it.
*  Because information theory grew out of Claude Shannon talking about, you know, how to send signals over wires.
*  And you send information more efficiently through a code that is high entropy,
*  because high entropy means you don't know what letters coming next.
*  Every time you get a letter, you get some new information.
*  It's very useful, right?
*  So information theorists or communication theorists like to link high entropy with high information content.
*  Whereas a physicist who thinks about the cup of coffee, not a message over the wires,
*  says if I'm in a low entropy state, if you tell me you're in a low entropy state,
*  then I know a lot about what state you're in because there's only a few of those states that look like that.
*  So I have more information about the system when it's in a low entropy configuration.
*  And I think that for this discussion that we're having right now, it's that definition of entropy that is more germane.
*  I think that in some sense, because the universe started in a very low entropy state,
*  it started with a lot of information in some sense built in.
*  And all we've been doing, we haven't been increasing the information content of the universe by having life or thoughts or books.
*  We've been degrading it because entropy is increasing,
*  but we've been using manipulating, taking advantage of the fact that entropy, that information is all around us in more and more interesting ways.
*  So breaking the universe up into these subsystems that manipulate information is a wonderfully proofful way, I think, of thinking about life and species and evolution.
*  Right. So interesting is another way of saying complex, I guess.
*  So you could say that the universe started off with a lot of information, but not much interest.
*  And now it has less informative, but more interesting.
*  And I think this is something that you get at with your questions about space and interactions and things like that,
*  because the universe as a whole increases in entropy and decreases in information, but it gets shuffled around in interesting ways.
*  And certain parts of the universe, like you and me, can hopefully take advantage of the overall degradation of information around us to make life interesting as we go.
*  I feel like we're living at an optimum time in the evolution of complexity in the universe, where it is maximally interesting.
*  Well, you know, they might have said that 10,000 years ago, too, because they didn't know.
*  The question is, are we at the top of the hill, or can we still climb it a bit higher?
*  Well, I think that, you know, what you would you have correctly pointed out is that there's no inevitability in this increase in complexity.
*  Like, sure, maybe there's a trend, maybe there's a tendency, but there's also this very definite empirical record of catastrophes.
*  Right. And so when you see us dumping carbon into the atmosphere and the sea levels rising and stuff like that, don't be sanguine that, oh, yeah, life is resilient and everything will be OK.
*  We could hurt it really badly. Yeah, that's a very good take home message.
*  Are you are you optimistic overall about how we're going to do?
*  Not optimistic, but hopeful.
*  Is that possible? I like to think there is there are things we could do.
*  But if you gave if you asked me to put a probability on it, I'd probably have to say it was lowish.
*  Lowish. Yeah. Well, I hope not.
*  But, you know, all we can do is is estimating the probability is less important than trying to increase the probability.
*  I think that's the thing to do.
*  I think if any species can can do it, then it's us.
*  There you go. Let's put it that way. I like that.
*  You know, the cats are not going to save us.
*  Believe me, I have two cats and they are not going to stop global climate change in any way.
*  Kate Jeffrey, thanks so much for being on the podcast.
*  It was a tremendously fun conversation. Thank you very much.
*  You
