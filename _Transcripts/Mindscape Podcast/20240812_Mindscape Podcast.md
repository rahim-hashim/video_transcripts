---
Date Generated: September 05, 2024
Transcription Model: whisper medium 20231117
Length: 4275s
Video Keywords: []
Video Views: 10293
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2024/08/12/285-nate-silver-on-prediction-risk-and-rationality/

Being rational necessarily involves engagement with probability. Given two possible courses of action, it can be rational to prefer the one that could possibly result in a worse outcome, if there's also a substantial probability for an even better outcome. But one's attitude toward risk -- averse, tolerant, or even seeking -- also matters. Do we work to avoid the worse possible outcome, even if there is potential for enormous reward? Nate Silver has long thought about probability and prediction, from sports to politics to professional poker. In his his new book On The Edge: The Art of Risking Everything, Silver examines a set of traits characterizing people who welcome risks.

Nate Silver received a B.A. in economics from the University of Chicago. He worked as a baseball analyst, developing the PECOTA statistical system (Player Empirical Comparison and Optimization Test Algorithm). He later founded the FiveThirtyEight political polling analysis site. His first book, The Signal and the Noise, was awarded the Phi Beta Kappa Society Book Award in Science. He is the co-host (with Maria Konnikova) of the Risky Business podcast.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll

#podcast #ideas #science #philosophy #culture
---

# Mindscape 285  Nate Silver on Prediction, Risk, and Rationality
**Mindscape Podcast:** [August 12, 2024](https://www.youtube.com/watch?v=1QFiKpElVWo)
*  Hello everyone and welcome to the Mindscape Podcast. I'm your host, Sean
*  Carroll. Human beings have a tough time being rational sometimes. We all know
*  that, right? There are various sorts of cognitive biases from wishful thinking
*  to confirmation bias. There's a whole long list. You can look it up on the
*  internet. But we human beings, we evolved over biological time to survive under
*  certain conditions. Sometimes sitting down and thinking things through
*  perfectly rationally is not the best survival strategy. You have to have some
*  heuristics. You have to see something and react to it very, very quickly. But I
*  think most of us would agree that all else being equal, it is better to be
*  rational than to be irrational. And therefore it's good to try to learn ways
*  to overcome those cognitive biases to be a more rational human being. That, however,
*  begs the question, what does it mean to be rational? Who says whether an action
*  is rational or not? People thought about this. Decision theorists, philosophers,
*  economists care about this a lot, psychologists. You know, roughly speaking,
*  if there are two outcomes that could come to pass because of an action that
*  you take and you want one outcome more than the other one, it is rational to do
*  the thing that brings about the outcome that you want. Okay, that's the easy part.
*  And then they make it more complicated. What if there are three different
*  outcomes and you have different preferences? So there's a feeling of,
*  there's a theory of what it means to be rational. The theory becomes complicated
*  when an action that you take does not directly lead to a consequence,
*  but maybe only has a probability of having different consequences. Now there's
*  a simple thing you can do, which is just to say, okay, attach a number,
*  the utility, to every possible outcome and then multiply the utility by the
*  probability that that utility, that outcome will actually come to pass.
*  Add those up and that's the effect of your action. This is called the expected
*  value of your action, which is a weird, which is a bad name because the expected
*  value is not the value you expect. The expected value is the value you expect
*  on average. And in a very, very clear context, like playing poker,
*  for example, where you know exactly what the value is of different outcomes,
*  you can very easily calculate, or at least you can attempt to calculate,
*  expected values and you can talk about certain moves, certain plays being plus
*  EV, positive effective value. But in addition to that expected value,
*  which is just sort of the average, there's the issue of risk.
*  We talked about this before with philosopher Lara Buchock, the idea that,
*  okay, it's not just enough to say that on average the outcome is going to be good
*  because if the worst possible outcome from this action is really super bad,
*  then maybe I don't want to risk that even if the best possible outcome is super
*  good. Other people will go the other way around. They like the idea of risk.
*  They would very happily take a risk for the promise of a really good best outcome.
*  So today's guest is Nate Silver, someone who is well known to many listeners,
*  I'm sure. He became quite prominent in the realm of political forecasting,
*  presidential elections and so forth. Was very successful at that,
*  founded the FiveThirtyEight website, has since left there, but he doesn't want
*  to primarily be known as the political forecasting guy. It's not the politics
*  that interests him, it's the forecasting and the idea of probabilities and living
*  in a world of uncertainty where we have to make decisions based on different
*  possible outcomes coming true. So his new book is called On the Edge,
*  The Art of Risking Everything, and it's about the difference in personality types
*  between people who kind of like taking those risks and the pluses and minuses
*  of that and people who don't like taking those risks. Now the sort of psychology
*  here of grouping people together based on not only their risk taking but also
*  on their analytical prowess, their conventionality and things like that,
*  their openness to new experience, this is something I am not in a position
*  to really judge, but it's absolutely worth thinking about. I do think that
*  on the list of things that we as a society don't think enough about,
*  uncertainty and risk and probability and how to deal with those things is
*  absolutely high up there on the list. What do you do if there's some action you can take that has
*  a very very tiny chance of being bad, but bad means the extinction of all life on earth?
*  This is a very relevant question right now, so we should be thinking of it. I think this kind
*  of conversation helps push us to think about those things more carefully, so let's go.
*  Nate Silver, welcome to the Mindscape Podcast. Thank you so much, Sean. I guess there's a,
*  let's start with the biggest view here. Why is it so hard for human beings to think probabilistically
*  about the world? It seems like it would be a natural skill. I think in some context that it is
*  natural. I think if you see storm clouds in the horizon, then you might bring an umbrella out
*  if you rain, if it's gonna rain, or if you're driving home from work, you might have some sense
*  of there's a drawbridge on a certain route, so you want to gamble on that not happening or whatever
*  else. I think people are not, look, we have millions of years of evolution where we're not living in an
*  environment of abundance, right? We're just barely trying to eke out a living. If you get some type
*  of disease or infection, it might kill you. A predator might come and raid your household or
*  your tent or whatever, so we're not used to having the amount of choices that we have and the amount
*  of complexity in the world that we have. We tend, I think, naturally to be risk averse, fight or flight
*  when we face stress. Yeah, partly it's coping with the complex modern world where things are uncertain
*  and maybe not getting enough practice. One good thing about poker, which of course I love and write
*  about in the book, you do get to play out the long run, right? If you play thousands of poker
*  hands, then a third of the time your opponent makes her flesh, you actually experience that.
*  It becomes more visceral, I suppose. Right. Of course, in the real world, we very often, as you say in the
*  book, have to kind of think like this, but in cases where we don't get the long run, like presidential
*  election forecasting, you don't really get to do it a number of times. Yeah, which is kind of why it's
*  ironic. This is a thing that happens every four years. In my adult lifetime, whenever maybe you have
*  15 or 16 of these things, right? Yeah, you'd need hundreds to know. You just have to be zen about the
*  fact that I became really well known for this thing where you'll never actually know if I'm any
*  good at it or not. Well, I do want to talk about the famous slash infamous example of the 2016
*  election when Donald Trump won over Hillary Clinton. The standard prediction day before the
*  election was that Hillary would probably win. You said Hillary would probably win, but you were less
*  confident than many people. And then when she didn't win, people gave you a hard time. And that
*  was legitimately unfair. I think so, in part because the way, look, before I ever forecasted an
*  election or really got into politics at all, I come from a background involving poker. And so I
*  dealt in the world where you're dealing with a lot of gambler types of people that I call, the
*  environment I call in the book, call it the river. We can talk about that in a minute. We will. But
*  to a poker player, the conventional wisdom, the betting markets were that Trump had a 15% chance
*  to win one five. And our model had him at 30% or 29 to be more precise. So a poker player looks at
*  that or a sports better and says, I'm going to go bet on Trump, right? I'm getting six to one odds,
*  and I'm going to win a third of the time or something. So what we call the expected value
*  of the bet, meaning if you were to play out things repeatedly, then that bet on Trump would make
*  money. So the poker buddies of mine were like, oh, great, I made money betting on Trump. And like
*  everyone else in my life was like, you're an idiot, Nate. But yeah, and look, elections are
*  different in part because of the high stakes, I think in part because campaigns always say,
*  this is the most important election of the rest of your life or the most important election of all
*  time. And there are different types of uncertainty too, right? It's like not like the elections like
*  literally determined by the roll of a dice, like a game of craps or something would be. But I mean,
*  it's worth considering some of the crazy contingencies that we've had in recent
*  political events. I mean, the one that comes to mind just recently is that because Donald Trump
*  turned to look at a display at a data visualization of immigration statistics, he turned his head just
*  enough where a bullet nicked his ear instead of did something far more serious. Or in 2000,
*  when Al Gore lost Florida by 537 votes in the state of 10 plus million people,
*  based in part on a flawed ballot design in one county in South Florida, sometimes decisions of
*  history can be actually kind of random and contingent. Well, I guess that's what when I
*  say that people are not very good at thinking probabilistically, one of the biggest thing I
*  have in mind is this idea that mentally, we tend to move all probabilities toward either zero or
*  one. And when you say there's a 29% chance that Donald Trump will win, people read that as he's
*  not going to win. Yeah, people move to zero, one or 50 50. You can allow them 50 50. Right?
*  Anything in the 75 25 or 70 30 zone is kind of kind of a thankless place to be right? You'll get
*  yelled at if you're wrong, but you'll still be wrong a lot because 30% chances happen all the
*  time, of course. Well, and poker players know that 1% chances happen all the time, because then there
*  are really many, many events. And so does the poker playing experience sort of inure you to that a
*  little bit? I think so or kind of risk taking experience in general where there are times in
*  poker, there's no risk free way to play poker. If you can get the money in as a 60 40 favorite,
*  you're thrilled, you know, the best you can usually do is, you know, 80 20 or so. I talk in
*  the book to a guy named Victor Vescova, who's like literally an explorer, he's climbed mountains and
*  things like that. And he climbed at one point attempted to climb Aconcagua, which is the tallest
*  mountain in South America in Argentina, okay, and kind of slipped, lost his footing, triggered a
*  mini little avalanche was knocked unconscious, nearly died. Fortunately, some like French climbers
*  saw him from uphill and rescued him and took him back to base camp. And when I talked to him, he
*  was like, yeah, you know, there's always a 2% chance something like that happens, you're not
*  going to totally eliminate risk climbing Aconcagua. So that mentality is really ingrained in people
*  who are who face virtual danger in the form of financial risks or or real actual physical danger.
*  I do have one unfair question. I'll try to be fair for the rest of the podcast. But I'm on your side
*  for the 2016 election. Are there any examples that come to mind where you blew it where like in
*  retrospect, you should have had a much better prediction than you did? Sure, I think you're
*  always looking at your mental process and your mathematical process. I think in the 2016
*  primary, we didn't have a model, but I was very confident that Trump wouldn't be nominated. I
*  thought, oh, this is just an you know, a sugar high in the polls because of name recognition and
*  media coverage. You know, thought the Republican Party at the end of the day, you know, was the
*  conservative party and nominated Mitt Romney types and people like that. So was was very wrong about
*  that. And that was a result of not being very rigorous. So yeah, sometimes you are it's not
*  always an excuse. Sometimes you are just plain wrong. I have exactly the same choice for my
*  worst example, or worse prediction. I had a really good track record without anything like the models
*  that you build. But I was very good at predicting political outcomes until 2016. And since then,
*  I've sworn off because it's too hard. But yeah, and look, people can people can overly pattern
*  match right in 2012. This is getting a little into the weeds in terms of Republican primary
*  history. But you had like, Newt Gingrich and Rick Santorum and Herman Cain, like all these different
*  flavors of the day that peaked and then fell. But you know, people politics changes and the
*  electorate changes. And so and so that's why it's not easy. Right. And you already use the word,
*  but let's dig into it, because your new book is mostly not about thinking probabilistically so
*  much as risk aversion versus risk tolerance, how comfortable people are with risk. So what, how is
*  that different than simply being good at judging the probabilities? I mean, in some sense, and
*  judging the probabilities is a good first step. Although there are also people in the book who
*  are bad judges of probabilities, but are still very risk taking. But it's really about people
*  that have two skills, right? I mean, the first is the probabilistic mathematical thinking.
*  But the second is whether it's a skill or maybe more of a personality type. They're very
*  competitive. They want to compete against themselves or they want to compete against other people.
*  As a result, they take chances to get ahead and many of them fail. I mean, there's a little bit
*  of bias in the book in the sense that like, you hear from the survivors and the survivors, right,
*  history, you don't hear although there are some counter examples in the book of the people who,
*  you know, start try to start up and had a big investment and failed and we never heard from
*  again. But yeah, it's unusual to have those because you think about people who are good at
*  calculation, you might think, oh, it's like an actuary or an accountant, someone who's kind of
*  risk averse, maybe a verge of being neurotic. But this is books about the rare type people
*  that have the overlap of highly competitive risk taking personality type with the analytical skills.
*  Okay, good. So I mean, let's figure out you mentioned, is it a personality type? Or is it
*  something about how we do rationality? I guess, let me ask as a question, what do you think of
*  it as? Do you think of it more as high risk taking high risk tolerance is more a personality
*  issue? Or is it a different way of being rational? I think it's correlated with other things and some
*  definitions of rationality. But no, I think there's something there's something intrinsic
*  that is formed early in our life course is my is my impression. If you talk to Victor Vescova,
*  who I talked to about before the mountain climber, you know, he of course is in the small fraternity,
*  of other mountain climbers. And he's like, yeah, we all have something innate or genetic,
*  we just like to kind of live on the edge. If you look at people who in the financial sector
*  in like venture capital, or founders, you know, Elon Musk had kind of a difficult childhood,
*  Jeff Bezos was adopted, right? It's people who have some degree of this weird middle ground where
*  they have enough trauma to really have a chip on their shoulder, but enough I don't know what
*  you want to call it maybe privileged to be given multiple opportunities to succeed and somehow
*  in that, the way it's calibrated just leads to really extreme outcomes.
*  Well, I know that you do quote, Laura Buchock in the book, and she was a philosopher who we had on
*  the podcast, and she did actually claim that it, it should, it should, we should change our definition
*  of rationality to allow for different tolerances of risk. I mean, the sort of most straightforward
*  definition of rationality is assign utility to every possible outcome, calculate the utilities
*  for what you're going to do and maximize your utility, right? But that that makes no statement
*  about risk or variance or anything like that. I mean, if you look in terms of expected values,
*  so if I get to play out a poker hand, 100 times or 1000 times, right, or if I get to invest in
*  500 companies over the course of my career as a VC, then I think you can critique people who are
*  not thinking probabilistically, but for like one off decisions, right? Should I get divorced?
*  Should I radically abandon my career path? Should I have some procedure, some medical procedure that
*  that would, you know, is un undoable, like those types of things, I think we should be much more
*  tolerant of people's, of people's varying types of rationality for sure, as I think
*  Larry would agree with. Yeah. Okay, very good. And I guess before I want to get into poker,
*  because I also love poker, I've had too many poker players on the podcast, compared to the audience.
*  But, you know, to just to tickle the philosophers out there, do you care about questions of what
*  probability is, you know, sort of Bayesian versus frequentist epistemic versus something else? I
*  mean, does that matter to your life at all? I joke in the book, it's kind of above my pay grade.
*  I'm interested in the philosophy of it. And the philosophy of is, is the universe truly random
*  on some irreducible level? I think, you know, some interpretations of like quantum mechanics would
*  say that it probably is intrinsically random to some degree. But no, look, I'm what I'm concerned
*  with in practice is estimation and decision making under practical uncertainty. It may be that if you
*  had perfect information that it wasn't actually uncertain. You know, in some sense, even in poker,
*  in physical poker, my opponent has two cards that have been dealt to her already, those cards are
*  not going to magically change. So in some sense, and the order the deck is not going to magically
*  change. So in some sense, even poker, once the cards are shuffled, is deterministic, but you
*  don't have information unless you can have extra vision to see her cards. And so it's, it's dealing
*  with incomplete information and uncertainty. Right. Okay, good. So it's very compatible with
*  the sort of Bayesian epistemic view of what we mean by chances and probabilities. For sure. And
*  people that have that more humble kind of Bayesian approach, I think, tend to be better tend to be
*  better risk takers in some pursuits. Sometimes you actually want people who are like, maybe on the
*  verge of being irrational. If you have your venture capitalist, and you want a founder who says, well,
*  I have this crazy idea, and there's a 95% chance it won't work. But if it does work, you'll make
*  1000 times your money back, right? That's a good positive expected value bet for the VC. It might
*  not be good for the founder in the sense that like, you know, 90% of the time, then they've wasted 10
*  years on something. And so and so you want people sometimes who are a little bit, a little bit crazy
*  if you're in Silicon Valley. Yeah. So let's talk about poker, because it's a great laboratory,
*  right? I mean, it, it removes all of the extra weird things, you know, when, when you make when
*  you talk to a founder that gives you those odds, where did those odds come from? They made them
*  up, I can be skeptical. But on the poker table, unless someone is cheating, I know that every
*  unknown card has a one over 52 chance of being a certain card. So is that why you like it?
*  I like it because yeah, maybe it maybe it avoids some of the messy real world complications that
*  you get, although not zero. I mean, a lot of what you're trying to do in poker is, is read people
*  and read their mindset, you know, a hand in in a pretty high stakes game the other day where
*  I tried to bluff an opponent, a friend actually of mine, because he had been having a rough night,
*  poker wise and calling a lot and losing a lot. And I'm like, he's not going to call me again.
*  You were taking advantage of the weakness of your friend. Yeah. Well, but he figured it out,
*  right? He was thinking one step ahead and wound up calling instead. So I cost myself a big, big pot.
*  But but yeah, look, I mean, it's calibrating your internal probability meter, where poker players
*  can be kind of uncanny about, oh, I have a, I need 30% chance to win. And I have 25% equity. So I
*  fold right, they can really get to within a couple of percentage points just through
*  having so much practice that it becomes this kind of sixth sense eventually.
*  Does it happen at the you know, I play poker, but at that sort of hack level at the very elevated
*  levels, when you're playing against great people, does it become less important to read them because
*  they're all kind of too good at faking it? There's some truth in that, I think, when all the super
*  pros are playing as one another, some what some of them actually literally do is they actually
*  literally randomize their action, right? Right. They won't actually bring a die, but they're
*  like, they can look at like the clock. And if the last digit of a clock is a seven or a nine,
*  they might bluff or something like that. So yeah, in, in some ways, I mean, poker has gotten closer
*  to being a solved game, it's a complicated definition. But yeah, in some ways, it's taken
*  a little bit of the variety out of the sport of the game, in terms of different styles of play.
*  And, and, but that's, you know, it's very rare to have two super broadcast players playing each
*  other. And then even when you have world class players, when you introduce an extra element
*  of stress, right, so day one of the main event of the World Series of poker, everyone's on their
*  best behavior, everyone's fresh, right, bright eyed bushy tailed, by day six or seven, even for
*  a high stakes pro. The stakes are just objectively really high. And we talked about this in the book,
*  you know, physically, your body starts to behave differently when you're in conditions of
*  extreme stress. And so they may not be as rational as they might like to think.
*  Well, tell us about that. I mean, that's, that's fascinating. How much do we know about
*  the physiological changes are actually like when you're trying to make these high stake moves?
*  So I talked to a couple people about this in the book. One of them is a guy named John Coates,
*  who was an economist who became a derivatives trader, I think for Deutsche Bank or Goldman
*  Sachs or something like that. And having an academic background, he's like, boy, these
*  fucking traders are really strange. The way they process stress are really, is really strange. And
*  he kind of decided to change careers, and devote his life to doing neurological studies of like,
*  Wall Street traders, basically. I found out a lot of things. One thing he found is actually
*  the traders who were more successful actually had more of a physical stress response.
*  It may not have been on a conscious level, they were kind of outwardly calm, but, but they,
*  they, you know, their body recognize that sometimes we face much more important circumstances than
*  others. And then actually can give us information, right? I mean, if you've ever been in a
*  situation, I haven't told the story before, I was in a situation when I was in January in
*  Los Angeles, we're in LA to see some friends, my partner and I, it might have been the day
*  after New Year's. And I like, and I go to get coffee, like the coffee bean and roastery or
*  whatever it was. And my back is to the window. And this woman and the other register line
*  starts yelling at people and looking like a ghost has hit her and saying, get down, get down. And
*  it turns out that outside there was an armed robbery, a guy was getting carjacked. And, you
*  know, this is open windows. And so the gun was kind of pointed right at the store, basically. And,
*  you know, eventually they took his watch and his wallet and went away. This is right on Pico
*  Boulevard, middle of Beverly Hills, kind of a crazy experience. But what you experience there
*  is that time slows down a little bit. And you actually kind of have this moment where you kind
*  of think with a lot of clarity. And then later I was like getting, you know, tacos or something
*  later and like, you know, texted my partner, haha, almost got shot. And then an hour later,
*  I'm like, what the fuck, right? And then it kind of hit me the stress that I had put out of my body.
*  And you experienced that like in poker too, if you're playing a really high stakes game,
*  doesn't happen every day, obviously, but a few times a year you run deep in a tournament or
*  playing for higher stakes and you maybe should be playing. And you think clearly in the moment,
*  and then you get home and boy, man, it hits you like a ton of bricks, just the stress of it.
*  And you process it in weird ways and you might have dreams about it positive or negative days
*  later. So we have a different operating system to be slightly nontechnical about it when we are
*  under conditions of extreme risk taking. I think for myself, what I keep finding myself doing,
*  catching myself doing is holding my breath. But I'm holding my breath whether I'm in a good
*  position or not, as long as it's a big pot. So I don't think I'm giving much away, just that
*  there's a lot of money in the pot. Yeah, look, I mean, there are a couple of things. I mean,
*  I think the notion of like, I have to remind myself a lot to like, slow down, I tend to make
*  decisions pretty quickly, even relative to other poker players. So slowing down and breathing and
*  taking the situation in, I think is pretty important. I mean, as you mentioned, you know,
*  it's hard to hide a stress response in poker. And sometimes you have to live with that, although
*  there are things you can do, you can like cover up your neck where we tend to show stress a lot,
*  for instance. However, some people actually feel more stress when they have a good hand than
*  than when they're bluffing, right? Then they get excited, like, I'm going to either win a little
*  bit money or a lot of money. This is really fun, right? When they're bluffing, they're like, I have
*  to get this bluff through to survive in the tournament. And they actually can be more focused,
*  I'm probably more more like that. But that's the reverse of how other players play. And so therefore,
*  therefore correlating people's stress response with their with their behavior. And look, sometimes
*  you've got a text saying that your plans got wrecked that night. And therefore you're in a bad mood
*  for reasons that have nothing to do with the poker hand. So it's not quite as easy as you think to
*  read people. But but for sure. Are there I think the answer is yes. But are there common personality
*  traits among very successful poker players? For sure. I mean, they tend to be, you know,
*  lone wolves kind of anti authority streak people. Because if you think about it, I mean,
*  the combination of mathematical skills and people reading skills that you have in, in poker could
*  translate well to a lot of things, right? You know, some hedge funds hire ex poker players,
*  right? And believe me, you know, you can make a lot of money doing something like that, or going
*  into investment banking, you're going into tech, or opening a business, right? These skills, I think,
*  are somewhat transferable. But the poker players, they don't want to boss, they don't want to have
*  to put up with other people's rules, right? It's kind of a weird hippie culture, almost in,
*  in a way you get up when you want, right? And, and you do what you feel like. And so that's why it
*  attracts people who are probably actually underachieving their financial net worth
*  potential. Yeah, but find the lifestyle, fulfilling and unique and enjoyable. But maybe something more
*  like a libertarian kind of hippie than a peace and love kind of hippie. Oh, for sure. You know,
*  the political leanings of poker players are, are an interesting cross section of kind of smart,
*  male, mostly public opinion, right? And that that contend toward being a little bit more
*  libertarian. Right. And so, are poker players more or less? Do they do they come close to
*  being optimal in terms of maximizing their expected value their EV? Like, how good are they at that?
*  Pretty damn good, right? I mean, they're getting to within like, a couple of percentage
*  points. Most of the time you can now study against computer simulators. And the computer will say,
*  buzz, you know, you made a huge error. And then you look at the fine print, it's like you were off by
*  0.01% or something. I mean, this is new, though, if you go back and watch poker games from like,
*  the 80s or the 90s, then the play was much less sophisticated. So it just, it's sort of enough.
*  It's a good thing or a bad thing. It's just a matter of like, everything in life is becoming
*  more ruthlessly efficient and poker with the computer tools that people have and the
*  financial incentives and just the fact that like, I mean, the game has remained really popular.
*  Live tournament poker is more popular than ever. We had another record breaking world series of
*  poker this year. So so yeah, it's it's it's careened toward maximal efficiency.
*  And is it I presume that the answer is yes here. But is there a correlation between being
*  comfortable taking risks and being a good poker player?
*  Yeah, no, you can't avoid having to take some risks when you play poker. And in fact, that can,
*  you know, there are the players who will make it to the money. That means you make it through the
*  first 85% of the field and then and then get very shy about taking any risks. And then finally,
*  they go all in. And of course, their opponents know they have aces or kings most of the time.
*  Yeah, you have to even even though tournament poker is more technical than you probably
*  care about. But yeah, in tournament poker, there is some reason not to take risk. There's some risk
*  aversion that's embedded in the structure of how the payouts occur. That's a little technical.
*  But even then, you know, you're not going to get to the money deep in the money poker without
*  taking and winning a few what we call coin flips, winning a few 50 50 spots.
*  Well, I think it's simple enough to understand the way that I understand it anyway, which is that
*  in a cash game where you're just playing for the pot in front of you or whatever,
*  maximizing your expected value gives you one answer. But in a tournament, the payoffs are
*  different. Like you can win a big pot that doesn't win you the tournament. So it makes perfect sense
*  that the strategy might actually be different, even if ultimately the goal is just to maximize
*  your expected value. Yeah. And then you also think about like, what are you doing with your
*  life value? Right? It's really valuable to you to like, win a tournament or get on TV and make a
*  final table or have something to brag about. Then maybe the life EV is worth more than the
*  tournament EV. Or maybe if you have a flight to catch, right? I've been in situations where I had
*  flight home from Vegas one night and we cost $300 change fee. And that can actually kind of,
*  I think it's probably bad to think about those things. Like I've stopped not booking a return
*  flight when I go to a poker tournament for that reason. Right. But yeah, I mean, there's, there's
*  life, life decisions too, to think about. But what struck me, and I'm still not sure that I've
*  wrapped my head around this, but a lot of super good poker players are degenerate gamblers in
*  cases where they know they will probably lose, right? Like they win a lot of money, the poker
*  player, and then they go play buck or raw or whatever, where unless they cheat, they can't win.
*  It's kind of 50 50, the poker players that gamble it up in the pits and the ones who don't,
*  I would think that in general, the better players are the ones who don't. But there are some real
*  degenerate gamblers among the poker playing scene too. Personally, I have lots of risk
*  taking tendencies and but like, I don't find, I mean, since I can play poker, and in principle,
*  we'll be making positive expected value wagers, right? Or maybe fool myself into being good
*  enough at sports betting, or at least I'm somewhere near break even and probably have fun doing it.
*  Yeah, I don't see any reason to like, voluntarily give like the MGM Corporation or the Caesars
*  Corporation my money, although I like the rewards points and stuff.
*  Well, good. So we didn't, I'm glad we don't need to like get into technical details of the rules of
*  Texas Hold'em or anything. But you do invoke a vocabulary word frequently in the book, which is
*  the river. And you're using the river, the last hand, the last part of the poker hand, as a
*  commonality of a certain personality type. So why don't you help us understand that?
*  Yeah, so the river is the last card that's dealt in poker. It's apparently called the river because
*  poker had origins in the Mississippi River boats of I guess, the mid to late 19th century. And if
*  a dealer dealt an unexpected card and was thought to be crooked, he'd be thrown in the river was
*  how the term the etymology of the term. But yeah, I think of the river as kind of this frontier,
*  where people who have this risk taking gene cross with the analytical capabilities tend to exist and
*  coexist. And I kind of thought when I started the book of this as like a metaphor, I mean,
*  kind of literally in the book, I like the first flight I took, you know, the first day I was like
*  fully vaccinated, or whatever gotten a flight to Fort Lauderdale and go to like a giant casino
*  in the middle of Florida in what's still technically a pandemic. And it was every bit the
*  shit show you'd expect a giant casino in Florida to be I was there for a poker tournament. I'm
*  like, oh, these are my people, right? These are the people that decided this was a good idea in
*  the middle of the pandemic and kind of, and explore the world out from there. And like, you know,
*  there are lots of people that cross over different domains. I mean, poker players who go and work for
*  hedge funds, or I played in some of the, you know, the venture capital of poker games, like the all
*  in podcasts, you know, people even in like the effective altruism world, that's a different
*  part of the river where people are trying to solve difficult problems using expected value and
*  probability theory. And their mindsets are I mean, they have the same shared kind of nerdy
*  vocabulary. So I think there is something to it. And they know one other it's a small community to
*  it surprised me. You know, once I got to know I'm not like best friends with people in Silicon
*  Valley, I live in New York, so New York's more of my speed, right? But like, you know, I was
*  surprised to know once he's talked to one or two of the of the top VCs or founders, and they're
*  happy to vouch for you to talk to other ones. And these are like, these are small communities.
*  It's a community of elites, I think you could say. But I'm, you know, I think they're trying
*  or starting to develop some like group identity as well. You see kind of the river being a more active
*  political force in some ways. I mean, Sam Beckman Fried, who we haven't talked about yet was a
*  major donor in both Democratic and Republican politics kind of actually surreptitiously in the
*  latter case. Obviously, people like Elon Musk and Peter Thiel have gotten very involved in political
*  ventures of various kinds or Mark Andreessen, people like that. So yeah, you have this
*  self interested group of elites. And they don't, by the way, I don't mean to say that
*  Silicon Valley are the only people in the river, right? Again, it starts out in poker and kind of
*  moves up from there into different parts of it. You know, Wall Street's there somewhere,
*  the kind of rationalists are there somewhere. But but there are there's more overlap than I
*  thought of people of literally the same personality type you see over and over again, a certain type of
*  a certain type of analytical nerd. Well, so this is interesting. And here, I'm not completely sure
*  that I'm convinced yet. But maybe you can convince me. You argue that there is a certain recognizable
*  personality type and being analytical is part of it being risk tolerant is part of it. But there's
*  also this aspect of decoupling, decoupling this and now now I think the it gets serious. So explain
*  to us what decoupling is. So decoupling means to separate a problem out in component into component
*  parts, or to decontextualize something. So the example I give in the book is, let's say that you
*  are in the market for a chicken sandwich, and you pass by a Chick-fil-A and Chick-fil-A's founder,
*  I think they've meloed in this somewhat since, but was like a notorious like, opponent of gay marriage.
*  And, you know, decoupling is the ability to say that like, I really dislike the Chick-fil-A
*  founders politics, but I really like their chicken sandwiches, right? Those are separate attributes,
*  or to say, you know, I like this Woody Allen film, even though he's extremely problematic in a lot
*  of ways, I think it's good art. And of course, art, maybe I'm getting a little bit over my head,
*  the art and the artists are hard to separate. But like that ability or a more relevant context for
*  my life, right? Is so I voted for I'm kind of a centrist, slightly libertarian myself kind of
*  befitting my my riverian roots, I guess, right? But I voted for Joe Biden in 2020. I thought there
*  were a fair number of things I thought he did a good job of in in the first two, three years in
*  office, right? I also thought that he was going to lose to Trump most likely, because of his age and
*  other factors. He had fallen quite far behind in the polls. And, you know, and since it's my beat,
*  I kind of talked a lot about that in my newsletter and things and media appearances. And, and people
*  got very mad at me. They're like, Why do you hate Joe Biden so much? I'm like, I like Joe Biden,
*  I vote for him, I might vote for him again, I wouldn't vote for Trump. But like my job is to
*  decouple, and to make a forecast that's disconnected from the outcome I'd like to see occur, I'm trying
*  to say what will happen, not what I want to see happen. And, and, and that skill is hard,
*  especially for people who are who are, I guess you'd say, like politically minded.
*  And I totally agree that the Chick-fil-A founder's ethos is terrible, and the sandwiches are very
*  good. So I guess I have evidence for decoupling there. But I guess, let me ask, is there,
*  and just just to clarify, I should clarify first, you're not saying that this person who makes these
*  claims would then conclude, therefore, I should buy the sandwich, because it's good, right?
*  No, that's right. Yeah, you could say I don't want to support this person's business. So even
*  though it's a tasty sandwich, then I'm not going to eat there. That's, that's totally fine, right?
*  You know, that's a moral judgment. But we're trying to, you know, we're trying to perceive
*  objective reality, and then we can make decisions based on, on the accuracy of our of our estimates.
*  And I guess what I don't understand is this description of decoupling sort of on the one hand,
*  leads to a more nuanced view of the world, because I can simultaneously think that I don't want to buy
*  the sandwich, but the sandwich tastes good, rather than just totalizing everything. But on the other
*  hand, there's an element of what in my area is called engineers disease or physicist disease,
*  where you model the world in overly simplistic ways, because you can, and therefore you sort of
*  are ignoring nuances and subtleties. Absolutely. It's very easy to build a bad oversimplified model
*  of the world, or to build a model that describes the past and isn't robust for the future.
*  There are a lot of bad models out there. And, and, and there are examples in the book, I mean,
*  Sam Beckman Fried is kind of the most prominent one of like, would quantify everything he was
*  utilitarian, but quantify things in crazy, very imprecise ways where he like way underestimated
*  the risk of like a, another Bitcoin crash, for example. Or, you know, I mean, he was also very
*  risk loving, he was willing to gamble at a high risk of ruin, and quite self admittedly. But he
*  was a pretty bad estimator, actually, he didn't play poker ever really, he told me. Maybe he
*  should have that kind of train some better risk taking skills, I think, potentially.
*  Actually, is there any evidence for that? I mean, I get the argument that poker is so
*  clean and unforgiving in some way that maybe it should train you. Do we know? Has anyone studied
*  that? Yeah, that's interesting. I mean, you know, when I actually talk to people, my buddies in
*  finance who, who are poker adjacent, right? I mean, they'll say that like, yeah, the analytical
*  skills are there. But as we were talking about before, the people skills may or may not,
*  may or may not be right poker players are, are selecting for the one field where you kind of can,
*  like many poker, I mean, some of my best friends are poker players. Sure. I don't mean that in a
*  sarcastic way. I mean, like half my friends at this point are like poker, poker adjacent.
*  But you know, you definitely get some difficult types who would have trouble thriving in an office
*  setting. Yeah, I would say. Okay, fair enough. Speaking of which, oh, that was a terrible,
*  terrible segue, but effective altruism. I want to, you know, you, you talk just to, we don't need
*  to have spoilers here. So, you know, you, you start the book with poker players, and you introduce the
*  idea of the riverians, but then you go on to talk about effective altruism, rationalism, Silicon
*  Valley, kind of entrepreneurs as these exemplars, which is interesting because they all sound a
*  little bit different, but you can kind of see the relationship. So talk to us about effective
*  altruists first. So effective altruism is what I call a brand name. It was created by two Oxford
*  philosophers, Will McCaskill and Toby Ord. And it's a pretty good brand name, right? Altruism
*  means obviously thinking being unselfish, more particularly used to be in the context of
*  philanthropy. So people give money away to the American Red Cross or something. And the effective
*  part is measuring how much bang do you get for your buck? How much good do you do based on the
*  amount that you spend, right? So one early intervention was they found that malaria is
*  still a very deadly disease in the tropics. And so like putting up bed nets at the cost of a couple
*  of thousand dollars each might save lots and lots of lives. You can save a life for 5,000 bucks if
*  you target anti-malaria mosquito nets, basically. What happened though is, I mean, this gets kind
*  of at the question that you were getting at a moment ago, Sean, about bad models. And a lot of
*  it is more kind of back of the envelope estimation than people might be wanting to admit to. And then
*  they get into higher grade problems, right? How effective is a charity is a reasonably
*  tractable problem, not as simple as poker, although poker itself is quite complex, right?
*  But that's something that, yeah, I felt like if you spent a year and had a team of smart people
*  doing that, you'd get somewhere and have tangible answers, right? These existential problems are a
*  lot harder to wrap your head around. I mean, the big one, the big area of concern is, is there
*  existential risk of things going very wrong from artificial intelligence, which a lot of EAs are
*  convinced that there could be potentially. But it's not settled science, right? I mean, you can find
*  some EAs who think this is ridiculous and some who literally think there's a 99% chance that we're
*  all going to die within the next 40 years because of runaway AI. The consensus is probably 5% or 10%
*  chance of catastrophic or worse existential risk potentially. And I think it's helpful most of the
*  time to be willing to put numbers on things. I can say, oh, there's a chance of this or that.
*  And those are weasel words that avoid accountability a lot of the time, right? I can say,
*  oh, Kamala Harris has a chance. Well, does she have a 10% chance or a 50% chance? Because those
*  are very different things. But yeah, look, Sam McMinfried is an example who identified as an
*  effective altruist of someone who made a lot of bad calculations and effective altruists made a lot of
*  bad calculations about Sam for so much of their revenue and the reputation to be tied up in this
*  one founder who had his hands in all types of good and bad and crazy and not so crazy things was a
*  risk that they did not foresee. And it's, you know, to the point before about how like the river kind
*  of is an actual place or maybe a series. What the reason I call it a river, by the way, is because
*  it's like not like one discreet town, right? It's like a region where you go back and forth
*  between different communities. The EA community is a pretty small community. Like one thing that
*  you find is like, is that, you know, the word was out that I'm writing a book about risk and kind of
*  the EA's notice and invite you to their events and the kind of evangelize a little bit, which
*  is helpful. I mean, obviously, as an author, you always want, you never mind sources who are
*  interesting people who were who were excited to talk to you. That's always helpful. But like,
*  but they're trying to spread the gospel. There is like, I mean, I use that term intentionally,
*  right? I think there are some parallels to religion, which I don't mean to I don't mean to
*  put down necessarily, right? I mean, they're asking like big philosophical questions, right?
*  These are not like solved problems. And I think that's, that's okay. But there is a
*  proselytizing aspect to it. And I guess maybe I'm good at better at decoupling than I suspected,
*  but I can see the goods and the good and bad here. I mean, if I'm going to be altruistic,
*  I would like it to be effective. I would like to learn where you know, my money has the biggest
*  impact. And if, but on the other hand, I have this feeling that I also like maybe donating to
*  my alma mater or the local cat shelter, these are clearly not the highest impact for my dollar.
*  Yeah, so so I want to hear the argument, but I'm not entirely persuaded by it.
*  Yeah, look, I would not identify as effective altruist myself, I might kind of be in some part
*  of some broader rationalist community. I think what they found is that the differences are,
*  are pretty large, right, particularly for things like, like university endowments, where you're,
*  you're giving to very rich institutions that are like, running hedge funds on top of their
*  universities and giving this hedge fund more money, right? Well, I mean, you know, why not
*  just donate more money to Goldman Sachs, or something like that, right? I think the more
*  ambiguous cases are things like giving to the local symphony orchestra, where what does the
*  symphony save lives? Well, I don't know, I don't know the amount of utility that having beautiful
*  music in the world or challenging, but well articulated music creates for the world and how
*  that inspires people. I mean, there might be a lot of good there, people have to like,
*  distinguish the things you can quantify in our low impact from the things where the impact is,
*  is hard to quantify. And I think some EA's and more broadly, people in the river, tend to tend to,
*  tend to neglect that.
*  Well, you use the word utility, and we've used it before in the conversation. And maybe we should
*  fess up to the fact that the EA philosophy goes very much hand in hand with being a utilitarian
*  about morals and ethics, and not everyone is utilitarian. So that's another way to
*  express some skepticism, I suppose.
*  Yeah, and I have both, like in the middle of this book about gambling, it's like a 3000 word
*  philosophical discussion where I like talk to all these like Princeton and Stanford philosophers
*  and stuff like that. So that's the kind of book it is, if that's the kind of book that you like.
*  So I have both practical and philosophical concerns with utilitarianism.
*  For one thing, I don't necessarily buy that we should be totally selfless and not have some
*  favoritism toward people that we love. Basically, I'm not sure that's a bad thing, ethically or
*  otherwise. But also, yeah, you do get people who are overconfident in their ability to calculate
*  these different equities. And I think one line I use in the book, or maybe I'm stealing it from like
*  Eliezer Yudkowski, who's a rationalist, someone who's concerned about AI risk, but a smart guy
*  who's always fun to talk to. He's like, yeah, we need a world where everyone has 150 IQ, right?
*  And unfortunately, we're in this world of 100 IQs. And so we're probably going to destroy ourselves,
*  right? Because we can create this technology like nuclear weapons, or large language models,
*  but we aren't smart enough to know how to control them. So I think sometimes that,
*  you know, I think there is a lot to be said for having a practical sense and kind of, you know,
*  wanting a pathway in between, quote unquote, common sense, and some EA adjacent form of
*  utilitarianism. The halfway in between, I think is probably a lot better than either extreme.
*  Well, I do wonder, who is it that is making these terrible tools are going to destroy the world? Is
*  it the 100 IQ people or the 150 IQ people? Subjectively, I think that the AI people are
*  very smart. I mean, AI is like the most, if you're this type of riverian nerd, then AI is like the
*  most exciting thing happening right now. And there are different projections, and I'm actually a
*  little bit ambivalent myself about like, am I an optimist or a pessimist or a doomer or what? But,
*  you know, chat GPT and other large language models were this amazing kind of almost miraculous
*  breakthrough. Let's just kind of keep feeding lots and lots of text to a computer, and then have this
*  relatively simple transformer model, and then just leave it on for a really long time, and see what
*  happens. And now it's like a magic box that can talk to you. I mean, it's kind of crazy. And I'm
*  using non-technical terms, because those are the terms that you talk to engineers at OpenAI, and
*  they call it like a big bag of numbers. And they'll tell you that we kind of have a sense for
*  how it works, but we're not really sure why it's doing what it's doing. And that is inherently
*  a little bit frightening sometimes. But they are smart people. I mean, it's attracting, I think,
*  the best and brightest between being on the frontiers of this next revolution, if it occurs.
*  And again, I do not take for granted that it will, right? But, you know, if you think there's a
*  30% chance of a new industrial revolution, in the meantime, you know, Anthropic and OpenAI and
*  Google, I'm sure, are paying people very well, too. So it's interesting, high-impact work,
*  and it's attracting bright people, for sure. And you've also mentioned the rationalists a few
*  times. Philosophers are very annoyed that this term is caught on, because they already have a
*  meaning for the word rationalist, and it doesn't mean what you mean by it. Tell us what you mean by
*  it. So rationalism is a sort of EA-adjacent movement that's more informal. I mean, terms
*  like team people like Eliezer Yudkowsky use the term rationalism, but it kind of is more of a
*  cluster of attributes, right? It's like people who are using expected value to think through
*  problems more clearly and have less biased in their words answers, but not necessarily to like,
*  for the greater good, right? It might just be to like, learn how to make a better trade,
*  or something like that, right? Or it might just be to like, solve some interesting problem on a
*  prediction market. Prediction markets are a big, I should say, I consult for a prediction market
*  company called Polymarket. Prediction markets are a good rationalist tool, because it forces you to
*  like, put money behind your answer, it forces you to quantify things. So yeah, rationalism and the
*  river have a fair amount of overlap, especially the kind of lowercase R rationalism used more
*  broadly, whereas effective altruism is more a more specific term and also different. It's more
*  prim and proper. You know, all the EA's are at like Oxford and Stanford and Princeton and Harvard
*  and Cambridge and all these places, whereas the person I mentioned, Eliezer Yudkowsky, maybe the
*  most influential rationalist, never finished high school, very much self-trained, self-taught. And
*  so it's kind of stroughier, it's more politically incorrect to use a slightly dated term. And I'm
*  a little bit more sympathetic to it, I think. I can tell, yeah, which is fine, of course. But so
*  when I try to be a good Bayesian, the following thing occurs to me, like, the sales pitch for
*  effective altruism or for rationalism is very compelling. Yes, altruism should be effective.
*  Yes, I should be rational rather than irrational. And then there's a bunch of objections, or at least
*  people who object, who sound very unconvincing. They have vibes-based objections, right? Like,
*  it's kind of icky, it's kind of mechanistic or whatever. But then, if I look at the history,
*  those people are right some non-trivial fraction of the time. Like, oh, there is corruption,
*  there is people bait and switching saying we're going to send mosquito nets, but really we're
*  going to send it to our own salaries or whatever. So I got to update and worry that I need a more
*  sophisticated model of this community. Yeah, and the SPFs and McMinn-Fried stuff. I mean,
*  look, if the movement had 100 years of history and dozens of chapters around the world, then
*  you could say, okay, sometimes weird things happen. You don't have the fraud of the century
*  happen on your watch every day, right? But the fact that he was maybe the single most important
*  person fundraising-wise for EA, you have to update on that, I think, quite a bit, maybe for lack of
*  common. And yeah, some of the critiques are in bad faith. And by the way, where they call themselves
*  EAs or not, I mean, you have had people like Bill Gates, Elon Musk, maybe less so now, but in the
*  past, Warren Buffett, Mark Zuckerberg. I mean, they all give, Musk is something of an exception.
*  The other three give quite a lot to charity and have demonstrated at least some interest
*  in effective charity. Yes. I mean, Bill Gates in particular, right? So that reflects the EA
*  influence, even if it's not the EA brand name. And I know the people I mentioned are some of
*  the most controversial figures in the world, but I think their charitable philanthropic work
*  has been quite impactful and quite positive for the world. So that's something which,
*  you know, you kind of have to weigh things in different buckets and the SBF thing weighs heavily
*  in this bucket, but motivating billionaires to be smarter about their philanthropy. Plus, you know,
*  the broader EA slash rationalist community was ahead of the curve in terms of understanding the
*  impact of AI. Elias Joukowsky has been talking about this stuff for like, literally, a quarter
*  century. And it was not the consensus view. I mean, the consensus view until transformer models
*  was like, yeah, we're kind of in an AI winter or something. So the book, when you have a long book,
*  it is a long book. You won't read it in a single sitting, I don't think, but like there's time for
*  nuance and subtlety and reporting, talking to a lot of people and giving them time in their own
*  words to make their case. SBF famously said that every book that you write is a waste,
*  is a mistake. I disagree. I'm part because like, there's like, yeah, in part because like taking
*  the time to write a book. I mean, this sounds a little through the looking glass. It's a little
*  bit like a large language model when it has time to like bounce a bunch of parameters off of one
*  another, then sometimes you have these kind of magical reactions that catalyze and you,
*  and you discover new things. I mean, I mean, first of all, just having an I mean,
*  use on the podcast, but like, just having an excuse if nothing else, to spend three years talking
*  to 200 really amazing experts and practitioners that are having these candid conversations with
*  you, mostly on the record, sometimes off the record, like that alone is incredibly valuable.
*  Like that's like getting a PhD or something, right? The amount of instruction you get. So thank you
*  all those people for their time. But yeah, there are a lot of people reflected in the book and I
*  have a lot of good material to work with. Well, and it may be as part of a prophylactic against
*  this engineer's disease where you do come up with a model that you like because it's very quantitative,
*  but in fact, doesn't capture some important aspects of the world. Just empirically bumping
*  into different people with different attitudes and trying to think it through and put it in your own
*  words can can force you to think a little bit more carefully. Yeah, like there's kind of this
*  contradiction where on the one hand, people on the river tend to be very contrarian, very
*  individualistic. I mean, definitely very individualistic, right? They take pride in that.
*  On the other hand, in things like prediction markets and an appreciation for markets in general,
*  I mean, even the best sports bettors in the world will tell you the betting lines are really good.
*  You have to be really good to beat the consensus Las Vegas over underlines or whatever. So we have
*  this duality where we appreciate consensus on the one hand, but we want to be contrarians on the
*  other hand. And that's why this is difficult. That's why it takes actual that's why the
*  subtitle of the book is the art of risking everything. There is art involved in this and
*  there are at the core of it, a lot of complicated and ultimately quite flawed human beings.
*  Well, okay. And you've mentioned Sam Bankman Fried quite a lot. And I'm sure that most of the
*  listeners know the whole story. We don't need to go through the whole story, but I love the
*  your use of that example to illustrate the Kelly Criterion and talk about that in the book. So
*  tell us what the Kelly Criterion is and how maybe it was a little perverted by SPF.
*  Yeah. So what the Kelly Criterion tells you is how much of your bankroll and how you define bankroll
*  is a little fuzzy, but how much of the money you're willing to gamble with, you should bet on a
*  particular game, right? So let's say there's a college football game and you think you're
*  going to win the points for a bet on the Michigan Wolverines 60% of the time. The Kelly Criterion
*  tells you how much you should wager in the long run to maximize your expected return while
*  minimizing your risk of ruin. What Sam said is that the Kelly Criterion is too conservative,
*  even though most gamblers will tell you that like actually it has you betting way too much.
*  You're going to lose and go on tilt too often, right? He played out correctly, actually, that
*  the Kelly Criterion is telling you how to maximize your expected return while minimizing your risk
*  of ruin so that you won't go totally bankrupt basically. However, if you don't care about
*  going totally bankrupt, then you should basically just go all in over and over and over again. And
*  so he pointed that out, but the practical implication is that you basically have literally
*  a scenario, it's called the St. Petersburg paradox, where let's say you can like press a button
*  for double or nothing your money at a very small advantage, like a 51%. You win a coin flip 50%
*  of the time to double your money or go broke. The paradox is if you keep pushing that button,
*  the expected value of the bet is infinity, where you're making a positive EV bet and then
*  doubling it an infinity number of times, right? However, you're also infinitely likely,
*  or one over infinity, so zero, to survive all those coin flips and button pushes.
*  And he was quite literally, he told this to Carolyn Ellison in reveal court testimony,
*  he told it to Tyler Cowan, the economist in an interview, if you could double the amount
*  of good in the world plus 1%, right? So the world is 2.0001x better as 2.001x more utility.
*  But there's a 50% chance of like the world being destroyed and like some paperclip apocalypse,
*  because the computers have the wrong objectives and are misaligned. He would like, I think,
*  quite literally take that bet. I mean, Sam was almost proud at various points, and I talked to
*  him before, during and after the bankruptcy, almost proud of how willing he was to accept this very
*  high risk of ruin for the chance. I mean, he thought he could become like the world's first
*  trillionaire. He literally thought he could become president at one point, gave himself like a 5 or
*  10% chance. I forget exactly what. And that's kind of insane. I mean, it's somebody who,
*  whether it's for kind of chemical reasons, I don't mean to imply that there's stories about
*  adderall use. I don't think that was the, from my reporting, not that big a part of the story,
*  but like, but you know, something about the way his brain was wired, where common sense didn't
*  really enter into the equation. Even a low dose of common sense can go a long way, I think, to
*  at least abetting the most potentially self-destructive tendencies.
*  Well, this goes back very, very nicely to where we started, because if you did, I mean, you can see
*  where his argument comes from. If all you wanted to do is maximize your expected value, then yeah,
*  destroy the earth with 50 minus epsilon percent, double the utility with 50 plus epsilon percent.
*  But like you imply, almost any person would say that's actually not rational. And they would say,
*  because there's things in life other than maximizing your expected value, it is okay
*  to try to lower your risk of complete annihilation.
*  I think one thing with Sam, and it gets a little dark, but there's reporting on this in the book,
*  including reporting on the record from his ex Alameda co-founder Tara, or Tara, I'm sorry,
*  I forget, Macaulay, who said that, you know, Sam's baseline was, he had, I'm not sure I'm
*  saying this right, anhedonia, which is an inability to feel pleasure or happiness.
*  So to him, and again, this is getting dark, but like to him, like kind of being in a prison
*  jumpsuit and eating terrible prison food maybe didn't have the same impact as it would for
*  for other people. You know, and maybe he had on some level, some type of self-destructive
*  death wish is a strong term, but I'm not sure that's wrong. If he like kind of literally says
*  you should be willing to like risk ruining your life, and he did ruin his life. I mean,
*  you know, and by the way, there are also some tragic human elements to this too. One critique
*  I have of EA is that it tends to recruit true believers, whereas people elsewhere in the river
*  are by nature very skeptical, right? Most savvy gamblers know if you're being offered a bet that
*  seems to be too good to be true, then it usually is too good to be true. Why is the counterparty
*  offering you that bet? You know, I think Sam recruited true believers who didn't push back
*  on him as much. He was in the Bahamas, which is kind of the part of the island he was in is like
*  quite far removed from the rest of civilization. He's in kind of an isolated compound. His girlfriend
*  works for his hedge fund, his parents work for the company. So he's not getting very much good advice.
*  And but okay, I mean, putting him aside, there are definitely, you know, aspects,
*  it's a fascinating psychological story. But all of us have this issue of weighing very unlikely
*  things that have enormous consequences with very likely things that have smaller consequences. I
*  mean, that's the issue with AI risk and other existential risks. I mean, having gone through
*  the book, having spent the three years, do you have any wisdom? Because I struggle with this. I
*  have feelings, but I don't have any rigorous theory about what to do about those possibilities.
*  I mean, look, Silicon Valley, in some ways comes out looking better than other parts of the book,
*  even though these people are sometimes vainglorious assholes, right? I mean, you know,
*  you're going to get, I think detailed and nuanced portraits of Peter Thiel and Elon Musk and Mark
*  and recent. I talked to most of these people, but not all of them didn't talk to Elon. But,
*  you know, but Silicon Valley, it's a mantra that you hear from every VC you talk to will kind of
*  repeat the same two things, right, which is number one, having a long time horizon is good that you're
*  making bets that may have it may take 10 years, 15 years, 30 years to pay off. And we live in a
*  country where it's kind of get rich quick, not get rich slowly. And so almost any time that you're
*  willing to take a longer time horizon, the just an advantage people discount the future, even their
*  own narrow selfish future too much almost almost universally. And number two, understanding expected
*  value understanding that a small chance of a very big payoff, if you can make that bet repeatedly
*  and fold different investments into a fund or a portfolio that like, you know, that's a very
*  lucrative profession. Once you get the once you get the wheels turning, and it becomes like a
*  flywheel, and you say, Okay, I'm going to invest in 15 companies in this fund, and some of them will
*  will flounder. And some will pay off one x, but we'll get one that pays off 50 x. And the next
*  one will get one that pays off 1000 x. And those two things understanding expected value, particularly
*  high, high, low likelihood, but high impact events and understanding time horizons and not and willing
*  to being to, you know, be patient. Those two things can make up for a lot of very flawed human
*  beings who are making these decisions. Yeah, no. And I think those aspects, again, I'm the sales pitch
*  is very compelling to me, you know, I get it. And if it's my job to sort of, you know, raise a question,
*  the question would be that it makes them very good at making their lives good. Is it necessarily
*  making the world a better place, especially when because we all are human beings, as you know,
*  some of these folks get to think get to thinking that only they have the answers and therefore they
*  should be given all the power. Yeah, so there there are a couple of things here. You know,
*  if you look at like the most successful top decile VC firms, I mean, there actually is evidence,
*  I think is pretty good. I mean, the returns are mostly private, but there are enough pieces of
*  evidence that they really might be making 20% annualized returns per year. If you compound 20%
*  over several decades now, it just kind of begins to eat everything else. And you kind of see now
*  how much power I mean, even the look at the 10 richest people in the world are now twice as rich
*  as they were 10 years ago, right? I mean, that's what you get if you have that compounding annual
*  increase in in well. So you now have, you know, these people are like more powerful than
*  many countries in the world. So that's one thing is a compounding nature of it where,
*  where, you know, it gets bigger and bigger every year and kind of eat the rest of the economy.
*  And the fact that, like, I'm a kind of, you know, neoliberal, capitalist, I think technology has
*  mostly been good, not mostly has been, you know, overwhelmingly more good than bad for the world.
*  And you look at growth in human lifespans, and the reduction of poverty in India and China and
*  places like that, and the amount of you know, even the amount of like, individual rights in the world,
*  it's easier to be a gay person now, for example, than it was for almost all of human history,
*  for instance. However, I'm losing my train of thought a little bit here.
*  The power of their head. Yeah, okay. But like the latest round of technologies, you know,
*  um, the social media create net social utility, I think a lot of people would say,
*  No. What about cell phones? I mean, there's, you know, Jonathan Haidt, my Penguin Press co author,
*  just wrote a book about kind of the impact of phones on adolescents and things like that.
*  With AI, Sam Baldwin will tell you it might destroy the world, right? And he's proceeding anyway,
*  actually thinks that way. Yeah, yeah, I mean, like that, you know, sorry, sorry, it's not just
*  because he thinks the good outweighs the bad, he thinks that he can control it better than someone
*  else can, therefore, he wants to be there first, right? Which can be a self serving rationale.
*  Yes. I mean, it's, you know, kind of a form of the prisoner's dilemma, where if they think China's
*  going to build it, or, or Google is going to build it, if open AI doesn't build it, that, hey, we're
*  the smart people can do it the right way. I mean, I'm, I'm not so sure I would, I would trust that,
*  right? And it's a time, you know, I'm someone who, again, you know, you have a little bit of that
*  kind of free market ethos, and you're a little bit skeptical of like government regulation, but like,
*  in the Manhattan Project, it was government controlling this technology that could potentially
*  destroy the universe, right? I'm not sure I would want Silicon Valley to develop nuclear weapons.
*  And I also am not sure kind of like, like, what right do you have? So during the Trinity test,
*  which is a Manhattan Project in 1945, right? Enrico Fermi and other physicists were slightly
*  worried that there was maybe a one in 1000 chance that testing the first atomic bomb might shut off
*  a chain reaction in the atmosphere, and destroy all life in the earth and probably neighboring
*  planets as well. So like, you know, what right did they have to take that one in 1000 chance of
*  destroying all of civilization? Well, I guess you could say, well, if we don't do it, then Germany
*  or Japan will develop the bomb first, there's a Holocaust going on. I mean, these are very,
*  very heavy things. In that circumstance, then I think it was a rationally justifiable risk,
*  right? But that was done by government, at least in some sense, you have some consent of the people,
*  whereas like, you know, what gives Sam McMinn free the right to press this button for 50-50 odds,
*  or even for 90-10 odds, or something like that. And so, you know, if you're not someone in the
*  river, if you're someone who thinks, you know, Elon Musk is evil, I can at least read the book
*  so you understand what the mentality is behind these people. Yeah. And I will second that
*  recommendation. The book is very worth reading for exactly those reasons. And for the last question,
*  then, in these communities, we're talking about one of the quantities they like to estimate is
*  P-Doom, the probability that we are going to do something that is going to destroy the world
*  entirely. And of course, people qualify what they mean by doom differently. All right,
*  so what is your estimate? What do you numbers you put on P-Doom yourself?
*  So I'll give the answer I gave in the book, which is kind of a punt, right? Which is I say 2% to 20%.
*  Because the definitions are so different, some people say literally all life has to be destroyed.
*  Right. Some people say, oh, if we just kind of lose agency, and kind of computers and AIs
*  control our life for practical purposes, like I think that latter definition is,
*  you know, dangerously plausible, I find the former pretty unlikely. But the consensus in the
*  community is like, five to 10%. And I expand it outward, because like, I spent three years talking
*  to the smartest experts in the world about this, they can't agree. So I'm not going to try to
*  superimpose my view on top of that. I mean, those are still huge numbers. Like if I want to end on
*  an optimistic note, for my listeners out there, for me, it's more like 10 to the minus three or
*  less. I think that these are crazy big numbers that people are getting by extrapolating from
*  very tiny bits of data. Look, I think since I was working on the book, there's been kind of
*  more of a pause in terms of large language models in particular. So maybe I would shade down
*  a little bit if I were re-estimating today. But there are a lot of very serious people who have
*  thought more about it than I have. And kind of as a Bayesian, I have to defer to them somewhat,
*  I suppose I'd say. That is a perfectly valid way of thinking about it. My gut is on the more
*  skeptical side, but like I don't, you learn not to trust your gut sometimes, or at least at least
*  not to give full weight to it. Not full weight. That's a very good way of going through this stuff.
*  Nate Silver, thanks very much for being on the Mindscape Podcast.
*  Cool. Thank you so much, Sean.
