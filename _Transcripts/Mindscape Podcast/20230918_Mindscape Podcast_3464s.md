---
Date Generated: June 07, 2024
Transcription Model: whisper medium 20231117
Length: 3464s
Video Keywords: []
Video Views: 7076
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2023/09/18/250-brendan-nyhan-on-navigating-the-information-ecosystem/

The modern world inundates us with both information and misinformation. What are the forces that conspire to make misinformation so prevalent? Can we combat the flow of misinformation, perhaps by legal restrictions? Would that even be a good idea? How can individuals help distinguish between true and false claims as they come in? What are the biases that we are all subject to? I talk to political scientist Brendan Nyhan about how information and misinformation spread, and what we can do as individuals and as a society to increase the amount of truth we all believe.

Brendan Nyhan received his Ph.D. in political science from Duke University. He is currently James O. Freedman professor of government at Dartmouth College. Among his awards are an Emerging Scholar award from the American Political Science Association, a Guggenheim Fellowship, and election to the American Academy of Arts and Sciences.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll

#podcast #ideas #science #philosophy #culture
---

# Mindscape 250 | Brendan Nyhan on Navigating the Information Ecosystem
**Mindscape Podcast:** [September 18, 2023](https://www.youtube.com/watch?v=s7T4qqhp_48)
*  Hello everyone, welcome to the Mindscape Podcast. I'm your host, Sean Carroll. If you're like
*  me, you know some people, maybe friends or colleagues, who believe untrue things. Their
*  beliefs are false, incorrect for some reason. Don't you hate it when that happens? It may
*  even be true. This is a wilder idea, but your friends might think that you have some untrue
*  beliefs. That's even more annoying. Why does this happen? Why do people believe different
*  things, even when they're quite educated about them? You might think that if people just
*  didn't know that much about something, they might be uncertain in their beliefs and be
*  corrected when they get more information, but that's not what we see, especially in
*  the social sphere, the political sphere, culture war kinds of questions. People believe things
*  despite the fact that there's a whole bunch of people who believe other things and are
*  trying hard to convince them. And we have a special problem these days with the media
*  landscape, with technology. We are flooded with information, with opinions, with attempts
*  to change our minds much more than ever before. So there's actually two questions going on
*  here. One is, what is the information or the sets of claims to which we are being subjected?
*  Are we in filter bubbles? Is the news media trying to be accurate or are we just hearing
*  things that are tribal or politically slanted in some way? So how do we control the relationship
*  between our attention and the information we get? And as a society, how should we try
*  to make sure that the information being given out is relatively accurate or safe or whatever
*  you want it to be? The other question is then, what do we do with that information that we
*  get? What kinds of information change our minds? We like to imagine a kind of Bayesian
*  utopia where we have propositions that we assign credences to and new evidence comes
*  in. We update our credences. But people very rarely work that way. I mean, we've known
*  that here on Mindscape since episode one. Our very first episode was with social psychologist
*  Carol Tavris, who talks about how people in groups that have some false belief together
*  can absolutely maintain that false belief in the face of enormously strong contrary
*  evidence. So today's conversation is with Brendan Nyhan, who is a political scientist,
*  who's done a lot of work on both sides of this question. What is the kinds of information
*  and influences that we get? And then what do we individually do with them? Some of his
*  early work was on the backfire effect, the idea that under certain circumstances, when
*  you hear evidence that contradicts a belief that you have, you can come away holding on
*  to that belief even more strongly. Now, it turns out to nobody's surprise, if you know
*  anything about psychology, it's more nuanced than that. That's not always true. It's true
*  in some cases. It's not true in others. It's an ongoing thing. But it's fascinating how
*  whatever we are as human beings, we are not entirely 100% rational. We have our biases.
*  We have our desires to fit things together. You know, when I wrote the big picture, I
*  talked about planets of belief. The idea that we have a particular belief in a particular
*  proposition independent from everything else is just nonsense. You know, our beliefs fit
*  together, sometimes coherently and consistently, sometimes less so. But that other set of beliefs
*  that we have, everything else that we're holding on to has an enormous influence on how we
*  judge each individual thing that we learn. So with Brendan, we're going to talk about
*  the information sphere that we have out there in the media right now, how well the mainstream
*  media does in trying to be objective. Should it try to be objective? When should it try
*  to call out lies versus just saying what both sides believe? And then a little bit about
*  how we individually process that information and try to personally come up with true beliefs.
*  How do people end up denying climate change or vaccines or something like that? These
*  are questions that matter right now to the world we live in. And I don't think we got
*  the once and final answers here, but I think it's something we really need to be thinking
*  about very carefully. So let's go.
*  Brendan and Ihan, welcome to the Mindscape Podcast. Great to be here. So I wanted to
*  start thinking about disinformation, misinformation, fake news, all these things. Put us in historical
*  context because I always worry that we think we're unique right now, but I know that there
*  was fake news back in the day. There was yellow journalism. There was snake oil salesmen,
*  etc. Are things really different right now?
*  Well, I share that concern that we're too quick to jump to historical differences that
*  we think exist, that conspiracy theories are worse, that misinformation is worse. And we
*  don't have any strong scientific basis to draw those sorts of conclusions. I think it's
*  fair to say that misinformation and conspiracy theories have been with us as long as human
*  beings have existed. And if you spend any time looking at history, you'll see misinformation
*  playing an important role. If you look around the world, you'll see the United States is
*  hardly unique and the role of misinformation and conspiracy theories here. So I'm, I'm
*  I would reserve judgment. There are aspects of how misinformation conspiracy theories
*  work now that may be different and that may be particular reason for concern. But the
*  idea that misinformation and conspiracy theories are more pervasive now or more widely believed,
*  we just don't know. One challenge is, of course, how you would measure these, these quantities.
*  That was my next question, right?
*  We only have modern survey research in the post-World War II period for the most part.
*  The polling on these questions is heavily concentrated in the last few decades and really
*  only the last 10 to 15 for the most part. So we simply don't have a great deal of empirical
*  data on belief. Similarly, the way that information spreads, of course, differs over time in ways
*  that are hard to systematically measure and track. Word of mouth, of course, played, still
*  plays an important role, but played a much more important role in prior eras. And that's
*  not a form of transmission that's legible to us as scholars. What gets written down,
*  of course, is a subset of what's most important in any time. We now live in this period when
*  digital data are available to us. And that allows for really exciting opportunities to
*  measure what's being spread that we might otherwise not have captured. But we should
*  be important, you know, not to, what's the expression, not to mistake the map for the
*  terrain. What's measurable to us is not necessarily ground truth, especially as you move through
*  different historical eras.
*  There's certainly the technology that has enabled us to misinform each other at a remarkable
*  rate, right? I mean, we have, I guess back in the day we had more newspapers, pamphlets,
*  and things like that. But my guess is it can't compare to our social media feeds, the number
*  of channels on TV and so forth.
*  Yeah, I think it's important to remind people of all the different kinds of media we've
*  had and that we've, you know, newspapers, for instance, we think of as a kind of boring,
*  standardized format, rarely takes risks, you know, retreats to a kind of both sides journalism
*  and so forth. But prior to the 20th century, newspapers were absolutely wild, frequently
*  printing scurrilous claims about political opponents, heavily partisan and so forth.
*  They were often a channel for the worst sorts of information that was being spread at the
*  time. And the, what we think of now is journalism essentially didn't exist. The profession sort
*  of codifies itself informally and develops professional norms and so forth, you know,
*  in the 20th century, in the early 20th century. And prior to that, you know, you could print
*  what you wanted to print and there were not necessarily professional standards governing
*  the evidence you had to marshal to make those sorts of claims. So that's just one example.
*  You know, the list goes on and in each case, this is something important. When these new
*  technologies were became available, people became very concerned about them and about
*  their harmful consequences for society and the ways they could be used to spread misinformation
*  or to propagandize people, etc. So we've had historically panics over the written word,
*  literally the printing press onto radio, television, and now of course, the internet and social
*  media. Again, that doesn't mean there's not reason for concern about our current technological
*  configuration, but I think it should make us be a little bit more circumspect about
*  thinking that what we're seeing now is going to be the downfall of democracy because similarly
*  situated people have come to similar conclusions about prior new media of the time. And we
*  now think of those in a very different way. So it's an integer future, you know, future
*  Americans, future human beings may may look similarly at us now.
*  But it's an interesting point because if we even allow ourselves to be open to the
*  idea that different historical eras were different, we tend to think of monotonic kind of change.
*  And maybe from what you're saying, there's a sense in which it used to be just as sort
*  of crazy and polarized as it is now. And then there was like a brief interregnum where the
*  power of the media was sufficiently concentrated and regularized and professionalized that
*  impression went away. And now we're just returning to that previous state.
*  Yeah, no, I think it's important to make clear to people in the way you're suggesting just
*  how abnormal historically the period around the middle of the 20th century was in the
*  United States in particular. So I'm an American politics specialist. So I'll speak to the
*  area that I know best. Historically, our politics have been heavily polarized. That was
*  true prior to this period in the in the mid 20th century. And it's been true afterwards as we've
*  had this increase in polarization. What's abnormal was this period that we think of as the way
*  things were and should be. Yeah, which in the in the mid 20th century, for reasons related to
*  our history, our country's awful history on race, the parties were not clearly ideologically
*  divided. And we had due to accidents of the way technology, media technology and communication
*  worked, we had a kind of establishment consolidation around a limited set of communication
*  tools, we had newspapers, with their economies of scale that rewarded very large newspapers, and
*  to achieve the kind of readership they needed to achieve to capture those economies of scale,
*  they needed very large audiences. And so that meant that the partisan model of the prior period
*  was supplanted by a this kind of neutral journalistic style that allowed both people from who supported
*  either party to read the newspaper. So we have these consolidation of these very large newspapers,
*  and then we have radio and television where there's a limited set of spectrum and regulation by the
*  government and some informal pressure to maintain higher news standards than the market might
*  otherwise support. So you have this unusual media configuration, where we go from pamphlets and
*  newspapers, lots of kind of chaotic information landscape to this more consolidated establishment
*  media, you go from a wildly partisan national politics to this less polarized one as the parties
*  become quite divided internally on the issue of race. And we get this, you know, abnormal period
*  in our politics. And many of the norms and institutions that we think of as foundational
*  to American democracy are really constructions of this period. And what we're struggling with
*  now is how we create a multiracial, multiethnic democracy when those conditions no longer apply.
*  And I just want to be very clear about the trade offs here that there's no you tow, there's no lost
*  utopia here. It was a very narrow range of voices that were allowed through the media at that time.
*  It was a very narrow set of people who are represented. And the reasons that the country
*  were, you know, the country was less polarized, because the parties were essentially conspiring
*  to keep race off the national agenda and preserve a system of racial apartheid in the south,
*  to kind of maintain the political and civic peace, so to speak, at the cost of the freedom
*  of millions of our fellow citizens. So none of this was acceptable. None of this was sustainable.
*  We have to, we're not going, the conditions that generated those circumstances are not coming back
*  nor should they. And we have to figure out how to move forward. And I just want to, you know,
*  give that brief digression, because I think it's really important sometimes to avoid the sense of
*  this kind of golden age nostalgia that creeps in when we think about our politics. There are very
*  significant challenges associated with polarization and changes in communication technology. But
*  we're not going to be able to wind back the clock, nor should we. And I think that's a
*  really important starting point for any conversation about how we move forward.
*  Yeah, no, very much. And I think it's okay to say, look, there was something good about that era.
*  And there were also very bad things about that era. And we can, we're big enough to accept both
*  things at once. And now our era has changed a little bit, whether it's cable TV or the internet
*  and so forth, those economies of scale that led to consolidation are less dramatic, I suppose. It's
*  easy for me to just start a website, start a newsletter, start a YouTube video feed or whatever.
*  And we seem to be flooded with misinformation, disinformation, fake news. Is it worth
*  distinguishing between misinformation and disinformation and things like that?
*  Well, a lot of ink has been spilled on these questions in my world of scholars who study
*  misinformation. I will say I don't find the distinction especially helpful most of the time.
*  The reason is when people construct these typologies, they often define disinformation
*  as information that is intentionally spread by people who know it to be false,
*  and it's spread in a malicious manner. We very rarely have access to people's interior motives,
*  or so called true beliefs to the extent those things even exist. And so it's very difficult
*  to pin down when someone is making a claim they know to be false. Donald Trump says
*  literally tens of thousands of false things. How many of them does he believe to be true?
*  I don't know. So occasionally we can say something like a Russian disinformation operation or
*  something where there's a very well identified actor and we have a kind of ground truth on
*  the construction of the false information itself. So we know people know that the information is
*  false because they themselves constructed it. But in the absence of those unusual circumstances,
*  I don't find the distinction especially helpful. It often leads to
*  debates about motives that aren't very useful to me. To some extent, whether Donald Trump knows
*  or not that any given statement he makes is false is immaterial. We should hold them accountable for
*  being responsible as a public figure in making accurate statements. Everyone misspeaks sometimes.
*  I'm sure I will make errors of fact in this podcast. But the pattern of
*  repeatedly making false statements, doing so after being corrected, and making these kinds of claims
*  that are reckless and inflammatory, I think we can hold them accountable. Whether or not he means to
*  do it or not, at some point a line must be drawn. And I find it more important to focus on those
*  kinds of questions and whether someone knows a claim to be true or not. And I guess there's
*  a utopian vision in which if we have enough communication channels, then you just can't get
*  away with misinforming people because some other communication channel is going to point out that
*  you are not telling the truth. And that mechanism seems to be of less strength or less effectiveness
*  than maybe we would hope. Is that impression off base?
*  No, I think we have to worry a lot about the incentives that people face to make accurate
*  statements, especially but not exclusively political elites. When you think about what
*  affects public opinion, when is misinformation especially harmful? It's often when it comes from
*  people who have a wide audience and an audience that's responsive to them.
*  And political elites are often among the most influential figures and institutions in spreading
*  misinformation. Their incentives, unfortunately, are quite warped. The sanctions for making false
*  statements are quite weak. Donald Trump, of course, is the canonical example now of
*  how little it seems to matter in terms of the political support you amass if you make false
*  statements, at least under certain circumstances. And so with those incentives in mind, of course,
*  the upside to misinformation may be relatively more attractive. It may be a way to decrease
*  support for your opponent, to activate your political base, to make a policy debate tilt
*  in a direction that's favorable to you, et cetera. And if the only cost is people
*  say you're making false statements in a medium that your supporters don't trust very much,
*  that's a pretty weak sanction. Now, I want to be very clear about this point. We can talk about
*  it more because it's a subtle thing. I am not saying we should roll back the First Amendment.
*  And in fact, I'm very uncomfortable with legal remedies in general. I think people have become
*  quite reckless in how quickly they jump to speech suppression as a solution to this problem.
*  And I think they should reflect carefully on how those kinds of steps could be misused
*  by folks they don't like if they have control over the relevant institutions, whether it's political,
*  legal, or say control of tech companies and platforms. In all of those cases, think of who
*  you don't want controlling speech and now imagine giving greater control over speech
*  to that entity. We can all, I think, imagine the potential for misuse. And so we can't
*  do that. And so I worry about people who say, well, misinformation is a problem and someone needs to
*  make it go away. And the way to do that are legal restrictions or the platforms taking care of it
*  or so forth. Those are, in some cases, the punishment may be, the cure may be worse than
*  disease. There is a philosophy question here about the nature of truth and how possible it is to get
*  there. I forget who it was. I read just very recently some politician about Donald Trump's
*  recent legal worries. A Republican politician was saying that this assumes that the government
*  can judge what is the truth. And I'm like, well, the legal system is certainly presumed to try
*  to judge what is the truth. But I think what you're raising is that if we try to make a
*  law saying, you know, you can't lie, you can't tell intentionally untrue statements in the media
*  or whatever, that would be, as a practical matter, very, very hard to make fair and shielded from
*  misuse. I think that's right. I tell my students when I teach about this topic that at any moment
*  a philosophy seminar about the nature of truth could break out. And there are intense debates
*  in my world about exactly where we should draw these lines. So for instance, for the fact checkers,
*  you know, these predominantly online journalists who evaluate the accuracy of statements made by
*  politicians, there's frequently debate about whether their ratings are fair, if they accurately
*  reflect the evidence, if the matter at hand is even a factual question about truth at all. In some
*  cases, it may be subjective or a matter of opinion in some important way. And these are very difficult
*  questions that don't necessarily have objective answers. And that's why I appreciate the way in
*  this country, the bar for defamation and libel cases is very high. Right. It's very high. And
*  that prevents cases from being successfully litigated unless the claims are
*  absolute or extreme. And it also, you know, you can't, it's very difficult to bring
*  cases against public figures for making false statements. I guess what, you know, the bottom
*  line to me is that false statements are part of living in a democratic society. There is no,
*  and I'm concerned about the way we went from saying misinformation is a problem to our goal
*  should be to eliminate misinformation. The price of eliminating misinformation is no longer living
*  in a free society. And we have to accept that there will always be misinformation with us.
*  And that we have to think about the competing values at play here. That doesn't mean we shouldn't
*  try to address misinformation effectively. And we can talk about ways to do that. But setting up the
*  goal is zero misinformation is taking us down a road towards an ill liberal society. And this kind
*  of problem pops up not only with politicians or bad actors who want to misinform for their own
*  reasons, but even with, as we hinted at before, journalistic outlets that are trying to do their
*  best to be objective. Right. It can, there's certainly a well-known worry that that degenerates
*  into both sidesism. Opinions on the shape of the earth differ. So what words of wisdom do you have
*  for a responsible news outlet that is trying to be objective and stick to the truth, but
*  is so used to just saying, well, party A said this and party B said that, that they are reluctant
*  to say, and party B is absolutely lying? Yeah. No, this has been a real debate in journalistic
*  circles now for a couple of decades. The fact checking movement in some ways was inspired
*  by the failures of mainstream journalism in this respect. The coverage, originally,
*  the seeds of this are the Ad Watch movement, where journalists were frustrated with the way that the
*  so-called Willie Horton ad was covered in the news. And it seemed to almost amplify the claims in
*  question rather than providing adequate scrutiny. And that Ad Watch format is a progenitor to
*  the fact check format, which sought to reorient the focus of journalism, at least within this
*  framework, towards evaluating the accuracy of the statements made by politicians instead of
*  reporting what is quote news, which is a subjective thing that often leads to
*  that he said, she said style of journalism you described. And in general, I think we have seen
*  a kind of transformation. I would point to two issues that have really driven this change.
*  The first is coverage of the climate movement, where it became, after many years of shaming,
*  it became professionally damaging to both sides climate change as the evidence became overwhelming.
*  Yeah. And then second, the sheer volume and audacity of Trump's false statements
*  during his campaign, and especially during his time as president, when it was simply impossible
*  to report on Trump and not indicate clearly that he was making false statements. And both of those,
*  I think, have increased the scope of journalists' willingness to describe evidence in non-50-50 terms,
*  even when contested by the parties. You still will see examples where
*  journalists retreat to that. I think it's still an ongoing challenge.
*  But I do think progress has been made. And that's important because empirical research suggests that
*  when you get, when you're exposed to these news stories that say, you know, views on the shape of
*  the earth differ, people infer, people may infer from that presentation that experts are divided,
*  that the evidence is mixed, that there's a lot of uncertainty. So it's important to
*  communicate precisely the relative weight of the evidence when such an expert consensus exists.
*  You know, of course, there are dangers of overcorrecting in the other direction, too,
*  and stating with too much certainty claims that turn out to be poorly supported or wrong.
*  We lived through a lot of instances of that during COVID, for instance,
*  where the media rushed to state experts know X, and then that consensus would, of course,
*  be quickly overturned. Well, that's the problem with science is that we try to be open-minded to
*  new results coming in. And it's hard to convey that we're pretty confident that this is true,
*  but we will change our minds if we learn new things. But I had Ezra Klein on the podcast
*  a while ago talking about polarization and how we've become more polarized over recent decades,
*  very consistent with things that you've said. But I asked the question, and he was sympathetic to
*  the idea that one thing is just politicians learn to be better game theorists. And if you
*  take as your incentive structure, not, I want to make the country a better place,
*  but I want to win the next election, then you just act differently, right? And you know,
*  maybe your standards are different and whatever. Do you think that the elite political class
*  has become better at gaming the system, including the feature of the system that
*  journalists are trying to be objective? It's an interesting question. I mean,
*  I'm a political scientist, so I always think politicians are being strategic. And
*  some of the most influential works in my field point out how much of political behavior you can
*  explain simply by the reelection motive. At the same time, I will say I thought there were more
*  lines that politicians wouldn't cross than turned out to be the case after, during the Trump years.
*  And so if anything, I've updated my views to think that the reelection motive is overwhelmingly
*  shaping politicians behavior. I would have thought actually some of the policy
*  heterodoxy of Trump also would have constituted a red line for people who are in politics for
*  ideological or policy reasons. But we've seen remarkable flexibility on some of those issues
*  as well. So whether politicians are behaving more strategically, it's not clear to me. I guess the
*  way I would describe, I think they've always behaved strategically. I guess that what we've
*  seen that I'm most concerned about is a breaching of a set of norms that constrained politicians
*  at the national level from moving into explicitly anti-democratic, explicitly anti-democratic
*  realm or normalizing misinformation in the way that Trump did. Those two trends, I think,
*  are genuinely worrisome because when that kind of rhetoric becomes normalized, the incentives for
*  politicians change. It was thought it was career ending to do the kinds of things that Trump did.
*  And so for sincere or strategic reasons, politicians didn't do them. They may have
*  believed in the norm and thought it was bad to violate it. They may have just strategically
*  avoided breaching the norm because they thought it would be bad for their career.
*  But those explanations both generate the same expectation. People won't engage in
*  anti-democratic rhetoric or anti-democratic actions. They won't spread misinformation as
*  brazenly and at the volume of Trump. Now we've seen those norms be breached. And norms depend on
*  this shared understanding of the limits of behavior. If you cross some line, you will
*  be sanctioned for it. And so a strategic politician may respond to the breaching of those norms by
*  changing their behavior. And that's really what I'm most worried about. We have an ongoing debate
*  about whether Trump is a kind of one-off figure or a harbinger of things to come. And it's clearly
*  proven difficult for other politicians to capture whatever it is he's doing, as we're seeing during
*  the Republican primary right now. So there are elements of his appeal that clearly are
*  non-transferable. But I think it's fair to worry that the breaching of those norms will change
*  the way politicians approach politics strategically. So let me give you, I think, a simple
*  example of this. Ron DeSantis is running for president right now. It has not gone well.
*  We're recording this on August 23rd. He has struggled. He was seen as a very strong
*  challenger to Donald Trump based on his political and policy success in Florida. There was this idea
*  he could pitch himself as both more electable and more conservative in a conventional sense. And that
*  would be a combination that could launch him to the presidency. He has struggled. He is not
*  attracting nearly as much support nationally or in key primary states as expected. One reason is he
*  has not found ways to present the case for his candidacy that are resonating with primary voters
*  in the Republican Party. And one thing we've seen in recent weeks as he's been shaking up his
*  campaign, changing staff, changing strategy, changing rhetoric, is an increasing pattern of
*  resorting to violent metaphors or indeed the endorsement of violence itself. So first,
*  he talked about slitting the throats of metaphorically of the parts of the federal
*  government workforce that he said he would cut, which is a kind of troubling metaphor for talking
*  about your plans for the government, civilian workforce. He then has now started talking about
*  how he will, under his administration, the United States will shoot alleged drug smugglers at the
*  border and just kill them as they approach or try to cross the border. So just a kind of explicit
*  endorsement of extrajudicial violence. And Ron DeSantis is nothing if not strategic.
*  He's a very cerebral person. He is responding to the incentives he faced. His kind of wonky
*  style, I will stand up to the woke people for you, et cetera, was not resonating. And now he starts
*  talking about violence and boy, he's getting a response. This is becoming one of the lines
*  that's generating the strongest responses at his rallies. He may deploy it at the Republican
*  presidential debate that's going to take place tonight. And that's exactly the kind of thing I'm
*  worried about that strategic politicians responding to these incentives may take us
*  towards increasingly authoritarian and illiberal places if we're not careful. Because even if you
*  just want to win and hold office, that may be the path to do so, unfortunately, in the current
*  Republican Party, especially. Well, and there's a feedback loop with the specifics of our political
*  system, right? You're a political scientist. You know about the median voter theorem. There's this
*  happy idea that politicians will move to the center to grab the largest number of votes. But
*  when we are in such a polarized atmosphere, especially with such strong geographic polarization,
*  as long as you think that your party has a good chance of winning most of the electoral votes or
*  most of the state houses, or et cetera, you're just appealing to the party. And you're just
*  appealing to get people out to vote by kind of poking at their emotions and getting them
*  very fervent and so forth. So these are not, I don't know if this is temporary or if it's
*  just an insight into how things work that politicians seem to be moving towards extreme measures
*  to game, again, game the system, but in this case, not the media system, but the particular
*  electoral system we have here in the US. Yeah, I think political scientists are increasingly
*  troubled by the intersection of geographic polarization and our two party system. The
*  incentives to try to appeal to wider audiences are quite limited. Most members of Congress
*  are at greater risk of losing a primer than they are of losing a general election. And under those
*  circumstances, it's not surprising, although extremely disappointing, that so many Republicans
*  would not vote to disqualify Donald Trump from running for office again after the January 6
*  insurrection. If they had taken that step, we wouldn't be in the position we are today.
*  But given the electoral incentives they face, of course, that may be an entirely rational strategic
*  response. Similarly, at the national level, we're so closely divided and that the downside
*  to taking extreme or anti-democratic actions is relatively limited. For all the things that
*  Donald Trump did, his approval rating moved in a very narrow band because so many Americans
*  were locked into how they felt about him. Pro-income. And we've seen the same pattern
*  under Joe Biden. That is not specific to Trump. The two-party system with the levels of polarization
*  we've seen now has created a circumstance where there's not much downside risk. Your supporters
*  will stick with you almost no matter what. And it's very difficult to win over the other side.
*  If you look historically in that unusual mid-20th century period we were describing earlier,
*  you'll see wild variations in approval ratings that we have not seen
*  now in many years. The last time we saw it was after September 11th. And ever since we've been
*  in this, the presidents have been, approval ratings have been moving in these very narrow bands.
*  One other point I would make is just simply that the two-party system itself has a dangerous sort
*  of zero-sum logic to it. Anything I do that helps the other side automatically hurts mine.
*  And that's why I think we're seeing more political scientists who are open to changes in the American
*  system to move towards multiparty governance. It would change the zero-sum logic. It would
*  create a way for Republicans who are uncomfortable with the misinformation and anti-democratic
*  tilt of Trump and his acolytes to have a viable path forward electorally. A world where there's
*  a center-right party as well as a far-right party would provide a home and a potentially sustainable
*  path towards electoral security for the Mitt Romney's of the world. And the George W. Bushes
*  and John McCain's and that whole swath of the Republican party. Right now our electoral
*  institutions make it very difficult for those people. We're seeing many of them retiring
*  and seeding the field to stronger supporters of Trump. And that's going to be a challenge
*  for the Republican party going forward. Again, just due to the strategic behavior,
*  people respond to the incentives they face. Let's move on a little bit from the elite
*  politicians here because they're not the only issue. We have Facebook and social media
*  algorithms and so forth that have absolutely contributed to the spreading of dis and miss
*  info. I guess I can ask an analogous question there. Is that maliciousness or are people just,
*  people, are the companies running these platforms just doing what they think is best and there's
*  sort of an inevitable spiral that we're in? Yeah, that's a tricky question. The platforms
*  are very different, especially in a world where Elon Musk controls Twitter. Speaking about
*  Twitter and Facebook in the pre-Musk era though, I think it's fair to say that the platforms were
*  trying to do their best. And in general, there were at least people within the companies who
*  are working very hard to try to address concerns about the spread of misinformation on the platform.
*  It turns out to be very difficult to identify and effectively counter misinformation
*  on platforms. You really have to think about the kinds of trade-offs we described earlier.
*  The interventions, there have been misguided interventions in terms of limiting the spread,
*  for instance, of information about Hunter Biden's laptop or various claims about COVID that turned
*  out to be true that I think don't look very good in retrospect. And we should bear that in mind
*  when we think about the platforms intervening more aggressively. At the same time, there are
*  many cases where the platforms were negligent in addressing potential vectors of harm on the
*  platforms. We talked at the beginning about why now might not be unique, but it is, of course,
*  true that the platforms enable false information to spread faster than it ever has before.
*  That can be quite powerful when something really spreads in that viral manner that can enable false
*  information to reach people very rapidly. It can also service false claims from the kind of digital
*  grassroots that are then popularized and spread by prominent news outlets and political figures.
*  We all hear about the idea that people now have filters and they live in bubbles because they can
*  pick and choose their own news sources. But I've recently read claims to the effect that
*  it's not true that we live in filters or we live in bubbles. It's just true that we are very good
*  at ignoring the news we want to ignore. And so we sort of effectively filter out ourselves no
*  matter what the world is giving us. Yeah, I've been a skeptic of claims that echo chambers are
*  predominant. You hear these claims about echo chambers and filter bubbles and so forth.
*  The worry is that digital media make it especially, the intersection of digital media,
*  and particularly social media and polarization have created a circumstance where people are
*  predominantly living in echo chambers or filter bubbles. The empirical data we have, which is
*  unusually rich now because of the kinds of digital behavior data that can now be collected,
*  shows that those sorts of claims are not well supported. Most people's information diet
*  is relatively balanced. On social media, people are often encountering information they don't like
*  relative to, for instance, the political mix in the area you live or the friends and family you
*  have, you're probably encountering much more discordant information online. To make this more
*  precise, I conducted a study after the 2016 election when there was the panic over fake news
*  and we found that the untrustworthy websites, which were a particular form of potentially
*  harmful content people were worried about, people thought were creating these kinds of echo chamber
*  effects. Consumption of those websites was heavily concentrated among a small
*  portion of the population, something like 20% of Americans, 20% of Americans with the most
*  conservative information diets online were responsible for about 60% of the exposure to
*  those sites in our data. We've seen even more extreme estimates for exposure to Russian
*  misinformation content during the 2016 election, exposure to so-called fake news on Twitter.
*  Those were again, concentrated among very small subsets of the public. We recently did a study of
*  YouTube exposure to the potential, the most worrisome channels on YouTube, again, overwhelmingly
*  concentrated in a very small percentage of the public. In general, echo chamber claims are
*  overstated. In particular, exposure to these kinds of potentially harmful content seems to
*  be concentrated to this narrow subsets of people who already have quite strong or extreme views.
*  I think that worry is misplaced. We should think instead about how exposure to this kind of content
*  might generate important harms in the world, even when it's being done by a small minority.
*  You might think of things like January 6, for instance, the ways that digital technology helps
*  enable the mobilization of people who already have extreme or fringe views. The way digital
*  technology might inspire acts of violence in the real world or racial or ethnic hate, things like
*  that that translate the latent sentiments that are out there in the world in these extreme pockets
*  of the population and help them manifest in harmful ways in the world. I'm more worried about
*  that than I am about the average person being trapped in echo chamber filter bubble. The average
*  American has better things to do, to be perfectly honest with you. They are not spending hours and
*  hours in so-called rabbit holes or reading tons and tons of politics. They don't follow politics
*  that closely even. Again, that doesn't mean there aren't reasons for concern about digital media.
*  There are. We should be really precise about it. These kinds of loose claims based on anecdotes,
*  I think, have led us down the wrong road in thinking about all the platforms and the kinds
*  of harms that they could generate. It brings up the complicated issue of how people actually form
*  their beliefs. It's certainly not true they're just exposed to claims and believe them. It's
*  not even true that they are good Bayesians and have priors and update things. How do we judge
*  the relationship between what people are hearing and what they're choosing to accept?
*  Yeah, this is an area of ongoing research. I think what we're tending to see,
*  the emerging story from the research suggests that when you expose people to corrective information
*  directly, people will tend to update their views at least in part in the direction of the information
*  that they're exposed to, even if it's counter attitudinal. That's a kind of encouraging finding.
*  Perhaps this encouraging finding, depending on your point of view, is that those effects may not be
*  durable and they may not lead to the changes in attitudes or behavior that people expect.
*  Often there's an implicit model people have in their head that as human beings, we reason from
*  facts to opinions or attitudes and to behavior. We learn things about candidates. We have factual
*  understanding of the validity of their statements. Then we update our opinion about that candidate.
*  Then we decide whether to vote for them. We learn things about COVID. Then we have opinions about
*  COVID policy. Then we go decide if we're going to get a vaccine or not. But it turns out the
*  direction of causality is not necessarily clear. In many cases, our factual beliefs may be reflections
*  of the opinions we hold or the behaviors we choose to engage in. It may also be the case that there
*  are a number of reasons we hold those opinions or engage in those behaviors and changing our
*  factual beliefs may not necessarily have any effect at all. We'll often see cases where people say,
*  I understand Trump didn't make that claim. Sorry, Trump made a claim that was false. I accept that
*  claim was false. It doesn't change how I feel about it. This false claim about COVID, okay,
*  I accept that it's false, but I'm not going to change how I feel about COVID policy about whether
*  I should get a vaccine. Importantly, this goes back to your point about philosophy earlier. It's not
*  necessarily the case that you have to, that it's logically entailed that you must change your
*  opinion or behavior because of that particular fact. You as an observer may have a particular
*  belief system where you think one should update their opinion or change their behavior in that
*  way. But of course, it's not necessarily so. It simply depends on how you weight the relevant
*  considerations, which of course is objective. No, I think this is a great point. I think that
*  people are a little bit too quick to attribute to irrationality that which is better explained just
*  by trying to make sure everything you know kind of fits together in some way. When it comes to
*  teaching physics classes or giving public talks about physics, when people ask me how to do it,
*  my first thing is don't imagine that your audience are empty vessels into which you are pouring
*  your wisdom. To me, it might make perfect sense that someone discounts a certain fact,
*  even though they think the fact is true because there's a whole bunch of other things that they
*  believe that are going to still point them in another direction. No, I think that's right.
*  People have reasons for what they do. It may not be the ones that you would like them to have,
*  but it's not simply a matter of right. I think the mistake is thinking if we pour accurate,
*  factual information into people, they will come out with the opinions and behaviors you would like.
*  That just rarely turns out to be the case in any of the areas I study.
*  We all do it. There's left-wing conspiracy theories, there's right-wing conspiracy theories,
*  etc. Is anything from your research giving you a little bit of insight into how we personally
*  can sweep our own doorsteps and try to do better at separating the true news from the fake news?
*  I wish I had a silver bullet and I don't. If anything, the emphasis that I tend to recommend
*  is on elites and institutions because human nature is what it is and it's not going to change,
*  except in evolutionary time. Faulting people for being human beings, to me, often leads us down
*  a road that generates a kind of elitism and condescension I don't like in these conversations.
*  I think people are being failed by the elite state trust. They're being failed by the
*  institutions that fail to give them the information they need to form more accurate beliefs.
*  We should challenge the media to do better. We should challenge politicians to make
*  accurate statements and so forth. With that said, what you can do, trying to rely on trustworthy
*  sources of news and information, of course, will improve the likelihood that you're exposed to
*  accurate information. They won't get everything right, but on average, they will do better.
*  It's also the case, actually, a finding that comes out of recent research that I think is useful is
*  that it's important to take accuracy into consideration when you're interacting with
*  news and information online. There's a stream of research that basically finds that just prompting
*  people to keep accuracy in mind before they encounter social media content seems to help them
*  make judgments that better reflect the accuracy of what they're interacting with.
*  Because it turns out there are lots of reasons we decide what to share and what not to share.
*  Accuracy is only one of them. Simply slowing down and thinking about is this accurate or not
*  in the moment is a small but useful thing you can do that will help you do better.
*  Now, I'm not sure how scalable that is. If every time you went on social media, they said,
*  accuracy, accuracy, accuracy, eventually you tune them out the way you do any of those kind of
*  repeated reminders. But on the margin, it's a nice thing to do. There are also some pretty useful
*  tips for discerning accurate information online that are sometimes distributed. I've tested the
*  ones that Facebook rolled out after 2016 and they were surprisingly effective. Just here are a set
*  of simple rules you might keep in mind when you encounter a news headline. Is this true? Does it
*  seem too good to be true? Are they using emotional language in a way that's designed,
*  potentially designed to inflame me? What's the source of this information? Just a series of
*  simple questions like that you might ask about the information you come across.
*  It seems to help people do a bit better in discerning what information is valid and what
*  information is invalid. It also seems to me that since we are very polarized these days
*  and people just perceive the other side as the enemy, no matter which side they're on,
*  we're a little too quick to pick up claims and purported news stories that make us feel good
*  or make the other side look bad. You already know that. You're already a little bit more
*  of that. You already mentioned it's too good to be true, but just thinking, well,
*  I like this. It makes me feel superior. I want it to be true. That's something that we should be
*  more skeptical about rather than less. Absolutely. To the extent that we're able to reflect our own
*  biases, which I think is a challenge for every person, if this is something that you realize
*  you might be gravitating towards for those reasons, then taking a second look might be important.
*  I'll give you an example of a design feature on a platform that I think tries to address this in a
*  useful way. I think this was undone by Musk, but earlier on Twitter, when you try to retweet
*  an article with a link and you hadn't clicked on the link, Twitter would ask you, hey, do you want
*  to read that story first? My suspicion is that in many cases, people were hammering that link
*  without even reading the story when it was consistent with their prior beliefs, when it
*  was consistent with their understanding of who the good guys and bad guys were and who's right and
*  who's wrong and so forth. For those of you who have a Twitter account, you can look at your
*  own analytics data and see people almost never click the link. I worry that we're jumping to
*  the kinds of conclusions you're describing and using those retweet and share buttons as an
*  expression of affiliation with a side or an idea. That's where I think we can easily go astray.
*  **Matt Stauffer** Okay. I know you have a deadline. The last question will be a quick and easy one.
*  How would you fix democracy? You already mentioned the idea that political scientists are playing
*  with ways to make it easier to be centrist, less extreme, et cetera. I don't know whether you care
*  about voting systems and things like that. Is it time for big structural changes in how
*  we elect our leadership? **Matt Stauffer**
*  I'm ready to consider them. I wasn't there a few years ago. I'll recommend to your listeners
*  Lee Drutman's work in this area. He has a book called Breaking the Two-Party Doom Loop that I
*  think is a really nice introduction to why we should reconsider the two-party system and how
*  we can start to do so. He's continued to work in this area. If you're able to find his work at the
*  New America Foundation, he's really at the cutting edge. People are experimenting with lots of
*  different potential changes. The one that's gotten the most interest is ranked choice voting. I don't
*  think that will be enough. I just want to go back to the two big ideas we've talked about.
*  When you get out of a two-party framework, it gets us out of that binary zero-sum thinking that I
*  think can contribute both to the endorsement of anti-democratic statements and actions and also
*  creates conditions that are ripe for the spread of misinformation. When you're in a good guy, bad guy
*  framework, your side is right and the other side is wrong. Multi-party systems have their challenges,
*  but there's a reason that we are quite unusual among our peers in our system of government.
*  I think it's time to restructure how we do things. How we get there is a very difficult
*  challenge given the nature of the Constitution, but that is a topic for another podcast. Thank
*  you for having me. I do worry that when we start changing the Constitution, things will get worse.
*  There's a certain conservatism there that makes sense to me. Thanks very much. You've given us a
*  lot to think about. Brendan Nihand, thanks for being on the Mindscape Podcast. My pleasure.
