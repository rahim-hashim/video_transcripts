---
Date Generated: June 08, 2024
Transcription Model: whisper medium 20231117
Length: 5384s
Video Keywords: []
Video Views: 16600
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2021/09/13/164-herbert-gintis-on-game-theory-evolution-and-social-rationality/

How human beings behave is, for fairly evident reasons, a topic of intense interest to human beings. And yet, not only is there much we don’t understand about human behavior, different academic disciplines seem to have developed completely incompatible models to try to explain it. And as today’s guest Herb Gintis complains, they don’t put nearly enough effort into talking to each other to try to reconcile their views. So that what he’s here to do. Using game theory and a model of rational behavior — with an expanded notion of “rationality” that includes social as well as personally selfish interests — he thinks that we can come to an understanding that includes ideas from biology, economics, psychology, and sociology, to more accurately account for how people actually behave.

Herbert Gintis received his PhD in economics from Harvard University. After a long career as professor of economics at the University of Massachusetts, he is currently a professor at Central European University and an External Professor at the Santa Fe Institute. His book Schooling in Capitalist America, written with frequent collaborator Samuel Bowles, is considered a classic in educational reform. He has published books and papers on economics, game theory, sociology, evolution, and numerous other topics.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel:  @Sean Carroll  

#podcast #ideas #science #philosophy #culture
---

# Mindscape 164 | Herbert Gintis on Game Theory, Evolution, and Social Rationality
**Mindscape Podcast:** [September 13, 2021](https://www.youtube.com/watch?v=UeeW6Du7ZN0)
*  Hello everyone and welcome to the Mindscape Podcast. I'm your host Sean Carroll and today's
*  episode is going to be one of the more ambitious mind-bending episodes that we get here on Mindscape.
*  But not because we're doing some esoteric physics or mathematics subject, we're thinking about human
*  beings. Today's guest is Herb Gintis who originally became well known as an economist but these days
*  probably better to classify him as a behavioral scientist because really Herb's whole thing,
*  the thing he really wants to get across is there's something called how human beings behave and we
*  should study and develop theoretical models for that behavior in a rigorous quantitative
*  empirically based way and then whatever we learn about how human beings behave should inform
*  economics but also psychology, sociology, anthropology and so forth. These different
*  disciplines might care about different aspects of human behavior but they should ultimately tell
*  compatible stories about human behavior right? To me this is just pushing all my buttons because
*  this is a very poetic naturalist way of looking at human beings. There are different vocabularies
*  for describing them but they better be at the end of the day consistent with each other in some deep
*  sense. So how do you do this? Well Herb has some ideas about how to do this. Roughly speaking based
*  on the idea that we need to understand the sense in which human beings are rational. There's this
*  whole story about rational choice theory which kind of gets a bad name because we think we know what
*  the word rational means and it doesn't mean that in the sense of rational choice theory. He suggests
*  the name beliefs and preferences as a replacement for rational choice theory but we're stuck with
*  the name but the idea is that people have beliefs and preferences faced with different situations.
*  They will act in certain ways. We can study those ways using the tools of game theory to understand
*  why they would think that they have incentive for behaving one way rather than another and then you
*  can use ideas from actual empirical psychological studies as well as biology and evolutionary
*  psychology to think about why people don't maximize their one-shot return in a game they're going to
*  play. Rationality is not completely individualistic in these situations. It's social rationality.
*  So Herb wants to unify all of the human sciences. You know like I said very very ambitious point of
*  view. I'm not enough of an expert to judge whether he's right but much of what he says is completely
*  compelling to me and he's also extremely entertaining and provocative while saying it. So I think this
*  is going to be a popular episode. Buckle up, hold tight, let's go.
*  Herb Gintis, welcome to the Mindscape Podcast. It's great to be here.
*  So I get the impression and maybe this is unfair, correct me if I'm wrong, from reading your stuff
*  and listening to you talk that you have a certain sense of frustration about the fact that
*  psychology and economics and sociology and anthropology are all separate disciplines rather
*  than sort of one big discipline of human behavior. Is that an exaggeration?
*  I wouldn't say exactly that. What I would say is like in the physical sciences or the natural
*  sciences, there are overlaps in chemistry and physics or biology and chemistry etc.
*  But when they overlap they agree and if they don't agree then they fight about it and figure out
*  what the truth is. But in the social sciences they overlap but they say totally different things.
*  So for instance economists classically would say you know people are motivated by self-interest
*  and you have to give them the proper incentives and there's no notion of morality. But in sociology
*  they don't even talk about incentives. They always talk about norms and violation of norms and proper
*  behavior and improper behavior etc. Well they can't both be right and in fact they're both wrong.
*  Now there's some other fields like for instance economics and biology both use what's called the
*  rational actor model. Biology you maximize fitness. In economics you maximize something
*  called utility but they're both rational actor models. Other fields like in psychology you can
*  read 10 textbooks and they'll all say rational actor model is stupid. It's not correct. We don't
*  use it at all. So what's going on here? It's not science and you know I attribute it to the fact
*  that you have these developed early 20th century these feudal fiefdoms where if you're an economist
*  you publish in certain journals and you talk to other economists and you don't care what
*  sociologists say. Nobody cares because they don't hire you, they don't fire you, they don't publish
*  you, they don't go to conferences with you and so they develop in strange directions. But if you
*  care about the truth it's a scandal, it's terrible, it can't be right to just forget about these
*  conflicts between the way they model human behavior in one field or another and also in biology.
*  There's a tendency towards saying that everything is inclusive fitness. What you do is
*  what an individual does is he helps himself and his nearby relatives. That's not true for humans.
*  It's not true for many social species that have very complex relationships that go way beyond
*  kinship. So anyway that's what the issue is. I'm very much on your side here. I tend to agree.
*  So to play the devil's advocate is it conceivable that for the purposes of economic behavior people
*  act one way and for purposes of social behavior they act another way and actually these are
*  compatible secretly? No, I mean of course that's possible but it isn't true. People do not behave
*  in the economy as though they are self-interested. Now when you have very complete markets you get
*  almost self-interested behavior but when you get interactions among people, face-to-face
*  interactions or other social interactions even in the economy people do not behave
*  self-interestedly. People in a firm that work together have a culture and it could be a very
*  positive culture that promotes cooperation and openness or a very backbiting culture which
*  inhibits cooperation. These are economic behaviors, very important ones having to
*  do with the organization of the labor. Similarly consumers care a lot more than just about
*  the physical attributes of what goes into their consumption. They care about values,
*  they care about who. For instance if you buy Nike shoes you want to know that your Nike shoes
*  were made by slave labor. Well that's not self-interested etc. Similarly sociologists
*  just forget about the incentive side of behaviors and they partially characterize some things but
*  not completely. So my argument is when you put them together you get much more complete behavior,
*  much more explainable behavior. I mean it seems so obviously true what you're saying, at least the
*  part that they should sit down and hash things out, that it's a little bit shocking that they
*  don't or that they haven't. I mean I know the siloing of academia etc. I feel it myself but
*  still one wants to say is it really that bad but maybe it just is. Oh yeah absolutely it's totally
*  that bad. Look at sociology and anthropology. What do they do? They both study human organization.
*  They have totally different reading lists. They don't even overlap. Margaret Mead is not studied by
*  sociologists. Talcott Parsons is not studied by anthropologists. How is it possible you're going
*  to have a theory or a model of human social organization if you divide the world up into
*  two places which have totally different theories? Yeah I can't argue with you there. What can I say?
*  I mean that's the way it is. Now I'll tell you this, when I started out and working on these issues
*  a connoisseur would say well we have to assume that people are self-interested because otherwise
*  you could just put anything you want into their utility function and it doesn't really explain
*  anything. And the answer to that, and that's a very good objection, if all you're doing you're saying
*  okay this guy when he goes to the dump he always travels around to buy his brother's house. It's
*  way out of the way but he likes to go buy his brother's house. So I put that into his utility
*  function. Well that's a big help. I mean all you're doing is epicycles on behavior. The problem there,
*  the answer to that is we now have a whole discipline called behavioral game theory
*  in which we take subjects in the laboratory and see how in fact they behave and infer what they
*  value from their behavior. And that is very advanced now. There have been Nobel Prizes for
*  it, and Danny Kahneman, Daniel Kahneman the psychologist, Richard Saylor. So we go into the
*  lab and then we can figure out what people value. And the objection to the standard theory goes away.
*  Well yeah and I want to get to the specifics of how we do that but I mean everything you're saying
*  pokes at another thing that I've heard a criticism of economics which is that it's not nearly as
*  empirical as it should be. You know we have a theory, we like the theory and rather than
*  testing the theory against data or experiments we just elaborate the theory more and more. That's a
*  cartoon but is there some validity to that kind of criticism? Well let me divide it into two parts.
*  First of all when you learn economic theory there are no facts. I had an amusing thing happen to
*  many years ago but when I started working on this one summer I was studying this big thick
*  thousand page book for introductory graduate economics students on economics. Everybody reads
*  it around the world and I was also reading a book on quantum mechanics. And in the quantum mechanics
*  book I learned black body radiation problem, Compton scattering, Lamb effect, all sorts of
*  empirical effects that gave rise to the standard model. In the economics book there wasn't a single
*  empirical fact, not one, a thousand pages, no facts. And the fact is what the economists are
*  trying to do is derive human behavior from the concept of rationality. What is it rational to do?
*  You can't do that because there's huge numbers of variables involved and rationality is important
*  but it doesn't determine which one you choose. I would say that's right and theorists really do
*  not like experimentalists in economics. It's quite different from physics where there's a deep respect
*  for the incredible versatility and depth of knowledge of the experimenters.
*  We pretend to have a rivalry between theory and experiment but in fact we both know that
*  we need each other desperately and hope that each other are doing good things.
*  It's not like that in economics at all. But now of course there is a branch of economics,
*  applied economics, like applied macroeconomics and this and that, and they use data all the time,
*  but they usually don't use much of theory. They put it in the computer and let the
*  regression coefficients tell you what's going to happen.
*  I would argue that's a different mistake but yes that's right. Let's get back to this issue of
*  game theory and rational behavior. In some sense I do get the impression that you take the rational
*  actor model seriously even if you don't think it's the complete story. What is the sense in
*  which we can think about people in some sense as acting rational? In what sense can you?
*  My overall statement about this is very simple. There are two of the behavioral sciences that
*  have core theories, meaning all over the world people learn the same thing.
*  That's economics and biology. These are the two disciplines that use the rational actor model.
*  Psychology is all over the place. There are always these new theories and people hate the old theories
*  and there's no cumulative development of theory. Similarly in anthropology there are waves of
*  popularity of different views but there's no core theory. I argue that the rational actor model
*  is exactly what you need in order to have a core theory of animal or human behavior.
*  The disciplines that ignore that just don't get very far. They end up being bogus
*  and scattered all over the place. The reason this happened was historical. Namely that the rational
*  actor model, to use you have to know some math. You can't just do statistics. You really have
*  to be able to model mathematically the way you do in physics or chemistry or biology.
*  They try to avoid that and the people in it all agree that we don't want to use it. The real reason
*  I think is it's just hard to do. It's really hard to use the rational actor model in biology and
*  economics but it's a very important part of the discipline. By the way there's a wonderful
*  statement I once heard of a psychologist. He was giving a talk and he said people aren't logical,
*  they're psychological. That really told the story. The joke I heard was that if you don't like math
*  you go into sociology and if you don't like emotions you go into economics. Exactly.
*  There could be something there too. You learn as a graduate student to make fun of the other discipline.
*  You really learn that. It would be like if you were doing natural science and someone said
*  oh in chemistry we don't believe in this relativity theory. We have Christomanicism.
*  It's a real nice alternative. Businesses are all crazy. It's something like that but it goes on
*  all the time in this behavioral sciences. Your home is a place that should bring you as much
*  joy as possible and you can show off what makes you you. Joybird's selection of customizable
*  furniture and modern home decor lets you bring your unique style into your space. And with summer
*  winding down, Joybird has all the modern outdoor furniture and accessories you need to make the
*  most of your patio hangs. And Joybird is committed to creating quality furniture and a more sustainable
*  future. Each piece is made with incredible care using responsibly sourced materials free of
*  harmful chemicals. Through partnerships with groups like One Tree Planted, Joybird is helping
*  conserve and restore earth's most precious natural resources. Quality craftsmanship, stain and scratch
*  resistant fabrics, and limited lifetime warranty. Joybird furniture can handle anything your family
*  throws at it literally. And Joybird stands by its quality and craftsmanship. If it's not everything
*  you hope for, just send it back. So create a space that brings you joy with Joybird. Visit
*  joybird.com slash mindscape and get 30% off your purchase. That's 30% off at joybird.com slash
*  mindscape. Okay, but the rational actor model then you're suggesting is a root to a core theory in
*  economics and biology. And should it be even broader than that? Is it the good starting point
*  for these other ways of thinking about human beings? Yes. I mean, there have been if you look
*  at the literature on the rational actor model, there's been dozens of criticisms of it outside
*  of economics and biology. And they're all wrong. It's hard to believe very intelligent people say
*  really silly things about it, mostly because they don't understand it. But the rational actor model
*  does have one, I think, serious defect. Okay, and here it is. The rational actor model assumes
*  individual minds have individual, what they call subjective priors, that is individual ideas
*  about how the world works, and the probabilities you attach to different behaviors. But I think
*  in the real world, people have what we call entangled minds. That is your what you believe
*  and what you think is a function not of you yourself, but of your network of entangled brains
*  around you, the people you agree with people in your family, the people in your social group,
*  and this and that. So you people become very, very adamant about what's true and what's false.
*  And they believe it only because everybody else they know believes it. If you go to a different
*  place, they believe completely different things. And this is an important part of rational behavior,
*  that people form beliefs, which they validate not against empirical evidence all the time,
*  but simply they validated against the beliefs of everybody else. And this is a weakness of the
*  theory, I think, for at least for humans, I don't think it really is that important for any other
*  species. But how do we, I just want to hear in your words, how we dismiss the most naive objections
*  to the rational actor model, namely that people do stupid, irrational things all the time.
*  Okay. First of all, this is a very important point. It's a good point to bring up.
*  The word rational means all sorts of different things. But here's what it, there's two meanings
*  that you can give it in economics or in biology or where the rational act of one is called
*  instrumental rationality. That means you have a goal and rational being rational means you're
*  choosing the means to get to that goal most efficiently, the fastest, the cheapest, etc.
*  That's called instrumental rationality. So, but there's another called formal rationality.
*  An individual is formally rational if his preferences are transitive. What that means
*  is if you prefer A to B and B to C, you prefer A to C. That's all there is to it. There's a
*  little bit more to get Bayesianism into it, but very little more. It's basically you prefer A to B,
*  prefer B to C, then you prefer A to C. And let me give you an example.
*  Mm hmm.
*  You see a guy fall down in the subway. He fainted. What do you do? Well, instrumental rationality,
*  help the guy get up. But that's not what happens. What happens is you say, oh, Jesus, I'm late for
*  work. Let somebody else help him up. I don't want to hurt my shoes. I want to help him up,
*  but I want to get as far away as possible as soon as the guy gets up. In other words,
*  you have multiple goals. You don't have single goals. And instrumental rationality is irrelevant
*  then. What you need is a formal rationality. And that's what I think we use when we say this is
*  how people behave. We don't say they're trying to achieve some goal. We say that they have preferences
*  which are transitive so that we can model them using a mathematical decision theory.
*  Right. And so it can seem to us from the outside that they are in fact being dumb or being
*  irrational. But at the moment, they are just doing what their preferences say they should do.
*  And that's all we need.
*  That's right. So for instance, you know, if you smoke cigarettes, that's a pretty stupid thing to
*  do these days. But it's not irrational. People do things all the time to hurt themselves. We know
*  that. I do. I don't like it. I wish I didn't. But we all do that. And we also make what's
*  called performance errors. That is you try to do X, but you don't do it right. Your logic is a
*  little bit complicated thing to do. So there are errors all over the place. When someone behaves
*  crazy, you're not sure why. Is it because they really have some underlying rational transitive
*  behavior or are they just momentarily out of their minds? Who knows? The point is that no
*  one's ever developed anything alternative to the rational actor model that you can use
*  systematically to explain behavior. But that word rational is a little bit overloaded and that gets
*  us into trouble. I know I've tried to change it. I started saying, I called it, what did I call it?
*  The beliefs and preferences model. I like that. Not going to get you on, but I get it.
*  I found an acronym for it. But people, it didn't hold. So I say rational, I say what I mean by
*  rational, formal rationality. And by the way, it doesn't mean you're self-interested either.
*  That's the other thing. People think if you rational means you only care about yourself.
*  Well, that's of course ridiculous. The only people who only care about themselves are sociopaths.
*  Seriously, I mean, we all care about a wide variety of things besides ourselves,
*  except for 10% of the population that are real sociopaths.
*  As a minor technicality here, my impression is that if you have a consistent set of preferences,
*  that can always be modeled as you're trying to maximize some utility function, even if that's
*  not actually what you're doing. It's just sort of a formal equivalence, right?
*  Right. That's the fundamental theorem of rational actor model. They talk about utility and maximizing
*  something, but that's not what's really going on. What's really going on is for mathematical
*  purposes, it's really nice to have a function you can maximize. You bring in the calculus and
*  differential equations and all that stuff. Very happy.
*  But what people are really doing is just having preferences once they're transitive.
*  And then you can build the utility function out of that.
*  Yeah. And once you do that, that's when game theory becomes a useful tool. Maybe we should
*  talk a little bit about game theory. I mean, probably people know what the words mean, but
*  does game theory really give us a useful model for how people behave? I mean, maybe you're saying
*  that it does in the sense of this beliefs and preferences idea.
*  Well, I wrote four books on game theory.
*  It's a leading question. Yeah.
*  Yeah.
*  No, I think along with the rational actor model, it's one of the central tools for
*  behavioral science. Games used to be, well, it started out with von Neumann and
*  Morgenstern at Princeton trying to model war games.
*  And poker.
*  But the major development that happened in game theory, really in biology,
*  when Maynard Smith, John Maynard Smith and Price developed a game theoretic model to explain
*  fights among butterflies for mating space. And it developed into a whole theory of what's called
*  evolutionary game theory, which has, I think, the basis for the understanding of the dynamics
*  of behavior of animals and humans. So it's used all the time in economics and biology.
*  It's used all the time actually in political science.
*  Although there, I hope we get time, I'll tell you there's some really funny things going on,
*  applying it to things like voting behavior. But yeah, game theory is very simple.
*  It's decision theory with more than one decision maker.
*  In a situation where there are only certain things that the various decision makers know
*  about what the others are doing. It's like when you play bridge, you know, I have my hand,
*  you have your hand, and I can signal a bit what mine is, and you can signal a bit what your is.
*  But basically, we don't know what the other one's doing. All we know is we're all trying
*  to win the game. So in the game theory, you have players, it could be two, three, four, five, or
*  10,000. And each player has a strategy set to choose from. And when each player chooses a
*  particular strategy, there's a particular payoff to the whole to each person in the group. And
*  that's game theory. And, you know, I've argued, a lot of people argue that it's really the basic
*  language that can be used across all behavioral disciplines, whether you're talking about dung
*  beetles on cow patties, or you're talking about humans voting in elections, etc, etc. It's the
*  same thing. The game, it's got players, got strategies, players make choices. And the payoffs
*  depend on the various choices the players have made. Yeah. And that's game theory.
*  And I think that the one concept within game theory that will be helpful for the
*  best of the conversation is the equilibrium idea. I mean, famously, there's the Nash equilibrium.
*  So I'll let you say what that is, because I'm sure you understand it better than I do.
*  Okay. John Nash was this incredible, incredibly bright mathematician at Princeton. He had mental
*  problems, which really destroyed him for most of his life. But he invented as a young, very young
*  man, the concept of Nash equilibrium, which is the equilibrium of a game occurs when no player
*  has an incentive to change his behavior. So everybody, everybody then plays it, but they're
*  doing the best they can. Everybody's doing the best they can do. And that's called an equilibrium,
*  because nobody has an incentive to change. Now, when you learn game theory, you learn,
*  they tell you something like this, almost always, because I've taught graduate students,
*  and I know what they have learned. They say, rational players choose Nash equilibria.
*  Well, that's just false. I'm not going to go through it in detail, but it is just, that's absurd.
*  Now there are articles in the literature that show you clearly the prerequisites for saying
*  that players choose a Nash equilibrium, and they're extremely implausible.
*  So then you say, well, why do you say game theory is so interesting? Oh, by the way,
*  if you want me to give you an example, I will. Have you ever heard of flipping coins?
*  I have.
*  I flip a coin and you flip a coin. And I'm sorry, not flipping coins, flipping fingers.
*  You put out one or two fingers, I put out one or two fingers.
*  Oh yeah, sure. Good.
*  Right. If we both put out the same number of fingers, you win. If we put out different
*  numbers of fingers, I win. How do you play the game? Well, the Nash equilibrium is you play 50-50.
*  Half the time you put out one, half the time you put out two. That's Nash equilibrium. Problem.
*  If you are playing 50-50, it doesn't matter what I do. I can play all heads or all tails,
*  because it doesn't matter what I do. Moreover, you know that it doesn't matter what I do.
*  So there's no reason for you to do 50-50 either. You get it?
*  Yes.
*  When I tell this to my students, they complain to the dean.
*  No, I'm kidding. They don't complain to the dean. But here's the point. Now,
*  here's a very important point. I wrote a whole book on this called Game Theory Evolving.
*  In an evolutionary game, where people play the game over and over, and the people who do well
*  get to reproduce more, like in a Darwinian evolutionary sense, then the only equilibria
*  of that dynamical system is a Nash equilibrium of the underlying game.
*  And that justifies using game theory in situations where you've had social evolution.
*  Because social evolution will favor people who choose strategies which in the long run
*  lead to a Nash equilibrium in the system.
*  For instance, if you have a whole bunch of people playing
*  one finger, two fingers, throwing fingers, they will evolve towards 50-50.
*  In any one instance, it doesn't matter what they do. But the people who play 50-50 in the long run
*  do better. So they evolve.
*  And some of the subtleties here are because in various games, various different kinds of
*  payoffs you could get for making choices, there's more than one Nash equilibrium.
*  And you could get stuck. Because the definition of Nash equilibrium is that no one can unilaterally
*  improve their life by changing. But if you cooperate, if you're not competing,
*  then in principle, everybody could get a higher payoff.
*  Yeah. Well, no, anyway, you said this two different things. First of all,
*  there can be multiple equilibria. Now, some Nash equilibria will never be
*  attained in an evolutionary sense. They're just evolutionarily irrelevant.
*  Other times, there's multiple equilibria, and they have basins of attraction. And if you get into
*  one basin of attraction, you go to one equilibrium. You get into a different one, you go to another
*  one. So it's basic dynamical systems theory, how that might work out. The second thing is,
*  I don't know, there's not many situations where universal cooperation is a Nash equilibrium,
*  unless there are no errors. If people make no errors, then you can sometimes support,
*  you can't support a complete cooperation equilibrium in a game, just by making a new
*  game and saying, look, we'll all cooperate. If it ever one person does not cooperate,
*  then we never cooperate again forever. That's called a trigger strategy. And that's fine until
*  someone gets sick and they don't come to work one day. You say, okay, we can't cooperate anymore.
*  You didn't contribute. So if there are errors, then you have big complications, and the models
*  become much more sophisticated. And cooperation is almost never universal. Okay, fair enough.
*  But then there is this new idea that I found in your book, in one of your books,
*  which is that of a Kantian equilibrium, after Immanuel Kant and the categorical imperative.
*  Explain that to us. I don't think it's original with you, but it certainly changed my thinking.
*  No, in fact, the idea of a Kantian equilibrium is as old as Kant. I mean,
*  the categorical imperative really is a game theoretic concept which says, I will choose a
*  strategy which if everybody chose, we would all do really well or do best. And if everybody else
*  chooses that strategy, then we have a Kantian equilibrium. Now, the problem with that is that
*  may be true, but even if it still could be that I do better if I violate the cooperation. So for
*  instance, I go to sleep rather than go hunting with the other guys. So a Kantian equilibrium is a
*  moral equilibrium. Usually it says to behave morally, I should do X, Y or Z. And I was always
*  very suspicious of that idea, but I decided a few years ago that Kant was, he's right on target in
*  understanding human morality. For instance, let me give you an example. This is something which is
*  it's so pervasive that it's stunningly mind blowing. If you're rational according to the
*  rational actor model, you don't vote. You'll never vote. Why? Well, you say, well, if you care about
*  social issues, you'll vote. The only reason you might not vote is because you're self-interested.
*  No, it doesn't matter what you care about. No vote in a large election, an election of more than
*  40,000 voters. No vote has ever been determined by one person. Okay. So no individual has ever
*  determined the outcome of one of these elections. So when you go to vote, you know, the fact is
*  you're not going to change what happens no matter what you do. So why vote? Moreover, why even read
*  the newspaper about politics? It's a waste of time. You can't change the outcome of an election,
*  but people vote and they care about the election. And in fact, you know, I've done this.
*  I've done this stand in line while you vote. This is before the pandemic. Well, yeah. Stand in line
*  and tell you the person. Why are you here? Is it? What do you mean? Why I'm here? Because I'm here
*  because I want the John Smith to win. And I say, well, yeah, but you know, do you think your vote's
*  going to change the outcome? Oh, no, of course not. Well, then why vote? They say, listen to a good
*  answer. If everybody thought that way, we can't have a democracy. It's the Kantian move.
*  The Kantian move. Exactly. It's not just some highfalutin philosopher. It's deep in our souls
*  that this notion that we should behave in ways which if everybody behaved, we'd all be better off.
*  And this is the deepest moral principle of human life, I believe. And people obey it. They obey it
*  so much that they don't even know they're obeying it. If you ask someone, why are you standing in
*  line? They make it sound like they're going to change the election. Right. Right. So all I'm
*  saying is that we have these deep people make moral choices, which go way beyond the rational
*  actor model towards what I call a social rationality, which no one's really explored
*  that much except the part that I've been talking about, voting in elections. But the whole idea
*  that people are self-interested if they vote in an election is just inconsistent. You may vote
*  for your social group. If you're a union member, you may say, okay, I vote the union. That doesn't
*  make me selfish. If I was selfish, I wouldn't vote at all. Anyway, you get the idea.
*  I do. And you mentioned something very provocative along the way there, which is that people do it,
*  and you just gave a sort of justification for why they do it. But the people themselves aren't
*  necessarily good at giving that justification. I mean, I've heard-
*  Are not, excuse me?
*  Are not necessarily good at giving the correct reason why they are doing this thing that they're doing.
*  Oh, no. Of course not. Of course not. No.
*  Or even analysts online or in newspapers, when they say go out and vote, they don't really give
*  you the right reason to do it, right?
*  Well, they can. There's no right reason. I mean, there's an unanticipated notion of social
*  rationality, but it's so sophisticated that you can't give it as a reason. We're talking about it
*  now, but I swear to God, it took me five years before I understood it. I understood the idea
*  that people have selfish preferences and altruistic preferences, but it didn't occur to me for years
*  that people can have altruistic preferences, and still, if they're irrational, they won't vote.
*  Okay? It's very difficult. And by the way, some audiences never, I talked about this a lot.
*  In some audiences, they simply do not understand what you mean when you say you can't affect the
*  outcome of election. They immediately go to say, well, if everybody thought that,
*  we couldn't run a democracy.
*  Yeah, which is true.
*  Which is true.
*  But-
*  But-
*  So anyway, these are the deep issues that come out when you try to deal with nature of human
*  morality. It's deeply intertwined with the notion of rationality and choice.
*  The internet is a great place to find little nuggets of this or that, but sometimes you want
*  something more substantial, a little bit more sustained introduction to some area of knowledge.
*  That's why I love Wondrium. That's W-O-N-D-R-I-U-M. It's the streaming service that our brains can't
*  get enough of. There's so much to explore. I love it. If you're familiar with the Great Courses Plus,
*  then you already know Wondrium. It's the same great service, now bigger and better, with even
*  more hours of video and audio content, fascinating documentaries, helpful how-to's, and answers to
*  every question you've ever had. For example, as a change of pace, I've been enjoying The Real History
*  of Pirates, which is such a fun watch. If you've ever seen movies about pirates or been interested
*  in pirate legends, you'll love learning the truth about pirates. I know you'll love Wondrium, so I
*  put together a special offer for Mindscape listeners, a free month trial of unlimited access.
*  Just go to the special URL, Wondrium.com slash Mindscape. That's W-O-N-D-R-I-U-M dot com slash
*  Mindscape. Think of how much you'll learn in just one month. Go to Wondrium.com slash Mindscape.
*  Is it somehow too cheap to attribute this to the fact that we talk and reason as consequentialists,
*  but we act more deontologically in some sense, more rules-based?
*  Some people, I'm sure that's true of a lot of people, don't talk consequentialist at all.
*  About politics, no way. The biggest thing about politics, most people are not consequentialists.
*  They think they want to vote for what's right, or they want to happen what's right.
*  That could have any kind of consequences. I think people are fundamentally, in many ways,
*  not consequentialists. They don't think in terms of what the consequences are. They think in terms
*  of what's right and what's wrong. My own thinking about morality is undergoing a very gradual shift.
*  Way back in the days when I was a kid, I was absolutely a utilitarian consequentialist. The
*  more I think about it, the more it just doesn't work for a whole bunch of reasons. I'm not exactly
*  sure what I am. As a metaethicist, I'm a moral constructivist. I think that there's no objective
*  morality out there that we make it up, but I'm not sure what the best thing to make up is. My
*  understanding of what you're talking about is not even necessarily a way of saying, here's what the
*  best morality is, but just saying, here's how people actually behave. You're trying to be more
*  descriptive than prescriptive here.
*  Paul Jay Oh, yeah. Well, that's the difference between
*  a philosophical approach to morality in which people are searching for what is truly moral
*  and what is not, and a behavioral approach, which is just to say, how do people behave?
*  It's really interesting that people actually take morality seriously. It's not at all what the
*  philosophers expect. By the way, this is an interesting thing. Now, of course, the philosophers
*  are doing more behavioral game theory, and they understand what's going on. Perhaps I should give
*  you an example of a behavioral game. Would you like that?
*  David Kemp Yes, please.
*  Paul Jay Okay. Maybe you'll do more than one, but the simplest one is called the dictator game.
*  David Kemp Okay.
*  Paul Jay You can play it in the laboratory, although if I have time, I could tell you how
*  it's played out in the field, as well as the laboratory. The dictator game, there are two
*  players, A and B, and they never see each other. They're in different rooms. They never get together.
*  And the experimenter comes in and tells both of them, I'm giving B $10. B can offer anything
*  he wants to you from one to 10. If you accept the offer, we split the money the way he wanted.
*  And if you reject the offer, you both get nothing. I take the $10.
*  David Kemp I remember this one. Yeah.
*  Paul Jay Okay. So, what does the... And one of them is called the proposer. He's the one
*  who's going to offer the other one. That's A. And B is the responder. He's going to say yes or no.
*  Now, if both players are self-interested, player A will offer player B a dollar,
*  and player B will accept it. Why? Because otherwise he loses a dollar. Why do that?
*  And player A says, well, player B is self-interested. So, if I offer him a dollar,
*  he'll take it and I get nine. When you play this game, that has never happened.
*  And we've played it in societies, not only in Boston, Massachusetts, and Palo Alto, California,
*  we've played it in the Peruvian jungles, in the Mongolian highlands, in African jungles,
*  et cetera, et cetera. Nobody ever plays it that way. The most common offer is half. I'll give you
*  $5. And if you offer $3 or less in most societies, people will reject it. Not 100%, but enough so
*  you shouldn't do it. You should offer five. Now, if you ask a philosopher, what is going on?
*  Okay. What's really going on here? Why did someone reject $3? And the answer is because
*  he's pissed off at the unfairness of the proposer. And he gets more pleasure or satisfaction out of
*  depriving the proposer of $7 than he does about getting $3. And the less the proposer offers,
*  the wider the gap is. If he offered one, well, I lose one, but he loses nine.
*  So it's retaliation. It's revenge. Yes, that's what it is. There's another word for it.
*  Retribution.
*  Okay. What's the difference? It's revenge and retaliation. I've asked philosophers,
*  like the conferences, they say they don't know what's going to happen. They go all over the place
*  a little. What about economists?
*  Okay. So that's an example of how humans are not self-interested. In particular,
*  they like to hurt people who hurt them. What do economists say about this game? What is their
*  prediction? By the way, the economists would say $1, at least the traditional ones, but everybody
*  knows now that this has been done hundreds of times. So everybody knows that there's a
*  concept of fairness and that's what's going on. There's another game. I'll do this one. It's an
*  honesty game. There are two players, again, A and B, and they can't see each other. They can only
*  communicate as follows. A is given two piles, two boxes with money in it. And A can look in the boxes
*  and see how much money is in each box. And then A can say to B, either, B, please choose,
*  if you want the most money, choose box one. Or if you want the most money, choose box two.
*  And then B can either choose box one or box two. Now, if people are honest, then player A will say,
*  choose the box that has the most money in it. And B will say, well, we're all on it, so I'll
*  lose it. But why should A be honest? It's costless for him to say, choose box two. And then player
*  B should say, why should I think he's truthful? He's going to lie. But I don't know he's going
*  to lie because he knows I might think he might go to lie. Like Professor Moriarty and Sherlock Holmes,
*  you know. You can't tell what's right with the right statement. So it's a completely indeterminate
*  game. But when you actually play this game, almost always player A tells the truth.
*  As long as the splitting of the money is not too uneven, player A will tell the truth.
*  And player B will assume that player A is telling the truth. And so player A for telling the truth
*  loses money. And player B knows he's going to expect to lose money. There's complications on it.
*  But as you see, people don't like to be dishonest. Now, I should say when you play this game,
*  if the stakes are not the height of the stakes, it's not how much the stakes are, it's how uneven
*  it is. If it's very uneven, then player one gets pissed off and says, well, I'm going to lie.
*  And you get cooperation falling apart. So we play these kind of games all the time.
*  And they show the extent to which people are self-interested versus altruistic or that to
*  the extent to which they believe honesty is important, etc.
*  Well, and surely a lot of this is because human beings in the real world interact many,
*  many, many times with many people and develop senses of fairness and expectations. And even
*  when you put them in these isolated psychological tests, they're still going to bring those external
*  ways of thinking to bear, right? That's exactly right. I mean, we did the first,
*  I had a large project, it was funded by the MacArthur Foundation some years ago. And we have
*  16 anthropologists go to their countries that they work in around the world and play
*  things like the dictator game and the ultimate game and the honesty game, etc.
*  When the results came back and I was putting them together, the result was that people take their
*  values from their society, whatever they are, and they take them into the laboratory, even in
*  conditions of complete anonymity, no one will ever find out. And they behave in the same ways
*  as they do in their societies, very egalitarian societies. People play the ultimatum game,
*  which I haven't really, yes, I have. That's the ultimate, it was what I described, not the
*  dictator game. Excuse me. I described the ultimatum game, not the dictator game from the very beginning.
*  Okay. It was a shocker to me. It reminded me of the old sociologists, the brilliant sociologists
*  talk at Parsons, the values really matter. Values do really matter. Really, I mean,
*  there are societies where, for instance, people do cooperative hunting, like for instance, the
*  Lamalera in the Pacific who hunt whales, they hunt together in a big boat. And they split it up
*  in a very egalitarian way. When they play the game, they do what's called hyper fair offers.
*  Player A, when he gets $10, he offers the other guy $8. And if he offers them too much, the other
*  guy rejects it. Can you believe that? Why? Here's why you ask him, why did you reject $7?
*  In the ultimatum game, well, he thinks he's a big shot. He's going to give me money now. He's
*  coming to some money. It's going to make me feel so bad, humiliated. Screw him. So you get all sorts
*  of behaviors that express the variety of human morality. And so, I mean, again, it's a completely
*  convincing case, I think that human behavior can be thought of as rational in this sense of beliefs
*  and preferences, but the rationality is not purely self interested. There is this social
*  rationality aspect. So let's then ask, why is that the case? Right? I mean, let's get into the issue
*  of how we evolve these particular sets of behaviors. Yeah. Boy, you ask hard questions.
*  You wrote the book. Well, you know, one thing that I should say from the beginning is,
*  I not only believe you have to integrate the behavioral sciences better, that is so where they
*  overlap, they agree. People should know more of the other sciences. So for instance, over the years,
*  I've taken upon myself to learn all of these disciplines. I mean, I'm an old man now. I've
*  learned a lot of disciplines, including anthropology. So for instance, I have a long article in the
*  evolution of human socio political systems. It was a lead article in current anthropology a couple
*  of years ago. And so I went through exactly this question. Now, it's a very difficult question.
*  But the point is that it's a long story, I think, but I think I worked some of it out. The first
*  thing you have to understand, I think, is this. The common ancestor of all the primate species
*  was almost certainly a multi male, multi female group in which you had promiscuous relations,
*  no pond bearing all males, females were accessible to all females, or at least random parts thereof.
*  And male hierarchy that is run by an alpha male, just like chimpanzees are today. But when humans
*  came along, the first split between hominids and the other primates, the humans had to cooperate a
*  lot more because they were doing cooperative hunting. And they developed tools. Now, what tools
*  throwing tools, they had bats, and balls, and not arrows that came 20,000 years later or more,
*  much more. And when they became very good at using these tools, you couldn't support a hierarchy
*  anymore. You couldn't have an alpha male take over because he's the strongest, because when he goes
*  to sleep, you can kill him. I know it sounds silly, but think about it. Chimpanzees can't throw,
*  or they can, but they can't hit anything when they throw. And when they fight, they fight with their
*  hands. They don't fight with any tools of any kind or weapons. And it takes a very long time for
*  even three chimpanzees to kill a fourth one. But once you get an accurate weapon,
*  you can kill a guy in his sleep. So you can't maintain a hierarchy based on power.
*  And human societies move towards cooperative leadership. It's called reverse hierarchy
*  by Chris Bohm, who has worked on this anthropologically. That is, people choose
*  their leaders, and they choose their leaders according to their ability to promote the
*  values and the fitness of members of the group. But once you do that, then you move towards having
*  language, because people have to make promises to each other. And you have the whole development
*  of the vocal system of humans, which by the way, is not just cognitive. It's not just you got a big
*  brain. It's you have incredible musculature. You have the larynx, which allows you to speak,
*  etc. So the upshot of this is there's a lot of cooperation in small scale hunter-gatherer societies.
*  They're not run hierarchically. They're run democratically. And in that situation,
*  there's a huge benefit to cooperation, which pays off for the individual, because they're
*  rewarded by other members of the group when they behave in a cooperative way. And they're ostracized
*  when they behave in a non-cooperative way. If you want to read about this, go to my website,
*  look at some of the references. But I think that's really it. Human society is very, very, very
*  singular compared to, I think, other social species in that regard.
*  So to dramatically oversimplify, you're saying that the invention of weapons
*  led to the invention of language.
*  Yeah. Oh, yeah, absolutely. It can't be great, because the way you defeat
*  a person who has a good mind and can speak it, is to have a good mind and speak it.
*  Interesting.
*  You can't just bash them over the head, because that doesn't give you… the group won't elect
*  you their leader, because you bashed the leader over the head. If you have better ideas.
*  And this is…
*  And by the way, this goes on right up to almost the present. The foot soldier, people talk about
*  who wins wars. Well, the answer is foot soldiers win wars. It's a society that's been in the
*  wars. It's such a shame the United States lost in Vietnam, it lost in Iraq, right today as we're
*  speaking, it lost in Afghanistan. In all cases, it's not the item bombs and the big bombers and
*  the tanks, it's the foot soldier. Okay? So these weapons, the democratic weapons have been a very
*  important source of basically democratic success. That is, in the Second World War,
*  the cavalry's lost, and they lost out to the foot soldiers with small caliber weapons.
*  That gave rise to a strong push for democracy in… after the First World War.
*  Anyway, yeah, I think weapons are very important.
*  Well, and this is an example, especially because as you mentioned, we had to literally change
*  the biology of our larynx and our vocal cords and so forth. So this is an example of gene,
*  culture, coevolution, right? I mean, one of the one of the…
*  Right, exactly.
*  …emphasis you get from your book is some kind of evolutionary psychology
*  plays an important role here, right?
*  Right. No, it's very… when you really think about it, it's very dramatic, the idea that…
*  I mean, notice first, the reason that chimpanzees can't speak is not because they're stupid.
*  They can't produce the sounds. Chimpanzees can go,
*  they can make about six or seven sounds, but they don't have the muscles in the tongue and in the
*  cheeks and they don't have the larynx low in the throat that allows them to articulate the way
*  the humans can. And that could only have developed because people who could communicate that way
*  were valued and were given more opportunities to have offspring who had also those characteristics.
*  So when people say language is because people have big brains, that's just not right.
*  Yeah.
*  People have language because of gene culture revolution. Here's how it goes. You have a
*  little bit of communication and people care a lot about it because they need to communicate
*  to figure out where to go to find the next profitable location for hunting and gathering.
*  And so they reward people who have a little bit of ability to communicate. That gives rise to
*  genetic changes that make people more capable of communicating verbally. And that leads to
*  more cultural dependency because people use communication more in their deliberations.
*  And so you have a circle of genes affect culture and then the culture promotes
*  more genetic behavior. This is only true in humans really because humans only have
*  cumulative culture. That is where from one generation to the next, you maintain a body
*  of knowledge and pass it on. In animals, animals have culture, but they don't have very much
*  cumulative culture. If birds learn how to open milk bottles, one generation learns how to do it.
*  After a while, they forget, it goes away. It's not cumulative.
*  Yeah. From a physics jargon perspective, this invention of cumulative culture was absolutely
*  a phase transition in how not only how we behave, but how we evolve for the reasons you just mentioned.
*  I mean, very tangible differences in how our genomes evolve over time.
*  That's right.
*  Exactly.
*  But it does also get us into yet another hot button issue, which you have to talk about,
*  which is the group selection controversy. As you already mentioned, a while ago, there's this sort
*  of standard belief in certain corners of evolutionary biology of inclusive fitness. I would
*  sacrifice my life for two siblings or four cousins or whatever, but the idea that there are groups
*  that are attached to each other in evolutionary ways without necessarily being kin is a controversial
*  one. Right. Well, I've written a lot about this. I have a lot of supporters in the biology community,
*  including E.O. Wilson and Martin Novak and other people. Also, it's a very ideological dispute
*  and a lot of population biologists are pure inclusive fitness supporters, and they're wrong.
*  I mean, it's just wrong. But I'll tell you what's really going on. What's really going on is there's
*  this guy, William Hamilton, who is a brilliant biologist, and I loved his work and I love his
*  work, who developed the concept of inclusive fitness, which says we shouldn't just be self-interested
*  we should try to promote our genes wherever they are in other people. So we should help
*  relatives. That's what you said, Sean. Right. The problem is this. The model that he built to show
*  this is a single locus model. That is, you have a genome. Your genome has 23 chromosomes,
*  and there are all sorts of genes all over it. His theory is what happens exactly at one locus,
*  one chromosome and one gene at that locus. It's not about all of the loci. It's about single ones.
*  Now, the problem is this. What they say in the literature is, oh, we'll assume that
*  it's additive across genes. That is, genes don't affect each other, but they each
*  follow the same inclusive fitness rule. That is, act as though as to maximize your relatives
*  at that locus. But the problem is the different loci have different interests.
*  So I may benefit by helping you at a different locus, or I may benefit by suppressing you.
*  Suppose at locus A, you're producing a poison that helps you as your gene, but it hurts the
*  rest of the genome. Well, the rest of the genome is going to develop mutations to suppress that gene.
*  Conclusion. That's why we have what are called mesomorphs. That is, multi-genetic organisms,
*  because the genes affect each other. They're not there side by side. They're affecting each other.
*  And when they affect each other, inclusive fitness no longer works. Now, what I can say is you get a
*  complex evolutionary dynamic in the genome that's well developed in the literature.
*  You can read, oh my, people are interested, go to my website and look up sociobiology and look at the
*  various entries on inclusive fitness. So there is this debate. And it's actually,
*  it's very interesting. It's amusing. Martin Novak and E.O. Wilson and a co-author, Cornita,
*  published an article in Nature, I think, or science. I forget what, Nature, I think. I'm not sure.
*  Sowing that inclusive fitness doesn't work. And the response was 127 biologists
*  sent a letter to Nature saying this is wrong. Yeah, I remember.
*  You remember that? I was appalled. I said, and the first paragraph,
*  their letter is just wrong. It's just wrong. So when I see biologists at conferences, I say,
*  you signed this. Why did you sign this? This is just wrong. You don't believe this, do you?
*  I say, well, you know, so we all signed it. And it's crazy. By the way, this reminded me,
*  you may have seen this. After Einstein developed his special theory, there was a book written in
*  German called 100 Authors Against Einstein. And they asked Einstein, sir, what do you think of
*  this book? 100 Authors Against Einstein. And he said, well, if I'm wrong, one would be enough.
*  You ever heard that? I have. I have. But I mean, just to be fair to the 100 authors here,
*  I mean, what was the argument against the Wilson and Novak and Tarnita, I think, paper?
*  Oh, I think some of the arguments were, I think, correct. But, and I don't think their article
*  was the last word on it. I think my article is the last word. I actually, believe it or not,
*  I presented this article. I just laid out kind of argument for you. I presented it at Oxford in the
*  biology department, which is the hotbed of inclusive fitness theory. And people were very
*  nice. So it's okay. The whole idea is this, you see, if inclusive fitness were true, it will be
*  wonderful because there's no complexity. There's no evolutionary dynamic needed. It's just one
*  little equation. It's linear. Which says something like B is greater than RC or BR is greater than C.
*  But it's just not that way. You have social species that are incredibly complex and diverse.
*  And they can't explain them in terms of inclusive fitness theory. Now, let me say one final thing
*  on this. Group selection, the notion of group selection, when people talk about it, they reduce
*  it to groups competing with each other. Group competition. Even John Maynard Smith did this.
*  But that's not right. When you say that a certain thing is selected, it doesn't mean it's selected
*  through competition with others. For instance, if I can escape a fox, that is a fitness enhancement
*  for me. I don't have to fight with another one of my species. I don't have to say, well, you know,
*  I have to fight with you. You just can't run as fast as I can. So I beat you. Similarly, group
*  selection in general means that the evolutionary dynamic is favorable to the evolution of groups
*  with certain social interactions. That's all. How it works inside is extremely complex and we don't
*  understand. We don't really understand social species. We know a little bit about them. But
*  there's a lot we don't know. All we can say is they evolved probably because there was some
*  benefit to this particular social organization of that species. So for instance,
*  bees are incredibly social. They're not highly related, by the way. This is a myth.
*  One queen and they're all the offspring. No way. First of all, queens die all the time. Some
*  species of social species of bees have six or seven queens and they can have many males.
*  So the genetic, this is technical literature, but if you measure the relatedness of workers
*  and some species of bees and wasps, they're actually quite low. They're almost to the level
*  of being no relation at all. And they still have incredible levels of cooperation.
*  So I'm not saying inclusive fitness theory is silly. It's very, very important. And it explains
*  most of what happens. But it doesn't explain social species. It explains what happens in
*  basically non-social species. Right. So we have this development of sociality once we had weapons
*  and then language. And that sort of has influenced how we play our games, how we think rationally,
*  become social rationality. And there's obviously a million places to go here from here, but
*  let me home in on one thing that you say, which is very provocative, the idea that
*  we evolve both a private and a public persona. Right. I mean, and presumably this is unique to
*  social species, right? I mean, my cat doesn't have a private and public persona. It's more
*  or less the same cat, no matter what is going on. So can you say a little bit more about what these
*  persona are and the roles they play in our game making life? Yeah. By a private persona, I mean,
*  in daily life, we go around doing our business without great concerns for how the whole society
*  works, what the rules of the game are, how I relate to the larger public, et cetera.
*  What we're doing now is my private persona. I'm just talking to you about stuff and you're going
*  to put it on air and it's not going to go public. I hope you know.
*  It's going to go out in the public. I hope you know. Yeah. That's why I'm talking to you.
*  Okay. So a public persona and in your private persona, you're not asked
*  to evaluate the impact of everything you do on everything in the world around you. Right. You
*  go to the supermarket, you buy eggs and they're your eggs. You're not concerned about the egg
*  industry or the farmer's profit or the chickens usually. Now that's changed. Now we only buy
*  free range chickens and this and that. But the public persona, you automatically enter a different
*  frame in which you're thinking as a Kantian categorical person and you're talking about
*  what's right and what's wrong. Who do I support and who do I not support? What values do I accept
*  in the large and which do I not? And you get a very different dynamic. For instance, one that
*  supports what I call social rationality as opposed to individual rationality. And people do both all
*  the time. Yeah. So you move from one to the other. Now a lot of people never enter the social realm.
*  They, you know, I mean, I know people, they just never think about anything except, you know,
*  what's happening today and what are we going to have for dinner? And there are a few people in
*  the other. They're insufferable. All they think about is everything they do has this deep social
*  meaning. So, but most people are in the middle and I have a typology on that which I've shown you.
*  There's homo socialis, homo universalis. Homo universalis is the public persona,
*  which is Kantian. That is, I do what I think is best for the world as a whole.
*  I forget the names I used even. Parochialis. Yes. The parochial is I do best for my group.
*  Hmm. I vote for my group. I support my group, whatever that group is. And that is not a selfish
*  behavior, by the way. Right. It is a support for a particular social group. So the public persona
*  isn't just what we do that is visible to the public, but what we do that is taking the public
*  into consideration in some sense. Right. From that perspective that humans have that they can
*  they can adjudicate and act on the rules of the game, not just play within the rules of the game,
*  but they can act on the rules of the game. So and they're very different. Hegel had,
*  I really got that from Hegel, who talks about exactly that.
*  Now I should say one more thing that I think is really interesting. It's the term that I coined
*  about the year 2000 called strong reciprocity. What is strong reciprocity? Well, we have to start
*  out this about humans. We have to start out with reciprocal altruism by the great biologist Robert
*  Rivers, which is some animals and humans, I scratch your back, you scratch my back. So we're a
*  mutual, it's a mutualism. But what I what we found out for humans is another thing where people
*  spontaneously help others without expecting anything in return. And they spontaneously hurt
*  others without expecting anything positive in return. They simply do it because they feel like
*  doing it. Let me give you an example, a few examples. This, by the way, is really big.
*  I'm at the airport and I want to get to a certain aisle or certain exit. And I stop someone in the
*  airport and I say, how do I get there? And they stop and they tell me, why do they do that? They
*  don't know me, they're never going to see me again. Why would they ever open the door for me?
*  If I have a package when I'm going into a building, that's what I call the strong
*  reciprocity cooperative. That is, people act like they would like to be treated themselves.
*  And by the way, this is a big deal. And they don't even care about you. Sometimes when I was a kid,
*  I used to drive a truck, deliver furniture in Philadelphia, this is way before there were GPS
*  systems. So if I had to find the street, what can I do? Stop and look on the map for five,
*  you know, for 20 minutes. No, I stop and I ask, how do I get to the street? Half the time,
*  they always answer and half the time it's completely wrong. So I was only 17, but I
*  developed a con. I said, okay, I'm going to invent a street, Jalopy Street. There is no Jalopy Street
*  in Philadelphia. And I went out and I fit my truck with my furniture in it. And I stopped some guy
*  and say, hey, where's Jalopy Street? Well, you go about three blocks off into the church,
*  you know, turn right. Now, that didn't help me at all. But it made him feel real good. He's helping
*  out there, you know. So that's the one side. The other side is even more interesting, which is the
*  negative side. People love to hurt people who hurt them. Go to your sociology book and see if you can
*  find the word retaliation or vengeance in the index of your sociology. It's not there. It's
*  treated as a, what do you call it? It's treated as an abnormal behavior to one vengeance and
*  retaliation. But it's one of the basic human behaviors. We do it all the time. People love
*  to hurt people who hurt them. I remember, of course, we do a lot of experiments to show this.
*  And this is really what's going on in the ultimatum game, where a guy rejects a positive offer. He
*  gets pleasure out of hurting the other guy who we thought wasn't dealing with him fairly. So I
*  used to tell my students, look, there are two kinds of movies. There are love movies and there
*  are revenge movies. The love movies, we all know love is human and we love each other. The revenge
*  movies, the guy like Arnold Schnurznager gets, his family gets hurt in the beginning and the rest of
*  the movie goes around killing everybody in spite. I mean, you come out of the movie and you say,
*  oh, that was really interesting. I feel really good about that movie. People love to reciprocate
*  evil with evil with no gain in mind. And the thing that's important about that is that this
*  is a major reason you have social stability. It's not governments. Humans didn't have governments
*  until a few thousand years ago. There were no governments. There were no jails, hunter gatherer
*  societies. All they could do is punish you or ostracize you. And there were no judges
*  there were no policemen. So strong reciprocities were kept things going. People helped those that
*  they thought were being nice and hurt those of being not being nice. Again, this is human behavior
*  that we discover in the laboratory that really nobody ever talked about. I got the notion because
*  of an experimentalist is a wonderful experimentalist Ernst Fair in Zurich.
*  But so this is what we do. We play games in the laboratory or in the field. So for instance,
*  the ultimatum game people said about the ultimately, okay, who cares about $10. So people,
*  it's a little bit of money. Okay, let's go to a society, a poor society, get farmers who make
*  about $300 a month and play the ultimatum game for $900 or $1,000. There you'll see whether they
*  accept. You know what happens? Nothing different. They still reject three, they'll reject a month's
*  wages. Wow. Well, I mean, this is clear that you've already made this connection with that. Let's just
*  draw it out because it's so important because what you're getting at is the idea that these
*  kinds of socially motivated behaviors, even taken and abstracted outside of an explicitly social
*  context, can be derived or thought of starting from these principles of some kind of rationality
*  played out by a game theory. I think that probably a lot of people have this idea that once you start
*  talking about rational actors and game theory, you're going to end up with selfishness and
*  individuality. But you're getting from there to social behavior in a very connected, entangled
*  kind of way. Oh, absolutely. That's the beginning. When Darwin did his stuff, people said, oh,
*  it's nature, tooth and claw, red in tooth and claw. It's all about competition. But for the
*  past hundred years, almost, it's been about cooperation. That's what really works well.
*  And Sam Bowles and I, when I co-op is we wrote a book called The Cooperative Species,
*  A Cooperative Species, explaining how human cooperation evolved. Now part of that is
*  cooperation evolves because hunter gatherer groups make war against each other. And to make war,
*  you have to cooperate. Non-social species do not make war. Only social species can make war,
*  like ants or humans. So yeah, we're all about how evolution develops not only conflict and
*  a struggle, it also explains cooperation. Well, maybe this is a good place to give you the final
*  question, final issue anyway to talk about. Because I always say it's the final question,
*  but then follow up sometimes happens. So the final thing to talk about, I'll give you a softball,
*  I'll give you an easy question. You've mentioned how these different disciplinary approaches end
*  up talking about human beings in very different ways, and they should talk to each other more,
*  etc. So how do we fix that? How do we fix academia and our intellectual lives so that these ideas are
*  not siloed so strongly that we don't even talk to each other anymore? Well, the first thing
*  to note is there are two really important developments to notice. One is if you look at
*  scientific results in the behavioral sciences, they have been interdisciplinary. As people who
*  have approached things, for instance, in epidemiology, it's not just microbiology,
*  it's also social interaction. So the whole theory of viruses and their spread, epidemics, etc.,
*  involves both sociology and microbiology. So the gain from doing these things in a more
*  transdisciplinary way is very high. Now, for me, the second thing has been the internet.
*  When I was younger, I still thought the same way, but I'd have to go to the library at Harvard,
*  Widener Library, and I was very strong. I take out journals and bring them home,
*  piles of journals, but it still took weeks to do anything. Now with the internet, I can learn a
*  new subject in a year without any problem. Now, I must say I'm now working on physics,
*  and physics is harder than some of the other subjects. It's taking me five years so far,
*  but I think the internet has made all the difference in the world in the ability to
*  gather information from all over and to talk to experts in fields that are not your own
*  and places far away from you. So I think it's happening, and there are examples of it.
*  For instance, the University of Arizona is organized in an interdisciplinary way,
*  and I think it's been very successful. Now, what else can I say about that?
*  I think that's about it. I will say that for young people, when you start out, you have to
*  go into a particular discipline, and you have to really learn it very well before you
*  can branch out. But I had the idea a long time ago of setting up a school where the first year,
*  for behavioral students, people are studying behavior of life forms. The first year,
*  you all learn the same thing. You learn statistics, you learn mathematical model building,
*  you learn the scientific method, and then you learn the basic core of every one of the
*  fields, psychology, sociology, political theory, economics, anthropology. Then in your third year,
*  you start specializing on what you want to do. I think that's not a bad model,
*  so that's all I can say. Now, I should say this. There's also a political problem. For instance,
*  I have found very high levels of political ideology tainting people's judgment in almost
*  all of these fields. For instance, sociologists tend to be extremely liberal, as far as I know.
*  I joined the ASA for a few years, and it felt like I was back in SDS in 1968 or something like that.
*  Support the workers at the school such and such, and this and that. Anthropologists have gone into
*  what's called postmodernism, which is a denial of the importance of science. You probably have
*  experience with that. I've done a lot of work in anthropology with my co-authors.
*  It's very hard to get anthropologists to think scientifically. It was very hard for us to get
*  funded by the NSF because they run their proposals through a council of anthropologists.
*  Anthropologists don't like to go in there and experiment on the simple society people.
*  I've published a lot with Princeton University Press. I think it's a very good press.
*  But when we submitted our anthropology book to them, which is called 15 Small Scale Societies,
*  the anthropologists wouldn't type it. It got published by Oxford. There's political stuff
*  all over the place. It will take a long time, but I think it's very interesting that scientists
*  talk about being interested in getting the truth, but when they disagree with each other,
*  if they're not in the same field, who cares? Forget about it. I think that's a very strange attitude.
*  Your mention of the funding situation is also important. I think a lot of people give lip
*  service to being interdisciplinary, but they only have finite resources. They're going to
*  partial them out to the people who do things that they feel comfortable with.
*  Right. I'm sure, but why don't they feel comfortable with doing game theory in 15
*  small scale societies? Well, one person did. A senior NSF guy, and he pushed through
*  the funding that we needed to actually carry out these experiments. It was a few million dollars.
*  And it's still very difficult. Interdisciplinary is very difficult. And people think interdisciplinary
*  means, well, you just combine the wisdom of the different disciplines, but that's false,
*  because the wisdoms don't agree with each other. They don't add up. They are contradictory.
*  I've done that in two books. One book, Game Theory Evolving, I said, what does economics
*  have to change in order to be compatible with sociology and political theory and psychology?
*  In my last book, which is called Individuality and Entanglement, I asked mostly the other question.
*  That is, what do the other disciplines have to do to be compatible with economics? But I think
*  there's a lot more work to be done in these areas. Well, that's always a good place to end. There's
*  a lot more work to be done. I'm hoping that a lot of young people are listening here and being
*  inspired. You've given good advice that it's good to learn a discipline and master it before
*  moving on to learn many more. Oh, yeah. Not only because you need to get a job, but also you have
*  to get really deep into a subject to know what's going on. If you've never done that, if you're
*  taking up the philosopher's road, you're not going to be able to deal with the intricacies of
*  particular disciplines. You need the zitsflex of working out one particular one. I'm tempted to
*  defend the philosophers here because they get into the nitty gritty of their own individual issues
*  more than any other field that I know about. I know. I read a lot of philosophy of physics,
*  and I think a lot of people are very, very good at it. But I must say, I'd rather spend my time
*  learning a standard model. Fair enough. I cannot. Reading more philosophy. I cannot argue with that.
*  Herb Gintis, thanks so much for being on the Mindscape Podcast. This is a very eye-opening,
*  thought-provoking conversation. Okay. It's been fun. Thanks, John.
*  you
