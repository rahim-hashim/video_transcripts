---
Date Generated: June 07, 2024
Transcription Model: whisper medium 20231117
Length: 4919s
Video Keywords: []
Video Views: 13667
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2023/01/30/225-michael-tomasello-on-the-social-origins-of-cognition-and-agency/

Human beings have developed wondrous capacities to take in information about the world, mull it over, think about a suite of future implications, and decide on a course of action based on those deliberations. These abilities developed over evolutionary history for a variety of reasons and under a number of different pressures. But one crucially important aspect of their development is their social function. According to Michael Tomasello, we developed agency and cognition and even morality in order to better communicate and cooperate with our fellow humans. 

Michael Tomasello received a Ph.D. in experimental psychology from the University of Georgia. He is currently the James Bonk Professor of Psychology & Neuroscience and Director of the Developmental Psychology Program at Duke University. He is a fellow of the National Academy of Sciences and the American Academy of Arts and Sciences. Among his awards are the Distinguished Scientific Contribution Award from the American Psychological Association, the Wiley Prize in Psychology, and the Heineken Prize for Cognitive Science. His newest book is The Evolution of Agency: Behavioral Organization from Lizards to Humans.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll

#podcast #ideas #science #philosophy #culture
---

# Mindscape 225 | Michael Tomasello on The Social Origins of Cognition and Agency
**Mindscape Podcast:** [January 30, 2023](https://www.youtube.com/watch?v=083w7Q1RayA)
*  Hello everyone, welcome to the Mindscape Podcast. I'm your host, Sean Carroll. You are of course
*  listening to a podcast at this very moment and there's a lot of podcasts out there in the world,
*  you might have noticed, doing very different things, different kinds of approaches, different
*  kinds of subject matter. Here is something common to all of the podcasts that I know about. They are
*  produced by human beings. There are no non-human animals that have their own podcasts, at least
*  not without help from regular old human beings. There's something special about human beings,
*  something that makes us different from other animals. And I say that with great caution
*  because of course there's an enormous amount that is common between human beings and other animals.
*  And you have to say other animals because we are animals. We are part of that heritage,
*  we share enormous amounts of DNA and functionality with other animals, especially the great apes,
*  our closest genetic relatives. But also we are different in some ways. So I think it's easy to
*  overemphasize either the similarities or the differences. There's a spectrum but we're at one
*  end of the spectrum. And so rather than just saying we're the same or we're different,
*  the interesting thing is to see exactly how we are and compare it to exactly how other animals
*  are and tease out both the similarities and the differences. So one of the leading researchers
*  in this area is Michael Tomasello, today's guest. He is a psychologist, probably if you had to pick
*  something, that's what you would call him. But if you look at his academic appointments at Duke,
*  where he is located, he's in the psychology and neuroscience department, also in the evolutionary
*  anthropology department, and also in the philosophy department. So he is spanning these different
*  areas. And one of the great things about Michael's work is that it's very empirical. He's doing
*  experiments and he's doing experiments comparatively between great apes and human beings, especially
*  young human beings you might expect to have the most in common with our primate relatives. And he
*  has a theory, he has lots of theories, he has lots of ideas that he's exploring, but he cares about
*  what makes human beings different. And he puts his finger on our sociability, our ability to have
*  social interactions of a particular kind. I mean, you remember we talked to Adam Bulley very recently,
*  and he and his collaborators have this idea that our ability to imagine the future and do mental
*  time travel is crucial to what makes humans different. And I think that that absolutely is
*  a plausible theory, but then what are the ways in which we become different? And so Michael Tomasello
*  wants to say it's how we interact with each other. Of course, other animals also interact and have
*  social webs in which they move, but there is something about human beings that enables
*  cooperation, morality, obligation in ways that seems to be special. His new book is called The
*  Evolution of Agency from Lizards to Humans, and he points out right in the podcast that the word
*  lizards is very intentional there in the title, because usually his research does not involve
*  lizards, doesn't go back that far. But there is some idea that agency, the idea of a person being
*  able to act for reasons has evolved over a very, very long time. And that's part of what makes us
*  special, that sort of intersection and interplay between individuality and the group dynamic and
*  how we come together. So lots of good stuff from one of the leading thinkers out there. Let's go.
*  Michael Tomasello, welcome to the Mindscape Podcast.
*  Yeah, hi, Sean. Thank you.
*  One of the things I love about your work is that you're interested in the differences
*  between human beings and other great apes. And therefore you study both. You study children in
*  development and also apes. So tell us a little bit about the methodology of doing those things. I
*  presume it's very different. And are you ever very surprised by similarities or differences that you find?
*  Well, I think one of the reasons that people find the work interesting is because we're always
*  thinking about how we're similar to animals and how we're different. The ancient Greeks already
*  thought like that. And I know from talking to non-academic friends and stuff, people find it
*  interesting. What do chimps do that's similar to us? What do they do that's different? So I think
*  it's kind of inherently interesting. So that makes it a little bit easy to sell. So in terms of
*  methodology, it sort of started out where we would do a study with kids and we'd say, well, let's try
*  it with chimps also. And there would be two different studies. And we started with gestural
*  communication and we looked at chimps for things that look like kids' gestures, like maybe like
*  pointing or something like that. And then, you know, I don't know exactly where the idea came from,
*  but I said, well, let's just, you know, put them in exactly the same situation as much as that's
*  possible and see what happens. And we used a metaphor at that point. Let's turn up the microscope,
*  you know, meaning from the beginning, make them as similar as possible.
*  And I knew from the beginning that there's a whole contingent of people out there who really
*  don't like saying how great apes are different from humans. They want to stress how similar we
*  are. I'm an evolutionist. I take similarity for granted. I take continuity for granted.
*  We're only six million years separated from them, 10 fingers, 10 toes. I mean, you know,
*  we perceive the world the same way, you know, interact with one another in lots of similar
*  ways. So I take similarity for granted, continuity for granted. But people don't want to see any
*  differences at all. And my colleagues like Franz DeWall and Christoph Bosch, who are always
*  stressing similarities, I say, okay, if you don't like my story, please, you know, tell me a better
*  story about what makes humans different. And, you know, I mean, we have basically won the large
*  mammal competition, all the other large mammals are under our control, we can wipe them out or
*  keep them alive as we please. So there must be something going on. And all I can ever get out of
*  them is language. But I have a whole book trying to show that language presupposes a lot of social
*  cognitive things, a lot of theory of mindy kind of things, a lot of cooperative, we share information
*  with one another cooperatively, in a way that other apes don't. I tell you stuff for your benefit,
*  I share stuff with you just to share it, just gossiping and whatnot. So there are different
*  social cognitive mechanisms, different motivations underlying language that are much deeper. And
*  that's where I get to the shared intentionality business. And language is an outgrowth of that.
*  So anyway, the whole point of going off on that little tangent was to say that those people,
*  I knew they would criticize the experiments for not having exactly the same methods,
*  because they can't be exactly the same. Yeah. All right. And so we did, every time we design
*  one of those studies, we did our very best to make them the same. And then in addition,
*  we had control conditions. And this is really important because some of the, I mean, control
*  conditions are a basic part of science from introductory class on scientific methods. But
*  Christoph Bosch in particular, who's not an experimentalist, but is a field worker,
*  has never appreciated, for example, people say, well, there's a human experimenter,
*  and that matches the species of the children and it's a different species for the chimps.
*  But we might do a study where we, like if we're gonna hide some food from the chimps,
*  and we kind of maybe lift it up a little bit or we do something, and then they find it.
*  Then we point to it. This is one of the places where they surprisingly fail. And we point to it
*  like this, and they don't find it. Well, the human experimenter was the same in both the
*  control condition and the experimental condition. So if it was gonna affect it, it would affect them
*  in both. And then on top of it, children find it, that particular test, just as an example,
*  they find it quite trivially easy from infancy. So this is what I call a good negative.
*  Because as we know in science, negative findings, meaning a non-finding, not different from chance,
*  could be due to anything. And so you don't know. But what I call a good negative is that the chimps
*  pass a control condition that's very similar to the experimental condition, that's only a
*  little bit different. And kids, in the same, as close to the identical methodology as possible,
*  they pass. And that to me sets the chimp failure in the key condition in a, it makes it a meaningful
*  fact. It's meaningful that they don't do it. So you asked me about the methodology. So I was
*  just saying, we try to make it as similar as possible. But of course, it's not identical.
*  But then we try to take care of that with control conditions. And we see if human children can do
*  the same thing. We did have friends to wall on the podcast. And it is fascinating research. But I
*  take the point, we're always slightly amazed when we find other primates showing empathy or altruism
*  or something like that, that we think about as quintessentially human, and we emphasize the
*  similarity there. But in some sense, there is something obviously different. There are no
*  chimpanzees who have podcasts or who use laptop computers. So there's clearly a question to be
*  addressed here, right? Every species, by definition, every species is unique in some way. Yeah,
*  right. So we're not saying anything. And humans would seem obviously, you know, we have skyscrapers
*  and podcasts and computers and language and social institutions and universities and governments and
*  mathematics. And so, you know, we are clearly what makes us different is clearly some kind of
*  cognitive thing. But at the same time, part of my shtick has been that the really unique cognitive
*  part is intimately bound up with the unique social part that what we do is put our heads together
*  with others. And from my very earliest things, I've used the thought experiment of the child
*  on a desert island who grows up without any other human beings from birth with no other human beings,
*  what mathematics would they invent? I feel like they would do pretty much what chimps would do,
*  right? So chimps can already quantify things and tell which one has more and things like that.
*  What would you invent on your own beyond that? Well, certainly, you know, maybe little, I don't
*  know what, but certainly not algebra, let's put it that way. And would you invent a language by
*  yourself? That makes no sense. There's nobody to talk to. You wouldn't invent a language by yourself.
*  And you certainly wouldn't invent a social institution or any of this complexity by yourself.
*  So this is the key diagnostic feature is that humans are not doing this based on individual
*  brain power. They are adapted to leverage, to use that metaphor, to, you know, what other people know
*  and collaborating with others and communicating with others and socially learning from others.
*  And of course, culture is built up to actually teach others. And so that's really the difference.
*  So if you raise the chimp on a desert island and the kid on a desert island, they wouldn't end up
*  that different. But humans are adapted. But then you raise a chimp in a human culture, which people
*  have done in various ways. And they maybe are, you know, a little bit different, but they're
*  pretty much still chimps and kids in a culture are, you know, doing all these human like things.
*  So clearly there is so I mean, let's just let's just get the claim very, very clear.
*  Other great apes, which means I guess what chimps, orangutans and gorillas, is that right?
*  And bonobos.
*  And bonobos, right. So they have some kind of social skills, but you're saying that there is a
*  special kind of social skill and we'll fill in the details. But there's something special about how
*  human beings interact with each other that does differentiate them from these other great apes.
*  Very, very good. Yes, precisely.
*  And clearly there has to be something biological there also, because like you say, you can't bring
*  the chimp into a house and raise it and it'll just be human. That's correct. So good. So our quest is
*  clearly defined now. You want to figure out. And if you want another indication of the biological
*  part of it is you have children with autism is the syndrome. They tend to be missing exactly the
*  things that I'm zeroing in on. Right. Of course, autism is very complicated because it is a
*  spectrum and you get people who are very... Correct.
*  And so that... But it is a good thing to point out that we can... That ultimately there are both the
*  differences and we're both suffused with commonalities and that's okay. We want to get exactly the
*  nuances right. That's correct.
*  So okay then. I've often in my simplistic physicist way been asked, is it possible that human beings
*  would ever be able to understand the ultimate laws of physics? And I have a line for that,
*  but you're the right person to ask whether my line is at all right, which is that we did undergo
*  some kind of phase transition in human cognition where we can manipulate symbols. And I almost want
*  to say it's like going from a primitive computer to a touring machine where we've reached a level
*  of abstraction where, yeah, I don't see any obstacles to us figuring out everything eventually.
*  Nature has to cooperate, but there's a different kind of cognition going on at the symbolic
*  manipulation level in human beings than in other apes.
*  I agree with that, but I would say that your child on a desert island, they're not going to
*  learn a language, right? There is no language to learn. There's nobody to communicate with.
*  Are they going to be symbol manipulators like that?
*  Okay.
*  So the brain has evolved to do all of that in interaction with others. And I think
*  getting other people disagreeing with you and you having to take their perspective
*  leads us to one of the things that I think is taken for granted in much of
*  adult cognitive science is that we can look at an object and say, that's a dog, that's an animal,
*  it's a thing, it's a pet. No problem. Call it whatever is appropriate.
*  Well, I don't think other creatures really have that kind of flexibility, that the same exact
*  item can be looked at from different points of view. And we all know from a certain age,
*  children know, maybe little children don't, really little ones, but from a certain age, we know,
*  it's just a matter of how you look at it. So we have all this flexibility. I've even
*  talked about perspectival cognitive representations. And I think symbolic,
*  the way you're thinking about it and the way a lot of people are thinking about it is of that
*  nature. When you mean symbolic, you mean a symbol for animal or a single symbol for dog or a symbol
*  for pet. And it's not about the world. It's about our conceptualization of the world. And then we can
*  manipulate those in all kinds of ways. So I think the evolution of the species was to be able to do
*  this in interaction with others. And then I actually start my book on the evolution of human
*  thinking with a metaphor. I say, it seems like thinking is something in the privacy of your own
*  mind. And it is. But it's like a jazz musician playing a jazz rift in his apartment by himself.
*  Yes, he's doing it by himself. But he learned jazz from other people. And the instrument was
*  built by other people over many years perfected. And he's playing in the genre that was invented
*  by other people before him. So yes, we end up doing all this thinking and symbol manipulation.
*  But if you look at the evolutionary and cultural history, the individual is growing up and
*  being assimilated into that. And that's an essential part of the process also.
*  So you mentioned that around 6 million years ago is when we diverged homo sapiens. Well, I guess
*  genus homo, should I say from?
*  Genus homo, yes.
*  Yeah, from the other great apes. What can we say?
*  Well, actually, it wasn't genus homo. Sorry, I correct that. That's when hominins, that's the
*  line leading to humans started. But it's only about two to three million years ago that we want to
*  call them homo. So they were australopithecines and things back at 6 million years ago.
*  I knew there was a very small chance I was going to get that right. Thank you for getting it right.
*  So what can we confidently say then about where in this evolutionary trajectory
*  this little transition happened? Do we know what came first?
*  It's a fascinating question. So let's take the 6 million years.
*  Yeah.
*  From what we can tell from the fossil record, for the first 4 million years,
*  some people might say more like 3 or 3.5, but somewhere more than half, we were basically
*  bipedal apes. All right, we were 4 feet tall, 4.5 feet tall. Our brains were the size of apes.
*  And we just happened to walk on two legs, but there was nothing that seemed to be different at all.
*  Then two, two and a half million years ago, you start getting these stone tools,
*  but they're not very sophisticated, right? And chimps already use stones to crack open nuts.
*  They don't fashion the stones, but they know how to use stones. And so you start getting
*  something new. And then two million years ago, you start getting a little brain growth. It looks like
*  a little bump there, and you're getting this tool use stuff. So it's two million years. I think you
*  can sort of zero in on part of it. But if you take this social cultural hypothesis seriously
*  and you look at the tools, it's really less than a million years ago that you get something that
*  looks like collaborative foraging, collaborative hunting, for example, which I think was a key
*  transition point. And so that's less than a million years ago, perhaps even a half a million
*  years ago if you don't allow group scavenging and stuff like that. And then so that's half a
*  million years ago. And then maybe 100 to 200,000 years ago, very recently, that's Homo sapiens
*  sapiens. And there's where you get the idea of really cultural groups and where different groups
*  have different tools. And that's the time where you might expect to see a conventional language
*  and things like that. So the answer to your question is when did it happen is I'm of the
*  view that it was fairly late. And out of the six million years humans have been on their own
*  trajectory in the last million, where something really different happened. And I forgot to mention
*  that there was also another brain growth spurt around a half a million years ago.
*  So okay, I mean, it does seem like a really hard but important question to say something like
*  the idea you already mentioned the idea of a theory of mind, the idea that human individuals
*  not only know things but know what other people know or have opinions about it.
*  Is it even contemplatable to imagine saying, oh, this point in evolutionary history is when
*  we developed a theory of mind? Well, you know, it doesn't leave fossils. So no, we don't.
*  But chimps already know some things. I mean, I try to avoid the word theory of mind just
*  because people mean different things by it. But, you know, one of our most highly cited studies,
*  the one that really kind of changed my mind, I originally started out thinking chimps didn't
*  understand any mental or psychological states of others. But then we did a study where
*  a subordinate chimp and a dominant chimp are competing for food. And the subordinate chimp
*  can see some food that the dominant can't see. It's on the subordinate side of a barrier, right?
*  Okay. And the subordinate behaves in ways that show she knows the dominant can't see it.
*  But this is just seeing. This is not sharing thoughts or disagreeing with opinions. All right.
*  We also have studies showing that they understand what others' goals are. So if they watch somebody
*  else trying to reach a goal and they're not able to reach the goal, they still know what they were
*  trying to do, even though they didn't see them do it. All right. So this is sort of ground zero
*  that I think the great apes all share is an understanding of the perception and goals
*  of other individuals and not the mental states more narrowly defined.
*  So there's already a starting point of that. And then that's why I say, you know,
*  continuity, it's continuity, but continuity doesn't mean identity. And so I think that
*  what starts making the difference is when it's important to me, like if we're collaborating,
*  it's important to me that we're both looking at the antelope over there, but you're seeing it from
*  one side and I'm seeing it from another. And you have one strategy and I have another strategy,
*  and we've got to coordinate those. And so one of the things that I've argued with children
*  is this hypothesis that I have about putting your heads together. It's a necessary feature is
*  something like a theory of mind, but to be sufficient, it needs to be coordinating with
*  other people's minds. And that's in communication. That's right. When we're having a conversation,
*  we're trying to, you know, I don't understand you, you have to revise yourself. You say something,
*  I disagree with you. We're coordinating our minds as we're communicating. And when we're
*  collaborating, we're coordinating not only our actions, but often our decisions. Did you know
*  in the in game theory coordination problems? I do, but the audience might not. So
*  so a coordination problem is a problem where we need to do the same thing. Let's say we're at a
*  rock concert and it gets out and we get lost from one another and we need to go home together.
*  You know, where are we going to meet? Well, I think, well, okay, where does he think I'm going to go?
*  Well, he thinks I'm going to go where I think he's going to go. And he thinks I'm going to go where
*  he thinks I'm going to go. So these coordination problems require coordinating and recursively
*  thinking about what he's thinking about what I'm thinking. And I think what we've called joint
*  attention, which you see in young infants already at about a year old, where we're looking at
*  something together and then the infant looks up at you and then looks down and we're coordinating
*  our attention to this object. I believe it has a recursive structure that not only am I looking at
*  it, I know you're looking at it and I know that you know I'm looking at it and you know that I
*  know you know I'm looking at it. So the sharing attention and sharing intentions and sharing
*  mental states is about this kind of what to get away from all the recursive embedding. We just say
*  common ground. We have common ground knowledge. We both know that we both know. And I don't think
*  chimps and other primates have that. And I think once you get that, so again, you're talking about
*  humans as symbol manipulators and reaching a phase transition with a new way of thinking.
*  I believe it evolved to coordinate your thinking with others, right? With this taking perspectives,
*  you know, and trying to make what you're thinking perspicuous for your partner. One of the things
*  people have asked me, couldn't humans have evolved all this fancy theory of mind,
*  including recursive thinking, in order to compete with others? So I'm wondering what he thinks I'm
*  going to do and couldn't it be competing? And in theory, it could be. But the thing about
*  cooperating is I want you to read my mind. If we're cooperating, I'm trying to make it,
*  if you and I are going to go do something together, I try to tell you, Sean, here's what
*  I'm thinking. Here's my plan. What do you think? All right. And wait a minute, wait a minute,
*  I changed. I'm going to do something else. So I am trying to facilitate you reading my mind. So I
*  think, and of course, a lot of the communication we engage in, I'm just informing you of things.
*  I'm just telling you things that I think will be helpful to you. And especially if we're
*  collaborating, oh, you dropped your spear over there or something like that. Again,
*  I'm trying to make it easier for us to read one another's mind and for us to collaborate
*  together on a common goal. And you can see why people would think of language as being so
*  important here. I mean, if you want to communicate to someone else what is in your mind, something
*  pretty intangible from the outside world, the ability to use language is very helpful there.
*  So you're not denying the importance of language, you're just saying that it flows out of this common
*  social skill. Absolutely. And again, the book that I wrote on the evolution of all this,
*  on the evolution of human communication, I say there's actually a halfway point that shows you
*  that it's about, that it's not language as a conventional symbol system.
*  That's not the first step. We have gestures that are uniquely human, for example, pointing
*  and iconic gestures or pantomime. All right. So if you and I are whatever, wandering around out in
*  the woods and I point like this, okay, what do I mean? Well, you have no idea with no context.
*  But let's say, you know, you and I are deciding we're going to go hunt antelopes and we both know
*  from our past experience, we know in our common ground that we need a spear and we need a wood of
*  a certain type to make a spear. And we're wandering around and I point over there and you see a piece
*  of wood like that. Okay. You can understand that I'm pointing out that piece of wood to you because
*  it'll make a good spear for us to collaborate together. A chimp cannot communicate in that way.
*  Pointing is basically, you gloss pointing as look over there and you'll know what I mean.
*  Yeah. Okay. Right. And with the same pointing, I can point over there and mean there are some berries,
*  there are some delicious berries. I can mean anything with the pointing, but it depends on
*  our common ground. It depends on what we know in common. When you search your search space,
*  what does he mean when he's pointing over there? It has to be things that we know in common. I
*  couldn't be pointing about something I don't know about and I wouldn't likely be pointing
*  about something that I knew you didn't know about. So it's things that we both know about.
*  So that's a kind of a halfway house to language. And iconic gestures are symbolic, right? So I say,
*  let's go, I make a gesture like throwing a spear to say, let's go hunting antelopes
*  where we throw spears. Other apes do not use iconic gestures either. And they're symbolic
*  already. So I started my career in developmental psychology on language. So I'm the last person
*  to say that language is not important. But language is the icing on the cake. It's the
*  jet rocket at the end. It's not the starting point. And in fact, they're actually theoretical
*  in principle arguments that you can't start from nothing and just say, oh, okay, let's call that a
*  tree. I think you have to have another form of communication and then you conventionalize it
*  into a language. And now you've got these conventional symbols and so forth. So anyway,
*  so yes, I think language is critically important for many uniquely human things.
*  And that's why our child on the desert island, one of the main reasons that he or she wouldn't
*  get to fully adult human cognitive capacities is because they don't have language. But it
*  presupposes a lot of other things. And if you want to say what makes humans different is language,
*  then you've got to go back and account for those other things that make it possible.
*  And where would you stand on the question of whether or not there is an innate language
*  capacity? Sort of Noam Chomsky, Steven Pinker point of view? I wrote a critique, I wrote a bunch
*  of critiques of it. But Pinker's book, The Language Instinct, which was such a sensation, I just said,
*  really, if you want to really understand, you have to be a little more precise. He's really
*  saying a generative grammar instinct. He's saying Chomsky's theory is an instinct. And that's what
*  I disagree with. Okay. All right. Of course, we are biologically prepared, biologically evolved
*  to use a language, there's no question. But I believe we're evolved, we're evolved to have
*  certain cognitive capacities to form concepts to communicate, like for example, with pointing and
*  pantomiming, which is not linguistic. So that form of communicative intentions and reading
*  people's communicative intentions, and recursive thinking and all that. So we're prepared in all
*  those ways, we're prepared to understand other to imitate other people when they use a piece of
*  language, we're prepared to internalize the language and use it in our own individual thinking.
*  But Chomsky's proposal was about generative grammar, it was about syntax.
*  Yeah. Right. And the institute I was at in Leipzig, Germany for many years,
*  we had a linguistics department that was focused on cross-linguistic studies. And yes, there are a
*  lot of commonalities in the languages of the world with regard to, again, the use of concepts and
*  communicative intentions and certain principles of pragmatics of communication and certain
*  principles. But the actual grammatical structures are quite different in different languages.
*  So I actually think that's the least likely thing to be innate.
*  Good. Out of all the aspects of language.
*  Yeah. Okay, good. I mean, I love language instinct, but I do take your critique pretty...
*  Well, it's a great book. You can disagree with something. And he made language interesting to
*  the general educated public in a way that nobody really ever had before. So it's a great achievement,
*  that book. And if you just softened it up in a few places and got away from the Chomskyian thing and
*  talked about language more generally, there's a lot of it that I could agree with.
*  And I guess the other thing that is very similar to that question is the distinctions between what
*  you're trying to talk about and what we normally think of as evolutionary psychology, because
*  you're both an evolutionist and a psychologist, but you diverge a little bit from the party line
*  in evolutionary psychology, if I'm not wrong. Okay. So sometimes people call it evolutionary
*  psychology with a capital E and a capital P. I've also heard it called high church
*  evolutionary psychology. When I started my department at the Institute in Leipzig,
*  I thought of the name evolutionary psychology, but it was already taken by a very particular view.
*  So what people call evolutionary psychology, I am an evolutionary psychologist by any normal
*  meaning of those terms. But the Tubian Cosmete's version of it has some special characteristics.
*  And from the beginning, they started in Cambridge, Massachusetts, where Chomsky is, and
*  they have this Chomsky was about language as a module, and it's innate and it's modular.
*  And so they took this idea of innate and modular and, you know, tried to see everything in through
*  those lenses. And I just find it a little bit narrow. I don't find it wrong. A lot of their
*  stuff is really fascinating and really interesting. But, you know, when you focus on something like
*  mate choice, okay, I'm all in. Okay, there's something that's really evolutionarily important,
*  obviously, is who you mate with. And who you find attractive and who you mate with and all that can
*  easily be a little specialized module. I don't have any problem with that. But things like language
*  and culture and all those things, they just don't fit the sort of innate modularity kind of idea.
*  So again, if you had a child on a desert island, I keep coming back to that as my touchstone.
*  You can have all the innate modules you want, but you're not going to get algebra and you're
*  not going to get a language and you're not going to get all of these things. We are adapted to
*  participate in social and cultural interactions and to internalize those into our own thinking.
*  So I don't disagree with hardly anything they do. I just think it's very narrow.
*  Is there a sense in which the emphases are a little bit different? I mean,
*  the evolutionary psychology literature wants to find an adaptive explanation for all sorts of
*  different behaviors, whereas you're more about a single big thing out of which many other things
*  are flowing. Again, a very interesting and important question.
*  You have to think about complicated species like apes and humans. You have to think about
*  them as organized cognitively, hierarchically. So I'm positing that at some point, humans
*  needed to collaborate with one another to get their food. What do you have to do to be a good
*  collaborator? Oh, and sorry, it's important that also there's partner choice. That is,
*  partners choose who to collaborate with. So what do I have to do to be a good collaborator? Well,
*  I could talk about that for about an hour. So I have to have certain cognitive capacities.
*  I have to have certain communicative capacities because I'm going to coordinate with my partner.
*  I have to have certain moral capacities because I'm going to share the spoils. When I really want
*  to take it all myself, I'm going to share the spoils. I have to have all kinds of things for
*  this evolved, for this task that is directing my evolution, that is selecting me, and including
*  the social part. So I have to be concerned about my reputation. I have to be concerned about how
*  other people view me as a cooperator. That means taking their perspective. So all of these things,
*  I'm sure you could get down to somewhere where you could call one of them an innate module.
*  But they're part of a larger organizational thing. The Tubian Cosmetes like to zero in
*  on the more things lower on the hierarchy, that is on the communication I might do or on the
*  negotiation I might do to share the spoils or something like that. So when you say I'm looking
*  for the one big thing, I just think that humans are like great apes in so many ways. I don't think
*  that in that last million years that we have separate adaptations for forming social institutions,
*  another adaptation for language, another adaptation for theory of mind, another adaptation for
*  mathematics, another adaptation. I think it's more plausible if the time frame you're talking
*  about is just a million years or even two, is that we had this. Yes, one of the things that Tubian
*  Cosmetes stressed that was really important in psychology and that I promote every chance I get,
*  people will say things like people who are not very evolutionarily minded, a psychologist,
*  a lot of psychologists included will say things like humans evolved to be smarter and to have
*  bigger brains. And Tubian Cosmetes argue really forcefully and really convincingly that evolution
*  doesn't work like that. You have to have a specific problem. You have to have a specific problem.
*  So they focus on very concrete problems, mate choice or whatever it might be.
*  What I want to say is you have to think about human behavior as hierarchical. I want to say
*  I'm agreeing with them and I learned from them. We have a problem and the problem is collaborating
*  to get food. It's just that that problem has about 50 sub-problems that it brings with it.
*  And they are both cognitive problems, communicative problems, socio-moral problems,
*  and all kinds of things that go with it. So I would stress that it's not that they have a lot of
*  little things and I have one big thing. I have one big thing that I think organizes a lot of
*  little things. Okay, that makes a lot of sense. And I like the point that the evolutionary pressure
*  is not to make our brains bigger. If anything, it's the other way around. Big brains are very
*  expensive, so there has to be some benefit of having them and the benefit should be the
*  specific, not that someday we'll have podcasts. And in addition, another, I know that a lot of
*  people, you seem to be a more broad-minded physicist than most, but I know a lot of people
*  who are more in the physical sciences and hardcore, the psychology stuff and theory minus
*  stuff, it all seems very airy and everything. But another concrete thing you can point to
*  is how much longer human's ontogeny is than other apes. So great apes, as soon as they wean
*  at about age three or four, they're on their own, right? And they're getting their food on their own
*  and nobody's teaching them anything, right? So there's no teaching. So they're basically
*  independent agents on their own. Humans, there are studies with hunter-gatherer groups that
*  youngsters don't bring in more calories than they consume until they're 16 years old or something.
*  And in the modern world, I could still have the credit card in their mid-20s,
*  have the parents credit card in the mid-20s. So this long dependency
*  has a lot of, you were saying the big brain has a lot of costs. It must be doing something.
*  This long dependency is both dangerous for children. They're not able to defend themselves
*  from predators or feed themselves for over a decade. And it's costly for the parents
*  because the parents are investing in the kids when they could be doing something more directly
*  productive for themselves. And when I watched chimps in Africa, I just did a month of field work
*  one time. But if a predator is nearby, moms typically have two youngsters hanging off of them.
*  And when you're scrambling, having two youngsters hanging off of you and trying to get away from a
*  leopard, that's not good. So this long ontogeny is costly and risky. So it must be doing something.
*  And what it's doing is it's giving time to learn and to socially coordinate and to become a member
*  of a culture. And I mean, I don't know if you've ever had Rob Boyd or Joe Henrik or one of those
*  guys. Yeah. So they would stress that humans have spread out. The other great apes mostly live in
*  the tropics and humans can live in the Arctic and everywhere else. But you couldn't do it yourself.
*  If somebody dropped you or me in the Arctic, we'd last 20 minutes. Or if they dropped us in the
*  middle of the jungle. So the people can live in these places because they accumulate knowledge
*  and information about these specific locations and transmit it culturally over time. So the long
*  ontogeny is clearly built on the fact that youngsters need a long time to learn stuff and
*  they need to be protected by their parents for a long time to get that done very costly. So again,
*  that's a concrete thing you can point to in physical development, as it were,
*  that is suggestive of a different kind of psychological orientation.
*  You mentioned morality a couple of times. I know that you have a whole other book on the origin of
*  morality and I'm going to guess that it fits in very well with this sort of social skill
*  development story. Yes. All the way back to Darwin, people have recognized that being
*  cooperative, being nice to others, altruistic is a problem for Darwin's theory. There's a famous
*  quip that in evolutionary biology, the definition of altruism is that which cannot evolve.
*  Because the individual, if I want to be a really nice guy and give away all the food and all the
*  resources that I gather, then I'm not going to be leaving any children. So I'm not going to be
*  contributing to the future gene pool. So Darwin got it right. Everybody, all the individuals have
*  to be looking out for themselves. But cooperation can be a win-win situation, which there are a lot
*  of people that don't understand this. There are a lot of people who think it's a zero sum game,
*  but there's another minority voice that's been in evolutionary theory for all along
*  that cooperation can be a win-win situation. Morality is, I define as the human version
*  of cooperation. It's a special version of cooperation. It's a psychology built for
*  cooperation because I'm sacrificing for you. I'm being fair and dividing the resources to include
*  you and have your concerns equal to my concerns and those kinds of things. But to make it work,
*  it has to not disadvantage the individual out of existence. That's the key. And so morality at the
*  balancing act between me keeping my concerns in mind enough to survive and keeping your
*  concerns in mind. And the key concept, so this is for people who are
*  hardcore evolutionists, this is the key concept. The key concept is interdependence.
*  All right. And one way you can think about it is symbiosis, right? You have symbiotic,
*  you know about symbiotic relationships between two species. Both of them are getting something out
*  of it, right? So that's the whole definition of it. Well, in evolutionary biology, symbiosis is
*  used between species. I'm not sure why it's restricted that way. I just want to generalize
*  it within the species. That is, I can do stuff for you that you need and you do stuff for me that I
*  need. And you can calculate the cost and benefits so that we... Let's say,
*  here was an example that I used to really dramatize it. Let's say that there's a female,
*  there's one female and she's the only female in the group that will mate with me.
*  My mating success is 100% dependent on her. Now we approach some food together. What is in my
*  long-term genetic fitness interest? To steal all the food and not let her get any? No.
*  Because if she dies, then my genes are not going. So because I'm dependent on her,
*  then I need to share with her. I need to look out for her thing. If I have a partner in
*  collaborative foraging, that's my best partner, we work well together, we're successful.
*  Everybody else is kind of a loser. Somehow I don't get along with them or whatever.
*  And now my partner is sick one night. Well, if I want to be successful hunting the rest of the
*  week, maybe I better get them some chicken soup or something. I better help them out.
*  So when you're interdependent, if you look at all the... If you go on Google Scholar and
*  put in evolution of cooperation, all of the top hits are all on computational models
*  of cooperation. And the computational models all assume these kind of independent modules,
*  everybody looking out for their own interests. And then the only way you can get cooperation
*  to work is if you find other cooperators and all kinds of green beards and all this.
*  But if you assume that they're living in an interdependent social network where they depend
*  on one another, then they're helping one another because they depend one another.
*  And there's this very simple mathematics to it. A guy named Gilbert Roberts. Again,
*  I don't know exactly your background, but do you know the Hamilton kin selection?
*  Again, I do, but let's not assume that the audience does.
*  Okay. So the kin selection is that my children share my genes and my brother shares my genes.
*  And so it's in my interest for my genetic fitness that I help them to a certain degree.
*  Now it wouldn't do for me to help them and die doing it because then I'm not going to have
*  future children and all that. So there's a mathematics to when it's in my long-term genetic
*  interest to help those people. I think Hamilton had a quip one time about I'd fall on a hand
*  grenade for two brothers, four cousins or whatever it is he's calculating. Well, the interdependence
*  has exactly the same formula, but you just substitute for it interdependence instead of
*  genetic relatedness. So to the degree that I am dependent on you, I will help you.
*  In the example I gave where I have a female, the only one who will mate with me, I'm 100%
*  dependent on her for my genetic fitness, then I'm guessing I need to share a whole lot of that food
*  with her and somebody who's just my grooming partner and I can live with a few more fleas,
*  it's not a big deal. I depend on them for grooming, but grooming is not a big deal.
*  Maybe I don't share with them, maybe I share a little bit with them, whatever. And of course,
*  it's actually more complicated than that because all the individuals in my group,
*  somebody might be my coalition partner and my grooming partner. So I think that most people
*  who see cooperation as still highly problematic have not quite comprehended this process of
*  interdependence. They think of individuals as all competing with one another all the time.
*  And that's not wrong. Of course, there's a level at which that's true. I started the whole thing
*  by saying you can't be altruistic to the point that you sacrifice your own existence. But there
*  is a mathematics of how much I should help people that I'm dependent on. And so the book on morality
*  starts with interdependence. If you have a social group where individuals are interdependent,
*  and almost by definition, individuals in a social group are interdependent on one another,
*  why are they in a social group to start with? The textbook explanation is protection from predation.
*  If you're in a group, we were better off together. So everybody's interdependent to a little bit.
*  If my social group goes away and dies on my own, I'm going to be in trouble if I'm a mammal,
*  for example. So I have an interest in keeping everybody alive a little bit. But then there's
*  some individuals that I really depend on for whatever, for mating, for cooperation, for grooming,
*  whatever it is. And so we start with that kind of interdependence, but then some species
*  have more interdependencies than others. And so nothing is more important than getting food.
*  I mean, food and mating, those are the key elements in evolution. But food,
*  you've got to do it every few hours, every day. If you look at chimps in the wild,
*  they're wandering around foraging for food. That's what they do all day. And maybe they mate on the
*  side and they have a fight on the side and they groom on the side. But where they go and what they
*  do is all aimed at getting food. And primates in particular, a lot of them, great apes, they eat
*  fruits. And the fruits only give you energy for a few hours, and then you got to eat some more.
*  So if humans became interdependent with one another in getting food to a degree that other
*  primates did not, and this becomes immediate and urgent interdependence, I'm ready to go out and
*  get some food. The only kind I can get is one where I can get collaboratively, or the only good kind,
*  certainly the only meat, and nobody will collaborate with me. What am I going to do?
*  Why won't they collaborate with me? Because I don't share at the end. If we get something,
*  I grab it all myself and I don't let them have any. So everybody selects against me. They don't
*  choose me as a partner and I'm a goner. So that's the context for the evolution of morality is
*  this interdependence cooperation, not cooperation out of just being nice, but this interdependent
*  cooperation where we have to treat one another fairly. We have to treat one another with respect
*  in the sense that I know that you don't have to cooperate with me. You have some other choices.
*  And not only that, but I know that you need me too, to some degree. Maybe you have some other
*  choices also, but I know if we're good partners, you depend on me and I depend on you. So I have
*  a little leverage here too. So what's the solution? The solution is, well, okay, let's divide it
*  equally. Let's be fair about it. So I do think that in the book on morality, I distinguish,
*  it goes all the way back to the ancient Greeks, the morality of sharing and helping and sympathy
*  and the morality of fairness, which is a more cognitive, rational kind of process.
*  The morality of sympathy, that's where Franz de Waal has focused most of his attention.
*  And that I believe is all mammals have some of it. They have their oxytocin and
*  the mothers are sacrificing for offspring all the time.
*  And some species generalize it. You may have seen some of the stuff about rats helping other rats
*  escape from cages and stuff. So they already have the mechanism for sacrificing for their
*  offspring. And that's probably evolved with genetic out of kin selection. But then they
*  just have to generalize the mechanism to non-kin. And so I think actually the sort of helping and
*  sympathy is widespread in mammals. It's just a matter of how widely do they use it. But the
*  morality of fairness and obligation, I have an obligation. You helped me last time. I have an
*  obligation to help you this time. We worked equally hard at this foraging problem. So I feel an
*  obligation to share equally that we do it fairly and equally. So that's a motivator. The sense of
*  obligation is not the same thing as being nice. It's something a little bit more... And I think
*  that is what comes from collaborative foraging. I did very recently a related podcast topic with
*  Adam Bulley. I don't know if you know him. He's a younger guy. But he's written a book recently
*  with Thomas Sudendorf and Jonathan Redshaw called The Invention of Tomorrow. Oh, yes. Well, I know
*  that Sudendorf is the one who's been singing that song for a couple of decades. So I know the
*  Sudendorf stuff. I haven't read that particular book. Yeah. But the idea that one of the things
*  that really separates human beings from other species is mental time travel, right? The ability
*  to put ourselves in the future. I really kind of like that perspective. It might be the physicist
*  and me talking and my interest in time. But everything that you just said about morality
*  takes that into account in the sense that you're saying, well, if I don't do this thing right now,
*  the future is going to come back to haunt me. And you can conceptualize that, right? And we
*  can conceptualize that in a way that other animals maybe cannot. Yeah. No, that's absolutely true.
*  And that's an important part of the process. There are studies with apes where they do
*  a little bit of planning, future planning, and they do a little bit of episodic memory.
*  It's not nearly to the same extent as humans. My initial tendency would be to say it probably
*  somehow is part of this story of relating to others and that kind of thing. But I don't have
*  a particular story for exactly how that works. Sure. But it does lead us exactly into sort of
*  the capstone of the conversation, which is the idea of agency, which is the focus of your most
*  recent book. You should tell us the title of your most recent book. The Evolution of Agency. And I
*  think it says Behavioral Organization from Lizards to Humans. I can never remember my subtitles
*  because they always change in the production process. I wanted to get lizards in there or
*  something like that because I wanted to convey to people who know my other books that I'm going a
*  little bit farther back in evolution than I have previously. So what do you mean by agency in this
*  context? Okay. So let me just start with an example that's on page one of the book. So squirrels
*  cash nuts, right? They hide them away and store them for winter and go get them later. That's
*  clearly an evolved behavior. All squirrels do it the world over. This is part of squirrel
*  evolved psychology. But if you look at a particular squirrel at a particular moment
*  with a nut and he's trying to decide where to cash it in this landscape, I'm saying that evolution
*  cannot in principle tell them what to do. It can't be determined like that. And so in general,
*  what evolution has done, and it may be that you can think of these very simple creatures,
*  one-celled organisms and very simple creatures, it may be that you can think of them in a deterministic
*  way. I don't know. But creatures that are a little more complicated, what nature has done is said,
*  okay, I'm going to build you in with a lot of stuff here. But then when it comes down to actually
*  making a decision about what to do in a particular situation, I'm going to leave it up to you because
*  I can't predict. I don't know exactly where the watering hole is in the place you're born. Nature
*  doesn't know that ahead of time. The watering holes change. So I'm going to build you with
*  the capacity to learn where your watering hole is and to decide when and how to go there and stuff
*  like that. So agency is about the agency evolves when there are unpredictabilities and nature builds
*  in an apparatus for the individual to deal with those unpredictabilities through what I call
*  informed decision making. That is looking around, gathering information and making the best decision.
*  That decision is on a particular occasion is not determined by mother nature. What's determined is
*  the decision making apparatus that you go to it with. So you need an agent. Now, a lot of people
*  say, oh gosh, that sounds like a homunculus to me, right? But this is why in that book, I start out
*  with control systems. So I think that, and this goes back to the cybernetics, to Ross Ashby and
*  Norbert Wiener and people like that, they build these machines and do this theory showing that
*  if you have a problem where you need a machine that can act autonomously from individuals, from
*  humans and intelligently, it has only one possible structure. And that is it has to perceive the
*  world. It has to have a goal state that it wants to be the case in the environment. It has to perceive
*  the environment and see if it matches with the goal state. And if it doesn't, it has to be able to do
*  something to make it match. So the classic is the thermostat, right? So if I want the room cooler,
*  I can go get a fan and turn on the fan. But the fan is dumb because I just turn it on or off. And
*  I'm the one who decides if it needs to be cool or not and what to do and all that. But the thermostat,
*  it has a thermometer. It senses the temperature. It has a set goal. I set the goal. I put it at 72
*  degrees, but it has that goal and it senses the temperature of the room and it sees if they match.
*  And if it doesn't, then it acts to make it match. I was explaining some of this to my 11-year-old
*  daughter a couple of weeks ago and we were at a stoplight. And she said,
*  that stoplight is a dumb machine, isn't it? And I said, it is because it turns on and off on a timing.
*  And I asked her, my 11-year-old, I asked her, how would you make the traffic light more
*  intelligent? And she said, well, it would have to have a camera that saw where the cars were
*  and then some algorithm or something that turns green where there's the longest line and turns.
*  It's pretty good.
*  So what I want to argue is that nature invented this. Homeostasis in the body is the same thing.
*  The homeostatic mechanisms that you have a blood temperature, body temperature,
*  and that's a set point. And when you get too cold or too hot, your body does things.
*  Right. The same model works in behavior. And again, I want to say that it's not homunculus,
*  which some people, the more deterministic minded people tend to worry about that.
*  I make an analogy to early 20th century biology. There was a big debate between people who were
*  vitalists and mechanists. And the vitalist said, okay, living things have a vital substance that
*  makes them different. And that's a kind of a homunculus, if you will. And it turns out,
*  that's not true. It turns out living things are made out of the same stuff as everything else,
*  but it's organized in a different way. So I want to say that there's nothing
*  homunculus that control systems show you a certain kind of organization that the organism
*  has in relation to its environment, that their behavioral decision making is organized in a
*  certain way. And that's what we want to call an agent. The agent is the organism acting with this
*  kind of cognitive organization that I gather in. I have a goal. I gather information. I decide what
*  needs to be done to meet the goal and so forth. So that's what the agency is.
*  And I would say that people who want to say that everything is deterministic in the world,
*  the Laplacian starting state and everything is determined, they just don't want psychology in the
*  picture. I want to say that if you want psychology in the picture, you have to have an individual
*  making decisions. And if you don't, then it's fine, but it's all physics or it's all biology.
*  And I'm a psychologist and I want psychology. And the psychology means I have an individual
*  who's assessing the situation and deciding what to do to meet its goals. So people kind of,
*  I don't think, I mean, it is controversial to some people, but I would say most psychology kind of
*  operates with that as a kind of an assumption. But in the field of animal behavior, and I actually
*  wrote the book on agency for people in animal behavior, there's still a lot of kind of
*  behavioristic talk like stimulus and response. The organism is responding to a stimulus.
*  Well, that's a kind of a classic physicalistic cause leads to effect. Stimulus leads to response.
*  I want to say no, the organism has a goal it's pursuing. And when it perceives something that
*  you're calling a stimulus, they're seeing that it doesn't match their goal. And so they're acting
*  to do, right? So you need to think of a circular causality of the cybernetic type of the control
*  system type. And even in a case where, so there may be things like reflexes, right? So a small
*  object comes toward my eye and I blink. Okay, I'm willing to give you that for stimulus response.
*  But anything that we think of as intelligent, autonomous behavior, what defines it is a certain
*  organization. And I want to call it agentive organization, control system organization.
*  And what I do in the book is step through different kinds of control system organization.
*  The key variable being how much executive control do you have? So very simple organisms are simple
*  control systems. But then when you get to things like mammals, they've got an executive control
*  system that can plan ahead, that can consider different possibilities before acting,
*  and that can get feedback from its actions and learn and adjust and so forth.
*  And then where I get to my work that we talked about for most of our podcast here,
*  the shared intentionality is that humans have evolved to be shared agents or social agents or
*  plural agents. All these are words different people have used. And when you and I decide to
*  solve a problem, when you and I are going hunting together collaboratively, we have a shared goal.
*  We have a joint goal. We have shared knowledge about the situation and we communicate to make
*  sure we have shared knowledge. And we kind of self-regulate it together. So I say, hey,
*  go over there and don't do this. You say, oh, don't do that, do this. And so we're kind of
*  regulating it. So we kind of make a shared agent. And I've used the word shared intentionality in
*  most of my work until recently. And it's the same thing, but shared agency is the behavioral side,
*  the actual collaborative to solve a problem. And shared intentionality is kind of underlying
*  cognitive capacities that allow the shared agency to work. But anyway, so that's what the idea for
*  the book was. I've always had this control system view all the way back to my earliest stuff. I've
*  never really elaborated it. And so I wanted to elaborate the control system view in the context
*  of the sort of arguing that psychology is important in evolution because organisms making decisions.
*  And then I can scale that all the way up to humans by talking about shared agency. And by the way,
*  Darwin uses the word agency. He actually says that the agency of organisms is a factor in their
*  evolution because I give an example in the book where let's say I'm a lizard or something,
*  and I usually get insects on the ground. And all of a sudden something wipes all those out and they
*  don't exist anymore. And now the only insects are the ones that are up in the trees. And some lizards
*  are capable of climbing the tree and getting the new insects and others aren't. So those are the
*  ones that survive. And they have made a choice to go up the tree and capture these guys. Other guys
*  have not. And so their actual behavior is leading the way. So now, for example, those guys may grow
*  longer claws. So this is what people sometimes are called genetic assimilation. So now the genes
*  follow the behavior. Now I need to be a tree climber where I didn't before. So now long
*  claws are an advantage. So this is again that hierarchical system. If I'm going to be
*  chasing insects in trees, I need to grow long claws, which I wouldn't if I didn't go up the tree.
*  So behavior and agency can be a leading edge in the evolutionary process itself. So that's
*  another dimension of it. Well, the different levels is an interesting idea because when you
*  started in the book, when you started the squirrel example, I thought you were going to put squirrels
*  on the non-agentive side of things and human beings on the agentive side. But you're saying
*  that in a sense a squirrel is an agent, has to figure out where to put its cache of nuts. But
*  you couldn't sit down with the squirrel and explain, oh no, no, this year you don't have to
*  do that. I promise to feed you. So that's the kind of agency that it doesn't have. That's correct.
*  And so I have this typology of sort of three types of individual agency and then the shared
*  agency that humans have. And this I think actually fits with this. From the very beginning,
*  we started with the idea that yes, humans are continuous with other creatures. And there has
*  been this building up of stuff over evolution that gets us to humans. And humans just add this one
*  little twist. I'm fascinated by the idea of goals as they appear here because it again,
*  and I don't have a strong feeling about what to say, but we have an arrow of time. We remember
*  the past and we causally influence the future. And it's always fascinating to me how, I don't know
*  if it's human or it probably goes back way deeper in evolution, but when was the first goal? When was
*  the first time that we could have attributed to a species or an organism the idea that there's a
*  concept of what I'm aiming for? In the book, I punt on some of the exactly when that might happen,
*  but I would say that single-celled organisms, bacteria, single-celled organisms and that stuff
*  do not have. Organisms without a nervous system probably don't. I'm just speculating, probably
*  don't. And I wanted to simplify my problem. I mean, I don't know if you know the Godfrey
*  Smith stuff on octopi and all that, but okay, they're off on a different world. I don't know
*  about that. All right. But on the line to humans, the first vertebrates would have been fish.
*  I don't, there's not a lot of research on fish, but if you now go to the first land vertebrates,
*  they're like lizard-like creatures. And I think they clearly have goals. If you look at the,
*  if you look at research with lizards, they are trying to achieve goals and you put them in
*  experimental situations and you can see that. So I don't know where the first one was, but I feel
*  confident that from vertebrates on, they do. And I don't, you know, there are these guys off to the
*  side like insects and octopus and all that sort of stuff. And I just, I'm, I'm, I don't know about
*  them. That's very fair. What are your feelings about free will? So the agency book basically
*  is saying that you have to, the decision-making apparatus is evolved. You don't have a choice
*  about whether to have that apparatus or not. Right. But given that apparatus, yes, the
*  individual has free will to choose within that, within that thing. Now I don't have a free will
*  to choose whether to blink my eye when a small object comes toward it. So not in all of my
*  behaviors. But, you know, humans can starve themselves to death or commit suicide or whatever.
*  So to me, people who want to deny free will are essentially taking
*  a kind of a physicist view of, of psychology, right? That somehow this, this is like, you know,
*  you know, planets attracting one another or atoms attracting one another or whatever.
*  I'm saying, no, the world is a multifarious place and there's a, and there are creatures that are
*  agentive that make decisions and they have evolved an apparatus to do it. So if you want to say it's
*  deterministic in the sense that the apparatus for doing it is deterministic, then fine. If you want
*  to say the criteria they take into account when the squirrel is deciding about where to cash the
*  nut, he probably doesn't take into account, you know, the temperature or the wind direction or
*  whatever, you know, they're so what is relevant to the decision might possibly be part of the
*  deterministic thing. But unless you want to eliminate psychology, you need that individual
*  making the decision. And it's not a homunculus. It's a, it's just organized as a control system.
*  That's all. And so that's, yeah, that's, and I would just say also that anyone who denies free will
*  is just doing it as an intellectual exercise because they themselves, if you really didn't
*  think people had free will, you'd never get angry at anybody. You never get angry at your wife for
*  not doing something because, well, she can't help herself, right? And you yourself would never,
*  you know, worry about a decision because, you know, it's all determined anyway. So I think in
*  their everyday lives, nobody believes it. I'm pro free will myself. I did have Robert Sapolsky on
*  the podcast and, you know, he did his best to convince me that it was all a myth. But if you
*  haven't read it or you're not familiar with it, I would recommend a book by Jananne Ismael, who's
*  a philosopher. She wrote a book called How Physics Makes Us Free. And it's very much in the spirit of
*  your sort of control theory way of thinking about things, recursion, the difficulty of fitting
*  ourselves into our physical description of the world, you know, the practical difficulty. And
*  that's what makes it hard to really in any even semi plausible sense to be a determinist about
*  the macroscopic world of human experience. Yeah. So there's a book by Christian Liss
*  called Why Free Will is Real. And he basically is saying, like I am, that
*  the tendency to want to deny free will is to look at things from one perspective, from this sort of,
*  you know, deterministic physical physicist perspective. But if you just keep your level
*  straight, you know, we're on the level that we work on, that Robert Sapolsky works on every day
*  when he decides what shirt to put on. You know, that's if he wants to say what shirt he puts on
*  this morning is determined, fine, but he doesn't really believe that. That's just, you know.
*  I get it. I wrote a book about that too. I'm on your site very much. So maybe, you know, to finally
*  wrap things up, leading from the different levels of agency, you have sort of a provocative thought
*  in the book about increasing complexity along this chain leads to not only different kinds of agency,
*  but different kinds of experience, you know, different kinds of, I don't know, you know,
*  mental relationship to reality. Well, this is a very long and difficult topic, Sean, that I
*  in a clear minority on, but I believe if you are an evolutionist, you have to, you know, what is
*  the world? Do you know von Uxkal at all? He was a classic. Anyway, what is the world for a worm?
*  You know, what is the world for a tick? I don't know, but I think that's a good question.
*  Von Uxkal has a big thing about ticks because he studied ticks, you know, and they basically
*  just sense the temperature of a mammal walking by or whatever. All right. So is it the case that
*  they have their restricted little world, worms only are below ground and whatever, and the ticks
*  are only sensing temperature, but we humans have access to the real world the way it really is.
*  Aren't we lucky? We have our world that's determined by this evolutionary process,
*  by our agentive system as well, and by what things are relevant to our agentive decision making.
*  When we make decisions, we scan the world for things that are relevant. We pay attention
*  for things that are relevant to our decisions. And so I just think that, you know, the general
*  idea of an ecological niche, that's an everyday common sense idea that animals live in different
*  ecological niches. Fish live in water in the same forest, you know, squirrels live in the
*  with leaves and trees and the worms live under the ground and the
*  butterflies thrive through the sky. So they live in sort of different worlds and even
*  that's their ecological niche. Well, I use the term experiential niche. The experiential niche
*  is the world as you perceive and understand it, which evolved to support your agentive actions in
*  and humans, even though we like to think differently, humans are the same.
*  Now, part of our ecological, part of our experiential niche is the mental world of
*  the other people we're dealing with and the cultural world into which we're born and the
*  normative world about the way things ought to be. You're talking about the mental time travel.
*  One part of mental time travel is the way things ought to be. And so no other creature, I don't
*  think I could be wrong, but no other creature, you know, plans its actions and behaves with respect
*  to what ought to be the case. So this is the human world. So I would just say that it's harder to see
*  in the case of humans and maybe a little easier to see in the case of other creatures, but I would say
*  that the organisms experience those things they need to experience to get done what they need to
*  get done. You know, I did talk to Ed Yong, and he had wrote a wonderful book about the different
*  umwelt that different kinds of animals have because of their sensory capacities. I am sad
*  that I didn't think myself to think about the experiential umwelt and how, you know, the
*  normative versus present future, everything going on. Yeah, there's layers here that it's very
*  fascinating to think about. The worm is not living in that world. I'm sorry. It's not.
*  Okay, now we say, oh, we're living in the real world and the worm is living in some subset.
*  Maybe. No, but there's certainly animals that can sense things that we don't. So yeah, absolutely.
*  Yeah, absolutely. That's Thomas Nagel's famous, what is it like to be a bat? Right, right, right.
*  So we still don't know, but we're learning. I think you've helped us a lot in thinking about
*  why we're slightly different. And okay, here's the final question. If this is the hierarchy
*  of our evolutionary advance with our increased capacities, is there another future
*  advance that super intelligences or anything like that might get to? Yeah, I don't know about that.
*  I don't know about it either. This might be over my pay grade. I would say sort of,
*  right now, the challenge for humans is more on the cooperation realm. We're going to blow ourselves
*  up or we're going to degrade the environment to the degree that we can't live in anymore or something
*  like that. So it's the cooperative challenge we have to meet. And if we can, you know, find a way
*  to meet that first, you know, then maybe we can do some more cognitive things. But
*  I will say that I think that, you know, once you start getting civilizations, like,
*  take Western civilization from Mesopotamia and Egypt and then ancient Greek and all that,
*  these were guys that were building up knowledge themselves. And then, and they didn't even know
*  the other guys existed. And then they bumped into one another. And a lot of incredible stuff
*  happened when they bumped into one another. The Greeks get math from the, you know, from the East.
*  And I think as the world, if, when and if the world can become more of a world community,
*  I think that will be a big boon because this social cultural process that I'm focusing on
*  will get another boost. I mean, we do know a lot. There are not many secrets in the world now,
*  I must say, with all the communication and whatnot. But maybe if we were more integrated
*  and scientists from different countries were working together more, you know, something new
*  might come of it. But first, we have to solve the cooperation problem and all these, you know,
*  nationalistic people who don't want to cooperate. Yeah, you know, at the end of the podcast,
*  we like to let our hair down and speculate a little bit. That's perfectly good. And you've been very
*  good support about that. So Mike Tomasello, thanks very much for being on the Winescape Podcast.
*  Thank you, Sean.
