---
Date Generated: May 19, 2025
Transcription Model: whisper medium 20231117
Length: 5336s
Video Keywords: []
Video Views: 823
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2025/05/19/315-branden-fitelson-on-the-logic-and-use-of-probability/

Every time you see an apple spontaneously break away from a tree, it falls downward. You therefore claim that there is a law of physics: apples fall downward from trees. But how can you really know? After all, tomorrow you might see an apple that falls upward. How is science possible at all? Philosophers, as you might expect, have thought hard about this. Branden Fitelson explains how a better understanding of probability can help us decide when new evidence is actually confirming our beliefs.

Branden Fitelson received a Ph.D. in philosophy from the University of Wisconsin-Madison. He is currently Distinguished Professor of Philosophy at Northeastern University. He is a co-founder of the Formal Epistemology Workshop, and winner of the 2020 Wolfram Innovator Award.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll

#podcast #ideas #science #philosophy #culture
---

# Mindscape 315 | Branden Fitelson on the Logic and Use of Probability
**Mindscape Podcast:** [May 19, 2025](https://www.youtube.com/watch?v=JG57WvAWzUM)
*  Hello everyone and welcome to the Mindscape podcast. I'm your host Sean Carroll [[00:00:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=0.0s)]
*  One of the things that I always like to say about science and how it gets done is that science never proves things [[00:00:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3.72s)]
*  This is something that is an important feature of science [[00:00:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=11.16s)]
*  Especially in the modern world where what science does how it reaches conclusions how trustworthy it is [[00:00:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=15.280000000000001s)]
*  These are all under contestation by different parts of society [[00:00:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=21.36s)]
*  So it's important to understand what science is and how it actually [[00:00:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=26.28s)]
*  Reaches its conclusions and the claim that science never proves things [[00:00:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=29.28s)]
*  Which is something that most scientists would go along with me on comes from a comparison to real proof in [[00:00:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=33.480000000000004s)]
*  Mathematics or for that matter in logic, you know [[00:00:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=42.160000000000004s)]
*  Most scientists have taken some math classes at least enough to know what it means to prove something in the old-fashioned sense of [[00:00:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=44.28s)]
*  Euclid and geometry or [[00:00:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=51.72s)]
*  Aristotle and logic proving a conclusion from some well articulated premises in [[00:00:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=54.199999999999996s)]
*  The philosophical study of logic. This is known as deductive reasoning [[00:01:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=61.68s)]
*  You have some premises and you reach a conclusion and science just doesn't go that way, right? [[00:01:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=66.03999999999999s)]
*  Science looks at the world [[00:01:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=71.36s)]
*  It looks at all sorts of things in the world and it tries to figure out what the patterns are that the world follows [[00:01:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=72.88s)]
*  Always knowing that tomorrow you might do a new experiment that will overturn your best guess as to what the pattern was or maybe [[00:01:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=80.4s)]
*  Someone will do something as simple as just thinking of a better pattern, right? [[00:01:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=87.48s)]
*  Theoretical physicists coming up with a better idea for what the laws of physics really are [[00:01:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=91.52000000000001s)]
*  So if science doesn't prove things if it just sort of comes closer and closer in some sense to getting it [[00:01:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=95.56s)]
*  Right, then what is? [[00:01:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=103.46000000000001s)]
*  What's going on? [[00:01:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=105.14000000000001s)]
*  You know one very common idea about what's going on is [[00:01:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=106.4s)]
*  Inductive logic rather than deductive logic and inductive logic. We begin to see a pattern, you know [[00:01:50](https://www.youtube.com/watch?v=JG57WvAWzUM&t=110.80000000000001s)]
*  ABCDEFG the next one is probably going to be H right because we think that probably you're just [[00:01:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=116.74000000000001s)]
*  Mentioning the alphabet in alphabetical order, but there's all sorts of paradoxes that come up when you do inductive logic [[00:02:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=123.24000000000001s)]
*  Like how do you know that it's not ABCDEFZ? [[00:02:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=130.52s)]
*  That's a that's a sequence of letters that you could have my old math teacher in college used to hate those [[00:02:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=133.79999999999998s)]
*  SAT questions or standardized test questions that would give you a [[00:02:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=140.44s)]
*  Series of numbers and ask you to guess the next one because he said I can I can make any number I want I can come [[00:02:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=143.76s)]
*  With a formula that would give you any number I want after the ones that you already showed me. So [[00:02:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=148.7s)]
*  philosophers unsurprisingly are very interested in [[00:02:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=154.28s)]
*  making as rigorous and careful as possible this idea of [[00:02:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=157.95999999999998s)]
*  Either induction or whatever should replace induction as the logic of understanding things in [[00:02:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=161.88s)]
*  science the names attached here go from [[00:02:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=167.76000000000002s)]
*  Old-school names like David Hume and John Stuart Mill to relatively newer ones like Rudolph Karnap Carl Hempel [[00:02:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=171.32000000000002s)]
*  Carl Popper for example, and it's still an ongoing thing [[00:03:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=180.16000000000003s)]
*  So this is something that lives at the intersection of how we think about science, but also how we think about probability [[00:03:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=183.68s)]
*  What probability is? [[00:03:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=189.06s)]
*  how [[00:03:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=191.24s)]
*  Conditional probabilities work Bayesian logic all that stuff and that's what we're gonna be talking about today [[00:03:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=192.88s)]
*  today's guest is Brandon Fidelson who is a [[00:03:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=198.32000000000002s)]
*  philosopher at Northeastern University and [[00:03:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=201.08s)]
*  It's you know, it's it's eye-opening to me as someone who is now part-time in a philosophy department [[00:03:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=204.4s)]
*  Just a huge range of stuff that gets [[00:03:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=210.26000000000002s)]
*  Characterized as philosophy right like some philosophers are saying what is the good? [[00:03:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=213.52s)]
*  Others are saying what happens when an observation is made in quantum mechanics and others are like doing pretty hardcore [[00:03:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=218.7s)]
*  mathy logic and [[00:03:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=226.57999999999998s)]
*  Well, there's mathematical logic when there's also just big picture questions about logic. How does logic how do probability? [[00:03:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=228.82s)]
*  How do these things get used both in a perfectly rational world and also in the slightly irrational world in which we live? [[00:03:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=235.7s)]
*  We're gonna be talking about both of those things [[00:04:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=242.66s)]
*  I think it's intrinsically interesting to understand probability and logic better [[00:04:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=244.82s)]
*  But also super important to thinking about how science works. So let's go [[00:04:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=249.07999999999998s)]
*  I [[00:04:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=253.48s)]
*  Am in finals and welcome to the mindscape podcast. Thank you so much for having me Sean. I'm a big fan [[00:04:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=269.92s)]
*  I think what you're doing here is super important, especially nowadays [[00:04:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=275.53999999999996s)]
*  I hope you still think those things after we are done talking but I hope to make it true [[00:04:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=278.58s)]
*  So we're talking about stuff that is dear to my heart. We're talking about [[00:04:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=283.35999999999996s)]
*  Increasing the probability that something is right. We're talking about what probability is how it fits in with learning about things [[00:04:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=289.79999999999995s)]
*  Obviously science cares about this a lot. So let's start at the very high level and you tell me what probability really is [[00:04:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=295.44s)]
*  What probability really is well, there's many kinds of probabilities so there's probabilities in science [[00:05:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=305.08s)]
*  So for instance biology has its own conception of probability [[00:05:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=312.46000000000004s)]
*  Which shows up in the theory of natural selection, especially and genetics? [[00:05:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=317.48s)]
*  physics, of course, as you know better than I has lots to say about probability both in [[00:05:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=322.78000000000003s)]
*  classical and quantum physics [[00:05:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=327.94s)]
*  Yeah, so and in economics we also use probability and then in many other special sciences [[00:05:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=331.7s)]
*  My interest in probability I started out as a physicist so I started out interested in probability in physics [[00:05:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=338.76s)]
*  That's how I got into it [[00:05:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=344.46s)]
*  but over the years I became more and more interested in the role probability plays in [[00:05:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=345.38s)]
*  thinking about evidence and [[00:05:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=351.32s)]
*  how strong arguments are that is how strong something is as a reason for believing something else and [[00:05:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=353.58s)]
*  That's kind of the application of probability that I'm most interested in nowadays and in that context [[00:06:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=360.38s)]
*  There's still many kinds of probabilities because when you're assessing the strength of an argument, it really depends on the context [[00:06:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=366.66s)]
*  so if you're playing a game of chance say and [[00:06:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=373.16s)]
*  You're you know like poker and a certain card comes up and you're wondering well [[00:06:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=376.84000000000003s)]
*  What effect does that have on my probability of winning this hand? [[00:06:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=381.12s)]
*  Well, now, you know our probabilities to use they're given by you know [[00:06:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=384.64000000000004s)]
*  The probabilities of a game of chance each card is equally likely to be drawn and that allows you then to calculate the probability of any [[00:06:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=388.20000000000005s)]
*  Hand given you know what's left in the deck and so on and so there it's very clear [[00:06:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=395.34s)]
*  What probabilities to use to assess the strength of that as a reason for believing say that you'll win or lose the hand? [[00:06:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=399.78s)]
*  In other contexts, it's much more difficult to say which probabilities are the appropriate ones [[00:06:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=406.41999999999996s)]
*  So for instance if we're wondering whether a certain scientific theory is true [[00:06:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=412.18s)]
*  in fact [[00:06:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=416.32s)]
*  We might even be worried about whether a certain scientific theory of probability is true [[00:06:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=416.94s)]
*  And you might have two competing theories of what probability in a certain scientific context is like [[00:07:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=421.26s)]
*  Well there how are you going to adjudicate how strong the arguments are? [[00:07:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=428.09999999999997s)]
*  Well, you can't it would be question-begging to assume a notion of probability that say one of the theories adopts [[00:07:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=432.46s)]
*  But the other rejects that would just be question-begging [[00:07:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=438.3s)]
*  So what you need is some more general notion of probability that will allow you to evaluate arguments even in those contexts [[00:07:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=441.34s)]
*  And as a philosopher I want to go even more broad than that [[00:07:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=448.84s)]
*  I want to be able to assess arguments for the existence of God maybe or [[00:07:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=451.48s)]
*  For ethical claims and so on and as you get more and more abstract and these contexts get further and further away [[00:07:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=456.04s)]
*  Let's say from games of chance, which is kind of the easiest case [[00:07:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=462.0s)]
*  It gets more and more controversial what kinds of probabilities are the relevant ones? [[00:07:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=465.76s)]
*  But you know, I think of this like any other science Sean. I think [[00:07:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=471.08s)]
*  Probability theory it's a theory and then what you do when you're faced with a certain situation is you have to construct models of the theory [[00:07:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=475.1s)]
*  And okay, that's a very complicated process which involves making all kinds of assumptions and idealizations [[00:08:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=482.06s)]
*  And that's okay. And the goal there is to try to come up with the best [[00:08:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=489.3s)]
*  account of which probabilities we should use [[00:08:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=494.78000000000003s)]
*  so that we're [[00:08:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=497.98s)]
*  adjudicating this question of how strong the arguments are in a way that's not that's fair and [[00:08:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=499.46000000000004s)]
*  reasonable and [[00:08:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=504.26000000000005s)]
*  That's really a case-by-case thing. I think so [[00:08:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=505.82000000000005s)]
*  I was just a couple weeks ago at the retirement celebration conference for Barry lower [[00:08:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=508.48s)]
*  former mindscape guest and there was a talk by David Albert former mindscape guest and [[00:08:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=514.1800000000001s)]
*  in part in [[00:08:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=520.82s)]
*  response to things that I and others have been saying about quantum mechanics and self locating probabilities and David, you know, he was just [[00:08:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=522.82s)]
*  Unapologetically old-school about it [[00:08:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=531.8800000000001s)]
*  he says the only sensible use of probability is when you have a frequency of something happening over and over again and [[00:08:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=533.48s)]
*  You can sort of imagine taking a limit of it happening infinite number of times that and the ratio of the number of times [[00:08:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=539.36s)]
*  Where it looks like X rather than Y that's the probability and you know, I tried to say but okay, come on we certainly use [[00:09:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=544.96s)]
*  Probability in a much broader sense than that [[00:09:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=553.1600000000001s)]
*  We talked about the probability of a sports team winning a thing even though we're not gonna do it an infinite number of times [[00:09:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=555.5600000000001s)]
*  or even twice [[00:09:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=560.02s)]
*  so is there a consensus about [[00:09:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=561.68s)]
*  this very basic question about the relationship between [[00:09:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=565.3199999999999s)]
*  Frequencies and probabilities versus just a more epistemic like this is my best guess kind of thing [[00:09:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=568.84s)]
*  Right, okay good. Yes, so there's lots of you know, what used to be called interpretations of probability [[00:09:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=575.52s)]
*  But I would just call them theories of probabilities or as I say there are many the frequency theory [[00:09:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=580.56s)]
*  Well, it's a very strange theory actually [[00:09:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=585.3s)]
*  It started off as an actual finite frequency theory where you know the probability of some event is [[00:09:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=587.6999999999999s)]
*  Actually just given by the actual frequency of some event in some population [[00:09:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=595.54s)]
*  So for instance suppose you have a coin and it's been tossed exactly five times [[00:10:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=600.42s)]
*  Three heads and two tails and then it's destroyed [[00:10:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=605.02s)]
*  Well, according to the actual frequency theory the probability is you know, three-fifths that its heads [[00:10:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=608.14s)]
*  Wow and [[00:10:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=616.28s)]
*  In fact if there's any odd number of tosses actual odd number time, then you can't get an even you can't get one-half [[00:10:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=617.96s)]
*  So even if you have a fair coin if it's tossed in odd number of times then according to the actual frequency view [[00:10:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=624.44s)]
*  Probably it isn't fair. Okay, so so the actual freeze of you was a non-starter, right? That's not going to work [[00:10:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=630.28s)]
*  So yeah, also you can't get irrational values [[00:10:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=635.9200000000001s)]
*  You can't get you know, you can only get rational values and that seems wrong because physics has all kinds of irrational very probably [[00:10:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=638.52s)]
*  Okay, so then people said well, okay, maybe what we'll do is we'll talk about [[00:10:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=644.14s)]
*  Hypothetical infinite extensions of the actual experiment. Okay. Well, what does that mean? [[00:10:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=649.3s)]
*  They say think they say things like well [[00:10:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=655.5s)]
*  It's what would have happened had you continued indefinitely that initial sequence of five tosses and I want to say well [[00:10:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=657.66s)]
*  Here's that's very hard to understand because there's uncountably many [[00:11:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=664.0999999999999s)]
*  such [[00:11:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=669.26s)]
*  Extensions and on almost all of them. There's no limiting frequency [[00:11:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=670.52s)]
*  so [[00:11:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=675.54s)]
*  It's true that for any real number you can get that as the limiting frequency of an infinite sequence [[00:11:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=677.06s)]
*  But it's also true that almost all of the sequences don't have they diverge in their in their limiting frequency [[00:11:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=683.14s)]
*  So sorry, this is yeah sounds like you're paraphrasing some technical result with the use of the idea of almost all that's a that's a technical [[00:11:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=689.74s)]
*  math term [[00:11:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=697.9399999999999s)]
*  Yes, that's right. I just mean [[00:11:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=699.1999999999999s)]
*  Well, it's not all there's like a there's like a relatively small number of sequences that will converge [[00:11:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=702.16s)]
*  Yeah, but it's sort of like it's sort of like if you pick a real number at random [[00:11:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=708.8399999999999s)]
*  It's it's like what are the chances of getting a rational number pretty small there on most of them are not rational [[00:11:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=713.3199999999999s)]
*  by any reasonable measure of most and [[00:12:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=720.2399999999999s)]
*  The same thing is true here. You have all these sequences. Well, which one? [[00:12:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=723.16s)]
*  And so then you've got to say well which hypothetical infinite extensions are the ones that actually give you the real probability [[00:12:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=727.0600000000001s)]
*  And I just think this is the wrong. This is just the wrong way to go. My view is I like to make an analogy [[00:12:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=732.7800000000001s)]
*  With measurement in general say in physics [[00:12:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=740.58s)]
*  So you might think my national what is mass say it? [[00:12:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=743.4200000000001s)]
*  suppose just for the sake of argument that we're in a Newtonian universe and [[00:12:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=746.7800000000001s)]
*  Mass just behaves the way Newton thought it did just for sake of argument and then you think well [[00:12:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=750.4200000000001s)]
*  What is mass anyway? Well my view about what mass is in such a universe is it's whatever the theory says it is [[00:12:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=755.24s)]
*  It's it's the functional role played by that concept in all the laws and that's a very complicated thing [[00:12:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=761.32s)]
*  There's no easy way to summarize. It's just whatever Newton's theory says it is but you might be tempted by a different view [[00:12:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=766.64s)]
*  You might think well wait, maybe it's just frequencies [[00:12:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=773.0s)]
*  maybe it's just what you do is you make measurements and then you take an average and [[00:12:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=776.6800000000001s)]
*  Maybe if you take infinitely many measurements and [[00:13:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=783.22s)]
*  You take the limiting value of the average. Maybe that's what the mass of the object is. No [[00:13:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=787.02s)]
*  No, if you're lucky that is if you're most if you're lucky then if you were to do that [[00:13:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=792.34s)]
*  Of course, you can't do it [[00:13:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=797.46s)]
*  But if you were to do that then if you're lucky you would get something very close to the actual mass [[00:13:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=798.14s)]
*  But that isn't what the mass is and I want to say the same thing about probability [[00:13:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=802.5s)]
*  Suppose you're doing some quantum mechanical experiment, right? You can make measurements. That's what you do [[00:13:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=807.48s)]
*  You make make you make a lot of measurements and you take averages and you do statistics and that's how you [[00:13:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=812.6800000000001s)]
*  Estimate the probability that something will be observed in a quantum mechanical system [[00:13:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=817.36s)]
*  But that's not what the probability is. The probability is what the theory says it is [[00:13:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=821.72s)]
*  And whatever that is so one property it has is you know, you use Born's rule to calculate what the probability is [[00:13:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=827.0400000000001s)]
*  Okay, that's a really complicated theoretical story, but but the probability isn't any sequence of measurements [[00:13:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=833.2199999999999s)]
*  It's not any limiting frequency. That's a symptom of this property of probability [[00:13:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=839.02s)]
*  But the property is what the theory says it is. So I just think the frequency view has got everything backwards [[00:14:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=844.16s)]
*  Frequencies are just the way we maybe know about probabilities, but they're not what the probabilities are [[00:14:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=849.66s)]
*  So that's that with you. Oh, I'm very sympathetic to that [[00:14:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=855.3s)]
*  How's that how does that view fit in with the sort of classic divide between thinking that probabilities are mostly epistemic [[00:14:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=858.1999999999999s)]
*  They're about our knowledge versus the probabilities latch on to some objective chances out there in the world. Oh [[00:14:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=865.4399999999999s)]
*  I think certainly there are objective probabilities. As I said, I think not just in physics but also in biology [[00:14:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=872.7199999999999s)]
*  I think each theory has its own concept of probability and at least the probabilistic theories do and [[00:14:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=879.14s)]
*  What probability is in those systems is whatever the theory says it is it's just like mass [[00:14:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=885.26s)]
*  So that's I have a very flat-footed view of that and so in quantum mechanics [[00:14:50](https://www.youtube.com/watch?v=JG57WvAWzUM&t=890.86s)]
*  Well, we know how to calculate probabilities the theory tells us to you know in statistical mechanics. We can also calculate [[00:14:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=895.64s)]
*  probabilities as well and [[00:15:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=901.54s)]
*  We can we can do that as well, you know, but and now you might wonder about the interpretation of those probabilities [[00:15:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=904.78s)]
*  But you can certainly calculate things which obey the laws of probability and system mechanics and so in that sense at least they are probabilities [[00:15:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=911.4399999999999s)]
*  They satisfy the formal principles of probability [[00:15:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=917.9599999999999s)]
*  And so yeah, I mean I I saw I want to say certainly there are objective probabilities. No question [[00:15:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=921.04s)]
*  I'm a scientific realist. So, you know if a theory if I accept a theory and the theory says there's a thing then there's that thing [[00:15:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=927.68s)]
*  That's it. So I I'm a realist so I don't have any problem with that. However [[00:15:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=932.92s)]
*  The problem is and you know where things get really tricky [[00:15:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=938.4s)]
*  I think and this is what got me really interested in in other notions of probability [[00:15:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=941.86s)]
*  The tricky thing is as I said suppose there's a dispute about the nature of probability in some physical context [[00:15:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=945.8s)]
*  Right. There's a dispute about that. You have two theories one theory says probably behaves like this [[00:15:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=953.78s)]
*  Another theory says behaves like that and then you do experiments [[00:15:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=958.34s)]
*  Okay, and you try to use that data to adjudicate, you know [[00:16:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=961.42s)]
*  Does the evidence favor the one theory of probability over the other well [[00:16:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=964.74s)]
*  Whatever probability you can you're using there. You got to be very careful because you don't want to beg any questions [[00:16:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=970.16s)]
*  So you don't want to use the probability that the one theory says is correct [[00:16:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=975.32s)]
*  But the other says incorrect to do the very calculations of how strong the arguments are that would be question-begging [[00:16:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=978.88s)]
*  So I think what you in those settings you need some other notion of probability and that's where I think the epistemic notion [[00:16:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=985.32s)]
*  Comes in I think you need it in at least these contexts where [[00:16:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=992.7s)]
*  You you're actually trying to adjudicate different physical theories of probability say you can't use [[00:16:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=997.58s)]
*  What one theory says to adjudicate because that would just beg the question against the other theory [[00:16:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1003.22s)]
*  Yeah [[00:16:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1008.78s)]
*  And so I think in those contexts at least you're gonna need some other notion of probability something neutral like a like a judge is [[00:16:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1009.1800000000001s)]
*  Impartial so you need some impartial notion of probably and I think this is the kind of notion that [[00:16:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1015.4s)]
*  Statisticians have been trying to come up with [[00:17:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1020.4599999999999s)]
*  You know ever since that early work in genetics [[00:17:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1022.98s)]
*  Which is where it all really started with Fisher and and how Dane and all those kinds of people and Pearson [[00:17:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1025.78s)]
*  so but [[00:17:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1033.7s)]
*  This is where I think Bayesianism is helpful the Bayesian approach because at least in these contexts where we're not sure [[00:17:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1035.7s)]
*  We're uncertain what the correct theory of probability is [[00:17:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1043.62s)]
*  We need something that's it feels like it's got to be epistemic at least it's got to be neutral and [[00:17:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1047.16s)]
*  It's got to be something you can use to adjudicate [[00:17:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1052.92s)]
*  does the evidence favor one theory of probability say over another and [[00:17:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1055.6000000000001s)]
*  But and for that matter like I said you want to adjudicate debates in other areas where? [[00:17:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1060.16s)]
*  Who knows what the probability of Newton's theory is I mean even if they're even if there are objective physical probabilities [[00:17:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1064.8s)]
*  It's hard to imagine how they would tell us what the probability is that Newton's theory is true good [[00:17:50](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1070.76s)]
*  Well, I mean, it's just what would that mean so so I think in those contexts where we're adjudicating physical theory say Newton versus Einstein [[00:17:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1075.4s)]
*  Or two different versions of quantum theory or something else [[00:18:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1082.8200000000002s)]
*  We're gonna need a some other notion of probability and that's where I think the Bayesian [[00:18:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1086.94s)]
*  Approach is kind of needs something like that because you need something neutral. I [[00:18:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1091.5800000000002s)]
*  Think I would have said [[00:18:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1097.02s)]
*  15 minutes ago that I don't believe that there is any such thing as objective probability in the world [[00:18:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1099.18s)]
*  I think that there's the world and [[00:18:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1104.9s)]
*  We describe the world the best we can and maybe we have incomplete information [[00:18:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1108.3200000000002s)]
*  So we appeal to some probability, but there's some exact description of it also [[00:18:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1112.74s)]
*  But and of course if you're judging between different theories of the world then you have some epistemic view of probability [[00:18:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1116.3000000000002s)]
*  But now you're pointing out that okay, but there's a notion of a thing that appears in a theory [[00:18:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1122.46s)]
*  whether it's quantum mechanics or [[00:18:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1129.22s)]
*  Genetics or whatever and that thing obeys the laws of probability it adds up to one and whatever and we might as well call that [[00:18:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1131.8600000000001s)]
*  objective [[00:18:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1138.82s)]
*  Yeah, yeah, I mean just like I would want to call mass objective. Yeah, I would say the probability in quantum mechanics [[00:19:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1140.02s)]
*  That's delivered by you know, the Born rule or whatever. However, you calculate it whatever that is [[00:19:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1146.54s)]
*  It's some real thing. It's just as real as mass or any other theoretical quantity [[00:19:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1151.38s)]
*  It seems to me that theory that the theory implicitly defines through its laws [[00:19:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1155.8s)]
*  So, yeah, I mean again, I'm a realist though, so I have to just fuss up to that [[00:19:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1159.44s)]
*  I'm but yeah, but as I say even if you're not a realist even if you think okay [[00:19:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1163.88s)]
*  Maybe there's different kinds of probabilities [[00:19:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1168.92s)]
*  But none of them is objective and in the relevant sense still if you want to know whether some evidence favors one of those theories [[00:19:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1171.0s)]
*  Over another one and you want that to be a probabilistic inference, which it is because it's not going to be deductive [[00:19:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1177.6s)]
*  I mean after all [[00:19:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1182.84s)]
*  Scientific evidence doesn't entail the answer to these questions [[00:19:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1184.12s)]
*  It doesn't deductively guarantee that one theory is true and the other is false. It just at best [[00:19:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1187.04s)]
*  Makes favors one over another and that's gonna have to be I think the best way to model that is probabilistically [[00:19:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1192.72s)]
*  But then you need a general framework of probability that's gonna have to be I don't know epistemic or something less objective [[00:19:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1198.36s)]
*  In that sense because otherwise it would it would run the risk of just begging the question [[00:20:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1205.72s)]
*  so good this leads us right into where I wanted to go, which is the [[00:20:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1210.92s)]
*  Idea of induction and how in the early days people tried to hope that [[00:20:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1215.56s)]
*  inductive reasoning [[00:20:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1221.7199999999998s)]
*  You know looking at many many examples and generalizing would be a kind of logic that would fit the scientific process [[00:20:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1222.7199999999998s)]
*  And then other people point out that there are problems with induction [[00:20:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1228.8799999999999s)]
*  So I mean pretend we're in the philosophy 101 class like what are the problems that people have with induction? [[00:20:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1233.12s)]
*  Well of course in philosophy [[00:20:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1238.22s)]
*  You know in epistemology generally you generally start out with the really really hard problems like skepticism and and induction is no is no different [[00:20:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1240.22s)]
*  Yeah, when you're studying philosophy of induction you tend to start with these skeptical arguments [[00:20:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1248.26s)]
*  You know like David Hume was was had a kind of skeptical arguments. He's like well, okay [[00:20:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1253.74s)]
*  You say there are these arguments that are you know that don't guarantee the truth of their conclusions [[00:20:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1258.6200000000001s)]
*  If their premises are true well their conclusions [[00:21:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1264.3s)]
*  Maybe they're quote-unquote probably true, but they're not guaranteed to be true like in mathematics and he he gave this dilemma [[00:21:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1267.58s)]
*  He said well, let's think about how that would actually work [[00:21:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1274.06s)]
*  so suppose you know you've observed the Sun rising and you know a million times and [[00:21:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1276.94s)]
*  You infer that on the basis of that evidence historical evidence that the Sun will rise tomorrow [[00:21:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1283.1399999999999s)]
*  He points Hume points out that well [[00:21:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1289.1399999999999s)]
*  That argument assumes some kind of principle of regularity of nature that you know the past [[00:21:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1292.62s)]
*  The future will resemble the past [[00:21:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1298.98s)]
*  And now if you ask how are you going to justify that premise that the future will resemble the past? [[00:21:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1301.3799999999999s)]
*  Well, you can't give a deductive argument for it because well, how would you do that? [[00:21:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1307.22s)]
*  I mean nothing you've observed is going to entail that the future will resemble the past [[00:21:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1312.5s)]
*  In other words, there'll always be some chance that you can't rule out with certainty that the future won't resemble the past [[00:21:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1316.4599999999998s)]
*  So it won't be a deductive argument [[00:22:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1323.3799999999999s)]
*  And then if it's an inductive argument, it just feels like now it's going to beg the question because well wait [[00:22:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1325.06s)]
*  What are you going to do reason as follows in the past? The future has resembled the past [[00:22:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1330.22s)]
*  So therefore in the future the now you're just it's now you're just circular now [[00:22:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1335.3799999999999s)]
*  It's just a circular argument because you're assuming the very principle of the future [[00:22:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1340.54s)]
*  Circular argument because you're assuming the very principle that you mean to justify in order to justify the argument [[00:22:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1344.02s)]
*  So, you know philosophy always starts with these skeptical arguments [[00:22:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1349.26s)]
*  I mean you but you you don't have to worry about induction [[00:22:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1352.94s)]
*  I mean this happens in every field like why believe there's an external world after all you can't rule out with certainty that there's an evil demon [[00:22:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1355.26s)]
*  Or that you're in a simulation or etc. Etc. Etc [[00:22:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1361.94s)]
*  You know, so what you I think what you got to do when you're doing philosophy [[00:22:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1364.78s)]
*  there's sort of the first thing you have to do in any of these domains is [[00:22:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1368.66s)]
*  Figure out how you're gonna respond to skeptic that is [[00:22:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1371.98s)]
*  What are you gonna what are you gonna say? Why do you think that there's an external world for it? [[00:22:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1375.34s)]
*  Let's start there and then we'll get to induction. Well, why do you think there's an external world? [[00:22:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1379.6599999999999s)]
*  Well, um, I can only speak for myself [[00:23:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1383.86s)]
*  The reason I think there's an external world is when I think about everything that I take myself to know [[00:23:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1386.54s)]
*  You know everything I take to be evidence about the world [[00:23:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1391.58s)]
*  All my observations, you know everything I take to be true and I think well, what's the best explanation of all of that? [[00:23:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1394.5s)]
*  To me, I don't see any way to plausibly explain all that stuff without postulating [[00:23:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1401.6200000000001s)]
*  the existence of an external world that is mind independent in many ways and [[00:23:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1406.66s)]
*  That's why I think there's a mind independent external world [[00:23:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1412.0600000000002s)]
*  And now I want to take the same anti skeptical view about induction. I [[00:23:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1415.5s)]
*  Think well, how do you explain? [[00:23:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1421.74s)]
*  Say the success of science or what appears to be the progress of science? [[00:23:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1424.94s)]
*  Well, I don't know but it seems hard for me to be able to explain that unless there weren't some [[00:23:50](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1430.02s)]
*  principles of when evidence actually does favor one scientific theory over another [[00:23:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1437.78s)]
*  And does provide reason to believe one rather than the other [[00:24:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1443.94s)]
*  and so what I tend to do is think about historical cases of that look like real scientific progress and then [[00:24:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1447.46s)]
*  What's the best way to explain that? So for instance when [[00:24:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1454.5s)]
*  When Einstein's general relativity theory of general relativity overtook Newton's theory of celestial motion [[00:24:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1457.78s)]
*  There were a lot of experiments that were crucial one was the motion of mercury the motion of mercury [[00:24:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1463.3s)]
*  Mercury moves in this very strange way around the Sun and [[00:24:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1467.94s)]
*  It was known that was known for a long time that it had this strange motion [[00:24:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1472.1000000000001s)]
*  well, the Newtonians tried their best to give explanations of that and [[00:24:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1476.3400000000001s)]
*  In the past they had had similar episodes, but they were able to explain [[00:24:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1481.8600000000001s)]
*  It by some missing mass that they found, you know, that was in the universe that they didn't know about and but eventually they realized now [[00:24:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1485.3s)]
*  There's no there isn't going to be the right hidden mass here. It's Newton's theory is just not going to be able to predict this [[00:24:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1492.26s)]
*  This is just a thing that Newton's theory can't explain can't predict and then Einstein comes along and gives a theory that explains all [[00:24:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1498.4199999999998s)]
*  The stuff Newton's theory could explain and this thing too and a bunch of other stuff that it couldn't explain [[00:25:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1505.7s)]
*  And this thing too and a bunch of other stuff that it couldn't explain [[00:25:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1510.82s)]
*  I that just now I want to say well [[00:25:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1514.1799999999998s)]
*  That just seems to make it more probable that Einstein's story is true [[00:25:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1517.06s)]
*  Or at least more probable that you know, that would be the better bet to make that would be the more acceptable theory [[00:25:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1520.98s)]
*  and [[00:25:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1527.9399999999998s)]
*  I think a probabilistic way of modeling that is just the best way that I know to model it. And so again [[00:25:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1528.82s)]
*  I just think well, what's the best explanation of these episodes of scientific progress? [[00:25:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1534.4199999999998s)]
*  And to me part of that has to be well [[00:25:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1538.58s)]
*  There just must be cases where the evidence really does favor one theory over another [[00:25:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1540.58s)]
*  Not that it guarantees that one's true and the other's false or anything like that [[00:25:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1545.3799999999999s)]
*  But it sort of raises the probability of one more than the other [[00:25:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1548.4199999999998s)]
*  And I just think I don't know how else to explain science episodes of scientific progress unless something like that is true [[00:25:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1552.82s)]
*  um [[00:25:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1558.82s)]
*  So I so I believe that something like that is true now the details of it are difficult to work out [[00:25:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1559.9399999999998s)]
*  But I think this is what statisticians as I said have largely been trying to figure out [[00:26:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1565.5400000000002s)]
*  How those inferences work like when we have an experiment and we think the evidence favors one theory of another what's the right? [[00:26:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1570.74s)]
*  Way to use probability right to model that and there's a lot of disagreement, of course in statistics between basians and classical [[00:26:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1577.7s)]
*  Statisticians there's all kinds of different schools. But one thing they all agree on is [[00:26:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1585.3000000000002s)]
*  There are episodes where the evidence favors one theory over another [[00:26:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1589.3000000000002s)]
*  And probability is an is an indispensable part of the explanation why [[00:26:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1593.54s)]
*  I do they all agree on that much [[00:26:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1598.18s)]
*  It might be unfair of me, but I do think that [[00:26:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1600.02s)]
*  It's a very common phase in an individual's philosophical maturation [[00:26:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1602.98s)]
*  To realize that not everything can be established on rock hard foundations that you agree with 100 [[00:26:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1608.66s)]
*  Like sometimes just gotta say this is the best we can do with what we got [[00:26:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1615.78s)]
*  Absolutely, I think most of the time we're kind of in that in that situation and that's okay [[00:26:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1619.14s)]
*  So I think but you know, that's the nature of these inferences as I said, it's not like deduction [[00:27:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1624.26s)]
*  You don't have the certainty of mathematics in these kinds of inferences [[00:27:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1629.8600000000001s)]
*  So, you know, there's going to be something that's under determined [[00:27:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1634.18s)]
*  You know, it's not going to exactly determine completely what our attitude should be [[00:27:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1638.5s)]
*  There's going to be some wiggle room some leeway [[00:27:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1643.3000000000002s)]
*  Some leeway [[00:27:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1645.7800000000002s)]
*  So in a way you're always making something of a leap of faith when you do one of these [[00:27:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1646.98s)]
*  Ampliative or inductive inferences and I just think you kind of have to live with that, you know and do the best you can [[00:27:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1650.74s)]
*  And this leads us right into you're very good at this [[00:27:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1656.98s)]
*  You're just bringing us along on the logical train of thought that we need to be on [[00:27:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1659.6200000000001s)]
*  the idea of confirmation [[00:27:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1664.0200000000002s)]
*  To try what we're trying to do is to formalize this idea [[00:27:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1666.42s)]
*  Like you just said that you know, einstein's theory is simple if it's the data newton's theory doesn't fit the data [[00:27:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1668.98s)]
*  In some sense einstein has now become more probably right than newton. What sense is that? [[00:27:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1675.5400000000002s)]
*  And confirmation is one of the words that gets batted around [[00:28:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1681.46s)]
*  I wanted to really sort of carefully explain to us what that's supposed to mean because I think [[00:28:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1684.74s)]
*  Many people informally think that if you've confirmed something, you know, it's true 100% and that's not how philosophers use the word [[00:28:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1689.0600000000002s)]
*  No, that's right. That's right. So yeah in in ordinary language the word confirmation has very strong [[00:28:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1698.8200000000002s)]
*  Conditions, but in the philosophy of induction confirmation is actually a very weak. It's actually a very weak claim and [[00:28:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1704.1599999999999s)]
*  I think a helpful example. I like to use simple examples [[00:28:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1711.22s)]
*  I think a nice nice example to use is one of diagnostic testing [[00:28:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1714.82s)]
*  I always like this example and in a way [[00:28:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1720.18s)]
*  I think it's kind of fully general because in a way you can think of scientific experiments [[00:28:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1722.6599999999999s)]
*  as a kind of diagnostic test [[00:28:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1726.8999999999999s)]
*  Where you're testing the world to see whether some hypothesis is true or false [[00:28:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1729.46s)]
*  And so when you design an experiment you really are in a way designing a diagnostic test [[00:28:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1733.3000000000002s)]
*  And so but let's think about diagnostic testing. So for instance [[00:28:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1738.42s)]
*  There are many diagnostic tests that are very reliable that you can buy in the store now [[00:29:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1742.66s)]
*  So for instance, you could you could buy a pregnancy test or an hiv test [[00:29:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1746.18s)]
*  Any of these tests that you buy if you read the box, you'll you'll notice something very interesting [[00:29:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1750.74s)]
*  On the box there's things they tell you and there's things they don't tell you [[00:29:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1756.66s)]
*  So one thing they tell you for sure is [[00:29:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1760.8999999999999s)]
*  What they call the true positive rate and the false positive rate of the test, right? [[00:29:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1764.5s)]
*  So the true positive rate is something like this suppose that you have the disease [[00:29:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1768.6599999999999s)]
*  Then how probable would it be that you would get a positive result from this test? [[00:29:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1775.1399999999999s)]
*  And then on the other the false positive rate is suppose you don't have the disease then how probable is a positive result? [[00:29:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1780.26s)]
*  And with the great thing about these diagnostic tests is you can determine those those error rates in the laboratory [[00:29:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1785.94s)]
*  You don't need to know anything about the subjects the particular subjects that are using it and so on [[00:29:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1792.5800000000002s)]
*  And that's why they can put that information on the box. It's very reliably known [[00:29:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1797.5400000000002s)]
*  Well that ratio of the true positive rate to the false positive rate is called a bayes factor [[00:30:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1801.22s)]
*  It's also called a likelihood ratio [[00:30:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1805.8600000000001s)]
*  And it doesn't determine how probable the hypothesis is [[00:30:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1808.2600000000002s)]
*  Given a positive result it doesn't determine that [[00:30:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1814.02s)]
*  In order to know that how probable it is that you have the disease you have to plug in what's called a prior probability [[00:30:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1817.14s)]
*  An a priori probability philosophers call it and what is that? [[00:30:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1824.18s)]
*  Well, that's something like the probability you how probable you think it is before looking at the evidence [[00:30:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1827.14s)]
*  Okay, well what that what is that well, of course, um the guys who design the test they can't tell you what that is [[00:30:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1834.66s)]
*  That's going to depend very centrally on things about you. So for instance suppose it's a pregnancy test [[00:30:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1841.06s)]
*  And if someone takes a pregnancy test and they get a positive result, well [[00:30:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1846.74s)]
*  They'll know the likelihood ratio. They'll know the the error rates, you know [[00:30:50](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1850.5s)]
*  False positive and true positive so they'll know how reliable the test is in that sense [[00:30:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1854.4199999999998s)]
*  But to get how probable it is that they're pregnant [[00:30:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1858.02s)]
*  Well, they need to know a lot about maybe their own behavior in recent days and so on which of course [[00:31:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1861.6999999999998s)]
*  The designers of the experiment can't know and and should and don't need to know in order to know the error rates [[00:31:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1867.22s)]
*  Right. So for I just to put an example on this [[00:31:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1873.3000000000002s)]
*  so if there is a pregnancy test that [[00:31:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1876.8200000000002s)]
*  The likelihood is very high like, you know, it's it is claimed that [[00:31:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1880.42s)]
*  Uh, if if it comes out positive the likelihood that you're pregnant is very is very large [[00:31:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1885.14s)]
*  But if I took a pregnancy test of that form, I am biologically incapable of becoming pregnant [[00:31:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1889.7800000000002s)]
*  I know that pretty with pretty high probability. So if I happen to get a positive [[00:31:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1895.14s)]
*  I would not conclude that my probability of being pregnant is high because my prior is so low [[00:31:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1900.9s)]
*  Exactly exactly. In fact, it might even be zero, you know, depending on the case [[00:31:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1907.3600000000001s)]
*  But it'll be very close to zero and that's exactly the distinction that I want to make [[00:31:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1911.8600000000001s)]
*  This distinction between that bayes factor that how reliable the test is which is just the ratio really of those two error rates [[00:31:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1916.3400000000001s)]
*  That could be really high but all that tells you is [[00:32:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1923.62s)]
*  What to multiply the prior by to get the posterior basically, it's like a multiplier. So if you start off [[00:32:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1926.74s)]
*  Low, but not that low and then you get a really reliable test [[00:32:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1934.1s)]
*  Well, maybe it's a multiplier by a factor of a thousand [[00:32:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1936.6599999999999s)]
*  Well, then you're going to have a reasonably high probability [[00:32:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1939.06s)]
*  But if you start really really low then even if you have a pretty high factor [[00:32:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1941.54s)]
*  A multiplicative bayes factor still you're going to end up low [[00:32:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1946.6599999999999s)]
*  And this people are very bad at making these inferences [[00:32:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1950.5s)]
*  This is something that Kahneman Tversky discovered back in the 80s. They called it the base rate fallacy [[00:32:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1954.34s)]
*  And when people are given an example like this where okay [[00:32:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1960.5s)]
*  So you have a reliable test for a rare disease [[00:32:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1964.34s)]
*  They're told the disease is rare like one in a thousand and then they're given pretty good error rates and they say well [[00:32:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1967.22s)]
*  And then they're asked how probable is it that the person has disease and often people give a very high number [[00:32:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1972.74s)]
*  And in fact, interestingly the numbers tend to cluster [[00:32:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1978.26s)]
*  around [[00:33:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1982.8999999999999s)]
*  Basically the bayes factor if you normalize it to a zero to one scale [[00:33:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1984.5s)]
*  And I don't think this is a coincidence. I think what's happening here is you have two factors [[00:33:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1988.6599999999999s)]
*  There are two things that are relevant here. There's how probable [[00:33:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1993.3s)]
*  it is that you have disease the probability of disease and then there's [[00:33:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=1997.1399999999999s)]
*  The how confirmation there's how much the evidence confirms and that's just how much does it change? [[00:33:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2000.82s)]
*  How much does it raise the probability? [[00:33:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2006.58s)]
*  And I think in these cases what you have is low probability but high confirmation that can be very confusing [[00:33:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2008.98s)]
*  Because both of these things are relevant to quote unquote how strong the argument is [[00:33:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2015.78s)]
*  But that is how strong the evidence is as a reason to believe that the disease is present [[00:33:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2020.82s)]
*  But they go in different directions. So it can be very confusing and then you might but there's still a residual question [[00:33:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2026.58s)]
*  Well, why would people defer to the relevance to the confirmation number? [[00:33:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2032.5s)]
*  Right, right when they're asked about probability [[00:33:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2037.22s)]
*  Um, I think this is not a crazy thing to do at all [[00:33:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2039.78s)]
*  As we said those error rates are objective and invariant in a really important sense. You can just discover them in laboratories [[00:34:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2043.06s)]
*  Uh, you could just by working with the causal structure of the test and the chemicals you're looking for [[00:34:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2051.3s)]
*  You can be pretty confident about those error rates [[00:34:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2056.5s)]
*  Independently of the prior probability [[00:34:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2059.46s)]
*  And so there's something more objective. Yeah about those numbers and you know, there's something really ironic [[00:34:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2062.1000000000004s)]
*  about the conamitversky research because [[00:34:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2068.98s)]
*  If you read their own paper [[00:34:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2072.5s)]
*  Well, that's a scientific paper. And so what do scientific papers do? [[00:34:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2074.7400000000002s)]
*  Well, they generally design an experiment and then perform an experiment and the experiment generates evidence [[00:34:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2078.5s)]
*  What do they tell you about the experiment? [[00:34:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2084.34s)]
*  What do they tell you about how to interpret that? [[00:34:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2086.34s)]
*  Do they tell you how probable their hypothesis is to be true given the evidence? [[00:34:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2088.34s)]
*  Of course, they don't just like the diagnostic test maker can't tell you how probable it is that you have disease [[00:34:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2092.34s)]
*  That relies on this prior information that they don't know [[00:34:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2098.34s)]
*  Science is the same way [[00:35:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2101.86s)]
*  When you design an experiment what you're really doing is trying to get maximum conformational power out of the experiment [[00:35:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2103.86s)]
*  You want it to be as much of a multiplier of that prior probability as you can [[00:35:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2110.34s)]
*  Either either a multiplier or a divider if it's if it's evidence against then okay [[00:35:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2115.3s)]
*  Then it's kind of a divider of how probable it is. It makes it smaller. It makes the probability smaller [[00:35:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2120.02s)]
*  But the point is it's not [[00:35:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2123.6200000000003s)]
*  Probability that you're you you can't maximize the probability that your hypothesis is true [[00:35:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2126.1800000000003s)]
*  That depends on the prior and different scientists are going to have different priors when they when they look at experiments [[00:35:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2130.34s)]
*  When they when they look at experiments [[00:35:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2136.2599999999998s)]
*  So all you can tell people basically is what the likelihood ratio what that base factor is of your experiment [[00:35:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2139.14s)]
*  Including conameters to versic's own experiment. So there's this real irony if they're implicitly criticizing human beings [[00:35:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2144.96s)]
*  For being bad at doing a thing [[00:35:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2152.18s)]
*  That their own paper doesn't require scientists reading the paper to do [[00:35:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2154.66s)]
*  In the big picture, I was a little cheeky. I put this idea as [[00:35:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2158.9s)]
*  Everyone's entitled to their own priors. No one's entitled to their own likelihoods [[00:36:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2163.3799999999997s)]
*  Exactly, and I think that's exactly right. And so I think there's something [[00:36:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2168.1s)]
*  Not irrational here about deferring to the likelihood information after all that's the objective [[00:36:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2172.8999999999996s)]
*  that's the invariant information that we can know and [[00:36:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2178.02s)]
*  And that's how science works, right scientific papers [[00:36:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2182.42s)]
*  They basically report base factors or something about whether the evidence favors one theory over another [[00:36:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2185.06s)]
*  They don't tell you how probable it is that one theory is true or the other theory is true [[00:36:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2190.26s)]
*  They know that's going to depend on these priors and they don't know the prior probabilities of their readership depends on what the readership knows [[00:36:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2194.5s)]
*  And so our self-appointed task is to come up with a formal understanding of this idea of confirmation like clearly it's important [[00:36:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2201.86s)]
*  I mean, maybe you have your own priors [[00:36:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2209.54s)]
*  Maybe you disagree or maybe you agree about them, but we should be able to quantify how much [[00:36:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2211.94s)]
*  The new evidence is confirming our theories and it's also like you say, but maybe it's worth emphasizing [[00:36:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2216.9s)]
*  It's weaker [[00:37:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2222.9s)]
*  Than entailment than from deductive logic. We're familiar from high school [[00:37:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2224.5s)]
*  P and if p then q therefore q like that sounds solid that sounds logic to us and we [[00:37:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2230.82s)]
*  want a logic of [[00:37:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2236.02s)]
*  confirmation [[00:37:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2238.7200000000003s)]
*  Yes. Yes, and and we can have one and and [[00:37:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2240.1s)]
*  Basically those base factors they give it to you [[00:37:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2243.2999999999997s)]
*  One thing that's really interesting about this literature and is this is really [[00:37:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2247.14s)]
*  What my this is what I really got interested in when I was in grad school [[00:37:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2251.8599999999997s)]
*  I wrote my dissertation on this if you look in the literature on probability statistics bay zinism any of that literature [[00:37:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2254.3399999999997s)]
*  There's lots of measures of this confirmation. There's lots of measures of say degree of correlation. So correlation is another word for confirmation [[00:37:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2261.3799999999997s)]
*  It's just when one thing raises the probability of another right? [[00:37:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2268.5s)]
*  There's lots of measures of how strong that confirmation is one thing you could do is just take the posterior probability and subtract off the prior [[00:37:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2272.34s)]
*  Probability and you could say well how that's one way of measuring how much of a difference the evidence made to the hypothesis [[00:38:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2280.1s)]
*  But there's many ways to do it because it turns out [[00:38:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2286.26s)]
*  That you can define correlation in in many equivalent ways [[00:38:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2290.1800000000003s)]
*  So one way is the the posterior is greater than the prior that's one way [[00:38:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2294.02s)]
*  But another way is that the true positive rate is greater than the false positive rate [[00:38:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2298.82s)]
*  Right, uh or greater than one minus the false project [[00:38:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2304.82s)]
*  So the probability evidence given the hypothesis is greater than the probability evidence given the denial of the hypothesis. Yeah [[00:38:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2308.1s)]
*  And that's equivalent qualitatively those are going to be true at this [[00:38:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2314.34s)]
*  But if you define measures based on those inequalities, they're actually different [[00:38:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2317.86s)]
*  They don't agree on which thing is better confirmed than which they actually disagree on orderings of how well confirmed [[00:38:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2321.78s)]
*  Hypotheses are so they can't be measuring the same thing. It's it's either it's being confirmed or disconfirmed, but they don't agree on how much [[00:38:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2327.94s)]
*  Exactly. And so if you want to measure it, which of course we do we want to know how much [[00:38:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2335.52s)]
*  Then you've got to pick one of these many and there's dozens of measures and they all disagree and I and I this is what I survey [[00:39:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2340.58s)]
*  in my dissertation [[00:39:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2345.94s)]
*  um, and so you've got to pick one now the the good news is [[00:39:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2347.2200000000003s)]
*  That if you're an inductive logician [[00:39:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2351.46s)]
*  Which is a certain tradition that i'm a member of [[00:39:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2353.94s)]
*  You've got you actually have a criterion that allows you to narrow things down to a unique measure and it turns out to be [[00:39:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2357.38s)]
*  The base factor the same thing that people report on the boxes of the diagnostic tests [[00:39:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2362.66s)]
*  And it's a very simple criterion. The criterion is however we're measuring [[00:39:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2367.86s)]
*  this confirmation [[00:39:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2372.9s)]
*  It should be such that it generalizes entailment in the following sense [[00:39:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2374.9s)]
*  if [[00:39:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2379.86s)]
*  The evidence did entail the hypothesis if it guaranteed that the hypothesis was true [[00:39:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2380.9s)]
*  Then that should receive a maximal value of confirmation and if it refuted the hypothesis [[00:39:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2386.82s)]
*  Entailed that it was false falsified it then that should be a minimal value [[00:39:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2392.58s)]
*  Just add that as a criterion and you're basically uniquely down to this base factor [[00:39:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2397.78s)]
*  good [[00:40:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2402.66s)]
*  And so that gives us if we're in the framework of inductive logic now [[00:40:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2403.7000000000003s)]
*  We actually do have a unique way of measuring and it just turns out and i'm not sure this is a coincidence [[00:40:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2407.06s)]
*  But it turns out it's the very same base factor that they tell you when you buy a diagnostic test [[00:40:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2411.14s)]
*  Good. Yeah, i'm now going to look in stores for diagnostic tests that tell me what my priors should be but [[00:40:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2417.2999999999997s)]
*  Right, that's right. It's a probability nine-tenths that you're pregnant no matter who you are [[00:40:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2423.62s)]
*  So just this might be a tiny little aside, but I remember when I was young and taking my first philosophy of science course [[00:40:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2429.7s)]
*  Um when we came to carl popper [[00:40:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2436.9s)]
*  Uh, we were taught that his notion of falsification [[00:40:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2440.1800000000003s)]
*  Was supposed to be a better thing to think than the old-fashioned logical positivist notion of confirmation [[00:40:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2444.1s)]
*  I know now that we weren't actually told what that old-fashioned logical positivist notion of confirmation actually was or at least it didn't become clear to me [[00:40:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2452.1s)]
*  But what is the difference between those two ideas? [[00:40:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2458.9s)]
*  Yeah, so this is that's a great question. So [[00:41:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2461.86s)]
*  There so I think popper was right in a sense there is an important asymmetry when you think about degrees of confirmation [[00:41:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2464.9s)]
*  So let's think about [[00:41:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2473.14s)]
*  How strongly? [[00:41:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2475.38s)]
*  Does something that refutes? [[00:41:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2477.14s)]
*  What's the conformational impact of that versus something that's that doesn't refute? [[00:41:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2480.58s)]
*  Well, as I just said our criterion requires refutation to be that's the worst [[00:41:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2485.7s)]
*  That's the most negatively relevant you can be and so in this sense, this is the kernel of truth of what popper said [[00:41:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2490.9799999999996s)]
*  Refuting evidence is more powerful than non-refuting evidence [[00:41:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2497.12s)]
*  Good, uh as a negative evidence and that's absolutely true. He's absolutely right about that [[00:41:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2501.2999999999997s)]
*  That's in fact one of the criteria that we use to get down to a unique the base factor measure [[00:41:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2505.7s)]
*  So I think popper's sort of what he what he wasn't right about was that all there is is refutation [[00:41:50](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2510.66s)]
*  So popper had this weird view that there's no such thing as inductive arguments here [[00:41:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2516.82s)]
*  I think he was influenced by hume. I think he really got hooked on that skeptical argument and he thought well [[00:42:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2520.82s)]
*  The only arguments that could be compelling must be deductive. So there aren't any inductive arguments. So [[00:42:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2527.38s)]
*  Well, then everything must be refutation. That is right. That's that was all that would be left [[00:42:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2532.98s)]
*  You couldn't have disconfirmation in a weaker sense because that doesn't exist [[00:42:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2537.3s)]
*  I as I said, i'm not a skeptic [[00:42:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2540.98s)]
*  I'm an anti-skeptic. I think we know a lot of stuff. I think we can make distinctions between refutation and just negative evidence [[00:42:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2543.46s)]
*  That's not refuting [[00:42:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2549.46s)]
*  Now, of course, it's difficult. It's an art. You have to decide on a probability distribution to use to assess [[00:42:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2551.06s)]
*  these things [[00:42:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2558.1s)]
*  Yes, you do have to do that at the end of the day or at least enough constraints on probability so that you can say [[00:42:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2559.46s)]
*  Like what the likelihood ratio is or something like that? [[00:42:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2564.82s)]
*  I mean you you need some probabilistic information to do that, but I think we can [[00:42:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2566.98s)]
*  Obtain such probabilistic information by doing statistics. So i'm not a skeptic at all. I mean, I I don't have a problem [[00:42:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2571.38s)]
*  So I kind of don't worry about the skeptical arguments [[00:42:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2577.62s)]
*  In epistemology at all including an induction [[00:43:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2580.9s)]
*  But let me just say one more thing [[00:43:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2583.62s)]
*  I think popper was also right in his criticisms and some of his criticisms of the logical positivist [[00:43:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2584.82s)]
*  so carnap was probably the the the real uh, best exemplar of someone who tried to develop a logical empiricist in [[00:43:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2589.46s)]
*  inductive logic and [[00:43:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2596.88s)]
*  A lot of what he says in his work is great and useful [[00:43:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2599.04s)]
*  But there's one I think key mistake that he makes and that a lot of people have made and that is this [[00:43:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2602.32s)]
*  he thought and I think many people still think amazingly that [[00:43:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2608.8s)]
*  There must exist a single probability function such that [[00:43:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2612.4s)]
*  Every argument strength can be measured with that one function [[00:43:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2616.8s)]
*  I think this is wrong. What do you mean by a probability function in that sentence? Yeah, so [[00:43:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2621.12s)]
*  There must be some probability distribution over the relevant propositions, okay [[00:43:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2627.2s)]
*  Right that such that for any argument as if there's this this uh, it's they used to call it [[00:43:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2631.8399999999997s)]
*  Well, some people called it like the super baby's probability function or something that there's this one probability function that can assess [[00:43:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2637.44s)]
*  Accurately the strength of any conceivable argument and I just think this is absurd. It doesn't exist [[00:44:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2644.08s)]
*  There's no such thing but I will but I do think there's a weaker claim that is true [[00:44:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2648.96s)]
*  I want to say that for every argument [[00:44:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2652.56s)]
*  There exists a suitable probability function [[00:44:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2655.36s)]
*  Such that when you use that probability function to assess the strength of argument you get a pretty accurate assessment of how strong the argument is [[00:44:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2658.96s)]
*  And so I just want to reverse the quantifiers this idea that there's one in the sky that works for every argument [[00:44:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2665.28s)]
*  No, that's what carna thought he was wrong about that [[00:44:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2670.4s)]
*  But I think it's true probably that for every argument there's some suitable probability distribution that works [[00:44:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2672.6400000000003s)]
*  That gives you the right assessment of what the evidence favors or you know, how strong the evidence is [[00:44:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2678.7200000000003s)]
*  Is carnap's idea [[00:44:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2683.68s)]
*  Either identical to or at least related to an idea that we could find the one true set of priors for all these propositions [[00:44:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2685.68s)]
*  Yes, that's right. That's another way of thinking about if you're a baysian then you'll think so-called objective basians [[00:44:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2692.88s)]
*  Yeah [[00:44:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2697.68s)]
*  Think that there's one probability function that will rule them all or something like that [[00:44:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2697.92s)]
*  And of course that just won't work [[00:45:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2703.04s)]
*  I mean you can just it's very easy to to and this is what carnap did for about 40 years. He kept getting [[00:45:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2704.64s)]
*  more and more sophisticated counter examples for whatever [[00:45:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2710.32s)]
*  Specification of the single family of probability distributions. Yeah, and I just think this is a fool's errand. You don't need to do that [[00:45:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2714.06s)]
*  Science the way side the way I think about science is you have a theory [[00:45:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2720.88s)]
*  So this theory is just probability calculus with your like with your base factor and your conditional probability [[00:45:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2724.64s)]
*  Okay, that's your theory of inductive logic [[00:45:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2730.8s)]
*  And now to you to apply the theory you have to construct models of particular arguments in particular contexts [[00:45:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2733.92s)]
*  That is an art and a science it's going to involve a lot of statistics. It's usually going to be empirical [[00:45:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2740.24s)]
*  It's going to involve a lot of extra work. It isn't going to be knowable a priori, but why should it be? [[00:45:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2746.56s)]
*  Yeah, you know I just so I mean this that was the logical empiricist dream that it had to be knowable a priori [[00:45:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2752.7999999999997s)]
*  And so there had to be just this one probability function. You could divine a priori [[00:45:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2757.8399999999997s)]
*  To determine all the answers and I just think no, that's not how science works [[00:46:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2762.08s)]
*  There are uncountably many probability distributions don't tie your hands by not allowing yourself to use ones [[00:46:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2765.92s)]
*  That science tells you are appropriate [[00:46:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2771.76s)]
*  And so that's just now that's going to be empirical matter of constructing models [[00:46:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2774.2400000000002s)]
*  Of real arguments and this is going to be hard work and there's going to be it's going to in many cases [[00:46:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2778.7200000000003s)]
*  It'll be controversial [[00:46:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2782.88s)]
*  But this is the same thing that happens when you're constructing models in science [[00:46:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2783.92s)]
*  You got to make all kinds of assumptions idealizations approximations [[00:46:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2787.28s)]
*  And it's going to be controversial how to do that the right way. Yeah [[00:46:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2791.2000000000003s)]
*  That's itself part of science, you know, and who said it was going to be easy [[00:46:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2794.72s)]
*  Nobody said it was going to be easy. That's for absolutely sure. I don't I don't think they did [[00:46:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2799.2799999999997s)]
*  But okay as someone who lives in baltimore [[00:46:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2804.0s)]
*  Home of ed grail and poe and the baltimore ravens. I am very fond of what we call the paradox of [[00:46:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2808.3999999999996s)]
*  Confirmation like as soon as you have this idea that you're going to start confirming things [[00:46:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2816.54s)]
*  You get in trouble and the philosophers come along to tell you it's not going to be so easy either [[00:47:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2820.88s)]
*  Yes, there are many there are many paradox of confirmation [[00:47:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2826.0s)]
*  But I think you're thinking of a hampel's pair the raven paradox hampel's paradox. Yeah, this is a classic [[00:47:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2828.4s)]
*  um [[00:47:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2834.0s)]
*  So the way this one goes is it involves a specific kind of hypothesis [[00:47:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2834.96s)]
*  Uh something like this all ravens are black [[00:47:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2840.4s)]
*  That's a hypothesis we could have we could formulate suppose we hypothesize that all ravens are black [[00:47:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2843.44s)]
*  And [[00:47:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2849.04s)]
*  If if you want that to work [[00:47:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2850.08s)]
*  The way we usually think we're confirming that is we make a lot of observations, you know [[00:47:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2852.7999999999997s)]
*  So we observe a whole bunch of positive instances [[00:47:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2857.68s)]
*  And we think by the more positive instances we observe more, you know by and large [[00:47:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2861.52s)]
*  The the better supported [[00:47:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2866.64s)]
*  This hypothesis is okay, but that assumes that even just a single [[00:47:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2868.72s)]
*  Uh instance would provide some support and maybe just a tiny amount [[00:47:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2874.2400000000002s)]
*  But it'll raise the probability a little bit of the hypothesis, which is a plausible idea [[00:47:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2877.84s)]
*  the problem is [[00:48:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2883.44s)]
*  Uh, if you accept that principle that a positive instance provides some support for a universal claim [[00:48:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2885.44s)]
*  So like the observation of a black raven should support a little bit that all ravens are black [[00:48:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2892.1600000000003s)]
*  Of course, you need many to do a lot of confirming but you but one does something right? That's how you get started [[00:48:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2896.6400000000003s)]
*  The problem with that is if you accept that and then you accept the following principle [[00:48:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2902.16s)]
*  Which sounds very plausible that if if a piece of evidence supports a hypothesis then it supports anything logically equivalent to that hypothesis [[00:48:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2906.08s)]
*  Sure, that seems right. I mean logical equivalence. That's a really strong form of equivalence [[00:48:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2914.0s)]
*  So anything's evidence for something should be evidence for something logically equivalent. In fact, we would just think they're the same hypothesis [[00:48:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2918.3999999999996s)]
*  well, okay [[00:48:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2924.3199999999997s)]
*  All ravens are black is logically equivalent to all non-black things are non-ravens [[00:48:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2927.2799999999997s)]
*  And now what's a positive instance of that hypothesis? Well, it would be the observation of a non-black non-raven [[00:48:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2932.3199999999997s)]
*  Okay, but now you get the conclusion that the observing non-black non-ravians confirms that all ravens are black [[00:48:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2939.44s)]
*  Okay, that's that doesn't sound good because it sounds like uh, you can engage in what nelson goodman used to call indoor ornithology [[00:49:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2946.08s)]
*  You just observe a bunch of shoes, you know [[00:49:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2954.3199999999997s)]
*  Or you know at or you know, uh, you observe a bunch of white shoes [[00:49:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2956.96s)]
*  You know a bunch of non-black non-ravians and you're going to get a lot of confirmation for the hypothesis [[00:49:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2960.96s)]
*  well [[00:49:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2966.32s)]
*  That's definitely a problem [[00:49:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2967.6000000000004s)]
*  But this is where the quantitative theory of confirmation helps [[00:49:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2969.6000000000004s)]
*  So yes, let's suppose you get some confirmation, right? But now that leaves open the following question [[00:49:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2974.2400000000002s)]
*  Might it not be the case that the amount of confirmation provided by the observation of a non-black norm is much much less [[00:49:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2981.04s)]
*  You know in in the circumstances we think we find ourselves in than the observation of a black raven [[00:49:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2987.7599999999998s)]
*  And in fact given very plausible assumptions about statistical sampling or however, you're modeling, you know [[00:49:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2992.72s)]
*  The usual statistical models of observing these things [[00:49:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=2998.4s)]
*  Given very plausible assumptions about the world, you know, here's one assumption. There are a lot more non-black things than there are ravens [[00:50:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3002.96s)]
*  That seems right [[00:50:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3012.4s)]
*  Okay, so that and if you think that's true and [[00:50:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3013.84s)]
*  It's still true. Even if you suppose that all ravens are black that is that wouldn't affect much the rate the relative proportions [[00:50:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3018.1600000000003s)]
*  Then it just follows that you're going to get more support [[00:50:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3026.2400000000002s)]
*  By by of the hypothesis by the observation of a black raven than by the observation of a non-black non-raven [[00:50:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3030.1600000000003s)]
*  So this is where the quantitative theory really helps and statistics gives us that it gives us a quantitative way to estimate [[00:50:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3035.44s)]
*  How much of an effect [[00:50:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3042.08s)]
*  Uh an observation has and so given very plausible assumptions [[00:50:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3043.68s)]
*  It's just going to be yeah, you get some evidence, but it's extremely weak [[00:50:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3047.36s)]
*  Compared to the evidence you get from black ravens and you can make this much more precise and you can show that [[00:50:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3051.6s)]
*  In general, it's just much more informative to say sample from the ravens and see if they're black [[00:50:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3056.96s)]
*  Then sample from the non-black things and see if they're non-ravens, right? [[00:51:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3062.8s)]
*  And you can just make this very quantitative using the theory of confirmation just these base factors [[00:51:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3067.52s)]
*  And given very plausible assumptions about what we think the probability distributions look like [[00:51:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3072.48s)]
*  It's just going to follow that [[00:51:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3077.2799999999997s)]
*  the best way to do the experiment is to sample from the ravens and see [[00:51:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3079.2799999999997s)]
*  If they're all black as opposed to sampling from the non-black objects and seeing if they're not ravens [[00:51:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3083.2799999999997s)]
*  Well and for the non-philosophers out there just to remind them that this notion of confirmation is extremely weak, right when you say [[00:51:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3087.04s)]
*  Observing a white shoe confirms that all ravens are black. It's really it's closer to supports [[00:51:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3094.72s)]
*  You even use supports a couple of times there as as a synonym. Yes provides a tiny amount of evidence [[00:51:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3100.0s)]
*  That might be really really tiny [[00:51:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3104.9599999999996s)]
*  Yeah, it could be it's just a some bump [[00:51:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3107.2s)]
*  It just means the probability goes up but it could go up in a tiny amount [[00:51:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3109.3599999999997s)]
*  And in fact, this is what we think happens [[00:51:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3112.9599999999996s)]
*  When we sample from the non-black things and see whether they're non-ravens as opposed to sampling from the ravens seeing whether they're black [[00:51:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3114.9599999999996s)]
*  We just think there's a much larger effect there [[00:52:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3120.72s)]
*  So although there's some effect. Yeah [[00:52:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3123.3599999999997s)]
*  it's not like it's totally gives you no information and by the way, it's plausible that you should get some information because [[00:52:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3126.0s)]
*  If you observe a non-black non-raven, then what you've done is you've ruled one object out [[00:52:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3132.0s)]
*  You know that there's one object in the universe that can't be a counter example [[00:52:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3136.48s)]
*  To the hypothesis and so in that sense, yes, you've gotten maybe a tiny bit of support [[00:52:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3140.0s)]
*  But it's it's absolutely minuscule compared to what happens when you sample from the ravens and see if they're all black [[00:52:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3145.3599999999997s)]
*  Okay, good so i'm i'm on board the the confirmation train here [[00:52:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3151.36s)]
*  But we still you mentioned in passing the idea of a quantitative measure of this confirmation factor [[00:52:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3156.08s)]
*  Um in one of the papers that that you wrote that I actually read some of um, you go through different [[00:52:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3163.36s)]
*  plausible [[00:52:50](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3170.2200000000003s)]
*  Suggestions for what the equation should be for giving you what that confirmation factor is and and there's something called the received view [[00:52:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3171.82s)]
*  That uh, what you call the received view do other people also call it the received view. I don't even know [[00:53:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3180.7200000000003s)]
*  uh, well, it's just [[00:53:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3185.92s)]
*  Yeah, I think it is just kind of the conventional wisdom about how to think about strength of arguments [[00:53:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3188.0s)]
*  Yeah, right. Okay, and you and that relates this confirmation factor to a conditional probability and I know that um [[00:53:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3192.7200000000003s)]
*  Some large fraction of your intellectual life has been thinking about conditional probabilities [[00:53:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3200.48s)]
*  So why don't you tell us what a conditional probability is and why it might be related to a confirmation? [[00:53:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3204.7200000000003s)]
*  Yeah, so [[00:53:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3210.56s)]
*  So so one thing you definitely want to know [[00:53:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3212.0s)]
*  It's just going back to the disease case one thing you definitely want to know [[00:53:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3214.56s)]
*  Maybe the most important thing you want to know is how probable is it that you have the disease? [[00:53:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3217.6s)]
*  Conditional on or given that you get a positive result, right? [[00:53:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3222.38s)]
*  That's called the conditional probability and the way it works is you do this you suppose that you get a positive result [[00:53:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3225.84s)]
*  And then you ask yourself given that supposition supposing the world is that way? [[00:53:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3231.36s)]
*  How probable is it that I have the disease? [[00:53:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3235.28s)]
*  Um, and that's sort of the natural way of thinking about it. And so conditional probabilities are essential to induction [[00:53:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3237.84s)]
*  um [[00:54:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3244.8s)]
*  But of course, there's many different kinds. There's many different conditional probabilities [[00:54:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3245.6800000000003s)]
*  There's the probability of h given e that posterior probability. That's really important [[00:54:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3248.88s)]
*  But there's also the likelihood the probability of e given h that true positive rate [[00:54:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3252.8s)]
*  And there's also the probability of e given not the false positive rate. So there's actually evidence and hypothesis [[00:54:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3256.96s)]
*  Yeah, e and h are evidence and hypothesis [[00:54:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3263.12s)]
*  So e let's say is a positive test result h is that you have the disease [[00:54:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3264.7999999999997s)]
*  And of course what you want to know is how probable is h given e right suppose e to be true [[00:54:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3268.24s)]
*  How and then if you learn e then you update you update and you accept as your new probability the old conditional probability [[00:54:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3273.3599999999997s)]
*  That's sort of the bayesian way of doing things [[00:54:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3279.92s)]
*  um, and yeah, you definitely want to know that of course, that's like that's a very good thing to know [[00:54:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3282.08s)]
*  but [[00:54:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3287.2s)]
*  knowing that [[00:54:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3288.16s)]
*  Requires you to know not just the true positive rate of the false positive rate of the test [[00:54:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3289.44s)]
*  But also the prior the unconditional probability the probability prior to the evidence before learning how the experiment turned out [[00:54:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3294.48s)]
*  And of course that's going to vary very greatly from subject to subject from person to person who's judging the evidence [[00:55:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3301.52s)]
*  So conditional probability is super important and I still want to say [[00:55:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3309.6800000000003s)]
*  That is one of the features that makes something a strong argument [[00:55:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3313.36s)]
*  You definitely want the you definitely want the hypothesis to be more probable than not at the very least given the evidence if you're going to [[00:55:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3316.72s)]
*  Believe it if you think it's a reason to believe it [[00:55:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3322.48s)]
*  That's part of the story [[00:55:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3325.12s)]
*  but I want to and that's the conventional view about how strong the the received view is [[00:55:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3326.3199999999997s)]
*  If you want to know how strong an argument is just calculate that posterior probability the probability of h given e and that tells you [[00:55:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3331.04s)]
*  How strong a reason is e is for believing h but that can't be right [[00:55:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3336.4s)]
*  It can't be right because take you or me if we take a pregnancy test [[00:55:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3340.48s)]
*  Yeah, look the likelihoods are still the same if we happen to get a positive rate, which is of course possible because physics [[00:55:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3345.92s)]
*  And not because things aren't impossible. We could get a positive result. Okay. Yeah [[00:55:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3352.64s)]
*  Well, we but we we don't think that's a good reason to believe that we're pregnant because we know we're not [[00:55:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3358.4s)]
*  So what that means is there's another dimension to the assessment of the strength of arguments [[00:56:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3363.44s)]
*  And that is what we've been calling confirmation [[00:56:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3367.8399999999997s)]
*  And basically I want to say it's just it's just the the ratio of those two error rates [[00:56:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3370.24s)]
*  It's just the the base factor the likelihood ratio whatever you want to call it [[00:56:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3374.48s)]
*  That's the way we measure that second dimension of confirmation. And so I want to say there's a I have a i'm offering a two-dimensional theory of argument strength [[00:56:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3377.76s)]
*  For an argument to be strong. It's got to be probable. Sure [[00:56:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3385.6s)]
*  Yeah [[00:56:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3388.16s)]
*  It should be more probably the conclusion should be more problem than i've given the premise or in this case the hypothesis should be more probable [[00:56:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3388.4s)]
*  Not given the evidence [[00:56:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3394.16s)]
*  But also the evidence should be relevant if the evidence is irrelevant. It's not a reason to believe the hypothesis at all [[00:56:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3395.76s)]
*  Right. So if you have an argument where the premise is just irrelevant doesn't affect the probability of conclusion at all [[00:56:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3403.12s)]
*  Then I don't want to say that's a strong argument because that it's not a reason to believe the conclusion at all [[00:56:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3408.64s)]
*  Okay, and so this was something that the classical inductive logicians just ignored [[00:56:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3414.64s)]
*  Not just carnap, but if you read books on inductive logic all the way up through brian skirm's this book [[00:56:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3419.44s)]
*  Which is one of the state of the art books from the 2000s [[00:57:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3423.76s)]
*  They just give you this one dimension the probability of conclusion given the premise [[00:57:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3427.2000000000003s)]
*  But I just think that can't be the full story because relevance confirmation also matters [[00:57:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3430.7999999999997s)]
*  As to whether something should affect your beliefs [[00:57:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3436.56s)]
*  So, um, let me try to rephrase it because i'm not sure I wrap my brain completely around it [[00:57:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3439.12s)]
*  The the classical story would say if the probability of the hypothesis given the evidence [[00:57:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3444.8799999999997s)]
*  Is very high then that counts as confirmation [[00:57:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3449.92s)]
*  But what if for example the probability of the hypothesis is just very high [[00:57:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3452.7999999999997s)]
*  What if we're already convinced of it then it could be also high given the evidence [[00:57:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3457.68s)]
*  But you wouldn't count that as confirmation. Is that the idea? That's right. That's right [[00:57:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3462.56s)]
*  In fact, it could even be highly probable given the evidence, but the evidence makes it a little bit less probable [[00:57:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3466.0s)]
*  Right, you definitely don't want to say that's a reason to believe no it if anything [[00:57:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3472.0s)]
*  It's a reason to believe that hypothesis is false [[00:57:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3476.56s)]
*  Right, okay, it just so happens that it happens to have still a high probability anyway given the evidence [[00:57:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3478.64s)]
*  But that's probably because it had such a high probability to begin with [[00:58:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3486.1600000000003s)]
*  Okay, it's not it's not that the evidence is a reason to believe the hypothesis [[00:58:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3489.6000000000004s)]
*  And so when as logicians what we want to know is not whether we should believe the conclusion is simplicator [[00:58:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3492.96s)]
*  But we want to know how strong the argument is as a reason to believe the conclusion [[00:58:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3498.48s)]
*  And that I claim requires both probability and relevance confirmation and simplicator is weird philosopher talk for all else being equal [[00:58:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3503.6000000000004s)]
*  Yeah, that's right. That's right [[00:58:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3511.2000000000003s)]
*  And sure if if the thing is relevant then all that matters is the probability but if it's not relevant [[00:58:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3512.72s)]
*  Then it's not a strong argument. I would say good. So [[00:58:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3519.12s)]
*  That sounds perfectly plausible [[00:58:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3522.9599999999996s)]
*  But of course we're going to want to know what is the way to know whether something is relevant [[00:58:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3524.48s)]
*  Is there is that just like a vibes based thing or is there an equation? [[00:58:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3528.7999999999997s)]
*  There's an equation there's and it is just that the thing they give you when you buy the diagnostic test [[00:58:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3534.08s)]
*  They give you this ratio of the two error rates the two likelihoods the probability of e given h and the probability of e given not h [[00:58:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3538.88s)]
*  And you take that ratio. That's a really good measure from an inductive logical point of view [[00:59:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3545.52s)]
*  It's pretty much the only one that's going to satisfy these desiderata. We like and so that's how I propose [[00:59:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3550.08s)]
*  So i'm proposing a two dimension so you can visualize it as like a cartesian space [[00:59:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3555.76s)]
*  The x-axis is the conditional probability of the conclusion given the premise and the y-axis is that likelihood ratio? [[00:59:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3559.76s)]
*  That is that measures how much impact how relevant? [[00:59:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3567.44s)]
*  Uh the premises to the conclusion or the evidences to the hypothesis and sort of and [[00:59:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3571.68s)]
*  Yeah, so there's no one number at the end of the day [[00:59:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3576.4s)]
*  It's not like you add those two together or you add their squares together or whatever. It's just you got to give me both numbers [[00:59:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3579.52s)]
*  Yes, and I think this is a really fundamental thing. That's so important to emphasize [[00:59:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3586.24s)]
*  I think one of the real deepest mistakes that was made in the history of inductive logic was [[00:59:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3591.04s)]
*  That they thought there'd be a single measure on which you could totally order all the arguments in terms of their strength [[00:59:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3596.1600000000003s)]
*  A single function that takes a premise and a conclusion and a probability distribution and gives you a single number [[01:00:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3602.5600000000004s)]
*  I don't think this can be done. I think what it gives you is a ordered pair [[01:00:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3609.0400000000004s)]
*  Yeah, it gives you a probability and a base factor [[01:00:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3612.96s)]
*  And that's all I think in general that can be said now, of course you can say some things [[01:00:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3617.1200000000003s)]
*  there's a there's some ordering because [[01:00:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3621.44s)]
*  If if the evidence if you move up [[01:00:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3623.52s)]
*  Both in terms of probability and relevance. Well, then you've gotten stronger because you've gotten stronger in both dimensions [[01:00:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3626.56s)]
*  But these mixed cases, this is the problem cases where you have improbability but high confirmation like the base rate fallacy [[01:00:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3631.36s)]
*  Or cases like the conjunction fallacy, which also involve relevance going one way confirmation going one way, but probability going the other way [[01:00:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3639.52s)]
*  And so these mixed cases, which I think it's no surprise. They led to the Nobel prize about [[01:00:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3647.36s)]
*  Concerning how quote unquote bad people are probabilistic reasoning [[01:00:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3652.64s)]
*  I think it's because the cases are mixed that people get confused [[01:00:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3656.16s)]
*  If you ask someone how strong is an argument? Well, if if that has two dimensions to it [[01:01:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3660.72s)]
*  And one of them's high and the other's low [[01:01:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3666.16s)]
*  That's ambiguous the question's ambiguous and so [[01:01:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3670.08s)]
*  You you could you might not blame them so much if they're a little confused about those arguments where you have high relevance and low probability or [[01:01:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3673.36s)]
*  You know high probability and low relevance. Those are hard cases to to assess [[01:01:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3682.0s)]
*  Yeah, right for for most people because because they realize both factors are relevant [[01:01:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3687.04s)]
*  And what they're being asked for is a single summary a single assessment, but maybe there isn't [[01:01:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3691.52s)]
*  Maybe it's ambiguous. Maybe it's strong in one sense, but not in the other [[01:01:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3697.04s)]
*  And so I I in general want there to just be two dimensions [[01:01:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3701.2s)]
*  And so you I don't think there's a total ordering is a single number you get for any argument and any probability distribution [[01:01:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3705.44s)]
*  There's going to be two numbers. I think in general and I think that's one of the mistakes [[01:01:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3712.0s)]
*  Yeah, has everyone basically agreed with your impeccable logic here [[01:01:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3716.0s)]
*  Well, I mean some people have so they're you know in psychology [[01:02:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3720.24s)]
*  So we did I had the pleasure of working with some psychologists [[01:02:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3724.24s)]
*  on these quote unquote reasoning fallacies and [[01:02:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3728.4s)]
*  Yes, there's a lot of experimental evidence now that [[01:02:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3731.36s)]
*  It's the mixed cases that are hard and it's and they're hard because they're mixed and so if you fiddle with the confirmation [[01:02:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3734.56s)]
*  That is the relevance you fiddle with that y dimension [[01:02:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3739.92s)]
*  It's really going to affect how good people are making judgments about the x dimension [[01:02:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3742.8s)]
*  and so [[01:02:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3746.96s)]
*  And I think this is because what people really care about is [[01:02:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3748.08s)]
*  Not just how probable the conclusion is given the premise they care about how strong is this as a reason to believe the conclusion? [[01:02:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3751.6s)]
*  And intuitively they know that depends not only on the probability but on whether the evidence is relevant whether the evidence confirms the hypothesis [[01:02:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3758.4s)]
*  And so there's a lot of psychological evidence now that that that notion of confirmation really is relevant to explaining what's going on in these cases [[01:02:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3765.7599999999998s)]
*  So let's go through some of these cases a little bit more carefully because i'm sure that people have kind of [[01:02:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3773.68s)]
*  Vaguely heard of them, but you know, it's always good to be clear the the conjunction fallacy [[01:02:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3778.16s)]
*  I think you already mentioned and it is one of my favorites because I was not fooled by it when I first saw it [[01:03:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3782.8s)]
*  But uh, I saw why I could be fooled by it. So i'm sympathetic [[01:03:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3788.72s)]
*  Yeah, yeah, let me let me that's a great one that's a great one so [[01:03:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3793.3s)]
*  Um, what the way that one works is you're given some evidence about a woman named linda [[01:03:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3796.7400000000002s)]
*  You're basically told that she uh, so she was she went to berkeley in the late 60s [[01:03:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3801.3s)]
*  She participated in anti-nuclear demonstrations. She was very active [[01:03:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3806.98s)]
*  Um politically and so on and so forth. She was like a flower child and so on and so forth [[01:03:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3810.96s)]
*  And that's the evidence you're given and now you're asked [[01:03:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3816.1800000000003s)]
*  This is years later you're asked, okay now I have two hypotheses i'm going to give you about linda nowadays [[01:03:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3819.78s)]
*  either she's a bank teller [[01:03:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3825.7000000000003s)]
*  Or she's a feminist bank teller and you're asked which is more probable given the evidence that I gave you and back in the day [[01:03:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3829.2200000000003s)]
*  A lot of people said feminist bank teller was more probable given that evidence [[01:03:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3836.26s)]
*  of course, that's impossible because [[01:04:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3840.7400000000002s)]
*  feminist bank teller entails bank teller so [[01:04:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3844.02s)]
*  Every possible world in which you're if which is a fantasy is a world in which she's a bank teller and since probability is just [[01:04:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3847.2999999999997s)]
*  A measure of you know, how big a class of possible worlds is [[01:04:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3852.18s)]
*  It couldn't possibly be that the conjunction is more probable than one of its conjuncts [[01:04:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3855.94s)]
*  Right that that would just violate basic logical and probabilistic principles. So that can't happen [[01:04:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3860.18s)]
*  So what's going on? Well [[01:04:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3865.94s)]
*  what we showed in a paper that we wrote and there's been a lot of research on this since then is that [[01:04:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3868.02s)]
*  Two very simple assumptions if two very simple assumptions hold which i'm going to give you in a second [[01:04:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3873.8599999999997s)]
*  Then it's just guaranteed that while yes [[01:04:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3878.74s)]
*  The the bank teller hypothesis is going to be more probable than the feminist bank teller hypothesis [[01:04:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3883.06s)]
*  The evidence will actually confirm the feminist bank teller hypothesis more strongly [[01:04:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3888.1s)]
*  It'll be more relevant to that conjunction than it is to the first contract and here are the assumptions. They're very weak [[01:04:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3893.7799999999997s)]
*  first assumption [[01:04:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3899.7s)]
*  The evidence isn't positively relevant to whether she's a bank teller [[01:05:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3901.14s)]
*  That seems plausible, okay second assumption suppose she is a bank teller [[01:05:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3906.1s)]
*  The evidence I give you still positively relevant to some degree to her being a feminist [[01:05:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3911.14s)]
*  Maybe it's only a tiny amount but still still somewhat relevant to her being a feminist [[01:05:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3915.06s)]
*  Those conditions entail that for any way of measuring confirmation for any of the measures [[01:05:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3920.02s)]
*  It turns out the evidence will confirm the conjunction more strongly than it confirms [[01:05:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3925.8599999999997s)]
*  The conjunct and so these are cases they're mixed cases. Do you have a case where probability goes one way bank teller is more probable [[01:05:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3931.14s)]
*  But bank teller is less relevant, right? It's less well confirmed by the evidence [[01:05:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3938.58s)]
*  And I think it's again no surprise that just like in these rare [[01:05:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3944.3399999999997s)]
*  Diagnostic testing cases rare disease cases which are called the base rate fallacy cases, which we already discussed just like in those cases [[01:05:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3949.2799999999997s)]
*  these cases involve [[01:05:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3956.5s)]
*  One of the dimensions of assessment probability going one way and the other dimension of assessment of the strength of argument [[01:05:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3958.26s)]
*  Confirmation or relevance going the other way and i'm not at all surprised that people defer to relevance [[01:06:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3963.46s)]
*  It makes sense. We already saw relevance is in many ways more objective. It's more invariant [[01:06:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3970.0200000000004s)]
*  It's it's it's sort of the language of science the way science understands evidence [[01:06:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3975.3s)]
*  It usually thinks in terms of how much the evidence confirms not how probable that hypothesis that depends on all these idiosyncrasies [[01:06:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3979.86s)]
*  About prior probabilities [[01:06:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3987.16s)]
*  So i'm not at all surprised that people do [[01:06:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3988.84s)]
*  Any of these things so I say it's kind of makes sense that when [[01:06:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3992.12s)]
*  Uh the confirmation goes one way and probability goes another way [[01:06:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3996.68s)]
*  Deferring to the confirmation kind of makes sense since there are many ways in which confirmation is just more [[01:06:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=3999.96s)]
*  More important more informative more objective than than probability is so I have a slightly different or I had [[01:06:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4005.4s)]
*  for a while after hearing about the [[01:06:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4012.2s)]
*  Experimental results a slightly different hypothesis about what was going on, but i'm not sure if it's slightly different [[01:06:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4014.4399999999996s)]
*  So let me uh explain it to you and you tell me if it's different [[01:06:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4019.96s)]
*  I'm wondering whether or not when people hear, you know, the the evidence which in this case is linda went to berkeley [[01:07:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4023.3999999999996s)]
*  She was a flower child. She was an activist and then they're giving the two hypotheses. She's a bank teller [[01:07:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4029.64s)]
*  And or she's a bank a feminist bank teller [[01:07:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4035.48s)]
*  implicitly [[01:07:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4038.8199999999997s)]
*  They assume that being a bank teller means that you're a typical [[01:07:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4040.2s)]
*  Bank teller and being a feminist bank teller assumes that you're a typical feminist bank teller [[01:07:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4044.04s)]
*  And the typical bank teller is not feminist [[01:07:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4050.12s)]
*  so there's some sort of interference or tension between [[01:07:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4052.52s)]
*  The hypothesis that she's a bank teller and the evidence that she was a flower child [[01:07:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4056.76s)]
*  Uh, it's still a sort of a mistake with the question phrased as it was [[01:07:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4061.72s)]
*  But I mean that would be a way of psychologizing why we make the mistake. I'm not sure if it's the same as your way or different [[01:07:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4066.68s)]
*  Well, yes, so there have been many uh proposals for different things that might be going on one of them that was [[01:07:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4073.64s)]
*  Received a lot of attention early on which is similar. It's in some ways. Maybe you can tell me [[01:08:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4081.16s)]
*  I think it's related to what you were [[01:08:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4084.76s)]
*  saying is [[01:08:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4087.0s)]
*  It was originally possibly that actually people were hearing the question slightly different. They're hearing it as [[01:08:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4089.48s)]
*  feminist bank teller versus non-feminist bank teller, yeah [[01:08:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4094.92s)]
*  and [[01:08:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4099.0s)]
*  Actually, there's definitive psychological research that that's not what's happening [[01:08:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4099.8s)]
*  So I can I can show I can point you to papers that are just absolutely stunning on this by some of my psychological colleagues [[01:08:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4104.2s)]
*  though, okay, so [[01:08:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4110.12s)]
*  their experiments where [[01:08:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4111.88s)]
*  First they teach people how to do deductive inferences. They teach them how to infer conjuncts from conjunctions [[01:08:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4113.88s)]
*  They teach them all this stuff and then they have them bet [[01:08:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4120.92s)]
*  They have them do betting and they still a lot of people bet more on the conjunction [[01:08:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4124.92s)]
*  Even though they know that the thing follows they've actually gone through the logical exercise of it of it following logically, right? [[01:08:50](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4130.52s)]
*  That one hypothesis entails the other so that this has been controlled for I think in my opinion this [[01:08:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4137.4800000000005s)]
*  This particular hypothesis actually there's a lot of evidence against it now. So I find the relevance approach the confirmation approach [[01:09:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4142.04s)]
*  More more plausible given all the evidence [[01:09:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4149.8s)]
*  But of course, this is you know, this is the active area of research [[01:09:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4152.92s)]
*  There's some even more recent research trying to refine the notion of relevance to go beyond confirmation and take into account other pragmatic [[01:09:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4156.2s)]
*  kinds of relevance as well [[01:09:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4162.76s)]
*  I think that's really fascinating research, but there's pretty strong evidence now that [[01:09:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4164.68s)]
*  This the second dimension i'm calling it of logic of argument strength is making a significant difference [[01:09:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4169.88s)]
*  There may be many other things that are making a difference, but it's pretty clear. It's making a difference [[01:09:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4175.4s)]
*  I kind of love the intersection of the actual psychology experiments with the [[01:09:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4179.32s)]
*  Uh philosophical reasoning and at the most abstract level it does, you know, the rubber does hit the road at some point [[01:09:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4184.92s)]
*  Oh, absolutely. I to me that's that's [[01:09:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4191.72s)]
*  One of the most interesting areas of research in general is that borderline between the descriptive and the prescriptive. Yeah [[01:09:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4194.68s)]
*  That's a really it's such a difficult area, but it's such an it's such an important area because after all what we're interested in is [[01:10:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4202.2s)]
*  evidence for humans, you know [[01:10:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4210.28s)]
*  It's like, you know, this is another weird thing about logical empiricism [[01:10:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4212.5199999999995s)]
*  Who cares about evidence? It's if it's just some purely formal [[01:10:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4216.12s)]
*  Logical relation between things. How does that actually bear on what we ought to believe? [[01:10:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4220.84s)]
*  So that's another problem with the whole kind of logical empiricist way of thinking [[01:10:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4225.88s)]
*  It's very disembodied and abstract and it's just unclear why it would ever have any purchase on humans [[01:10:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4229.48s)]
*  Okay, so let's um, I think one more example might seal the deal here and and you suggested the [[01:10:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4235.48s)]
*  four card problem, which I do remember like I looked it up, you know, you have your paper but your paper is full of like all these [[01:10:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4242.04s)]
*  Equations and things so I just looked it up on wikipedia to remind me what it was [[01:10:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4249.72s)]
*  And I do remember coming across a four card problem and I that one I I did get right just because i've uh done [[01:10:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4253.320000000001s)]
*  Probability problems before but but it's I I see the similarity here, but the argument plays out in a slightly different way [[01:11:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4260.26s)]
*  So why don't you tell us what the problem is? [[01:11:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4267.0s)]
*  Yeah, so there's this famous case [[01:11:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4269.48s)]
*  Of the waste and selection task is what it's called [[01:11:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4272.84s)]
*  uh, and [[01:11:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4277.16s)]
*  There's so the way it works is [[01:11:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4278.76s)]
*  there's uh, there's cards and there's different variants of it, so i'm trying to remind myself of uh, [[01:11:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4281.24s)]
*  The version that we that we actually worked on because I don't want to talk about a version that I don't [[01:11:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4287.48s)]
*  I actually don't I wrote it down if you want me to give the the problem and then you can explain [[01:11:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4292.36s)]
*  Yeah, could you do that and then I can yeah, let me the version that I know [[01:11:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4296.5199999999995s)]
*  From your paper is that there are these cards and you know that there's a number [[01:11:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4300.28s)]
*  On one side of the card a letter on the other side of the card. You know that [[01:11:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4304.5199999999995s)]
*  And you're shown four cards [[01:11:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4309.48s)]
*  One says the letter d the other says the letter k. I don't know if this is for daniel condeman or not [[01:11:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4312.12s)]
*  I don't know where these letters came from [[01:11:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4317.799999999999s)]
*  Then it shows the number three and the number seven [[01:12:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4320.12s)]
*  Okay, so dk three seven [[01:12:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4323.08s)]
*  So obviously you showed the letter side of two of them the number side of the other two and then the hypothesis is [[01:12:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4325.08s)]
*  All cards that have d on one side will necessarily have three [[01:12:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4331.24s)]
*  On the other side and the question is which cards you have to flip over to most efficiently [[01:12:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4336.679999999999s)]
*  Test that hypothesis that if d is on one side three is on the other side and you're shown dk three seven [[01:12:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4343.639999999999s)]
*  Yes [[01:12:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4350.92s)]
*  Yes, and so yeah, so this is this is a great case [[01:12:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4353.08s)]
*  So we wrote this paper a while back me and jim hawthorne wrote this really it's my favorite paper [[01:12:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4357.48s)]
*  I've ever written still to this day [[01:12:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4361.88s)]
*  and [[01:12:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4363.96s)]
*  So it's about this ways and selection task, which people make a certain kind of mistake in [[01:12:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4365.08s)]
*  uh tend to and [[01:12:50](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4370.36s)]
*  It's relation to the paradox of confirmation which we already talked about so you remember back in [[01:12:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4372.599999999999s)]
*  When we were talking about the paradox of confirmation [[01:12:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4379.16s)]
*  that [[01:13:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4381.88s)]
*  It's a better strategy [[01:13:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4382.84s)]
*  To sample from the ravens and see whether they're black than it is to sample from the non-black things [[01:13:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4384.92s)]
*  And check whether they're non-ravians, right? [[01:13:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4390.92s)]
*  It's just more confirmationally powerful to do to to sample from the ravens and check and see if they're black [[01:13:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4393.08s)]
*  This turns out to be an isomorphic problem. This is this problem is basically the same problem. Okay? [[01:13:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4398.84s)]
*  Um [[01:13:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4405.48s)]
*  Because so what hypothesis are we being asked to test in this in this case? [[01:13:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4407.24s)]
*  So we've got the four cards dk three and seven and what what hypothesis are we being asked to test? [[01:13:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4412.44s)]
*  If d is on one side, then three is on the back [[01:13:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4419.8s)]
*  That's right. So all d cards [[01:13:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4424.04s)]
*  Are three cards? [[01:13:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4426.92s)]
*  Yes [[01:13:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4428.36s)]
*  Or you could just say all d's are threes. Yep [[01:13:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4429.8s)]
*  Okay now [[01:13:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4433.16s)]
*  all d's are threes same structure as all r's are b's all ravens are blacks and [[01:13:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4435.08s)]
*  exact and the same kinds of things happen, so [[01:14:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4441.24s)]
*  What you what you want to do is? [[01:14:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4444.76s)]
*  If you think about back to the raven case, what did we say? [[01:14:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4448.04s)]
*  The best strategy is look at the ravens and then check and see whether you know whether they're black the analogous thing here would be [[01:14:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4450.12s)]
*  Check the d card [[01:14:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4458.4400000000005s)]
*  And then turn it over and see whether it's a three on the other side [[01:14:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4460.76s)]
*  That is exactly the analogous thing and you can and the same models will show [[01:14:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4465.24s)]
*  That that's the most efficient way to to respond to this [[01:14:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4470.28s)]
*  And in fact if you just use some very weak assumptions about probability and you use this confirmation measure that we were talking about [[01:14:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4474.04s)]
*  Then you can actually rank the strategies [[01:14:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4481.72s)]
*  In terms of their conformational power and it'll turn out given very weak assumptions about what's going on that [[01:14:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4484.68s)]
*  Turning over the d card is the best [[01:14:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4492.52s)]
*  Then next turning over the three card [[01:14:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4495.24s)]
*  Oh, sorry, no, that's what people actually do. Sorry, right. That's what people actually do [[01:14:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4498.6s)]
*  So what people actually do this is great because I just actually did it what people actually do is they turn over the three card [[01:15:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4502.76s)]
*  That's the second best strategy because that isn't the second best strategy, right? Yeah, they think that they're trying to confirm but uh, [[01:15:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4508.52s)]
*  That's not the best way to learn [[01:15:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4514.92s)]
*  Yes, what you should be doing is looking for counter examples, right next so you should turn over the seven card, right? [[01:15:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4517.08s)]
*  And see whether it's a d right? Yes, exactly [[01:15:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4523.879999999999s)]
*  And this is exactly we show because we actually show that the two cases the pair of sclerompration and the waste desk are actually [[01:15:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4526.599999999999s)]
*  Isomorphic they have basically the same structure [[01:15:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4532.58s)]
*  And that you can use the same kinds of probability models to model them [[01:15:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4534.92s)]
*  And when you do you get exactly the prescriptions in both cases you get [[01:15:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4539.0s)]
*  best thing [[01:15:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4544.12s)]
*  Sample from the raven see if they're black [[01:15:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4545.32s)]
*  next best thing is look at the [[01:15:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4547.32s)]
*  uh non [[01:15:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4551.0s)]
*  Black look at right the non-black things and see if they're ravens right look for counter examples, right same thing here [[01:15:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4552.92s)]
*  But what people actually do in this waste and test which is really interesting is they they reverse those the second and third strategy [[01:15:58](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4558.92s)]
*  So what they do is uh, they'll say d first, but then they'll say three [[01:16:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4566.68s)]
*  Yeah, they'll say no turn over the three card when that's definitely less informative and here the papearian intuition really is correct [[01:16:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4571.16s)]
*  You should be trying to refute next you should be looking at the seven card [[01:16:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4579.400000000001s)]
*  And as I as I was saying the papearian thing [[01:16:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4583.400000000001s)]
*  It's a the kernel of truth of popper comes out in this paper because basically you can just show [[01:16:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4586.04s)]
*  that [[01:16:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4592.4400000000005s)]
*  after sampling from or sampling the d card and looking to see whether it's a three the next best thing [[01:16:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4593.24s)]
*  Is looking at the seven and seeing whether it's a d [[01:16:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4599.8s)]
*  that's [[01:16:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4603.88s)]
*  That's uh, that's popper's intuition basically and people aren't papearian [[01:16:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4605.08s)]
*  It turns out because they think turnover the three cards better than turnover the seven card [[01:16:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4609.8s)]
*  But actually it's very easy to show just using very weak assumptions about probability [[01:16:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4613.32s)]
*  That that's wrong. And so in a way, this is a vindicate. It's a bayesian vindication of popper [[01:16:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4617.8s)]
*  That's one of the things I like about this paper. It it tells you the kernel of truth in in the papearian falsificationism that in this case [[01:17:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4623.48s)]
*  Going for the falsifications better [[01:17:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4631.48s)]
*  Uh, it's it's the second best thing and not the third best thing, which is what people tend to think it is [[01:17:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4634.2s)]
*  Yeah [[01:17:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4640.44s)]
*  But the thing that so but the thing that people tend to do they they they reason if it can be called that they think [[01:17:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4640.599999999999s)]
*  Well, your hypothesis is that if there's a d on one side [[01:17:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4648.12s)]
*  There's a three on the other if I flip over the three and I see a d on the other side [[01:17:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4650.839999999999s)]
*  That will confirm that will give some evidence for this in the space of all possible cards [[01:17:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4656.12s)]
*  That's a more like a thing to see [[01:17:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4661.8s)]
*  Yes, and and it will confirm but because refutations are always more powerful than non-refutations. Exactly. Yeah [[01:17:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4664.12s)]
*  That's the papearian insight and that's why popper was correct. So yes, you're absolutely right [[01:17:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4671.16s)]
*  it's a kind of confirmation bias and [[01:17:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4675.88s)]
*  In our paper [[01:17:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4679.0s)]
*  we actually prove given very weak assumptions that the only way to get that ordering is if you come into the [[01:17:59](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4679.64s)]
*  Experiment with a confirmation bias that is you think you're more likely to see positive instances rather than counter examples [[01:18:05](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4685.8s)]
*  Exactly, right good [[01:18:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4693.56s)]
*  And you can just prove that that just follows from the very weak modeling assumptions [[01:18:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4695.72s)]
*  We have that the only way to get that ordering is going to be if you come in already thinking [[01:18:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4699.240000000001s)]
*  That you're more likely to get confirming instances rather than refuting instances [[01:18:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4703.8s)]
*  Which is is is sort of a classic confirmation bias and it is but it's not it is a bias [[01:18:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4707.72s)]
*  And I think that in this case, you know, the parameters are sufficiently clean that uh doing d and seven [[01:18:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4713.64s)]
*  Is is clearly the right? [[01:18:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4720.360000000001s)]
*  Uh strategy here, but the real world of science is complicated, right? [[01:18:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4722.360000000001s)]
*  I mean, I guess you know, we're getting late in the podcast. We can let our hair down and think about [[01:18:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4726.4400000000005s)]
*  uh less, uh [[01:18:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4731.400000000001s)]
*  Completely logically rigorous deductions here [[01:18:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4733.56s)]
*  I mean are there lessons for how we should do science like [[01:18:56](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4736.4400000000005s)]
*  Scientists are constantly arguing about what experiments are the best ones to do. Um, obviously [[01:19:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4740.759999999999s)]
*  It has to do with the probability that your different hypotheses are true your priors [[01:19:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4748.759999999999s)]
*  Which of course we don't agree on but also I think you would argue [[01:19:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4753.32s)]
*  The relevance of that experimental result to changing your beliefs [[01:19:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4757.8s)]
*  Absolutely, I think when a great way to think about experimental design [[01:19:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4763.3s)]
*  Is to think what you're doing is you're trying to maximize the conformational power [[01:19:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4767.88s)]
*  Of the evidence generated [[01:19:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4773.5599999999995s)]
*  And that could be so that's neutral as to whether it's negative [[01:19:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4775.719999999999s)]
*  Negatively relevant evidence which it might be or positively relevant [[01:19:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4779.16s)]
*  But what you want to do is maximize the conformational power and that's the framework of this waste and and uh, [[01:19:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4782.04s)]
*  Hempel paper that we did. Yeah, where we're basically just a very simple measure of conformational power [[01:19:46](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4786.92s)]
*  It's basically just the absolute value of this, you know of this uh confirmation measure that we have [[01:19:52](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4792.2s)]
*  And if you just try to maximize that then you can just you can just figure out which strategies are going to do that [[01:19:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4797.48s)]
*  Now just to your more broad question [[01:20:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4803.5599999999995s)]
*  Just speaking a little bit more philosophically here zooming out a little bit [[01:20:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4806.12s)]
*  So as I said, I think this is a very elegant theory of inductive logic now [[01:20:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4809.4s)]
*  And when you're actually applying a theory you have to construct models and this is where all the hard work comes in [[01:20:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4814.28s)]
*  You got to really come up with not necessarily an exact probability distribution, but you have to have enough constraints [[01:20:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4820.679999999999s)]
*  on your probabilities to be able to decide whether the evidence in your experiment favors one hypothesis over another [[01:20:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4827.4s)]
*  And you might not need to give an exact marital probability distribution over everything [[01:20:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4834.5199999999995s)]
*  But you'll need enough constraints to determine what whether favoring occurs, you know in which direction it goes in [[01:20:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4838.84s)]
*  And how do you do that? Well [[01:20:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4845.16s)]
*  It's going to be quite difficult in many cases. It's going to involve a lot of [[01:20:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4847.48s)]
*  science measurement statistics [[01:20:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4851.96s)]
*  Uh a lot of also just theoretical arguments and just trying to you know, it's so it's partly an art [[01:20:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4854.84s)]
*  Modeling is not just a pure science, but this is true in all branches of science [[01:21:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4861.32s)]
*  So what I want to say is inductive logic is no different than any other science [[01:21:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4864.68s)]
*  It gives you a theory [[01:21:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4868.2s)]
*  But in order to apply that theory you have to construct models and that's really got to get in the trenches [[01:21:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4869.08s)]
*  And do a lot of really difficult science a lot of statistics a lot of measurement a lot of idealization [[01:21:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4874.6s)]
*  Whatever is suited to to assessing that argument and it's going to be case by case [[01:21:20](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4880.459999999999s)]
*  It's going to be each context [[01:21:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4885.179999999999s)]
*  We have to do the best we can to come up with the most plausible constraints to tell us what the evidence favors [[01:21:27](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4887.259999999999s)]
*  That's all we can do. You know, so I really think it is a case by case [[01:21:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4892.54s)]
*  Thing of constructing models and doing the best we can just like the rest of science when you know [[01:21:36](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4896.94s)]
*  All you know people often say all models are false, which I agree with but that doesn't mean the theories are false [[01:21:41](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4901.82s)]
*  So, you know when you take general relativity and you try to model actual situations with it [[01:21:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4908.219999999999s)]
*  Well, what do you do? [[01:21:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4913.42s)]
*  Well, you have to make all kinds of approximations because you can't solve the equations [[01:21:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4913.98s)]
*  And then you got to make all kinds of auxiliary assumptions and all kinds of measurements you got to do and you're going to statistics [[01:21:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4917.66s)]
*  There to figure all these things out and get parameters right and all that [[01:22:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4923.179999999999s)]
*  Okay, those models of course are false because they all involve idealization and approximation and so on but but the theory might be true [[01:22:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4926.54s)]
*  It certainly could be [[01:22:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4934.3s)]
*  At least a really good framework for constructing models and this is how I think of the framework [[01:22:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4936.139999999999s)]
*  I'm offering for inductive logic with its two dimensions of assessment in order to apply it. Yeah, you've got to [[01:22:21](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4941.58s)]
*  You got to fit in some adjustable parameters [[01:22:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4948.139999999999s)]
*  You have to tell me what the premises are what the conclusion is and then you got to tell me enough about the probabilities over those things [[01:22:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4949.82s)]
*  So that I can get a judgment as to whether the evidence favors the conclusion or not, you know [[01:22:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4957.0199999999995s)]
*  Is is the evidence relevant to the conclusion you may not be able to say how probable the conclusion is but but at least you'd [[01:22:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4963.26s)]
*  Like to say how relevant is the evidence get some assessment of how relevant it is [[01:22:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4968.86s)]
*  Yeah, I guess i'm trying in real time here and not quite succeeding to put this in very very down-to-earth terms [[01:22:53](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4973.66s)]
*  you know, my favorite example of a non-frequentist probability is [[01:23:01](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4981.5s)]
*  Is the dark matter? [[01:23:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4987.1s)]
*  A weakly interacting massive particle a wimp or is it an axion? That's another candidate for the dark matter [[01:23:09](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4989.02s)]
*  Or is it something else a third category, you know thing something we haven't thought of before [[01:23:15](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4995.900000000001s)]
*  So obviously this is not a frequentist kind of question, right? [[01:23:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=4999.660000000001s)]
*  This is something that we have some priors we're going to update [[01:23:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5002.9400000000005s)]
*  But now what i'm presuming is that your way of thinking about this would help me answer the following question [[01:23:25](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5005.660000000001s)]
*  If I had a certain amount of money to build an experiment and one experiment would [[01:23:32](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5012.540000000001s)]
*  Confirm like detect the wimp right detect that it is that [[01:23:38](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5018.2s)]
*  But the other experiment would like tell me that it is not an axion or something like that [[01:23:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5025.34s)]
*  Could I somehow I i'm truly not able to answer the question in real time, but could I somehow [[01:23:51](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5031.099999999999s)]
*  Judge which is more useful depending on what my priors were for those different hypotheses [[01:23:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5037.34s)]
*  Yeah, I think you could I mean what you would need [[01:24:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5043.82s)]
*  I mean you may not even need your priors what you're going to need are the likelihoods. You're going to need [[01:24:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5047.0199999999995s)]
*  Okay, how probable is it that we would have observed this evidence, right? [[01:24:12](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5052.94s)]
*  Given the one hypothesis versus given the other hypothesis. So you're going to have to be able to compare those likelihoods [[01:24:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5056.7s)]
*  Yeah [[01:24:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5062.06s)]
*  At the very least that will give you some information about the relevance dimension like does the evidence favor one over the other? [[01:24:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5062.7s)]
*  It may not tell you the probabilities because for that you're going to need priors [[01:24:29](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5069.0199999999995s)]
*  But still it can give you a good amount of information and it can tell you something that the experiment's doing something valuable [[01:24:33](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5073.1s)]
*  It's it's giving you evidence that favors one of those hypotheses over the other because it's more relevant to one than it is the other [[01:24:39](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5079.58s)]
*  Even if you don't know how probable they are, that's fine. You may not know how probable they are [[01:24:45](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5085.5s)]
*  So you may not know whether to accept or reject but you still can say hey [[01:24:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5089.740000000001s)]
*  This is this evidence seems to favor the one hypothesis over the other and I think that's generally how scientific experiments actually work [[01:24:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5094.38s)]
*  as I was saying before [[01:25:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5102.22s)]
*  When you're designing experiment, you can't determine how probable things are going to be [[01:25:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5104.22s)]
*  I mean you can given your priors or something if you know, you could yourself determine but what you can do [[01:25:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5108.54s)]
*  Generally is you can can design experiments such a way that it provides evidence that favors one thing over another or is relevant [[01:25:14](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5114.3s)]
*  To to the experimental question [[01:25:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5122.62s)]
*  There's a claim out there that i'm a little sympathetic to that scientists should be more open about what their priors actually are [[01:25:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5124.62s)]
*  Like when we do an experiment like we turn on large hadron collider and scientists said well we could find all these new particles [[01:25:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5131.42s)]
*  Tell me what the probability is that I will actually find these new particles which physicists at least never ever do [[01:25:37](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5137.42s)]
*  I don't know if people in other fields actually do that [[01:25:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5142.9400000000005s)]
*  Do you think it'll be good that they you know put their money where their mouth is in that way? [[01:25:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5144.780000000001s)]
*  Well, the great thing about so i've been thinking a lot about different sciences because i'm working on this project with a couple colleagues [[01:25:48](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5148.700000000001s)]
*  on the replication crisis in science and [[01:25:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5154.06s)]
*  The different sciences are very radically different in terms of how they're dealing with replication and what problems they have [[01:25:57](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5157.0199999999995s)]
*  Particle physics is what is sort of like the gold standard. I mean the the experiments they do [[01:26:02](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5162.46s)]
*  The evidence they generate is so confirmationally powerful [[01:26:08](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5168.06s)]
*  That it almost doesn't even matter what your priors are right like it it really doesn't it basically just swamps completely [[01:26:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5171.82s)]
*  There's such large likelihood ratios that you get from those experiments that you know come in with whatever prior you want [[01:26:18](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5178.94s)]
*  You're going to basically come out pretty sure that these particles exist if you're paying attention to the evidence [[01:26:24](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5184.14s)]
*  And so particle physics is this is really a great example of where we're designing experiments that are so [[01:26:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5188.700000000001s)]
*  confirmationally powerful that it almost doesn't even matter what your priors are but other sciences are not like that other sciences [[01:26:34](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5194.76s)]
*  It's much more sensitive to your priors as to what attitude you're going to come out after looking at the experiment [[01:26:42](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5202.54s)]
*  Um, and also it's even more controversial whether you whether you have really relevant evidence or not [[01:26:47](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5207.9800000000005s)]
*  Even that is is controversial in a lot of the special sciences. Whereas in particle physics [[01:26:55](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5215.02s)]
*  No, you know, the evidence is very relevant. It's extremely relevant [[01:27:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5220.3s)]
*  And so that's I view that as kind of one of the easy cases and you know, like any theory [[01:27:04](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5224.78s)]
*  It's going to have [[01:27:10](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5230.54s)]
*  Cases it's really good at explaining and it's going to have anomalous cases and that goes for the bayesian theory that i'm [[01:27:11](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5231.9s)]
*  Of inductive logic that i'm offering [[01:27:17](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5237.42s)]
*  Um, it's a pluralist bayesian. It's not it's not saying you should use [[01:27:19](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5239.5s)]
*  A particular probably but it's some probability function, right? [[01:27:23](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5243.34s)]
*  It's basically in the sense that i'm willing to put probabilities over all the hypotheses, right? [[01:27:26](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5246.54s)]
*  Okay, which which non bayesians aren't willing to do but in any event, um [[01:27:30](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5250.06s)]
*  Look, it's a theory and it's going to have limitations just like newton's theory wasn't able to explain [[01:27:35](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5255.5s)]
*  You know in any really plausible way the motion of mercury [[01:27:40](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5260.7s)]
*  I'm sure there are going to be cases that we can find in science where the where the theory i'm offering [[01:27:44](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5264.46s)]
*  It's going to have to be really challenged to come up with plausible models that explain [[01:27:49](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5269.26s)]
*  How much confirmation there is in that case and you know, but that's the nature of science. And so [[01:27:54](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5274.22s)]
*  Even in so I like to think there's a there's a spectrum of cases [[01:28:00](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5280.46s)]
*  There's easy cases like particle physics or games of chance [[01:28:03](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5283.900000000001s)]
*  You know [[01:28:06](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5286.62s)]
*  These are easy cases and then you go down the spectrum and there's really really much harder cases and much more controversial cases [[01:28:07](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5287.02s)]
*  But that's true pretty much of any science [[01:28:13](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5293.74s)]
*  Okay. Well, I think that we have confirmed that this is a fun thing to talk about but maybe we haven't because my prior was so [[01:28:16](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5296.46s)]
*  Big that it didn't actually wasn't actually relevant the evidence to be selected here. But in any event brendan phytelson [[01:28:22](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5302.06s)]
*  Thanks very much for appearing on the mindscape podcast [[01:28:28](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5308.22s)]
*  Thank you so much. Shawn. What a pleasure [[01:28:31](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5311.02s)]
*  You [[01:28:43](https://www.youtube.com/watch?v=JG57WvAWzUM&t=5323.5s)]
