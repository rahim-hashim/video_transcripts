---
Date Generated: June 08, 2024
Transcription Model: whisper medium 20231117
Length: 5102s
Video Keywords: []
Video Views: 30822
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2021/10/11/168-anil-seth-on-emergence-information-and-consciousness/

Those of us who think that that the laws of physics underlying everyday life are completely known tend to also think that consciousness is an emergent phenomenon that must be compatible with those laws. To hold such a position in a principled way, it’s important to have a clear understanding of “emergence” and when it happens. Anil Seth is a leading researcher in the neuroscience of consciousness, who has also done foundational work (often in collaboration with Lionel Barnett) on what emergence means. We talk about information theory, entropy, and what they have to do with how things emerge.

Anil Seth received his D.Phil in Computer Science and Artificial Intelligence from the University of Sussex. He is currently a professor of cognitive and computational neuroscience at Sussex, as well as co-director of the Sackler Centre for Consciousness Science. He has served as the president of the Psychology Section of the British Science Association, and is Editor-in-Chief of the journal Neuroscience of Consciousness. His new book is Being You: A New Science of Consciousness.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll
---

# Mindscape 168 | Anil Seth on Emergence, Information, and Consciousness
**Mindscape Podcast:** [October 11, 2021](https://www.youtube.com/watch?v=dzC4nw3HCMc)
*  Hello everyone, welcome to the Mindscape Podcast. I'm your host, Sean Carroll. Longtime listeners,
*  readers, etc. will know that I'm not someone who thinks that consciousness is a separate
*  ontological category out there in the world. We've talked about consciousness on the podcast a number
*  of times, David Chalmers, Philip Goff, and other people. And a lot of people, including those two,
*  think that we can't just explain consciousness as the motion of material stuff in the universe,
*  right? Pure physicalism. We need to have separate categories for mental actions and properties and
*  so forth. It's a little bit vague in my mind what other people want. I don't want that, okay? So,
*  people like me go around saying consciousness is emergent from an underlying purely physical
*  structure. And we can go into what that means. It's not that we know how it emerges, okay? And
*  I'm not claiming that, but we know enough about the underlying behavior of the physical stuff that
*  it's very, very difficult to imagine adding in new stuff that would somehow be responsible for
*  consciousness. And so the word emergent in that set of claims plays an important role. And the
*  people who are skeptical of people like me will often say, like, what do you mean by emergence?
*  Like, you're just, that's just as magical and wish-hoping as our idea that there's a separate
*  ontological category. And that's completely fair, right? I mean, we do understand a lot about the
*  underlying stuff, the electrons and protons and neutrons and the different forces that push them
*  around. That stuff we understand very, very well. To say that at some higher level of description,
*  complicated things turn into consciousness without adding any new ingredients is a big
*  leap. And we would like to understand that better. So, forget about consciousness. It's really
*  important to understand what you mean by emergence. What is it? When does it happen? Under what physical
*  circumstances does a complicated system exhibit emergent behavior? So today's guest is Anil Seth,
*  who is a leading researcher on consciousness. And in fact, Anil has a new book coming out that I can
*  recommend to you called Being You, a New Science of Consciousness, where he pushes this line that
*  consciousness is an emergent phenomenon out of the physical stuff. It's always good when people
*  who you want to have on the podcast have a new book coming out, then they are very much more likely
*  to say yes when you invite them on the podcast. But even better than that, Anil is someone who
*  thinks very carefully about this idea of emergence. He's not just saying, yeah, yeah, don't worry,
*  it'll emerge. He's thinking both about consciousness and about emergence for its own sake. And in fact,
*  coincidentally, he and his collaborator, Lionel Barnett, just came out with a paper called
*  Dynamical Independence, Discovering Emergent Macroscopic Processes in Complex Dynamical Systems.
*  So again, forget about consciousness for the moment. Just think about complex systems and
*  ask yourself, under what circumstances do you get emergent behavior? Somehow, we know a lot that we
*  want to have happening when emergence happens. We want to be able to describe systems pretty well on
*  the basis of very, very, very incomplete information. We don't know all the positions and velocities of
*  all the different atoms that make up you or me or a cup of coffee or anything like that. And the
*  descriptions that we get of that behavior at the macroscopic level, the emergent descriptions,
*  can look and feel very, very different than the underlying descriptions. I personally think this
*  is one of the biggest barriers to people getting what it means to say you have an emergent
*  description because we tend to think that we're Laplace's demon. That, you know, sure, I don't
*  know where all the atoms are, but I know where a lot of them are. That's almost as good, right? But
*  we have nowhere close to the information you would need to be Laplace's demon. And so what we need to
*  do is understand the relationship between the underlying theory and the emergent theories. And
*  Anil and Lionel Barnett just wrote a paper about exactly that. So because he wants to promote his
*  new book on consciousness and I wanted to talk about emergence, I invited him on the podcast.
*  And mostly, I'll admit, we talked about emergence because that's what I wanted to talk about. So
*  this is really the first full podcast episode, mostly devoted to the topic of emergence and
*  what it is. But we do get into consciousness because there are similarities between the general
*  theory of emergence and the general theory of consciousness for its own sake. You know,
*  the conscious brain looks at the world and gets a very tiny slice of the pie, right? It doesn't see
*  all of what's going on in the outside world, but nevertheless, it constructs a story about it.
*  That's an amazing thing. Maybe there's some relationship there between what the brain's
*  doing and how we talk about emergence more generally. I don't know. I'm crossing my fingers.
*  Maybe it's true. This is all very cutting edge stuff. Again, plenty of work here to be done for
*  future generations of smart young people growing up to be scientists and philosophers and thinking
*  hard about this. So let's go. Anil Seth, welcome to the Mindscape Podcast.
*  Thanks for having me, Sean.
*  So you're one of the neuroscientists out there who's willing to talk about consciousness. I mean,
*  there's many neuroscientists talk about consciousness, but you're even willing to
*  talk about the more philosophical side of things. And we know I've had people like David Chalmers
*  and Philip Goff on the podcast who think that there is this hard problem, right? This impossibility
*  of explaining the first person perspective of conscious experiences if we're just physicalists,
*  materialists who think that it's just a collective behavior of atoms in the brain. So tell us just
*  to set the stage where you come down on these kinds of questions. How do you think about
*  consciousness vis-a-vis the physical stuff of which we are made?
*  I suppose I'm a pretty standard physicalist or materialist that I think my starting position
*  anyway is that consciousness is part of the natural order of things. It's part of the natural
*  world. Everything that we know closely ties it to the brain, at least in some way, at least the kind
*  of consciousness that I'm interested in explaining, which is the consciousness that we are familiar
*  with in our everyday life, the difference between being awake and aware and having experiences of
*  drinking coffee or watching TV and falling into a dreamless sleep or going under general
*  anesthesia. These are differences in consciousness that apply to human beings and probably to many
*  other living organisms as well. And they do seem to be closely coupled with something about
*  the brain. The question is, is what? So now that's a fairly typical empirical physicalist
*  standpoint. I am, in the end, a little agnostic about how consciousness will turn out to be part
*  of our overall story of the universe. The idea of the heart problem, which you mentioned, David
*  Charn, is extremely influential and very articulate in putting this apparent mystery and the idea that
*  we could explain everything about how the brain works in physical terms, how neurons interact with
*  each other, how they explain all the capabilities and functions of things that brains do. And these
*  functions can be things in the vicinity of consciousness, how perception works, how we pay
*  attention. But the charm is there's always going to be something left over. Why should any of this
*  physical processing be associated with or identical to the redness of red or the sharpness of a
*  toothache? Why is there anything going on for the system in terms of subjective experience? That's
*  the heart problem. How does consciousness fit into our physical picture of the universe as a whole?
*  And that's where you get these kind of menu of metaphysical options. You have dualism, that they're
*  two completely separate modes of existence. Then there's the awkward problem of how they interact.
*  You have panpsychism, which I think is an easy get out to the whole mystery. It just says, well,
*  you know, we can't figure it out. Then we'll just say, we can just build it in from the ground up
*  and say it's here, there, and to some extent everywhere. Or just as bad, in my view, idealism
*  that say, well, consciousness is kind of all there is. And the problem is not how you get mind from
*  matter, but how you get matter from mind. So I'm actually, I don't know the ultimate resolution of
*  that. I also think that conscious experiences exist. There's another camp, which is the sort
*  of strong illusionist camp, which says something like, we're mistaken about there being a mystery
*  at all. When we think conscious experiences are something special that are hard to fit into the
*  picture of the universe. Well, that's just because we're misunderstanding in some crucial way,
*  what the explanatory target is. But I just prefer to start almost like a practical matter that
*  conscious experiences exist. In fact, I think that's probably the only thing that I'm really
*  sure of is that I am having conscious experiences. I'm also pretty sure that there's an objective
*  physical reality out there, consisting of something that physicists will know much more about.
*  What that is, the problem is how do we relate the two? And in trying to relate the two, maybe
*  this apparent mystery of the hard problem will evaporate, will dissolve in a similar, though not
*  identical way to how the apparent mystery of life eventually evaporated when people got on with the
*  job of explaining how living systems work. So I call it a bit of tongue in cheek. The real problem
*  of consciousness is to explain why conscious experiences are the way they are in terms of
*  things happening in brains and bodies. And by pursuing that agenda, hopefully, though not
*  guaranteed, but hopefully the big metaphysical hows and whys will become less mysterious.
*  So I don't know anything about consciousness at a detailed level myself, other than being
*  an avid user of it. But I do know something about physics and the physical world. So I have gone on
*  record and even written a paper trying to explain how whatever consciousness is, whatever is going
*  to be the ultimate explanation for it, don't make your first move to change the laws of physics to
*  account for it. Which fine, I mean, that's a whole school of thought. But then so what does
*  account for it? And the word I like to use is emergence, right? How there's different levels
*  of description, and there's a higher level where we talk about people and consciousness and so forth.
*  So I had David Chalmers on the podcast, and I use that word emergence because I do.
*  And I actually brought it up here because I want to quote David exactly. I don't want to
*  misrepresent him. He said, Yeah, my view is that emergence is sometimes used as a kind of a magic
*  word to make us feel good about things we don't understand. How do you get this from this? Oh,
*  it's emergent. But what do you really mean? So to be fair to David, he's thought a lot about
*  emergence and written about it. But it clearly he's a little bit skeptic, it's going to do
*  enough of the work. Are you on the in the camp that says that we should be able to ultimately
*  someday think about consciousness as an emergent phenomenon? I think emergence used properly and
*  carefully. So I'm with David on this, that it's not to be used as some sort of elixir or magic,
*  magic source, special source that that just relabels the mystery.
*  You don't just solve consciousness by replacing it with another mystery.
*  But there is something intuitive about many systems, complex systems that admit
*  to multiple levels of description. And the brain is a highly complex system as we as we know,
*  composed of 86 billion neurons and 1000 times more connections between them, something like that.
*  Very, very complicated. Yet it gives rise to relatively easily characterizable macroscopic
*  properties, large scale properties, whether that's a behavior of a whole organism or a
*  a mental state or a single perception, I'm having a unified perceptual experience of what's going on
*  around me right now. There are things that apply to the to the collective rather than the individual.
*  Yeah. So how do we characterize that relationship? I think
*  it's almost trivially true to say that consciousness emerges from neural activity.
*  It's the devil is in the detail. What do we mean by that? How does that actually help shed
*  explanatory light on the relationship between the level of description at some lower level,
*  whether it's neurons or some other level, and the level of description of what's going on for me as
*  a conscious subject? Is it worth trying to go into the difference between weak and the strong
*  emergence? Is that a difference that you care about? Yeah, I think definitely. And I think from what
*  I've read when you've written about emergence, I think you care about it as well. I do. Which is
*  good. I think we all should because it's in these distinctions that emergence transitions from being
*  just another mystery to I think something we can get both a theoretical and quantitative grasp on.
*  So this idea, at least as I understand it, and I wonder if you understand it the same way, that
*  strong emergence is the more mysterious idea of emergence, where you might have some macroscopic
*  property that is in principle not explicable by or reducible to the microscopic components
*  that make it up. And furthermore, that it may exert some sort of downward causal power on these
*  micro level constituents affect them in some way that goes beyond the causal interactions unfolding
*  among the micro level components themselves. This is weird. This is a kind of
*  it's uncomfortably close to magic to talk about emergence this way. It's unclear how it fits into
*  a physicalist picture of the universe, though some philosophers will claim that it can do,
*  that there's no real problem with bringing new things in at higher levels like this.
*  But for me, it's a little of a dramatic move. I don't quite know what to make of it, how it
*  would actually work. And I think most tellingly, there aren't very many good examples where you
*  would be tempted to think this is happening. And very revealingly, one of the only examples
*  that reliably comes up is consciousness. Yes, that's right. So it's just this is this whole
*  reciprocal mystery thing. Now, weak emergence is very different. It preserves the intuition
*  that the whole is more than the sum of the parts in some sort of interesting way.
*  So there are many examples. There are things like gliders in John Conway's Game of Life.
*  The example I like to use is flocking birds, which are really nice computer simulations of
*  birds flocking. But I see them most evenings here in Brighton over the ruins of one of our old
*  piers. You have these flocks of starlings that, murmurations of starlings, I think they're
*  properly called, that flock together before roosting for the evening. And the flock really
*  does seem to have a life of its own. And it seems very appealing that the behavior of individual
*  birds within the flock is somehow guided by the flock as an entity that's flying around, remaining
*  part of the flock in some way. But there's nothing mysterious going on here. There are just birds
*  following local rules, how they fly together, as far as we know. Certainly, you can simulate things
*  purely locally. The birds are behaving local rules. And if you set it up the right way,
*  you get what looks to an external observer like an emerging property, something that's more than
*  the sum of its parts. And so the question is, how do you operationalize that? How do you become a
*  bit more specific about what systems display weak emergence and what don't? And here, I've been most
*  influenced by the philosopher, Marc Bedow, who describes weak emergence as something for which
*  there is an explanation, a macroscopic property for which there is an explanation in terms of
*  microscopic components. But it's what he calls incompressible. You can only figure out what the
*  global property is by simulating exhaustively the microscopic interactions.
*  And that's, I think, quite a nice starting point, but it's a kind of all or none starting point.
*  So I think that nowadays, and this is something I've been interested in for more than a decade now,
*  is how do we get a little bit more empirical quantitative graded about these things? Given
*  a system, can we measure the extent to which a macroscopic property like a flock or some other
*  property, maybe at some global activity pattern in neurons, can we measure the extent to which
*  that is weakly emergent from its constituent parts? Your home isn't just a roof over your head.
*  It's a reflection of who you are. And Joybird helps you create a space that shows off your
*  personality and inspires you to live your best life. Joybird offers modern customizable
*  furniture for every space available in a variety of vibrant durable fabric options.
*  And now, Joybird's semi-annual sale is here. Ordering furniture online has never been easier
*  or more fun. You can choose from over 18,000 customization options or browse curated collections
*  to find the perfect piece for your one-of-a-kind style. And Joybird is committed to creating
*  quality furniture and a more sustainable future. Each piece is made with incredible care,
*  using responsibly sourced materials free of harmful chemicals, quality craftsmanship,
*  stain and scratch resistant fabrics, and a limited lifetime warranty. Joybird furniture can handle
*  anything your family throws at it, literally. Finally, Joybird stands by its quality and
*  craftsmanship, so they offer 90-day returns. If it's not everything you hoped for, just send it back.
*  Create a space that brings you joy with Joybird. Visit joybird.com
*  slash mindscape and get 30% off your purchase. That's 30% off at joybird.com slash mindscape.
*  So, yeah, you've sparked a lot of ideas in my brain. I know that you're the guest on the podcast,
*  but let me just say a couple things that come to mind when you say that and you can choose to
*  respond to them or not. First, I think that it's a terrible choice of vocabulary that we're stuck
*  with to talk about weak and strong emergence because they're almost opposites of each other,
*  right? They're not two different versions of the same thing. The whole idea of weak emergence is
*  that everything inheres in the microscopic components ultimately, and emerge in that sense
*  means you look at the collective behavior of it, whereas strong emergence means that when you have
*  this collection, something new appears and the emergence has a totally different kind of meaning.
*  It emerges out of something that is not just the microscopic dynamics by itself. So being that as
*  it may, maybe that is what is contributing a little bit to the confusion. Having said that,
*  I have thought about it hard and I do think that it is not insensible to imagine something like
*  strong emergence. The example I would give is, you know, an atom or an electron, an elementary
*  particle obeys the laws of physics. And those laws of physics are really, really local, right?
*  They say the electron cares about what is going on in other quantum fields at the point where the
*  electron is nowhere else. But what if the real laws of physics say that that's pretty good when
*  you have two or three or 10 electrons, but when you have 10 to 23, it's not good anymore. There
*  are literally new laws that come in and there's some feature of the organization that the electron
*  is stuck in that needs to be taken into consideration. I think that would count as strong emergence and
*  it would also be completely incompatible with everything we know about physics. So you're welcome
*  to think about it, but it is something very different. Whereas just to finish up, maybe the
*  idea of strong emergence does make sense when both your sort of finely grained theory and your
*  coarsely grained macroscopic theory are themselves theories of complex structures. So like with the
*  starlings or the birds flocking, a bird is not an electron. So a bird has its own internal
*  structure and its memory and things like that. And so maybe when you relate those two levels to each
*  other, there is some sense in which strong emergence is a useful concept to lean on.
*  But when you're relating the brain to the atoms of which it's made, I don't see how it can personally
*  make sense.
*  Let me respond to both of those. I think there's, I kind of agree mostly, although I quite like the
*  weak strong terminology, because for me it echoes other domains in which that terminology has been
*  used. And it's often the case that people are initially attracted to the strong version of
*  whatever phenomenon it is, whether it's something like strong artificial intelligence, which is
*  supposed to connote genuine intelligence rather than the simulation of it, or strong artificial
*  life, similar idea. There's something about the strong X in which the X possesses some quiddity,
*  some essence of the phenomenon that you're talking about. But it almost always turns out that in
*  fact, you make more progress by taking a weak stance and thinking, okay, how do we stimulate,
*  how do we understand the mechanisms that exhibit some of the properties that we associate with this
*  phenomenon, but without trying to sort of build it in as a fundamental essence. There's an old
*  paper I was very influenced by, I think came out of, was one of the original papers in network
*  theory, that from Mark Granovetter called The Strength of Weak Ties. Again, just having this
*  idea that weak things, weak interactions, weakly coupled systems can give you really powerful
*  effects. And for some reason, I quite like that way of thinking, that not trying to do so much
*  can actually lead to making more progress. We see the same thing in consciousness too, actually.
*  This gets back to just where we started, that if you try to solve the hard problem head on and
*  explain why consciousness is part of the universe, maybe you want to build a system that is
*  artificially conscious, going off the strong artificial consciousness,
*  it's unclear you're going to make much progress because we just don't know how consciousness
*  fits into our understanding of the universe in general. But taking a weak approach and just
*  saying, okay, look, consciousness has these properties and let's try to understand them
*  individually, one by one, you get somewhere. So I do quite like that. As to the other point about
*  whether there are legitimate situations in which to invoke something like strong emergence,
*  I think, to be honest, I don't know enough about the relevant domains of physics to know
*  whether that is justifiable. Because there's also another form of emergence which often gets
*  overlooked, which is nominal emergence. Which is-
*  I don't think I even know that one.
*  ... emergence where you just have a property that can apply to a whole that just by definition
*  cannot apply to the parts. So the example I think that Mark Beddow uses is a circle is
*  nominally emergence from the set of points that make it up. There's nothing mysterious going on
*  here. It's just that a circle is not the kind of property that can ever be attributed to
*  a point, a single point. It's only something that a collection of things can have. So my
*  intuition is that if you combine that with a sufficiently rich version of weak emergence,
*  then you get everything you need. And the key thing for me about this weak emergence picture is
*  the causal closure of the physical world. That you want things to run through all the way down.
*  Of course, there are concepts that we will use to describe things at a higher level of
*  descriptions, ontologies that appear at more abstract levels of organization,
*  which can be absolutely essential for our understanding of a system. And they are real
*  too. Daniel Dennett talks about real patterns. The fact that something is described at a higher
*  level doesn't mean that it doesn't exist. It just means that that's a higher level description
*  can be very, very useful for our- can be essential for our understanding of how a system works.
*  But it doesn't mean there's some disruption to this sort of picture of physical causality
*  that ultimately runs right down to whatever reality really is, which again is in your
*  wheelhouse, not mine, fortunately. But we did- I'll also plug the appearance of Dan Dennett
*  on the podcast, where we center the whole conversation on this idea of real patterns
*  and how large scale things can have an identity of their own, even if they're just depending on
*  the small scale things. And as you imply, there are those who take the opposite tack, right? That
*  you need to sort of add more ontological categories at each level and consciousness is going to be
*  something that only exists at this higher level. But the challenge that those people would give to
*  you and me is, you know, again, demagicify this word that you're using of emergence. And so if you
*  think that consciousness or experience or whatever is not a separate category, if it just comes out
*  of the motion of atoms and neurons, etc. at some level, how exactly does that happen? So I was
*  thrilled to see that you've actually written a paper about, at least beginning, maybe we can say,
*  to understand how exactly that happens when you can talk about a complex system with many moving
*  parts in terms of a higher level emergent description. So why don't you tell us the
*  punchline to that paper? I'd be happy to. It is, as you say, it's very much a starting point. And
*  there's actually a few different approaches now. And I think this is for me a promising sign,
*  because I don't know which approach is going to be right. And having a diversity of different ideas
*  out there is a healthy situation to be in. And the paper I think you're referring to is a very
*  recent one with my colleague Lionel Barnett, who's a proper mathematician in our collaboration.
*  And he sort of takes vague ideas and makes beautiful, beautiful concepts from them.
*  But it actually began for me about 10 years ago. It's the first way I thought about how to
*  operationalize this idea of emergence, and was really taking Mark Beddow's idea about
*  weak emergence and thinking, how can we build some simple measures that make that work in practice?
*  And so you unpack it one stage further. His initial proposition was that a weakly emergent
*  property is you have to run the microscopic level exhaustively to extract the microscopic property.
*  You have to simulate it entirely. There's no shortcut. Conceptually, you described a weakly
*  emergent property. Let's think about the flock of birds again, just to give it some, just to
*  guide our intuitions. We have a flock of birds wheeling around the pier here.
*  To call it weakly emergent is to say that the flock is simultaneously both dependent on
*  the birds that make it up. It's not that you have a flock floating somewhere where the birds are.
*  The flock is made of the birds. Philosophically, we would call it supervenient on the birds.
*  But the flock seems to have an autonomy. This is the life of its own thing. The
*  behavior of the flock seems to be more than the sum of the behavior of the individual birds
*  in some interesting way that leads us to say, oh, it's a flock and it's not just birds flying
*  randomly all over the place or birds flying in some sort of super fighter jet formation where
*  they're very rigid and there's no interesting dynamics going on.
*  My challenge then was, well, how do we measure that? Let's say we have a simulated bird flock.
*  What's a way of applying a measure so that we get a high number when it looks like a flock and a
*  low number when it looks like the birds are just randomly doing their thing or flying in a rigid
*  formation? The approach then that I took was to use a method that I'd been using in neuroscience
*  for a bit called Granger Causality. Speaking of terrible names, this is another terrible name
*  because Granger Causality has nothing to do with causality. It's to do with prediction.
*  It's to do with prediction. To unpack it very simply, it basically provides a way of measuring
*  information flow between two variables. Let's say you have two variables that change over time.
*  We're used to thinking whether they're correlated or not. Do they share information?
*  Correlation is a bidirectional notion. If A is correlated with B, then B is correlated with A
*  to the same extent. It's symmetric. In information theory, as you know, mutual information would be
*  the equivalent. They share information. Imagine if you could put an arrow on it and say that
*  A is conveying information to B, but B is not conveying information to A or is conveying less
*  information. There are ways to measure that statistically. What Clyde Granger, who developed
*  this concept of Granger Causality did was basically say that you can say that A Granger Causes B,
*  and I have to get this right because it always messes me up when I'm trying to explain it. You
*  say that A Granger Causes B if A contains information that helps you predict the future of B
*  that's not already in the past of B. You have a time asymmetry going on here now because
*  causality is often about time. It's just intrinsically caught up with our notions of
*  causality. Basically, A is giving you information that helps you predict how B unfolds that's not
*  already in B. Now you can see that this is not necessarily symmetric.
*  Information is flowing from A to B in that sense.
*  Exactly. It's a way of actually measuring, given two time series that fluctuate over time.
*  This could be any of the trajectories of birds in a flock or the trajectories of prices in the stock
*  market or the electrical voltages of neurons in the brain. It could be anything described in the
*  form of variables that change over time, time series. You can ask the question,
*  does one Granger cause the other, which is equivalent to one transfer information to the
*  other? The equivalent of Granger causality and information theory is called transfer entropy.
*  It's that idea that it's now not a shared information, but A is giving information to
*  B because it's helping predict its future. When you say the equivalent, are they mathematically
*  the same or are these two labels that mean slightly different things in different contexts,
*  transfer entropy and Granger causality? I'm very glad you asked that question because it's
*  one of those beautiful examples where conceptually they're very, very similar,
*  but they came out of different mathematical contexts. Granger causality came out of this
*  statistical framework of autoregressive modeling, which is just the way of saying you model
*  variables based on weighted sums of their past. It's just one particular statistical framework.
*  Transfer entropy, same concept, but the mathematical infrastructure for it is information
*  theory. I always thought that they were very closely related and that somebody would have
*  shown that they were identical under certain conditions. My colleagues at Sussex, this was now
*  11 years, 12 years ago, Lionel Barnett and my other postdoc at the time, Adam Barrett, basically
*  realized that nobody had shown that and showed it. It was one of those great,
*  very quick papers that we did. They did it really. We showed that if variables are Gaussian,
*  which is to say if they're described by normal distributions, bell curve distributions,
*  an assumption you might often make, then in fact, Granger causality and transfer entropy are
*  exactly equivalent. Well, one is one half the other, which is really nice because it actually,
*  it's not a trivial thing because you connect now two different domains of mathematics in a way.
*  You connect this whole framework of autoregressive modeling, which is very convenient to work with.
*  It's very easy to build models of data that way, but you now can translate it directly into
*  information theory and talk about bits per second of information flow and have a measure of
*  information flow in terms of bits that you don't get the other way. There is a very deep relationship
*  between the two concepts. If you've ever wanted to learn a new subject or even just refresh your
*  memory about a subject you used to be familiar with, you can do that at Wondrium. That's W-O-N-D-R-I-U-M.
*  Wondrium is a streaming service that used to be the great courses plus that has incredible
*  content with answers to millions of the whys, hows, where's, what's, who's, and whens you've
*  ever had. For example, I used to be on the chess club back in high school, but it's been decades
*  since I've seriously played and Wondrium has a great course on how to play chess taught by
*  Jeremy Sillman, an international master and winner of the US Open. All of Wondrium's videos
*  are academically comprehensive, relentlessly entertaining, and led by engaging experts.
*  I know you'll love Wondrium too, so we've arranged a special limited time offer for listeners,
*  a free month of unlimited access. To get this offer, sign up now through the special URL
*  Wondrium.com slash Mindscape. That's W-O-N-D-R-I-U-M dot com slash Mindscape. There's so much you can
*  learn in a month. Go to Wondrium.com slash Mindscape to start your free trial.
*  So let's just give ourselves an independent definition of transfer entropy. Is it something
*  like how many bits of information are flowing from one series of events to this other series?
*  Sort of. I think that, yes. I mean, that would be the way of describing, interpreting what the
*  transfer entropy metric means. To say what transfer entropy is in information theory terms, if I can
*  get this right, it's again, you've got your two variables and it's to say that it's the degree to
*  which the future of, let's say, B is conditionally dependent on the past of another variable A,
*  conditioned on its own past. So it's always this thing about what is another variable bringing to
*  the table in terms of predictability or additional information? So you have B all by itself and you
*  can say, well, from what B is doing, like if B is a football flying through the air obeying
*  Newton's laws, and you can predict what it's going to do next. But then there's some other
*  variable that maybe if you knew that also would or would not teach you even more than from what
*  you knew about the past of the football. Yes. Although you just raised one of the
*  important constraints in practice where these things make sense, which is that they only really
*  can be used in stochastic systems. There has to be some at least apparent randomness to what's
*  going on. If it's deterministic, you already know what's going to happen. So there's no way to
*  compare how much more you know by introducing another variable. So these things have certain
*  domains of application, at least in the way we would use them. They have to be applied to stochastic
*  systems that are stationary and so on and so on. I mean, would it count to have a parent stochasticity
*  because the fundamental laws are perfectly deterministic, but we don't know exactly the
*  initial conditions like we have in statistical mechanics? Yes. Okay. So long as it's stochastic
*  with respect to the tools you're using to model the system, then it's okay. Okay. Then these things
*  work fine. So your example is, yeah, it makes sense. You can watch basically, you watch one thing
*  going on in the world. You can imagine, let's go back to a neuron. A neuron is firing, and you can
*  try to figure out what will, you could try to predict on the basis of the past of that neuron
*  firing, what its future firing is going to be like. And then you can just ask the question, okay,
*  I can do, maybe I'm 70% good at predicting the future firing of this neuron. Now I look at another
*  neuron. Can I do better by bringing in knowledge from what this other neuron is doing? And if I can
*  in this statistical way, then yes, there's information play between the two. There's
*  greater causality between the two. But we've gone quite far from emergence here.
*  Let's bring it back. But the next step is actually pretty simple, which is instead of thinking of
*  two neurons or two birds flying around or two stock prices, we think of two levels of description.
*  So you've got your macroscopic level of description and your microscopic level of
*  description. You've got your flock of birds and you've got your individual birds that make it up.
*  And now you can apply some of these same concepts to characterizing the relation between the flock
*  and the birds, between the macroscopic and the microscopic. And now there are many options for
*  how you might use these concepts to come up with a range of different measures of emergence, like
*  things. So for instance, you could say, and this was my original approach 10 years ago, I could say,
*  okay, does the flock as a whole predict its own future behavior better than I can do from just
*  the birds alone? Is there sort of some self causality, self information for the flock
*  conditioned on the parts that make it up? And if so, then I could say, well, that's a way of
*  operationalizing this idea that the flock has a life of its own. It's driving its own behavior in
*  a way that goes beyond what I can say by looking at the parts. Now this isn't to say there's
*  something spooky going on because to make that claim, I have to have imperfect knowledge of the
*  system. It's only just a way of saying, given imperfect knowledge of the system,
*  some things will look like they're flocking, other things won't. And can I distinguish these
*  cases? And it turns out, yes, I can by using this method. So that's one approach. In another
*  approach, and this is what with Lionel Barnett we were working on recently, it's a slightly
*  different thing. Imagine that you don't know that there's a flaw. This is another question that
*  comes up in emergence. We often ground it with these discussions of what's intuitive. A bunch
*  of birds that flock is intuitive. We know, we can see there's something going on there that's
*  interesting. Gliders in the game of life, they leap out at you, which is why they're interesting.
*  But maybe emergent properties don't always leap out to us as observers of them. And if I look at
*  a whole bunch of neurons flickering under some calcium imaging thing, maybe they're all synchronizing
*  together. That's pretty obvious. But if they're not, if they're just flashing on and off,
*  it's very hard for me as an external observer to know whether there's anything interestingly
*  weakly emergent in their global patterns. And that's the problem of identification of an
*  emergent property. So what with Lionel we were interested in was can we develop methods
*  that allow us to, in a data-driven way, identify candidates' weakly emergent
*  macroscopic properties. Another word for that would be coarse graining. Higher level abstractions
*  of the system that have this kind of property. And we did it in a slightly different way. So for
*  Lionel, the key idea was that a candidate's weakly emergent variable must be what we call
*  dynamically independent from its microscopic underpinnings. Which just, again, this just means
*  that knowing what's going on at the microscopic level does not help you predict what's going on
*  at the macroscopic level. So that's why we use that word, dynamical independence. Doesn't
*  necessarily mean in this case that the macroscopic level has to predict itself in any interesting
*  way. However much you can do that, it just has to be independent of what's going on in the bottom.
*  Which is why I say there's this whole variety of different options now. How to think about
*  what an emergent property might be and what we're doing in my group at the moment is trying to
*  flesh out many of these different directions and figure out how they relate. There's not going to
*  be one single answer. Well, I think I don't want to let this go by too quickly because what you
*  just said is not only very beautiful but philosophically really, really important, I think.
*  When I have these arguments with people who would like to let a richer ontology into their
*  universe. So they want to, like we said before, have new fundamental concepts at every level.
*  In practice, it's not exactly applicable to your definition, but if I say a chair or a table is
*  emergent from a bunch of atoms, well I'm helping myself to the fact that I see tables and chairs
*  and I know what they are already long before I ever knew what atoms were. I think that a lot of
*  the people who want these richer ontologies are saying like there's no way you'll ever find tables
*  and chairs if you just start with atoms. So your response to gussy it up a little bit is, yes I can
*  and here's how to do it. Here are the equations that say here are the conditions under which we
*  find these emergent structures. Yeah that's right. I mean that's the intuition. That's the
*  motivation anyway. I don't know how far you get that way, but I think I always want to push back
*  against the temptation as you say to just bring in new things because it seems like you can't get
*  there without doing that. I mean this is the whole, it's the same sort of intuition that I think drives
*  the heart problem. This idea that you'll never get to consciousness just by thinking about what neurons
*  do. But there's a whole, there's a lot of things neurons can do that we've not yet learned to think
*  about and we just need to, we need to exhaust the possibilities of thinking about what very
*  complicated systems of billions of neurons can in fact do before reaching the conclusion that
*  consciousness is not among them. Now this might seem philosophically naive because you might be
*  able to say look however complicated it is it still will not get there. But I'm just inclined
*  to bracket that and say I might be being philosophically naive here. I still think we've
*  not exhausted the possibilities of the kinds of things that physical systems can do given
*  sufficiently rich interpretation of them. And let's just see how far we get and be guided by
*  the ultimate target whether it's consciousness or emergence or try. I mean here's the thing, I see
*  emergence in this sense as a way to enrich our descriptions of physical systems that might have
*  relevance to consciousness. I'm not saying that we will demonstrate that consciousness is an
*  emergent property or come up with some equivalence. But it allows us to characterize the behavior of
*  complex systems in ways that might help us get closer to the explanatory target of consciousness.
*  Like there is a sense in which conscious experiences are unified and global and seem to be more than
*  the sum of the things that make them up. So it might be very useful to have some something in our
*  toolbox that allows us to assess these claims in general and then see how they stand up when we
*  apply them to let's say the brain dynamics when people lose consciousness under anesthesia or
*  fall asleep or other such other such things. Do weakly emergent properties dissolve in those
*  cases or not? It's an empirical question. And if you think that you can answer this question
*  using equations, that's always the best part right? There are equations here. This is not just
*  some words we're throwing around. So you can say I have a complex system made of many little pieces.
*  Here are the chunks I need to divide it up into to get emergent behavior. The next hard question,
*  hard in the old fashioned sense of hard, not Chalmers' sense, is this generic, this kind of
*  behavior? Is this robust? Like when I have a whole bunch of little things, will it inevitably be the
*  case that I can chunk it up into some emergent big things? Or are there multiple different
*  incompatible ways of chunking it up into big things? Or is the generic situation that there's
*  no way that emergence is a special delicate flower of some sort? Yeah, these are all great
*  questions. And I think you probably have better answers than I do. I don't know. I think that
*  it's appealing to me when we think about this approach of discovery of candidate weakly emergent
*  properties. One other appealing thing about that is we don't have to make assumptions
*  or too many assumptions about that. Don't have to assume there's a single
*  level at which emergence plays out. You can in fact look for emergent properties at multiple
*  different levels of abstraction, what we would call multiple different coarse grainings, and in
*  that sense figure out an emergence portrait for a system. Do all systems have emergence portraits?
*  Well, yes, but some might be trivial. Some might be just like, well, there's really nothing
*  interesting happening at any given scale. And I could construct just, for instance, a system of
*  totally random particles just moving around, not interacting with each other at all. For me,
*  I would be happy or I'd be reassured for any candidate measure of emergence to come out
*  basically flat, however you looked at that system, because that's not a system where I
*  want to see, expect to see emergence. I then have to struggle with what do I mean by emergence if
*  it can happen in a system where nothing is interacting with anything. And I think,
*  I'll make a guess. I don't think I know the answer to the question that I posed myself,
*  but my guess is personally that emergence is a rare kind of thing in the space of all systems we
*  can imagine. The existence of these higher level descriptions that are as good at predicting what
*  will happen next as you can be without extra microscopic information is probably very unlikely
*  if you just picked randomly how to course grain in some sense. And in fact, I think it opens up
*  maybe even more things to explore like the nestedness of these descriptions. So, I mean,
*  not only do we imagine that atoms emerge into a higher level description in terms of cells
*  in biological organisms and cells emerge into a higher level of organisms and organisms to
*  societies or whatever, but probably there is no universe in which something like atoms emerge into
*  something like cells and something like organisms without it being nested, right? Like without the
*  organisms themselves emerging from the cells in some way. And these are all just speculations,
*  conjectures. Let's call it a conjecture. That sounds more impressive, but that's the kind of
*  question we can now start investigating. Yeah, that sounds appropriate. I do think the first
*  thing you said, though, I think it's still probably a conjecture, but I think it's quite
*  easy, at least in some systems, to check and validate. So it's certainly the case that for
*  many sorts of systems you might write down that arbitrary coarse grainings will not have this
*  property of emergence, will not have this property of dynamical independence. So it will be
*  rare for many example classes of system, which suggests that it's rare in general, but then
*  the real world is complicated. So quite how rare these things are in the world as it is,
*  is much harder to make a strong statement about. And the nestedness question is very interesting
*  as well. Very hard to get a quantitative grasp on that. You have to do something that gets a
*  little bit recursive and gets complicated. That's why we have graduate students, right?
*  The young people are energetic enough to address these questions. But okay, so now we have some
*  framework on the ground. We'll link to the paper if people want to look it up. I'll warn you ahead
*  of time listeners, there are a lot of equations in the paper, but that's good. It's healthy for
*  you. I was surprised to learn there's a whole book that Lionel wrote about transfer entropy that
*  people can try to learn the basics about. But let's go back then to our initial motivation for this,
*  which was consciousness. So have we learned anything from this investigation about the
*  claim that consciousness is a kind of emerging phenomenon? I would say not yet. Besides just
*  the conceptual clarifications, besides deflating a little bit this association that people
*  intuitively make between consciousness and strong emergence. Just by showing that there are other
*  ways to think about emergence, I think is a contribution. Another way that contribution
*  plays out is that you can also think about downward causality or top-down causality in
*  this framework in a metaphysically innocent way. You don't have to think about competing causes
*  where you have actual top-down causes that compete with causes at the micro level and then you have
*  all these problems of which cause dominates and so on. No, I can simply say from the perspective
*  of an observer, are there occasions where the macroscopic variable, whatever it is,
*  helps me predict the evolution of the microscopic components better than knowing what the
*  microscopic components are doing. And again, this is not introducing anything that challenges
*  a physicalist picture where causes just run all the way down. But there might be systems where
*  that's the case and there might be systems where that's not the case. Back to the original
*  bird flocking thing, it turns out that certainly for the measure I was using 10 years ago,
*  that indeed when you have a bird flock, you do observe information flow from the flock
*  to the individual birds in a way that you don't when they're all flying randomly around.
*  So just having these things in your toolkit helps us resist some of the otherwise unfortunate
*  tendencies to think of consciousness as necessarily something magic. The work to be done is how much
*  purchase empirically and how much explanatory insight do these concepts offer in practice when
*  we flesh them out. And that's something that is a story yet to be told. There's a few
*  groups, we're one group doing this. There are some other groups doing this, people at the
*  University of Wisconsin-Madison and Giulio Tononi's group have other sorts of measures of emergence.
*  But there's a lot of there's a lot of trickiness in how you actually apply these in practice and
*  what assumptions you have to make and all the usual stuff which doesn't make it easy. But my
*  hope would be that if we could as a first step show that weakly emergent variables can be
*  identified in conscious states that are not there in unconscious states, they can maybe use to predict
*  levels of consciousness in people in maybe with better accuracy and fidelity than other
*  measures of global brain dynamics. I think that would be a start. I certainly don't think it's
*  suddenly going to be the solution to all our questions about consciousness. Not at all. It's
*  just another way of building explanatory bridges that might carry some of the weight of this
*  apparent mystery. What's the secret to your best night's sleep? First, toss out the memory foam
*  and upgrade to Awara. Awara features natural and sustainable latex tapped from real rubber trees,
*  humanely sourced New Zealand wool that promotes cooling and airflow, and breathable cotton for
*  enhanced moisture control and softness. Awara is known for a weightless feeling with neutral
*  spine alignment, so no sinking or pulling on the natural curve of your back. Furthermore,
*  Awara features a best in the industry 365 night trial, no questions asked. If you don't like it,
*  they'll take it back. That's with free shipping and returns and a forever warranty.
*  So for a limited time, you get $499 in free accessories, two natural latex pillows,
*  cotton sheets, and a waterproof mattress protector with every mattress purchase,
*  and feel good knowing that Awara plants 10 trees with every purchase. To redeem, go to
*  www.awarasleep.com. That's A-W-A-R-A-S-L-E-E-P.com. Discount auto apply to check out.
*  Well, one of the interesting things about your proposal based on the transfer entropy to define
*  dynamical independence and therefore emergence is that it talks specifically about the internal,
*  the self dynamics of the system. From what the system has done, what will it do next?
*  You could imagine a different approach based on the fact that one of the features of the
*  flock of starlings is that I see it as a flock. I mean, one could imagine basing a theory of
*  emergence on the fact that, or a theory of coarse graining and macroscopic states based on the fact
*  that I only have observational access to certain features. When I see the cream and the coffee
*  mixing together, I see the gross features of where the cream is and where the coffee is,
*  not the individual atoms. And therefore I talk about cream and coffee as higher level emergent
*  phenomena in some sense. So is there, I don't even know what my question here is. Is that way of
*  thinking about emergence in terms of observational capabilities or access the same as related to,
*  independent of your sort of internal dynamics way of thinking about it?
*  I think it's related, although we are, I think we're both speculating about this now. I think
*  it might be related in the sense that if we have a data driven means of identifying emergent
*  properties, they stand as hypotheses for the sorts of things that might observationally stand out to
*  us. But maybe they won't. And part of the reason I'm interested in this is that I don't want to
*  make that assumption and want to be open to the possibility that there'll be weakly emergent things
*  that do not leap out to us. There may also be the converse. There may be things that leap out to us
*  that are not in any interesting sense emergent. They may be, what we called before as nominally
*  emergent. They're just properties that inherit to a whole that cannot inherit to the parts,
*  but not in any particularly interesting sense. Well, one of the reasons
*  why I asked is because, I mean, number one, I had been wondering about that question independently,
*  but number two, when it comes to consciousness, one of the facts, features, I should say,
*  of consciousness that you yourself have emphasized is how the brain constructs a picture of the world
*  based on highly limited data, right? How we, you know, we don't just look at the world in terms of
*  pixels and then build something up in a systematic way. We come with kind of templates of some sort.
*  Maybe I should let you say these in your own words because you know what you're talking about,
*  but explain a little bit about how that works. That's actually the line of work that I've been
*  mainly following for the last few years as well. And to some extent, it's gone along
*  relatively independently of our work on emergence. And so one of the interesting prospects is how
*  these things will interact, just as you were raising with your question. And I don't know yet
*  is the answer to that question, but they make the idea of how the brain forms its perceptions
*  based on sparse sensory data. For me, that's grounded in a different way of thinking about
*  what brains do, which is in terms of brains being prediction machines of one sort or another. This
*  is again, an extremely old idea that goes back in philosophy. You can trace it back to Plato, to
*  Kant, to wherever you want to stop on the way that we don't perceive. We don't have direct access to
*  reality as it is. Everything we see is some sort of interpretation of something that is ultimately
*  unknowable. And in psychology, there's this tradition going back to people like the German
*  Pauline and Hermann von Helmholtz, thinking about the brain as an inference engine and perception
*  as the result of a process of unconscious inference. And the idea here is really quite
*  straightforward. It's that sensory signals that bombard our sensory surfaces, the light waves that
*  hit our retinas, the pressure waves that hit our hair cells and our ears, they don't come with labels
*  on saying what they're from. They don't come with labels saying which part of the body they're
*  hitting. They just trigger electrical signals which flow into the brain. And in the brain,
*  it's dark, it's quiet, there's no sound, there's no light. The brain has to make sense of these noisy
*  and ambiguous sensory signals. And the idea about how it does this is that it's doing some kind of
*  Bayesian inference on the causes of these sensory signals. The brain is always trying to figure out
*  what are the most likely causes of the continual barrage of sensory signals that it swims in.
*  And the content of our perceptual experience at any one time is the brain's best guess. It's the
*  result of this process of inference. It's the posterior. It's combining sensory data with some
*  prior expectation or belief about the way the world is. And these prior beliefs can come from
*  evolution, from development, or from your experience a few minutes ago. All of these
*  prior expectations provide context for interpreting ambiguous sensory signals.
*  And it's the interpretation that that is what we perceive. I think that's the stronger claim
*  that what we perceive is not some readout of sensory signals that we just extract features
*  of increasing complexity as the sensory signals stream into the brain. But the sensory
*  signals are really there just to update and calibrate our top-down perceptual predictions.
*  And it's the collective content of these top-down perceptual predictions that is what we perceive.
*  There's just another slight extension to this, which I think I spoke to say for it the whole
*  thing to make sense, which is it's one thing to say that the brain is doing some Bayesian
*  inference on the causes of sensory signals, that it's somehow doing this inference. How is it doing
*  it? Again, there could be many ways in which brains could accomplish something like this.
*  One of the most popular proposals is that it's engaged in predictive processing, sometimes called
*  prediction error minimization. And this is the idea that the brain always has some kind of
*  best guess about the causes of its sensoria. And that it's continually updating that by using
*  sensory signals as prediction errors. So the stuff that's flowing into the brain from the outside
*  world is really just the error, the difference between what the brain expects and what it gets
*  at every level of processing within the brain. This is kind of counterintuitive. We're used to
*  thinking in terms of perception as reading out the sensory signals. But I've come to think of it now
*  as, no, the sensory signals just calibrate. And what we actually perceive is the stuff going in
*  the other direction, the top-down predictions that are being reined in by the sensory prediction
*  errors from the world. And that process approximates Bayesian inference. If you have a system that's
*  implementing this prediction error minimization, then with some other assumptions, you'll find
*  that it does actually approximate Bayesian inference. So this is the way, or this is at
*  least one proposal about how the so-called Bayesian brain works. So let me dig into that
*  a little bit because on the one hand, I love it, but on the other hand, I don't really understand
*  it. So the idea that we have this, the brain makes a prediction for what it's going to see.
*  And I can see that an MPEG file, an encoded video file on the internet, they saved a lot of
*  storage capacity by figuring out that all you have to update is how the image changes, not
*  including what the image is at every moment. So the brain is doing something like that. But
*  clearly, there are moments when I look at something completely new, when a movie starts,
*  and I see something, and there has to be that first flash of recognition. Does the brain
*  shuffle through a bunch of possibilities, or do we even know what's happening in those moments?
*  Maybe. Yes, there's some interesting challenges. So there's challenges about how can you see
*  something new for the first time if you live in a world of the already expected. But I think there
*  are ways to address these challenges. And the first way is that perception in this view is
*  something that's very deeply hierarchical, that are high level perceptions about what's going on.
*  I see a movie star or I see whatever happened, a ship out in the sea on the beach here.
*  Those high level perceptual contents are built up out of much lower level things. Classic
*  vision science tells us that, that part of our visual system deal with detecting variations in
*  brightness and then a bit deeper in lines and then line segments and shapes and all the way up to
*  faces and people and objects and places. And so even if you see something that you haven't seen
*  before, like maybe a movie star that you weren't expecting to see, it's still going to share a lot
*  of the same lower level features with other things that your perceptual system is very used to making
*  best guesses about. And so you still do live in a world of the mostly already expected, and it's
*  only at the last bit that you have to make a little leap and see something new. And sometimes
*  that might be even accompanied by this psychological recognition that I'm seeing something new, some
*  sort of surprise thing too. So I think it does work and the brain also learns. So one of the other
*  components of this way of thinking is that the brain encodes something that we'd want to call
*  a generative model. So it encodes a model of the causes of sensory signals. This is what supplies
*  the predictions that then get compared against prediction errors. So in a sense, everything that
*  we perceive is constrained or everything that we can perceive is constrained by the generative
*  models that are encoded in our brains. But these generative models can change and develop over time.
*  And we can therefore learn to perceive new things through experience. And I think we're all familiar
*  with this in some ways. When you start drinking red wine, they all taste the same. But then after a
*  while, you learn to make discriminations and you have perceptually different experiences.
*  Your generative model has developed to be able to make distinct predictions for distinct kinds of
*  sensory signals, whereas previously, it wasn't. It reminds me of stuff I read a while ago when I was
*  thinking when I was writing my first trade book about the arrow of time, about how memory works
*  in the brain versus imagination and prediction working in the brain. And fMRI studies saying that
*  they used very, very similar parts of the brain, maybe the same parts of the brain in some sense,
*  which led to a hypothesis, which I'm not sure if it's continued to be popular or not, that
*  what we stored in our memories was not a videotape of sets of images that we saw,
*  but more like a screenplay. And there's a little puppet theater in the brain that we could sort of
*  feed in the script and it would put on a show every time we wanted to remember something. So
*  we had some shapes, some sounds, some pre-existing concepts we could put into
*  play and then the data we needed to bring those to life was much more compressed than if we literally
*  just had a whole bunch of images. Yeah, I think there's something right about that. There's
*  certainly something very wrong about the idea of memory being a videotape or in general being some
*  sort of newly implemented file storage system. That I think is an example of taking the computer
*  metaphor of the brain too far. Computers are useful metaphors up to a point, but I think
*  overextended they can be radically misleading. Memory definitely doesn't work like that in the
*  brain. And there's so many empirical examples of that, not least that we tend to have pretty bad
*  memories. And the more often you remember something, the less accurate that memory becomes.
*  Every act of remembering is a sort of active regeneration. As you put it, it's people in the
*  screenplay reenacting the scene or something like that. So that every time you do it, you change it
*  a bit. This has been a notorious problem in things like eyewitness testimony that people's memories
*  become progressively less reliable. But often they develop the conviction that their memory is
*  becoming more reliable when in fact the opposite is going on. But I think there's a lot of overlap
*  between these ideas of perception, imagination, memory, dreaming even, all these categories that
*  might seem to be separate, leverage and utilize and refine a highly overlapping set of underlying
*  mechanisms. So there's one idea that I really love in this area. It's been around for a while,
*  but it was very beautifully articulated recently by Eric Howell, which is this idea of dreams
*  as refining degenerative models in the brain. If you can imagine walking around during your
*  everyday life, you're perceiving lots of things, your brain is trying to fit all this sensory data
*  that's coming in. But as with any statistical model, you can overfit. If you try and fit too
*  many data points, you won't be able to generalize very well to new things. This is just very basic
*  stuff in statistics, right? That you just fit all the data points, then you have a new situation
*  and you find out you've not captured the invariances that really matter. And so you want to
*  guard against overfitting. And so one idea that Eric talks about is that dreaming is a way of the
*  brain pushing back against this daily overfitting during perception. It's sort of freewheeling its
*  generative model, pruning all the unnecessary connections, getting back down to the basics so
*  that you can see better the next day. It's still an idea, it's very little evidence for it, but to
*  me it's a lovely way of thinking about what dreams are, they're not just replays of what happened in
*  the day. It's also not true that they're fundamentally meaningless either. They may play
*  an interesting semi-computational role in tuning our perceptual systems. Well, there's at least
*  a very cheap and obvious connection between this discussion and the emergence discussion based
*  simply on the fact that coarse graining is really, really important, right? Data compressibility
*  is really, really important. And I think that from a physicist's point of view, normally I like to
*  play the role of the physicist adding insight here, but I think that physicists are caught a little
*  bit in this dream of being Laplace's demon, right? Like if we had perfect information, what would we
*  be able to predict about the future, et cetera? Whereas almost all of our experience and understanding
*  of reality comes on the basis of very, very tiny amounts of data compared to the whole thing
*  that is out there. And in both this idea that the brain is an inference engine and predictive
*  processing and so forth, and the idea of emergence and higher level descriptions, we're
*  thinking or discovering ways to say sensible, useful things about the world by saying a very,
*  very tiny fraction of everything there is to be said.
*  Yeah, I think that's right. I think there is a connection there. Quite how much use you can make
*  of that connection is something I don't have a good intuition about. But certainly this idea of
*  coarse graining runs both through predictive processing, where you indeed you extract
*  relatively abstract high level models of the causes of sensory data, which allow you to generalize,
*  and the general case of weak emergence that we were talking about. That's true. What we do with
*  it, I don't know. What we do with it. Yeah, well, we need to leave open problems for the listeners
*  to solve. This is part of our job here on the podcast. But okay, sort of winding up, I do want
*  to just let you, I'm not even sure if I have a specific question here, but there's another
*  really big idea that you emphasize in the new book that you have out and elsewhere, that is very
*  relevant to consciousness, which is the role of the body, as well as the brain in this whole thing.
*  And it's something I've alluded to on other episodes of the podcast, but I'd like to hear
*  your take on it. The idea, you know, again, if physicists sometimes fall into this dream of being
*  Laplace's demon, then other people who are more computer-y in orientation fall into the idea
*  of the brain as an information processing machine. And it could be on a computer, on a hard drive,
*  just as well as it could be in the human brain. But there is something in de facto about the fact
*  that our brains are embedded in bodies, and we keep getting this input both internally and externally,
*  that really plays a role in what we call consciousness. Yeah.
*  Yes, the question is what role and how fundamental that is. And there's a lot of things
*  to talk about here. And possibly the most important one, or certainly the one that comes up
*  very frequently, is this idea of substrate independence. So there's a very common
*  assumption or position in thinking about consciousness that it doesn't matter that the
*  brain happens to be made out of neurons that happen to be made out of carbon-based stuff and
*  so on. That if you wired a computer up in the right way, programmed it in the right way, that
*  it would be conscious too. This argument I find myself just very agnostic about. I just don't
*  think there are good knockdown reasons to believe either that consciousness is substrate independent
*  or that it isn't. If you take one position and say that consciousness is a thing that only
*  particular kinds of substrates, physical systems can have, things made out of neurons, let's say,
*  or carbon, then of course you've got to give an explanation of why that is. And I don't have an
*  explanation of why that, or a good explanation of why that must be. There are some intuitions
*  why I think it's not a silly idea, but there's certainly no knockdown argument. But the same
*  applies the other way around too. If it is substrate independent, then I want to know what's a good
*  positive reason for believing that, because not everything is substrate independent. The usual
*  example is if I simulate a weather system on a computer, it's a simulation. It doesn't get wet
*  and windy inside the computer. Brain is not substrate independent. And so what's consciousness
*  like? Is it more like something like playing Go, which is substrate independent? I can get a
*  computer to do that. It's actually playing Go, as we've seen recently with DeepMind. Or is it
*  something more like the weather, which is not. All conscious systems we know of so far are housed in
*  brains made of neurons that are embedded within bodies, that are embodied in environments, and so
*  on. So it's a good default starting point to at least wonder whether consciousness is something
*  that requires a biological system. Or to put it more weakly, in order to understand consciousness,
*  we have to understand its substrate a bit more deeply. And I think this is useful because doing
*  so pushes back against another unfortunate tendency of taking the computer metaphor a bit too far,
*  which is the sharp distinction between hardware and software. That the software is the mind and
*  the hardware is the brain. There's no such sharp distinction in real biological systems. Yes,
*  there are activity patterns and yes, the neurons are wired up in particular ways. But there's
*  chemicals washing about every time neurons fire. The structure changes a bit as well.
*  And then how far do you go down? Even single neurons have very, very complicated activity
*  patterns relating their inputs to their outputs. So there's no clean separation of hardware from
*  software or wetware from mindware. And if there's no clean separation, then at what point do you even
*  make the claim that something is substrate independent? Where does the substrate start?
*  So that's one reason I feel uneasy with this idea of consciousness being substrate independence.
*  And that brings us to the question of what else does thinking about
*  the biological instantiation of consciousness bring to the table? And I actually think it brings
*  an awful lot. We talked about this idea of the brain being a prediction machine,
*  inferring the causes of sensory signals. We tend to think of brains as in the business of perceiving
*  the outside world and acting on the outside world. And the body at most is maybe something that
*  enables this and takes the brain from meeting to meeting. But it's otherwise unimportant,
*  just has to be kept going. But the purpose of having a brain in the first place is to keep the
*  body alive. That's the fundamental evolutionary duty of a brain is to keep the body alive.
*  And the brain is in the business of sensing and perceiving its internal state as well.
*  And from the perspective of the brain, the internal state of the body
*  is also inaccessible and remote and has to be inferred. It gets sensory data about,
*  let's say, the heart rate and blood pressure levels and all this stuff.
*  But they're still comprised of electrical signals. It has to make inferences about the state of the
*  body. But the inferences in this case are much more geared towards controlling the system rather
*  than figuring out what things are or where they are. My brain doesn't care where in the body my
*  liver is, but it does care that it's doing the job that it should do. So when I perceive the
*  internal state of my body, I don't perceive my internal organs as having shapes or colors or
*  locations. But I certainly do perceive how well my body is doing at staying alive, whether I'm
*  hungry or thirsty or in pain or suffering. The character of the perceptual experience is really
*  determined by the role the predictions are playing, but it's still predictions.
*  So I think we can understand a great deal about the nature, the contents of our conscious
*  experiences of the self, these emotions and moods and the simple experience of just being a living
*  organism that I think grounds all of our experiences. The larger claim would be that everything
*  that we experience, even our experiences of the outside world, ultimately grounded in the predictive
*  mechanisms that evolved and developed and operate from moment to moment in service of regulating our
*  bodily physiology. That's a very deep connection between consciousness and life that is not the
*  same as saying that you have to be alive to be conscious or that everything that is alive is
*  conscious. But it's saying that that's the way to understand how our conscious experiences are
*  formed and shaped. So since we're past the hour, Mark, on the podcast, we can be a little bit more
*  speculative and not be as beholden to rigor as we were in the beginning parts. So let me just,
*  you said, I think, two things that I want to have different levels of signing on to.
*  The part about how, in fact, our consciousness is enormously influenced by the fact that we live in
*  a body and the body lives in a world and we're getting inputs from inside and outside. I'm 100%
*  on that. And I think that, in fact, I once proposed this as a solution to the Fermi paradox. Why aren't
*  there any aliens? Because we all, because the idea would be that if you get sufficiently
*  technologically advanced, everyone uploads their brains into the computer. And then when they are
*  removed from the demands of living in an environment, right, of eating and sleeping and all those things,
*  we decide that, you know, there's just no point in living anymore. We don't do anything. We don't
*  ever leave the planet. It's become sort of a meaningless nirvana and we don't explore the
*  galaxy. But this begs the question of whether or not uploading is a thing that could happen. And,
*  you know, you raise this other issue of the substrate independence, which I'm less on board
*  with a little bit. There are people we had Nick Bostrom on the podcast who thinks we could be in
*  a simulation. Maybe rain is substrate independent. If you simulate rain accurately enough, it's just
*  as good. David Chalmers, of all people, makes the argument that things that happen in a
*  simulation are just as real as things that happened in the real world. So do you see
*  a distinction between those two parts of the argument or do they sort of group together in your mind?
*  I'm a bit suspicious of this simulation argument of Nick Bostrom. So for me, the logic runs a bit
*  the other way around that the possibility of us living within a simulation requires substrate
*  independence to be true. That's one of the assumptions that in Nick's presentations of
*  the argument, he does sort of skate over a bit and say, well, this is a relatively common
*  assumption and that's fine. And we just have to worry about the other things about the likelihood
*  of civilization getting to the stage where we have all these descendants who are for some reason
*  interested in building ancestor simulations and so on. But before even getting there, I just
*  don't think it's a safe assumption that substrate independence is true. If it were to be true,
*  then indeed it might be harder to really know whether we are in some sort of face reality or
*  in some simulation. But I think in terms of assigning prior credencies to these sorts of
*  things, I think it's much more likely that substrate, actually this could be construed
*  as a good argument for why consciousness must be substrate dependent. Because if consciousness is
*  substrate independent, then maybe the simulation argument holds up and we're living in a simulation
*  and I don't want to reach that conclusion. Therefore, consciousness must be substrate
*  dependent. Not a very good argument, but I'll put it out there. Maybe some people will like it.
*  Yeah. Well, I always encourage the listeners to be good Bayesians one way or the other. And I
*  think you've lived up to that goal, just bringing up our prior credences right there. So setting a
*  good example for everyone out there thinking about emergence and consciousness. Anil Seth,
*  thanks so much for being on the Mindscape Podcast.
*  Thank you, Sean. It's a real pleasure and a privilege. Thank you.
