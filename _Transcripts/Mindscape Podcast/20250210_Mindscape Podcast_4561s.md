---
Date Generated: February 13, 2025
Transcription Model: whisper medium 20231117
Length: 4561s
Video Keywords: []
Video Views: 5074
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2025/02/10/304-james-evans-on-innovation-consolidation-and-the-science-of-science/

It is a feature of many human activities - sports, cooking, music, interpersonal relations - that being able to do them well doesn't necessarily mean you can accurately describe how to do them well. Science is no different. Many successful scientists are not very good at explaining what goes into successful scientific practice. To understand that, it's necessary to study science in a scientific fashion. What kinds of scientists, in what kinds of collaborations, using what kinds of techniques, do well? I talk with James Evans, an expert on collective intelligence and the construction of knowledge, about how science really works.

James Evans received his Ph.D. in Sociology from Stanford University. He is currently the Max Palevsky Professor of History and Civilizations, Director of Knowledge Lab, and Faculty Director of Computational Social Science at the University of Chicago; External Professor at the Santa Fe Institute; External Faculty at the Complexity Science Hub, Vienna; and Visiting Faculty Researcher at Google.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll

#podcast #ideas #science #philosophy #culture
---

# Mindscape 304 | James Evans on Innovation, Consolidation, and the Science of Science
**Mindscape Podcast:** [February 10, 2025](https://www.youtube.com/watch?v=Az5I4IAS4CI)
*  Hello everyone, welcome to the Mindscape podcast. I'm your host Sean Carroll. [[00:00:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=0.0s)]
*  Something I've figured out after doing science for quite a long time is that [[00:00:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3.44s)]
*  science is hard. It is hard to do it, it is hard to do it well. That's probably not [[00:00:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=9.120000000000001s)]
*  really news, that's not probably something that is very controversial out [[00:00:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=14.24s)]
*  there, but I wonder if people appreciate the ways in which it is hard. I mean of [[00:00:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=17.580000000000002s)]
*  course the actual doing of the science can be hard, right? Doing a great [[00:00:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=21.92s)]
*  experiment, doing a difficult calculation if you're a theorist or [[00:00:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=26.52s)]
*  something like that, but there are all these pre-existing difficulties that [[00:00:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=31.0s)]
*  come long before when you get to that. Mostly like what problem do you choose [[00:00:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=35.96s)]
*  to work on? What is a promising area of research, right? Resources are finite. The [[00:00:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=41.24s)]
*  time that you have as a scientist is finite, the money that you have, the [[00:00:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=48.72s)]
*  You're trying to not only make a big discovery but also ensure that there are [[00:00:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=53.48s)]
*  future discoveries to be made, which is the nice way of saying you got to get a [[00:01:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=60.12s)]
*  job. You have to impress the people who might be hiring you or promoting you or [[00:01:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=64.24s)]
*  whatever enough that you will be supported in your aspiration to keep [[00:01:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=69.72s)]
*  doing science. You want to be new and innovative but you don't want to be so [[00:01:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=74.4s)]
*  crazy and out there that people don't pay attention to you. And even once you've [[00:01:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=78.72s)]
*  chosen what to work on, how exactly do you work on it? Do you sit by yourself [[00:01:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=82.76s)]
*  trying to think very very hard? You know there's people like Paul Dirac who very [[00:01:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=87.96s)]
*  famously thought that all of the good papers ever written in science, all the [[00:01:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=93.24s)]
*  good science ever done, was done by a single individual all by themselves. But [[00:01:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=97.0s)]
*  the world is very different than in Dirac's time right now. There are big [[00:01:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=102.12s)]
*  collaborations experimentally of course but even within theorists who are very [[00:01:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=105.60000000000001s)]
*  nimble and can change what they're doing from month to month, it's so easy to [[00:01:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=110.52s)]
*  communicate with people over the internet or in person. You can start up [[00:01:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=114.76s)]
*  collaborations with people who don't know the same things you know and might [[00:01:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=118.4s)]
*  be helpful to you. So who is your set of collaborators and co-authors and [[00:02:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=122.04s)]
*  helpers? These are all great questions and they're next to but but separate from [[00:02:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=127.44s)]
*  questions about is science really making the progress that it could be making? Is [[00:02:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=133.84s)]
*  it is it moving fast enough? Is it daring enough and bold enough or is it stodgy [[00:02:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=138.24s)]
*  and the set in its ways? Are we leaving food on the table as it were? So of [[00:02:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=143.52s)]
*  course lots of people have opinions about these things. These are issues that [[00:02:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=150.04000000000002s)]
*  many people have talked about for many years. The difference now is we can [[00:02:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=152.76000000000002s)]
*  really collect data in a more or less objective at least wide-ranging way [[00:02:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=156.56s)]
*  rather than just sort of looking at this or that key feature in the history of [[00:02:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=162.96s)]
*  science or key episode. We can actually look at many many scientific [[00:02:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=167.48000000000002s)]
*  investigations. Many people many researchers writing papers who are they [[00:02:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=172.08s)]
*  collaborating with? Are they making advances because they're collaborating [[00:02:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=176.84s)]
*  with the same people or with a different set of people every time with people in [[00:03:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=180.72s)]
*  their field outside the field? Do old people make the advances because they're [[00:03:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=184.36s)]
*  very wise or do young people make them because they're not restricted by the [[00:03:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=188.52s)]
*  conventional wisdom? These are all great questions but don't try to answer them [[00:03:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=192.32s)]
*  just by thinking and by using your intuition. Look at the data. That's what [[00:03:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=195.92s)]
*  today's guest likes to do. James Evans is technically a sociologist at least you [[00:03:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=200.32s)]
*  know he's in the sociology department at the University of Chicago but he does [[00:03:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=205.51999999999998s)]
*  wide-ranging research on computer science topics and all sorts of [[00:03:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=209.06s)]
*  sociological topics but in particular the science of science. Understanding how [[00:03:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=215.2s)]
*  scientific progress gets made and thinking of it as an example of [[00:03:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=219.84s)]
*  collective intelligence. Science is not just one person. There's lots of [[00:03:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=225.48s)]
*  scientists doing things so how do these scientists come together in groups? Where [[00:03:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=229.24s)]
*  do the groups come from? How big are the groups? What kind of groups make the best [[00:03:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=234.52s)]
*  decisions moving forward and so forth? I think that my prediction is that if [[00:03:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=238.44s)]
*  you're someone who's thought about these things for a little while what James has [[00:04:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=243.36s)]
*  to say will in some ways reinforce things you already thought and in other [[00:04:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=247.16s)]
*  ways surprise you a little bit. These are tricky questions that that's why data is [[00:04:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=252.76s)]
*  important. That's why doing the science of science is important in addition to [[00:04:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=257.71999999999997s)]
*  doing the history of science, the philosophy of science, the sociology of [[00:04:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=261.56s)]
*  science, the psychology of science, etc. All of these are important. These days we [[00:04:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=265.04s)]
*  do the science of science at an unprecedented level and we're learning [[00:04:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=269.15999999999997s)]
*  new things both about how science works, how it can work, how changes like AI are [[00:04:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=273.76s)]
*  going to help it and hurt it and things like that so the world is changing we [[00:04:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=278.52s)]
*  got to keep up with it let's go. [[00:04:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=282.36s)]
*  James Evans welcome to the Mindscape podcast. Thank you I'm delighted to be [[00:04:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=285.84s)]
*  here Sean. You know I have to start by saying a couple of months ago we had [[00:05:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=304.55999999999995s)]
*  Blaise Aguirre-Iarcas on the podcast talking about the spontaneous emergence [[00:05:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=308.44s)]
*  of computational life and it took me a while to ping on the fact that you are a [[00:05:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=315.0s)]
*  co-author on that paper even though there's no sociology involved in that [[00:05:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=319.16s)]
*  paper so how did that happen? I'm kind of a computational scientist that's the way [[00:05:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=323.16s)]
*  I think of myself or even really a meta scientist I mean that's I study how [[00:05:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=328.44s)]
*  science works as systems and a lot of that comes through an evolutionary lens [[00:05:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=333.04s)]
*  and so I've been involved in following a life for a while. I'm actually I work [[00:05:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=338.28s)]
*  with Blaise on his team his paradigms of intelligence team at Google and there [[00:05:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=344.40000000000003s)]
*  are kind of three levels there where we're looking at kind of the ways in [[00:05:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=349.84000000000003s)]
*  which you know biological kind of forms processes and organisms shape the way in [[00:05:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=353.68s)]
*  which we think about AI and one part is evolution one part is kind of [[00:06:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=361.36s)]
*  neuroscience and cognition and then the third part is collective intelligence [[00:06:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=365.68s)]
*  and so I spend even more time you know kind of helping to cultivate and [[00:06:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=369.6s)]
*  catalyze work in this space of using principles of collective intelligence [[00:06:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=374.36s)]
*  and diversity underlying collective cognitive populations to think about [[00:06:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=378.44s)]
*  building AI in that space. Well I think this is it's a good place to start [[00:06:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=383.84000000000003s)]
*  because it's like a personal spin on the more big picture substantive questions [[00:06:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=388.64000000000004s)]
*  we'll be getting to later but you know someone like you who researches topics [[00:06:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=393.24s)]
*  like this sometimes it can be hard to find a department to hire you right like [[00:06:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=398.84000000000003s)]
*  so what do you do really right you must have gotten that question before. Right [[00:06:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=404.96000000000004s)]
*  right yeah it's true that right now I'm in so I think part of it has been that [[00:06:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=409.24s)]
*  I've been involved in creating a fair you know number of departments so I [[00:06:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=415.04s)]
*  began my home in sociology and I think some of my colleagues think some of my [[00:06:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=419.40000000000003s)]
*  work looks like sociology especially the work where I'm kind of looking about how [[00:07:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=424.24s)]
*  it is that scientists and people in the world organize around information but a [[00:07:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=428.36s)]
*  lot of it doesn't look like that I'm studying the complex systems underlying [[00:07:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=433.12s)]
*  you know deep neural networks I'm I'm understanding you know so I think that [[00:07:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=436.36s)]
*  so I've I've spent a lot of time I built a computational social science program [[00:07:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=440.32s)]
*  that's that's been increasing where we we built a data science Institute and now [[00:07:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=444.96000000000004s)]
*  kind of department at the University of Chicago we're in the process of trying [[00:07:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=451.0s)]
*  to create a new college or division about artificial intelligence here so I [[00:07:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=455.56s)]
*  think that you know not having like a fixed home also creates an instability [[00:07:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=460.84s)]
*  that allows me to create new things which is fun but the but yeah I mean I [[00:07:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=467.24s)]
*  completely agree I'm exactly in a very similar position myself but the need to [[00:07:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=472.44s)]
*  get there is tricky and I mean maybe one thing we'll talk about along the way is [[00:07:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=476.8s)]
*  how do we sort of get make on ramps for young people who want to do that like it [[00:08:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=481.56s)]
*  seems when people ask me for advice my advice is always like be pretty [[00:08:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=487.6s)]
*  conventional early on in your career because there's a lot of gatekeeping a [[00:08:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=492.4s)]
*  lot of bottlenecks you have to jump through it's hard to be too quirky as [[00:08:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=496.36s)]
*  too young and unproven person yeah I think I mean I would say the one caveat [[00:08:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=500.76s)]
*  is I would say you have to be able to present conventional early on yeah which [[00:08:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=505.84s)]
*  is to say I think if you just do conventional early on you will likely do [[00:08:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=512.24s)]
*  conventional forever but if you have a portfolio that you're cultivating enough [[00:08:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=515.8399999999999s)]
*  of which you can purpose to to present conventional leadership then then that's [[00:08:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=521.92s)]
*  you know and I yeah I and I had to do that in the context of sociology even [[00:08:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=529.4399999999999s)]
*  though I would consider myself kind of a more multidisciplinary post disciplinary [[00:08:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=533.92s)]
*  scientist yeah no that's a very good amendment so when we are thinking about [[00:08:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=538.7199999999999s)]
*  science and how it works this is one of the things that you do just to just to [[00:09:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=542.56s)]
*  get a feeling obviously this is something that people have talked about [[00:09:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=547.5999999999999s)]
*  for many many years a lot of it has been in the context of like history or [[00:09:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=550.16s)]
*  philosophy of science are we doing it today in a more data driven way yeah I [[00:09:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=553.7199999999999s)]
*  mean we have and I think what's interesting both in science in general [[00:09:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=561.2s)]
*  and I would say you know in artificial intelligence models is their performance [[00:09:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=567.04s)]
*  their predictive possibility the ability to create generative digital doubles is [[00:09:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=572.52s)]
*  all driven by massive data and so I think that's a phase transition it's not [[00:09:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=578.88s)]
*  just like oh you know we didn't have data and we had some science and we [[00:09:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=583.0s)]
*  improved a little bit by increasing some data I mean it's just the difference [[00:09:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=586.6800000000001s)]
*  between systems that work that predict and those that do not you know and so so [[00:09:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=589.96s)]
*  yeah I think we're doing it with large-scale data and because because [[00:09:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=596.0400000000001s)]
*  scientists are incentivized to leave droppings which is to say we are our [[00:10:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=601.32s)]
*  capital is our credit you know in the system then then we leave more droppings [[00:10:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=607.0400000000001s)]
*  than people in business you know in an other context where people are covering [[00:10:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=612.72s)]
*  their tracks you know it's really hard to tell stories about how action in [[00:10:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=617.16s)]
*  those places micro action personal action decisions but in science because [[00:10:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=621.38s)]
*  we have to broadcast every step to the world because we're certified and and [[00:10:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=626.0s)]
*  that's how we get promoted and it provides a rich landscape for thinking [[00:10:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=630.8399999999999s)]
*  about collective knowledge and individual contributions that is a [[00:10:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=636.04s)]
*  great point you know my wife is a journalist a science writer and and one [[00:10:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=639.3199999999999s)]
*  thing you notice there is that scientists when they you know get give [[00:10:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=643.02s)]
*  you an interview or whatever they really care about getting credit in the news [[00:10:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=647.5s)]
*  article that's being written and not only for themselves but like no you must [[00:10:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=653.54s)]
*  list all eight authors of our paper in your in your 1,000 word article and the [[00:10:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=657.14s)]
*  journalists are like that's just not how we roll but it's very very important for [[00:11:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=661.74s)]
*  academics more broadly right right and this is our this is this is the coin of [[00:11:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=665.8199999999999s)]
*  the realm you know is you contributed to this paper and we can we can basically [[00:11:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=671.18s)]
*  say all the papers that cited your paper got to get back propagated to your you [[00:11:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=675.7399999999999s)]
*  know enlarging avatar of influence so so as a scientist I mean let's try to help [[00:11:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=680.9799999999999s)]
*  the audience most of whom are not professional scientists right one of the [[00:11:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=690.4599999999999s)]
*  things you got to do forget about getting jobs or whatever you have to [[00:11:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=694.8199999999999s)]
*  decide what research to do right how to pick a research problem and and and this [[00:11:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=697.94s)]
*  is hard both because you know ideas are scarce and things like that but also [[00:11:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=704.58s)]
*  there's a style question am I gonna work on something quirky and innovative or [[00:11:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=708.3800000000001s)]
*  am I gonna fit in to kind of a bandwagon is that something that we can study [[00:11:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=713.62s)]
*  quantitatively sociologically yeah yeah I've been studying this question or [[00:11:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=718.3000000000001s)]
*  variance of this question for 20 years for two reasons one we want to just [[00:12:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=723.98s)]
*  understand how it is that that science happens how people make decisions and you [[00:12:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=728.98s)]
*  know this is a valued quantity of life on the other hand you know economic [[00:12:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=733.3000000000001s)]
*  growth happens through scientific advance you know I mean this is this is I [[00:12:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=739.22s)]
*  mean credit you know like it financial credit is given because we assume that [[00:12:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=743.54s)]
*  some magic will happen when we give this money to a corporation that they will [[00:12:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=748.38s)]
*  reorganize things in a new way and new values will be generated like credit in [[00:12:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=752.42s)]
*  the ye old days was extractive you know I'm gonna give you money and I'm gonna [[00:12:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=757.8199999999999s)]
*  take more money from you and so it's just so I think as a result then it [[00:12:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=761.9s)]
*  becomes really important for nations which are typically the units that [[00:12:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=768.78s)]
*  bankroll science like countries bankroll science there is international science [[00:12:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=774.66s)]
*  people experience it but where do they get their funds they get their funds [[00:12:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=779.7s)]
*  from their country most countries all universities are are effectively public [[00:13:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=783.5s)]
*  in the US even though we have quote-unquote private public universities [[00:13:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=790.3000000000001s)]
*  almost all science research funding is is well increasingly it's from private [[00:13:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=793.7s)]
*  organizations private and public but but certainly a vast you know [[00:13:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=798.86s)]
*  contribution and the most focal element is from from public contribution so I [[00:13:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=804.86s)]
*  think part of this is like how do we think about if like the country as a [[00:13:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=809.26s)]
*  whole is relying on its competitive power its ability to kind of generate [[00:13:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=813.7s)]
*  new markets and services and new you know values for life then they need [[00:13:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=820.1s)]
*  collectively to organize people to start exploring different kinds of things or [[00:13:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=825.94s)]
*  they're just gonna they're not gonna get any return in their investment and so [[00:13:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=831.82s)]
*  yeah so I think it's it's a big question even though you know it's a micro [[00:13:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=836.22s)]
*  question but it has you know really collective implications for for [[00:14:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=842.38s)]
*  countries and so it's kind of an existential question for for for [[00:14:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=847.74s)]
*  countries so so yeah so one of the ways in which we've studied it is is looking [[00:14:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=851.62s)]
*  precisely at you know what it is that people are engaged with relative to the [[00:14:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=857.26s)]
*  distribution of prior work and this is where big data matters right because [[00:14:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=862.18s)]
*  because think about it you know like if you were to kind of take if you want the [[00:14:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=866.6999999999999s)]
*  the modal story the average story you don't need much data you know you can [[00:14:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=871.9399999999999s)]
*  take a very small sample of a few scientists if you want to tell a story [[00:14:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=876.8199999999999s)]
*  about change between one period and another you need at least twice as much [[00:14:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=881.8599999999999s)]
*  data right you know the difference between one period in the next to tell [[00:14:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=886.5s)]
*  a story about innovation requires exponentially more data because you have [[00:14:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=891.82s)]
*  to understand everything that was expected to understand the significance [[00:14:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=897.3000000000001s)]
*  of something that was not expected you need to understand in theory everything [[00:15:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=901.46s)]
*  that was expected by any scientist in the space to understand really what's [[00:15:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=905.1s)]
*  new relative to that space so this is so I would say innovation is something that [[00:15:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=910.7s)]
*  you can only study with large-scale data doesn't even make sense to study without [[00:15:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=915.0600000000001s)]
*  it you need the full distribution of expectations that normal scientists [[00:15:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=920.18s)]
*  would have so that we can understand when and why they're surprised and how [[00:15:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=924.18s)]
*  their world of technological and scientific possibilities updates and so [[00:15:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=928.74s)]
*  so we've been studying this initially we looked at this in the perspective of [[00:15:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=934.14s)]
*  networks where individual concepts or technological components you know a [[00:15:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=937.74s)]
*  method or a gene you know or you know even a theoretical concept or kind of [[00:15:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=942.98s)]
*  nodes in a complex network and we would look at how those networks evolved over [[00:15:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=950.4200000000001s)]
*  time the difference between bridging different parts of the network the [[00:15:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=955.1s)]
*  likelihood of bringing a new node into the network but increasingly with the [[00:15:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=959.0600000000001s)]
*  emergence of artificial intelligence natural language processing and now [[00:16:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=964.66s)]
*  large-language models inside those large-language models is a very thick [[00:16:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=969.66s)]
*  deep representation of meanings so for example and in you know the new chat GPT [[00:16:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=976.26s)]
*  models you know there are trillions of parameters and those all those [[00:16:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=983.02s)]
*  parameters are numbers inside of a graph that represent a complex [[00:16:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=988.1s)]
*  representation of all the meanings associated with with our language that [[00:16:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=994.3s)]
*  these language models have they're kind of the love child between on the one [[00:16:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1000.8599999999999s)]
*  hand what I'll call the autoregressive language model where we predict the next [[00:16:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1006.26s)]
*  word for prior words and these and these basically kind of meaning pixels which [[00:16:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1009.74s)]
*  is to say rather than selecting on words predicting the next word we're really [[00:16:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1016.8199999999999s)]
*  predicting the next meaning right and it turns out that the moment they started [[00:17:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1020.9s)]
*  doing that all of a sudden these let these models became much more stable [[00:17:06](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1026.62s)]
*  because it's not about the particular fragile word that you're using it's that [[00:17:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1030.3s)]
*  I'm selecting this meaning followed by that meaning followed by this meaning [[00:17:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1033.78s)]
*  followed by this kind of word function followed by and all of a sudden these [[00:17:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1037.98s)]
*  models worked and of course you know we added many parameters so they could [[00:17:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1042.3799999999999s)]
*  self-learn in important features so we use those internal representations as a [[00:17:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1046.74s)]
*  map of the cultural world and we can look at the difference between past for [[00:17:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1051.98s)]
*  example research and future research or we can plot every piece of research in [[00:17:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1058.9s)]
*  the past and we can you know plot a new piece of research and say exactly how [[00:17:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1064.38s)]
*  surprising is it relative to that past relative to the past model and in fact [[00:17:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1068.9s)]
*  I just got a 20 million dollar grant from the government to basically build [[00:17:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1075.46s)]
*  what I call chronologically trained language models work we're building [[00:17:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1079.74s)]
*  these models based on the past so that we can evaluate when a new paper or a [[00:18:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1085.74s)]
*  new patent or a new product emerges how surprising or improbable was that idea [[00:18:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1090.78s)]
*  to the to this model which is a machine for probability it's predicting what the [[00:18:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1098.5s)]
*  most probable next patent paper or product description is so and when [[00:18:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1104.26s)]
*  really surprising things happen what's interesting with these models we can say [[00:18:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1110.98s)]
*  not just oh that's surprising everyone knows it's surprising we can say well if [[00:18:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1114.42s)]
*  this improbable thing is actually now probable right if like no one would have [[00:18:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1119.26s)]
*  thought of this this paper but it turns out if you write this paper you do the [[00:18:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1126.22s)]
*  research by in this paper it's true then what are all of the other things that [[00:18:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1130.54s)]
*  were improbable before the become probable now yeah right what are all the [[00:18:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1134.3799999999999s)]
*  adjacencies that were like distant before but now are all of a sudden close [[00:18:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1138.42s)]
*  to one another inside the space which allows things like the government to to [[00:19:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1142.58s)]
*  take fast breaks you know which they don't do historically you know if if one [[00:19:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1149.62s)]
*  thing becomes true it's like oh okay here's ten thousand other hypotheses [[00:19:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1154.7s)]
*  that were impossible were extremely improbable but now are absolutely the [[00:19:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1158.26s)]
*  next thing that you should study and set the space but maybe this sounds like a [[00:19:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1162.74s)]
*  little scary to me I mean if we could predict ahead of time what the next [[00:19:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1167.7s)]
*  innovation would be why would we have to do boring things like experiments and [[00:19:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1173.82s)]
*  stuff oh no no no my whole point actually is is I'm not building I I'm not building [[00:19:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1177.74s)]
*  a model that's going to predict the optimal next paper I'm saying like the [[00:19:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1184.02s)]
*  experiment in this space is that someone did an experiment in its surprised this [[00:19:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1189.62s)]
*  whole cultural world model we had and it allows us to kind of predictively update [[00:19:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1195.74s)]
*  okay what are how does the whole world change as a result of this surprising [[00:20:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1200.94s)]
*  thing that came as a result of experiment good okay yeah you're not [[00:20:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1205.74s)]
*  predicting what the surprise will be you're sort of bringing the changes on [[00:20:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1208.74s)]
*  the surprise to figure out how everything shifts in a response to it [[00:20:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1211.7s)]
*  exactly and one other thing that we can do in these models which I think is is [[00:20:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1215.74s)]
*  exciting is we can do the same kind of thing that scientists have historically [[00:20:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1219.6200000000001s)]
*  done so Charles Sanders purse who was I think really the great 19th century [[00:20:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1224.26s)]
*  American philosopher had this idea of abduction he was unsatisfied with the [[00:20:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1230.78s)]
*  philosophical cartoons of reasoning which were kind of deduction which kind [[00:20:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1236.5s)]
*  of comes out of Aristotle's invention of the syllogism where you kind of build [[00:20:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1242.62s)]
*  from established you know axioms or assumptions or facts and you kind of say [[00:20:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1247.1s)]
*  well if these are true then what necessarily must be true what other [[00:20:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1252.42s)]
*  things must be true that was kind of old-style science and then and then sir [[00:20:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1255.78s)]
*  Francis Bacon wrote this book called Novum Organum the New World and it had a [[00:21:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1260.46s)]
*  picture on the front of a big ship going to America and like all this new stuff [[00:21:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1265.54s)]
*  you know like and and it was like okay no we need to scrap that we need to do [[00:21:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1270.74s)]
*  induction we need to basically like learn all the new things in the world [[00:21:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1277.22s)]
*  and then generalize you know from those it's not going to create something [[00:21:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1281.34s)]
*  that's provable but it will allow us to grow and learn collectively and that was [[00:21:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1285.1s)]
*  the basis of the scientific revolution and this thing called the experimental [[00:21:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1289.3s)]
*  philosophy which is the core of what you're saying and then Charles Sanders [[00:21:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1294.74s)]
*  purse kind of emerges in the end of the 19th century he was kind of a failed [[00:21:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1298.9s)]
*  academic but but academics were all failed back then you know tenure was [[00:21:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1303.66s)]
*  uncertain he had a funny personality and so he bumped from place to place he was [[00:21:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1307.34s)]
*  at Johns Hopkins for about a year he was that he was a lot of places for about the [[00:21:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1312.98s)]
*  academic position officially yes so so he had this idea that as knowledge grows [[00:21:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1317.66s)]
*  as you learn more about the universe then your best signal for theoretical [[00:22:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1325.5800000000002s)]
*  development and collective knowledge is surprise right which is to say when you [[00:22:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1331.42s)]
*  run an experiment or have an observation that violates your expectations that [[00:22:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1336.14s)]
*  violate your growingly accurate world model and and what's what's I mean [[00:22:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1340.7s)]
*  initially he kind of thought well where do these surprises come from or they [[00:22:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1346.58s)]
*  come from you know he was also lived at the birth of psychology and was a kind [[00:22:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1349.74s)]
*  of a proto psychologist and so he believed that that the real model was [[00:22:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1354.78s)]
*  the subconscious you know that you would basically people would dream and [[00:22:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1359.02s)]
*  associations would be made in their subconscious mind and and he even has a [[00:22:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1362.82s)]
*  series of stories including one about he himself that's very much like Sherlock [[00:22:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1367.6599999999999s)]
*  Holmes where he has engaged in abduction you know someone steals his watch and he [[00:22:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1373.74s)]
*  like figures out where they are through this set of combination of surprises and [[00:22:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1378.54s)]
*  coming to the best explanation one of the things that we've studied recently [[00:23:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1383.26s)]
*  is well how does abduction actually occur you know how do people identify [[00:23:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1387.4599999999998s)]
*  surprises because it turns out that the people who are most likely to identify a [[00:23:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1394.4599999999998s)]
*  surprise are kind of like the priest class of a scientific field like they've [[00:23:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1401.34s)]
*  read the literature they know what everyone expects the large language [[00:23:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1405.8999999999999s)]
*  model of the field and then and then they see a surprise and they realize hey [[00:23:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1409.5s)]
*  this does not fit in but that class of person is the least likely to have the [[00:23:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1414.26s)]
*  intellectual resources to resolve the uncertainty to develop a new pattern and [[00:23:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1420.54s)]
*  so we show in recent work with large-scale data that on average that [[00:23:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1427.18s)]
*  those basically kind of you know abductive discoveries are mergers you [[00:23:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1433.3400000000001s)]
*  know the conversations between insiders and outsiders so increasingly you get [[00:24:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1440.18s)]
*  your resources not through induction where you just kind of generalize from [[00:24:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1445.22s)]
*  your mind about you know from from patterns you have a surprise that occurs [[00:24:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1448.6200000000001s)]
*  in your field and you look you survey a range of other fields for the intellectual [[00:24:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1454.86s)]
*  resources that come from the most disconnected fields from yours you know [[00:24:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1461.3799999999999s)]
*  that could it could be literary studies could be astrophysics it could be [[00:24:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1465.58s)]
*  molecular biology people who were not part of your conversational cultural [[00:24:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1469.18s)]
*  world and who have access to a set of distinct patterns you know through [[00:24:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1473.34s)]
*  theory through data that is accessible to them and that those people are [[00:24:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1478.18s)]
*  systematically kind of like coming in in an expedition to solve your problems [[00:24:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1482.66s)]
*  that's where disruptive advance occurs so so part of this in some ways I'm kind [[00:24:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1487.14s)]
*  of pushing back against the question of like oh it's about people choosing where [[00:24:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1494.1000000000001s)]
*  to go it's it's really it's about this collective conversation that occurs [[00:24:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1497.98s)]
*  between problem makers and problem takers you know inside this market for [[00:25:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1502.66s)]
*  I can definitely think of examples in my own fields where some wonderful [[00:25:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1509.3600000000001s)]
*  brilliant new idea has come along typically from a young person and then [[00:25:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1515.0400000000002s)]
*  some older person who knows everything has sort of fitted into the broader [[00:25:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1518.72s)]
*  context in a way that suddenly everyone gets excited about that's that's that's [[00:25:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1522.0800000000002s)]
*  that's a common pattern another pattern or what I find what I call expeditions [[00:25:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1527.0s)]
*  where you have a whole group of people from an outsider field physicists you [[00:25:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1532.04s)]
*  know coming into molecular biology and they bring a set of tools a set of [[00:25:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1538.48s)]
*  perspectives and and the reason why in those early works you don't see teams [[00:25:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1542.96s)]
*  forming between insiders and outsiders is because teams require a kind of a [[00:25:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1548.0s)]
*  social contract that this thing makes sense these expeditions are like it's [[00:25:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1553.44s)]
*  like blitzkrieg you know it's like someone got a barbarian coming in you [[00:25:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1557.84s)]
*  know with an approach and and they publish it in in this field that's never [[00:26:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1561.6s)]
*  seen anyone like them before and no one from their field has ever seen this [[00:26:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1565.28s)]
*  field but has ever published in this space before and those tend to be on [[00:26:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1569.48s)]
*  average the big hits that the things that that really kind of grow and [[00:26:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1574.08s)]
*  disrupt the knowledge space and really update how people think about problems [[00:26:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1579.52s)]
*  in advance it's a tricky thing I guess because I think that especially from an [[00:26:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1584.96s)]
*  outsider's perspective people are like well why isn't there more innovation why [[00:26:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1589.84s)]
*  isn't there more creativity isn't there some ossification of your field because [[00:26:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1593.9599999999998s)]
*  you're all working on the same stuff and it's just moving ahead incrementally [[00:26:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1599.0s)]
*  isn't it more fun when someone just completely upsets the apple cart and [[00:26:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1602.4399999999998s)]
*  comes in with new ideas and it's not that that's wrong but you I think you [[00:26:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1606.8s)]
*  need both right I mean you need some apple carts being upset but you also [[00:26:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1610.9599999999998s)]
*  need the gradual accumulation of conventional wisdom well exactly if you [[00:26:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1614.72s)]
*  didn't have the gradual I mean you can imagine a version where it's all [[00:27:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1620.12s)]
*  disruption all the time and that is a system with no memory yeah and no [[00:27:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1624.84s)]
*  accumulation right so it's like but it's true that there is an oxymoron in [[00:27:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1629.94s)]
*  creating innovative institutions yeah right because it's like we're but what we [[00:27:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1637.24s)]
*  need what we're trying to we're basically saying hey we're gonna try to surf the [[00:27:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1643.08s)]
*  boundary between order and chaos and and so it's very different I mean [[00:27:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1645.84s)]
*  basically you know education systems I mean these are control systems like [[00:27:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1653.6799999999998s)]
*  these are we've studied syllabi and it turns out the oldest people in the field [[00:27:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1657.8s)]
*  have the greatest influence on the things that young people learn and that's [[00:27:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1661.9199999999998s)]
*  a recipe for reproduction and not growth yeah you know and so and there's [[00:27:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1666.68s)]
*  also some worry about bandwagons or bubbles like something becomes a popular [[00:27:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1672.68s)]
*  idea and suddenly everyone has to do it and then yeah a few years later turns [[00:27:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1678.16s)]
*  out well okay it wasn't that exciting after all that's right yeah that's that [[00:28:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1683.6000000000001s)]
*  that's the case where yeah there's this this no memory in the field and [[00:28:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1687.8400000000001s)]
*  everybody jumps to the kind of the hot new thing we've of a project that we [[00:28:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1691.28s)]
*  recently worked on when we looked at across countries at this style of [[00:28:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1696.66s)]
*  exploration and we find for example we compare China and the US that the [[00:28:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1701.5400000000002s)]
*  individually Chinese scientists for example move further across topics over [[00:28:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1708.3400000000001s)]
*  their career okay within any one particular time kind of as a whole [[00:28:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1713.3400000000001s)]
*  actually has far fewer topics that are focused on because on average people are [[00:28:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1718.8600000000001s)]
*  following the trend there are many smaller pockets in this space which are [[00:28:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1726.06s)]
*  effectively autonomous people are less likely to move over the course of their [[00:28:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1732.98s)]
*  crew but that becomes a reservoir of diversity yeah that from which abduction [[00:28:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1737.02s)]
*  becomes collectively possible I wonder if it's possible to sort of [[00:29:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1742.82s)]
*  institutionalize and nurture this kind of thing I mean we can valorize [[00:29:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1747.1s)]
*  innovation but I know just from personal experience if I write a very [[00:29:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1752.18s)]
*  very boring paper in physics that is nevertheless correct in every equation [[00:29:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1756.14s)]
*  I can get it published no problem there's gonna be zero worry that the [[00:29:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1761.98s)]
*  referee is gonna reject it if I try to be interesting and novel maybe that's [[00:29:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1765.54s)]
*  gonna be more important down the line but it's also much harder to get it into [[00:29:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1771.5s)]
*  the journals because you know the referee is like I don't I've never seen [[00:29:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1774.8s)]
*  this before I don't know how to deal with it and and likewise when you're [[00:29:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1777.54s)]
*  hiring people like you kind of feel comfortable hiring people who work on [[00:29:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1780.34s)]
*  the things you work on or whatever so you know what can we do to nurture the [[00:29:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1784.6599999999999s)]
*  right amount of difference innovation thinking outside of the boxes that we [[00:29:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1789.8999999999999s)]
*  built yes I think I think that it's you know from my perspective and when we've [[00:29:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1796.06s)]
*  looked at this you can think of what an economist might call a single equilibrium [[00:30:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1802.06s)]
*  solution you know which is like what's the right amount for each person like [[00:30:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1807.46s)]
*  what's the average amount of the balance of innovation and and versus [[00:30:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1811.02s)]
*  institutional you know kind of history and tradition for each particular [[00:30:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1816.9s)]
*  person but again systematically we find that that it's it's a multi-equilibrium [[00:30:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1820.9s)]
*  solution it's you know it's it's really about a complex balance of people who [[00:30:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1825.5s)]
*  are much more likely to be the kind of the priests you know of the field versus [[00:30:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1829.9s)]
*  the prophets who are traveling around and coming from outside so I think one of [[00:30:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1835.78s)]
*  the challenges is how do we build an ecology that facilitates multiple kinds [[00:30:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1839.94s)]
*  of career paths that allows people to kind of and and because institutions [[00:30:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1843.98s)]
*  defend and reproduce themselves then then I think you know one of the reasons [[00:30:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1849.98s)]
*  we talk about innovation all the time is because we need to talk about it and we [[00:30:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1855.96s)]
*  need to find novel institutions that kind of like resist and push against [[00:31:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1862.74s)]
*  these natural forces of preservation and memory which which I mean the entire [[00:31:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1867.98s)]
*  educational and scholarly enterprise reinforce you know journals you know [[00:31:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1873.94s)]
*  method sequences in graduate school like all these these things you know they're [[00:31:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1880.98s)]
*  thought collectives which were formed most of them with with titles and names [[00:31:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1887.18s)]
*  you know in some cases two three four hundred years old yeah right so these [[00:31:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1894.66s)]
*  are very old associations and they're powerful associations and they run [[00:31:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1900.7s)]
*  things like the Nobel Prize committee and you know they they have you know [[00:31:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1905.6200000000001s)]
*  these have disproportionate amounts of power so the reason we're talking about [[00:31:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1910.9s)]
*  innovation all the time is just because we fail at innovation most of the time [[00:31:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1914.6599999999999s)]
*  and in fact one of the things that we were looking at recently a project I was [[00:31:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1918.78s)]
*  just writing of this this morning is just for example a scientist age their [[00:32:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1924.3s)]
*  their appetite for for for change and innovation shifts as you were suggesting [[00:32:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1930.6599999999999s)]
*  and one of the things that we find is that you know not only so the average [[00:32:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1937.1799999999998s)]
*  scientist citation so this is like the distance between the paper they're [[00:32:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1941.46s)]
*  publishing and the papers they cite age at about a month a year this is in all [[00:32:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1945.3s)]
*  fields you know over all time except for the one field whose methods haven't [[00:32:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1950.88s)]
*  changed in 200 years mathematics which age at two months a year because and it [[00:32:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1955.3s)]
*  turns out everyone's favorite paper was published on average a year before their [[00:32:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1960.9s)]
*  first paper and what happens at about year 10 is is scientists basically [[00:32:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1966.1s)]
*  start what we looked at all the citations and all the context and on [[00:32:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1975.06s)]
*  average they basically start policing their fields so they basically start [[00:33:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1980.34s)]
*  criticizing other papers disproportionately and almost always [[00:33:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1983.98s)]
*  young papers young people's papers bringing new ideas and new methods from [[00:33:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1987.82s)]
*  outside the field or the new to the field so basically there's this so one of the [[00:33:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1994.46s)]
*  challenges here you know it's like how do we how do we influence this [[00:33:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=1997.94s)]
*  innovation it turns out that just the demography of your field dramatically [[00:33:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2002.88s)]
*  impacts the likelihood of churn of new ideas in the field and it and it's not [[00:33:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2008.14s)]
*  the reverse causal direction it's not like oh fields are stalling out and so [[00:33:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2013.06s)]
*  young people stop coming in it's the opposite it's it's you know basically if [[00:33:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2017.26s)]
*  you have a high proportion of old people in your field or even in your [[00:33:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2021.5s)]
*  department you can see this in a micro level then the field hits rigor mortis [[00:33:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2025.06s)]
*  and no new ideas come in and new ideas are getting shot down systematically [[00:33:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2030.06s)]
*  inside the papers that exist and and and those new ideas that are getting shot [[00:33:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2034.98s)]
*  down are in the same context as like citation context like paragraph as as [[00:33:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2038.86s)]
*  the as the citations which are their favorite citations which are on average [[00:34:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2044.9s)]
*  the paper that was published the year before their first paper right so it's [[00:34:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2049.7s)]
*  it's like so I think part of it is like we actually need to and you see across [[00:34:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2053.2999999999997s)]
*  countries for example India has the youngest scientific workforce and there's [[00:34:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2058.06s)]
*  a lot of innovation there China has a slightly older but much younger than the [[00:34:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2064.3799999999997s)]
*  US workforce and there's a lot of innovation of a certain kind there the [[00:34:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2068.74s)]
*  US scientific workforce is getting older Japan scientific workforce is [[00:34:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2075.1s)]
*  getting even older and you can see the reflection of those field level within [[00:34:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2079.5s)]
*  country environments dramatically impacting the likelihood that new ideas [[00:34:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2086.7799999999997s)]
*  will enter and thrive so one of the ways we manage this is actually by managing [[00:34:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2092.2599999999998s)]
*  the demography and the US the Supreme Court made it illegal for tenure-track [[00:34:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2097.02s)]
*  professors and institutions to to have a an age cap for retirement so it's you [[00:35:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2103.46s)]
*  know became illegal for ageism and we can show that in 1994 when that happened [[00:35:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2111.1s)]
*  there was just a linear increase in the age of citations on average in the field [[00:35:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2115.94s)]
*  and a decrease in the associated churn of ideas within those fields so I think [[00:35:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2123.54s)]
*  that's one of the ways we have to think about like the big picture managing the [[00:35:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2128.82s)]
*  whole environment the whole gene pool of ideas it is interesting because I've [[00:35:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2133.6600000000003s)]
*  noticed that the best popular music is what I was listening to as a teenager I [[00:35:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2138.78s)]
*  think that's just an objective fact right of course yeah and I think we're [[00:35:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2143.34s)]
*  probably about the same era so yeah the 80s danceable music I mean that was like [[00:35:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2147.34s)]
*  where is that and am I remembering correctly these studies of where funding [[00:35:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2151.1800000000003s)]
*  dollars go these days or where prizes are awarded at least in the US they are [[00:35:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2158.62s)]
*  going to older people than they used to absolutely yeah that's that there's a [[00:36:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2164.38s)]
*  linear increase in the age of first NIH grant for example that the people [[00:36:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2168.58s)]
*  experience the prizes on average are highly conservative which is to say you [[00:36:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2175.06s)]
*  know and the reason is because they are given by contacts you know they are [[00:36:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2183.66s)]
*  given by the physics community or by you know they're given by associations [[00:36:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2187.66s)]
*  like which systematically undervalue work that violates the boundaries [[00:36:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2192.06s)]
*  between those contexts so so the things that are the most disruptive in in [[00:36:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2198.7799999999997s)]
*  citation that attract the most kind of burst the biggest bursts of attention [[00:36:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2204.1s)]
*  are not the same things on average that are getting prizes the Nobel prizes [[00:36:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2209.8599999999997s)]
*  yeah so back to the like individual scientists I know you've written one [[00:36:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2216.14s)]
*  paper that was kind of provocative to me about why scientists disagree with each [[00:37:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2222.1s)]
*  other I mean the thing about science is of course you've established some things [[00:37:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2227.66s)]
*  as reliable but then you're also speculating about what's going to happen [[00:37:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2232.02s)]
*  next what is interesting where to go and so forth and it's remarkable how people [[00:37:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2235.7799999999997s)]
*  can be really devoted and even passionate about insisting that it's [[00:37:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2241.62s)]
*  going to be going a certain way or I guess the way that I like to say it that [[00:37:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2246.7s)]
*  is that is most you know generous is every approach has its looming obstacles [[00:37:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2251.22s)]
*  and every advocate of every approach says oh but our obstacles will be [[00:37:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2257.66s)]
*  overcome I can see that whereas your obstacles are absolutely going to make [[00:37:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2263.06s)]
*  you stuck where does that come from it's not purely objective is it like [[00:37:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2267.38s)]
*  personality are there some cognitive traits that individual scientists have [[00:37:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2271.82s)]
*  to get in the way yeah I think I think there's that there are many forces I [[00:37:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2275.42s)]
*  mean so one are the paper that you're referring to that's that's forthcoming in [[00:38:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2280.06s)]
*  nature human behavior is one where we basically look at a deep dispositional [[00:38:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2285.1800000000003s)]
*  trait so we look at psychologists we run the same kind of psychological [[00:38:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2290.38s)]
*  profiles on psychologists that they run on college students around the world and [[00:38:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2297.06s)]
*  and it turns out that they're really stable and strong associations between [[00:38:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2302.42s)]
*  their relative you know acceptance of ambiguity and whether or not they're you [[00:38:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2307.06s)]
*  know interested in for example like multimodal findings you know that are [[00:38:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2312.94s)]
*  just supported by for example you know a certain kind of statistical or [[00:38:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2316.98s)]
*  mathematical model you know if they can so so there's definitely the there you [[00:38:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2322.1s)]
*  know the background proclivities which shaped the relative likelihood of whether [[00:38:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2327.8199999999997s)]
*  or not something's attended to I would say another approach really is the [[00:38:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2332.94s)]
*  zeitgeist of an age of a moment there's one paper that I love it's by a guy [[00:38:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2337.3399999999997s)]
*  named Paul Forman in 1971 it's a book length paper called Weimar culture [[00:39:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2344.38s)]
*  causality and quantum theory it basically yeah at this it's a beautiful [[00:39:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2350.74s)]
*  paper it basically kind of shows it tells a story and it shows that okay we've [[00:39:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2357.8999999999996s)]
*  got a whole host of people in the wake in the Weimar Republic in the wake of [[00:39:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2362.74s)]
*  the loss of World War one by Germany who kind of are against causality as an [[00:39:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2368.58s)]
*  approach and and so philosophers are kind of writing against this nihilism is [[00:39:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2374.8599999999997s)]
*  emerging in the artistic space and it turns out that the physics there are [[00:39:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2379.58s)]
*  some physicists who were reading this philosophy who were writing [[00:39:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2383.54s)]
*  philosophical tracks against causality and those were the ones who embraced the [[00:39:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2387.38s)]
*  kind of the quantum revolution which is arguably an a causal physics and so it's [[00:39:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2393.02s)]
*  kind of like you know this moment this you know this kind of post-war [[00:39:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2396.98s)]
*  depression malaise you know anti in causal enthusiasm allowed the relative [[00:40:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2401.82s)]
*  selection of what was otherwise epistemically very unpopular and very [[00:40:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2410.06s)]
*  unsatisfying from the ways in which it so you know epistemic standards in [[00:40:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2416.1800000000003s)]
*  science are are the standards by which we credit something as knowledge right [[00:40:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2420.38s)]
*  if if we've got standards and that that that crediting there there's some strict [[00:40:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2425.7000000000003s)]
*  criteria oh you've got a you know we have to demonstrate some empirical [[00:40:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2430.7799999999997s)]
*  accuracy maybe through experiments or through observations or for quasi you [[00:40:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2434.58s)]
*  know synthetic experiments but there are a host of other hidden epistemic [[00:40:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2439.2599999999998s)]
*  standards and those hidden standards come from what is familiar to us what we [[00:40:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2443.8999999999996s)]
*  associate with advanced what's beautiful you know what's simple so we have all [[00:40:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2451.1s)]
*  these deep preferences about what science should like and so when science [[00:40:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2457.46s)]
*  shows up that looks like that then we are ready to give it awards we're ready [[00:41:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2461.86s)]
*  to credit it with advance and if it doesn't look like that then it's it's [[00:41:06](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2466.02s)]
*  often hard and one of the reasons I'm interested in studying that is because I [[00:41:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2470.02s)]
*  really am interested in collective advance and the way in which science is [[00:41:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2473.98s)]
*  and can be an engine yeah and that means we need to basically critically observe [[00:41:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2479.26s)]
*  the impact of these kinds of hidden epistemic standards on unlocking in a [[00:41:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2485.7s)]
*  certain kind of scientific slow gradual progress it's a great point because I [[00:41:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2491.7799999999997s)]
*  think I came across that paper you're referring to when I was an undergraduate [[00:41:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2497.58s)]
*  and I was very dismissive of it because you know quantum mechanics works because [[00:41:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2501.5s)]
*  it fits the data in some sense and I wanted to say like who cares about the [[00:41:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2505.98s)]
*  philosophical predispositions in post-Fly-Mar Germany but now in my in my [[00:41:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2509.8999999999996s)]
*  twilight years when I'm more sophisticated I can absolutely see that [[00:41:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2515.26s)]
*  there's certain ideas you're open to certain speed at which you're willing to [[00:41:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2519.46s)]
*  change your mind about things which will be affected by the wider world and I'm [[00:42:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2525.82s)]
*  actually in retrospect super impressed with the scientists of the 20s that they [[00:42:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2529.82s)]
*  were so quick to embrace this very very different view of the world and no doubt [[00:42:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2535.14s)]
*  the wider context had a lot to do with that right yeah and I think I think you [[00:42:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2541.42s)]
*  know one of the reasons we can study this is just to identify it but I think [[00:42:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2546.5800000000004s)]
*  another generative and constructive way in which we can use this so I spend a [[00:42:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2550.46s)]
*  lot of time talking with science funders you know and advising science funders in [[00:42:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2555.1000000000004s)]
*  the US and in Europe and in China and elsewhere and and so you know part of [[00:42:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2559.7400000000002s)]
*  this is is the ability to do what I'll care you know it's science fiction right [[00:42:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2565.6200000000003s)]
*  so so if if we didn't have a predisposition against this approach then [[00:42:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2570.06s)]
*  let us now turn the crank and see what other kinds of approaches would or could [[00:42:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2575.86s)]
*  have been or could now be probable so if this is the flow of the scientific river [[00:43:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2580.5s)]
*  then what are other tributaries that that let's just imagine that some of the [[00:43:06](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2586.54s)]
*  decisions that were made to pursue or not pursue areas were not rational let's [[00:43:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2591.98s)]
*  just assume that that I mean maybe many of them were obviously you know science [[00:43:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2596.7s)]
*  moves forward but let's just assume that some of them have to do with these [[00:43:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2600.7799999999997s)]
*  complexities of history now we can basically build we can use these these [[00:43:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2604.2599999999998s)]
*  models large network models are now you know kind of like two large language [[00:43:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2608.66s)]
*  models to basically run science fiction and my group spends a lot of time now [[00:43:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2612.8599999999997s)]
*  creating conferences that never have and never could exist generating paper [[00:43:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2617.14s)]
*  topics patents proposals that that that are that that the people don't exist in [[00:43:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2623.18s)]
*  the population of our world to have created those but if we had a different [[00:43:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2628.74s)]
*  structure of education system these proposals will be very likely to exist [[00:43:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2632.2999999999997s)]
*  and this allows us to think about like you know with an expanded view you know [[00:43:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2636.46s)]
*  what are places we could pivot to what what is the field of action that we can [[00:44:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2643.14s)]
*  engage in so I think if this is not just an act of humanities but an act of [[00:44:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2649.06s)]
*  speculation in the in the most generative tradition of speculation can [[00:44:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2653.58s)]
*  we build engines that facilitate and illuminate new possibilities I'm very [[00:44:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2658.1s)]
*  curious as to what are the fun conferences that could have been held in [[00:44:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2663.46s)]
*  other possible worlds that we weren't in and do they teach us anything about what [[00:44:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2667.06s)]
*  conferences we should organize well this is this actually so one of the nice [[00:44:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2670.86s)]
*  things about science again is there's lots of data people say on their CVs [[00:44:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2675.22s)]
*  every conference they participated in since they were a baby you know and so [[00:44:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2679.98s)]
*  and every year there are new conferences and I would say you know about about 25 [[00:44:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2685.22s)]
*  percent of science funding is convening you know it's pulling together people in [[00:44:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2691.54s)]
*  different places for summer schools and and so we have basically experiments [[00:44:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2696.52s)]
*  continuously that basically allow us to see what's the you know what are the [[00:45:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2700.78s)]
*  effects of these convenings basically in the unfolding space of science and and [[00:45:06](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2706.2200000000003s)]
*  we have identified you know so for example what one project we're working [[00:45:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2710.98s)]
*  on is is there is you know there's a kind of a attentional and status order [[00:45:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2716.02s)]
*  of science which is to say I noticed electrical engineers site physicists more [[00:45:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2721.34s)]
*  than physicists electrical engineers CS computer scientists site electric you [[00:45:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2726.14s)]
*  know you know EE more than EE side CS information science site computer [[00:45:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2730.94s)]
*  science more than computer science sites so there are there flows and [[00:45:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2738.46s)]
*  institutions of information and we show basically systematically on average when [[00:45:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2742.66s)]
*  something gets cited against that flow it's associated with much more disruptive [[00:45:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2749.82s)]
*  attention in the field which and it turns out well you know maybe those were [[00:45:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2756.9s)]
*  the best things to explore well it turns out that it's much more likely for [[00:46:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2763.5800000000004s)]
*  example for the things that get discovered against the grain to be [[00:46:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2767.7400000000002s)]
*  accidentally discovered from a person at your institution it's even more likely [[00:46:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2773.5800000000004s)]
*  for you to be married to the person in the lower status field that you get [[00:46:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2778.14s)]
*  exposed to the so it's not like just the best ideas are flowing against the grain [[00:46:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2781.7799999999997s)]
*  it's like occasionally when we randomly violate the status order then [[00:46:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2786.62s)]
*  systematically we found disruptive and disruptively useful things to these [[00:46:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2792.22s)]
*  fields so so so there's a whole host of conferences where in this world people [[00:46:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2797.9s)]
*  from this camp are too good to associate with people from this camp you know they [[00:46:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2804.26s)]
*  have epistemic standards that are different they have and we're building [[00:46:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2810.7400000000002s)]
*  these these playful you know large language model agents that are having [[00:46:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2813.38s)]
*  conversations and disagreeing with one another and coming up with and have who [[00:47:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2820.1800000000003s)]
*  have different dispositions and personalities and we're building [[00:47:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2824.94s)]
*  these things those are kind of spaces where you can basically steer these [[00:47:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2830.34s)]
*  models not just through text but through just through the through the the [[00:47:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2834.54s)]
*  simplex of the model space to pick exactly this particular kind of person [[00:47:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2839.1800000000003s)]
*  you know a stoic you know physicist with a view of this from you know 1950 and we [[00:47:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2844.06s)]
*  can put them in a room with someone who has a very different view of the world [[00:47:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2851.46s)]
*  and and we can see sparks fly and so I know it's it's it's ridiculous and yet at [[00:47:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2854.7799999999997s)]
*  the same time it's it's just another extension of of this question of [[00:47:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2861.2999999999997s)]
*  expanding the space of speculation yeah and it's a it's very useful if you want [[00:47:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2865.94s)]
*  to go forward and figure out how to do things better I mean one thing is that [[00:47:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2872.74s)]
*  science is just bigger now right there are more scientists there are larger [[00:47:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2876.7s)]
*  collaborations there there are teams that are trying to get things done you [[00:48:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2881.26s)]
*  know what can we say about that in general and in particular like our big [[00:48:06](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2886.5s)]
*  collaborations better in some ways than smaller teams etc so you know so that [[00:48:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2892.3s)]
*  this this kind of a few layers to this you know this morass right so one is is [[00:48:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2899.42s)]
*  that the field levels fields get larger we find there is a kind of caring [[00:48:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2905.1800000000003s)]
*  capacity to to a field so which you can think of as a field as a conversation [[00:48:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2911.22s)]
*  it's a sustained conversation that occurs in departments and in journals [[00:48:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2916.4199999999996s)]
*  and in all these environments and as the field as fields get larger there's an [[00:48:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2920.8199999999997s)]
*  exponential decline in the likelihood that new ideas will enter the canon of [[00:48:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2925.18s)]
*  kind of most cited ideas so if you have two ideas two fields that merge they [[00:48:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2929.62s)]
*  won't retain the kind of the intellectual diameter of of the [[00:48:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2934.94s)]
*  independent fields union you know those two added to one another they will [[00:49:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2940.62s)]
*  collapse all of a sudden there will be forced competitions between ideas and [[00:49:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2944.42s)]
*  over eyeballs and attention and and they'll collapse to kind of one part of [[00:49:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2949.58s)]
*  the space so I think one challenge we see is like as we grow fields we have [[00:49:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2954.98s)]
*  greater greater success as we recruit you know new ideas to these to these you [[00:49:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2959.66s)]
*  know kind of mega fields then they you know that that size is massively [[00:49:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2966.54s)]
*  sublinear relative to the relative new ideas that those yes new individuals [[00:49:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2973.7s)]
*  bring within teams we see kind of a similar but slightly different dynamic [[00:49:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2979.2999999999997s)]
*  because teams are are you know constructed you know project by project [[00:49:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2988.46s)]
*  often sometimes you know into larger institutions that have you know some [[00:49:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2993.38s)]
*  greater stability but we find that that big teams you know they tend to not [[00:49:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=2997.34s)]
*  produce highly disruptive work and you know so they and there are a few reasons [[00:50:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3005.26s)]
*  that appears for this you know so what are these teams do systematically well [[00:50:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3012.58s)]
*  they produce papers really quickly so they're more productive on average [[00:50:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3017.18s)]
*  that's one of the things that the teams have to demonstrate and and how do they [[00:50:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3022.1s)]
*  how do they perform that productivity and still get you know a measure of [[00:50:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3027.46s)]
*  attention well they tend to do it like a big production company does you know if [[00:50:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3032.2599999999998s)]
*  they're trying to decide between you know producing transformers 9 and you [[00:50:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3035.8599999999997s)]
*  know slumdog millionaire it's like they're gonna predict they're gonna do [[00:50:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3041.98s)]
*  you know they're gonna do transformers not like they they they're gonna bet on [[00:50:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3046.06s)]
*  the winning horse and this is what happens in science they basically take [[00:50:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3050.46s)]
*  huge popular ideas of yesterday and they basically momentum invest they take like [[00:50:53](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3053.66s)]
*  the next step and they're gonna get you know like transformers 9 is gonna get [[00:50:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3058.14s)]
*  transformers 8 receipts minus epsilon and you know and they're gonna get you [[00:51:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3061.34s)]
*  know some all you know most of the market that existed for the prior [[00:51:06](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3066.42s)]
*  finding and so small teams are much more nimble and and part of it is because [[00:51:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3069.46s)]
*  they have to be because they can't produce transformers 9 they can't be the [[00:51:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3075.62s)]
*  biggest hit that builds on alpha fold 2 like they can't do that so they have to [[00:51:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3080.58s)]
*  do something different so they dig deeper into the past they dig deeper [[00:51:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3084.66s)]
*  across fields or farther across fields and and so they're much more predictive [[00:51:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3088.8599999999997s)]
*  of advances that are likely if they succeed to occur and be important in [[00:51:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3095.38s)]
*  five or ten years basically when this when whatever this bet we've made has [[00:51:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3100.98s)]
*  really run dry like we've mined all the good stuff out of this vein it's like [[00:51:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3106.18s)]
*  that's when like we're like oh wow those small teams had you know other ideas and [[00:51:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3110.9s)]
*  it turns out that when we look at the structure of teams underlying those [[00:51:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3115.7s)]
*  papers so we can build hierarchies within those those projects we find the [[00:51:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3119.7400000000002s)]
*  flat of the teams which is to say the more people that are involved in like [[00:52:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3124.86s)]
*  the design of the ideas it slows down the production of papers but increases [[00:52:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3129.22s)]
*  the instability of the papers it makes it more likely for those papers to have [[00:52:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3134.22s)]
*  fused ideas fundamentally from different fields inside these spaces so it's a [[00:52:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3138.54s)]
*  it's a it's a complex bet you know if if it turns out that people do more [[00:52:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3143.5s)]
*  innovation on average than their if they just were trying to maximize their [[00:52:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3148.8999999999996s)]
*  citations would recommend because as you said you can publish something if it's [[00:52:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3153.2599999999998s)]
*  true but boring and familiar but but at the same time you know every time we [[00:52:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3158.06s)]
*  measure this like how much innovation is happening relative to what the optimal [[00:52:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3166.46s)]
*  amount would be to maximize discovery while retaining some memory in the [[00:52:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3172.2999999999997s)]
*  system we find that more is more you know more is is better we're not we [[00:52:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3177.62s)]
*  this optimal limit of innovation inside almost all the fields that we're looking [[00:53:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3183.5s)]
*  at because you know we may have a plan oh hey we're gonna we're gonna build an [[00:53:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3189.66s)]
*  institution where 15% of the grants go to completely new things and you know 85% [[00:53:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3195.94s)]
*  of the grants go to completely establish things but then even within those [[00:53:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3201.1s)]
*  proposals you have established people who are running both of the yeah both [[00:53:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3206.58s)]
*  the innovative and the non-innovative like it just the the conservatism goes [[00:53:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3211.06s)]
*  all the way down right and so but there's also the the fact that most [[00:53:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3215.34s)]
*  things that might qualify as innovative are bad right like there's a lot more [[00:53:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3220.98s)]
*  ways to be wrong than to be right absolutely yeah absolutely yeah yeah [[00:53:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3227.1s)]
*  most yeah so it's it's really so this point becomes critical it's like if you [[00:53:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3231.18s)]
*  want to increase the likelihood of disruptive success you have to increase [[00:53:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3236.58s)]
*  your failure rate yeah like you like if you're if you're in a lab or in a field [[00:54:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3241.34s)]
*  that is consistently making good bets then a robot could have made those bets [[00:54:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3247.98s)]
*  yeah like you're not succeeding like succeeding is violating expectations [[00:54:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3252.9s)]
*  which and most of those violations will obviously be wrong because we know [[00:54:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3258.7s)]
*  things like because a lot of this physics a lot of these other fields you [[00:54:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3263.86s)]
*  know have insights that that worker that are highly descriptive I will say this is [[00:54:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3268.7000000000003s)]
*  where you know another place where kind of AI comes in fields that are kind of [[00:54:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3275.06s)]
*  like fundamentally multi-scale that are that are complex by complex I mean like [[00:54:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3280.9s)]
*  self dissimilar you know it's not fractal it's not like if you see it at [[00:54:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3287.38s)]
*  this level it's also true at this level it's it's different at these different [[00:54:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3291.22s)]
*  levels like these kinds of complex systems have you know in many cases [[00:54:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3294.54s)]
*  really I've not even been the subject of intensive scientific study because [[00:54:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3299.8999999999996s)]
*  because we don't have scientific traction and these are the kinds of [[00:55:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3305.4599999999996s)]
*  places where the kind of function arbitrary function fitting that large AI [[00:55:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3309.02s)]
*  style models are actually bringing a really big Delta of inference and it's [[00:55:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3314.74s)]
*  it's less likely for them to discover new things about simple and basic physics [[00:55:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3320.58s)]
*  and about some of these other things which have been you know we've had great [[00:55:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3325.2200000000003s)]
*  minds on them for you know centuries but but areas which are kind of like okay [[00:55:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3328.26s)]
*  the intersection of you know physics and chemistry and biology complex system [[00:55:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3334.62s)]
*  self dissimilar systems these are the spaces where you know like the right [[00:55:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3339.7400000000002s)]
*  most parsimonious equation might be like 500 pages long like that the most [[00:55:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3345.06s)]
*  parsimonious I'm not saying just the most overfit you know like that might be [[00:55:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3351.9s)]
*  the best description and it might actually be quite predictive and quite [[00:55:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3356.46s)]
*  general so so these are all of a sudden you know science leaves the capacity kind [[00:56:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3361.18s)]
*  of of the of potentially of the human brain I think this is this is one of [[00:56:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3368.5s)]
*  those science-fictions that we have to consider you know alpha fold 2 is [[00:56:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3373.74s)]
*  learning a huge complex function that does not look like any equation that has [[00:56:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3378.4199999999996s)]
*  sit inside biology text ever and it kind of killed you know structure of [[00:56:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3384.14s)]
*  prediction I mean it just does it better and it and it's not reducible we're not [[00:56:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3389.1s)]
*  gonna be like we're gonna search through the neuroscience of that model and find [[00:56:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3394.02s)]
*  you know like oh it's doing this one thing like really well like no it's it's [[00:56:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3398.14s)]
*  we've squeezed down those models and they're still large and and so it's [[00:56:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3403.66s)]
*  kind of like you know yeah I think I think we're entering an interesting era [[00:56:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3412.42s)]
*  where we're considering the fact that you know they're gonna be different [[00:56:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3417.8999999999996s)]
*  forms and shapes of of knowledge science and kind of technology or control and [[00:57:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3421.22s)]
*  they're increasingly they're gonna be some things like you know alpha fold 2 [[00:57:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3427.66s)]
*  which is not science I mean it's it's it is a regularity the machine knows what [[00:57:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3432.26s)]
*  it knows so it has machine science we don't have access to that science is [[00:57:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3437.78s)]
*  that there's a great paper called crumbs from the table it's at the last page of [[00:57:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3443.3s)]
*  of a nature magazine in 2000 by Ted Chiang where he basically says he kind [[00:57:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3447.5400000000004s)]
*  of describes a world of meta humans at that time he was kind of talking about [[00:57:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3454.26s)]
*  these pharmaceutical you know creatures that we couldn't understand anymore and [[00:57:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3457.26s)]
*  and he kind of talks about you know he imagines a world in which all of [[00:57:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3462.9s)]
*  science is hermeneutics we're just all interpreting the artifacts that have [[00:57:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3466.78s)]
*  kind of come to us without understanding and we're trying to do neuroscience on [[00:57:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3472.38s)]
*  these artifacts and I find myself and a lot of other scientists this is in fact [[00:57:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3476.38s)]
*  precisely what we're doing we're trying to make sense of of brains that look [[00:58:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3480.3s)]
*  like they know things and and you know that's a great point I recently talked [[00:58:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3484.66s)]
*  to Jeff Lichtman who is a Harvard professor neuroscientist who is a leader [[00:58:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3489.8199999999997s)]
*  in mapping the connectome of the human brain and one of the things I thought [[00:58:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3494.18s)]
*  was interesting and it was unexpected in our conversation was he pushed back on [[00:58:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3498.58s)]
*  the idea that we're trying to understand the brain because he said look if you [[00:58:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3502.7799999999997s)]
*  could understand the brain in sort of in the sense of coming up with some [[00:58:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3508.3799999999997s)]
*  simplified description of it then the brain would be simpler the brain is as [[00:58:33](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3513.26s)]
*  simple as it can be and it's super duper complex because it's doing these things [[00:58:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3518.1400000000003s)]
*  we need to sort of figure out what it does but we're not going to find a you [[00:58:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3522.0200000000004s)]
*  know a short description that encapsulates the brain right yeah so and [[00:58:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3525.7400000000002s)]
*  this but this is this is this represents a new era if we take that seriously if [[00:58:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3530.86s)]
*  like that's what our intellectual you know ventures become about then then [[00:58:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3536.74s)]
*  then science changes its character it changes its standard it changes its [[00:59:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3544.2599999999998s)]
*  meaning and and you know and the epistemic standard of to something feel [[00:59:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3548.8599999999997s)]
*  right does it look right does the equation you know have the right number [[00:59:13](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3553.02s)]
*  of variables is it elegant you know all these things you know I won't say they [[00:59:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3556.54s)]
*  go by the wayside I think they're important obviously pruned models and [[00:59:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3561.7799999999997s)]
*  simplified understandings allow them to travel like like kind of components new [[00:59:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3565.7s)]
*  areas so there's all kinds of reasons that simplification is useful it just [[00:59:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3571.3799999999997s)]
*  may be it's likely to be for many of these complex self dissimilar systems [[00:59:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3576.74s)]
*  that that the components that we learn you know from these systems are much [[00:59:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3582.2999999999997s)]
*  larger and themselves more complex than we had previously imagined and they and [[00:59:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3588.8599999999997s)]
*  they become objects in the world like a fab facility I was in Silicon Valley [[00:59:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3594.66s)]
*  when they they moved the first big chip fabrication facility Intel from from [[00:59:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3598.78s)]
*  there you know in the kind of San Jose area to Ireland and they had done so [[01:00:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3605.7s)]
*  many changes on that facility like they you know they fixed you know something [[01:00:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3610.7400000000002s)]
*  like 15 million errors so they had no idea why the fab facility at the [[01:00:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3615.98s)]
*  tolerance levels it did and so when they moved it they were like okay we [[01:00:21](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3621.62s)]
*  need to retain everything like its orientation to magnetic north it's like [[01:00:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3624.8599999999997s)]
*  you know like the relative density of the air you know it's its elevation like [[01:00:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3629.2599999999998s)]
*  they had no idea and they took it over and it and it broke for reasons again [[01:00:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3634.02s)]
*  that they didn't understand and had to had to kind of fine-tune out but that [[01:00:37](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3637.9s)]
*  it's like our our new theories are looking more like this the fab facility [[01:00:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3641.2999999999997s)]
*  that produces like chips with a high accuracy low tolerance level and it's [[01:00:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3645.8599999999997s)]
*  unsatisfying as a scientist in some ways to look at that fab facility and and say [[01:00:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3651.46s)]
*  wow that's that's what we know you know what is that I don't even know what that [[01:00:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3656.9s)]
*  is like like yeah I mean I guess I kind of get it and I have very mixed feelings [[01:01:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3660.66s)]
*  about it I mean I agree it's yeah no no what my feelings are not going to affect [[01:01:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3665.58s)]
*  what what's going on but but I to sort of I mean put it in other words and you [[01:01:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3670.26s)]
*  can tell me whether I'm capturing it correctly I mean there's a whole new way [[01:01:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3675.58s)]
*  of understanding things of modeling things of being a scientist once you [[01:01:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3678.3s)]
*  have large language models probably isn't the right word but you know these [[01:01:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3684.1800000000003s)]
*  these deep learning high many many number of parameters things you can [[01:01:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3689.82s)]
*  capture complexity in a way that is unprecedented impossible if you if you [[01:01:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3694.34s)]
*  need a one-line equation to count as understanding so you can do that but so [[01:01:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3699.96s)]
*  much of science is sort of counterfactual right is sort of saying [[01:01:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3705.48s)]
*  well if things were different what would happen and without that simple [[01:01:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3709.68s)]
*  understanding I mean maybe the the example of the fab factory is is an [[01:01:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3714.48s)]
*  important one how good are we at saying we truly understand or even the AI truly [[01:01:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3719.72s)]
*  understands if we can't say well when we change things what are the effects of [[01:02:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3725.48s)]
*  those changes so we have got a paper that's where we look at the impact of AI [[01:02:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3729.24s)]
*  on science of the last 25 years and of course it's gone through different [[01:02:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3736.9199999999996s)]
*  generations first it was machine learning and then it was kind of deep [[01:02:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3740.7999999999997s)]
*  learning and now more recently is these large transformer style kind of [[01:02:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3743.6s)]
*  foundation models and we look at the impact on scientists and on science and [[01:02:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3748.16s)]
*  we find that basically on scientists it increases their mobility across [[01:02:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3752.3999999999996s)]
*  scientific ideas it increases their speed of getting papers done decreases [[01:02:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3756.36s)]
*  the number of people in this papers increases their rate of promotion for [[01:02:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3760.6800000000003s)]
*  science as a whole right now it actually narrows the scope of ideas that are [[01:02:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3765.88s)]
*  discussed because these are big data seeking models and where do we have big [[01:02:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3772.34s)]
*  data one problems that we've been generating data forever about problems [[01:02:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3776.6s)]
*  we already know about so so exactly as you suggest on average right now these [[01:03:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3780.36s)]
*  models are not being to to origins questions origin space you know origin of [[01:03:04](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3784.84s)]
*  time origin of language origin of you know like you know any of these these [[01:03:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3791.1600000000003s)]
*  origins questions that live before the institutions that produced and preserved [[01:03:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3796.1200000000003s)]
*  data and so so that's a world of counterfactuals now that being said it's [[01:03:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3800.7200000000003s)]
*  not obvious to me that AI has to fulfill that role that is the role that it has [[01:03:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3806.7200000000003s)]
*  fulfilled what I was describing earlier is that with these large data driven [[01:03:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3812.0s)]
*  models we can actually engage in kind of like continuously steering [[01:03:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3815.72s)]
*  counterfactuals in a way that was unprecedented before you know creating a [[01:03:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3821.16s)]
*  factory for counterfactuals and so I actually think it's possible for it to [[01:03:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3825.18s)]
*  enter some of these these new areas but it's going to require a new range of [[01:03:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3830.8s)]
*  conceptual thinking and scientists effectively will have to become in some [[01:03:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3835.04s)]
*  ways philosophers of science you know where they're selecting between [[01:03:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3839.44s)]
*  philosophies they're navigating yeah you know what their tolerance for kinds of [[01:04:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3843.04s)]
*  like philosophies of hypotheses are and then you know the machines will produce [[01:04:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3847.2400000000002s)]
*  them and in some cases will test them you know well I guess creativity is a [[01:04:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3852.28s)]
*  big sticking point with the AI's like is it I guess there's a school of thought [[01:04:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3857.46s)]
*  which will say that they're just not creative in the standard way they're [[01:04:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3863.0s)]
*  remixing all these various ideas that they've been fed from their training [[01:04:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3868.32s)]
*  date or whatever but I see no reason in principle that that an AI couldn't be [[01:04:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3871.88s)]
*  creative I mean if only because you could throw some random numbers in there [[01:04:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3876.92s)]
*  but then there's a question of how do you cleverly throw the random numbers in [[01:04:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3881.28s)]
*  there like how do you how do you nudge the AI towards being creative in useful [[01:04:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3886.36s)]
*  ways is this is this just my lack of understanding or is this a frontier here [[01:04:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3890.6400000000003s)]
*  this is this is an interesting frontier I I've got a DARPA grant with law [[01:04:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3896.0s)]
*  Varshney's a computer scientist and a really creative engineer at the [[01:05:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3900.7999999999997s)]
*  University of Illinois at Urbana-Champaign he when he was at IBM when [[01:05:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3907.32s)]
*  he created this kind of blue chef system that kind of created really creative [[01:05:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3912.72s)]
*  combinations of ingredients and recipes that then you know would automatically [[01:05:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3917.04s)]
*  kind of yeah it's work spending time looking at the sciences and also [[01:05:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3920.7599999999998s)]
*  building kind of theories of creativity that will facilitate the kinds of [[01:05:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3924.76s)]
*  abductive creativity that we see in the world but I think a critical piece of [[01:05:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3930.36s)]
*  this is what we're talking about earlier I mean outsiders and insiders [[01:05:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3934.1200000000003s)]
*  abduction surprises that are are because like our expectations that come from [[01:05:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3938.0s)]
*  literature and like the data that come from experiments and observations are [[01:05:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3943.2400000000002s)]
*  separate they're not so so what does that mean we you know large you know [[01:05:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3946.5600000000004s)]
*  language and large multimodal models and these deep learning models they're [[01:05:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3951.4s)]
*  not one model there are many models and so we basically have to exploit that [[01:05:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3955.28s)]
*  underlying diversity and accentuate that underlying diversity we have to [[01:06:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3962.64s)]
*  separate some of these in turn so if you just train these models in prediction [[01:06:07](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3967.04s)]
*  you'll find that they actually create themselves little schools of thought but [[01:06:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3971.4s)]
*  then they recombine at the last moment to make predictions they're doing yeah [[01:06:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3976.2000000000003s)]
*  science inside themselves for us to use them to kind of push the boundaries of [[01:06:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3980.32s)]
*  science we need to use them to generate really deep expectations and then we [[01:06:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3985.76s)]
*  need to use other models to survey the space of experiments and observations [[01:06:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3990.92s)]
*  and we need to like identify dynamically like what are the surprises and how [[01:06:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=3996.52s)]
*  should that so absolutely if we just you know use these models to create more data [[01:06:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4001.52s)]
*  and then use that data to train the model will have a collapse of attention [[01:06:47](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4007.24s)]
*  and the models will not get better they'll get worse but if we basically [[01:06:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4011.7599999999998s)]
*  build an ecology of models in the same way that we need to cultivate an ecology [[01:06:55](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4015.56s)]
*  of scientists with different temperaments from different fields with [[01:07:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4020.7999999999997s)]
*  different expertises those ecologies of models or have the potential to kind of [[01:07:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4023.96s)]
*  create a new world of creativity in the same way that like when we think about AI [[01:07:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4030.24s)]
*  safety and it's like no we okay we've got a we have to put the thumbscrews the [[01:07:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4036.2s)]
*  you know restraining bots on these robots no we like we do the things that [[01:07:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4040.16s)]
*  we do with unpredictable intelligences in the past you know we make them sign [[01:07:24](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4044.7599999999998s)]
*  the Magna Carta we create a set of independent you know institutions checks [[01:07:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4049.6s)]
*  and balances like we need to create an ecology of regulatory AIs you know an [[01:07:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4054.16s)]
*  independent court system you know an independent you know legislative body [[01:07:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4059.24s)]
*  you know that I mean all these things are that's how like safety works that's [[01:07:43](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4063.44s)]
*  how innovation works even though those systems are kind of in some ways opposed [[01:07:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4068.4s)]
*  to each other we do it collectively and and so we need to basically harness [[01:07:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4072.2000000000003s)]
*  ecologies of kind of artificial intelligence models and agents to kind [[01:08:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4080.12s)]
*  of create the same recipe basically for knowledge generation that that we that [[01:08:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4085.1600000000003s)]
*  we see working or have you know has worked really increasingly works in the [[01:08:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4090.84s)]
*  human system I mean that seems to be a common thread here one thing we didn't [[01:08:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4095.96s)]
*  get to is a paper you wrote on political polarization in editors of Wikipedia [[01:08:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4099.92s)]
*  articles and how you get the best articles when it's not written from a [[01:08:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4106.88s)]
*  single point of view when there's some team of rivals aspect there and in some [[01:08:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4111.72s)]
*  sense you're saying that's just as true for the computers as it is for the human [[01:08:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4115.88s)]
*  beings that's right and the problem is that you know the computer model [[01:08:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4119.64s)]
*  generators would love to be monopolists so you know they will be you know they're [[01:08:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4125.240000000001s)]
*  trying to sell a product that is the one true AI product you know that has all [[01:08:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4130.88s)]
*  diversity completely within itself embedded and and the answer is that [[01:08:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4137.280000000001s)]
*  cannot possibly work as a long-term generator of surprise in the same way [[01:09:02](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4142.92s)]
*  that if you have two communities and you force them into one conference room [[01:09:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4148.64s)]
*  they will talk about half of the ideas that they talked about when the two [[01:09:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4152.96s)]
*  communities were separate like we need to create an ecology of the AIs that you [[01:09:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4157.200000000001s)]
*  know that basically enhance the population genetics you know from which [[01:09:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4162.76s)]
*  future innovation becomes possible I mean I'm glad you just said that because I [[01:09:27](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4167.4800000000005s)]
*  think you said it before a version of it but it didn't quite sink into me you [[01:09:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4171.52s)]
*  need the different communities to talk to each other but they also need to be [[01:09:36](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4176.24s)]
*  different communities otherwise they become just homogeneous yeah and this is [[01:09:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4180.2s)]
*  where tradition is absolutely critical in creating membranes between communities [[01:09:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4184.719999999999s)]
*  that can basically self-evaluate and have their own tastes like so so I'm not [[01:09:49](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4189.679999999999s)]
*  a I'm not an anti-field I in fact I think I think fields are absolutely [[01:09:54](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4194.96s)]
*  critical in this connected age like they need to hold their own standards those [[01:09:59](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4199.36s)]
*  standards become resources from which other fields can draw and if you get to [[01:10:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4203.8s)]
*  the point where everything is interdisciplinary everything is post [[01:10:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4208.4800000000005s)]
*  disciplinary then you destroy the very intellectual dispositional and epistemic [[01:10:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4211.360000000001s)]
*  assets that themselves become building blocks and new knowledge it's just much [[01:10:17](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4217.16s)]
*  rather than a bunch of interesting little things just much no structure [[01:10:22](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4222.52s)]
*  that's right black hole okay good it's the end of the podcast so I'm just gonna [[01:10:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4226.360000000001s)]
*  completely change gears and give you a couple minutes to talk about the fact [[01:10:32](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4232.04s)]
*  that you and my old physics buddy Daniel Holtz teach a course at the University [[01:10:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4235.0s)]
*  of Chicago on the end of the world on the forthcoming doom this seems like a [[01:10:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4240.24s)]
*  like a you know bleak topic for a college course give it give us the sales pitch [[01:10:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4244.12s)]
*  for why we should be thinking about these ideas well I think if you look at [[01:10:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4250.8s)]
*  the mammalian kind of historical you know pre-historical record you find that [[01:10:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4256.4s)]
*  on average like the species lasts for about 3.5 million years and we're about [[01:11:03](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4263.799999999999s)]
*  you know I don't know one two hundred thousand years into our our lifespan [[01:11:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4270.16s)]
*  that means we should have 3.3 million years left if we're average we might be [[01:11:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4274.759999999999s)]
*  better than average we were smarter you know any of the creatures that went [[01:11:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4279.599999999999s)]
*  before but who thinks you know who's listening to my voice now that we can [[01:11:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4283.2s)]
*  project a thriving world in three million years right we haven't you know [[01:11:29](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4289.599999999999s)]
*  we can't think 20 years we're making decisions on like you know a next year [[01:11:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4294.599999999999s)]
*  basis on two years in on our competition between some other country in 15 years [[01:11:41](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4301.36s)]
*  you know the biggest plans are 2050 you know that's 25 years I mean that's that [[01:11:46](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4306.5199999999995s)]
*  you know like I think Dan Holtz who you know is a physicist and worked at Los [[01:11:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4312.08s)]
*  Alamos National Lab and it's very sensitive about you know the potential [[01:11:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4316.92s)]
*  for you know nuclear arms to get in the wrong hands the wrong place and to set [[01:12:00](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4320.6s)]
*  off a cascade of you know so I think he's thinking things could happen on a [[01:12:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4325.32s)]
*  very short time frame that could be cataclysmic and they're an increasing [[01:12:09](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4329.72s)]
*  number of those things because they're the flip side of powers yeah artificial [[01:12:14](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4334.08s)]
*  intelligence and environmental and you know nuclear powers that we're [[01:12:18](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4338.8s)]
*  controlling can get out of hand there can be lab leaks there can be you know [[01:12:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4345.76s)]
*  nuclear meltdowns right so the more powers we have the more ways we can [[01:12:30](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4350.360000000001s)]
*  destroy ourselves from my perspective is even if we destroyed ourselves in ten [[01:12:35](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4355.64s)]
*  thousand years it would still be 3.3 million years too soon you know we need [[01:12:40](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4360.04s)]
*  to build and why don't we think longer you know why don't we have a longer time [[01:12:44](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4364.72s)]
*  horizon it's because of the very specific evidence-based epistemic [[01:12:50](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4370.64s)]
*  standards that drive scientific advance like we have standards for what [[01:12:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4376.6s)]
*  represents knowledge and if we if you know for many fields you know in modern [[01:13:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4381.8s)]
*  economics if you haven't done a causal identification of a certain flavor then [[01:13:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4388.280000000001s)]
*  it is just it's just not knowledge it's like you just you can't even make the [[01:13:12](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4392.0s)]
*  comment like just get out of the room you know it's just not and it and so [[01:13:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4395.56s)]
*  we've got like this great scientific standards which have been very [[01:13:19](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4399.64s)]
*  historically useful for advance in our fields but are ill-fit for thinking [[01:13:23](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4403.56s)]
*  about alternative futures and these singularity events where something [[01:13:28](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4408.6s)]
*  melts down or something explodes or something takes over and it's all over I [[01:13:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4414.48s)]
*  mean we have a single experiment that we're running which is humanity and and [[01:13:39](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4419.68s)]
*  so we have to imagine alternatives in a way and with a precision that we have [[01:13:45](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4425.4800000000005s)]
*  never done before which invites us to explore new epistemic approaches and [[01:13:51](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4431.320000000001s)]
*  clue and including things like narrative including things like science fiction [[01:13:57](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4437.76s)]
*  and stories to think about possible futures and harms because of the risk [[01:14:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4441.160000000001s)]
*  that we're creating because of our increased power over the world so I [[01:14:05](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4445.92s)]
*  think I actually found the class therapeutic students came in with [[01:14:10](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4450.68s)]
*  anxiety about climate and about other issues and and in talking about them and [[01:14:15](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4455.6s)]
*  facing them and talking about you know policy possibilities and thinking about [[01:14:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4460.92s)]
*  alternatives we actually I think it conveyed to all of us a sense of agency [[01:14:25](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4465.24s)]
*  and possibility and and and also a long view you know we don't think about this [[01:14:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4471.56s)]
*  unfolding set of future possibilities and people and environments that that [[01:14:38](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4478.200000000001s)]
*  will be the inheritors of our choices today and so anyway that was the reason [[01:14:42](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4482.96s)]
*  for the class there's a tricky balance right because he wants to emphasize the [[01:14:48](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4488.160000000001s)]
*  very real worry that disastrous things could happen with the lesson that and [[01:14:52](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4492.6s)]
*  there's still things that we can do about it right there's still tools we [[01:14:58](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4498.6s)]
*  have to prevent it so you know be alarmed but don't despair right exactly [[01:15:01](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4501.96s)]
*  and I think talking through with experts from around the world about you know [[01:15:08](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4508.120000000001s)]
*  some of whom were despairing some of whom were busily engaged in in their [[01:15:11](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4511.8s)]
*  particular projects I think gave us an expanded view for how to think about [[01:15:16](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4516.160000000001s)]
*  talking about knowledge extrapolating from the singular experiment which is [[01:15:20](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4520.76s)]
*  humanity and this world in this universe you know all right you've given us an [[01:15:26](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4526.16s)]
*  expanded view James Evans thanks very much for being on the landscape podcast [[01:15:31](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4531.2s)]
*  thank you Sean it's been a pleasure [[01:15:34](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4534.5199999999995s)]
*  you [[01:15:56](https://www.youtube.com/watch?v=Az5I4IAS4CI&t=4556.16s)]
