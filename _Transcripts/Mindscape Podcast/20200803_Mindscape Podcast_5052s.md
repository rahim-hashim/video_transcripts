---
Date Generated: June 09, 2024
Transcription Model: whisper medium 20231117
Length: 5052s
Video Keywords: ['information', 'disinformation', 'statistics']
Video Views: 14149
Video Rating: None
Video Description: Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2020/08/03/108-carl-bergstrom-on-information-disinformation-and-bullshit/

Patreon: https://www.patreon.com/seanmcarroll

We are living, in case you haven’t noticed, in a world full of bullshit. It’s hard to say whether the amount is truly increasing, but it seems that everywhere you look someone is trying to convince you of something, regardless of whether that something is actually true. Where is this bullshit coming from, how is it disseminated, and what can we do about it? Carl Bergstrom studies information in the context of biology, which has led him to investigate the flow of information and disinformation in social networks, especially the use of data in misleading ways. In the time of Covid-19 he has become on of the best Twitter feeds for reliable information, and we discuss how the pandemic has been a bounteous new source of bullshit.

Carl Bergstrom received his Ph.D. in biology from Stanford University. He is currently a professor of biology at the University of Washington. In addition to his work on information and biology, he has worked on scientific practice and communication, proposing the eigenfactor method of ranking scientific journals. His new book (with Jevin West) is Calling Bullshit: The Art of Skepticism in a Data-Driven World, which grew out of a course taught at the University of Wisconsin.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x

#podcast #ideas #science #philosophy #culture
---

# Mindscape 108 | Carl Bergstrom on Information, Disinformation, and Bullshit
**Mindscape Podcast:** [August 03, 2020](https://www.youtube.com/watch?v=xh91ducr6_4)
*  Hello everyone and welcome to the Mindscape Podcast. I'm your host, Sean Carroll.
*  In fact, welcome to a special Bullshit edition of the Mindscape Podcast.
*  Now I know what you're thinking, there's probably plenty of other episodes of Mindscape which qualify as bullshit,
*  but this is not supposed to be a description of the episode, as a description of what the episode is about.
*  I apologize for anyone who finds the language a little bit colorful or spicy,
*  but bullshit has become a technical term in philosophy ever since the publication in 2005 of On Bullshit by Harry Frankfort.
*  The idea was supposed to be that bullshit is different than lying.
*  In lying, you know that there's some truth and you're telling the opposite of it,
*  whereas in bullshit, it's not that you're trying to tell untruths, it's just that you don't care what the truth is.
*  You have something that you want people to believe and that's what you're going to try to make them do.
*  So today's guest, Carl Bergstrom, is a biologist at the University of Washington who studies the role of information in biology.
*  Not especially information in some highbrow information theory sense, although there is that,
*  but how organisms use information, how organisms share information with each other and sometimes information that is not true.
*  Basically, even crustaceans and birds can bullshit each other in the correct circumstances.
*  So this naturally led him to study the flow of information in social networks among human beings.
*  And now it's made him an expert in the COVID-19 era of the amount of bullshit that we're hearing over social media
*  and even over respectable news organizations about what this pandemic is doing to us.
*  He's perfectly situated to talk about this because Carl and his colleague Jevin West have been teaching a course
*  that has now turned in to a published book called Calling Bullshit, the Art of Skepticism in a Data-Driven World.
*  It's especially about how we can use charts and graphs and numbers and data to make a case that is basically bullshit.
*  One of the features of the modern internet, highly interconnected world is that bullshit can both exist in new ways
*  and travel much more frequently and much more effectively.
*  So we need to understand both sides of the equations, both how to recognize bullshit when it's out there in the world
*  and also how to prevent ourselves from promulgating bullshit even if that's not what we mean to do.
*  So this is a fun episode. You will even see us do a little calculation in real time
*  and we'll get to both big picture issues about the nature of truth, but also directly relevant issues to the big crisis that we're all facing right now.
*  So remember, for those of you who don't already know, we have a Patreon for the Mindscape Podcast.
*  You can find a link to it at the website, preposterousuniverse.com, slash podcast, or just go right to patreon.com, slash Sean M. Carroll, and you can find it there.
*  We have enormous gratitude to all the Patreon supporters. My endless thanks to you folks out there.
*  You help support the podcast, keep it going, keep it vibrant, and Patreon supporters get ad-free episodes,
*  as well as the ability to ask questions for the monthly Ask Me Anything episodes. So with that, let's go.
*  Carl Bergstrom, welcome to the Mindscape Podcast.
*  Thanks a lot, Sean.
*  So you have a book that has come out called Calling Bullshit. That's the title, is that right?
*  That's right. Calling Bullshit, the Art of Skepticism in a Data-Driven World.
*  Yeah, we're going to have to put one of the caveats on this episode saying that occasional bad language will be used if bullshit counts as bad language, I suppose.
*  But just so everyone knows, I mean, it's an interesting journey. You're a biologist by training. You've studied how information comes into biology and the role it plays.
*  So I can kind of see how that segues into bullshit. But why don't you fill us in on how exactly that happened?
*  Yeah, it has been kind of an interesting journey. I started out trying to understand animal communication and wrote about animal communication a great deal as a PhD student.
*  Thinking about in particular what keeps it honest and why do animals tell each other the truth?
*  Because if they lied all the time, then they wouldn't listen to each other. But they do listen to each other.
*  So what is it that keeps communication honest? And they're a really elegant set of mathematical models that get at these kinds of questions.
*  And they're paralleled by really neat models in economic game theory.
*  And so that was what I was really interested in as a graduate student. From there, I moved on and started studying epidemiology, actually.
*  And did a postdoc in epidemiology. Started trying to understand how new is kind of unfortunately prescient, but how new diseases emerge from animal hosts into the human population and what happens then and what does that spread look like and what can we do about it?
*  And at the time I was really thinking about things like H5N1, avian flu and such.
*  And as I started studying more and more about epidemiology, I was thinking a lot about how things spread on networks.
*  How do diseases in particular spread through human contact networks?
*  Because if you just sort of treated disease as this mass action situation where all of the individuals are just bumping into each other at random, you don't get a very good picture of what disease spread actually looks like.
*  So I sort of took this detour and spent five years thinking about sort of the physics of networks and working on problems in network theory.
*  And as I started to emerge from that, we had all of the kind of current cultural issues going on about spread of misinformation and disinformation on social networks.
*  And so that brought together some of these things I'd been interested in for a very long time and it sort of kept working on it on a sort of back burner way about animal communication and about honesty and dishonesty and the economics of information.
*  And that brought that together with really thinking, trying to think clearly about networks and how information travels or anything else travels along networks.
*  And with all the stress that was given on the role of social media, with the spread of fake news and such around the 2016 elections, this became something I was really very interested in and started trying to work in that area.
*  And but it must be a slightly weird situation because you've written a book with your co-author Jevin West and based on a course that you've been teaching at the UW on calling bullshit.
*  And presumably, if I know how publishing works, in between when you handed in the manuscript and when it came out, we got hit by a massive pandemic.
*  And you were sort of positioned to talk about this in a useful way.
*  And now you're at least a minor Twitter celebrity as the go to place to have bullshit called on various takes about COVID-19.
*  Well, certainly it's been something that I've been trying to contribute during the during the COVID pandemic.
*  Yeah, I mean, you're right. We did hand in the manuscript before the before the pandemic broke out.
*  And it sort of feels like in some ways, the book was written in a in a different world in a different time and place.
*  On the other hand, it's amazingly relevant to everything that's going on right now.
*  And, you know, I think you rewrite the entire book, swapping out every single example in every chapter with something that's happening around COVID.
*  Because it's just these are the sorts of problems that we're dealing with, whether it's the misuse of sort of numbers and statistics to try to, you know,
*  basically push people around and intimidate people with, I got all these mathematical models and my models show this or my models show that or here are the figures.
*  And, you know, figures don't lie, which, of course, they do.
*  Or whether it's sort of the dynamics of the way that that social media leaves us vulnerable to disinformation being injected by foreign actors.
*  I mean, all of these things have turned out to be major players during the during the current pandemic.
*  And so, yeah, it has been interesting to to write this book and then and then find sort of immediate application for it, if you will.
*  I mean, there's no shortage of applications, of course. But yes, this is a particularly sharp example of some of these things.
*  I mean, but so let's you know, let's be scholarly about this.
*  What do you mean by the word bullshit? Because I'm sure that some people have slightly different ideas in mind.
*  Yeah. So when I talk about bullshit, I'm really talking about the the use of language or figures or statistical arguments that are intended to impress or persuade or intimidate viewer or reader with blatant disregard for the actual truth of these arguments that are being made.
*  So Harry Frankfurt, the philosopher who wrote the book on bullshit, which was this sort of originally a scholarly essay and obscure journal and then became a surprise bestselling little book through Princeton University Press.
*  He defines bullshit as as he distinguishes it from lying by saying, you know, the liar knows what she wants you to believe and tries to lead you there away from the truth.
*  And the bullshitter doesn't even care what you know about what the truth is.
*  The bullshitter is just simply trying to, you know, bullshit.
*  I mean, trying to often try to impress you or persuade you or something like this without even necessarily having the targets in mind.
*  So I think, you know, I think of an example, I think of like, you know, I think we all had this experience in high school of having to write an essay about about something in one of our humanities or social sciences classes.
*  We didn't really understand the reading that we had done and we'd left it until too long.
*  And we wanted to write something that would make it look like we'd understood it.
*  We didn't really give a damn what the teacher believed about whatever we were writing about.
*  But we did want to try to make ourselves look competent.
*  And that's kind of the epitome of bullshit in Harry Frankford sense.
*  So it's less I mean, maybe tell me this is accurate or not.
*  It's less about lying per se and more or less just not caring if what you say is the truth or not.
*  You have some instrumental goal in mind.
*  You're going to try to get there by saying whatever it takes to get that reaction in your audience.
*  Yeah, I think that's exactly right.
*  And, you know, very often that that goal, I think, has something to do with, you know, trying to impress someone or persuade them of your own competence or your own likeability or whatever that is.
*  And so is this something that hooks into your the biology research that you that you mentioned?
*  I mean, are there evolutionary reasons why we bullshit?
*  Because clearly it's it's prevalent. It's all over the place.
*  Yeah, that's right.
*  I mean, we talk about that in the in the leading chapter of the book.
*  And and we look at we look at sort of where you know, where where do these things have their origins?
*  And so it may be more along the lines of true straight up deception, more along the lines of lying than along the lines of, you know, Harry Frankford's type of bullshit.
*  But, you know, bullshit or or at least at least deception goes way, way back in the animal kingdom.
*  And we have we talk about some examples.
*  They talk about stomatopods, these crustaceans that that have these very, very powerful claws and they threaten each other and they fight with these powerful claws and they wave the claws around.
*  But they do something when they're molting and when they're molting, their claws are, you know, just basically, you know, a shelled lobster claw.
*  They're defenseless and useless, but they wave them around anyway and try to intimidate each other.
*  And it's often successful.
*  This kind of deception.
*  We talk about ravens and the way that ravens actually have a theory of mind and some of the experiments that show that ravens can can, you know, actually think about what other birds see and what they might be interpreting and the way that they use that to try to fool other conspecifics.
*  So, of course, you know, deception of that sort goes way, way back because, you know, information can be manipulating other organisms access to information is a very good way to manipulate their behavior and whether that's done by, you know, manipulating that access to information through a communication channel that sort of evolved for the purpose of communication or whether it's done, you know, through something like camouflage.
*  It can be a very effective way to, you know, communication channels in general give you handles on other people's behavior.
*  I tell you, how do I get you to do something, Sean?
*  I don't grab your arm and move it.
*  I talk to you and convince you that that's the thing that you want to do.
*  And so and so this goes way, way back.
*  And then as we move toward humans, you know, what we have that sort of unique in humans, or I believe unique in humans is we have this sort of infinitely expansible combinatorial language that allows us to create an infinite range of meanings and so forth.
*  And so we can we can talk about and we can we can construct all of these kinds of arguments and narratives and entire cognitive edifices in the world that we can use to influence what people do and think and so on.
*  And so we have all of that.
*  And then we have a quite well developed theory of mind about one another.
*  So we can kind of think about in advance how the stories that I'm telling you are going to manipulate your own belief states and how that might lead you to respond.
*  So when you put all of this apparatus together with the fact that human incentives are rarely perfectly aligned between you need two people, that creates the sort of setting in which we'd have a bunch of lying and a bunch of bullshitting as well.
*  I guess I'm going to guess that there is some game theoretic reason why when it comes to communication between individuals, you usually want to be telling the truth.
*  Otherwise, people won't believe anything you say, right?
*  There's some sort of optimum mixture of bullshit you should stick in there to maximize the chance that you'll be believed and also get what you want.
*  Yeah, that's spot on.
*  And I mean, we see things like that.
*  I mean, you see something like this even in a poker game, right?
*  That's what I'm thinking of.
*  That's my general paradigm for these issues.
*  Okay, yeah, exactly.
*  Right.
*  So you bluff some, but you can't bluff always.
*  And so otherwise people will call your bluffs all the time.
*  And it's the same when we interact in person.
*  And then the frequency of the interaction varies.
*  I mean, if I do a single appearance on your podcast, I may bullshit a lot more than if you're a close colleague that I deal with on a daily basis, that sort of thing.
*  I wonder if the incentive to put false ideas about the world in the mind of other individuals is pretty obvious to me.
*  What about putting false ideas about the world into our own minds?
*  I know that people have sort of debated how much we trick ourselves, but clearly we do in some sense.
*  Either we trick ourselves or at least we're not very good at always getting to the right picture of the world.
*  Yeah, of course there's a ton of self-deception that goes on.
*  And I think a lot of it, in my personal view, is actually due to relatively ineffective application of heuristics that we have to various ways of interpreting the information we have about the world.
*  There are certainly people that argue that actually you have sort of adaptive or optimal self-deception where you can actually perform better at certain problems or tasks if you believe things that are false and so on.
*  That to me clashes with an awful lot of what I think about our basic principles in decision theory.
*  I've not found those arguments particularly persuasive, but what is completely clear is that we're all very good at convincing ourselves of things that are wrong.
*  Though I just don't think it's necessarily optimal that we're doing so.
*  Well, I mean, that's interesting to me. Is it an open question or considered an open question? Is it optimal to be as correct as possible?
*  Well, in decision theory you would certainly, for whatever your objective function is, you'll do better if you have correct information than if you have incorrect information, making say Bayesian decisions based on that information.
*  Similarly, in decision theoretic context, not in a game theoretic context, but if you're just trying to make a decision that doesn't impact anybody else, more information is always at least as good as less information and usually better.
*  Things get a little bit more complicated when you move into a game theoretic context. You can definitely have situations where getting more information can hurt you.
*  It's less obvious to me that getting false information helps you in those kinds of situations.
*  But there are people that argue especially that there are constraints about what we can do.
*  Humans can't bluff well, so the only way to be effective at bluffing is to believe the thing you're bluffing about, for example, would be one argument.
*  So we've evolved the ability to self-deceive in order to be better bluffers. I don't understand why we didn't just evolve to be good bluffers and believe that truth.
*  I mean, I guess this is off topic, but it's just fascinating to me. Is there some sort of group selection argument we could put down to say that for any individual they would be best off getting the most accurate view of the world possible?
*  But within a species or within a community, if some people are wrong, there's some benefit to that. Like they act in crazy ways that benefit the group because of their adventurousness or something.
*  As an evolutionary biologist, I tend to be pretty skeptical of group selection arguments without really, really hard quantitative backing because they just typically don't go through.
*  The basic problem with the group selection arguments are what George Williams brought up, a great evolutionary biologist, and he said, well, look, sure, that might be true that a group that has a mix of people, the ones that have crazy ideas and ones that don't, does better than a group that all has sensible ideas.
*  But within that group of people with crazy ideas and reasonable ideas, which ones do better? Well, the ones with reasonable ideas do better.
*  So pretty soon you lose the genes for having crazy ideas go away to massively oversimplify things and pretend that they're genes for having crazy ideas. But you see what I'm trying to say about this?
*  I do. I do. And yet so many people have incorrect ideas about the world. So we have to work to understand this. Good. So back to bullshit then. Is there like a categorization? Is there a grand Aristotelian theory of kinds of bullshit?
*  You know, there have been, it's remarkable. There's been quite a detailed exploration of the nature of bullshit in the philosophy literature since Frankfurt's original paper. There is not a taxonomy that I'm completely happy with. There are some kind of fundamental debates that come out in that literature.
*  One of the really important ones is bullshit in the mind of the speaker or the mind of the beholder. In other words, does intent matter? And so there are arguments that go in both ways. For Harry Frankfurt, intent very much matters.
*  And for some other authors, you know, it's like, I mean, it's a statement. It's on paper. It's just the text. It's bullshit or it's not. Which is it? So these are the kinds of things people are carving up. I don't know if there's sort of a grand taxonomy of bullshit in any other sense.
*  I mean, I guess then the two strategic questions are, how do we avoid being bullshitted? And then maybe the slightly naughtier one is, how do we become better bullshitters when it would benefit us?
*  Yeah, I mean, both of these are interesting, valid questions. It's kind of been a challenge, too, as we've been thinking about. We've been teaching this course, Calling Bullshit, since 2017. And one of the things we've been kind of thinking about is, you know, how do we make the world a better place with this course instead of just simply training people to be better bullshit artists?
*  So let's see, to get to the sort of first question, how do we avoid being bullshit? I think we're actually quite good at that for what I'd call old school bullshit. And old school bullshit is the kind of weasel words that you'll hear from, you know, company spokespeople.
*  It might be a sort of a political speech. It's sort of just taking rhetoric and words and maybe this notion of poultering that people use to kind of, you know, bend the truth or get around the truth enough to have, you know, plausible deniability or diffuse away the direct responsibility by using passive voice and all of this.
*  And we're I think we're pretty attuned to that. We're good at picking that kind of thing up. When people are bullshitting, we know it and we wince and people have a natural distaste for sort of weasel wordery and all of that.
*  And what the book is really about is that there's this stuff that I call new school bullshit and that comes clad in the trappings of science and in particular in the trappings of numbers and statistics and kind of figures and machine learning algorithms and all of that.
*  I think that we are more susceptible to this because first of all, it's a relatively new thing. The world's so much more quantified than it was 20 years ago for reasons we could talk about.
*  You know, second of all, I don't think the education system is really doing as much to train us to be tuned to this kind of quantitative bullshit that's that's out there. And third, I think there's this feeling that we have that numbers are somehow more real or objective than words.
*  Or opinions and they're kind of they're fuzzy and numbers are these hard things that come straight to Nate from nature. And of course, you know, that's not true. And then, and even when it is true, there's so much flexibility in the way that people present numbers and facts and figures that they can give you true numbers but make you feel completely differently about them depending on how they're presented.
*  So that's really what we're trying to do in the book is to say, Look, you know, we're assuming that you know, when when the corporate spokesperson is just bullshitting their way out of taking responsibility for something but but it's a lot harder when somebody comes rolling in with a statistical analysis and waves that you're facing you don't quite you know, you've never learned that kind of analysis or you don't remember what it does if you have learned it, you know, then how can you challenge them?
*  Yeah, I mean, I guess I want to get to the quantitative stuff, because obviously, that's it's fascinating. But maybe I'm a little bit less optimistic than you are about the old school bullshit. I mean, for the examples that come to mind are just hugely grandiose claims from sketchy sources, which in my experience, people are really willing to buy. And as a physicist, you know, people on the street come out saying, Oh, I've solved all of physics. And there's a remarkable number of
*  people who are like, Okay, we should take that seriously. Or recently, just as we're recording this, The New York Times had a story about UFOs being captured by the Pentagon. And people like, Oh, we should definitely pay attention to this.
*  It is really interesting. You know, I this this, I just curiosity, I went to a heterodox science conference that was held on the campus of the University of Washington, because essentially, because the university is a public institution, and anybody cannot use our facilities. And I was I was quite interested to see what what what was going on. Of course, every person there had either, you know, disproven general relativity or had, you know, unified
*  it with quantum theory. And, and, and, and so it was very interesting, they're, you know, they felt that there was this conspiracy by by by big science, to sort of, to sort of cover up the problems with, with with modern astrophysics and quantum theory, and so on, which was interesting in its own right. But the thing that was, I think the most interesting to me was that the rhetoric they used was very much the many of the things that we've essentially
*  tried to teach our students in classes to be skeptical, you know, to say, you don't want to just don't take this for granted, you know, ask, and somehow, it was just this sort of misapplication of those principles, which are quite reasonable principles that that had led people down the wrong path, you know, coupled with various delusions of grandeur and deep misunderstandings about how science works. That that had led you to this place. So I see, I see what you're saying, especially as a physicist, how you would
*  feel feel vulnerable to this, you know, it's, there's, there's, there's, there's, there's nothing, you know, glorious about figuring out about, you know, reversing the, the popular belief about the life cycle of the three toed river salamander. And so these guys don't come after that, but they sure come after, you know, grand unified theories of physics and such.
*  But I mean, can you, for our audience members who might be romantically tempted by these theories, is there a, is it's, I know that it's difficult to make everything boil down to an algorithm, but like, are there rules of thumb when we see a scientific claim outside our own area of expertise, like none of us has an area of expertise on all of science, right? But what are the warning signs that okay, maybe this is a little bit less reliable than something that we're
*  going to see something else might be?
*  I mean, you know, this is, this is, this is, I mean, I'm going to give you an answer that people will immediately, you know, people, contrarians will immediately say is an appeal to authority. But, you know, my, my answer is, if somebody makes a particularly, particularly someone makes a really shocking or extraordinary claim, you want to look at the, the venues in which that claim appears and the, and the credence that it's given by, by people who are well thought of.
*  In the field and, you know, and I think the, so if somebody, if, you know, if somebody actually was able to mathematically show that there were fundamental contradictions in general relativity, and we should throw the whole thing out and replace it with their new framework, you know, we would expect this to appear in, you know, better be in physical review letters and in science and better be in the newspapers and you have top physicists, you know, taking it very, very seriously. And to give you an example, I mean, you know, there are some people who are, you know,
*  people say, oh, there's a cover up, they'd never, they'd never do that. But of course, people do take these things very seriously. And when we had the cold, whole cold fusion story, there were a number of really good groups that that investigated that in great detail, even though it seemed like a fairly implausible claim. Because it's so damned important, if it turns out to be right, and it wasn't, you know, it wasn't patently wrong on the surface, even though it did raise some major questions that no one, you know, had answers to at the time, if it had been true. So, you know, I think one thing to do is just basically
*  look at the venues, look at who's supporting this and, and think that look, the world changing ideas may not come from, you know, the most important, most prominent people, but they will be relatively quickly embraced by some reasonable fraction of serious scholars in that area. And here, I think it just helps enormously to try to explain to people a little bit more about how, about how the scientific community works. It's not like we all, you know, go to a meeting and sit down and decide what
*  we're going to tell the public. It's, it's this very, you know, my goodness, no, it's this very red and tooth and claw world, right, where everybody is trying to scramble their way to the top. And there's, you know, enormous prestige and so forth to be had by, by getting in early on something that's right and disproving something else. And, you know, so if somebody had really made this major discovery, you know, that's a that and you're one of the first people to pick that up. That's that's that completely makes your career and and people
*  can jump on that. So anyway, I think that's maybe might help with dealing, you know, thinking about some of these sort of contrarian scientific claims.
*  No, actually, I think that's a wonderful point, probably the best advice you can give. I mean, people talk about the establishment or whatever, as if it's a monolithic thing. But the reality is, there's a bunch of people who are competing with each other, and they would love to find the new brilliant idea. So if some outsider scientist comes up with it, if it's at all
*  plausible, someone's going to jump on that. I mean, I think it's a very good thing to point out.
*  Yeah, absolutely. I mean, I think that's the you know, and if no one does jump on it, then then that that tells you something, right? Let's tell him. Yeah, this this heterodox conference was very interesting, because the one of the speakers there, one of the organizers actually said, you know, he was talking about what they needed to do to, to move forward. I mean, these are people that are passionately in love with science, by the way, these are not, you know, denialists or anything like that. I mean, they adore science, and they want to be they want to be part of it. But they're talking about what they need to do. And then
*  the organizer said, Well, one of the problems is when we have our conference, everybody's selling and nobody's buying. Everyone comes in and they've got their own personal theory. And it's almost as if everyone knows that no one else's theory is worth taking seriously. And that's so different from what science is, right? Because when we go to a meeting, you know, sure, we're selling, but but we are buying, I mean, there just be no point to go to, you know, a major society meeting, if you weren't there to buy, so to speak. Oh, yeah.
*  Yeah. No, I mean, I dream about, you know, small meetings with wonderful people and at which there are no talks, and everyone just sort of talks to each other. And here's what each other has to say, but
*  pretty much the ones I go to anymore. Well, I guess I used to go to and I don't know, I don't go to anything. I just log on to zoom in the morning.
*  So has, so you indicate the idea that the quantitative era that we're in now has sort of changed the nature of bullshit. I imagine that's both in the kinds of bullshit that we can get, but also in how we can spread it. I mean, what are the new kinds of bullshit that have arrived since we started to quantify the universe? So precisely?
*  Yeah, so I think, you know, I think there's just been a fundamental change in the last 20 years about how data and numerical arguments are introduced into the public discourse. And so, you know, if you look at newspaper articles from the 1980s, say, you know, when I was in high school,
*  you would not see a whole lot of data visualization, you wouldn't see, you wouldn't see, you know, just a whole lot of discussion of statistical arguments. If you did, you just say, you know, oh, the Fed did statistics. And here's the qualitative, you know, outcome or something like this, but you wouldn't go into these kinds of details. And you wouldn't, you wouldn't have, there's no such thing as data journalism. And, and, and we just simply didn't use numbers to, for persuasive purposes, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to, to
*  dining in games. Everything just kind of seems to be in sync.
*  Ben, when you mentioned data advisory itself and now having it in our 21st century, maybe which came more and moreGS
*  presentation, it gives usolf a sense of it's a Thrones, and, and the range of data economy has really just improvedですね and lasted.
*  data system has flourished. And we've actually been części is the way we do now. So much has changed in the last 20 years.
*  If we think about the availability of data compared to what, what was there even in the year 2000. I mean, first of all, we're all tracking
*  where we want to go and, and Tinder knows who we want to go
*  there with and all of this, right.
*  So all of this information is, is, is out there.
*  It's we're creating, you know, just unbelievable data sets.
*  So then the sort of AB testing that any of these companies can
*  do in real time on their user interfaces means that every
*  single one of these companies knows more about psychology than
*  the, than, you know, than sort of the collective discoveries of
*  the entire site community.
*  Um, at least about these, you know, very specific things about
*  what color buttons do people click on and, and what kind of
*  wording works well in headlines.
*  Um, and in fact, not only do they know that, but they know that
*  like tailored to each of us individually because of, so there's
*  all of that data and then there's all of the environmental sensing that's out there.
*  Um, you know, and then we have the internet of things.
*  And so, you know, my refrigerator is telling Google a tremendous amount
*  about how often I go to the grocery store because once a week, I leave it
*  open for, for 20 minutes when I load it in and my car down.
*  So just all of this data that we live in is, is, is a fundamentally new thing.
*  And we're taking that on, I think in the way that we, that we make persuasive
*  arguments about how the world works and about what we should do in the world.
*  And so when you look at, you know, even on a news broadcast, you see a ton of
*  data visualization, you know, the New York times has a large and extremely
*  talented data visualization team, a couple of dozen people that does these,
*  you know, amazing things.
*  Um, and I see all of that as really being a massive change in the last 20 years.
*  And I feel like our education system hasn't really adequately caught up to that.
*  And is the biggest problem that people misuse it or people don't know how to
*  use it when it comes to, you know, making persuasive cases on the basis of some
*  data sense?
*  I think that there's some of each, um, you know, I think there's, I mean, you
*  know, there are, you know, there are most, I think, you know, most of the people that,
*  that are putting material out there in say traditional media are, you know, good
*  actors at heart.
*  Um, however, we typically do have perspectives and we try to, uh, convey
*  those perspectives as powerfully as we can.
*  And I think that's completely fine by the way.
*  I mean, this is the same thing in science, right?
*  It's like, you know, part of why science actually works well is as we've talked
*  about, it's a somewhat adversarial system.
*  It's, you know, I would love to prove that you were wrong.
*  And that sets up these nice arguments where we each try to make our case as
*  well as possible.
*  And then the universe can adjudicate, uh, between us.
*  And so that's, so we do, anyways, we do the same thing in the, in the media.
*  Um, and even if we don't necessarily know, um, you know, all of the, the
*  black arts of, uh, of manipulating data and the stories that come out and, and,
*  and telling misleading stories out of data, we certainly kind of, you know, get
*  this, get an inclination as we're playing around with ways to display things.
*  Oh, well, you know, it sort of seems more persuasive.
*  Uh, you know, I want these numbers to look really big, so I'm not going to
*  write them down as percentages.
*  I'm going to write them down as absolute numbers, cause there's 330 million
*  people in the U S if I do that, you know, the numbers get big, you know?
*  Um, so you see these sorts of arguments where someone says, you know, uh, you
*  know, a thousand, uh, a thousand, uh, DACA recipients have been accused of
*  crimes against Americans, right?
*  And it sounds like this terrible number and, and, oh my gosh, a thousand crimes.
*  And, uh, then, uh, you know, what you're not, you know, what you, what you're not
*  pointing out is that that rate of, uh, of being accused of crimes is more than an
*  order of magnitude lower than American citizens, for example.
*  And, uh, you know, as we talk about those kinds of examples in the book, um, and
*  the, and we see this, you know, uh, I, I, you know, some of this may be malicious
*  and deliberate and, and a lot of it, I think is just people that, uh, that are
*  trying to make their case as well as possible and kind of, you know, doing that.
*  However, you know, it kind of, uh, you know, stumbling into some of these tricks,
*  if you will.
*  Well, the example that you just mentioned, I think, I mean, that is an
*  example, um, of a more general trend, tendency, whatever you want to call it,
*  uh, to people to not take either rates or fractions or proportionalities into account.
*  I mean, I read a, the thing that really bugged me as I read, uh, it's an article
*  about buffets and restaurants and, you know, how they're going away and, and
*  it would just say like, you know, oh, in this town, three people got sick at a
*  buffet, but there was no comparison to how many people got sick from other ways
*  or at non buffets or anything like that.
*  I mean, is this an example of a general principle that we should be keeping in
*  mind when we look at other people's data?
*  Yeah, I mean, we have, we essentially have a chapter on this in the book.
*  Um, and, uh, you know, uh, so some of the things that you describe, you know, there
*  are these, you know, people choosing whether to use percentages, uh, you know,
*  you can use percentages to, to, uh, um, so if you have a, if you have a really big
*  number, but you have a really big denominator and you want to make that big
*  number look small, you can report it as a percentage or vice versa.
*  Um, and you brought up another very important thing, which is that.
*  Numbers need to be presented in a way that allow you to make useful comparisons.
*  And when numbers are presented in ways that don't allow you to make useful
*  comparisons, that makes them almost by their very nature bullshit.
*  Uh, because if I just say, you know, Hey, look, Sean, um, you know, uh, 123
*  people, uh, you know, um, had a heart attack while listening to a podcast last
*  year, I really need to stop doing this.
*  Um, you, you, you might think like, Oh shit, you know, I, I need to rethink my
*  whole life, but, but, but, uh, not your whole life, but one, one little element
*  of your life, but in any case, um, uh, you know, but of course the right thing to do
*  would be to say, well, you know, how many hours are, how many hours did Americans
*  listen to podcasts and how many, uh, you know, how many heart attacks do people
*  have an hour and so on and cash that out.
*  Cause there's just, you know, if I just give you a number, you can't, you can't
*  possibly make meaningful comparisons.
*  And, and so, I mean, that actually, that's, I mean, this is really something we're
*  talking about a lot in the book is this, this sort of use of sort of quantitative
*  shock and awe where you just throw these numbers out there, um, and because you've
*  got them, it's really hard for somebody to come back and I, you know, if I make a
*  claim like that, by the way, I have no idea whether it's, you know, I'm off by
*  two orders of magnitude in either direction, but, uh, um, but in any case,
*  so if I make a claim like that, it's really hard for you to respond right away
*  because, you know, unless you're super good at firmly estimation, which you may
*  be, um, you know, you're going to, you're going to, you're going to struggle to,
*  to be able to come back and say, you know, oh yeah, well here, here is the right
*  denominator. And when you do this division and here's the comparator.
*  And, uh, so, you know, one of the things that we're really encouraging people to
*  do is when they're, when they feel like they're getting pushed around by numbers
*  like that is to, you know, take a step back.
*  Um, you know, we talk a little bit about Fermi estimation and how you could sit
*  down and do that calculation and, uh, and, and figure out whether a number like
*  that should be, uh, you know, something that's frightening or whether that's
*  entirely to be expected, um, et cetera, or just, or, you know, alternatively just
*  run a quick Google search and work something like that out that way.
*  Um, maybe for the listeners, you can fill them in on, uh, what a Fermi
*  calculation actually is.
*  Oh yeah. So Fermi calculations are, uh, it's just this notion of doing a sort of,
*  you know, back of the envelope, uh, quick estimation of the rough order of
*  magnitude, sort of what power of 10 is a, is a particular, um, quantity and
*  named after Enrico Fermi, who was very, very successful, uh, very skilled at this.
*  And, and I find it a very, very, uh, useful technique whenever I'm confronted
*  with, uh, with, with these various, uh, you know, um, numerical claims, uh, to,
*  to just see whether, you know, is this even, um, in the ballpark of plausible?
*  Um, and is, and then also, uh, if it is in the ballpark of plausible, is it
*  anything I should be surprised by?
*  You know, um, and so I can sit down and you could, you could say, well, people
*  live for roughly a hundred years as a certain number of people in the United
*  States, they must be dying at a certain rate.
*  Should I be surprised that people die while listening to podcasts?
*  Exactly.
*  Yeah.
*  Yeah, that's right.
*  You say, and you try to do it and you know, what we encourage for Fermi
*  estimation is that you don't get sort of hung up, you know, just to get it roughly
*  right, you could, uh, you could do it, uh, you know, just use powers of 10.
*  And so, uh, so I mean, we can even do it.
*  We can even do that one live and then you can cut it out if it doesn't work.
*  But, uh, you know, so, uh, so, so, so what do you think people live for a hundred
*  years?
*  I'll agree with you on that.
*  Um, uh, what fraction of Americans, you know, a 10th of Americans are podcast
*  listeners, shall we say, and, and, uh, of these, of these podcast listeners, um,
*  you know, they,
*  yeah.
*  You think they listen 10 hours a week?
*  Okay.
*  So, uh, order magnitude.
*  Yeah.
*  Yeah.
*  Order magnitude, uh, uh, 10 hours a week.
*  Let's, let's have them, uh, let's, let's have them, uh, listen.
*  Um, let's see.
*  Yeah.
*  Okay.
*  So, so then, so then they've got, uh, um, you know, then, then you've got
*  500 hours of, of listening, um, a year and, uh, so I shouldn't be trying to do
*  this live the, uh, make it a hundred hours a year if it's, the numbers would
*  be easier.
*  Yes.
*  You can see, I see you listen a hundred hours a year and, um, and, and, but of
*  course off the top of my head, how many hours in a year, um, that's what it
*  gets hard, right?
*  Right.
*  Right.
*  Right.
*  Right.
*  Exactly.
*  Because we don't live in a sensible universe for years or a thousand days
*  long, geometric.
*  This would all be so much easier, you know?
*  So, uh, yeah, uh, but let's leave this in, but not 10,000.
*  Okay.
*  Yeah.
*  We, you can cut this one out, but you know, 10,000 hours in a year, they're
*  listening for a hundred hours.
*  Um, so, you know, there's a one in a hundred chance if somebody dies in a year
*  that they're listening to a podcast while they do it, um, you know, and now,
*  uh, now you've got 300 million Americans, 330 million, uh, 330 million Americans.
*  So we're going to have, uh, you know, well, here, here, here, here, here, here,
*  here, your Americans live, you know, lives exactly a half a log between,
*  between your powers of 10, which is always unfortunate in doing these
*  calculations, but, uh, but you, you know, so, so, so let's, so let's say you've
*  got, uh, um, let's, let's say that's three million Americans dying a year,
*  one in a hundred of them is, uh, is dying while listening to a podcast.
*  If they're a podcast listener, it's only one in 10 of those.
*  So one in a thousand of the, of the three million Americans that die a year
*  listening to a podcast.
*  So one in 3000, uh, uh, uh, so, so you have about 3000 podcast deaths due to
*  heart attack or podcast deaths a year, not all due to heart attack.
*  And then we can say, well, you know, one in 10 Americans dies to heart attack
*  and we get one in 300 and, and, you know, so it's the same order of magnitude
*  as the one 23 that I threw at you at the start.
*  Yeah, I know.
*  That was pretty good.
*  Yeah.
*  I hope you'll cut that all out, but that's, but you, but you really, cause
*  I'm going to keep it in there.
*  Cause I think that this is, you know, it's a,
*  it's fine.
*  Yeah.
*  I mean, it's a wonderful, you know, I just did, I'm doing these videos these
*  days on, uh, uh, some of the big ideas in science and believe it or not, I got
*  the periodic table dramatically wrong.
*  I said the beryllium was the third element rather than lithium.
*  And you know, I got some comments saying like, Oh, that was my favorite part
*  because you made a mistake.
*  I love that.
*  Yeah.
*  That's, that's totally true.
*  That's, uh,
*  seeing how the sausage is made is very, very useful.
*  I think it is useful actually.
*  And it's kind of fun to do, right?
*  I mean, it's, yeah.
*  And it's a demonstration that it's doable.
*  Like, and it's also, you know, there is the fact that your IQ gets cut in half
*  when you stand in front of a blackboard or get on a live podcast.
*  So this is certainly true.
*  That's a few people should cut slack for that.
*  But, you know, so part of this is, is, uh, how we get the data and what we do
*  with it in our individual brains.
*  But I know that you're interested in the sort of ecosystem questions as well.
*  And there are a lot of journalists or more broadly people sharing
*  information who are not trained, who have not taken your course.
*  Um, is there some realistic aspiration that we can just train up all the
*  citizens in the country or in the world to think a little bit more carefully
*  about statistics and rates and things like that?
*  I think if we're going to keep using social media, I don't
*  think we have an alternative.
*  Uh, and the thing about social media, right?
*  Is that we had this, and we talked about this as well in the second
*  chapter of the book about the way that sort of, uh, the way that information,
*  uh, production and distribution has changed, uh, you know, not only sort
*  of the volume of information and its rate, but also what kind of
*  information is out there.
*  And so there's been this, there's this, you know, fundamental change,
*  essentially for most people in the 1990s, where, uh, where all of a
*  sudden you go from having, uh, you know, the, you know, you basically, you get,
*  you get, uh, you know, the internet plus digital type setting, and now everyone
*  can create professional level content.
*  Um, and you add the web on top of that, plus the acceptance of worldwide web.
*  You don't even have to know LaTeX.
*  And then you, uh, you, you add, um, you know, so then you're starting
*  to get all this, you know, new content.
*  And we were all very excited about this in the 1990s, cause it was going to
*  bring all these voices to the table that maybe hadn't had the political and
*  social and economic capital to be there.
*  And, and to some degree that promise has been realized.
*  Um, but what we also got, of course, is this enormous glut of
*  information and we came to all these problems about how do we sort through it?
*  And one of the solutions that we've come to, especially given the sort of
*  acceleration at which, you know, about the rate at which this information is,
*  is produced is, is through social media, where, uh, we all take on the role of
*  becoming editors for one another.
*  And so all of a sudden I have this really important role in determining
*  what my friends read or, you know, uh, given the amount of time I'm spending
*  on Twitter these days of a lot of people I've never met and what, what, what,
*  what, uh, you know, and what they read, but we're all doing this.
*  And so we're, we're all filtering information in this way.
*  And we're all doing the things that professional editors used to do.
*  And one of the big problems is, you know, we, you know, not only don't
*  we have the training, but we also don't have the same incentives, uh, that
*  professional editors do in terms of, you know, protecting our reputation.
*  And, and, you know, we may be trying to signal something about our group
*  identity by sharing a meme instead of like, you know, trying to signal
*  something about the truth.
*  Uh, but in any case, because of, because we're using a information exchange
*  system where we are all playing this role of editors, um, people have to, I
*  think if we're going to have, you know, reasonable information hygiene out there
*  in the world, people have to, you know, what we suggest in the class is they
*  have to learn to think more, share less.
*  Right.
*  And, uh, and, and, and, and how to think carefully about what they are sharing
*  before they, before they share it.
*  And it was the sort of, as I see it, there's kind of three approaches you can
*  take to this problem in the social media university, you could try to throw
*  technology at it and, oh, we're going to have AI that can detect fake news.
*  And while that might get you to deal with a VC, I don't think there's any
*  chance you're going to be able to actually make that happen, uh, because
*  there's a power of adversarial AI and everything else, um, you know, even,
*  even if someone were able to do it for the current, you know, as, as things
*  stood now, it would be easy to overcome.
*  So, and then you could try regulation and you could, you could try doing
*  things like many places have of sort of criminalizing misinformation and so on.
*  And as a pretty strong advocate of, of, um, uh, very, uh, broad, uh, uh,
*  interpretation of first amendment rights.
*  I don't like this solution.
*  Right.
*  I would like to see some regulation over the tech, you know, of the tech
*  industry to make sure that, uh, that we have some control of individual users
*  of what we see, uh, but other than that, I, I, you know, I don't want to.
*  Go down that road and the sort of the third leg of the stool that I
*  see there is, is, uh, education.
*  And, and that's the only one that I think we can really stand on is to help
*  people, uh, understand better how to parse the media environment that we all live in
*  now and a big part of that is sort of media literacy and, and, and that kind of
*  education, but, uh, at the same time, as we move toward this increasing, uh,
*  uh, quantification of our world, I think this quantitative literacy becomes
*  very important as well.
*  But I guess what I worry about with that, I mean, I agree with everything you said,
*  but, um, the pessimist in me says, well, the biggest problem is not people who
*  want to get the truth, but don't have the quantitative education to do it, but
*  people whose incentives are to do something other than get the truth, you
*  know, to identify with their tribe or whatever.
*  And, and media, social media make that so much easier in some ways than it ever was before.
*  I don't have a rebuttal to that.
*  I mean, we've slammed very, very hard into that during the, uh, during the
*  COVID crisis.
*  And that's something that actually, uh, we never really anticipated or saw coming.
*  I spent the 20 aughts, you know, doing pandemic planning work.
*  And while there were a lot of, uh, you know, debates, uh, you know, in the
*  scientific community and in the political, uh, setting about, you know, what
*  role should the government versus the free market have in planning for rare
*  you know, health disasters and so on.
*  We all assumed that if something like this ever broke out, everyone would be on
*  the same page.
*  Uh, and we just try to get the, get this thing done.
*  And instead, you know, of course we find ourselves in a world where the very
*  existence of the virus is a politicized issue, whether masks work politicized,
*  does hydroxychloroquine work politicized.
*  And this is really bonkers because if you sort of think about it, I mean,
*  there are a lot of things where if I said, oh, hey, you know, Sean, there's
*  going to be this crisis in two years.
*  Here's what the crisis is going to be.
*  Uh, some people are going to want to do this response or then the left or the
*  right, you'll say, oh, military intervention.
*  They're on this side, right?
*  If I said, you know, Hey, Sean, there's going to be a pandemic and some people
*  are going to want hydroxy chloroquine.
*  You've got no way to tell me whether that's going to fall on the left or right.
*  Right.
*  This is just, there's no reason to politicize that it doesn't make any sense,
*  but it is this tribal allegiance that you're talking about.
*  And it is facilitated by, uh, um, you know, by social media.
*  And it's been an enormous problem, uh, in our national response to, to COVID,
*  because you get things like, you know, people refusing to wear masks simply,
*  uh, to signal, uh, their, their, uh, their tribal affiliations.
*  Yeah.
*  I mean, it seems as if I've never really thought about it in these terms, but it
*  seems as if there's some, um, uh, stew of interactions that spiral you down
*  between number one, the ability to bullshit and quantitatively in this, uh,
*  data-driven world we're in.
*  Number two, the ability to spread the bullshit through the social media.
*  And number three, the partisan or identity affiliations that make your
*  allegiance to a certain statement stronger than your allegiance to the truth.
*  And, uh, somehow we got to change the incentives so that somehow people are
*  punished for giving into that.
*  I think that's, you know, I think that is the sort of thing that, that is happening.
*  You know, uh, my colleague, Joe Bach Coleman and I have sort of, you know,
*  not completely jokingly said that the answer to the Fermi paradox, you know,
*  the fact that there are no, uh, you know, we, the fact that we don't see evidence
*  of intelligent life anywhere out there is not that people invent nuclear weapons.
*  It's they invent social media.
*  And it launches you exactly into that, uh, not people, aliens, but it launches
*  you exactly into that spiral that you're, that you're sort of describing.
*  And that could be an existential threat.
*  We have a somewhat more serious paper that we're working on about, uh, we call
*  human collective decision-making as a crisis discipline.
*  You know, the idea is, is again, this, this same sort of thing.
*  It's like, once you network people and you have all these tribal affiliations,
*  um, you know, what happens, what happens to the way that information flows,
*  what happens to the ability to have an informed electorate?
*  And these become things that, you know, we were working on this before COVID and,
*  and thinking this was going to be a real problem.
*  And, you know, it's one of those papers where now everyone doesn't, it doesn't
*  seem nearly as prescient when you publish it after it's already happened.
*  Well, we shouldn't blame, put too much blame on Facebook and Twitter at all.
*  I mean, you also mentioned things like Ted talks or self-help books, or there's,
*  there's pre-existing set of ways that we bullshit ourselves and each other.
*  That's for sure.
*  You know, there's, you know, it's, it's by no means the, uh, you know, sole domain of,
*  uh, of, of social media.
*  I think that's, you know, I keep coming back to this partly because of this interest.
*  I talked to you about at the start about, uh, the way that information spreads through
*  networks. And I find that so fascinating. It's really, you know, the, the patterns of
*  information flow are so fundamentally different from these highly centralized patterns where,
*  you know, you have the, the Ted foundation or whatever it is that, you know, hand picks,
*  some, um, you know, people to groom into media stars and then puts them up and, and, and, and,
*  you know, teaches them how to give a 10 minute talk that, that, uh, starts with a, uh, a
*  problem and, and, uh, you know, ends up with this techno-optimist solution and it has three
*  jokes along the way at, at minute two, seven and nine and, and so on. And then, uh, uh,
*  and then, you know, broadcast that in a central broadcast fashion. And then it's just absolutely
*  so different from the dynamics of what we see playing out on the internet. Uh, when, when,
*  you know, which can be at really enormous and powerful scale as we see things like the dreadful
*  information around the plandemic video and so on, um, taking off. So understanding those dynamics
*  are so fascinating to me. That's why I keep coming back to it, but absolutely. I mean, the seeds of
*  all of this, uh, you know, predate social media, there have always been, uh, um, you know, there've
*  always been charlatans and hucksters and, and all of this. And a lot of that, uh, takes the form,
*  I think of, of bullshit rather than of just outright lying because a lot of them just want
*  to impress you and make you think, wow, that, that person's really smart. That person's a thought
*  leader that, you know, whatever. Well, yeah, the thought leader terminology is a good one because
*  it once again comes back to the incentive structures. I mean, I know that there has been a
*  lot of discussion in recent years on the role of public intellectuals. And one claim is that we
*  don't have public intellectuals anymore. All we have are thought leaders and the difference being
*  that the thought leaders are a little bit, uh, more beholden to, you know, certain patrons who
*  will pay them to say optimistic things about technology or whatever. And it's a little bit
*  less rigorous and scholarly than the public intellectual model. Yeah, that's very interesting.
*  I think that, that, I, you know, I, I, I've just heard it now, but I buy it, uh, it's on a first,
*  on a first, on a first thought. Yeah. So I guess there's not much intellectual about a thought
*  leader as the other. Um, well, yeah, I mean, I think it's, I don't know what the, uh, origin of
*  the phrase thought leader was. It might be something that was originally very sincere and, and now has
*  been, uh, given so much irony layered on top, but, uh, it might be Dan Dresner. It was, it was,
*  who made that? Who was it? Sorry. Daniel Dresner, maybe. Oh, okay. The place I know it was, uh, you
*  know, in the, in the nineties, um, this was, uh, this was the term for, uh, that, that, so basically
*  it was what the pharma companies use to, uh, to influence what doctors do, uh, and for their
*  prescribing practices. It's too expensive to get things, uh, to get, uh, uh, on label uses approved
*  through FDA. But what you can do is you can have people, uh, give talks at meetings about off label
*  uses, which then doctors have the right to do. And thought leaders are the people that people look up
*  to who are, uh, who would, you know, be able to give a compelling talk in front of an audience of,
*  say, 5,000 or 10,000 at a major medical conference. And so a thought leader was
*  precisely the person that pharma would seek out to give a talk about off label use of their product.
*  But that's interesting because that, so to the extent that that's true, built into the idea was
*  the idea that it was more for signaling purposes than for finding truth purposes. Absolutely. I
*  mean, that was the, uh, you know, and I don't know if that's the original origin. That's just my first
*  place I encountered it. Maybe I do want you to have a chance to say a little bit more, uh, about
*  solutions to the technology social media problem. I mean, you mentioned that there could be
*  intrinsically technological solutions or regulatory solutions and neither one of these
*  were things you're really optimistic about. I mean, maybe say a bit more about that. I know
*  that that's also very much in the news these days, especially with Facebook, Twitter, maybe a little
*  bit less, but, uh, Facebook, YouTube, there are algorithms that drive people to places where maybe
*  we don't want them to go. And maybe that is fixable. Yeah. I mean that, so, so this is a
*  really important issue and maybe we'll just start, start with YouTube, right? Is this well-known
*  effect that YouTube, uh, YouTube sort of radicalizes. And so, you know, YouTube pushes you toward more
*  and more extreme content. We talk about this in the book. There's a little story where Jevin and
*  his son are watching, uh, watching live feed from the international space station on YouTube. And then
*  on the sidebar are all these flat earth videos. And, uh, and so, you know, so this comes back to
*  the constant AB tests and the psychological experiments that, you know, these, uh, these
*  algorithms are figuring out, uh, that people move toward more extreme content over time. And there,
*  of course, all of these algorithms are being, um, you know, are optimized to maximize engagement, not,
*  education or accuracy or anything else like that. So, uh, you know, I think definitely that kind of,
*  uh, algorithmic direction is, is really important and really problematic. I mean,
*  we see something similar if you try to use Facebook or Twitter to, uh, get a good sense of, uh,
*  what the, what the, you know, general, uh, zeitgeist in the country is not just the zeitgeist among,
*  uh, the friends of a, you know, an academic in Seattle say. Uh, so I follow people all over the
*  country with different opinions and things like that. But, you know, Twitter quickly learns that
*  when, uh, you know, some of my right wing follows who I don't necessarily tend to agree with post
*  links, I don't click on them. So it stops showing them to me. And so then I, I, I get pushed back
*  into my own filter bubble, if you will. So, I mean, this is where I think regulation could be
*  somewhat useful is I'd like to see, uh, I'd like to see ideally, ideally it's sort of opt out, but,
*  but even opt in would be okay. I'd like to see people have a lot more control over the content
*  that they actually see on social media and things like this. I'd like to see these algorithms, um,
*  you know, the sort of recognition that these algorithms are not designed to, um, move us
*  toward this, uh, you know, extremely important, uh, um, uh, you know, feature of, of having an
*  informed electorate. They're designed for something else. And given that, um, and given this role,
*  these, these are playing essentially as, as, as major media companies, um, we need to have a
*  little bit more, you know, we need to downplay the influence that, that these algorithms are having.
*  So, um, you know, I'd like to see, if you opt in on Twitter, you should be able to just see
*  what your follow, the people that you're following have posted in order, you know, no, no bullshit.
*  And, uh, so these kinds of things I think would be, would, would, would be little steps that would,
*  that would move us in the right direction. I think they're, they're, they don't,
*  they don't trouble me in terms of sort of first amendment arguments. I mean, if you look back to
*  the origins of, uh, of the fair and balanced doctrine from the FCC prior until it was killed
*  under Reagan, uh, it was not something about bandwidth limitation per se. It was, uh,
*  basically that it was a synch with nonferred democracy was that people here, you have to have
*  an informed electorate. And so we need fair and balanced coverage of the issues that matter.
*  And so that was one of the other criteria there was that they, you know, the news stations had
*  to talk about relevant things. Um, and, uh, so, uh, I think that there's quite reasonable precedent
*  in the way we think about, about media to say that, you know, uh, another synch with nonferred
*  democracy is to have people able to get access to the information they want instead of being
*  manipulated by these algorithms that are able to run nonstop experiments on them 24 hours a day to
*  maximize their own engagement. So that would be, you know, kind of the, my ideal, there are these
*  little things you could do that would chip away at the problem, but would only chip at the way
*  problem. You know, it's like, why do we allow, uh, targeted political advertising on social media?
*  This is so dangerous. You know, I can, I can, you know, target all of the, uh, you know, I could
*  target all of the unemployed men between 35 and 45 and Tequila who have indicated racist sympathies.
*  Um, that's something we've never been able to do before. It more or less trivial to do on,
*  you know, with social media advertising. And then once I do it, that ad that I've put out there is
*  dark in the sense that if I run a national racist broadcast ad, everyone sees that I did it. But if
*  I just push a message to these 400 people, um, no one even knows that I did that. And I think that's
*  a really, really dangerous thing. We've got very strong restrictions on political advertising
*  overall. And so why we continue to allow this, I have no idea. I mean, again, a tiny piece of the
*  puzzle, but these are the sorts of places where I think regulatory solutions could be useful.
*  Has there anything that you specifically learned or changed your views about
*  since the COVID-19 pandemic hit? I mean, you've been, you've been out there on the Twitter front
*  lines trying to set people straight. Uh, is it more or less given that you're an expert in both
*  biology and bullshit, what you would have expected or has your world been rocked by how crazy things
*  have been? Uh, it has somewhat been rocked because I really did think we were all going to be on the
*  same, you know, all going to be on the same team when, when this thing hit. And, uh, I thought that,
*  I mean, you remember what things were like after 9 11, you know, like everybody just felt like we're
*  all Americans and we're going to put these political divides behind and we're going to
*  unite and we're going to solve this problem. And yeah, there, I mean, it wasn't, you know,
*  it wasn't blissful. There was a lot of, you know, uh, latent and not so latent racism that came
*  along with that. And it wasn't all good, but, uh, you didn't see the sort of massive hyper
*  politicization of just every aspect of the, you know, the crisis that we were dealing with. And
*  we did have this feeling of sort of a common, uh, goal. And, and, and when you deal with the pandemic,
*  of course, you may not want to admit it, but we really are all in this together because of the
*  infectious nature and the, of the, of the disease and the fact that these things spread exponentially
*  through communities early on and so on. Uh, and yet we've completely failed to address this as a
*  unified country. We're unable to, you know, not only are we unable to sort of mount, uh, come up
*  with, uh, uh, you know, widely supported consensus policies about what to do. We can't even agree on
*  things like, uh, whether this is killing one, one person in a hundred or one person in a thousand.
*  We can't agree on whether or not, uh, you know, school children are who, uh, who get it or risk
*  to their parents. We can't agree on whether masks help. Um, I definitely did not expect that level
*  of politicization of the science. And, uh, and, and, and, you know, I think some of the ways in
*  which that has, has happened have become quite interesting as you, as you look at what's changing
*  about the science, we've gone to, you know, in an effort to solve this problem, we've gone to this,
*  you know, most, you know, massively open science that we've ever tried where everyone is posting
*  raw data and preprints, uh, you know, immediately people are, are sharing all the code, all the
*  bottles are up there for the most part. There's some exceptions that are sort of notable, but,
*  but, uh, you know, it's, it's been much more transparent than it ever has before at much
*  earlier stages, whether the waiting till everything goes through peer review, the discussion is taking
*  place on open boards, on Twitter, on pub peer, places like that, instead of at conferences and
*  by, by private email. So all of that discussion is out there for the public to see. And the, you know,
*  the piece that I kind of hadn't really done an adequate job of anticipating was that as soon as
*  that happens and you have this thing super politicized, now every single paper that goes
*  out there lands on one end or the other of a political spectrum, unless you exactly split the
*  middle and sit on the rail. And as soon as that happens, you know, that paper gets picked up by
*  one side and used as a cudgel to bash the other side with. Uh, and so, you know, as soon as I
*  release a paper, like if my paper is just trying to estimate R naught for this disease, you know,
*  the intrinsic rate of increase, um, that paper is going to, you know, benefit the arguments of one
*  side and, and, and harm the arguments of the other. And all of a sudden it just gets launched
*  into this, into this partisan debate that we as scientists aren't used to. I mean, we're completely
*  used to the fact that, you know, you think R naught's two and I think it's three and I think
*  you're an idiot and I'm going to prove it, but it's, there's no partisan tie to this. And, and,
*  and so this new, uh, and similarly people will, you know, when, when your evidence overweighs mine,
*  people will just take your side. And now that this has become polarized like this, you know,
*  even if your evidence overweighs mine, no one's going to, you know, no one in my tribe is going
*  to take your side anyway, because they don't want to risk anyone thinking that they're in your tribe.
*  So I, so this is the part that surprised me and has been, um, you know, I guess in, in April,
*  I just found it enormously discouraging. And I think I've kind of accepted it at this point and
*  just, you know, trying to think about how to work in that environment now, but it was, yeah, that was,
*  that was a real shock. I mean, in addition to the sort of political or identity, uh, aspects of it,
*  I mean, there's, there's some sort of purely scientific aspects that are curious to me. I mean,
*  the idea of how to model, uh, the spread of an epidemic like this. And there's even been,
*  I mean, maybe this counts as politics, but there's been little squabbles like
*  economists versus epidemiologists and who has the higher GRE scores, right?
*  Yeah. Yes. Right. Right. Right.
*  Have we, have we learned, have you learned anything about that? Let's say, has that surprised you any?
*  I guess I already knew it, but I've learned you shouldn't hold George Mason against economics.
*  But, uh, um, you know, I think that's actually been more common. You know, I've done, you know,
*  I've been, I've, I've always loved doing interdisciplinary work and it's been tremendous
*  fun and, uh, and it's a learned, it's a learned skill, right? And one of the, one of the key
*  things to doing good at a disciplinary work is, is not assuming the other person's need even when
*  they sound like one, uh, because you're probably not understanding something, but it is something
*  you have to learn and, and, and, and you have to learn by, by doing. So I think you have a lot of
*  people that are all of a sudden coming from different communities, working on the same
*  problem where maybe they haven't done as much interdisciplinary work in the past. And so you do
*  see more of these, of these kinds of clashes, whereas, you know, you know, my own experience,
*  you know, it's like so much fun, you know, sitting down with a, with, you know, computer
*  scientists and having them tell me about game theory from their perspective. And you just think,
*  gosh, like everything this brilliant person has said for the last hour is wrong. How can they be
*  so dumb? And then you finally eventually figure out what the, what the difference in assumption
*  is, you know, you're thinking about, uh, expected case and they're thinking about worst case and,
*  and that clicks. And then, and then you, you know, then it all, uh, and if you, if you poison the
*  well before that clicks things, you know, you don't move forward. So I think, I think that's been the,
*  you know, I think that's been some of the struggle there. Um, and, you know, there,
*  you know, I don't want to, uh, to some degree, I think there are different disciplines that have,
*  you know, different cultures and different, uh, uh, perspectives of their own superiority already.
*  Um, that may be, you know, we may be bumping into a little bit of that too, but, uh,
*  I don't know. And you already mentioned the, the fact that some of the science is being done
*  out in the open. Um, but this is, there are issues. So not only is that being outdone out
*  of the open, but then it's instantly politicized, like you said, but these are not new things
*  because of the pandemic there. We're learning things. We're seeing things that were always
*  there, right? Is this more of a reminder that science is kind of messy and politicized and
*  we should keep that in mind when we evaluate any bit of science? I would, I would disagree. I mean,
*  I guess the, the first one thing I just want to note before I do that is that I'm, I'm acting
*  as if this is a surprise and all my friends in climate science are just thinking like,
*  you know, you, you, you poor innocent, like naive child, like what the hell did you expect?
*  Yes. And, uh, uh, because they've been dealing with this for, for, for decades. Um, and, and
*  the rest of us just kind of missed that. And I missed it even though I was not, um, you know,
*  even though I was actually involved in all this sort of evolution wars stuff, uh, in the, in the
*  early two thousands around, uh, around intelligence design creationism and all that. And I still,
*  still didn't anticipate this. Um, yeah, but I think science, uh, I think science is really
*  not politicized in the same, in the same way that we're, that we're seeing right now. I mean,
*  I think that, uh, you know, there are, there are areas where as you move toward,
*  uh, you know, applications, you start to see more and more of that. But I think what we talk about
*  as being political in, in science is really a, uh, quite different thing. Um, you know, I take,
*  for example, in my own home discipline of, uh, evolutionary biology, mathematical population
*  genetics, when we talk about sort of political fights, it often essentially come down to battles
*  between the, you know, great grandchildren of Sewell Wright and the great grandchildren of,
*  of R.A. Fisher, right? And it's, and it's absolutely remarkable. Actually, if you treat, you know,
*  my, uh, PhD advisor, Mark Feldman gives a great lecture where he sort of traces back these ideas.
*  And, and you actually see that we really are the great grandchildren, you know, having the fights,
*  continuing the fight between these two, between these two men. Um, and, and, and so that's really
*  politicized, you know, maybe it's like, you know, it's like, God damn guy is a selectionist just
*  through and through, I just don't understand how he could not see the way that epistasis works. And
*  as we talk about that as political, but it's a really different kind of political than, you know,
*  Trump thinks hydroxychloroquine will work and, uh, and, and, and damn the conspiracy that's trying
*  to cover it up. No, that's true. Just to, just to clarify, I was using politicized in the former
*  sense more, you know, nothing to do with right versus left, Republican versus Democrat, red versus
*  blue, but there, there are, uh, human attachments, whether they're, you know, or, or even just ways
*  that you were brought up as a scientist to pay attention to some things versus another that are
*  not completely rational that have huge effects over what we think is important and how we go
*  about doing even the most removed science from, uh, political cares in the real world.
*  Yeah, absolutely. I think that that's a really good observation. You know, a friend of mine,
*  Jacob Foster, who's in sociology at, uh, at UCLA and I spent a couple of weeks, um, trying to,
*  not making a ton of progress on this, but trying to understand whether an adversarial
*  model of science, you know, we have an adversarial, uh, model of, uh, of, of justice in this country
*  where you've got a prosecutor and a defendant, you don't have sort of consensus where everyone
*  sits down and decides whether the person's guilty or innocent. Um, and to some degree,
*  science is more adversarial than it's usually portrayed in the public because you do have these
*  different schools and these different, uh, you know, political camps in the sense you're talking
*  about. And so we were thinking about whether that could possibly actually be a good thing.
*  And I think it probably is. Um, and, you know, because it really, uh, you know, sharpens the,
*  uh, the, um, conflict among, among, uh, the data that we, that we, that we have, you know, you,
*  you rarely have direct observation of what you want to know. And so you have these various
*  indirect ways of trying to get at this, at this question and, and where there are conflicts there,
*  if everyone kind of just agreed to ignore them, we might not, uh, you know, make the same headway
*  as we do when you have, you know, this school is determined to prove that that school is wrong and,
*  and so forth. I think that's, I think that's all good and well, I think what's, what's been,
*  you know, so discouraging with the, with the pandemic is the way that, um, you see the,
*  you just see a whole different level of disinformation getting put out there. I mean,
*  uh, things that scientists would, would never do. I mean, I, you know, I may, I may really dislike
*  the, uh, the, the, you know, selectionists and population genetics, but I'm not going to make a
*  video where I tell lies about them. Nobody does that. I'm just going to try to write a paper that
*  shows that, you know, their, their, their interpretation of the data is stupid. And, uh,
*  so, so like, like this, just a whole different level. And I'm certainly not going to be, you know,
*  calling their universities and trying to get them fired and, and sending threats and all the other
*  things that public health officials in the United States are dealing with right now.
*  So that's, that's just sort of a different scale. Um, it's like, I don't, I mean, maybe it may,
*  this may just be, you know, a sort of, uh, uh, appeal to the conventions that I'm comfortable
*  with, but, uh, I, in some ways I'm kind of saying, you know, boy, people aren't fighting by the rules
*  this time. Well, emotions are running high and stakes are high, right? So even if I deplore it,
*  I get it. I'm not completely surprised. And even, you know, far removed from those kinds of stakes,
*  the, the, the examples that are close to my mind are like, um, loop quantum gravity versus string
*  theory. Right. And I do work and I worry about the, um, even though I'm pretty establishmentary on,
*  on many physics issues, I do worry about a lack of diversity, uh, viewpoint diversity here because
*  from a game theory perspective, if you think there's a 90% chance string theory is right and
*  a 10% chance that loop quantum gravity is right, every department is going to want to maximize the
*  chance that as people are right. So they will only hire string theorists, right? And it,
*  it's hard to build in that kind of, uh, multiplicity of efforts.
*  Yeah. A couple of my friends in the philosophy of science have written quite nice things about this
*  Kaylin O'Connor and, uh, and, um, Kevin Zollman, and they've written about, uh, about the, um,
*  the value of epistemic diversity in, in scientific research. And they, uh, you know, studied these
*  kinds of, uh, things where you have, say, epistemic networks, where people share their beliefs with
*  one another. And in fact, if you have this, you know, too tight of a community where people quickly
*  adopt one another's beliefs, you know, basically everybody can get off on the wrong track and
*  science doesn't proceed as fast. And so I think that's, you know, there's, that's a, you know,
*  very important observation. And, and this has really been something I've been very interested
*  in the last five years and then sort of got derailed by, by the, by the whole COVID crisis.
*  But basically like, you know, taking a hard look at the way that science operates and looking at
*  what are our institutions and our norms that we use and, and thinking about the way that those
*  norms and institutions create the incentives that, that, that, that shape our behavior and the
*  questions we ask. And of course that determines the outcome we get. And so there's this direct
*  tie from the structure of these norms and institutions, which evolved more or less haphazardly,
*  uh, you know, out of, you know, essentially enlightenment ideas, uh, and, and, and Western
*  Europe to, to the beliefs that we have about the world as emerging from science right now.
*  And so one thing we can do is we can go back and look at the structure of some of these,
*  uh, institutions, whether it's things like publishing or priority rule for credit or,
*  or the tenure system or whatever it is, uh, and ask, how are these things affecting,
*  you know, epistemic questions about, you know, what we believe to be true that is true, what we
*  believe to be true that isn't, what, you know, what we, what we don't know is true, even though it is,
*  et cetera. And, and thinking about, you know, are there ways to, uh, nudge the system to, uh,
*  to make it function better? You know, we see a lot of this going on as people are trying to
*  tackle the reproducibility crisis right now. And, um, you know, you can ask very similar
*  questions around issues such as, uh, as viewpoint diversity. Yeah. I mean, and the mentioning of the
*  reproducibility crisis brings up the previous thing you mentioned about how science is now being done
*  in the open more. And I know there's, there's also two sides to that. Uh, you know, science is being
*  done in the open a lot more in, including the fact that, especially because of the COVID crisis,
*  people are noticing that there are pre-print servers, right? You can get scientific papers
*  that haven't yet been peer reviewed. And on the other hand, something I've, I've, even though I'm
*  a believer in peer review, I do try to tell people that just because a paper has passed peer review
*  does not mean it's correct. You still need to be a little bit skeptical of it. I mean, do you think
*  that this greater openness is improving science or is it a danger? Cause I know there's a lot of
*  people who say it's terrible to let the hoi polloi in on all the speculations and preliminary ideas
*  that scientists around all the time. That's, that's gatekeeping bullshit that I completely
*  disagree with that. I agree. But it would be, it would be, you know, I mean, you're a physicist,
*  you know what it does to science when you open up pre-print servers. It blew my mind. The first time
*  I wrote a physics paper, I, it's a paper on, uh, it's a paper on network theory wrote with postdoc
*  of mine, Martin Rosfall. I was really excited about it. I thought it was, I thought it was neat
*  work and I really hoped I could get it into a good journal so that people would read it and,
*  and give me some feedback on it. Martin wasn't nearly as concerned about this. We posted it to
*  the, uh, posted it to the archive. Um, and within a week, every single person that I wanted to read
*  it had written me back, you know, unsolicited and had read the paper and had the comments that I was
*  hoping to hear, or in some cases critiques, I was hoping they wouldn't, you know, that wouldn't
*  exist and so on. But that was like, that was a revelation to me. So, you know, having pre-print
*  servers and, and, and, and, you know, having the time lag between putting an idea out there and
*  it being adopted by the rest of the community and being a few days instead of a year is, is
*  enormous, obviously. And I also think that, you know, this, this, this notion of gatekeeping is,
*  you know, and, and we shouldn't let the public see what's going on behind the,
*  the walls of the ivory tower. This is also absolute rubbish. What we could do a better job
*  of is explaining how the whole process works. And if we do that, then we have to hit on the thing
*  that you hit on as well, which is that, you know, peer review is no guarantee of, of, uh, correctness
*  either. What I, you know, what I think of peer review as, and this, we write about, we have all
*  chapter about science and how it works and all this stuff in the book, but, you know, what I think
*  of peer review as is I think of it as, uh, you know, kind of like burn in, in engineering, it is
*  enriching for things that are correct and interesting. Um, it's not guaranteeing that
*  anything is correct and interesting. It's just taking a bunch of the stuff that isn't correct
*  and a bunch of the stuff that isn't interesting and throwing that out. And you end up throwing out
*  a little bit of the stuff that is correct and interesting, but that's the cost of, of enriching
*  the pool of stuff that you see. And then of course, you've got this tier of journals from the highly
*  enriched, um, to, to the barely enriched and, uh, and you can sort through all of that and,
*  and the highly enriched maybe enriching for not the things you want. And people complain about,
*  you know, most of the stuff in science and nature is sensationalized and so on. And then, you know,
*  maybe the case where, you know, most of the stuff in cell is maybe enriched for being correct,
*  but not being very interesting or whatever, uh, depending on your, on, on your perspective. Um,
*  but I mean, fundamentally that's what peer review is doing. Um, it's helping improve the
*  papers as well and it's enriching the pools, but it's not, you know, it's, it's, it's not this like
*  seal of approval that we, um, that it's been presented to the public as unfortunately.
*  All right. Final question going to be completely unfair here. I mean, I know you,
*  you begin your book by saying that, uh, what is the, what is the sentence you use? You remember it?
*  Uh, there's, there's so much bullshit probably.
*  We are washing the world. The world's a washing bullshit and we're drowning in it.
*  World is a washing bullshit. So, um, and we've, we've mentioned a lot of
*  techniques that people can use, uh, offhandedly, but like, is there the best piece of advice you
*  have for, you know, we people on the street who are washing bullshit to separate it out? I mean,
*  is there like one or two, uh, pithy little things we can say, or is it more that we just have to
*  generally keep our wits about us and try our best? No, there are a few pithy things that you can do.
*  Um, you know, what, one of them is to just recognize that, uh, that if something, if some
*  claim seems too good or too bad to be true, it probably is. And, uh, so, so these are the things
*  that we're most likely to share, especially on social media. And yet they're the most likely
*  to be wrong. I learned today, only today that there's a, there's a law about this, which
*  twin men's law for data analysis is that any figure that looks interesting or different is usually
*  wrong. More unusual or interesting, the data, the more likely they are to have been the result of
*  an error of one kind or another. And this seems quite a reasonable law of data analysis. And it's
*  law of media analysis as well, I think, when you, when you think about it. So that, so that would
*  be one, you know, another thing I really push people on is, you know, especially in those cases.
*  And if you care, track things back to the source. So, you know, the way, one of the things that,
*  that emerges through, um, you know, through the social media environment, but we had even
*  beforehand, it's just exacerbated is that you have this sort of game of telephone where you have a,
*  you know, maybe you'll have a set of, you know, research studies that are distilled into a
*  scientific paper that is written up in a medium post that's picked up by the New York Times that
*  gets tweeted about. And then, and, and then you see the tweet. And so if the tweet seems too good or
*  bad to be true, start tracking back and finding the, you know, finding this, you know, figure out
*  for yourself what the story is. So I think, you know, the most important and the most important,
*  this is what we teach in the class. And the students get so excited, you know, I'll have
*  the students come in and they'll say, you know, oh, I saw this tweet from NBC news. And then I
*  tracked it back and it was, it was actually about this story. And the story came from this research
*  paper. And you know what, professor Bursch from it was bullshit. And, uh, which is so cool. And,
*  and when it done good, well, what it, you know, what it, what it gets at for us is, is a fear with
*  this class is that we create a, uh, you know, a community of Nellis and, and, and, and cynics.
*  Whereas what we want to try to do is to show people that despite the, uh, you know,
*  bullshit prone world that we live in, there is truth out there and you can get to it.
*  Yeah, that's a very good motto. I cannot possibly think of a better place to finish the podcast on.
*  So Carl Bergstrom, thanks very much for being on the mindscape podcast.
*  Thanks. It was great to talk to you, Sean.
