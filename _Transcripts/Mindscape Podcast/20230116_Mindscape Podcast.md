---
Date Generated: June 07, 2024
Transcription Model: whisper medium 20231117
Length: 4252s
Video Keywords: []
Video Views: 10512
Video Rating: None
Video Description: Patreon: https://www.patreon.com/seanmcarroll
Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2023/01/16/223-tania-lombrozo-on-what-explanations-are/

There are few human impulses more primal than the desire for explanations. We have expectations concerning what happens, and when what we experience differs from those expectations, we want to know the reason why. There are obvious philosophy questions here: What is an explanation? Do explanations bottom out, or go forever? But there are also psychology questions: What precisely is it that we seek when we demand an explanation? What makes us satisfied with one? Tania Lombrozo is a psychologist who is also conversant with the philosophical side of things. She offers some pretty convincing explanations for why we value explanation so highly.

Tania Lombrozo received her Ph.D. in psychology from Harvard University. She is currently a professor of psychology at Princeton. Among her awards are the Gittier Award from the American Psychological Foundation, an Early Investigator Award from the Society of Experimental Psychologists, and the Stanton Prize from the Society for Philosophy and Psychology.

Mindscape Podcast playlist: https://www.youtube.com/playlist?list=PLrxfgDEc2NxY_fRExpDXr87tzRbPCaA5x
Sean Carroll channel: https://www.youtube.com/c/seancarroll

#podcast #ideas #science #philosophy #culture
---

# Mindscape 223 | Tania Lombrozo on What Explanations Are
**Mindscape Podcast:** [January 16, 2023](https://www.youtube.com/watch?v=DGU2ItybIIU)
*  Hello everyone and welcome to the Mindscape Podcast. I'm your host,
*  Sean Carroll. It's very natural when things go wrong, when something is very different than
*  what you were led to expect it would be, to demand an explanation. To ask, why is it like this? What
*  is the reason why? The explanation for the state of affairs that you didn't expect. But what does
*  that mean exactly? Does an explanation mean some causal connection between one event or another?
*  Or is it a way that the world is? If you remember back when we talked to Judea Pearl about cause
*  and effect. And Pearl of course is one of the world's experts in teasing out what causes lead
*  to what effects in all sorts of messy situations in the real world. He claimed that babies spend
*  their time making causal maps of the world. Saying if I poke this, it reacts in this other way. So
*  what exactly is going on not just in babies but in grownups also when we human beings construct
*  this image of the world or this model of the world which says this is an explanation for this
*  other thing over there? Well today's guest is Tani Lambroso. She's one of the world's experts
*  in exactly this question. She's a psychologist at Princeton University and her lab at Princeton is
*  called the Concepts and Cognition Lab. Which I love that as a name. I would love to work in the
*  Concepts and Cognition Lab where she studies what an explanation is. What do we mean when we say
*  here's the explanation for that? What should we mean? What are we talking about philosophically
*  as well as psychologically? Do people agree on what explanations are good? Why do we want them?
*  What is it psychologically that moves us to burst into the room and demand an explanation for
*  something? I like it because it's not only a psychology topic but of course it has something
*  to do with the structure of the world out there. The fact that there are things in the world that
*  we accept as explanations is an interesting fact all by itself. And there's other things that
*  someone might say when you demand an explanation which most of us would go, no that doesn't really
*  work. Going down to very detailed questions for example at the intersection of science and
*  religion when you say why is there something rather than nothing? And someone says well God
*  made it that way. Is that a good explanation? Does that satisfy you? Should it satisfy you?
*  And I'm not telling you what the answer is. I'm saying these are very good questions. We're
*  going to get into it so let's go. Donnie Lambroso, welcome to the Mindscape Podcast. Thanks for
*  having me, Sean. So you work on explanations which is something that to me sounds like very
*  natural for a psychologist to work on. It's always funny to me when I read psychology papers
*  and they say like this is actually an understudied area of psychology and I think that yours is one.
*  Is it true that explanation is an understudied area of cognitive psychology? I think it depends
*  which types of explanations you're thinking about. So two communities have thought about
*  explanation for a long time. One is social psychologists. They've been really interested
*  in how we explain our own behavior and other people's behavior and there's decades of research
*  specifically thinking about explanation in that context. And another community that's been really
*  focused on explanation is educators, people thinking about educational psychology and learning,
*  and explanation in those contexts. I think what's newer is people appreciating how fundamental
*  explanation might be to our everyday cognitive lives, not just in the social domain but more
*  generally. So I and many other people as well I think over the last two, three decades have really
*  focused on new questions related to explanation but drawing upon what we know from social psychology
*  and educational psychology. And so but is your work then in the in the domain of cognitive
*  psychology? I consider myself a cognitive psychologist although as with any demarcation
*  between disciplines the boundaries get a little bit fuzzy and I think they should not be very
*  well sharply drawn. I think what's most distinctive about the approach that I've taken to thinking
*  about explanation is that many of the questions I'm interested in are the ones that arise in the
*  context of philosophy. So philosophers of science have been interested in explanation for a very
*  long time, overwhelmingly thinking about the role of explanation and science but not exclusively.
*  And I think if you take seriously the idea that there is some important connections between everyday
*  human cognition and what we do is everyday researchers trying to make sense of the world
*  and what scientists are doing in their quest to make sense of the world, then it's very natural
*  to think that the kinds of questions that arise about explanation in the context of science and
*  philosophers of science have been interested in also have analogs in the context of just everyday
*  human cognition. I did want to ask you about that because I can imagine the philosophers want to
*  know what explanation is and you know what's a good explanation whatever whereas I might imagine
*  that psychologists are also interested in how we do explanations, how we start doing explanations
*  as children and things like that. So do you see quite a bit of overlap and intersection there? I
*  think that's right. So I think philosophers have asked largely what explanation is and also what
*  explanations should be. So asking a more normative question. I think those questions are also
*  relevant for psychology but on top of that we might want to think about where explanations come
*  from developmentally. But also one of the things that I've asked a lot in my own work is what do
*  explanations do? And I think that might be a more useful entry point for starting to think about
*  this, right? So rather than first defining what an explanation is and then maybe thinking about its
*  consequences, we can ask what do explanations do for us? Why are we the sorts of creatures to explain?
*  What's the function of this activity? And perhaps by getting a grip on that, on the role of
*  explanation, on what explanations do, we can then work backwards to thinking about what explanations
*  are, right? So rather than starting from a definition, sort of starting from a functional
*  role, what explanations do? And if I recall correctly, there's even the possibility that
*  much as in physics you could get feedback from the science end into the philosophy end. I think that
*  in one of your papers you're saying that this philosopher made the following claims about our
*  intuitions about explanations. So we tested them and it turns out those are not our intuitions.
*  Yeah, that's right. And we've done that across a variety of projects and sometimes we find that
*  our results accord very closely to what philosophers have said and sometimes we find interesting
*  departures. And of course, whenever that happens, there's an interesting question. Is it just that
*  humans are wrong or is it that philosophers are wrong? I think it varies case by case.
*  Do the philosophers then listen? Is it an active in practice back and forth between your work and
*  those of the philosophers? That's an interesting question. I think it really varies by what
*  question philosophers are asking and of course, which philosophers. There's a huge variability
*  in the field as I'm sure you know better than I do in the extent to which people engage with
*  empirical work of various kinds and in philosophical work. But I think it does vary. I can give you an
*  example if you'd like of a case where I think there is interesting crosstalk back and forth.
*  So one area where epistemologists in particular have been really interested in explanation is
*  in the context of what's called inference to the best explanation. And this is something that I
*  think most people kind of intuitively are familiar with. Sherlock Holmes claimed that he engaged in
*  deduction but a lot of the time what he was doing was really inference to the best explanation. He
*  was looking at a bunch of evidence and trying to come up with what would best explain that body of
*  evidence and on the basis of that concluding that that explanation might be true. So that's a pattern
*  of inference that we see in science but we see all the time just everyday cognition. And one question
*  might be, you know, when ought we to engage in this kind of reasoning? Right? Is it ever normatively
*  warranted? Is it a good kind of reasoning or is it a mistake? And I think there's truth to both of
*  those things. There's conditions under which it's good and conditions under which it's bad. But
*  there's an interesting dialogue that's happened back and forth between some of the empirical
*  evidence and some of the kinds of normative claims that epistemologists might make that have to do
*  with thinking about what the goals of that kind of inference might be. So you might think our goal
*  in engaging in certain kinds of inference like this might just be to be as accurate as possible,
*  meaning that we want to sort of like minimize our long-term inaccuracy. We just want to like in the
*  long run get things right and we want to have practices for updating our beliefs that mean that
*  we're going to in the long range be at least raw. And if you have that view you might think that what
*  we ought to do is something like apply what's called Bayes' rule based on inference from
*  statistics. It's sort of a rule that tells us how to combine our prior beliefs with the evidence we
*  have in order to arrive at what they call a posterior probability. Now it turns out that if
*  you look at human explanation, evaluation and so on and these processes of inference is the best
*  explanation, there's some systematic departures from what Bayes' rule tells us that we should do.
*  No.
*  Yeah, I know, I know. I'm sorry. I'm sorry to be the bearer of bad news for somebody who wants to
*  advocate that. But I'm happy to say more about what those look like. But the interesting thing
*  is, you know, so philosophers could just say, well, I guess, you know, laypeople are just wrong
*  about this. They're doing it poorly. But I think a really interesting idea that's been proposed is
*  maybe the thing humans are trying to optimize isn't long-term inaccuracy. Maybe it's something
*  else. So what might that something else be?
*  What might something that as I guess as just what I was going to ask, you know, human beings evolve
*  under evolution, natural selection, you know, reproductive fitness and things like that. So in
*  some sense, the answer is always reproductive fitness, right? But I could imagine that having
*  an accurate and predictive model of reality helps with my reproductive fitness, right?
*  Yeah, that's right. So the one of the proposals and there's a handful of people who've argued
*  for this under the banner of sort of explanationism, is that maybe what we want to do is get things
*  mostly right in the short term rather than being least wrong in the long term. And that's something
*  that I think you can imagine trying to motivate in terms of reproductive fitness. We don't know if
*  we're going to be around long term, but if we can get things mostly right in the short term, that
*  might be the standard that actually matters. And it turns out that if that's what you're going for,
*  you shouldn't always use Bayes' rule. Sometimes you should do something a little bit different.
*  You might also think that what we ought to do depends on our cognitive limitations as humans,
*  right? If we just don't have the cognitive capacities that allow us to engage in certain
*  kinds of statistical inferences or very complicated kinds of mental computations, you might think that
*  we ought to employ the kinds of shortcuts that are going to be good enough given the cognitive
*  machinery that we have. And so that's another idea that I think again makes sense within an
*  evolutionary context, but gives us goals for what we're trying to do that look a little bit different
*  from, for example, just applying Bayes' inference. Yeah, I mean, thinking and being cognitively
*  careful both takes a lot of energy and a lot of space, I guess, a lot of neurons, but also time.
*  And maybe you don't have time when the lion is bearing down on you to think too hard about what
*  to do next. That's right. That's right. And so being fast, being efficient, having sort of
*  heuristics or mental shortcuts for arriving at conclusions might be very beneficial. And that's
*  some of what we see in terms of the explanations people prefer, right? So for example, one of the
*  things that we've looked at in my lab is people's preference for simpler explanations. And you might
*  imagine simpler explanations are easier to process, easier to remember, easier to arrive at,
*  and so on. And so you might see a host of these benefits. So I was going to ask, and maybe that's
*  the answer, what are the systematic deviations from sort of perfect Bayesian reasoning that we
*  might expect in real human beings? Right. So there have been a handful, and I'll tell you just a
*  couple for which we have the most evidence. So one of them is that there is some evidence that people
*  seem to be more sensitive to the evidence than they ought to compared to Bayesian inference,
*  meaning that they will converge to an explanation that fits the data well more quickly than they
*  should, and consistent with this idea that they're trying to get to what's probably right fast.
*  Interesting. Okay. In my own lab, one of the things that we have looked at, as I mentioned,
*  is simplicity. And the way we've tried to get at that in psychology experiments is by giving
*  people scenarios where there's one or a couple of effects that they observe, and they're trying
*  to come up with the best causal explanation. So they're trying to come up with an explanation
*  that cites one or more causes that generate those effects. And under those conditions,
*  if you know the probability of the causes and you know the probability of the effects given the
*  causes, you could just do the math. And so in some sense, we kind of have the ground truth for what
*  the right pattern of reasoning would be if people were just doing what's most likely. But what we
*  find is that although people are very sensitive to the probabilistic evidence, they choose simpler
*  explanations more often than they should, where we define simpler explanations as those that involve
*  fewer causes that are themselves unexplained. So for example, if you have two symptoms that you can
*  explain by appeal to one disease or by appeal to two diseases that each just cause one symptom,
*  you find that people prefer the single disease explanation more often than they ought to,
*  given the probabilistic evidence that they have. Physicists certainly act that way,
*  but maybe it works in physics in a way that it might not work in medicine or everyday life.
*  Yeah, it's an interesting idea. In our lab cases, we want to know what the ground truth is, right?
*  So we set things up so that we have some basis for saying what's most likely or what's not.
*  But in most real world cases, we don't have the ability to cleanly say when people are getting
*  things right and when they're getting things wrong. And so what we could be seeing in the lab
*  is the overgeneralization of a strategy that actually maybe does make a lot of sense in a lot
*  of real world cases. I mean, in the physics cases, I'd be curious if you have a thought on
*  are physicists right to be doing this? Are they wrong to be doing this? Has it helped
*  scientific practice of theorizing for them to show a preference for explanations that
*  have this kind of structure? I think it's a big ongoing debate, to be perfectly honest,
*  especially in my little corner of fundamental physics, where progress is a little stalled
*  these days. And so people are debating different methodologies based on their personal preferences,
*  right? And some like I have a strategy, which is to step back and think about the foundations
*  in a more philosophical way to make sure that we're on a firm ground where we do our further
*  down the road reasoning. Other people are just going to switch fields and come to some area
*  where they can come up with a better explanation and test against the data. And others are going
*  to argue about beauty and math and all these things. So that's why I was asking you.
*  It's physicists love what works, right? And when some strategy works for one problem,
*  they declare victory. But the next problem is always different. So we don't know.
*  Yeah. Yeah. And I think the everyday cognition cases are hard. If I had to guess, I would say that
*  there are many cases where preference for explanations with a structure, in fact,
*  does lead us astray. Right. But that's a guess. I think it's very hard to quantify that in everyday
*  cases. Well, as a psychologist, is there an understanding of psychologically why we are
*  driven to seek explanations? Is it just that there's a part of the human brain that is naturally
*  curious or which sounds kind of lofty almost like we're naturally curious creatures? Or is it more
*  down to earth, do you think? So we definitely have evidence that basically from the moment kids have
*  the language capacities to ask questions, they are asking questions. And a lot of those questions
*  are what I would call explanation seeking questions. So it seems like it's an early emerging
*  human capacity. And we know it plays an important role in human learning. So what I've argued in
*  some of my work, and I think other people have argued for things along similar lines, is that
*  it is a pretty basic human capacity. And it plays a very important role in learning in particular.
*  And so I think the one version of that is very obvious because it's so familiar to our everyday
*  experience. But then once you dig into it, it gets a little bit more peculiar. So one thing to think
*  about is that I think it's very straightforward why there would be some sort of adaptive benefit
*  for humans to be good predictors, for example. Right. If we could predict what's going to happen,
*  that's clearly very beneficial. We can anticipate our circumstances. We're going to know what's
*  going to happen if we intervene to bring something about and so on. But explanation's different from
*  merely predicting. Explanations are typically backwards looking. So we observe something that's
*  already happened. And then we wonder, why did that happen? And we try to figure out what happened in
*  the past. So it's maybe not super obvious why it is that we would have this practice of trying to
*  explain things and of wanting things with a particular type of explanatory structure
*  if the thing that's actually useful for us is just to be able to predict. And so what I've argued is
*  that actually we can make sense of why explanations have some of the capacities they do, some of the
*  characteristics they do rather, in this backwards looking sense, where the thought is that our
*  explanatory practices and looking for explanations actually helps us construct the sorts of intuitive
*  theories about the world that are going to help us predict down the line. Okay. So to give you,
*  here's one example of something along these lines. So one of the phenomena that I'm really
*  interested in is that we seem to learn better by explaining to ourselves or to other people. Right.
*  Which is a little bit puzzling because when you explain to yourself or to somebody else,
*  you don't get new information. Right? If you give me an explanation, you've given me something new,
*  but if I'm explaining to myself, I'm just rearranging the pieces that are already in my head.
*  So what's going on there? So we construct all of these lab studies where we compare people who are
*  learning some task by explaining to themselves versus doing something else like thinking aloud
*  or describing some sort of control or comparison task. And we find that the people who are
*  explaining to themselves actually learn better. They learn certain kinds of regularities in the
*  environment better than those who don't. So for example, they're more likely to identify
*  subtle patterns that differentiate two categories that they're trying to learn to differentiate.
*  Sorry, can you elaborate on what the two choices are? Like one person is seeking an explanation,
*  the other person is doing what? That's right. So it varies across experiments because there's
*  no perfect control condition. But to make this all more concrete, suppose you come into the lab
*  and you're in one of these experiments, your task is going to be to learn to categorize new types of
*  robots. Okay. I'm going to show you eight examples of robots. Four belong to the Glorp category and
*  four belong to the Drent category. So you're going to have four labeled examples of each type of
*  robot. And you're going to study these in order to figure out how to differentiate Glorps and
*  Drents because I'm going to show you some new robots later and you're going to have to tell me
*  if there are Glorps or Drents. So I'm looking for the pattern. Exactly. So everybody in our task is
*  basically trying to find what the pattern is in these stimuli that will allow them to generalize
*  to new cases. So here's what we manipulate. Half the participants as they're studying the Glorps
*  and the Drents get asked an explanation question. So we ask them like, why do you think this one's
*  a Glorp? Why do you think this one's a Drent? And they try to come up with an explanation and we
*  don't tell them if they're right or wrong. So they're not getting any feedback, but they're
*  engaged in explanation seeking. And we compare what they learn to participants in a control
*  condition. And the control condition we varied across studies, it could be describe this Glorp,
*  describe this Drent. So they're being forced to use language, they're being forced to pay attention
*  to the task. We could ask them to think aloud, just tell us what you're thinking as you are studying
*  this Glorp or Drent, or we could give them no instructions at all, but give them an opportunity
*  to study so that everybody basically has the same task, has the same data. Now we design the
*  stimuli, these Glorps and Drents or whatever we're studying in that particular experiment,
*  so that there's some relatively subtle pattern that you might discover that differentiates the
*  Glorps and Drents. There's other things going on too, but maybe it only accounts for half of the
*  Glorps and Drents or 75% of the Glorps and Drents. The only thing that it counts for, you know,
*  that all and only the Drents have versus all and only the Glorps is this sort of subtle pattern.
*  And what we find is that the participants who are prompted to explain are significantly more likely
*  than those in these alternative conditions to discover that. So what's going on there? Well,
*  it looks like by virtue of the fact that they were trying to explain, they learned something
*  real about the structure of these stimuli. And they learned it faster and better. Sorry?
*  They learned it faster and better than they would have otherwise.
*  That's right. That's right. That's right. And so it seems like there's something about
*  human explanation seeking that at least for particular kinds of structure in the world
*  might be especially good at making us formulate useful hypotheses, test them in effective ways,
*  and come up with sort of a good way of characterizing some real generalization in the world.
*  And this is a place where you might think simplicity is beneficial even if the world
*  is not simple. By virtue of trying to find a simple pattern, we might sort of look harder
*  and try harder and discover whatever structure is actually there even if the structure that's there
*  is not itself simple. And in the Glirps and Drents, are the patterns that they will ultimately find
*  ones that they can interpret kind of functionally for the robot, their little robots, so they have a
*  pre-existing idea of what robots might do or is it just like this one has stripes and this one has
*  spots? We've done the studies both ways. So sometimes they're totally arbitrary features
*  that don't seem very meaningful. So for example, some of them have feet that are pointy at the
*  bottom and some of them have feet that are flat at the bottom. You can come up with reasons why
*  that might matter for being a Glirp or a Drent, but I don't know a lot about Glirps and Drents,
*  so probably not. In other versions, we actually give people more information that would allow
*  them to make that be meaningful. So for example, we tell them that some of these are indoor robots
*  and some of them are outdoor robots. And now all of a sudden you can kind of come up with some
*  reasons why foot shape might matter. Maybe they'll scratch the wooden floor if they have pointy feet,
*  but that makes sense on a different type of material. And what we find there is that explaining
*  makes you more likely to discover the sort of simple pattern that accounts for all cases either
*  way, but that when you have this rich background information, you use that more when you're trying
*  to explain. And I think that makes sense when we think about explanation in everyday cases. A lot
*  of what explaining looks like is trying to make sense of new observations in the context of what
*  we already know. We're trying to sort of like fit it in to what our existing beliefs and intuitive
*  theories of the world are. And so when we prompt people to explain, we see them doing that more.
*  They're sort of trying to come up with a story about like why pointy versus flat feet would make
*  sense given that they're indoor versus outdoor robots. I mean, maybe this is a crazy over
*  generalization, so correct me if I'm wrong, but it seems that over and over again we see examples
*  where we have an idea of what acting in a perfectly rational way would be and human beings come close
*  to it, but not really because they're doing something completely different than being
*  rational for completely other reasons, but nevertheless the reasons have led them to sort
*  of mimic rationality in some kind of way. Yeah, no, I don't think that's an over generalization
*  at all. I mean, I think that's a really interesting way to think about this. In this particular case,
*  one thing that I've come to think is that there might be a story about why it's rational to prefer
*  simpler explanations, for example, or explanations with other kinds of structures,
*  but it's not the one that we might have thought. So I think the intuitive idea is the idea that I
*  think Newton advocated. He has this lovely quote in the Principia which is something like,
*  you know, he says we should basically prefer simpler explanations because
*  nature affects not the pump of superfluous causes. So the thought is something like if nature itself
*  is simple, then we should prefer simpler explanations because those simpler explanations are more likely
*  to accurately reflect nature. And so that would give you one reason why preferring simpler
*  explanations would be rational. And I'm skeptical of that one. I'm really skeptical of that.
*  But I think what our data might suggest is that having the practice of preferring simpler
*  explanations might lead you to learn about your environment and look for particular types of
*  structure in your environment in a way that might have the positive downstream consequence
*  of leading you to discover the structure that's actually there. And so it's almost more like a
*  methodological strategy to get you to the right place, but without the assumption that the world
*  is itself simple. It's rather that having humans be sort of picky about explanations is going to
*  be something that motivates us to go out there and figure out what's really going on. Because
*  the world is a weird mixture of simple and complex, right? As a psychologist, I'm going to say more
*  complex than simple, but yes. We have to work hard to find the simplicity, I guess, is the point
*  I'm trying to make. And we do, like you just said. I guess I didn't want to let go of the intriguing
*  thing you said about explanations being mostly looking backward in time rather than predictive
*  in some sense. I mean, it makes me think of mystery novels. We love mystery novels. I love mystery.
*  And mostly the detective is trying to come up with an explanation for something that happened
*  in the past without necessarily helping us predict the future on the basis of that. But
*  can we conceptualize it as part of a larger strategy that if we know why all these murders
*  are committed, that will help us in the future? Or is there something else going on? I think there
*  might be two things going on. So I think sometimes we care about the backwards looking part,
*  because we want to hold people causally or morally responsible. Right? And there it seems like
*  that judgment is really playing almost more of a social role in how we regulate other people and
*  interact with other people. So that's important. But I think also the practice of explaining why
*  particular events occurred is going to be part of what allows us to construct a causal model of that
*  domain or just more generally sort of a theory of that domain. And then it's the theory of that
*  domain that will allow us to predict things in the future. Right? So to give a toy example,
*  you might imagine that by virtue of trying to figure out a particular murder in this detective
*  story and so on, somebody comes to learn something about human motivations that they
*  didn't appreciate before. They come to learn something about how particular poisons work
*  and how you can mask the effects that they didn't know before. Right? And so they come to learn all
*  of this particular stuff. And that actually might be useful in the next case. Maybe not narrowly
*  for preventing another murder, but it is contributing to your repository of knowledge about the world
*  in ways that is going to be useful in the future. Yeah, I guess I'm actually interested in this
*  because I don't know why the mystery genre, I mean, in some sense, almost all genres are subsets of
*  mysteries, right? Like things happen and we don't know why we want to fix them. And it has a very
*  powerful hold on us psychologically. And I'm willing to buy that it stems from the same impulse as the
*  impulse to understand and predict the world going forward. Maybe that is it. Or maybe there's
*  extra ingredients being fed. Yeah, I think that's right. I love this example. The case I thought
*  about a little bit more is something like riddles. Right? We find riddles extremely satisfying.
*  We're very curious about the answer to riddle. We're very satisfied when we get the answer to a riddle.
*  But it's hard to make the case that riddles play a fundamental role in human learning. Right? It
*  sort of seems like it's the candy of the system. And I think the mystery novels might have some of
*  the same characteristics, right? They mimic some of these cases where we really are prompted to
*  find an explanation and where that's really central to our ability to learn about the environment.
*  So they sort of push all the right buttons without necessarily giving us the same
*  adaptive consequences that we may be seeing the explanation case. But by virtue of that structure,
*  we do feel drawn in. We are very curious. We do feel very satisfied when there's a good resolution.
*  Another thing I don't want to let go of is the relationship between explanations and causes.
*  Causality is something that philosophers debate a lot about. We had Judea Pearl on the podcast
*  some time ago. It's a whole subfield of understanding causal influences on things.
*  Is it okay to think about the search for explanation as mostly a search for the cause
*  for why something happened? Or is there a division between those?
*  As I'm sure you know, there's a debate about this in philosophy. And I'd say,
*  probably in psychology as well, my own view is that a lot of explanation is causal, but not all
*  explanation is causal. I think one of the clearest examples of non-causal explanation is mathematical
*  explanation. Right? So they can give an explanation for the Pythagorean theorem,
*  and it doesn't look like there's anything causal going on there. And so, you know, I think that
*  raises the question about the relationship between the causal cases and the non-causal cases.
*  Are there really just fundamentally different kinds of explanations? I'm more attracted to views
*  that think that it's really very similar across these kinds of cases, that explanations in general
*  produce understanding that the nature of human understanding involves something about appreciating
*  dependency relationships of a particular type. And there might be multiple types of dependency
*  relationships. Causal dependency relationships are a really important type that characterize
*  huge swaths of what we care about, but they're not the only type. You know, things can be
*  kind of a deductive or an entailment relationship in the case of math, things could have a
*  constitutive relationships. So I think there's actually lots of other kinds of relationships
*  that can support explanations and explanatory understanding. But by and large, the ones that
*  I've studied are the causal cases. And I think those are the paradigm cases we typically think
*  about. Well, it's interesting, because of course, we don't agree on what constitutes a causal case,
*  and some people are going to say, well, Pythagoras' theorem is true because of the
*  postulates of Euclidean geometry. And to me, that's a very different notion of the word cause
*  than the person died because they were stabbed by their friend or whatever. I mean, we're using the
*  same word, but these are very different philosophical concepts, I think. I think that's
*  right. I mean, I think it's tricky to interpret because causally. We use because in all sorts of
*  ways, and at least I would hesitate to say that they're all causal. We did some research in my
*  lab that tried to narrow in on a part of your question. So we thought, what's the most minimal
*  contrast between a cause claim and an explanation claim? And so we had cases where, for example,
*  A causes B or B because A. And so the thought is they're kind of as close as possible, basically.
*  But one's an explanation talk and one's in causal talk. And we found that these two behaved very,
*  very similarly in terms of what sorts of evidence people thought was relevant for assessing whether
*  or not the claim was true. But we did find some differences, right? So these weren't identical.
*  So here's where maybe I'll give you a concrete case so you can get an intuition for how these
*  worked. So we wanted cases where there were causal factors where people would not antecedently think
*  were related at all. So one of our cover stories involved, you had to imagine that you've gone to
*  work for a museum and one of your tasks is to tabulate lots of data about the museum,
*  who visits which exhibits and what they do and so on. And you just notice this correlation in all
*  of your data. There's a correlation between having visited the portrait gallery in the museum and
*  having made an optional donation when you leave the museum. So one thing we can vary now is what's
*  the strength of that correlation? Is it just like a really weak association or is it like pretty much
*  a perfect relationship? Every single, all and only the people who went to the portrait gallery
*  made an optional donation and so on. And we ask people claims like, to what extent do you agree
*  that visiting the portrait gallery caused this person to make an optional donation as they left
*  the museum? Or why did this person make an optional donation when they left the museum? Because they
*  visit the portrait gallery, right? So that we have the kind of matched causal claims and explanation
*  claims. So the stronger the statistical evidence that there is a relationship, the more people are
*  willing to endorse these claims. But that has a bigger effect for the causal claim than for the
*  explanation claim. Here's on the flip side of what we found. Now we give some of our participants
*  a mechanism linking these two things, right? So if we constructed our stimuli correctly for what
*  we were going for, it should hopefully not be at all obvious why there would be a correlation here
*  and what might explain that. So we tell half of our participants that actually there's a lot of
*  research in social psychology showing that if you're surrounded by watchful others,
*  like in a portrait gallery with eyes and faces, that triggers these mechanisms where you're
*  concerned with your reputation and leads you to act more socially and so on. And so you're more
*  likely to do something like make an optional donation. Okay, so when you give people the
*  mechanism, that makes them more likely to accept the causal claim and more likely to accept the
*  explanation claim that the reason the person, for example, donated was because they were in the
*  portrait gallery. But that has a bigger impact on the explanation claim than on the causation claim.
*  So, you know, what is this? This is tricky. Yeah. Okay, good. So that is a bigger
*  impact on the claim that they donated because they went to the portrait gallery than it does
*  on the claim that going to the portrait gallery caused them to donate. Exactly. Very fine distinction
*  we're drawing here. But okay, good. Yes, that's right. But I mean, part of the reason, I mean,
*  we wanted to be a fine distinction because we're really trying to drive a wedge between these
*  otherwise extremely similar claims, right? The kind of like bare causal claim, the bare explanation
*  claim. So that's just the empirical finding. But of course, I think the more interesting question
*  is like, why, right? What does this tell us about the nature of explanation and causation and so on?
*  So what we think might be going on is that this might give us some hints towards what the functional
*  role of explaining is for people, right? What do we want our explanations to do for us such that
*  we'd be more satisfied when we have, say, the mechanism information in this case? And what we
*  argue in this work is that one of the reasons why mechanism information might be so central to
*  explanation is because mechanism information is what allows us to generalize to new cases.
*  So suppose I now ask you to imagine a case where some of the patrons at the museum visit the
*  sculpture garden, and you need to predict whether or not those who visit the sculpture garden are
*  also more or less likely to make an optional donation. Well, if you have the mechanism,
*  you have a basis for making that prediction. You might want to know, well, were the sculptures
*  figurative? Did they involve faces? If so, I'm going to predict that you're more likely to make
*  a donation. If these were all abstract sculptures, then no, you have no reason to think that you're
*  more likely to make a donation. So by virtue of knowing the mechanism, you are able to generalize
*  from the original case outside of the data that you'd already observed. By contrast, if you only
*  have the correlation or the statistical evidence there, that tells you how strong the relationship
*  is in the population that you studied already, but it doesn't give you guidance for how to
*  generalize from that population to a novel population. And so part of what we think is so
*  key about explanation is that it's going to direct you, make you look for the sorts of things that
*  support generalization. And this ties back to our earlier discussion about how explanation might
*  support prediction, right? If what explaining is making you do is not just find any kind of structure
*  in your environment, but specifically the kind of structure that's likely to be useful for generalizing
*  to new cases for predicting in the future, then that would make a lot of sense. It does. So in
*  other words, what looking for a good explanation is about is more than just finding a pattern,
*  but finding a pattern that sort of fits into the rest of our knowledge of the world in such a way
*  that it has some implications for other things we might say going forward. That's right. That's
*  right. And I think that it helps explain why merely predicting something accurately doesn't
*  give us a sense of understanding and explanatory satisfaction. You know, if you had a black box
*  that allowed you to predict lots of things very accurately, but you had no idea how to use it,
*  to get to new cases, that's not going to give you what we want in explanations, even though you're
*  getting some predictive leverage there. It is weird because in certain corners of modern physics,
*  I'm bringing up physics more than average in this psychology conversation, but there's a movement
*  precisely because some modern theories of physics invoke things we can't observe, right? Like the
*  multiverse or string theory or whatever. There's a sort of countervailing argument that says,
*  all I care about is making predictions for observations. And we have to stand up for the
*  idea that, no, actually, I want to know why. I want to actually know the explanation. Some people
*  are moving away from that. So I like it. I like the idea that it's really the knowing why that is
*  the goal here, not merely recognizing the existence of a pattern. That's right. Although I think in
*  the physics cases, you get to a real question, which at least for me is an open question, which
*  is what are the limits of that? Right? Are there going to be cases where human mind is not capable
*  of understanding the why? The best we can do is predict in some cases or rely on our deep learning
*  system or extremely complicated theory to do the predicting for us. So I think that is,
*  as an account of the psychology of explanation, I think we really do care about the why. And then
*  thinking about what does that mean for science, I think in that case, you really come up against
*  these cases where it might turn out that some things are beyond our human capacities. It's
*  possible, but I don't think we're there yet. So I'm not worried about that. If that comes up,
*  then I'll worry about it. I prefer to be an optimist about this. Thank you. I do. I do.
*  And I guess this has been implicit in some of the things we said, but from the psychological
*  angle, have we learned what counts as a good explanation? I think we all have ideas about
*  what counts as a good one. Again, making the ability to predict the future fitting into other
*  things we think, but is there like an accepted set of criteria for what an explanation is a good one?
*  Yeah, there's sort of two questions. And I think we have partial answers to both. One is what
*  even counts as an explanation, right? So that contrast is really what's an explanation versus
*  a non-explanation. And for that, I think an explanation typically generates understanding
*  about why what you're asking about was the case as opposed to some often implicit contrast,
*  right? So if I say, why is the sky blue? I might be implicitly asking why is it blue as opposed to
*  another color? And an explanation has to generate understanding about why it's blue as opposed to
*  another color. You might very legitimately then say, what do you mean by understanding there? And
*  we can come back to that. But I want to contrast that with the question more the way you formulated
*  it, which is more like given that something is an explanation or being offered as an explanation,
*  what makes it a good explanation or satisfying explanation? And there we know a bunch of features
*  that seem to play a similar role. So we've been talking about simplicity. That seems to be one
*  of them. And there seem to be a few different notions of simplicity. So we can unpack that
*  further and talk about kinds of simplicity. Brett seems to be another one. So we like
*  explanations that explain everything we invoke them to explain, not just sort of subsets of it.
*  We do. Being consistent with your prior beliefs, as you've already suggested,
*  is sort of fit in with what you already know. People like explanations better that don't make
*  untested predictions, right? So if something predicts something that hasn't been observed,
*  that might feel a little bit risky. And we don't like that so much in our explanations.
*  Isn't that the opposite of what philosophy of science is supposed to tell us, that we
*  love the explanations that make predictions that haven't been tested yet, because then we can go
*  test them? Yeah, that's not what the psychology suggests. But yes, the psychology result here is
*  very puzzling. So this is a body of work focusing on what they call latent scope. And the idea is
*  that it's thought of typically as an error. But for example, if you have two diseases that could
*  explain a set of symptoms, one of them predicts that if we did a blood test that we haven't yet
*  done yet, you'd see an abnormal value, and the other one predicts that you'd actually see a normal
*  value. People seem to prefer the theory that does not make the unverified prediction that maybe
*  departs from the default, even in conditions where you statistically control for various things. So
*  that seems like it may be an error, although it's perhaps an error we can understand as an
*  overgeneralization of a strategy that makes sense under some conditions. Other cases like this are
*  sometimes I sometimes call them explanatory vices as exposed to explanatory virtues, because it's
*  not clear that they're always rational strategies for evaluating explanations. But to give you other
*  examples, people do prefer explanations sometimes that involve reductive jargon. So the classic
*  case of this is that if you give people explanations for psychological phenomena that do or don't invoke
*  totally irrelevant neuroscience, at least that neuroscience is irrelevant according to experts,
*  you typically find that laypeople like those explanations better with that reductive jargon.
*  There is a similar finding. It was in the context of scientific abstracts rather than explanations,
*  but people were seduced by irrelevant math, right? So if you add some irrelevant math in there,
*  maybe that makes it seem more legitimate, more rigorous.
*  I do that all the time, so good.
*  But the experts don't recognize it's irrelevant. But the novice maybe can't. People tend to like
*  explanations that offer a mechanism. We've talked about that already. There's other
*  characteristics like this. I think part of what's challenging is that for any one of these,
*  there's a question of how you really define that, right? So for example, what do we mean
*  to say an explanation is simpler or broader and so on. And also most of these do show some context
*  sensitivity, and that makes it very hard to make unqualified generalizations. So to give you an
*  example with respect to simplicity that we've been talking about, people also seem to have this view
*  that very complex phenomena might require a more complex explanation. And so even though
*  they generally seem to prefer simpler explanations, for a very complex phenomenon,
*  you might actually see something that goes a little bit the other way, where they start to
*  think that some complexity is required in the explanation itself.
*  Okay, good. Yeah, I can see that in different contexts. But I guess different people react to
*  different ones of these standards differently. Sorry, I'm not articulating this very well,
*  but maybe some people are more in it for the simplicity. Some people are more in it for the
*  scope. Some people are more in it for the fit to existing knowledge, things like that.
*  Yeah, I think that's right. So I think that's an area where we actually just don't have
*  much data so far. There's a little bit. The data that is there does suggest that there's individual
*  variation across people and the extent to which, for example, they want the mechanistic details.
*  I think we all know this from everyday life. There's a people who are just happy to show them
*  a microwave for the first time and they're like, great, I know it's button to push and that's it.
*  And there's a person who really wants to understand like, well, what's going on under the hood?
*  So that's a dimension of individual variation that's been documented. In explaining other
*  people's behavior, you also find variation in the extent to which people are open to there being
*  more complex interactions between a person and their environment versus tending to think that
*  it's sort of like a more simple straightforward explanation just in terms of the person.
*  I'm weirdly the person who does not want to know the details sometimes. Like when I met the dentist
*  and they're always like, would you like to see what we're doing to your teeth? No, I have no
*  desire whatsoever to see that. Just make it work. Just make them healthy. I think you've also written
*  about some things that maybe, I don't know if they count as explanations or not, but there's the idea
*  of an explanation as kind of an abstract framework. But there's the strategy of telling a story or an
*  anecdote or a narrative. And sometimes people are going to count that or even prefer that in terms
*  of being an explanation. Yeah, I think those cases are fascinating. Part of the reason I started to
*  think about it was because most of my research is really focused on the role of explanation and
*  learning, suggesting that explanation is important for generalization and so on. And for that story
*  to work, you really want explanations to be focusing on relatively abstract, generalizable
*  features of a situation. That's what we tend to look for in science, right? We like explanations
*  and laws and things like that. And so I was trying to reconcile that with this other everyday human
*  behavior, which is that you ask someone why they were late to work and they don't give you some
*  abstract generalization. They say like, oh my gosh, you won't believe the morning I've had, right? And
*  then they'll tell you about the play by play leading up to their being late to work. And that
*  feels much more like storytelling or narrative. And so the way I think about this now is I think
*  there's sort of a continuum between these. I think very often everyday human explanations
*  can sort of be at an intermediate point, sort of giving you the very abstract, generalizable
*  features of a situation versus focusing on these concrete particulars. And I think they serve
*  different functions. So I think the law-like generalizations are useful precisely because
*  they support generalization to other cases. They're picking out the features of a situation that are
*  relatively invariant that might support prediction to other cases and so on. I think a lot of these
*  other things, the concrete sensory details, the things that make a piece of fiction really
*  compelling, all of that extra nuance and detail. I think part of what that's doing is giving you
*  input that allows you to do something like a mental simulation of the situation or put yourself in
*  somebody's shoes. And so you understand the situation from a particular sort of embodied
*  perspective. And that can give you a kind of insight about the particulars of that situation
*  that you might not get from this more abstract perspective. So for example, by virtue of hearing
*  about the play by play of your morning and how you spilled your coffee and so on, I'm going to be in
*  a better position to appreciate how you really felt and how it was frustrating and what that might
*  have led you to think or to feel or to say and so on. And so it might be partially a peculiarity of
*  the way human cognition works, but it's partially by getting those concrete particulars that we can
*  engage in those kinds of mental simulations effectively. No, that's a fascinating point.
*  Very interesting. Is it almost a mirror neuron situation? Oh gosh, I think I'm going to not
*  speculate about mirror neurons because I will get myself in trouble. I certainly don't think that
*  that's, I don't think that's likely to be a necessary part of this story. You see, I'm adding
*  on unnecessary neuroscience to make it a more compelling explanation.
*  Now people are going to think it's a better explanation. I should have gone with the mirror neurons.
*  But no, I do like the idea that somehow, forget about the mirror neurons, but the embodiment of
*  the explanation. Like there's a set of rules abstractly, okay, that's one thing. If I can
*  picture myself in it, that's another level of appreciation of this purported explanation, right?
*  That's right. That's right. I mean, sometimes, I think you see this reflected in natural language
*  and in discussions of philosophy as well, in terms of different kinds of understanding.
*  One kind of understanding we talk about is the sort of understanding where you say,
*  I understand quantum mechanics, or I understand how to derive the Pythagorean theorem or something
*  like that, where it seems to be this relatively abstract kind of understanding. But then there's
*  this other thing we do where we say, oh, I really understand where you're coming from. I really
*  understand her. I really understand the character of this book, or I feel understood. And all of
*  those notions seem to be much more like this sort of first personal story narrative-like case,
*  where we really can sort of put ourselves in the position of somebody else. And so just like I
*  think explanation and storytelling sort of span the scam, and I think these different notions of
*  understanding show a similar kind of variation. I like that. Is it also possible that the
*  storytelling end of the spectrum sort of gets a bad rap because we valorize rationality?
*  That's interesting. So I think it would legitimately get a bad rap if we used the
*  concrete storytelling to serve the roles that should be served by the more general explanation.
*  Right? So an example like that might be somebody taking an anecdote to be a good basis for a public
*  policy decision, for example, rather than looking at data and the generalizations that are actually
*  available to us at this large scale. And there is some evidence like that. I mean, in the context
*  of persuasion, anecdotes and good stories are persuasive. And so those might be cases where
*  they legitimately get a bad rap insofar as they are being mistaken for strong evidence. But on the
*  other hand, I think they're playing a really important role. So I think maybe what we need
*  to do is legitimize valuable roles for stories and for that mode of explanation, as long as we
*  don't mistake it for playing the role of giving us the abstract generalization. And maybe for
*  empathy more broadly, I did talk to Paul Bloom on the podcast, and he made the opposite claim.
*  He worried that people were too quick to be empathetic, and that sort of biased them toward
*  people like themselves, and they should try to be more rational. And I tried to say, well, but yes,
*  we should, the solution to that is not to not be empathetic, but to be empathetic to a broader
*  spectrum of people. And I'm not sure who's right there. Yeah, I'm inclined to say that there's
*  value to empathy, there's value to empathy in a broader range of cases, but maybe we shouldn't
*  only rely on empathy, right? That's just one of the tools that we have for making sense of a
*  situation. So why does it have to be rationality, or empathy, or, you know, the utilitarian calculus,
*  or the kind of empathic response, maybe we should see what each has to offer, and then integrate
*  both of those into our overall evaluation. Fair enough. So how often in this whole game,
*  do you run across the issue of what is the explanation for the explanation? Like, is there
*  a bottoming out of these explanations anywhere? At what point are people satisfied to say like,
*  okay, that's the explanation, I don't need to dig more deeply. I wish I knew the answer to that
*  question. We have definitely thought about it. I can tell you the crumbs we've picked out,
*  you know, in the vicinity, but we don't have an answer to that. So one thing that's really
*  interesting is that when you get a satisfying explanation, that doesn't stop inquiry, right?
*  I mean, you might have thought that you keep looking till you get a satisfying explanation.
*  And then once you get a satisfying explanation, like, yeah, you're done. At least for kind of
*  rich real world cases, like explanations for why the dinosaurs became extinct and things like that.
*  What you find is that when somebody's received a satisfying explanation, they're now more curious
*  about follow up questions. So it's almost like they've found like, oh, there's stuff to learn
*  here. This is valuable. This is rich and they keep going. Another thing that we have a little bit of
*  evidence for, this is more tenuous, but I think it's plausible. One place where questioning might
*  stop is where you can't imagine a plausible other way that things could be, right? So in order to
*  ask a question like, why is the sky blue? It seems like on some level you have to represent
*  the possibility that could have been non-blue. And so it could be that some of when where things
*  bottom out is where you just either don't or can't represent a real alternative to the way that things
*  are. So if you can't imagine something, nothing existing instead of something, for example,
*  then you might not be puzzled by the question of why is there something rather than nothing.
*  It's only once you recognize this alternative possibility that you're able to ask the question,
*  well, why X and not Y, right? The Y has to be there even if it's implicit.
*  You scooped me. I was exactly next going to ask you an entirely unfair question, which is what is
*  your feeling about the question? Why is there something rather than nothing? I mean, my feeling
*  is that that's the kind of grammatical construction that looks like it's perfectly well formed, but it
*  doesn't actually apply. The world is not the kind of thing that necessarily has an explanation for
*  why it exists. Yeah, that's interesting. I don't know how to think about that case except to say
*  that I have a hard time knowing what the alternative would be. Right. And I think that's part of my
*  having my hard time wrapping around my head around the question. But as I said, our evidence for that
*  is indirect. I don't think I have any great evidence to speak to the something rather than
*  nothing question. I mean, I will say something which I think is also sort of related to this,
*  which is that we found variation in the cases where people are willing to accept that something
*  is a mystery. Okay. And so we'll try out your intuitions here. So if I said something like,
*  why does the moon cause the tides? It's a mystery. I mean, that just seems very unhappy.
*  Because you probably not just because you probably actually know something about the physics there,
*  but like, that's the sort of thing that's not like can't be a mystery. But if I say something like,
*  why does God answer prayer? And I say this to somebody who is a believer, believes that
*  there is a God and God answers prayer and so on. It's a mystery. That seems much more acceptable.
*  Right. And so that's something we find is a reliable domain difference where people tend to
*  think that scientific questions sort of demand an explanation more than religion questions,
*  that it's more acceptable to say that it's a mystery for the religion questions than for the
*  science questions. And we find variation for other things in between. I'm not entirely sure
*  what to make of this, but philosophy and psychology fall somewhere between natural science and
*  religion in terms of people's willingness to sort of accept its mystery claims. And so I think part
*  of this has to do with the perceived limits of human comprehension. That seems to be part of the
*  story. We have some data for that, but that isn't the whole story. There also seems to be variation
*  across these cases and what people think we should try to explain. So some people have the sense that
*  some things are appropriate targets for explanation and inquiry. Other things are not appropriate
*  targets for explanation and inquiry. And that's going to be another factor that affects, I think,
*  where explanations bottom out. If you hit a point where people no longer think either think
*  it's a mystery or no longer think it's an appropriate target for inquiry, you're presumably
*  going to stop asking why. But I wonder if, I mean, how much of that is attributable to the kinds of
*  science questions that we're interested in here? Because, yeah, why God doesn't answer prayers?
*  All right, that's a mystery. Why the moon causes the tides is not. But then you say, oh, well,
*  because gravity works in this way. But okay, why does gravity work in this way? Well, it has
*  something to do with the curvature of space time. Okay, why is space time curved? Like at some point
*  you will bottom out. And I think that what the scientists would say is that's just how it is.
*  There is no further explanation. But is that very different than saying it's a mystery?
*  So we do find this subtle difference in our data, where it's a mystery is not exactly the same as
*  it's unknown. Okay. So in the case of these science questions, the modal form of ignorance
*  that people express is it's unknown to me. Whereas for religion, the modal form of ignorance that
*  people express is it's a mystery. Not just to me, just it's a mystery full stop. Interesting.
*  I don't know how to think about those fundamental physics cases. What people think it's sort of
*  merely unknown, merely unknown to them. Is it unknowable to everybody? Is it deep down a mystery?
*  You know, empirically, I have no data there. My own personal sense is that it's unknown,
*  but in such an unsatisfying way. We really want more and think we probably aren't going to get it.
*  And that might be part of what, you know, when we call something a mystery, part of what we might
*  be saying is it's unknowable. You know, we've kind of hit a hard, hard limit. It's not just something
*  that's merely unknown now. But this idea of what is satisfying to us is so crucial. And I do find
*  myself sometimes when people demanding to know something big picture philosophical, scientific
*  question, I'll give what I think is the best explanation. And then you say like, I'm just not
*  satisfied with that. And I have to say, well, no one ever promised you you would be satisfied
*  with the correct scientific explanation. So I think that that desire to be satisfied is on the
*  one hand, crucially important, on the other hand, hard to really justify on any foundational grounds.
*  That's right. I mean, I think that's part of what actually that that sense of wanting something
*  satisfying, I think is part of what explains why explanation plays an effective role in learning
*  for humans. Right. That's part of what it's like the motivational wing of the exploratory
*  explanation seeking enterprise that we engage in. So I think it plays an important role. But I think
*  there's going to clearly be cases where it it just sort of leaves us astray. We know we're unsatisfied,
*  but there's nothing more to say. I mean, I think I think a lot of coincidences have that kind of
*  character, right? They sort of strike us as things that are, you know, it just seems like there must
*  be something to the fact that, you know, your birthday is the same as my birthday. And, you know,
*  and we can whatever make up arbitrary coincidences here. And at the end of the day, the story is just
*  like, well, I mean, of course, there's a causal story about like, why that's your birthday,
*  there's some story about why this is my birthday. But there's no further fact about us both having
*  the same birthday that feels like that might feel really unsatisfying. I mean, I sometimes think that
*  certain kinds of conspiracy beliefs or other kinds of crazy ideas that people talk themselves into
*  are motivated by these cases where it really feels like there should be more to say about why things
*  happened the way they did. It's really unsatisfying to just in a lot of cases say, it was just chance,
*  there's nothing more to say about what seems like, you know, something calling out for explanation.
*  Well, I agree. And I think that it's, again, it's very hard to articulate the degrees with
*  which we should accept claims like, it's just a coincidence, or it's just a mystery, right? Like,
*  we do fight against that. But sometimes it's just right. And I don't know how exactly to say
*  when that's okay. Yeah, that's right. I mean, I think I think part of it might be that we don't
*  always know in advance, right? A lot of it might just be an empirical question, right? We got it
*  right or wrong in a given case. And there's the error of thinking there's nothing further to learn.
*  When in fact, there is, and that seems like it's a problematic error. And then there's the error of
*  continuing to look when in fact, there was no explanation. And that's also problematic in so
*  far as you're expending cognitive resources and so on. But you might think that we're better off
*  being the kinds of creatures who keep trying a little bit more than we should. That's fair.
*  Under some circumstances, and the kinds of creatures who give up too soon. Well,
*  you mentioned that the religious in the religious context, people are more willing to put up with
*  mystery as a state of explanatory progress. But as I recall correctly, there's also some different
*  research you did on religious versus non religious explanations and their connection to sort of
*  epistemic functions versus non epistemic functions, like the religious religious explanations are
*  doing something for us other than just giving us knowledge about the system. That's right. So what
*  we did in that research is that we chose to look at explanations for existential questions,
*  things like, where did the universe come from, and so on. And what happens after we die? Part
*  of reason we do that is because those are questions where you see people very often
*  spontaneously appealing to both religious and non religious sorts of explanations.
*  And so we had people generate all sorts of explanations. And then we had other participants
*  code the characteristics of all of those explanations. And some of those characteristics
*  were what we would call broadly epistemic, things like how much there's evidence for that
*  explanation to what extent it's based on evidence, whether it's based on logical
*  argumentation and so on. And we also had them evaluated for what we consider to be non epistemic
*  characteristics, like does this give you comfort? Does this reduce negative emotions? Is this a sort
*  of explanation that promotes moral behavior that brings people closer together and so on? So sort
*  of a host of social, moral and emotional kinds of benefits. And so there were a few interesting
*  results. So one is just if you just on average see what characteristics do people think these
*  explanations have, the scientific explanations did better than the religious explanations on
*  these epistemic dimensions, like evidence and logic. And the religious explanations did better
*  than the scientific explanations in terms of these non epistemic kinds of characteristics.
*  But part of what I think is interesting is that you can further break that down by the extent to
*  which a given individual believes the explanation. Right? So, you know, on a sort of five point scale,
*  how strongly do you believe this explanation? And we replicate these results for every level
*  of belief. So what that means is suppose you have somebody, two people who both give a
*  given religious explanation of four on this five point scale, even though they're giving it the
*  same, they endorse it equally strongly, they're still going to say that the scientific one is
*  better than the religious one in terms of these epistemic dimensions and the religious is better
*  than the scientific in terms of the non epistemic kinds of characteristics.
*  I would like to explain that.
*  I mean, here's one way to here's a different way to describe it that I think is much more intuitive
*  and I don't have the figures here to point this out as I talk you through this, either with you
*  or with your listeners, you'll have to hopefully this will make sense. One way to make sense of
*  that pattern of findings that I just described is that people have different thresholds for
*  scientific and religious explanations in order to be willing to believe them at a certain level of
*  confidence. For a scientific explanation, they demand a lot of evidence and are less demanding
*  with respect to the non epistemic characteristics. But for the religious explanations, it's the
*  reverse. They're very demanding with respect to the non epistemic characteristics. They have to
*  meet a high threshold there for them to believe it, but they're less demanding with respect to the
*  epistemic characteristics. Got it. Actually, that made perfect sense. I think you did a very good
*  job of explaining that. And is this something that's particular to religion or what is the pull of
*  non epistemic factors when it comes to us seeking explanations? I guess to make it more concrete,
*  how often do people accept an explanation for something because it would lead to good behavior
*  if people felt that? Yeah, that's a great question. So one important qualification that I should make
*  about all of the research I've talked about about religious explanations is that these are
*  predominantly Christian participants in the United States. Fair enough. Good point. So when I say
*  religion, I really mean that of the population we've studied and it might be different in other
*  cultures and for other religious traditions within the United States. I think that's an
*  important qualification. But I think this is actually probably pretty widespread. So if you
*  think about, suppose you have to explain why you forgot somebody's birthday or something like that.
*  What's going to make that a good explanation? Well, you have a lot of goals in giving that
*  explanation. And some of those goals are presumably more epistemic. I mean, you want to say things
*  that are true. You want to perhaps instill true beliefs in the other person, but you have a lot
*  of other goals. I do, yes. You want to not think of yourself as a terrible person. You don't want
*  the other person to think about you as a terrible person. And so I think it's actually just very,
*  very common in everyday explanations that we're constantly juggling these kinds of
*  epistemic sorts of goals, but also these non-epistemic goals. We're constantly regulating
*  our own emotion and other people's emotions. We're constantly thinking about the social
*  consequences, the moral consequences of what we believe and what other people believe. I don't
*  think this always happens consciously and explicitly. Sometimes we might self-deceive ourselves into the
*  most charitable interpretation of why we forgot somebody's birthday. But that makes me think it's
*  actually quite widespread. Although I know it's hard to put a number on this and I don't have a
*  number, so I don't want to claim I have data to support the claim I just said. But that's
*  what my bet would be if we found a good way to measure that. Is it just hard being a psychologist
*  sometimes because you're too aware of why you're doing different things for not always the right
*  reasons? Yes, but also that's part of what's fun. So for me, everyday life provides all sorts of
*  fodder for thinking about the things that I like to think about. Right. How much feedback is there?
*  Does being a psychologist affect your behavior? I'll tell you about the most painful case of that,
*  which is that I know something about child development. My PhD was partially in cognitive
*  development. I really wish I could tell you that made me a better parent. I really, really wish I
*  did. But mostly I'm inclined to say no. I think it probably makes me more aware of shortcomings. I'm
*  not sure how much better it makes me at correcting those shortcomings. Fair enough. I could absolutely
*  believe that. I mean, certainly being a physicist does not make me a better billiards player or
*  anything like that. So it's perfectly fair. The practicalities of the real world do get in the
*  way. But good because that leads me to the last thing I wanted to ask about, which was childhood
*  development. You mentioned it a little bit, but it seems like we are born with this desire to explain.
*  Can we pinpoint that at two years old, three years old, four years old, whatever? Is there a moment
*  when our explanation seeking impulses kick in? Yeah. So as I mentioned, we do know that basically,
*  as soon as kids have the language to start asking questions, they do. And so you might think that
*  that's the earliest we can go. But there's a couple of very clever approaches developmental
*  psychologists have taken to try to take this question earlier. I'll tell you two of my
*  favorites. So one was a study that tried to compare explanation seeking in humans and in
*  non-human primates. And I'm pretty sure this was a chimpanzee's. And so that raises this really
*  interesting puzzle, which is what does explanation seeking look like and how do you measure it in a
*  non-verbal organism? And so what they did, which I think is very clever, is they basically used an
*  exploration task. So they trained the participants in this experiment to learn how to balance a
*  particular block in a particular way. And then they gave them blocks that had internal weights
*  that would make them not balance. So they would try to balance them in the way that you might
*  think it would balance, it falls over. What do you do? The thought is that if you spontaneously
*  are seeking explanations, what you're going to do is basically examine it, explore it, try to figure
*  out what's going on. And so what they found was that quite young toddlers engaged in this kind of
*  behavior. So that's a really nice non-verbal measure of sort of spontaneous exploration that
*  seems to be explanation directed. Another thing that people have done is look at looking time
*  with infants. Like what do infants look at? I'm sorry, did the primates do that also?
*  Well, it's a little bit complicated. So mostly they did not. But there's a really important
*  difference between that experience for the toddlers and for the primates in that study,
*  which is that the toddlers basically understood the task immediately with very little training.
*  Whereas the primates had to have like, I can't remember what it was, but dozens and dozens and
*  dozens of trials to understand that what they were supposed to be doing was taking these blocks and
*  putting them somewhere. And so I'm not sure what to make of the fact that after that training regime,
*  they didn't spontaneously explore because it's not clear to me that they understood what the
*  task was and what was, you know. So that part of the result, I'm less confident in, but I think
*  the methods are just super clever. Thanks. So the way people have sort of thought about this for
*  infants is by looking at what infants look at, right? Because that's a behavior that we can measure.
*  And what you can do is give them two little sort of scenarios where one involves something that's
*  physically possible. So for example, you try to balance a cup on the edge of a table and it's
*  such that the center of mass is on the table, just a little bit of the cup is off the table. And so
*  you might expect that that will not fall versus one where it's, you know, just barely touching
*  the table. So an adult would expect it to fall. And you can do various kind of variations like
*  this, but which one is the infant going to look more at? And for a lot of cases like this,
*  the infant spent more time looking at the thing that is something like a violation of a principle
*  or expectation. So the fact that they discriminate those two cases and how long they look tells us
*  something about what their expectations are about the way the world works. Now, does it tell us that
*  they're explaining? This is now much more controversial, but at least some of the people
*  who do this research have suggested that part of what's going on when infants observe these cases
*  is that they try to construct an explanation for what they observed. So you're seeing a sort of
*  mechanism of explanation-based learning in these kinds of cases. And that part of the way they form
*  the relevant generalizations about their expectations in these cases is by explaining the cases that they
*  do observe. And so it's possible that even that looking behavior reflects something like the infant
*  looking for an explanation for this otherwise anomalous event. Have you seen these videos where
*  someone hides behind a blanket and the dog is looking at them and then they pretend to disappear
*  when they let the blanket go and the dog kind of freaks out because the person isn't there anymore?
*  I haven't seen the videos, but I can imagine them. I mean, that phenomenon of object permanence is
*  one that's been studied in infants. Well, that's, and that's why I'm asking, because, you know, object
*  set count as an explanation or is that even more primitive somehow? Like if I decide the
*  distinction between that and the kid in the center of gravity. Yeah, I think that's right. I mean,
*  the truth is I think we don't yet know in the infant case or in the dog case. I'll add that into
*  if they're looking longer, if they're startled, I think that shows something like an expectation.
*  Does it show something like explanation seeking? I mean, if the dog then went and like sniffed
*  around where the person was and sort of looked around, I think that starts to get a little bit
*  more compelling. But what counts as a genuine nonverbal measure of explanation seeking is just
*  a really challenging methodological question. Fair enough. Okay. I guess the final thing then is
*  does this, maybe you already answered it informally, but do these insights help us in thinking about
*  how to educate children or even educate ourselves as grown up adults, you know, like better
*  strategies for seeking explanations and deploying them in the real world?
*  I think there might be two lessons. So one of them that I should acknowledge has been
*  well recognized in the education community as well, is that there are benefits to explain to
*  yourself and to others. And that's one of the reasons why peer tutoring, for example, is so
*  effective. In fact, sometimes in peer tutoring context, people who benefit more are the tutors
*  rather than the two T's because they're the ones who are doing the explaining. So I think that's
*  one thing is just engaging in explanation seems to be valuable. That's an activity we could do more
*  of. One version of this that I think is very familiar is you think you understand something
*  until you try to explain it to somebody else. And then in the course of doing so you realize
*  you don't, right? So if we engaged in that more spontaneously, we would catch those gaps in our
*  own understanding, we'd be better calibrated in what we do and don't understand. So explaining
*  is good in educational contexts, formal and informal. The other one though, is that I think
*  maybe we should be a little bit wary of expecting satisfying explanations when we look. All right,
*  I mean, some of the time the world just really is complicated. Yeah. Number of the times the
*  explanation is not beautiful. So while I think explanation seeking is something we should do,
*  I think at the same time, we have to at least be cognizant of the fact that the explanations are
*  not always going to be beautiful or satisfying, willing to entertain the possibility that the
*  beautiful or satisfying explanation is wrong. I think that sounds very true and very important,
*  but it calls out for a well formulated theory of when to stop looking for the explanation. And I
*  think we previously agreed that's a very tricky question. I wish I had that. Maybe the physicists
*  can figure that out for us. No, I very much doubt that. I think this is your job, you and the
*  philosophers. But I've learned a lot. You've explained a lot. And again, it must be weird,
*  not just being a psychologist, but you're constantly trying to explain these facts about
*  explanations and it all gets a little meta. So I think that we handled it pretty well. So Tanya
*  Lambroso, thanks very much for being on the Mindscape Podcast. Thanks for having me. This has been fun.
