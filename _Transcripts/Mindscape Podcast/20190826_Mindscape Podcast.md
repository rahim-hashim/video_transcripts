---
Date Generated: June 10, 2024
Transcription Model: whisper medium 20231117
Length: 4214s
Video Keywords: ['thinking', 'psychology', 'bias', 'mistakes', 'vice']
Video Views: 13074
Video Rating: None
Video Description: Blog post with audio player, show notes, and transcript: https://www.preposterousuniverse.com/podcast/2019/08/26/61-quassim-cassam-on-intellectual-vices-and-what-to-do-about-them/

Patreon: https://www.patreon.com/seanmcarroll

All of us are wrong about things from time to time. But sometimes it was a simple, forgivable mistake, while other times we really should have been correct. Properties that systematically prevent us from being correct, and for which we can legitimately be blamed, are “intellectual vices.” Examples might include closed-mindedness, wishful thinking, overconfidence, arrogance, and so on. Quassim Cassam is a philosopher who studies knowledge in various forms, and who has recently written a book Vices of the Mind: From the Intellectual to the Political. We talk about the nature of intellectual vices, how they manifest in people and in organizations, and what we can possibly do to correct them in ourselves.

Quassim Cassam received his Ph.D. in philosophy from Oxford University. He is currently Professor of Philosophy at the University of Warwick. He previously held faculty positions at Cambridge University and University College London. He has served as the president of the Aristotelian Society, and was awarded a Leadership Fellowship by the Arts and Humanities Research Council in the UK.
---

# Mindscape 61 | Quassim Cassam on Intellectual Vices and What to Do About Them
**Mindscape Podcast:** [August 26, 2019](https://www.youtube.com/watch?v=SDohKBfA83g)
*  Hello everyone, welcome to the Mindscape Podcast. I'm your host, Sean Carroll. And if you're
*  anything like me, you're surrounded by other people who are wrong about all sorts of important
*  things. Now, of course people can be wrong for all sorts of different reasons, right?
*  I mean, maybe they're just not that smart. Maybe they just end up being not quite clever
*  enough to get the right answer. Or maybe they're just not informed to be a little bit less
*  judgmental about it. Maybe they don't have the right background, the right information
*  to reach correct conclusions. But there's other people who you no doubt notice seem
*  to be really smart and yet keep getting things wrong, or at least get something wrong in
*  a really, really important way. And in some sense, it's their fault, right? If someone
*  is just uninformed, you don't blame them for being wrong unless you blame them for being
*  uninformed. But you could just say, well, they didn't know any better. But there's cases
*  out there where you recognize that people really should know better. And there's something
*  about that person that is preventing them from being correct. My guest today is Qasim
*  Qassam. He is a philosopher at the University of Warwick in the UK. And he's written a book
*  on intellectual vices. The book is called Vices of the Mind, From the Intellectual to
*  the Political. And the point of the word vice here is that this is something that is preventing
*  you from getting the right answer in a blameworthy way. We've all talked about cognitive biases
*  or other things like that. Sometimes a cognitive bias can be an intellectual vice, but other
*  times it's sort of inevitable. So it's a slightly different kind of category. So Qassam is talking
*  about all the different ways in which people get things wrong in important but in principle
*  correctable ways, ways that we can really blame them for getting wrong. And of course,
*  we can go on about the current political situation and wonder whether or not the people we disagree
*  with are subject to these intellectual vices. One way or the other, I think that the important
*  thing here from my perspective is we all have these vices ourselves. There should be some
*  way to get better at it. So we talk a little bit about where these vices come from, why
*  they exist, why it is worth blaming someone for being wrong in these different ways, and
*  then of course, how we ourselves can be better at it. I want to remind you that we have a
*  website for the podcast, preposterousuniverse.com slash podcast. On the website, you know, for
*  every different post for every different episode of Mindscape, you can find not only links
*  to the people's stuff, but you can also find a full transcript of every episode. There's
*  also a Patreon page linked to from the website. And if you're wondering why there's a Patreon,
*  though there are ads on the podcast now, you can get an ad free version of the podcast if
*  you subscribe and support on Patreon, as well as monthly Ask Me Anything episodes. So there's still
*  reasons to be a Patreon supporter, as well as of course, my undying gratitude. With that, let's go.
*  Kassim Khassam, welcome to the Mindscape podcast. Oh, hello there, Sean. It's good to be here. Now,
*  you're a professional philosopher and epistemologist, I think it's safe to say, and I know a little bit
*  about epistemology, not that much. My experience with epistemology is that it's a somewhat dry
*  field. People are talking about the sense data we collect, how to verify propositions and things
*  like that. But you're involved in a project in particular with what you call intellectual vices,
*  that seems a lot more grounded down to earth related to, you know, psychology and how people
*  live and talk in the world. So why don't you give us a little bit of background on epistemology
*  generally, and then how your project fits into that? Yeah, so epistemology, I think, can often
*  be a very dry field. So epistemology is the philosophical study of knowledge. So the sorts
*  of questions that epistemologists typically ask are questions like, what is it to know something?
*  What are the sources of human knowledge? Questions like that. So these are very abstract, high-level,
*  general questions. And although epistemologists usually use examples to illustrate their points
*  and their claims, the examples they use tend to be rather kind of contrived, made up examples that
*  are designed to make the point they want to make. So I have to confess that, you know, a lot of my
*  own work in the past has been a bit like that. But in the last few years, I've become quite interested
*  in seeing how to apply epistemology, the philosophical insights about the nature of knowledge to the real
*  world problems, to real world issues, and particularly political questions and political issues. So
*  there's a kind of branch of epistemology now, which people call political epistemology. And I
*  guess that's really what I'm doing. So political epistemology is an attempt to connect epistemology
*  with questions about how politics works and how it doesn't work. And that really was the kind of
*  inspiration for my book. And I say at the beginning that I was really motivated to write the
*  book by the way politics seemed to be going both in the UK and in the US, particularly in 2016,
*  with kind of major events on both sides of the Atlantic, and before that, the Iraq War. So I have
*  kind of discussions of all of those subjects in my book. And I try to account for them using this
*  notion which you mentioned, the notion of an intellectual or an epistemic vice. And I guess I
*  should say more about that if you'd like me to. Well, yeah, I mean, I think that I personally,
*  and I hope that mindscape listeners are very familiar with ideas like cognitive biases,
*  or you know, ways in which we can be irrational. But your your this is slightly different slant,
*  it's closely related, it's in the same neighborhood, but a vice seems much more normative,
*  right? Much more judgmental. So yeah, tell us what an intellectual vice is. Yeah, so one thing that
*  maybe distinguishes vices, intellectual vices, and indeed, even moral vices from cognitive biases,
*  is that vices are clearly personal qualities. So vices are personal characteristics that, you know,
*  one person may have and another person may not have. So some people, let's say, are close minded,
*  and others are not. Arrogance is a characteristic that some people have and others don't. Maybe
*  wishful thinking is something that some people are more prone to than others, and so on. So that's
*  one difference, because certainly, when people talk about cognitive biases, I think they tend to
*  think of them as universal, more or less, and in many cases, as operating not at the level of the
*  person, but at the level of their brains and the way their brains process information. So that's
*  the first thing to say about the notion of a vice. Now, these personal qualities can take many
*  different forms. So some vices, I want to say, take the form of character traits. So close mindedness
*  you might think of as a character trait, or there are vices that take the form of ways of thinking,
*  like wishful thinking. And then there are vices that take the form of attitudes. So for example,
*  you might think of prejudice as an attitude and as an intellectual vice. So that's the next thing to
*  say about these vices. But the really big point is this. So a vice is something that's kind of bad.
*  That's the basic notion of a vice. So virtues are good qualities to have and vices are bad personal
*  qualities to have. So traditionally, of course, people thought very much about moral virtues and
*  vices in this connection. So classically, courage was seen as a moral virtue and cowardice is a
*  moral vice. So intellectual vices and virtues are intellectual qualities that people have, which are
*  either good for them to have that contribute to their intellectual flourishing or bad qualities
*  for them to have. And those are the intellectual vices. And just this again, I think, relates to
*  your question about cognitive biases. So when people talk about virtues and vices, I think there's
*  a really strong intuition that your virtues and vices are things for which you can be praised or
*  blamed, or criticized or admired. So you know, the virtues are supposed to be kind of admirable
*  personal qualities, qualities for which you might reasonably be praised. And vices are the opposite,
*  they're dis-admirable qualities. And that again is a difference with at least some cognitive biases,
*  where it's not so clear that notions of praise and blame. So there you have the story. So they're
*  personal qualities, their intellectual qualities. In the case of vices, their personal
*  inter-intellectual qualities that are in some sense bad for us, intellectually speaking. And lastly,
*  their personal qualities for which we can be blamed or criticized. So that's the basic notion of an
*  intellectual vice.
*  Right. And this discussion sort of begs the question of whether or not it's or under what
*  circumstances is it okay to blame somebody or give them responsibility? There's sort of a free will
*  volition kind of issue that comes in here. Do we imagine that vices are things that people could
*  choose to change if they wanted to, or at least that they could try to change them?
*  Yeah, so that's a really fundamental question about virtues and vices. So you're absolutely right. So
*  if you're going to talk about blame, particularly, then it seems as though you have to think that
*  vices are things that people are responsible for. And then if you think people are responsible for
*  them, then it looks as though they need to have some kind of control over them. And then people
*  worry that, you know, we don't really have control of our own character traits. So how can we be, you
*  know, how can we be blamed for them? So I think that the discussion of this issue is kind of really
*  complicated. So one thing I would want to say is that with respect to at least some vices, I don't
*  think that control is a really big issue. If you think of vices that take the form of attitudes, to
*  say that we have control over them is to say that it's possible for us to change or alter our
*  attitudes. And indeed, I think it is possible in at least some cases. Similarly, it's possible to
*  change, at least to some extent, the way we think. The hardest case is character traits, where it's
*  much more tempting to think of them as completely fixed and unalterable. I'm not sure I really buy
*  that. I think that I think that we, again, are not completely victims of our own character and that
*  there is some possibility of revision. I mean, the question really is, is how, how easy is it for us
*  to revise our character traits or attitudes or our thinking styles? So that's one kind of cluster of
*  cluster of issues. But I just want to give you an example, which may be, you know, maybe is helpful.
*  Right. So this is an example suggested by a philosopher called Heather Batley. So imagine a young
*  man in an area of Pakistan who is brought up in a Taliban control village. And because of the way
*  this guy has been brought up, he has all sorts of prejudices, say prejudices against women, for
*  example, right. So he thinks that, you know, women should not be allowed out of the house unless
*  unless accompanied by an adult male relative. Now, of course, if you're trying to, if you ask, well,
*  why does this person think this? And what kind of control does this person have over this attitude
*  of his? So the natural thing to think is, well, he thinks these things, not because they're true,
*  and I guess they aren't true, but he thinks these things because of his circumstances and his
*  upbringing and the community and culture which he lives in. And then to say, well, he could, you
*  know, he has control over these things seems implausible, right, because you might want to say,
*  well, you know, how can he change those things? But I think it is worth noting in this case that
*  whatever we think about the issue of, you know, control or change, I don't think he's completely
*  off the hook. I mean, it seems to me that it would be odd to say, you know, that he's
*  straightforwardly blameworthy for his attitudes. Maybe blame isn't quite the right notion here. But
*  nevertheless, I think it's perfectly reasonable to criticize, to criticize his attitudes, right. I
*  mean, these are really bad attitudes to have. And I think criticism is completely appropriate in
*  these cases. And then of course, the question is, well, are you criticizing his attitudes? Or are
*  you criticizing him? And so maybe, you know, there's some scope for saying, well, no doubt he has
*  terrible attitudes. And you know, we it's okay to criticize his attitudes, but it's that doesn't
*  mean we criticizing him. But you know, beyond a certain point, it's quite hard to sustain the
*  distinction between a person's attitudes and the person, because you might think the person is in
*  some sense made up of his attitudes and character traits and so on.
*  It seems that the discussion sort of presumes that there is some shared or maybe even universal
*  objective kind of goal that we have when being epistemologists or when trying to think about the
*  world that we all want truth, right. And it's probably an easier discussion to have when we're
*  talking about scientific or physical, natural facts about the world than about moral stances. And so
*  is that is that a fair thing to say that, you know, we can only have this discussion about
*  what's an intellectual advice if we agree that we all want to get things right at the end of the
*  day, and we more or less agree on what it would mean to get things right?
*  Yeah, I suppose that's that's fair enough. I mean, I guess that rather than talking about about truth,
*  I think I'd want to say that that, you know, what what we want and need as human beings is,
*  is knowledge of the world around us. I mean, that's something we actually need, just to,
*  you know, just to survive and just to get by. And the other thing that we look for is understanding.
*  It's not just a matter of knowing that certain propositions are true, but we also want to
*  understand why they're true or how they how they're true and how they fit in with other things that we
*  that we know. So now, of course, if somebody says, well, look, there's no such thing as knowledge,
*  or there's no such thing as truth, then you know, you're quite right that that sort of ends the
*  discussion, although I'd want to probe them a bit more about why they think these why they think
*  these things. But I think for most people, and, you know, hopefully for most people listening to
*  this to this podcast, I mean, you know, we do think that it's possible for us to know some things.
*  And that there are personal qualities that make it easier, easier for us to know things about the
*  world around us and personal qualities that make it much more difficult to have knowledge or
*  understanding of the world around us. So the vices are then these personal qualities that get in the
*  way of our ability to know or understand the world around us. And if somebody were to say to me in
*  all seriousness, yeah, well, that's fine. But who cares about knowledge or understanding?
*  I think I'd be inclined to think that they're not really being serious. I mean, that's the kind of,
*  you know, provocative remark that people make for the sake of argument. But I don't think I don't
*  think it's a very sensible thing to say. I mean, supposing you have a, you know, supposing you have
*  a young child, and you are, you know, considering whether to give the child, you know, vaccinations
*  recommended by, you know, by your doctor, I mean, you know, I guess you really want to know what's
*  the right thing to do. I mean, that's a that's a that's a very pressing practical question for you.
*  And if somebody were to say, yeah, but look, you know, who cares about knowledge, you don't really
*  need to, you know, we don't need to worry about knowing whether this is the right thing to do or
*  not for your child. I just don't think we that's what anyone seriously believes. And the same goes,
*  you know, for, you know, for each of us in our in our own lives. I mean, you know, you want to know
*  things. And if you don't want to know things, you're not really going to get very far in your life.
*  Now wanting isn't enough. I mean, you need to have the, you know, you need to have the intelligence
*  resources to actually know stuff. And these intellectual resources are going to include,
*  you know, personal qualities that either make it easier or more difficult for you to know.
*  Let's just home in exactly on this difference between cognitive and intellectual vice and a
*  cognitive bias. On the one hand, the vice is something you can be blamed for. On the other
*  hand, the bias might be deeper ingrained, and you you can't help it. In fact, in some sense,
*  you can't help it. In fact, in some sense, vices could even be useful in the sort of,
*  you know, thinking fast kind of way, there's shortcuts heuristics that get us places,
*  but and they but they overlap at the same time, right? Maybe some examples of one versus the other
*  would help people clear things up. Yeah, so I mean, a good a good example is something like
*  confirmation bias. Right. So confirmation bias is something that I think we all
*  we all suffer from, you know, the tendency to look for information that supports what we already
*  believe, and the corresponding tendency to ignore evidence that goes the other way.
*  You know, so confirmation bias, I mean, I suppose you can certainly imagine circumstances in which
*  confirmation bias isn't isn't necessarily going to be bad for you. I mean, in, you know, if what you
*  already believe is true, then, you know, confirmation bias isn't going to get in the way of
*  your grasp of the truth, it's just going to, you know, strengthen your already true beliefs. But
*  I mean, maybe this goes back to the, you know, the thing you were saying about, you know,
*  traditional epistemology. I mean, one thing that traditional epistemology has always thought,
*  I think, and and I think this is true, is that knowing isn't just a matter of having beliefs
*  that are true. Knowing also involves having beliefs which you are justified in having.
*  So there's some sense in which, you know, knowledge requires justified beliefs, beliefs based on,
*  you know, for example, evidence or good reasoning or, you know, solid solid information.
*  So in the case of confirmation bias, I mean, if your if a particular belief of yours is sustained
*  by this bias by kind of unthinking confirmation bias, even if that belief of yours happens to be
*  true, and even if you are confirmed in that true belief by your bias, it's still going to be
*  problematic, because there's still not going to be the case that your belief is justified.
*  If it is really sustained by a cognitive bias and, and nothing else. Having said all that,
*  I mean, I think it's also I mean, I think it's perfectly true that the distinction between
*  cognitive biases and intellectual biases isn't a sharp one. And, you know, they may be, as you as
*  you were suggesting, there may be a kind of area where they, you know, they shade, they shade into
*  one another. So I think there are there are, you know, there are these two, there are these two sort
*  of things to think about. I mean, one is, is, is there a sharp distinction between the two? And I
*  would want to say, there isn't a sharp distinction between the two, but there is some distinction
*  between the two. Right. And the other thing is, is, is to think about the conditions for, you know,
*  for knowing and how knowing requires actually having beliefs that are justified, not just beliefs
*  that are true. You have some wonderful examples in the book, you did this wonderful thing where in
*  every chapter, you begin with another egregious example of intellectual vices getting away.
*  Let's share some of those with the audience. I mean, there are a lot of them are sort of quasi
*  political. So that's just the price we pay for this. But there's certainly examples in history
*  where, regardless of what you thought at the time should have happened in retrospect, people made
*  mistakes. And you say that in some cases, we can attribute those mistakes to really pretty severe
*  intellectual vices. Yeah, yeah. So this is the example I start the book off with is the
*  2003 Iraq war. So with that example, I'm not really interested there in the question of whether
*  the US was right or wrong to invade Iraq in 2003. That chapter is more about whether given that the
*  US had decided or did decide to invade Iraq, what went wrong with the military preparations for the
*  invasion. So I mean, clearly, I mean, I guess it's relatively uncontroversial now that it all went
*  horribly wrong. And it's a really important, important practical question, politically,
*  militarily, and in other ways to figure out how things went so badly wrong. Why was the US
*  apparently so ill prepared for this very complicated operation? Now, if you look back
*  at the way the operation was planned, and the attitudes of those planning it, I mean, one thing
*  that you can that I think you can see fairly clearly is, you know, considerable intellectual
*  arrogance, you know, the assumption by senior people in the then administration that they knew
*  best, they knew what they were doing, they didn't really have to listen to what the military
*  planners were telling them. And that was the sort of, you know, arrogant, overconfident attitude
*  that led to disaster. I mean, overconfidence is another one, which I just mentioned. I mean,
*  you know, overconfidence is a really powerful force in our lives. And when it comes to,
*  you know, wars and military planning, it's absolutely catastrophic. And I think that the
*  overconfidence of the Bush administration, I think, was a real problem in that case. So there are just
*  two examples of intellectual vices that caused serious practical difficulties. I mean, other
*  people have, you know, have other kind of analyses and diagnoses of what went wrong. But
*  it's kind of interesting how many of these analyses really do talk about either intellectual vices or
*  cognitive biases. I mean, even if you think about the, you know, the whole business about weapons
*  of mass destruction, WMD, and the inquiry into whether Iraq did or didn't have WMD, you know,
*  in retrospect, of course, there was lots of talk about, you know, confirmation bias,
*  you know, the assumption that Iraq had WMD, and then the tendency to interpret all evidence
*  supporting that assumption. Another thing that people talk about in this connection is groupthink,
*  you know, the tendency for a bunch of people to all kind of collectively as a group, all agree
*  with one another and just move in a particular direction. So these are all, whether you want
*  to call them cognitive biases or whether you want to call them intellectual vices,
*  these are all examples of, let's call them intellectual defects or intellectual failings
*  or intellectual flaws that had a major impact on the conduct of the war and, you know, had a major
*  impact on the way war preparations were made. And then in later chapters, of course, I give other
*  examples. I mean, there's a chapter that's dedicated to the Brexit vote in the UK and
*  the whole issue of how that was argued for and how that was presented. So in that context, I mean,
*  one issue is what people's attitude was towards expert evidence about the consequences of the UK
*  leaving the EU. And there are certainly plenty of examples, which I quote in the book, of people
*  basically saying, we just don't need to worry about what the experts tell us. You know, we know how
*  things are and we just don't need to worry about the facts. You know, there are the facts and then
*  there are the facts that the expert tell us, but then there are our facts, you know,
*  the alternative facts. And that is an attitude which I think is deeply destructive as well and
*  had destructive consequences in that debate. So, you know, so here's a kind of, you know,
*  general question that people might want to think about. I mean, if you're thinking about, you know,
*  political developments, politics in the last five or 10 years, you know, can you think of
*  particular political events or politicians or developments where the intellectual
*  vices of some of the major actors played a big part in producing the political outcomes that we saw?
*  I suspect that most listeners to this podcast won't have much difficulty in thinking of
*  examples of this thing. I mean, clearly, which examples you come up with is rather going to
*  depend on what your politics are. I mean, I can imagine, you know, people on the Democratic side
*  in the U.S. immediately thinking of your current president when looking for examples to illustrate
*  intellectual vices in action. But equally, I'm sure that people on the other side will have different
*  examples. These examples are great because it highlights how what we're talking about,
*  forget about cognitive biases for a second, but it's not just foolishness or stupidity or
*  ignorance that we're talking about here. It's an active, you distinguish between attitudes,
*  styles of thinking and character traits that actively get in the way of getting to the truth.
*  It gives people, I think, a handle on how the vices are special and they could be improved,
*  because it's not just a lack of knowledge, it's some way of thinking that you have that is
*  actively obstructing you from getting to the truth. Yeah, so let me give you another example.
*  I mean, so one of the chapters talks about the famous case of the 1973 Yom Kippur War.
*  So this is something that's been really extensively studied in Israel and elsewhere. So just to remind
*  people of the history. So in 1973, Israeli intelligence was starting to receive multiple
*  reports of military preparations by the Egyptians and Syrians, preparations that pointed to an
*  impending attack by Egypt and Syria on Israel. Now, at that time, the director of military
*  intelligence in Israel was someone who was very strongly committed to the belief that
*  the Arabs would not attack. I mean, I'm simplifying a bit, but I think his view was
*  that they would be crazy to attack and therefore that they wouldn't attack and therefore that
*  any evidence indicating that they were about to attack was not reliable, that all such evidence
*  could simply be dismissed. So, well, what happened? Well, of course, what happened was that
*  they did attack. So they attacked on Yom Kippur in that year. And because no serious preparations
*  had been made on the Israeli side, the initial phase of that war went very badly for Israel.
*  Eventually, they turned things around. But in fact, the Egyptians managed to cross the
*  Suez Canal virtually unopposed at the outset. Now, if you're thinking about, well, what's the vice
*  here? That's all very interesting, but what's the vice that we're talking about? Well, the vice that
*  we're talking about in that case is closed-mindedness. So this is a case of someone who,
*  so we're talking here about the head of military intelligence in Israel, someone who had
*  arrived at a certain view, had, as they say, frozen on a certain conception of what would
*  and would not happen. So he'd frozen on the idea that Israel would not be attacked at that time.
*  Having fixed on that idea, his mind was really closed to all alternative perspectives. So that's
*  really closed-mindedness, where you are simply not willing to give serious consideration to other
*  points of view, to other perspectives. And it's not just other points of view, it's also not being
*  willing to give serious consideration to actual concrete evidence, in this case intelligence,
*  that points the other way. Now, of course, we all know what happened. There was a real military
*  price paid by Israel for that. Now, if you're thinking about, well, what can we do about this?
*  I mean, can we do anything to guard against this? Well, of course, the obvious thing is to put
*  structures in place to make sure that people in these positions of power are really forced to
*  consider alternative perspectives, even if they're not really inclined to. And I mean,
*  open-mindedness can go too far, but nevertheless, it's really important that people in these
*  positions are seriously willing to engage with alternative perspectives. So that's an example,
*  the example I gave is really an example of a particular intellectual vice, closed-mindedness.
*  And if you think about what the impact of that vice was, the impact was that it prevented
*  the director of military intelligence in Israel from knowing something that he would and could
*  otherwise have known. I mean, he had all the evidence necessary to know that an attack was
*  about to happen. He failed to know it. Why did he fail to know it? Because he ignored the evidence.
*  Why did he ignore the evidence? Because he had already made up his mind and was closed-minded.
*  And so there you have a kind of explanation of a series of events, and that's what I call a vice
*  explanation, an explanation of how things turned out, in which the intellectual vices have won
*  or more people is doing important explanatory work. And I don't think that this explanation is
*  particularly high-tech. I think it's a perfectly commonsensical explanation. And it's also,
*  interestingly, an explanation that's been given by people who studied what went wrong in that case.
*  And I'm not just making this up. I mean, there is actual evidence that this is actually what happened,
*  and there are quite a few references in the book to the relevant literature on this subject.
*  And I mean, the whole, it's rather odd that I keep coming back to military examples, but these are
*  examples where it's just easiest to see the point. Another case was a much older example,
*  Operation Barbarossa, when the Nazis invaded the Soviet Union. Again, the Russians under Stalin had
*  plenty of intelligence that the Nazis were about to attack. Stalin was convinced that they weren't
*  going to attack. And I mean, look, get this for closed-mindedness, right? So Stalin was so convinced
*  that the Nazis were not going to attack that he had people who reported that they were going to
*  attack. He had them shot. That's closed-mindedness. But this is an excellent example to sort of dig
*  into a little bit, the example of closed-mindedness, because you sneaked in there the statement,
*  it's possible to be too open-minded. And you have the case in your book of what about
*  Holocaust denial, where you say, you're not a super expert in the Holocaust. You know the basics, but
*  you're just not interested in spending your time reading the purported evidence from Holocaust
*  denialists. So where exactly do we draw this line between being open-minded and closed-minded?
*  Is there an objective way to do it, or is it a more practical wisdom kind of thing?
*  Yeah, I think it's a very practical question. So let's just go back to, I mean, just go back
*  to Aristotle. This is going back a long way. So lots of modern talk about virtues and vices originates
*  in Aristotle. So Aristotle had this, I think, absolutely brilliant idea. And I think it still
*  is correct, which is that with all these qualities that we've been talking about,
*  it's possible to have too much of something, and it's possible to have too little of something,
*  and it's possible to have just the right amount of it. So the virtuous person who has
*  neither too much nor too little. So the classic example is courage. So courage is a virtue.
*  On the other side of courage is cowardice, where you have, as it were, too little courage. And then
*  on the other side, on the opposite side, you have rashness, which is where you have, as it were,
*  an excess of courage. So you have vices of excess, vices of deficiency, and then the virtue in the
*  middle. So I think the same is true in the case of intellectual virtues and vices. So if you're
*  thinking about close-mindedness as a vice, and open-mindedness as a virtue, so then the question
*  is, so what would be the extreme? What would be the case where you are, as it were, too open-minded?
*  So that might be the vice of gullibility. So the open-minded person, the virtuous person, is someone
*  whose mind, of course, their mind has to be open to the extent of being willing to consider
*  serious alternative options to what they think. So they need to not dismiss
*  views just because they are at odds with their own views. But it's also true that to function
*  in the world as a knower and as someone with understanding, you have at some point got to
*  take some questions as having been settled. And having reached that point, you don't need to
*  take seriously every single alternative perspective that's proposed, however ill-founded
*  that perspective is. So a question that I take to be to be to be settled is the question of
*  the reality of the Holocaust. I take that I take there to be overwhelming
*  historical evidence that the Holocaust happened in just the way that we were all taught. Now,
*  of course, there are Holocaust deniers. So Holocaust deniers say things like Hitler didn't
*  know anything about it or Hitler didn't order it or that far fewer Jews were killed in the Holocaust
*  than the six million figure that's normally given and so on and so forth. Now, if somebody were to
*  say, well, look, if you're open minded, surely you've got to take those claims seriously.
*  Surely you've got to be willing to consider them. I think my answer to that is, well,
*  it depends on what you mean by take those claims seriously. I mean, I'm aware that those claims
*  have been made and I'm also aware that those claims have been refuted, they've been rebutted.
*  And I've in fact, speaking for myself, I've actually read some of those rebuffles and I
*  found them kind of convincing. So having somebody saying to me, yeah, but look, it could still be
*  true, couldn't it? And I want to say, well, no. I mean, in this case, there actually is evidence
*  that settles the question. So I think when people talk about closed mindedness, I mean,
*  I think it's a mistake to think that just because you think that certain questions have been settled,
*  just because you think that the evidence does indeed point in one direction rather than another,
*  that in itself makes you closed minded. Open mindedness, so the virtue of open mindedness,
*  then it's quite a kind of delicate matter to say what it involves. And I guess, you know,
*  in a way, the simplest way to put it would be to say, well, it's neither an excess nor a deficiency.
*  And there's no mathematical formula for that. Good. That's exactly what I was going to get at
*  because I know in physics, among scientists and among many philosophers, and among me in my past
*  life, there was this really strong desire for a mathematical formula, right? Like if we were
*  trying to say something deep and profound about either the world or wisdom or how to live our
*  lives, there should be clear cut guidelines. And as I age into what is hopefully greater amounts of
*  wisdom, I'm increasingly becoming impressed or fascinated by the idea that sometimes there just
*  aren't clear, bright lines between these things. And in morality, it's also something that comes up.
*  Utilitarians can be thought of as people who want to find the formula for how we should act
*  in all these different circumstances. And I'm increasingly of the opinion that the formula
*  doesn't exist. Do you think that's a healthy or disastrous philosophical attitude?
*  I think it's an incredibly sensible attitude, actually. And even when there is a formula,
*  it's not clear that you necessarily have to use it. I mean, let me give you an example.
*  So think about cooking. Now, of course, there are recipes to cook, recipes that you can follow that
*  tell you exactly how much of each ingredient is required. Now, of course, it's possible to
*  follow those recipes. But I mean, one thing is that in the case of many recipes, it actually
*  doesn't matter very much or matter at all if there are minor variations around the quantities
*  that are given in the recipes. And of course, really good cooks don't rely on recipes. They
*  just have a feel for what's the right amount of salt or what's the right amount of chili.
*  Yeah.
*  And I think that's just life. People with practical wisdom are people who just have
*  just a kind of, I don't know what to call it, a kind of instinctive sense of just what's right
*  and what's wrong. And supposing you're going to a drinks party and you're thinking, well,
*  we don't want to stay too long. We don't want to stay so long that the hosts get annoyed with us.
*  But equally, we don't want to leave too early because we don't want to be rude. So then you
*  imagine saying to your partner, okay, so let's figure this out. Exactly how many minutes do we
*  need to stay for it to be the right number of minutes? Now, that would be a kind of really
*  stupid approach to this. Because I mean, of course, in reality, what happens if you're sensible is
*  that you go to the drinks party and then depending on how things are going, you kind of have a feel
*  for when it's time to go. So you realize that basically if you turn around and walk out of the
*  door within 30 minutes, you're probably going to offend them. And you know equally that if you stick
*  around until three o'clock in the morning, that's probably also a really bad idea. So the good
*  point, the good place, the good time to leave the party is going to be sometime between half an
*  hour and 3 a.m. But there's no formula for that. There's no formula for that. It's just that
*  sensible people will actually kind of just be able to work it out. And there'll be a range.
*  Leaving any time in that range is going to be basically fine. And I think that's really
*  these examples of the drinks party and the cook. I think they're very much in the spirit of what
*  you're suggesting about life. That the search for rigid formulae is just silly. I mean, life isn't
*  mostly like that. Like I said, I am moving in that direction. When I try to be
*  hard on myself, when I try to avoid the intellectual vices here, I worry that it's
*  just a cop-out that because I don't know what the formula is, I deny that there is a formula. So I'm
*  in between denying the existence of the formula and insisting that it must be there.
*  Yeah. So let me ask you a question. In the case of the drinks party,
*  would you want to say there's a formula in that case?
*  You know, I think I get the example. It's a very, very good one because it's very relatable.
*  I can't say it's impossible that there's a formula. I think that the way that you set it
*  up is cheating a little bit because it sounded like we have to decide how many minutes ahead of
*  time. But maybe there's a formula that says given the data we're collecting while we're there,
*  given the eyebrows of the host and who's sitting on the couch, there is a way to figure it out.
*  But on the other hand, maybe not because I think that once we get into the realm of normativity
*  and judgment, I think it's not such a matter of it's too hard. It's just that the criteria
*  themselves are fuzzy. Yeah. I mean, judgment is absolutely
*  the key word there. That so much is a matter of judgment. And I think that actually good judgment
*  sounds like a very good candidate for being an intellectual virtue and poor judgment is a very
*  good candidate for being an intellectual vice. And if you think about people with bad judgment,
*  you think about the lives they end up living. Mostly it's a terrible thing for them. Just
*  on a personal level, leave aside intellectual matters, even on a personal level, having bad
*  judgment is something that has a real impact on us. And it's something that we really want and need
*  to avoid. And I think that's a kind of illustration of a point I'm quite keen to emphasize in the book,
*  which is that when we talk about virtues and vices, although using labels like
*  closed mindedness and dogmatism and so on, although these are kind of quite abstract labels,
*  we're not really talking here about something that's purely abstract. We're talking about
*  stuff that actually makes an enormous practical difference in our day to day lives. And of course,
*  in the political world and the military world and the medical world, all of these things
*  have consequences. They have real world impacts. And if you're thinking about, well, why do you
*  classify closed mindedness as a vice and why do you classify humility as a virtue? Well,
*  it's got to be because you think that you're going to do better intellectually speaking and
*  indeed personally speaking with a bit of humility than if you are closed minded. So we are talking
*  here about something that's philosophical but also very practical. Is there some sort of grand unified
*  theory of intellectual vices? Is there like a single or vice from which everything else
*  spills? Or is it just a mishmash of different things that are preventing us from getting to the
*  truth? Well, I mean, I think it's more of a mishmash than there being a single grand theory.
*  If you want a grand theory, then my offering in the book is what I call
*  obstructivism. Obstructivism basically says that intellectual vices are personal qualities
*  that systematically get in the way of knowledge and that we can be blamed or criticized for.
*  That's your kind of uber theory of what an intellectual vice is. Because there's so much
*  focus on these vices getting in the way of knowledge, I tend to refer to them in the book
*  as epistemic vices, but basically it's the same thing. That's your kind of general characterization.
*  But then the question is, okay, so you've told me that they're personal qualities that get in the
*  way of knowledge and that are kind of bad for us. But well, which qualities are these?
*  Now, when you get to that level, then of course you start to think about, well,
*  what are the different qualities that can have these impacts? And what unifies them? And
*  how do we kind of classify them? So I tend to be kind of quite relaxed about this. I mean,
*  in the book I give, as I said earlier, examples of character traits, ways of thinking and attitudes.
*  That I want to say are intellectual vices, but maybe there are other kinds of intellectual vices.
*  I'm kind of quite open about this. I don't think we should be too rigid or too dogmatic about
*  the different kinds of vices that there are. But the important point is that there have got to be
*  personal qualities that systematically get in the way of knowledge or understanding,
*  or if one prefers. And there's got to be some room for blame or criticism. I mean, if somebody
*  says, look, this is a vice, but of course if somebody has this vice, you couldn't possibly
*  blame them or criticize them or indeed say anything but negative about them on account of this.
*  Then I want to say, well, then it's not a vice, right? I mean, it's got to make sense to blame
*  or criticize or negatively evaluate somebody if what they have is really a genuine intellectual
*  vice. Could we imagine that things could be improved if there were an insistence on greater
*  transparency about what people believed? I know that some people have gone so far as to suggest
*  that everyone should make bets on what they think is true in some public forum or prediction
*  markets. Is part of the problem with intellectual vices that there's not enough accountability for
*  being wrong about these things? Well, I'm not sure that that's the case. I mean, if you think about
*  accountability, in the end, the world turns out a certain way and then it becomes apparent
*  what the flaws were in your thinking. I mean, if you're thinking about the Iraq war example,
*  this was a very controversial question in the run up to the war. How many American troops would we
*  needed to carry out a successful invasion of Iraq? So as I understand it, there were huge variations
*  in the numbers there. There were people in the military who thought that the number needed would
*  be something like 300,000 or something like a really big number. And then there were people in
*  the Bush administration who thought that the number needed would be much smaller, that's 40,
*  50,000 or something like that. Now, if you were to say to these guys, okay, so I really want to know
*  what you really believe about this. So put your money where your mouth is, how much you're willing
*  to bet on this. So maybe the people on the small number side said that we're willing to bet a
*  certain amount on the number being small and the people on the other side were willing to bet a
*  certain amount on the number being large and maybe they were willing to bet the same amount. So
*  both sides believe with equal strength in what they were saying. But that in itself doesn't really
*  get us anywhere because then the question is, well, were the people who believe the number was
*  really small justified in believing that and were the people who believe that the number was really
*  big justified in believing that? I mean, that's the question. And that's not a question about
*  the strength of your belief or the strength of your conviction. It's a question about whether
*  you actually have good grounds for your beliefs. Now, in that case, I mean, I would have said that
*  even before the whole, even before we knew the outcome, that the people on the small number
*  side of things were actually wrong, that they weren't justified in believing what they said.
*  And I mean, one reason they weren't justified in believing it is that it went against expert military
*  advice. The people who were defending the large number were actually tended to be professional
*  soldiers and the people defending the small number tended to be professional politicians.
*  And given the choice between believing a professional soldier and a professional
*  politician, I think I know what I would pick. But in any case, history turned out the way it
*  turned out and one side was proved right and one side was proved wrong. So it's not transparency
*  that's the issue. If by transparency, you mean, you know, it's got to be transparent what people
*  think. In this case, it was perfectly transparent what the different sides to the debate thought.
*  I mean, what went wrong is that some people thought the things that they thought on good
*  grounds and others thought the things that they thought are not very good grounds. And that's the
*  fundamental point. Probably if we were having this discussion in 2004, we would bring up examples
*  like this of intellectual vices. And we might even say, you know, it seems to be that these
*  intellectual vices are becoming more prevalent in some way, at least in the political realm.
*  And then 15 years later, we're probably saying, Oh, my God, how naive we were back then. Now they're
*  really becoming prevalent. Is there any way to be fair about talking about whether or not there is
*  some large scale shift towards putting up with or accepting or even intentionally
*  leaning into this kind of wishful thinking, closed mindedness sets of vices?
*  Yeah, so it's very hard to answer this question without, you know, without being being political.
*  I mean, I would say that things have certainly become more vicious in every sense in the last
*  10 or 15 years. I mean, so here's one kind of manifestation of this. I mean, it used to be the
*  case, I think, that politicians who would say things that were clearly false and unfounded would
*  be, you know, would be criticized for that. And there would be people pointing out that what they
*  were saying was false. And that wouldn't make a difference. You know, it wasn't good for them
*  politically to be discovered to be to be talking to be talking nonsense. The thing that seems to
*  have happened recently is that it is that it seems now that actually making false and unfounded and
*  ridiculous claims is not only, you know, politically acceptable, it's actually politically effective.
*  And it seems as though, you know, plenty of plenty of voters no longer regard it as a fatal defect
*  in their politicians, that they talk nonsense, say things that are just plainly not, you know,
*  that are plainly not true. So there's this great discussion of the notion of bullshit. So a
*  philosopher called Harry Frankfurt wrote this absolutely brilliant essay about 30 years ago
*  called On Bullshit, where he distinguishes between lying and bullshitting. Right, so the liar says
*  things that he knows are false, and he says them in order in order to deceive other people.
*  Whereas the bullshit of Frankfurt is someone who just doesn't care whether the things he says are
*  true or false, they're just to have no concern with truth at all. And so I think one way of
*  thinking about what we've seen in politics in the last few years has been the increase in
*  bullshit levels in politics, where bullshit is now, you know, being almost being used as a kind of
*  technique in politics, where, you know, you say something without any, you know, you say something
*  about, you know, immigration or climate change, or whatever it is, and you say something seemingly
*  with no concern at all about whether what you're saying is true or justified or well-founded.
*  And as I was saying, you know, I think 20, 30, 40 years ago, that would have got you into some
*  trouble. And politicians, you know, actually went to some lengths to try to avoid being caught
*  doing that kind of thing. Whereas now, you know, it's just, it seems to be politically acceptable
*  to bullshit. And the attitude that underpins bullshit, you know, this attitude of not giving
*  a shit about the truth or the evidence, I mean, that's, you know, that attitude is an example of,
*  you know, an intellectual vice, a very powerful and these days rather common one in the political
*  realm. So I would say, so my general take on this is fairly pessimistic. I mean, I think things have
*  been getting worse. Someone wrote a book, actually, in which they talked about something which they
*  called peak bullshit. And I guess that, you know, the interesting question is, have we now reached
*  have we reached peak bullshit? Or is there even more bullshit still to come? You know,
*  there's always a temptation to think things couldn't possibly get any worse. And sometimes
*  they do. So I think we really need to be we need to be worried, you know, we need to be really
*  concerned about, you know, the lowering of the intellectual tone and caliber of political debate.
*  I think that's a really terribly worrying, worrying thing. And you know, what's even more
*  worrying than the fact that politicians do it is the fact that, you know, a lot of voters just don't
*  seem to care. So I'm, you know, that's, that's a rather downbeat assessment. But that's what I think
*  anyway. Well, and it's not just politicians, right? Among the people who are not professional
*  politicians, not only is there a greater acceptance of people who do not seem to be that invested in
*  telling the truth, but I know that you have a new book coming out on conspiracy theories.
*  Is this is the is there an increase in the acceptance of conspiracy theories? Is that hand
*  in hand with the acceptance of bullshit? Well, this is a really interesting question. I mean,
*  of course, everyone thinks that conspiracy theories are more popular now than they have ever been,
*  you know, that we're living in the age of conspiracy. I mean, interestingly, there's been some research
*  done on this question about particularly a belief in conspiracy theories in the US. And the empirical
*  evidence is that belief in conspiracy theories has actually been going down in the US,
*  not not going up. So there is an issue here about what the you know, what the actual what the actual
*  facts are. I mean, the research showing this is really, really, really good and very, you know,
*  kind of kind of ingenious, and I think quite, you know, quite convincing. Nevertheless, leaving aside
*  the question of whether conspiracy theories are more or less prevalent. It's true that conspiracy
*  theories are, you know, are, are popular and influential across the world, and you know,
*  particularly in the US. And, you know, one might want to think one might want to relate the whole
*  issue of belief in conspiracy theories to intellectual vices, and maybe there's something
*  in that. But actually, in the book on conspiracy theories, which I've, you know, just finished,
*  and which is coming out soon, I'm actually much more interested in the idea that conspiracy theories,
*  or at least the sort of big ticket conspiracy theories are really forms of political propaganda,
*  that what they're really, you know, what they really do is to advance a political agenda.
*  And, and that's really, you know, that's really their role. And I think they used, you know,
*  conspiracy theories are used quite sort of self consciously in that way. You know, if you if you
*  are, I mean, this is a very contentious example. But if you are, you know, strongly opposed to
*  gun control in the US, and you are confronted by all these terrible mass shootings, then of course,
*  you know, it's going to be quite tempting to say that these are false flags, or that some of these
*  are false flags. And that's just a way to, you know, deflect criticism of, of, you know, of gun use.
*  So that's an example of how, you know, conspiracy theory is not just a theory, you know, it's a way
*  to make a political point and to advance a political agenda. And if you think of them that way,
*  it's not even clear that the people who put these theories forward necessarily believe them. You know,
*  the thing that people often ask is, well, why do people believe conspiracy theories? And I think,
*  you know, it's worth actually just, just, just pausing to reflect on the distinction between
*  the people who invent and promote these theories, and consumers of these theories. And I don't think
*  it's true that everyone who can invent, you know, invents these theories believes them. And I don't
*  even necessarily think it's true that consumers of conspiracy theories necessarily believe them
*  either. But it's all, you know, the fundamental point is that, is that, you know, to think about
*  conspiracy theories, you really have to think about their political role, their political function.
*  And then I want to say that the function of conspiracy theories is, is, is, is that, you know,
*  they're fundamentally forms of propaganda. Okay, good. I'm definitely looking forward to that book.
*  But before we go, I do want to circle back to this idea, or this question of what we personally do
*  about the possibility that we are subject to intellectual vices. You know, whenever I hear
*  people talk about irrationality and cognitive biases and so forth, you can always see people
*  in the audience going, oh, yes, my intellectual enemies are subject to all these things. And it's
*  much harder to look at ourselves. But happily, you've written a whole book on self knowledge.
*  Does does is there an intersection between the search for better self knowledge and the
*  guarding ourselves against intellectual vices? Because probably there aren't that many people
*  who say, Oh, yeah, I proudly have this particular intellectual vice. Yeah, yeah. So I mean, I think
*  it's true that that that, you know, to actually do something about your own intellectual vices,
*  you need to recognize that you have them. And, you know, most of us are really bad at recognizing
*  our own intellectual vices. I mean, we're very easy at recognizing the vices of other people,
*  but not our own vices. And one thing I say in the book is that is that, you know, one explanation
*  for that is that many of our intellectual vices are what I call stealthy vices. They're vices that
*  actually obstruct or block their own detection. So this is relate. I mean, this is the same ballpark
*  as the famous Dunning-Kruger effect. So, you know, the kind of pop version of the Dunning-Kruger
*  effect is some people are too stupid to know how stupid they are. Right. So that's that's a case
*  where, you know, the trait itself, stupidity blocks its own detection by the person who has it who has
*  that trait. And I think that's also true of many intellectual vices. And of course, as long as we
*  don't recognize our own intellectual vices, the whole question of what we are going to do about
*  them doesn't even arise. But although we are reluctant, I think, to recognize our own vices,
*  it isn't actually an impossible thing to do. And, you know, the way that our intellectual vices
*  really come out is when they have terrible consequences. And when their consequences
*  make it apparent that we have those, you know, we have those vices. I mean, again, you know, having
*  bad consequences isn't a guarantee that you'll recognize them because you may have other vices
*  that make you kind of explain it all away in some other way. So I guess I'd want to say that, you
*  know, there is a connection with the whole topic of self-knowledge. It is difficult to get to know
*  our own intellectual vices because many of these vices are stealthy vices. But it's not impossible
*  to know our own intellectual vices. I mean, you know, it is possible, I think, for some of us to
*  actually, you know, be honest with ourselves and actually think in a serious way about
*  our own intellectual attitudes and character traits and thinking styles. And, I mean, just one
*  thing to just, you know, point out. If you think of prejudice as an intellectual vice, as well as,
*  I believe, a moral vice, it's actually not true that people don't recognize their own prejudices.
*  I mean, I've seen, you know, an opinion survey of people in the UK asking them,
*  would you say that you are racially prejudiced? And, you know, something like a quarter or a
*  third of people said yes in answer to that question. So it's not, it's actually not true
*  that people don't recognize their own intellectual vices. They do recognize them. I mean, maybe these
*  people who said that they were prejudiced wouldn't accept that there's anything wrong with being
*  prejudiced. But maybe some would. I mean, you know, maybe we should give, maybe we need to have a
*  kind of more sophisticated view about what truths about themselves people are willing to recognize
*  and what truths about themselves they're not willing to recognize. Yeah, I guess I'm thinking
*  mostly about things like wishful thinking, because that's probably of the vices that you've gone
*  through, the one that I can see in myself the most vividly. I think that wishful thinking is bad.
*  I know that I do it. I try not to do it. And yet I do it. I mean, maybe I'm better at avoiding it
*  now than I was when I was younger. But I mean, I don't know, are there exercises one can do? Is it
*  should I be meditating? Or are there just philosophical brain stretching exercises that
*  I can train myself to have fewer intellectual vices? Well, in the case of wishful thinking,
*  I mean, I'm going to simple question to ask yourself is, is this wishful thinking, right?
*  I mean, supposing you have a favorite sports team, and you know, you're convinced that,
*  you know, they're going to win the Super Bowl or whatever it is. You know, I mean, I think
*  a perfectly sensible question to ask yourself whenever you make a prediction like that is,
*  is this just wishful thinking? Am I saying this? Am I thinking this because it's, you know,
*  it's really the outcome that I want? Now, maybe you won't be able to answer that question. I mean,
*  maybe you can't be sure, you know, what's really driving you in this case. But it's a question that
*  you can certainly raise for yourself on these occasions. And something that I think very,
*  you know, all of us are able to do is after the event, we're quite often willing to say, well,
*  I guess that was just wishful thinking. You know, so it's not completely kind of beyond us
*  to accept that wishful thinking might be playing a role and also, you know, detecting it, you know,
*  after the event. I mean, I don't suppose that it's possible to prevent it altogether. I mean,
*  I think wishful thinking is just we are sort of hardwired to do it to some extent, but there are,
*  you know, there are degrees of it. And I call my view in the book, a kind of moderately optimistic
*  view about suffices. I mean, what I mean by that is that, you know, there is the kind of pessimist
*  who says, we're just stuck with these things. It's just nothing that we can do about them.
*  And I don't think that's plausible. But equally, I also want to accept that, you know,
*  tackling our own intellectual vices is difficult. It's hard. And that it isn't always possible to
*  do it very effectively. But, you know, the choice isn't between, you know, completely being
*  completely in control and having no control. I mean, you know, I think we're sort of somewhere
*  in the middle, we have some degree of control. And it's a matter of kind of, you know, exercising
*  whatever control we have over these personal qualities that are doing us no good.
*  I probably should have asked this earlier, but it brings to mind this question of,
*  is there an intellectual vice of the sort of kind of unequal or biased attention to different things?
*  Like if I see prejudice against my group, I'm hypersensitive to that. If I see prejudice
*  against someone else's group, I can go like, yeah, you should suck it up and deal with it.
*  Is there some intellectual vice that qualifies as that?
*  Yeah, well, I mean, it's a kind of bias, right? So there's that, that would be one way to describe it.
*  I mean, this isn't really an intellectual vice, but I mean, something else that's a very powerful
*  force is, you know, is a kind of persecution complex. You know, the idea that bad stuff that
*  happens to your group, to the in-group is, you know, particularly terrible and much worse than
*  anything that happens to other groups. So I think, I mean, that would be a case where there are
*  intellectual factors at play, but there are also kind of moral factors, you know, and maybe that's
*  also something that's worth thinking about, of how intellectual vices interact with moral vices,
*  and whether there's really a sharp distinction between intellectual and moral failings.
*  And I think that a lot of the intellectual failings that I talk about seem also to be
*  moral failings, you know, closed mindedness seems to be a moral failing. But then there are other
*  intellectual vices that aren't. I mean, I'm not sure I'd want to call gullibility a moral failing,
*  you know, or foolishness a moral failing. So I think there are kind of quite subtle, you know,
*  there are quite subtle questions here about how these two things interact. And the example that
*  you just gave is one that, you know, just brings out how complicated this is.
*  Well, it is complicated. I think that if nothing else, you know, the whole discussion
*  probably is a little bit unfair, but it's kind of depressing to think about all these vices that
*  we're all subject to. But maybe sunlight is the best disinfectant. If we keep talking about them,
*  people will automatically become a little bit more self correcting.
*  Yeah, I mean, hopefully, that's right. And, you know, the other thing that I would urge people
*  to do is not only to reflect on their own, you know, intellectual vices, but also just to think
*  about, you know, why this topic really matters, you know, and think about these big political
*  events in political developments and just think about how these vices have really had a, you know,
*  significant impact there. And I think that that should really bring home to people that look,
*  you know, this really matters. You know, this isn't just abstract philosophy, it matters.
*  Well, I've had a couple of podcast episodes on the nature of democracy. And I think maybe you
*  make this point in the book, or maybe I just overlaid it on top. But if we live in a democracy,
*  these things matter a lot, we make choices, you know, the power of governing our future as a
*  society and a polity is in our hands. And therefore, it's kind of our responsibility,
*  not just for our personal lives, but for the rest of the world, to try to be as intellectually
*  virtuous as we can. Yeah, I mean, absolutely. So if you're thinking about the basis on which you
*  vote for one one side or another, I mean, you know, it is for democracy to work well, it's quite
*  important that that voters actually, you know, know something about what the policies are of the
*  different political parties and take the trouble to find stuff like that out. And, you know, maybe
*  one of the things that's going wrong at the moment is that people aren't really interested in that so
*  much as, you know, identity politics, you know, just voting on the basis of, you know, he's one
*  of us or not one of us. And that's had some pretty dramatic consequences on politics. So I completely
*  agree that that, you know, you can't really have you can't really have a well functioning democracy,
*  along with, you know, massive intellectual vices affecting both leaders and the lead. I mean,
*  that's just not going to end well. Yeah, I suspect that these things are never going to go away. But
*  we can at least, you know, keep up the good fight against them. So, because he's on thanks so much
*  for being on the podcast. No, it's been my pleasure. Thanks very much.
