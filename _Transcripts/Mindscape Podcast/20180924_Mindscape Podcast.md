---
Date Generated: June 10, 2024
Transcription Model: whisper medium 20231117
Length: 5041s
Video Keywords: ['brain', 'language', 'neuroscience', 'thought']
Video Views: 35108
Video Rating: None
Video Description: Blog post with show notes: https://www.preposterousuniverse.com/podcast/2018/09/24/episode-15-david-poeppel-on-thought-language-and-how-to-understand-the-brain/

Patreon: https://www.patreon.com/seanmcarroll

Language comes naturally to us, but is also deeply mysterious. On the one hand, it manifests as a collection of sounds or marks on paper. On the other hand, it also conveys meaning â€“ words and sentences refer to states of affairs in the outside world, or to much more abstract concepts. How do words and meaning come together in the brain? David Poeppel is a leading neuroscientist who works in many areas, with a focus on the relationship between language and thought. We talk about cutting-edge ideas in the science and philosophy of language, and how researchers have just recently climbed out from under a nineteenth-century paradigm for understanding how all this works.

 David Poeppel is a Professor of Psychology and Neural Science at NYU, as well as the Director of the Max Planck Institute for Empirical Aesthetics in Frankfurt, Germany. He received his Ph.D. in cognitive science from MIT. He is a Fellow of the American Association of Arts and Sciences, and was awarded the DaimlerChrysler Berlin Prize in 2004. He is the author, with Greg Hickok, of the dual-stream model of language processing.
---

# Episode 15: David Poeppel on Thought, Language, and How to Understand the Brain
**Mindscape Podcast:** [September 24, 2018](https://www.youtube.com/watch?v=aBOqKmRXSAA)
*  Hello everyone and welcome to the Mindscape Podcast. I'm your host Sean Carroll and let's
*  start with a very quick meta note about what's going on with the podcast. In particular,
*  I wanted to mention that we now have transcripts of every episode that are going to appear
*  on the webpage with the individual posts for the episodes. We'll have the entire transcript
*  as soon as it appears. This of course costs money. I'm not doing it myself. So a huge
*  thank you to those who are supporting the podcast on Patreon. You're the ones who made
*  that possible. So I think this is going to be very good both for accessibility and also
*  for searchability. You can go in and you can see what the podcast is about even before
*  you listen to it. Search for terms throughout the whole archives. That's going to be really
*  good.
*  Moving on to today's show, I want you to think about what is happening in your brain at this
*  very moment. You're listening to my words or you're reading the words if you're reading
*  the transcripts. One way or another, there's a signal coming in. Let's just say that you're
*  listening so you're hearing sounds. So there's a vibration going on in your eardrums, words,
*  sentences and so forth. And you can recognize these words just like you can recognize nonverbal
*  sounds. But there's something else going on that by the set of words coming in, we create
*  meaning. We attach to these words, to these sounds that we're hearing some picture of
*  what I'm trying to say, some relationship between these sounds and something out there
*  in the world or some abstract concept or something like that. So how does that happen? How is
*  it that a bunch of sounds hitting our eardrums get turned into meaning inside the brain?
*  That's what we're talking about on today's episode with Professor David Purple, who is
*  a professor at NYU and also the director of a Max Planck Institute in Frankfurt, Germany.
*  I love this. His Max Planck Institute is called the Institute for Empirical Aesthetics. I
*  have no idea what that means, but I know that what David does is actually study what's going
*  on inside your brain. He studies it not primarily with the standard fMRI picture, which is when
*  you put someone's brain inside someone's head, you don't take the brain out, you put someone's
*  head inside a machine and look at where the blood is flowing to, to pinpoint where things
*  are happening in the brain, which is very precise in terms of where things are happening,
*  but it's slow. You can't see when things are happening. So mostly David uses MEG machines,
*  Magneto Encephalograph machines, to see exactly when a thought is happening inside your brain.
*  In fact, if you have my book, The Big Picture, you can see an image of my brain, not the
*  conventional wrinkly crinkly thing that you use from pictures of the brain, but just a
*  very crude image of the quadrants of my brain in which different magnetic fields are appearing
*  as charged particles race around from neuron to neuron, perfect evidence that I really
*  do have a brain inside my head. So it turns out that this question we're asking about
*  how sounds get turned into language and meaning, people have thought about this for a long
*  time. There's a standard model, if you like, but that standard model appeared in the 1800s
*  and has not been updated as much as you would like since then. So with his collaborator,
*  Greg Hickok, David Purple has suggested a updated model, something called the dual stream
*  model, which isolates not just one part of the brain, but different parts of the brain
*  that are responsible for different aspects of language processing. We'll talk about that
*  exactly how it works. And also just because David is an opinionated guy, we'll talk about
*  all sorts of other issues in neuroscience, including the role of big data, how we're
*  coming along and understanding memory and so forth. So let's go.
*  David Purple, welcome to the Mindscape podcast.
*  Hi there. Nice to be here.
*  Yeah, this is completely by accident that we met each other or, you know, we've known
*  each other for a while. You were a famous participant at the Moving Naturalism Forward
*  meeting back in 2012. But now we happen to be in the area where you live. So of course,
*  I'm going to podcast you and that's great. What let's start by laying the groundwork.
*  I'm trying to think of a way for the audience to describe what you do for a living. You're
*  like a professor in half of the departments of the various universities that you're a
*  member of. Is it OK to say thought and language?
*  It's fair enough. I mean, the one liner that I try to remind myself of is study how you
*  go from vibrations in the ear to abstractions in the head. So as we're having this conversation,
*  the only signal you're actually getting is your eardrum vibrating because I'm sending
*  sound your way. And amazingly, that turns into abstract ideas, words, ideas in your
*  head. So the fact that that works at all is already amazing and weird. And all the sub
*  process sub process are things that I study in my labs.
*  Yeah, I mean, it's a great way of putting it because really the position of the eardrum,
*  it only vibrates in one dimension, right? It's only in and out. So we get one number
*  time stream into our brain. And from that, we create everything we think about.
*  It's the fact that it works at all is astonishing. And the fact that it works at the speed
*  at which we're doing it is even more astonishing. You have a bunch of you know, you have tens
*  of thousands of words stored in your head. And we're sitting in this, you know, my lovely
*  backyard in Connecticut. And it's a little bit noisy. We might see a bear walk by. And
*  it's and yet you can extract complicated information in, you know, segments of tens of
*  milliseconds. How does that work at all? And so those are the kinds of problems I worry
*  about. And that includes obviously listening to music, listening to sounds that are not
*  speech. But the major emphasis in my lab is on speech perception and language comprehension.
*  Just a note for podcast listeners, if a bear does walk by, I will let you know, but we
*  are inside. We're relatively safe, right? Ish. I'm thinking the bear could probably
*  get through these flimsy walls that are surrounding us.
*  Well, we're looking pretty we're looking pretty tasty. So we got to be careful. All
*  right, we'll be careful. So good. So how do you go about doing this? Well, actually, let
*  me back up even before we get to how you go about it. What got you here? Like, did you
*  when you were 10 years old, start thinking I want to understand how audio signals in
*  my ear turn into abstract thoughts?
*  Exactly. Good for you.
*  Exactly what I wanted to know when I was 10, 12, even 16. Yes, as a pubescent boy, those
*  were my main thoughts. No, I got there completely by accident or partial accident. I am after
*  college, I really wanted to be an actor or rather a director. I really wanted to be a
*  director. Everybody wanted to be a director. I really wanted to be a director, partially
*  because my wife is an actress and she was a successful actress. And then we thought,
*  well, one of us should have a job. So I thought I should perhaps go to graduate school. And
*  I ended up accidentally in a neuroscience lab working for a distinguished neurobiologist
*  at MIT, learning how to do neurophysiology and all the different using the different
*  tools. But in the back of my head, I liked language. I grew up in a very multilingual
*  environment and it was sort of, you know, something I had a gut level intuition about.
*  And people at that point said, you know, there's a famous language researcher here, you
*  should probably go listen to some of the lectures. His name is Noam Chomsky. Oh, that's
*  interesting. I'll go to some of those lectures. And I did. And that was sort of like,
*  somebody opens the curtains for you.
*  Right. You go to some of those lectures and you suddenly have a completely different
*  view of how language can be looked at, studied, investigated. And it really that's a
*  that's a game changing experience. And at that point, I decided to go to graduate school
*  to study language works, how speech works, and then began to connect it to serve my
*  interest in biology. So it's accidental that I'm, you know, I really did want to be a
*  director. I'm not kidding. I still want to be a director.
*  No, like you're young, you can do it.
*  But now I'm a director of a McPunk Institute. So that sort of counts.
*  No, it doesn't quite doesn't count at all.
*  Doesn't quite have the same vibe.
*  So put Noam Chomsky in perspective for us since you mentioned him. I mean, obviously,
*  he's a huge name. He's a huge name, not only in the academic field of linguistics and
*  psychology, but outside. So forget about the outside in the politics. My impression is
*  that my impression is completely untrustworthy here. So I'm hoping you'll correct it,
*  that Chomsky was extremely influential, but there's a sense of moving beyond him. Or
*  have we simply improved upon what he I mean, tell us a little bit what he had to say and
*  how we think of it today.
*  Yeah. I mean, so so he remains an incredibly influential and very polarizing figure. So
*  his his influence derives from the fact that he really changed how we do psychology and
*  language sciences and philosophy of mind in the mid fifties. So based on a series of his
*  early books and papers, he first of all, effectively got rid of behaviorism. And one
*  can even pinpoint that into behaviorism. So behaviorism was the dominant view in psychology
*  for decades before that. And it's a very sort of pleasing and simplistic view. And
*  effectively, it boils down to there's one principle of the mind, which is the principle
*  of association. Okay. So it's the basis for all of the theories of conditioning.
*  Conditioning under underlies learning. Conditioning underlies effectively all of
*  behavior. So the term behaviorism became used as a sort of catchall phrase for all of
*  psychology. And psychology was based on the principle of association. Now, that's a very
*  nice and Pavlov and his dog, Pavlovian conditioning, operant conditioning. And then,
*  of course, the most, let's say, egregious direction, which has went is Skinner's work. So
*  Skinner's B.F. Skinner had famously and professor at Harvard worked on the Skinner box, but the
*  presupposition that you could put your even your own children, and I don't begrudge him this idea
*  as a father of three sons, nice idea, put them into a box and train them explicitly to respond
*  in selective ways to certain stimuli. And so the stimulus response, stimulus response paradigm was
*  the dominant paradigm for learning memory for everything in psychology and neuroscience.
*  Does some of this I know this is attention, but that's okay, we have time. Does some of this
*  reflect to the influence of positivism in the sense that, you know, rather than looking for some
*  underlying mechanisms, we should just look at what happens in the world and describe it as fully as
*  possible. And I think the more sophisticated behaviors certainly were, you know, avid readers
*  of, you know, Viennese positivism, I would think. But the so I think that the most disturbing part
*  of the story of behaviorism is that it's still around, of course, deeply, and certainly true in
*  my field in the neurosciences, I think it's actually the default position. And now the
*  influence of Chomsky was to argue, in my view, successfully that you really wanted to have a
*  kind of mentalist stance about psychology. And he had a lot of very interesting arguments. He also
*  made a number of very important contributions to computational theory, to computational linguistics,
*  and obviously to the philosophy of mind. And we're, you know, we're bracketing his political work.
*  Yeah, which is interesting, but it's separate.
*  It's completely separate. Although I think he doesn't see it as completely separate in a
*  principled sense. But it is separate. And you know, he's, as you know, very well known in Europe as a
*  political dissident, in some sense. And he's basically not invited on most US channels, because
*  he's too obnoxious. You just don't hear him. You see him on TV shows in the Netherlands, but in the US,
*  you know, he's on some kind of fringe radio show in Cambridge, Massachusetts, or something. But he
*  is, I mean, he's difficult. I actually just finished a chapter a couple of, you know, last year or so
*  called The Influence of Chomsky on the Neuroscience of Language. And because, you know, many of us are
*  deeply influenced by that. And the fact of the matter is his role has been both deeply important
*  and moving and terrible. And it's partly because he's so relentlessly undidactic. If you've ever
*  picked up any of his writings, he's just, it's all about the work. He's not there to make it bite size
*  and fun. He assumes a lot, a lot of technical knowledge and a lot of hard work. And so if you're
*  not into that, you're never going to get past page one, because it is technical. But that's made it
*  very difficult, because it's, you know, it sort of seems obscurantist to many people.
*  It's always very interesting. There's so many fields where certain people manage to have huge
*  outside influences, despite being really hard to understand. That's, is it partly the cache of
*  the reward you feel when you finally do understand something?
*  I mean, I wish that were true. That would mean a lot of people would read, let's say, my boring
*  papers. But the, I think in the case of Chomsky, it's true because there are superficial
*  misinterpretations and misreadings that are very catchy. And at people, so the, you know, people,
*  the most famous concept is, you know, language is innate. Right. Now such a claim was never made,
*  never said. It's much more nuanced. It's highly technical. It's about what's the structure of the
*  learning apparatus. What's the nature of the evidence that the learner gets. So obviously,
*  this is a very sophisticated and nuanced notion. But what comes out is, oh, that guy's claim is
*  language is innate. But I can remember that and repeat it at cocktail parties. Exactly. I mean,
*  and that's, that's a little bit unfortunate because, you know, that's true for all fields. I mean,
*  if there are sort of nugget-sized one-liners, they're fun to remember, they're fun to talk about,
*  but they're probably almost always wrong. That's right. Stuff's complicated. Yeah, stuff is
*  complicated. But so generative grammar is the other phrase that I associate with Chomsky. All
*  my Chomsky comes from reading the language instinct by Steve Pinker. Yeah, no, I mean,
*  so Steve, one of my professors in graduate school, did a, you know, remarkable job
*  popularizing the language sciences and linguistics, although he's himself actually
*  not a linguist. He's a psychologist, right? But of course, lots of the interpretation of what people
*  think about Chomsky comes through the lens of how Pinker wrote about it. And of course, that has
*  its own interesting flavors, right? So, I mean, Steve's a remarkable writer and, and
*  fabulously interesting thinker, but you know, he has his own lens. Yes. And one should probably
*  go to the source and read the actual material to understand. You know, I'm writing a book about
*  quantum mechanics right now and everyone should read it and everything I say in it is correct,
*  but it's not necessarily what anyone else thought in the past, even though I try my best to represent.
*  No, no, I think in your books, of course, every word is true. Yeah. It goes without saying. That's
*  good to know that there's some people out there like that. But I mean, yeah, sometimes, I mean,
*  especially in the, in the, let's say, technical disciplines, you have to do the hard work and you
*  can't cut any corners, right? So you have to actually get into the technical notions and why
*  they were, what are the presuppositions? What are the, let's say, hypothesized primitives of the
*  system? How do they work together to generate the phenomena we're interested in? So on. So, yeah,
*  the concept of generative grammar, very interesting. It's a notion of grammar that's trying to go away
*  from simply a description or list of factoids about languages and trying to say, well,
*  how is it that you have a finite set of things in your head? I mean, a finite vocabulary and
*  ostensibly a finite number of possible rules, maybe just one rule, who knows, but you can generate
*  and understand an infinite number of possible things. That's the concept that's typically
*  called discrete infinity. Yep. And that's a, that's a cool idea. And the idea was to work it out.
*  Well, if, you know, if those are the, if that's the parts list, how can you have a system and how
*  can you learn that system, acquire that system? How can that system grow in you? And you become a
*  competent user of it. And that's actually subtle. And that's, you can't just, right? So it requires
*  thinking deeply about, well, what is, what is actually the parts that's the architecturally
*  given to you as a human being, having a human brain? So in which sense do we have to be parochial,
*  a human brain, brain has its own properties and which things are sort of, let's say,
*  general properties of the vertebrate. Right. So, and those are, how do they interact? What do you
*  need? Is there extra special sauce? Do you need God? God forbid. And things like that. So these
*  are a bit, and of course this has had a tremendous influence on how we think about the system and how
*  we study it, what kind of methods we can use, and what are the bigger questions. But it's safe to say
*  the mind is not a blank slate, right? The brain does have functions. Pretty much, pretty much a good bit.
*  I think you can put that one in the bank. And when it comes to language, there is something,
*  what I remember from Pinker is that there's in some sense a set of switches in the brain,
*  hypothetically, which sort of by learning different languages, we flip one way or another.
*  I think that's a pretty fair way to think about it in a non-technical. So you can think of it as
*  parameters or something like that. I mean, people think about it in many different ways, but I mean,
*  we can certainly assume that we have a system. So look, let's back up for a second. Suppose we were
*  talking about the visual system and not the language system. We wouldn't be having this
*  discussion because people say, obviously you have a visual system, you have it because you're a
*  vertebrate brain, and obviously it changes in some specifics as a function of what's around you.
*  This is not newsworthy. But as soon as we talk language, everyone's an expert. Everyone speaks
*  the language, everyone has a powerful intuition, and the amount of nonsense promulgated is
*  kind of astonishing. The level of silliness is kind of...
*  No, I'm very sympathetic. I've written three popular books so far, one on the nature of time,
*  one on the Higgs boson, and one on the big picture and the meaning of life. By far, the best Amazon
*  reviews are for the Higgs boson book because no one has a pre-existing view of the Higgs boson.
*  They're willing to take what you have to say about it, but they think they know the meaning of life,
*  and they think they know how time works. And if you don't agree with what they have to say,
*  they're not going to be receptive. Yeah, no. It's again, there's something about...
*  Well, in the arts, I guess it would be called connoisseurship.
*  Do we still appreciate the pain in the neck of having to do the hard work to become a connoisseur
*  or have technical knowledge in something? And well, whatever, it takes a long time. It's hard,
*  and you might not get very good at it, but it turns out to be required. So if you want to become
*  really good at knowing the old masters of the Netherlands, you can become a connoisseur only if
*  you actually study it. Likewise, with language or the brain or physics, well, damn, sit down, do the
*  work. So having said that, let's proceed to drastically oversimplify how the brain works.
*  So where did you go after being inspired by Chomsky and started studying how the brain
*  processes what we hear? Yeah, I studied a lot of the technical aspects of language for a while,
*  and I became relatively quickly, like everyone else of my generation, I guess, seduced by the
*  possibilities that we now have of recording from the human brain. So when I was a graduate student,
*  about halfway, early on in graduate school was the time when the modern brain imaging machines
*  were actually first developed and first rolled out. So for many years, we had things like X-rays and
*  CAT scans, but in the late 80s, there was a lot of research using PET scanning, that's positron
*  emission tomography, a very onerous and in some sense invasive technique to take pictures of the
*  brain while it was processing something in a complicated way with a lot of analytic steps.
*  And then the early 90s, there was really a kind of game changing event, the development of functional
*  magnetic resonance imaging, FMRI, we call it, and everybody's probably seen an MRI machine,
*  it's in every hospital, if you've blown out your knee or your shoulder or, God forbid, you've had
*  your head scanned, and those are ubiquitous. And there were a lot of interesting developments, both
*  in the physics of magnetic resonance and in engineering and signal processing, that allowed
*  us to begin to use these machines to measure and quantify the human brain while something is
*  happening. So you're lying in this, it looks like, you know, I don't know, a giant hairdryer or a tube,
*  you're lying in this sausage, and it's taking, it's really taking pictures, it's called a tomographic
*  technique, it's an imaging technique, and it was able to take pictures of which parts of your head
*  were, you know, informally speaking, active when you were doing something like listening to words
*  or listening to a piece of music or moving your right finger or looking at a checkerboard, those
*  are the usual experiments. And blood flow is the proxy for activity, right? And there the proxy is
*  blood flow or actually blood oxygenation. Okay. And so that was an interesting technique because you
*  could take not completely non-invasively, like it's kind of cool, imagine you can take a picture
*  inside someone's head from a meter away, who knew? I mean, that's, you know, with a resolution, by the
*  way, of about a millimeter these days. I was going to ask about the resolution. So the spatial resolution
*  now with the machines that we use is on the order of a millimeter, sometimes even better. So, you
*  know, there are high resolution scanners, for instance, at seven Tesla, which is, you know,
*  really pretty substantial magnetic field. And you can scan things with a resolution better than one
*  millimeter, which is pretty good. But what do you give up for that wonderful picture? You give up
*  temporal resolution, right? So now you take a really, really great picture of someone's head,
*  but the dynamics that you're able to capture are very, very slow. So what have you given up there?
*  Well, cool picture, but no nothing about the change or the actual online processing. And by the way,
*  a cubic millimeter brain still has a buttload of neurons in it, right? It's not a neuron by neuron.
*  Buttload or a shit ton. I mean, it depends on what your units are. But the you want to be the,
*  if you take a square millimeter of tissue in the brain and the cortex and the cerebral cortex,
*  and you look in the cortical column above, right? So the cell, the tissue that's directly above a
*  square millimeter, it goes up about three millimeters or so, depending on where you are.
*  Estimates are that's on the order of a hundred thousand neurons. And that's just the neurons.
*  There's other junk in there, right? So the parts list of the brain is very complicated. There's
*  lots of little stuff in there. So we vastly underestimate what's going on in even, you know,
*  certainly a cubic millimeter of cortex. We have no idea. Right. Okay. I mean, it's shameful.
*  But anyway, you were mentioning that we also don't have pinpoint timing of what's going on.
*  So now, so yeah, so here things get interesting because we have to, so let's say we want to,
*  you know, we're committed to studying the human brain and there's stuff you can learn from,
*  from animal research, very important stuff. And you can do other kinds of experiments that we can't
*  and should not do with people. Right. So there you can use techniques that have even higher
*  spatial resolution, even higher temper resolution, but, you know, except for very extreme medical
*  cases, those are not appropriate. So we have to use noninvasive techniques. So you're talking
*  about things where animals are sacrificing themselves to the cause of science. Yes. And
*  in very important ways. And, you know, if you've ever gone to the dentist, then you should be very
*  grateful for their research. If you've taken now there are, you know, this is a very politically
*  sensitive and complicated topic. To what extent do we support animal research? I'm a hundred percent
*  enthusiastically in favor of careful, responsible, ethically executed, well-managed animal research.
*  There is no alternative for it. And there are currently wild and scary debates about this in
*  Europe in particular, more active than the United States. And they're quite terrible. And they're,
*  they're, you know, the debates, the debates are irrational, vitriolic and dangerous.
*  And they are leading to a sharp reduction in, you know, careful animal research. So we, of course,
*  it's not necessary for, you know, as far as I'm concerned for, let's say, cosmetics or something
*  like that. Shampoos. Forget that. Right. But they're, you know, to understand basic principles of
*  physiology. And we have no alternative. And I think it'd be, you know, a very peculiar stance not to
*  advance that. So, but at this point, we do not take human subjects and pry open their brains.
*  We do not. And we should not. And so we have, so there are wonderful new techniques that are used
*  and, you know, everyone talks about them. Optogenetics is a particularly exciting one. You can
*  treat cells, you can inject cells with particular light activated molecules such that you can then
*  control their activity, but you can't do that with people. You can record single cells for
*  in animals, but you can only do it under rare conditions in humans, for example, during epilepsy
*  surgery. But so look, we have non-invasive techniques that are amazing. I mean, there are,
*  so we can take MRI pictures of your brain, but then we're sacrificing time. And if you don't
*  believe time matters, you, how fast do you think our conversation is going? So our conversation,
*  if you measured it, the mean rate of speech across languages, by the way, it's independent of
*  languages between four and five Hertz, right? So the amplitude modulation of the signal. So the
*  signal is a wave. You have to imagine that there's any signal, but the speech signal in particular is
*  a wave that just goes up and down in amplitude or informally speaking in loudness, right? So the
*  signal goes up and down and the speech signal goes up and down four to five times a second.
*  What does the speech signal mean? This is what your brain? So the speech signal is the stuff
*  that comes out of your mouth. Okay. Okay. Right. So I'm saying your computer is gray. That is a,
*  let's say that was two and a half seconds of speech. It came out of my mouth as a wave form.
*  And that's the way form that vibrates your ear, your eardrum, which is cool. But if you look at
*  the amplitude of that wave form, right? It's a signal amplitude going up and down. It's actually
*  now, you know, this is, this is not debated. It's four to five times per second. This is a fact
*  about the world, which is pretty interesting. So the speech rate is where the so-called modulation
*  spectrum of speeches is four to five Hertz. Is it very different for different mammals?
*  It's a good question. We don't know so much about that because nobody localizes as much as we do.
*  It's probably a little different because it has to do with sort of the cortical processing rate.
*  And of course the biomechanics of the articulator. So it's likely to be a little different music,
*  incidentally, has a modulation spectrum. That's a little bit slower. It's about two Hertz. So
*  that's equivalent to roughly 120 beats per minute, which is pretty cool. Favorite number. Yeah. So
*  a favorite number really comes out when you do the physics of signals. If you take dozens and
*  dozens of hours of music and you calculate what is the mean across different genres, what is the
*  mean rate that the signal goes up and down? It's two Hertz. Cool. Cool fact. You should remember it.
*  That's science. We science the hell out of that. So speech happens very fast. And in that rate,
*  so if our mouth opens four to five times per second, that's not fast enough yet because of
*  course inside those, that's roughly the rate of syllables, but syllables have internal structure.
*  So that means it must be going even faster, faster than a hundred milliseconds. So if you
*  really want to understand what's going on as stuff comes into your head, whether it's hearing
*  or vision or touch, you need devices that can measure things at the rate of milliseconds,
*  you know, or tens of milliseconds, a thousandth of a second. That's absolutely necessary because
*  that's the speed at which our mind and our perceptual apparatus works. So there are other
*  tools that we use. And fMRI was? And fMRI's time resolution is on the order of at best a second,
*  but more likely, you know, seconds, five seconds, eight seconds. So now we need different machines.
*  So we have one kind of machine like MRI that takes really detailed pictures in space, but has
*  miserable temporal resolution. On the other hand, there are other tools. The most well-known one is
*  electroencephalography. It's been around since the 1920s. And that has, those are electrical
*  techniques. So they have very good temporal resolution. So you can measure things at the
*  outside of the head using electrodes. And now you have very, very high temporal resolution,
*  as high as you want, depends on your processor, let's say 1000 samples per second. Right? So
*  really, so every millisecond you measure the data. That's still very low for some processes
*  in physics, that would be ultra slow. Oh, we're septoseconds. Yeah, but that's okay.
*  Between friends, what's the big deal? What's a few orders of magnitude?
*  And so you want to pair, you want to have those machines too, right? Because you want to,
*  since processing is fast, you want to be able to understand, well, how does, you know, what's
*  actually happening at those timescales. And for that, my own favorite technique is one called
*  magnetoencephalography. And that measures the magnetic fields generated by current flow in
*  your brain. And it's the most sensitive technique we have to measure the human brain noninvasively.
*  It looks like a giant hairdryer. And that giant hairdryer has little detectors in it
*  typically, then they don't see them, obviously, they're inside the hairdryer,
*  and they're swimming in liquid helium to keep them at superconducting temperature.
*  And they're little coils. And let's say there's about, you know, 150 above them inside of in
*  surrounding your head. And then you can measure the brain activity at let's say a millisecond
*  resolution and reconstruct as best you can how fast and where things happen. So you really want
*  to pair these different techniques if you want to have an increasingly comprehensive thing. And I
*  remember not that long ago, I stuck you into one of those machines. I was in the in fact,
*  I got a lot of mileage out of that. You stuck, I stuck your head into an MEG machine. MEG, yeah.
*  And we measured your brain response to different tones and a few visual stimuli. And it turns out
*  your brain worked. You confirmed the existence of my brain. I was very happy. So the news was good.
*  All is well. The internet has mixed reviews on the existence of my brain. So I was glad you could
*  confirm it using science. We found all the parts and no extra parts. So it's all good.
*  And I like it especially because there's physics, right? The reason why you could get the signal is
*  because a thought is manifested by charged particles being accelerated. That's right.
*  And that's where the magnetic field comes from. It's amazing. Again, amazing that it works, right?
*  So I mean, the fact that we can have a conversation is a mechanical wave vibrating your ear,
*  which turns into electricity in your auditory periphery, which sends a signal using a code we
*  don't yet understand into different parts of your brain, where it's decode, where it's decoded or
*  represents information using some code that we also don't understand using electricity,
*  which flows around generating magnetic fields. Yeah. I mean, it's wild out there. You have a
*  lot to do. There's a lot of science. But it's pretty cool that it worked that we can do it at
*  all suggests that using the insights and tools of physics and the sort of the toolbox of physiology
*  is the best way to go. And so if you have a theory, that's my, that's the other tool.
*  That's the next step. I was going to say we have learned something by doing all these things,
*  right? We've changed how we think about how language is processed. It's not just,
*  maybe we can do this. We've made progress. We've made, I think, good progress. And I'd say,
*  it's very hard to measure in this area of research, what would constitute compelling progress, right?
*  And what universe would we say, holy cow, we have a true explanation. We got it once and for all.
*  And partly that has to do with what do we think is an explanation. And that's a very complicated
*  concept in its own right, whether you're thinking about from the point of view of philosophy,
*  the sciences, you know, sort of an epistemological idea. But we do have, let's say,
*  what we have for sure is better descriptions, if not better explanations. And the descriptions
*  have changed quite a bit. And that being said, and I don't know what the time scale is that
*  would count as success, but I think it's, we can sort of say that we've had the same paradigm for,
*  we've had the same neurobiological paradigm for about 150 years since Broca and Valnecke,
*  since the 1860s, actually, a very straightforward idea, you know, so that's older than
*  electromagnetism. Yes, that's the same age. And then that should worry you. It's older than
*  statistical mechanics. And so what should worry about that is that that model is still so what is
*  that model? Let me tell you. I mean, the idea was, well, language is a some faculty of the mind,
*  it lives, whatever that means, in the left hemisphere, typically. And so the model says,
*  and there's a blob on the front part of your brain and the frontal lobe on the left side,
*  and there's another blob of tissue in the posterior part of your brain and the temporal lobe,
*  they're connected by a wire, which has the charming name arcuate fasciculus. And that's what you get,
*  you've got an area for production, an area for comprehension and a wire that connects the two.
*  And if you go and there's a couple extra wires, but they're not, you know, they're not talked about
*  much. If you go to classic neurology textbooks now, and if you have a stroke, the chances are
*  probably better than, you know, 10 to one that the neurologist examining you will refer to that
*  figure. And that model, and that really should worry you. And was that model based on people
*  dissecting human brain? It was my that model was based on what really in some sense, the oldest
*  model in neuroscience, it was based on patient data. Famously, the patient guy named LeBorgne,
*  or known in the literature as Tom, and Broca, who was a neurologist in Paris, right, had the
*  examined him, tested him behaviorally came and noticed that this guy couldn't say much.
*  Remarkably, a few days after he gave him a thorough examination, the man died and was able to do,
*  you know, huh, who knew? My data never works out that way.
*  Yeah, well, let's say I went into your machine, so I think I'm happy that it doesn't work out.
*  So, you know, they found correlations. So it's what's called, you know, deficit lesion correlation.
*  So they found a lesion in this patient's brain, and or Broca in this case, and was able to
*  correlate it with the particular behavioral deficits. And look, that's interesting.
*  If this part of the brain is broken, and this behavior is broken, there must be a some kind of
*  causal relationship between a particular brain area and the function it executes.
*  Now, that's a very reasonable hypothesis, I mean, you know, subject to subtle things,
*  one could change about it. But it's very, but it seems like a good start. That's a good.
*  Some years later, the German neurologist Wernicke made a similar discovery for a different part of
*  the brain. He found patients that had a lesion or a brain injury through due to stroke in the
*  posterior part of the brain in the temporal lobe. And that patient or those patients had trouble
*  and understanding they were they could talk, they were very fluent, but didn't make any sense.
*  So the assumption was, okay, so the comprehension part is broken. So we have a production part and
*  a comprehension part. And so now we have a kind of understanding. Now, what's the problem with that?
*  Well, first of all, that's not a theory of language. For that, we had to wait another 100 years until
*  the language sciences were more mature. And there the work of Chomsky in the 1950s played an enormous
*  role. But for those 100 years, from 1861 to let's say 1961, the theory of language that was at the
*  basis of how we think about brain and language was pretty naive. I mean, it was something we could
*  come up with right now with a piece of paper. And that's, of course, it's amazing how powerful that
*  model was and how hard it was to get to get beyond it. But now we've known for
*  Sorry, remind me what are the two blobs connected by the wire. So there's an area called Broca's
*  region, right? So Broca's area named after the neurologist Paul Broca, an area called
*  Wernicke's region after the neurologist Carl Wernicke, and then a wire, a set of wires really
*  in between called the arcuate fasciculus. So that's basically tissue connect, you know,
*  those are literally the wires connecting the one blob to the other. And the idea is well,
*  Yeah, the role of the two areas.
*  The role of the two areas is one is for production, and one's for comprehension.
*  Okay, got it.
*  Very simple idea and very elegant. Very elegant.
*  If only the world were so simple.
*  If only the world were also aligned to, you know, so models are doomed to be true for a while.
*  So in this case, this is very powerful because it has the elegance of simplicity,
*  but also is empirically wrong. So it's wrong for many reasons. Patients with the different lesions
*  turned out not to have those syndromes. The brain organization is much more complicated.
*  The wiring diagram is, you know, gazillions of times more complicated. So we've known for
*  certainly 40 years that it's incorrect. And now in the last 10 years, I'm happy to say,
*  there are, you know, a handful of models that really go well beyond that. And that show us
*  actually how long the parts list is, and how much more complicated the structure is,
*  partly that's because these contemporary models are much more in tune with what we know about the
*  biology of the human brain, and likewise, what we know about the psychology of human language.
*  So they try to link the, you know, let's say models of linguistics and psycholinguistics
*  to models of neurobiology. And surely they're as inadequate, but hopefully they're wrong in
*  an interesting way. And they are, you know, de facto the state of the art right now.
*  One hopes for progress, not for definitiveness, especially against the brain.
*  That's a nice way to say it. Yes. I mean, I think, you know, so look, the brain's a complicated place.
*  You work on big things, really, really, really big places. And so the place I work on is small
*  by comparison, just the size of two fists really squished together. That being said, my small place
*  is pretty complicated. Way more complicated. It has 100 billion parts, right? And has about,
*  so the current estimate for the human brain is has 86 billion cells.
*  And each cell has, you know, if you think about it, sort of in the Facebook sense,
*  each cell has between 1000 and 10,000 friends. So are they really friends, though?
*  Are they? Well, there's likes, there's acquaintances, you know, how should we really cash this out?
*  But then if you imagine that they're, of course, you know, communicating with each other electrically
*  and chemically, the computational complexity of the problem gets out of hand in a hurry.
*  This is one of the reasons we don't really have, you know, the kinds of theories that are
*  successful and adequate at the moment. Right. But we do. So you are part of the originator
*  of something called the dual stream model. So you complicated the simple model a little bit
*  by imagining that there are, there's more than one thing going on. Is it possible to simplify that
*  enough to podcast? Sure. I mean, so that's of course the correct model.
*  Of course. Now that we know.
*  So that was an attempt by a colleague of mine, Greg Hickock and me, we've worked together on
*  this kind of thing for many years, trying to bring together data from patients, right, patients with
*  stroke and imaging and biology and linguistics to come up with a much more, let's say, biologically
*  realistic, computationally explicit and theoretically well-motivated idea. And
*  what we really did is we borrowed, or let's say we adopted and adapted the standard model of vision,
*  actually. So in the standard model, so what do you have to do when you see something?
*  The most straightforward way to think about vision is you have to locate things and then you want to
*  know what they are. Right? So there's a where system and a what system. And that's, you know,
*  actually not that much of a simplification as it turns out. So there's a whole chunk of brain
*  tissue that, you know, the human brain, the vertebrate brain has enormous amounts dedicated
*  to the visual system. And so there's an enormous amount dedicated to processes that identify
*  objects, the so-called what system, and they go along, as it turns out, the temporal lobe and
*  their job. So this is sort of the side of the brain under your ears. And these series of regions,
*  of which there are dozens, actually, are their job is to extract the information that lets you
*  actually identify things. So how do I know this is a glass of water, that's a glass of wine,
*  this is a chair, that's a hawk flying by? Right. So you have to identify the object. That's super
*  useful. You kind of want that. However, you also want another thing. You need to know where is it
*  relative to where you are. So you need a system that allows you, for instance, to regulate your
*  eye movements, figure out where you're reaching to grab something, see that saber-toothed tiger
*  is coming from the left and not the right. So vision has really worked this out in wonderful
*  detail, you know, very, very elegant. And so we have one stream principally responsible for
*  localization information, and other things as well. But that's sort of a good summary statement.
*  And another stream of another anatomic stream with sub areas responsible for identifying
*  objects. Very cool idea. So you've sub, by the way, you've now bought yourself an interesting
*  problem. How do you put them together? Well, I was going to say it could have been that there
*  was really only one system that did both functions, but it's two different systems, both sort of
*  operationally, but also literally where they are in the brain. They're literally a different
*  stream of information. So this was discovered a long time ago in the 60s in the hamster, actually.
*  So this notion of multiple sensory areas and multiple different streams responsible for,
*  in some sense, it's an engineering idea that you then see replicated in the brain. So you want sort
*  of subspecialization, because the circuitry in those areas really does things optimized for that
*  thing. So you want to, you know, let's say you want to really identify an object, you want to have
*  very high spatial resolution, you really want to be able to see the details, analyze its surface,
*  make guesses about how heavy it is, and so on. Whereas you don't care so much when you just need
*  to, let's say, move your eyes to the right to run away or something. So that's special. So we
*  basically stole that idea. In the best scientific sense. In the sense of adopting and adapting and
*  said, well, what if the speech and language system actually did something that's not that similar,
*  capitalizing on similar computations? So the visual system is pretty old, but it's pretty useful.
*  So one of the things you have to do in the language case is, you know, what do you want from the
*  information that you have? Well, one of the things you want is the content, the what. So I need to
*  recognize words, I need to string words together to recognize meaning. So, you know, I need to be
*  able to tell the difference between dog bites Sean and Sean bites dog, which would be uncool.
*  Yeah, I try to stay away from that.
*  So those are the same set of words, but they mean something completely different. So you need to
*  actually so you know, in this case, the particular ordering has a clear consequence for the
*  interpretation. And so we reason that maybe the brain is organized or capitalized on the same
*  computational principles. You have one stream of information says, look, what I really need to do
*  is figure out what am I actually hearing? What are the words? How do I put them together? And
*  how do I extract meaning from that? And you have another stream that really needs to be able to
*  deal with well, how do I translate that into an output stream? So let's say let's call it a how
*  stream or an articulatory interface. So why why would you do such a thing? Well, let's take a
*  the simplest case of a word. And so what's a word? Well, you know, word is not a technical concept,
*  by the way, word is an informal concept, as you remember from your reading of Steve Pinker's book.
*  So the technical term here would be morpheme, the smallest meaning bearing unit, but we'll call them
*  words, words roughly correspond to ideas. Yeah. So what is a word? So you have a word that comes in.
*  So my word that comes in into your head now is, let's say, computer. And as it comes in, you have
*  to link that sound file to the concept in your head, right? So it comes in, you translate into
*  a code we don't know, let's say, you know, Microsoft brain, and you then translate that code then gets
*  linked somehow to the file that is the storage of the word computer in your head. Now, in your head
*  somewhere, there's a file an address that says the word computer, what it means for you, like,
*  I owe it, you know, I'm on deadline, you know, oh, this file, God damn, my email crashed. But there's
*  many other things. So you know what it means, you know how to pronounce it, you know a lot about
*  computers, but you also know how to say it. Right. So it also has to have an articulatory code. Now,
*  here comes the rub, the articulatory code is in a different coordinate system than all the other
*  ones, because it's in the motor system. So it's in basically time and in motor people call joint
*  space, because you move articulators, or you move your jaw, your tongue, your lips. So the coordinate
*  system that you use as a controller is quite different than the other ones. So you have to
*  have areas of the brain that go back and forth seamlessly and very quickly because speech is fast,
*  between an articulatory coordinate system for speaking, and an auditory coordinate system for
*  hearing. And some coordinate systems yet unspecified, but you would understand at all for meaning.
*  So you're screwed. So even something banal, like, you know, knowing the word computer or glass or
*  milk, is already a deeply complicated theoretical problem. So in the visual case, the dual streams,
*  if we call that in the visual case? Yeah, they're simply called the what and where,
*  but the dual stream is simply that you subdivide problems into multiple streams,
*  like an engineer would. But those particular streams are what things are and where they are.
*  And then in the audio case, the hearing case, it's what they mean. Well, it's, let's say,
*  we call an interface to the meaning system, you know, let's say structure and meaning,
*  and an interface to the motor system. So we call it a, for example, I mean, so we called it a
*  sound to meaning interface and a sound to articulation interface. It does sound like
*  it's a slightly different problem in the sense that language is where these meanings come from,
*  or at least often, you know, sometimes we just yelp or scream or whatever. But in the vision,
*  the vision problem seems much more straightforward, right? Like any vertebrate is going to want to know
*  where things are and what they are. We humans have a special problem when it comes to sound,
*  which is that we want to interpret these in much more abstract ways.
*  Yeah, I mean, the, it's quite true that you don't want to over-analogize here. I mean, the, the,
*  and there are aspects of this, which we, which to me seem quite different, right? So one of the main
*  things you do in the language case is what's technically called compositionality, right? So
*  it's just to take things and put them together. And that's not so obvious how that's true in the
*  vision case, although it may be, I don't want to over, you know, state my case here, but
*  the kinds of things you have to do in language and vision are different. And certainly the output
*  systems are different, right? So, you know, the eye movement system is not like the speech system
*  or something like that. But what you could imagine is that certain of the subroutines
*  that are executed in the way there are shared. So for instance-
*  That's a very common evolutionary strategy, right? The brain is always borrowing, the body
*  is always borrowing old systems. That's exactly right. So you want to basically recycle stuff,
*  right? So, so one reason that, that Greg Hickok and I argued for this particular dual stream
*  position, ours is now one of a few. I mean, there's a handful of these, I think there are,
*  you know, we, of course things are, ours is still the best, although it's now 10 years old by now,
*  it's actually, but it's de facto one of the, I'll tell you a fun sociological story about that in a
*  second. But the, so one of the things that might be shared is this notion of, let's say, a coordinate
*  transformation. So the reason I'm very attached to this is because the same part of the brain
*  that we argue does this for the language, speech case, for the speech perception to production,
*  sensory motor cases, that you have to do a similar thing in the eye movement case. So if you take the
*  problem, I mean, here's a simple problem that everybody can do for themselves right now. You're
*  sitting, while you're listening to this magnificent podcast, you have a glass of wine in front of you.
*  And- We do, by the way, gentle listeners have glasses of wine in front of us.
*  Which we do. And I now really want to reach for this glass of wine, terrific red wine, by the way.
*  And so what do I have to do to execute that, you know, ostensibly simple thing? So the first thing
*  is the glass falls onto my eyeball, onto my retina in particular, right? So the surface, the back of
*  my eye that does the initial encoding. And so the coordinates of that are retinocentric, right? So
*  that is a particular two-dimensional sheet. And the glass is now falling somewhere on that sheet.
*  And the information now goes into my head. But now note that I can move my eyes.
*  So now it's no longer in the coordinates of the retina, but in the coordinates of the eyeball.
*  Now I can move my head. I can also move my trunk. But in the end, what I'm trying to do is reach
*  for the damn glass of wine. So it has to be in coordinates that are relative to my trunk
*  and to my arm, right? So because I'm going to reach my arm out and it needs to be,
*  I need to have knowledge of where is my current position of my hand? Where does my hand need to be?
*  How hard does my hand need to grasp? So the simple act of reaching for a glass of wine or a pencil or
*  anything ever requires a series of transformations, conceptually, right? So it doesn't mean you're
*  doing a series of equations right there, but you may be. But you need to transform the information
*  into a suitable format. And so if it comes in in eye centered coordinates and has to go out
*  in hand centered or muscle centered coordinates, what gives? How do you do that? That doesn't come
*  for free. So the regions of the brain that do that in the posterior part of the parietal lobe,
*  different part more on the top of your head, likely are optimized for that kind of computation.
*  And we reasoned, well, look, I mean, if that's the same kind of mathematical problem,
*  maybe that's really well implemented there. And maybe the speech problem is similar in kind. Now,
*  obviously, the inputs and outputs are quite different. You're going to get, let's say,
*  informally speaking, a sound file in and some kind of motor command out. But the kind of problem is
*  the same kind of problem. I mean, you have to have some kind of basis function, you have to transform
*  it into a different thing. So that's why we borrowed the thing from vision and tried to say,
*  well, this is computationally similar. And that's why we're, we think this sort of constitutes a
*  form of progress, because we try to be explicit about the set of operations that you really do
*  have to do in order to achieve what's ostensibly almost idiotically simple. But the bottom line is,
*  we do not know how we recognize a single word or a single object.
*  I do have a question, but first, I'm using sociological story. You promised me.
*  Well, okay, fair enough. So this is kind of how science sometimes works. And it has funny parts
*  and slightly less amusing parts. But when so about 10 or maybe by now 15 years ago, when Greg
*  Hickok and I started working this out, one of the things we argued for was this dual stream concept.
*  Another thing we argued for was that things really are much more bilaterally organized.
*  And at that point, we were still extremely young. Well,
*  younger than now. Now you're only mostly young. Now I'm just, you know, a little more mature.
*  So Greg and I wrote the stuff up and we sent it to our the initial reaction to our work
*  was that we were basically crazy. Because there was a model from the 19th century,
*  it worked, it was clinically useful. And we were accused of being, you know, charlatans and the
*  most naive bunch of yahoos who didn't know the first thing about any of the relevant disciplines,
*  which kind of bummed us out. Yeah, we were like, okay, you know, we were just reading the literature
*  and doing our work. And I mean, it's true that we departed pretty drastically from the standard
*  model at that point. But we thought we were being very, you know, motivated by vision,
*  thinking about linguistics, thinking about the biology of the brain, people basically dismissed
*  as a complete nut jobs. The problem is that people who sound like complete nut jobs, if you do have a
*  tremendously important breakthrough that changes the world, you will be told you're a complete nut
*  job. But most people who sound like complete nut jobs do not have tremendously important
*  breakthroughs. Yeah, there's a Yeah, I mean, we were. So we thought we were being pretty careful
*  in our reasoning. Now, so of course, our feelings were because we're young, we were both, I think,
*  assistant professors at that point, and our feelings were heard understandably. And but then
*  ironically, so you know, people started saying, well, maybe, maybe they're not so stupid. The data
*  started amassing and you know, the people started really thinking about it and reading and pay a
*  lot of attention to this thing. And now 10 years or 15 years later, it's become more or less a
*  standard thing. And it's now it is the textbook model. But now, ironically, all the young people
*  stand up and basically take shots at us about how naive and how stupid our so we never had the good
*  years, right? Never were the feet. Initially, we were the cranks who were just didn't know. And now
*  we're just like the old guard, you know, who just really isn't on the cutting edge. You were outdated
*  even before you were accepted. So sometimes we sort of a little wistfully think like when
*  don't we ever get a break here? Do we know people? The answer is no, you do not get a break,
*  you do not get a break. So that was I mean, we're obviously happy that people are interested in
*  this. But it would have been nice to have like two years where you say, good for you, you know,
*  nice idea, it's probably wrong, but good for you. I know it well. But I'm thinking, you know, is it
*  is there an obstacle to understanding both vision and auditory signals that we kind of in the back
*  of our minds know a little bit too much about how computers work? Like when we take a picture with
*  a camera, we have pixels, and we imagine there's just data of where things are and what color they
*  are. And the brain is much more based on extrapolations from incomplete data, both in
*  speech and in vision. Is that is that getting in the way of solving this important problem of how
*  we go from the basic input stream to the meaning inside? Well, I think you I think that's not quite
*  right. That's to say, the pixel or camera metaphor for vision is also wrong.
*  Right. So just as hearing and language comprehension is entirely constructive process, so is vision.
*  And so in the brain, it is yeah, I'm saying for a camera, for a camera, it's not so we're taking
*  the camera analogy. So we don't want to take that too far. I mean, what we do know, and we've known
*  effectively since I want to say Helmholtz, but probably earlier, Helmholtz always right about
*  most things. Most there's a there's a good line by I want to say David Hubel, the noble laureate
*  and winning neuroscientist who discovered fundamental principles of the early visual cortex.
*  He and Torsten Weasel won the Nobel Prize in 1981. I think it's I vaguely remember hearing this in a
*  lecture that David Hubel gave many years ago thing, most of what we do are footnotes to Helmholtz.
*  Very nice. Which I thought was sort of, you know, cribbing, demoralizing, but pretty cool.
*  You know, Emerson's line, philosophy is just footnotes to play dough. Yes. That's where he
*  gets it. Yeah. So I mean, I think that the the notion that it's entirely constructed, right,
*  so that you need a kind of computational theory using the word computational, but loosely,
*  I think is now completely convincing. Right. So that it's that the way we do things are predictive,
*  for instance, that most of what we do is a prediction, that the data that you get are,
*  you know, vastly under determined, the percepts and experience that you extract from the initial data.
*  And so that it's a filling in process, right. So you take under specified data,
*  and that are probably noisy anyway, and then you build a internal representation that you use for
*  inference and you use for action. Those are the two things you presumably want to do most. I mean,
*  you want to not run into things and you want to think about stuff. And so there, I think,
*  story of my life, not running into things and think about stuff. That's, yeah, I mean,
*  we all have the same issue there. I often succeed. Yeah, this is better than I do. I mean, I make both
*  mistakes. I think poorly and do run. But the, so I think that the, there's now, for many years,
*  the start, I mean, this actually brings us back to what we were talking about earlier, the influence
*  of Chomsky and mentalism was the embracing of what was and still is called the computational theory
*  of mind and very influential. I mean, I think people like Fodor played an enormous role in this
*  and subsequent, you know, Jerry Fodor, the philosophy, Jerry, the philosopher, Jerry Fodor,
*  and then subsequently people like Dan Dennett picked it up. And it's, you know, de facto,
*  as far as I can tell, the most reasonable way to think about the mind, you know,
*  boring. I mean, there are no alternatives I find even vaguely credible. Not that they're not all
*  over the interwebs. You can find them. But these are, I mean, so these are extremely,
*  what has made these helpful is the, the requirement to make things explicit and sort of proceed,
*  to think a little bit like a program. I mean, really spell out what are the, I mean, in some
*  sense, it's taking work on the mind and brain, which I don't take to be particularly different,
*  just like any other discipline, biology or physics, that is to say, your first job is to
*  identify the parts list. I mean, what is the ontological structure of your domain? What are,
*  what are actually the primitives, as you might call it, or I just like to call it the parts lists.
*  It's less complicated sounding. What are the smallest elements that you need to use to generate
*  the phenomena? And then you need to identify the forces or the interactions between the primitives
*  that generate the phenomena under study. And that's the, the computational theory of mind has been
*  very good about that. Now the quest there, obviously one can do better because we don't,
*  what the primitives are is a research program, just like in physics, takes decades and decades.
*  We don't know what the smallest pieces are, right? Because it turns out to be really difficult.
*  Every time we look, it's a little bit smaller, it's changed a little bit, or it's, you know,
*  for example, now, if you ask someone, well, what do you think is the relevant part of the brain,
*  they're going to say, it's a neuron. I'm like, well, that's a nice idea. That's, but maybe it's
*  a sub part of a sub part of a neuron, or it could turn out that it's going to be five neurons wired
*  up a certain way, namely two are a capacitor and one's a, you know, who the hell knows? We simply
*  don't know what the encoding of information is. Well, even for the neurons, it's progress, right?
*  In the sense that I get the impression that at some point in the history of psychology,
*  it was thought that they're, you know, the brain was a bunch of blobs interacting with each other
*  and just the progress that has been made by thinking of it as a network, right? Of neurons,
*  and they're not all connected to each other equally. There's some hierarchical structure there.
*  Yeah, look, I mean, that's, that breaks a very interesting and slightly dodgy point, right? So
*  the, now nobody would argue that the network metaphor isn't necessary and important research
*  agenda. That being said, isn't that just kicking the can down the road? And before you said, well,
*  it's this part of tissue and we don't understand. Now you say, well, it's five pieces of tissue
*  with a bunch of wires interacting and we don't understand those. So I'm so simply saying, well,
*  it's a network is kind of punting on the problem for me. It's a tiny little thing. I, so it is very,
*  so that look, I mean, we're all on board with it. Obviously, everybody agrees. Look, it's a super
*  complicated dynamic system with many interacting parts. We're trying to figure out how this,
*  you know, the extremely high dimensional dynamics of the things work, but it's, but it's to me,
*  not a mechanistic answer. It's a metaphoric extension, not a, it's a metaphor, not a mechanism
*  to say it's a network. Well, how far does, so there has been progress made. How far does that get us
*  to the stated goal of understanding what happens when we hear words like freedom or love, you know,
*  words that are not referring to objects out there that we can point at abstract concepts.
*  Very difficult question. I mean, the vast majority of standard work, shall we say,
*  refers to, let's say the so-called open class items or, you know, nouns and verbs, you know,
*  chairs and dogs and bears and things like that. And no bears yet, by the way, no bears, although
*  some deer are often over there. Maybe I brought them to New York. So the issue of abstraction is
*  particularly difficult because you no longer want to deal with things like, oh, this concept has a
*  bunch of features that make them, and, you know, these necessary and sufficient features make you
*  a member of the category honesty. Right. The, now there are such ideas, namely the concept of embodied
*  cognition, very, very popular these days in psychology and neuroscience. I can't say that I
*  find it coherent, but it's certainly, you know, be my guest and work it out and then I'll watch the
*  movie. You know, it's all good. But the, it gets even more gnarly when you think not just about
*  abstract concepts. So, so how does the, let's, you know, backing up for one thing, how does thought
*  partition roughly? You might say, well, there are concrete things that we think about like dogs,
*  cats and tables. And, you know, the untutored intuition says, well, those are the easy ones.
*  Yeah, not easy either. Then there are abstract things. That they're not easier or just not easy?
*  They're not easy and they're not easier. There's no reason to believe that the way we understand
*  cat is easier than the way we understand honesty. Okay. I have no reason to believe that. All right.
*  Right. So we have intuitions that because I can understand honesty at all, I know that, but I
*  don't know if that's helpful. Your cat also doesn't understand cat actually. So, no, but I mean,
*  so there are, of course, in our world, concrete things that we reason about. There are abstract
*  things that we make inferences about, but then there are the real juicy bits, which is these
*  small lists of words in all our languages, so-called close class items that make, you know,
*  make it all worthwhile, namely things like and, or, under, through, not. Yeah. And that's where the
*  fun begins. So how are the, and those are the ones you really want to understand because that's
*  actually the glue that holds the stuff together, right? So you don't say cat, dog, or, I mean,
*  that's the near, unless you're aphasic actually. But I mean, what you really say is, you know,
*  no, I don't want that quinoa, you know, past the gluten rich pasta.
*  I've often said those words, yes. So- But you're sounding pessimistic. You're sounding like, well,
*  at least realistic about current progress. Well, no, I'm trying to sound realistic about the
*  progress. So I'm trying to say, look, you know, I'm not optimistic about where, I think we've made
*  wonderful progress, and I think that sort of we're piecing this stuff slowly together.
*  But I'm a little, and actually, okay, so here's what I'm optimistic and pessimistic about. I'm
*  optimistic about that we can get a grip on, let's say in the next 10 years, the, let's call them
*  rules or operations or computations that put items together to yield larger items. So the fact that
*  red can, for instance, is a can and not a red. Right. How'd you know that? Yeah. That doesn't
*  follow from first principles. You have to actually figure that out, right? So that's actually, you
*  know, that's not a gimme. Right. And the, so, but my hunch is that these sort of elementary operations
*  of composition or combinatorics that yields larger units that then become the input to the next steps,
*  I'm actually pretty optimistic about that we're going to get a grip on that, believe it or not.
*  Okay. What I'm much more, we're not pessimistic, but just kind of bewildered about and stuff that
*  I think that's giving me more, you know, sort of stuff that I think about a lot is, well, how do
*  you store anything to begin with? So if I say red can, that's great, but where's red, where's can,
*  and how to put red can together? So literally located in the brain, such that, so the remarkable
*  thing is, as we talked about earlier, you have, let's say you have 50,000 or you're, you're
*  uber educated, so you probably have a hundred thousand things in your head. Right. Now,
*  any of them are silly and useless, many of them useless, but, but even the useless ones, you pull
*  us at the rate that our conversation is happening. And we said, you know, four to five Hertz is a
*  typical syllable rate. That means we speak, you know, something between three to five words per
*  second, super fast. So it means at that time scale, you have to translate the information coming into
*  the periphery into the correct code, go into your bag of words, pull out the correct item, not the
*  wrong item. We're pretty good, right? Compared to machines are here that are unbelievably robust,
*  resilient to noise and all kinds of stuff. Pull out the right item and keep doing that sequentially,
*  put them together with the next one and also with ones that are distant and get the correct
*  interpretation out at a scale, at a sub-second scale all the time. Right. I mean, that is, so
*  the operations that happen, I'm pretty optimistic about that. We get a grip on, because we're,
*  I think there's wonderful research happening of that in many different labs. But the process of,
*  the identification of how we actually store, not just words, but anything at all is to me
*  deeply puzzling and I think is one of the deepest mysteries of neuroscience.
*  I always, well, I would have thought at the most naive level, again, perhaps being misled by the
*  analogy with computers, that information is stored in individual neurons as some bits somewhere,
*  like there's a computer memory. My understanding is that that is wrong and neuroscientists will
*  tell me that it's closer to being stored in the connections between the neurons.
*  But maybe you're going to tell me that we don't even know that.
*  So that's, you're absolutely right. So I much prefer your first story that you say,
*  that maybe things are stored inside cells or the structures of cells or even possibly the genome.
*  But the, that would be the really interesting case. How do you say?
*  The color red, I can learn the color red and it will be stored in my genome.
*  Well, I mean, what do you have all the introns for? I mean, who knows? We don't know. But look,
*  the standard story is the one you just said. So our standard story in memory right now is
*  it's the connections between cells as the synaptic structure and the synaptic connectivity is what
*  reflects memory of something and the modification of that connection between cells is effectively
*  what learning means. So learning means a modification, a cellular molecular level
*  modification and ultimately a genetic level modification. Right.
*  And Nobel prizes have been giving out, given out numerous.
*  Right. So this is, yes. I mean, so the, you know, the first one, perhaps, you know,
*  Candell most famously for, you know, for this synaptic. So the synaptic pattern of things is
*  the basis of this. And this is, you know, this is the standard story. But when you start to dig in
*  a little bit, and I think the most, most, let's say harsh critic is Randy Gallistil from the,
*  from Rutgers, who's a very distinguished psychologist and cognitive scientist who's worked
*  most of his life on learning actually. And from a computational point of view,
*  and has written a very, very fascinating book called Memory and the Computational Brain.
*  Okay. And a bunch of papers in which he
*  basically pulls the rug out from under neuroscience of memory and says, look, you know,
*  show me at least how you store the number 17 or something, or anything for that matter,
*  any bit of information. Yeah. Where, and where is it? How is it done? And then how is it actually
*  implemented when you use it? How do you, so we have sort of intuitions that yes, the pattern of
*  connectivity may be, you know, activated or deactivated, but you really need some kind of
*  digital storage device. Right? So, I mean, the issue that's very tricky in memory is you,
*  on the one hand, so the way human memory works is certainly content addressable. We know that for
*  words, for instance, right? So it's content addressable in the sense of, say, doctor, you
*  think nurse or toothache or, you know, whatever the appropriate semantic field is that that
*  associates with you. So that, that's what content addressability is, right? So there's a content
*  based sort of cloud of ideas, but you also want what a computer has, which is address addressability,
*  right? So you go to a location and you pull something out. And so how do we, so is that
*  possible? Can we put things there? How would we store in a sort of digital format, the digital
*  information we have? How do we actually compute, let's say with variables? I mean, take that, you
*  know, the wonderful examples from, you know, the animal world, the Tunisian desert ant, Cataglyphus,
*  okay. Right. So it lives in the desert, Tunisia, flat, not much to see, right? No visual cues. The
*  ant walk comes out of its burrows and comes out and has to walk around to find, let's say a leaf,
*  right? So the ant has to, these ants are small and not huge brains. The ant walks around, walks
*  around meandering, you know, maybe a meter, two meters finds a bit of leaf. How does the ant walk
*  back? Straight back to its hole. How? Okay. How does the ant know how to do that? Okay. So how would
*  you do that? Right? So you'd have to figure out a bit of math. You have to figure out, okay, wait,
*  wait a minute. So here's a simple one. It does it like Hansel and Gretel. So it leaves a little bit
*  of chemical trail, but if it did that, it would wander back the same path. It doesn't do that.
*  It actually takes a kind of straight vector back and then looks for its hole. So it must have,
*  first of all, figured out how far it went. So it has to count the steps or something,
*  which turns out it does. It has to keep track of time because at that point, the sun has, of course,
*  changed position. So it needs the solar ephemeris function. So you need to actually have an equation
*  in your head in which you plug in the value of variables that you then calculate in order to say,
*  I have to go back, you know, south by southwest and, you know, yay, much, you know, whatever,
*  four feet. Now that's a kind of simple example. Well, a test in beautiful experiments, by the way,
*  but that's a kind of compelling, you know, and very clear case where a small nervous system has
*  to take, you know, does a very simple behavior, namely finding your home after walking out.
*  But in order to do that, it has to plug a value into a variable. So how do you do that? Now things
*  get a little dodgy. Many junior high school students struggle with this. Do not enjoy this concept.
*  And so how does the little tiny brain have represented a variable that then is able to take
*  a specific value, then do its little calculation and say, I'm going that way. Is this the experiment
*  where they put the little ants on stilts? That is exactly one of them. Yeah, there's a whole bunch
*  of experiments. These are mostly by RÃ¼diger Wiener from Zurich. Beautiful, beautiful experiments.
*  And when they were on stilts, they got the wrong answer because they took the number of steps,
*  but they didn't understand how far they were going. Exactly right. So that was the evidence
*  that you have a counter because if you're too high and you take the number, you would go too far.
*  So, but that makes it such a compelling case for a simple kind of computation.
*  So if the ant does that, it can't be impossible. So there is circuitry in a small brain that allows
*  you to have variable-based computation. Now if you attribute it to the ant, do you not attribute it
*  to the vertebrate? That seems weird to me. And you're hinting that this might be part of the
*  origin of abstraction? Well, I mean, that's already too far. And I think I would like to,
*  to me, it's a sort of reminder that one of the things we have to have an answer for is
*  let's say algebraic computation. So, I mean, it's actually good to have a tractable goal,
*  right? So, okay, so if we can understand that, which in some primitive sense, even ants can do it,
*  that would be nice. Yeah, I mean, it gives a very specific and so it's the kind of problem that
*  language faces too. So for instance, look, I mean, one of the interesting things about language
*  processing is that it's the so-called property of structure dependence, right? So one of the
*  things that makes computers different from, you know, human brains is for the most part, I mean,
*  so is that the way the language works across all languages, it's not a string of pearls,
*  but it's more like an Alexander Calder mobile, right? So it has relationships that are dependent
*  on where in a structure things are, not just in a sequence. So it's not just, you know,
*  I have a sentence that has seven words, one, two, three, four, five, six, seven in a row,
*  and it matters what is your neighbor, your nearest, but it matters what their structural
*  relation is. And there's, you know, there's sort of incontrovertible evidence for this,
*  this is not debated, right? So this notion of, that means you have to have some kind of,
*  yeah, some people give it a kind of tree structure, because that's a good way to visualize it. Other
*  people are deeply offended by trees, and they say, well, you can't have trees living in the
*  brain. But that's just a notational variant of you can express that many different ways.
*  Call the networks, people will love it.
*  Call networks, or it can be bracketing, like a borough, whatever. I mean, you could call it
*  whatever you want. It's just that their relations are not non-local, right? And that's a really
*  deep property, right? So you have to be able to deal with non-local relationships. The most
*  obvious example is how you deal with, let's say, pronouns, and the thing that they refer to, the
*  so-called antecedent. So I say, like, you know, Sean was finished with his recording, and he asked
*  me to give him another glass of wine. What is the hymn? Yeah. Is that that could be Sean, but that
*  could be someone else, could be some other hymn, could not be me. But how do you know that off the
*  fly? It knows because there's actually a structural relationship between the pronoun,
*  or, and the antecedent, if you use himself, that can only refer. So these are kind of trivial
*  examples, but they highlight a very special property, namely the property of, sort of,
*  what's commonly called that there are constituents, or constituents are just equivalence classes,
*  right? So constituents, when I say, you know, horse greenings. Yeah, the red can was on the table,
*  then the red can is a constituent, because I could say the transparent glass was on, so I can
*  substitute for something else. And the fact that you have such things, and that they have, of course,
*  causal force in how we say stuff, suggests that they make, you know, they must be in your head
*  somehow, and unless you are a dualist, and that's fine too. No, it's not. We don't be dualists here.
*  I'm not, well, I'm not okay with that. But I mean, that doesn't work for me. Some of my best friends
*  are dualists. I mean, if you have a brain with 85 billion neurons in it, and as you said, each
*  neuron has thousands of friends, right? So there's lots of connections. It's a gigantic computational
*  problem, as you said, even at the most functional level, forgetting about meaning and abstraction
*  and poetry and music. If physicists were in charge of this, they'd just be throwing gigantic
*  computer power at it and treating it as a big data problem. And I do get the impression this is
*  happening also in neuroscience. No, that's absolutely right. I mean, I think that there were,
*  you know, many of us, maybe all of us are seduced by the power of, by the computational power now
*  available, right? Everybody and their brother has, you know, some wicked GPU in their laptop.
*  The, and, but it is changing ways in interesting ways. Maybe it's good, maybe it's bad.
*  The fact of the matter is that the data sizes that we now collect, the data amounts are extremely
*  large. That's true. So when I stick someone in, so like I put you in a magnetoencephalography
*  scanner, right? So we recorded for let's say 10 minutes, that was about two gigabytes of data.
*  And that's a lot of data. And it's very, and so obviously you need to automatize the analysis,
*  you need to figure something out. The, but now comes a very important epistemological choice
*  that you have to make. There's, do you approach these data with, let's, let's call it, well,
*  it's almost old school with a hypothesis. Like you learned, do you actually have an idea?
*  Were you looking for something? I mean, did you design what you did with a particular thing in
*  mind? So do you have a hypothesis, a model, a theory, which is very Baconian and boring and,
*  you know, but has done pretty well last few hundred years. I'm not going to lie. Or do you
*  throw, do you pursue a kind of data driven or, you know, big data approach at the thing? And
*  that's very popular because we can, right? We have machines that do well and you can, certain
*  problems are, let's say at least descriptively reasonably well addressed by simply classifying
*  things. And if you're, if you have a classification problem, then big data is a cool approach. You
*  just throw, you know, you train your network on gazillions of trials and then you throw some new
*  data on it. And maybe you have even an unsupervised learning situation and you get a beautiful
*  clusters of things out of them. And I think that's very powerful. And I'm not going to lie. We use
*  that in my lab. And looking for correlations. So let's be clear. I mean, if you take this approach,
*  you're looking at an orgy of data that's almost treated hypothesis free. It's purely correlational
*  approach you use for, so it's basically the mother of all regressions. And that's, so what might
*  happen? So in one universe, you might get lucky. It might turn out that the regression you build,
*  the giant correlation matrix, which is, you know, obscenely large turns out to give you an interesting
*  fractionation or, you know, factorization of the problem. But what are the chances? I mean,
*  it could happen, but I mean, there's a lot of data are weird and messy and noisy. A lot of weird
*  things could happen. And so my, I tell you my, as I'm not against this at all, I mean, nobody's
*  against having more data. I mean, it's kind of silly, but the question is, how do you approach
*  this data you've collected? And I mean, I guess I'm very sympathetic and, you know, in my own lab,
*  we have vitriolic energetic debate. I love everybody in my lab, wonderful people, but we
*  don't all agree. And I have, you know, lab members that are strongly pushing me on this. And I'm
*  strongly pushing back. And I believe it's a really good idea to design the experiment with a question
*  in mind. If I stick you in a machine and I'm going to spend a lot of money, energy and time
*  on recording these really quite sophisticated, complicated data, I kind of want to know what I'm
*  looking for. And look, I mean, a very, very big version of this is the Large Hadron Collider. You
*  don't build that thing, you know, just because you say, oh, shit, let's just correlate a bunch of
*  stuff. Oh, no, but exactly the same debate is going on between targeted searches and sort of blank
*  searches for some, some anomaly in something somewhere. Yeah, that's interesting how you might
*  interpret it. I'm sympathetic to finding things by serendipity, but my own feeling is still that
*  my own hunch is that actually a very well articulated model that can then be shown to be wrong
*  reduces the nature of the problem. And I'm simply not satisfied by some giant correlation matrix or
*  the answer to a regression. Those are engineering solutions in my own, you know, as I know before,
*  my sort of gut feeling is that in the neurosciences in the summer of 2018,
*  engineering approaches and big data approaches are actually replacing the standard approach
*  of the sciences. I mean, that's a little weird that engineering is superseding science. But is
*  it a temporary enthusiasm that... Well, it's where we're all enthusiastic, because it's cool to be
*  able to look at gigantic amounts of things. But here's the danger. The danger is that we end up,
*  maybe it's not a danger, maybe I'm just an old guy, an old angry guy. I think the potential
*  danger is that we become theoretically myopic. That is to say, the kinds of answers that are
*  yielded by this approach are of a certain form. And we will only be getting that form of answer,
*  the form of answer that comes out of giant regressions. And that may be theoretically
*  misleading. That is, we might have a generation of science in which the answers that are provided us
*  come from that kind of epistemological stance and prevent us from seeing theoretical alternatives
*  that are not fully aligned with that approach, which I think would be a huge bummer. So ironically,
*  by not having a theoretical framework with which to analyze and construct the experiment,
*  you're locking yourself into certain possible things you could discover, refusing to look for
*  other ones. I'm working on this problem with one of my colleagues right now. So our diagnosis of
*  this is we're not at all against using huge amounts of data. That's exciting. But here's our
*  diagnosis. Suppose you run a big data approach on a neuroscience problem. So let's say I want to study
*  spoken word recognition, something I actually know a little bit about. And what I'm going to do is
*  I'm going to record, I'm just going to have a thousand people listen to 10,000 words, some
*  giant data. I'm going to crank this thing through my convolutional neural network. And then I'm going
*  to get some interesting classification scheme out of it. And I can probably record in different layers.
*  So you're looking at what happens in the brain when they're listening to these words.
*  Yeah. So you're just going to look for correlations. And I'm just going to record this and then I'm
*  just going to take this data and I'm going to correlate everything with everything. And of
*  course some correlations will come out. That's great. Now let's say I end up with a very good
*  model, right? A terrific model fits and that model will be characterized by a series of parameters.
*  And it's going to be great. And let's say it has, you know, 14 different things that I had to tweak.
*  Awesome. Now I have a fantastic model and I have these 14 values. I've got a kappa because you got
*  to have a kappa. Maybe a tau is always good. Lambda is nice. Got a couple of lambdas. Okay.
*  So now I have these parameters that I fixed and they yield the optimal thing. What's my next step?
*  My next step presumably is to do quote unquote normal science on what these parameters are.
*  So I now have just bit myself in the butt. I have to say, well, I have these 14 things. Now I have
*  to actually figure out what they are because they're the ones that are ostensibly the causal
*  they have the force of being explanatory over the model. So what gives? I mean, I think that's fine.
*  But my argument is that this is a lovely approach, but in the end you're going to actually
*  reinvent what you have to do to begin with to give a full comprehensive explanatory account of the
*  parameters of your machine learned models. So you think that there's still room for human
*  thought and language in trying to understand human thought and language.
*  I think you need human thought. You need just common sense. Solid common sense. No bullshit.
*  Have a good bullshit detector and read all the details and don't worry about it. And it turns
*  out you have to actually do the homework. You have to do the homework.
*  Good advice. We'd like to leave on a good advice and I can't do better than do the homework. So
*  David Purple, thank you very much for being on the podcast. Thank you.
