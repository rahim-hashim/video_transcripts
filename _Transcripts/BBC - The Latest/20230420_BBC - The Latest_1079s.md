---
Date Generated: May 18, 2025
Transcription Model: whisper medium 20231117
Length: 1079s
Video Keywords: ['bbc', 'bbc news', 'news']
Video Views: 164848
Video Rating: None
Video Description: Controversial facial recognition firm, Clearview AI says it now has 30 billion images, scraped from platforms such as Facebook, taken without users' permissions.

It claims its technology is being used by hundreds of police forces in the US.

The company has repeatedly been fined millions of dollars in Europe and Australia for breaches of privacy.

Critics argue that the use of Clearview by law enforcement puts everyone into a "perpetual police line-up" – and that the technology doesn’t always work.

Clearview says it has never knowingly been involved in a case of mistaken identity.

The BBC’s James Clayton investigates.

Please subscribe here: http://bit.ly/1rbfUog

#Technology #USA #BBCNews
---

# US police forces using controversial facial recognition technology - BBC News
**BBC - The Latest:** [April 20, 2023](https://www.youtube.com/watch?v=uGeRTmDdqUI)
*  In March 2017, Andrew Conlin got into a friend's car. A few minutes later, they smashed into this tree. [[00:00:00](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=0.0s)]
*  Yeah, well the car would have been against here, right? [[00:00:09](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=9.0s)]
*  Yes. [[00:00:16](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=16.0s)]
*  If it wasn't for facial recognition technology, Andrew may well be in prison right now. [[00:00:17](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=17.0s)]
*  I think we made it about a mile and a half into a three mile trip. [[00:00:23](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=23.0s)]
*  Andrew is in the front passenger seat. His friend is driving. [[00:00:29](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=29.0s)]
*  And he was probably hitting 80, 90. I mean I was saying, you know, slow down. [[00:00:33](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=33.0s)]
*  It was falling on deaf ears. I don't think he responded at all. [[00:00:39](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=39.0s)]
*  So I basically reached the conclusion that somebody was going to die that night. [[00:00:42](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=42.0s)]
*  The car has hit a tree. The driver was thrown into bushes nearby. [[00:00:50](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=50.0s)]
*  He's seven? [[00:00:55](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=55.0s)]
*  He died from his injuries. [[00:00:56](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=56.0s)]
*  I'm very fortunate to have walked away from that wreck. [[00:00:58](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=58.0s)]
*  One of the first people on the scene pulled Andrew out of the car. He told the police what happened. [[00:01:03](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=63.0s)]
*  Did anybody see what happened? Any of you guys see what happened? [[00:01:09](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=69.0s)]
*  The driver took off and he got ejected from one of the windows. [[00:01:12](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=72.0s)]
*  Wait, that's not the driver? [[00:01:16](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=76.0s)]
*  No, he was the passenger. [[00:01:17](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=77.0s)]
*  Despite the man's testimony, the police suspect Andrew was in fact the driver. [[00:01:19](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=79.0s)]
*  There is no way that that's the passenger. [[00:01:24](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=84.0s)]
*  The passenger side of the vehicle was all smashed in. There's no way the passenger survived that. That's the driver. [[00:01:27](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=87.0s)]
*  After telling the police what happened, the man left the scene without making a formal statement. [[00:01:33](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=93.0s)]
*  We know where this person is that pulled him out. We really don't know either. [[00:01:38](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=98.0s)]
*  That's who we're trying to find. [[00:01:41](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=101.0s)]
*  After a lengthy investigation, the police concluded that Andrew had been the driver. [[00:01:42](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=102.0s)]
*  He was charged with vehicular homicide, punishable with up to 15 years in prison. [[00:01:47](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=107.0s)]
*  Andrew's only hope was for his legal team to track down the man who pulled him from the car. [[00:01:52](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=112.0s)]
*  This unknown man could prove Andrew wasn't driving. [[00:01:58](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=118.0s)]
*  Chris O'Brien was his defence lawyer. [[00:02:02](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=122.0s)]
*  We printed up pictures of him off of the body cam, handed them out at every shop, every Starbucks downtown, put it on social media and no one knew who he was. [[00:02:05](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=125.0s)]
*  Chris and his colleagues convinced a controversial facial recognition company to license their technology and help find the witness. [[00:02:18](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=138.0s)]
*  They ran a search of this image from the police body cam footage using artificial intelligence. [[00:02:26](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=146.0s)]
*  This AI popped him up in like three to five seconds. It was just pictures just popping up. Here you are like pop up. [[00:02:32](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=152.0s)]
*  Here he is. This is the guy. And it was him, everyone. So it was just wild. It was wild. It was like hitting the lottery. [[00:02:42](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=162.0s)]
*  Over four years after the crash, Chris and his team finally found their key witness, Vince Ramirez. [[00:02:48](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=168.0s)]
*  Were you surprised that he was being charged with vehicular homicide? [[00:02:57](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=177.0s)]
*  Oh, I was because I remember telling them what happened. It's like, wow, I can't believe this is still going on. [[00:03:02](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=182.0s)]
*  I thought it was case closed. All right, you know, he wasn't the driver, but it was a shock to me. It really was. [[00:03:10](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=190.0s)]
*  What do you remember about where he was in the car? [[00:03:18](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=198.0s)]
*  I remember he was in the passenger seat, but he was mangled up where like that side definitely like had him crushed in with the seatbelt on. [[00:03:21](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=201.0s)]
*  So it took me a while to take it off and try to get his feet and body over the centre council to get him out of the vehicle. [[00:03:29](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=209.0s)]
*  So he was definitely in the passenger seat. Yes. [[00:03:36](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=216.0s)]
*  We knew at that point we were going to win this case. And within an hour of him giving this testimony, this deposition, the case was dropped. [[00:03:40](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=220.0s)]
*  They called me that afternoon and said, hey, it was, you know, it went as expected and they've dropped the case. [[00:03:48](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=228.0s)]
*  How did he feel? [[00:03:54](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=234.0s)]
*  Obviously, that's a huge weight lifted. [[00:03:56](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=236.0s)]
*  After spending years facing a potential prison sentence, Andrew could finally move on with his life. [[00:03:59](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=239.0s)]
*  The facial recognition technology that Andrew's lawyers used is New York based Clearview AI. [[00:04:11](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=251.0s)]
*  The company has been fined over and over again for scraping billions of users photos in countries including the UK, Greece, Italy and France. [[00:04:17](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=257.0s)]
*  Critics say a controversial startup poses a new and profound threat to everyone's privacy. [[00:04:26](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=266.0s)]
*  A company called Clearview AI has the largest known facial recognition database of images in the US, larger than the FBI's. [[00:04:33](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=273.0s)]
*  The company is run by this man, Juan Tontat. [[00:04:44](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=284.0s)]
*  He's the eccentric founder of Clearview AI, a privately owned company that promises the most comprehensive image search solutions in the world. [[00:04:48](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=288.0s)]
*  I want to find out how many pictures the system could find of me. [[00:04:59](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=299.0s)]
*  You take a selfie. [[00:05:04](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=304.0s)]
*  Okay. [[00:05:06](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=306.0s)]
*  Take any face you want. [[00:05:07](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=307.0s)]
*  Wow, and instantly, yeah, that just comes up. [[00:05:08](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=308.0s)]
*  As you scroll down, there'll be photos that were, you know, less similar or if you see a plus one. [[00:05:11](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=311.0s)]
*  Yeah, this is all me. [[00:05:16](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=316.0s)]
*  Clearview scours the internet for images. [[00:05:17](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=317.0s)]
*  A powerful algorithm compares size, shape and distance between facial features to find potential matches. [[00:05:21](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=321.0s)]
*  I don't know where that is. [[00:05:28](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=328.0s)]
*  It's wild how many pictures are just out there on the open web. [[00:05:30](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=330.0s)]
*  The search finds pictures I've literally never seen before. [[00:05:34](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=334.0s)]
*  I'm in the back of someone's profile picture and it still finds me. [[00:05:38](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=338.0s)]
*  Fascinating. [[00:05:42](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=342.0s)]
*  And it's picked me up because I am right in the back there. [[00:05:43](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=343.0s)]
*  It doesn't need to be a picture that you uploaded or your friends uploaded. [[00:05:48](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=348.0s)]
*  It's just if you're in the back of a picture, you can still be found. [[00:05:51](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=351.0s)]
*  It's a really surreal, accurate technology. [[00:05:54](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=354.0s)]
*  How many images is this scraping? [[00:05:57](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=357.0s)]
*  How many images are in the database? [[00:06:00](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=360.0s)]
*  In the database, there's about 30 billion images. [[00:06:01](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=361.0s)]
*  Because I guess the debate is some people say this is just Google for faces and other people say this is going to change privacy as we know it. [[00:06:04](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=364.0s)]
*  It's both. [[00:06:13](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=373.0s)]
*  I mean, it really is Google for faces. [[00:06:14](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=374.0s)]
*  That's exactly how it works. [[00:06:16](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=376.0s)]
*  But I do think it is a big change in the fact that people can be identified with just a photo. [[00:06:17](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=377.0s)]
*  And what we're trying to do is figure out what is the most compelling pro-social use case. [[00:06:24](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=384.0s)]
*  And I think for law enforcement and government usage, it's a total game changer in the ability to keep us, all of us safe together. [[00:06:30](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=390.0s)]
*  Clearview says they've been used by hundreds of law enforcement agencies across the US. [[00:06:40](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=400.0s)]
*  But there's no official record of which police forces use this tech. [[00:06:45](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=405.0s)]
*  One police force we do know that uses it, though, is Miami PD. [[00:06:50](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=410.0s)]
*  So there we go. [[00:06:55](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=415.0s)]
*  Got something? Yep. [[00:06:57](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=417.0s)]
*  We're on a ride along with Officer Jack Perez. [[00:06:59](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=419.0s)]
*  What's been reported? [[00:07:02](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=422.0s)]
*  It's a bailout. I don't know if it's a stolen vehicle or a robbery vehicle. [[00:07:04](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=424.0s)]
*  I want to see how facial recognition could potentially help the cops fight crime. [[00:07:10](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=430.0s)]
*  Someone has reported their car as being stolen. [[00:07:17](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=437.0s)]
*  Dozens of armed police are circling the area, searching houses for the perpetrator. [[00:07:21](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=441.0s)]
*  They believe he may be armed. [[00:07:26](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=446.0s)]
*  So the police here think that there might be a person who's hiding in one of these houses, so they're being very careful. [[00:07:29](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=449.0s)]
*  They're going to basically take this gate apart before they go in. [[00:07:36](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=456.0s)]
*  We're jumping one over right now. [[00:07:40](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=460.0s)]
*  They're jumping over right now. [[00:07:42](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=462.0s)]
*  The cops didn't have a photo of the perpetrator. We didn't find him. [[00:07:49](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=469.0s)]
*  This would be an excellent one for facial recognition. [[00:07:54](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=474.0s)]
*  If we had those cameras up and got a picture of the offender, they could go to the victim and show a photo lineup and say, [[00:07:57](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=477.0s)]
*  OK, here's a photo lineup. Do you see the person that robbed you? Oh, yeah, this guy. [[00:08:04](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=484.0s)]
*  You got that off the facial recognition. [[00:08:09](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=489.0s)]
*  Armando Aguilar is the head of investigations at Miami PD. [[00:08:12](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=492.0s)]
*  The force pays Clearview for access to their database. [[00:08:16](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=496.0s)]
*  We investigate crimes that are heinous in nature. [[00:08:21](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=501.0s)]
*  We investigate crimes that, to where sometimes it's difficult to get support, [[00:08:25](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=505.0s)]
*  we're going to have to go to the police. [[00:08:31](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=511.0s)]
*  We're going to have to go to the police. [[00:08:34](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=514.0s)]
*  We investigate crimes that, to where sometimes it's difficult to get support from eyewitnesses, [[00:08:36](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=516.0s)]
*  support from the public, for many reasons, because of perhaps loyalty to the people carrying out the crimes, [[00:08:43](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=523.0s)]
*  fear of retribution for cooperating with the police. [[00:08:52](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=532.0s)]
*  Is there any crime that you can't use this for here? [[00:08:56](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=536.0s)]
*  That we cannot use it for? No. [[00:08:59](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=539.0s)]
*  As long as it's a violation of a criminal statute, our detectives and our analysts are allowed to use it. [[00:09:02](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=542.0s)]
*  So sort of shoplifting right the way up to murder. Correct, yes. [[00:09:08](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=548.0s)]
*  The BBC can reveal that Clearview has been used by American law enforcement nearly a million times. [[00:09:11](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=551.0s)]
*  And there are many other systems in use. But what happens when it doesn't work? [[00:09:19](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=559.0s)]
*  In 2018, this man walked into a shop in New York and stole some socks [[00:09:32](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=572.0s)]
*  before appearing to wave box cutters at a member of staff. [[00:09:37](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=577.0s)]
*  Kaitlyn Jackson is the lawyer for the man the police believed was the perpetrator. [[00:09:41](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=581.0s)]
*  He wants to remain anonymous, but has agreed for Kaitlyn to speak out on his behalf. [[00:09:46](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=586.0s)]
*  Because it was a theft plus a weapon, it was charged as first-degree robbery, [[00:09:53](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=593.0s)]
*  which means if you're convicted of it, it's a pretty hefty prison sentence. [[00:09:59](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=599.0s)]
*  My client would have been looking at between five and 25 years in prison for essentially stealing six socks. [[00:10:04](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=604.0s)]
*  The main witness was a security guard, sometimes referred to as a loss prevention officer in the US. [[00:10:10](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=610.0s)]
*  What we learned was that shortly after this theft happened, [[00:10:16](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=616.0s)]
*  a detective from the NYPD went and met with the loss prevention officer and said, [[00:10:21](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=621.0s)]
*  and said, we want to see the surveillance. And they watched the surveillance, [[00:10:26](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=626.0s)]
*  and they took a screen grab of the face of the person who stole the socks. [[00:10:30](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=630.0s)]
*  And then the detective told the loss prevention officer, we're going to put this in facial recognition software. [[00:10:34](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=634.0s)]
*  So essentially what I got was a piece of paper that had a screenshot from the surveillance [[00:10:40](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=640.0s)]
*  and my client's mugshot that said possible match. [[00:10:47](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=647.0s)]
*  They don't do a photo lineup. They don't do any kind of better identification procedure. [[00:10:50](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=650.0s)]
*  They just shoot him a text and say, is this the guy? [[00:10:57](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=657.0s)]
*  So at this point, imagine you're the loss prevention officer, right? [[00:11:00](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=660.0s)]
*  He says, yeah, that's the guy I saw. But of course he did. [[00:11:03](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=663.0s)]
*  You'd have to be telling the detective your high tech software doesn't work. [[00:11:06](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=666.0s)]
*  That's not the person, right? It is such a suggestive way to do the ID. [[00:11:10](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=670.0s)]
*  Shortly after that, my client got arrested. [[00:11:16](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=676.0s)]
*  On the day of the robbery, Caitlin's client had an alibi. [[00:11:19](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=679.0s)]
*  His son was born that day. He was at the hospital. [[00:11:23](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=683.0s)]
*  The birth happened within a few hours of the robbery. [[00:11:26](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=686.0s)]
*  So not at the exact same time, but in order to believe that you had the right person, [[00:11:29](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=689.0s)]
*  you have to believe that on the way to the birth of his child, [[00:11:34](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=694.0s)]
*  my client stopped at a big box store to steal a six pack of socks [[00:11:38](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=698.0s)]
*  and then immediately went to the hospital for the birth of his child. [[00:11:42](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=702.0s)]
*  It just wasn't him. He didn't do it. [[00:11:45](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=705.0s)]
*  Caitlin's client was sent to jail for five months awaiting trial. [[00:11:48](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=708.0s)]
*  He agreed to plead guilty so that he could be released. [[00:11:52](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=712.0s)]
*  Today, he still maintains his innocence. [[00:11:56](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=716.0s)]
*  The only way for him to get out and get home to his newborn baby was to take a plea, [[00:12:01](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=721.0s)]
*  and that's exactly what he ultimately did. [[00:12:07](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=727.0s)]
*  It's also a way for the police and the prosecutors [[00:12:09](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=729.0s)]
*  not to really have to investigate or sit with the fact that this might have got it wrong. [[00:12:13](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=733.0s)]
*  The NYPD told us they had not taken enforcement action [[00:12:19](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=739.0s)]
*  based solely on identification of a possible facial recognition match. [[00:12:22](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=742.0s)]
*  And it's important to emphasize that Clearview AI's technology was not used in this case. [[00:12:29](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=749.0s)]
*  The police used different software. [[00:12:34](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=754.0s)]
*  But it does throw up a crucial question. [[00:12:37](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=757.0s)]
*  How accurate is facial recognition technology? [[00:12:40](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=760.0s)]
*  Clearview will often say that it's almost 100% accurate, [[00:12:47](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=767.0s)]
*  but that's on mugshots, not photos taken outside like CCTV or body cam footage. [[00:12:51](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=771.0s)]
*  So we thought we'd put it to the test. [[00:12:58](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=778.0s)]
*  We took a range of different photos to see whether Clearview could find me. [[00:13:01](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=781.0s)]
*  We took some pictures, sort of like, you know, progressively more and more difficult. [[00:13:07](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=787.0s)]
*  So we have like, there's one of me with some glasses on, [[00:13:12](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=792.0s)]
*  there's one of me with a mask on looking at the camera. [[00:13:16](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=796.0s)]
*  All right. Sometimes blurry ones work, sometimes they don't. [[00:13:18](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=798.0s)]
*  It's tricky, but we can give it a try. [[00:13:22](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=802.0s)]
*  The algorithm found me in some of the shots, but not in others. [[00:13:25](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=805.0s)]
*  None of me wearing a mask were found. [[00:13:28](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=808.0s)]
*  When they're higher quality, they have a higher chance of making a hit. [[00:13:30](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=810.0s)]
*  So it depends on the quality of the picture? [[00:13:34](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=814.0s)]
*  Yeah, exactly. [[00:13:37](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=817.0s)]
*  The accuracy depends on the quality of the picture. [[00:13:38](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=818.0s)]
*  So that's why we've added things like that warning, as you saw, saying, [[00:13:40](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=820.0s)]
*  hey, this is a lower quality image. [[00:13:43](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=823.0s)]
*  So, you know, take extra care when taking a look at the results. [[00:13:45](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=825.0s)]
*  The police argue that they don't just rely on facial recognition to make an arrest. [[00:13:49](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=829.0s)]
*  So we treat a match from any one of our face recognition platforms as a tip. [[00:13:55](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=835.0s)]
*  We don't run out and make an arrest based on that tip. [[00:14:00](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=840.0s)]
*  Our detectives logged about a 40% positive identification rate [[00:14:02](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=842.0s)]
*  across all of our facial recognition searches. [[00:14:07](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=847.0s)]
*  We're talking about we got this match, detectives investigated, [[00:14:10](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=850.0s)]
*  and then reported back to our real-time crime center that, yes, [[00:14:14](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=854.0s)]
*  that the person that you sent me as a match was, in fact, [[00:14:17](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=857.0s)]
*  the person that we established probable cause to arrest. [[00:14:21](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=861.0s)]
*  A 40% positive identification rate is a very different figure [[00:14:25](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=865.0s)]
*  to Clearview's claim of almost 100% accuracy. [[00:14:29](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=869.0s)]
*  Kwan Tontat doesn't seem to want his technology tested in court. [[00:14:34](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=874.0s)]
*  Our view is it's going to be better if we don't have facial recognition as evidence in court [[00:14:39](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=879.0s)]
*  because the investigators, they're using other methods to also verify. [[00:14:44](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=884.0s)]
*  Shouldn't it be interrogated in court? [[00:14:48](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=888.0s)]
*  Well... [[00:14:50](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=890.0s)]
*  Like it's being used to find people. [[00:14:51](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=891.0s)]
*  We're happy to testify about how the algorithms work, how accurate they are, [[00:14:53](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=893.0s)]
*  but any of these mistakes that have been made with facial recognition, [[00:14:57](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=897.0s)]
*  and none of them made with Clearview, have come down to poor policing. [[00:15:01](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=901.0s)]
*  In many places in the US, the police often don't have to divulge [[00:15:07](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=907.0s)]
*  whether they even use facial recognition. [[00:15:10](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=910.0s)]
*  We have no idea how many people have been arrested because of this technology. [[00:15:13](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=913.0s)]
*  But a few cities have pushed back. [[00:15:19](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=919.0s)]
*  In San Francisco, the police's use of facial recognition technology is banned. [[00:15:22](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=922.0s)]
*  Matthew Guariglia works for the Electronic Frontier Foundation, which pushed for the ban. [[00:15:28](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=928.0s)]
*  Part of the problem with facial recognition isn't just that it's invasive, isn't just that it's wrong, [[00:15:34](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=934.0s)]
*  it's also that the police departments themselves are incredibly opaque about how and when it's used, [[00:15:38](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=938.0s)]
*  and the companies are opaque about how the technology actually works. [[00:15:43](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=943.0s)]
*  So whether you're in court or not, whether you're questioning how the police use it [[00:15:47](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=947.0s)]
*  or how it works from the companies, it's often very hard for defense attorneys, [[00:15:51](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=951.0s)]
*  for celebrities organizations, for concerned citizens to find out when or how it's being used and how it works. [[00:15:55](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=955.0s)]
*  Vince is waiting to meet Andrew for the first time. [[00:16:06](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=966.0s)]
*  They haven't spoken to each other since the night of the crash. [[00:16:09](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=969.0s)]
*  What's going on, man? Long time no see. [[00:16:18](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=978.0s)]
*  Yeah, you're a hard guy to find. [[00:16:20](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=980.0s)]
*  Yeah, apparently. [[00:16:22](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=982.0s)]
*  So how's everything? [[00:16:23](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=983.0s)]
*  Oh, a lot better since we found you. [[00:16:25](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=985.0s)]
*  Yeah, I know. I thought it was case closed after I told the cops what happened. [[00:16:27](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=987.0s)]
*  I just didn't think it carried on for five years later. [[00:16:31](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=991.0s)]
*  But even though facial recognition technology worked in this case, they're both still torn by the technology. [[00:16:34](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=994.0s)]
*  That was a pretty grainy footage and they still, you know, within a matter of, I believe it was actually seconds [[00:16:40](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1000.0s)]
*  from when they uploaded the image or however that worked to having other photos of you. [[00:16:47](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1007.0s)]
*  And then from those photos, finding your friend and ultimately you was not a big reach. [[00:16:54](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1014.0s)]
*  I can acknowledge the usefulness while still saying that's really creepy. [[00:17:00](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1020.0s)]
*  It is. [[00:17:07](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1027.0s)]
*  You know. [[00:17:08](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1028.0s)]
*  Facial recognition can help in policing. It can also be abused. [[00:17:09](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1029.0s)]
*  And it can get things wrong. [[00:17:13](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1033.0s)]
*  It's up to lawmakers to strike a balance between the battle for justice and our right to privacy. [[00:17:15](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1035.0s)]
*  Thank you. [[00:17:45](https://www.youtube.com/watch?v=uGeRTmDdqUI&t=1065.0s)]
