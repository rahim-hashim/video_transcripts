---
Date Generated: May 23, 2025
Transcription Model: whisper medium 20231117
Length: 2890s
Video Keywords: ['a16z', 'andreessen horowitz']
Video Views: 470279
Video Rating: None
Video Description: Fei-Fei Li and Justin Johnson are pioneers in AI. While the world has only recently witnessed a surge in consumer AI, our guests have long been laying the groundwork for innovations that are transforming industries today.

In this episode, a16z General Partner Martin Casado joins Fei-Fei and Justin to explore the journey from early AI winters to the rise of deep learning and the rapid expansion of multimodal AI. From foundational advancements like ImageNet to the cutting-edge realm of spatial intelligence, Fei-Fei and Justin share the breakthroughs that have shaped the AI landscape and reveal what's next for innovation at World Labs.

If you're curious about how AI is evolving beyond language models and into a new realm of 3D, generative worlds, this episode is a must-listen.

Timestamps: 
00:00 - Spatial Intelligence: A New Frontier
01:38 - Scaling AI: The Impact of ImageNet on Computer Vision
06:56  - The Role of Compute
09:16 - Data as the Key Driver
17:01 - Defining AI’s Ultimate Goal
18:58 - What is Spatial Intelligence? Unlocking 3D Understanding in AI
26:35 - Comparing Models: Spatial Intelligence vs. Language-Based AI
29:41 - 1D vs. 3D
32:39 - Building Immersive Worlds with Spatial Intelligence 
35:11 - From Static Scenes to Dynamic Worlds
37:42 - The Future of VR and AR
40:42 - Creating Deep Tech Platforms
44:26 - Building a World-Class Team
45:54 - Measuring Success: Milestones in Spatial Intelligence

Resources: 
Learn more about World Labs: https://www.worldlabs.ai
Find Fei-Fei on Twitter: https://x.com/drfeifei
Find Justin on Twitter: https://x.com/jcjohnss
Find Martin on Twitter: https://x.com/martin_casado

Stay Updated: 
Let us know what you think: https://ratethispodcast.com/a16z 
Find a16z on Twitter: https://twitter.com/a16z 
Find a16z on LinkedIn: https://www.linkedin.com/company/a16z 
Subscribe on your favorite podcast app: https://a16z.simplecast.com/ 
Follow our host: https://twitter.com/stephsmithio 

Please note that the content here is for informational purposes only; should NOT be taken as legal, business, tax, or investment advice or be used to evaluate any investment or security; and is not directed at any investors or potential investors in any a16z fund. a16z and its affiliates may maintain investments in the companies discussed. For more details please see a16z.com/disclosures.
---

# “The Future of AI is Here” — Fei-Fei Li Unveils the Next Frontier of AI
**The a16z Podcast:** [September 20, 2024](https://www.youtube.com/watch?v=vIXfYFB7aBI)
*  Visual spatial intelligence is so fundamental. [[00:00:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=0.0s)]
*  It's as fundamental as language. [[00:00:04](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=4.0s)]
*  We've got these ingredients, compute deeper understanding of data, [[00:00:06](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=6.5s)]
*  and we've got some advancement of algorithms. [[00:00:11](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=11.0s)]
*  We are in the right moment to really make a bet and to focus and just unlock that. [[00:00:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=14.5s)]
*  Over the last two years, we've seen this kind of massive rush of consumer AI companies and technology, [[00:00:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=21.0s)]
*  and it's been quite wild, but you've been doing this now for decades. [[00:00:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=25.0s)]
*  And so maybe walk through a little bit about how we got here, [[00:00:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=29.0s)]
*  kind of like your key contributions and insights along the way. [[00:00:31](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=31.0s)]
*  So it is a very exciting moment, right? [[00:00:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=34.0s)]
*  Just zooming back, AI is in a very exciting moment. [[00:00:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=37.0s)]
*  It's a very exciting moment. [[00:00:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=41.0s)]
*  It's a very exciting moment. [[00:00:43](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=43.0s)]
*  I personally have been doing this for two decades plus, [[00:00:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=45.0s)]
*  and we have come out of the last AI winter. [[00:00:48](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=48.0s)]
*  We have seen the birth of modern AI. [[00:00:51](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=51.0s)]
*  Then we have seen deep learning taking off, showing us possibilities like playing chess. [[00:00:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=54.0s)]
*  But then we're starting to see the deepening of the technology and the industry adoption of AI. [[00:01:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=60.0s)]
*  We're starting to see the deepening of the technology and the industry adoption of some of the earlier possibilities like language models. [[00:01:08](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=68.0s)]
*  And now I think we're in the middle of a Cambrian explosion in almost a literal sense, [[00:01:20](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=80.0s)]
*  because now in addition to texts, you're seeing pixels, videos, audios, [[00:01:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=86.0s)]
*  all coming out with possible AI applications and models. [[00:01:31](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=91.0s)]
*  So it's a very exciting moment. [[00:01:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=97.0s)]
*  I know you both so well, and many people know you both so well because you're so prominent in the field, [[00:01:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=99.0s)]
*  but not everybody grew up in AI. [[00:01:43](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=103.0s)]
*  So maybe it's kind of worth just going through your quick backgrounds just to kind of level set the audience. [[00:01:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=105.0s)]
*  Yeah, sure. So I first got into AI at the end of my undergrad. [[00:01:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=109.0s)]
*  I did math and computer science for undergrad at Caltech. [[00:01:53](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=113.0s)]
*  That was awesome. [[00:01:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=115.0s)]
*  But then towards the end of that, there was this paper that came out that was at the time a very famous paper, [[00:01:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=116.0s)]
*  the cat paper from Honglek Lee and Andrew Ng and others that were at Google Brain at the time. [[00:02:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=120.0s)]
*  That was just like the first time that I came across this concept of deep learning. [[00:02:05](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=125.0s)]
*  And to me, it just felt like this amazing technology. [[00:02:09](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=129.0s)]
*  And that was the first time that I came across this recipe that would come to define the next more than decade of my life, [[00:02:11](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=131.0s)]
*  which is that you can get these amazingly powerful learning algorithms that are very generic, [[00:02:17](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=137.0s)]
*  couple them with very large amounts of compute, couple them with very large amounts of data, [[00:02:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=141.0s)]
*  and magic things started to happen when you compile those ingredients. [[00:02:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=145.0s)]
*  So I first came across that idea like around 2011, 2012-ish, [[00:02:28](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=148.0s)]
*  and I just thought like, oh my God, this is this is going to be what I want to do. [[00:02:31](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=151.0s)]
*  So it's obvious you got to go to grad school to do this stuff. [[00:02:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=155.0s)]
*  And then sort of saw that Fei Fei was at Stanford, one of the few people in the world at the time who was kind of on that on that train. [[00:02:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=157.0s)]
*  And that was just an amazing time to be in deep learning and computer vision specifically, [[00:02:44](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=164.0s)]
*  because that was really the era when this went from these first nascent bits of technology that were just starting to work [[00:02:48](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=168.0s)]
*  and really got developed and spread across a ton of different applications. [[00:02:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=174.0s)]
*  So then over that time, we saw the beginnings of language modeling. [[00:02:58](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=178.0s)]
*  We saw the beginnings of discriminative computer vision, where you could take pictures and understand what's in them in a lot of different ways. [[00:03:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=181.0s)]
*  We also saw some of the early bits of what we would now call GenAI, generative modeling, generating images, generating text. [[00:03:06](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=186.0s)]
*  A lot of those core algorithmic pieces actually got figured out by the academic community during my PhD years. [[00:03:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=192.0s)]
*  Like there was a time I would just like wake up every morning and check the new papers on archive and just be ready. [[00:03:18](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=198.0s)]
*  It's like unwrapping presents on Christmas that like every day, you know, there's going to be some amazing new discovery, [[00:03:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=203.0s)]
*  some amazing new application or algorithm somewhere in the world. [[00:03:27](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=207.0s)]
*  What happened is in the last two years, everyone else in the world kind of came to the same realization using AI to get new Christmas presents every day. [[00:03:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=210.0s)]
*  But I think for those of us that have been in the field for a decade or more, we've sort of had that experience for a very long time. [[00:03:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=217.0s)]
*  Obviously, I'm much older than Justin. [[00:03:42](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=222.0s)]
*  And I come to AI through a different angle, which is from physics, because my undergraduate background was physics. [[00:03:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=225.0s)]
*  But physics is the kind of discipline that teaches you to think audacious questions and think about what is the remaining mystery of the world. [[00:03:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=234.0s)]
*  Of course, in physics, it's atomic world, you know, universe and all that. [[00:04:04](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=244.0s)]
*  But somehow that kind of training thinking got me into the audacious question that really captured my own imagination, which is intelligence. [[00:04:08](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=248.0s)]
*  So I did my PhD in AI and computational neuroscience at Caltech. [[00:04:19](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=259.0s)]
*  So Justin and I actually didn't overlap, but we share the same alma mater at Caltech. [[00:04:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=265.0s)]
*  And the same advisor at Caltech. [[00:04:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=272.0s)]
*  Yes, same advisor, your undergraduate advisor, my PhD advisor, Pietro Perona. [[00:04:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=274.0s)]
*  And my PhD time, which is similar to your PhD time, was when AI was still in the winter in the public eye. [[00:04:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=279.0s)]
*  But it was not in the winter in my eye because it's that pre-spring hibernation. [[00:04:48](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=288.0s)]
*  There's so much life. [[00:04:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=294.0s)]
*  Machine learning, statistical modeling was really gaining power. [[00:04:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=296.0s)]
*  And we, I think I was one of the native generation in machine learning and AI, whereas I look at just this generation is the native deep learning generation. [[00:05:02](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=302.0s)]
*  So machine learning was the precursor of deep learning. [[00:05:15](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=315.0s)]
*  And we were experimenting with all kinds of models. [[00:05:20](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=320.0s)]
*  But one thing came out at the end of my PhD and the beginning of my assistant professor time. [[00:05:24](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=324.0s)]
*  There was an overlooked elements of AI that is mathematically important to drive generalization. [[00:05:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=330.0s)]
*  But the whole field was not thinking that way. [[00:05:40](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=340.0s)]
*  And it was data because we were thinking about the intricacy of Bayesian models or whatever, you know, kernel methods and all that. [[00:05:43](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=343.0s)]
*  But what was fundamental that my students and my lab realized probably earlier than most people is that if you let data drive models, you can unleash the kind of power that we haven't seen before. [[00:05:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=355.0s)]
*  And that was really the reason we went on a pretty crazy bet on ImageNet, which is, you know what, just forget about any scale we're seeing now, which is thousands of data points. [[00:06:11](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=371.0s)]
*  At that point, NLP community has their own data sets. [[00:06:27](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=387.0s)]
*  I remember UC Irvine data set or some data set in NLP was it was small. [[00:06:31](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=391.0s)]
*  Compare Vision community has their data sets, but all in the order of thousands or tens of thousands were like, we need to drive it to internet scale. [[00:06:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=397.0s)]
*  And luckily, it was also the coming of age of Internet. [[00:06:46](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=406.0s)]
*  So we were riding that wave. [[00:06:51](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=411.0s)]
*  And that's when I came to Stanford. [[00:06:53](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=413.0s)]
*  So these epochs are what we often talk about, like ImageNet is clearly the epoch that created, you know, or at least like maybe made like popular and viable computer vision. [[00:06:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=416.0s)]
*  In the Gen. AI wave, we talked about two kind of core unlocks. [[00:07:07](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=427.0s)]
*  One is like the Transformers paper, which is attention. [[00:07:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=430.0s)]
*  We talked about stable diffusion. [[00:07:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=432.0s)]
*  Is that a fair way to think about this, which is like there's these two algorithmic unlocks that came from academia or Google and like that's where everything comes from? [[00:07:13](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=433.0s)]
*  Or has it been more deliberate? [[00:07:20](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=440.0s)]
*  Or have there been other kind of big unlocks that kind of brought us here that we don't talk as much about? [[00:07:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=441.0s)]
*  Yeah, I think the big unlock is compute. [[00:07:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=445.0s)]
*  Like I know the story of AI is often the story of compute. [[00:07:27](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=447.0s)]
*  But even no matter how much people talk about it, I think people underestimate it. [[00:07:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=450.0s)]
*  Right. [[00:07:33](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=453.0s)]
*  And the amount of the amount of growth that we've seen in computational power over the last decade is astounding. [[00:07:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=454.0s)]
*  The first paper that's really credited with the breakthrough moment in computer vision for deep learning was AlexNet, which was a 2012 paper where a deep neural network did really well on the ImageNet challenge and just blew away all the other algorithms that Fei Fei had been working on. [[00:07:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=458.0s)]
*  The types of algorithms that you've been working on more in grad school. [[00:07:53](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=473.0s)]
*  That AlexNet was a 60 million parameter deep neural network, and it was trained for six days on two GTX 580s, which was the top consumer card at the time, which came out in 2010. [[00:07:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=476.0s)]
*  So I was looking at some numbers last night just to put these in perspective. [[00:08:06](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=486.0s)]
*  The newest, the latest and greatest from Nvidia is the GB 200. [[00:08:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=490.0s)]
*  Do either of you want to guess how much raw compute factor we have between the GTX 580 and the GB 200? [[00:08:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=494.0s)]
*  Shoot, no. [[00:08:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=501.0s)]
*  What? [[00:08:22](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=502.0s)]
*  Go for it. [[00:08:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=503.0s)]
*  It's in the thousands. [[00:08:24](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=504.0s)]
*  So I ran the numbers last night like that two week training run, that six days on two GTX 580s. [[00:08:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=506.0s)]
*  If you scale, it comes out to just under five minutes on a single GB 200. [[00:08:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=512.0s)]
*  Justin is making a really good point. [[00:08:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=518.0s)]
*  The 2012 AlexNet paper on ImageNet challenge is literally a very classic model, and that is the convolutional neural network model. [[00:08:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=521.0s)]
*  And that was published in 1980s, the first paper. [[00:08:52](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=532.0s)]
*  I remember as a graduate student learning that. [[00:08:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=535.0s)]
*  And it more or less also has six, seven layers. [[00:08:59](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=539.0s)]
*  The practically the only difference between AlexNet and the ConvNet. [[00:09:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=543.0s)]
*  What's the difference is the GPUs, the two GPUs and the deluge of data. [[00:09:08](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=548.0s)]
*  Yeah. Well, so that's what I was going to go, which is like so I think most people now are familiar with, like, quote, the bitter lesson. [[00:09:16](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=556.0s)]
*  And the bitter lesson says is if you make an algorithm, don't be cute. [[00:09:22](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=562.0s)]
*  Just make sure you can take advantage of available compute because the available compute will show up. [[00:09:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=565.0s)]
*  Right. And so like you just like need a like wife like to. [[00:09:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=569.0s)]
*  On the other hand, there's another narrative which seems to me to be like just as credible, which is like it's actually new data sources that unlock deep learning. [[00:09:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=572.0s)]
*  Right. Like ImageNet is a great example. But like a lot of people like self-attention is great from Transformers. [[00:09:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=579.0s)]
*  But they'll also say this is a way you can exploit human labeling of data because like it's the humans that put the structure in the sentences. [[00:09:43](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=583.0s)]
*  And if you look at clip, let's say, well, I could be using the Internet to like actually like have humans use the alt tag to label images. [[00:09:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=589.0s)]
*  Right. And so like that's a story of data that's not a story of compute. [[00:09:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=596.0s)]
*  And so is it just is the answer just both or is like one more than the other? [[00:10:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=600.0s)]
*  I think it's both. But you're hitting another really good point. [[00:10:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=603.0s)]
*  So I think there's actually two epochs that to me feel quite distinct in the algorithmics here. [[00:10:06](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=606.0s)]
*  So like the ImageNet era is actually the era of supervised learning. [[00:10:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=610.0s)]
*  So in the era of supervised learning, you have a lot of data, but you don't know how to use data on its own. [[00:10:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=614.0s)]
*  Like the expectation of ImageNet and other data sets of that time period was that we're going to get a lot of images, but we need people to label every one. [[00:10:19](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=619.0s)]
*  And all of the training data that we're going to train on, like a person, a human labeler has looked at every one and said something about that image. [[00:10:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=626.0s)]
*  And the big algorithmic unlocks. [[00:10:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=632.0s)]
*  We know how to train on things that don't require human labeled data. [[00:10:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=634.0s)]
*  As the naive person in the room that doesn't have an AI background, it seems to me if you're training on human data, like the humans have labeled it, it's just not explicit. [[00:10:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=638.0s)]
*  I knew you were going to say that, Marty. I knew that. [[00:10:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=645.0s)]
*  Yes, philosophically, that's a really important question. [[00:10:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=649.0s)]
*  But that actually is more true in language than pixels. [[00:10:52](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=652.0s)]
*  Fair enough. Yeah. Yeah, yeah, yeah. [[00:10:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=656.0s)]
*  But I do think it's an important distinction because PLIP really is human labeled. [[00:10:58](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=658.0s)]
*  I think attention is humans have like figured out the relationships of things and then you learn them. [[00:11:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=661.0s)]
*  So it is human labeled just more implicit than explicit. [[00:11:06](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=666.0s)]
*  Yeah, it's still human labeled. [[00:11:09](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=669.0s)]
*  The distinction is that for this supervised learning era, our learning tasks were much more constrained. [[00:11:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=670.0s)]
*  So like you would have to come up with this ontology of concepts that we want to discover. [[00:11:15](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=675.0s)]
*  If you're doing in ImageNet, like Fei-Fei and your students at the time spent a lot of time thinking about which thousand categories should be in the ImageNet challenge. [[00:11:19](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=679.0s)]
*  Other data sets of that time, like the Coco data set for object detection, they thought really hard about which 80 categories we put in there. [[00:11:28](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=688.0s)]
*  So let's walk to GenAI. [[00:11:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=694.0s)]
*  So when I was doing my PhD before that you came, so I took machine learning from Andrew Ng, and then I took like Bayesian, something very complicated from Daphne Koller, and it was very complicated for me. [[00:11:36](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=696.0s)]
*  A lot of that was just predictive modeling. [[00:11:46](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=706.0s)]
*  And then like I remember the whole kind of vision stuff that you unlocked, but then the generative stuff has shown up, like I would say in the last four years, which is to me very different. [[00:11:48](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=708.0s)]
*  Like you're not identifying objects, you're not predicting something, you're generating something. [[00:11:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=716.0s)]
*  And so maybe kind of walk through like the key unlocks that got us there and then why it's different and if we should think about it differently and is it part of a continuum? [[00:12:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=720.0s)]
*  Is it not? [[00:12:08](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=728.0s)]
*  It is so interesting. [[00:12:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=730.0s)]
*  Even during my graduate time, generative model was there. [[00:12:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=732.0s)]
*  We wanted to do generation. [[00:12:17](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=737.0s)]
*  Nobody remembers, even with letters and numbers, we were trying to do some, you know, Jeff Hinton has had to generate the papers. [[00:12:19](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=739.0s)]
*  We were thinking about how to generate. [[00:12:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=749.0s)]
*  And in fact, if you do have, if you think from a probability distribution point of view, you can mathematically generate. [[00:12:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=752.0s)]
*  It's just nothing we generate would ever impress anybody. [[00:12:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=759.0s)]
*  So this concept of generation mathematically, theoretically is there, but nothing worked. [[00:12:43](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=763.0s)]
*  So then I do want to call out Justin's PhD. [[00:12:50](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=770.0s)]
*  Justin was saying that he got enamored by deep learning, so he came to my lab. [[00:12:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=774.0s)]
*  Justin's PhD, his entire PhD is a story, almost a mini story of the trajectory of the field. [[00:12:59](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=779.0s)]
*  He started his first project in data. [[00:13:08](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=788.0s)]
*  I forced him to. [[00:13:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=790.0s)]
*  He didn't like it. [[00:13:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=792.0s)]
*  In retrospect, I learned a lot of really useful things. [[00:13:15](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=795.0s)]
*  I'm glad you say that now. [[00:13:17](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=797.0s)]
*  So we moved Justin to deep learning and the core problem there was taking images and generating words. [[00:13:20](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=800.0s)]
*  Well, actually it was even about, I think there were three discrete phases here on this trajectory. [[00:13:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=809.0s)]
*  So the first one was actually matching images and words. [[00:13:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=814.0s)]
*  Right, right, right. [[00:13:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=817.0s)]
*  Like we have an image, we have words and can we say how much they are lost? [[00:13:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=818.0s)]
*  So actually my first paper, both of my PhD and like ever, my first academic publication ever was the image retrieval with scene graphs. [[00:13:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=821.0s)]
*  And then we went into the generating, taking pixels, generating words. [[00:13:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=829.0s)]
*  And Justin and Andre really worked on that. [[00:13:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=834.0s)]
*  But that was still a very, very lossy way of generating and getting information out of the pixel world. [[00:13:58](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=838.0s)]
*  And then in the middle, Justin went off and did a very famous piece of work. [[00:14:06](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=846.0s)]
*  And it was the first time that someone made it real time. [[00:14:11](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=851.0s)]
*  Right. [[00:14:16](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=856.0s)]
*  Yeah, yeah. [[00:14:17](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=857.0s)]
*  And then there was this paper that came out in 2015, a neural algorithm of artistic style led by Leon Gaddis. [[00:14:18](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=858.0s)]
*  And it was like the paper came out and they showed like these real world photographs that they had converted into Van Gogh style. [[00:14:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=863.0s)]
*  And like we are kind of used to seeing things like this in 2024, but this was in 2015. [[00:14:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=869.0s)]
*  So this paper just popped up on archive one day and it like blew my mind. [[00:14:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=874.0s)]
*  Like I just got this like genii brain worm like in my brain in like 2015 and it like did something to me. [[00:14:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=877.0s)]
*  And I thought like, oh my God, I need to understand this algorithm. [[00:14:44](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=884.0s)]
*  I need to play with it. [[00:14:46](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=886.0s)]
*  I need to make my own images into Van Gogh. [[00:14:47](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=887.0s)]
*  So then I like read the paper and over a long weekend, I re-implemented the thing and got it to work. [[00:14:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=889.0s)]
*  It was a very actually very simple algorithm. [[00:14:53](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=893.0s)]
*  So like my implementation was like 300 lines of Lua because at the time it was Lua. [[00:14:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=896.0s)]
*  It was Lua. [[00:15:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=901.0s)]
*  There was this was pre-PyTorch. [[00:15:02](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=902.0s)]
*  So we were using Lua torch, but it was like very simple algorithm, but it was slow. [[00:15:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=903.0s)]
*  Right. [[00:15:07](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=907.0s)]
*  So it was an optimization based thing. [[00:15:08](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=908.0s)]
*  Every image you want to generate, you need to run this optimization loop, run this gradient to stent loop for every image that you generate. [[00:15:09](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=909.0s)]
*  The images were beautiful. [[00:15:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=914.0s)]
*  But I just like wanted to be faster. [[00:15:15](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=915.0s)]
*  And Justin just did it. [[00:15:18](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=918.0s)]
*  And it was actually, I think your first taste of an academic work having an industry impact. [[00:15:20](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=920.0s)]
*  A bunch of people had seen this slow, this artistic style transfer stuff at the time. [[00:15:28](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=928.0s)]
*  And me and a couple others at the same time came up with different ways to speed this up. [[00:15:31](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=931.0s)]
*  Yeah. [[00:15:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=935.0s)]
*  But mine was the one that got a lot of traction. [[00:15:36](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=936.0s)]
*  Right. [[00:15:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=938.0s)]
*  So I was very proud of Justin. [[00:15:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=939.0s)]
*  But there's one more thing I was very proud of Justin to connect to Genii. [[00:15:40](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=940.0s)]
*  Is that before the world understand Genii, Justin's last piece of work in PhD, which I knew about it because I was forcing you to do it. [[00:15:43](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=943.0s)]
*  That one was fun. [[00:15:53](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=953.0s)]
*  Yes. [[00:15:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=954.0s)]
*  That one was fun. [[00:15:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=955.0s)]
*  Was actually inputting language and getting the whole picture out. [[00:15:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=956.0s)]
*  It's one of the first Genii work. [[00:16:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=963.0s)]
*  It's using GaM, which was so hard to use. [[00:16:06](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=966.0s)]
*  But the problem is that we are not ready to use a natural piece of language. [[00:16:09](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=969.0s)]
*  So Justin, you heard he worked on scene graph. [[00:16:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=974.0s)]
*  So we have to input a scene graph language structure. [[00:16:17](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=977.0s)]
*  So, you know, the sheep, the grass, the sky in a graph way. [[00:16:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=981.0s)]
*  And literally was one of our photos. [[00:16:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=986.0s)]
*  And then he and another very good master student, Grimm, they got that GaM to work. [[00:16:28](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=988.0s)]
*  So you can see from data to matching to style transfer to generative images, we're starting to see you ask if this is a rough change for people like us. [[00:16:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=995.0s)]
*  It's already happening in the continuum. [[00:16:47](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1007.0s)]
*  But for the world, it was it's more up. [[00:16:50](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1010.0s)]
*  The results are more abrupt. [[00:16:53](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1013.0s)]
*  So I read your book. [[00:16:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1015.0s)]
*  And for those that are listening, it's a phenomenal book. [[00:16:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1016.0s)]
*  I like I really recommend you read it. [[00:16:58](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1018.0s)]
*  And it seems for me, it's a phenomenal book. [[00:17:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1020.0s)]
*  And I'll talk to you, Fei-Fei, like a lot of your research has been, you know, and your direction has been towards kind of spatial stuff and pixel stuff and intelligence. [[00:17:02](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1022.0s)]
*  And now you're doing world labs and it's around spatial intelligence. [[00:17:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1032.0s)]
*  And so maybe talk through like, you know, is this been part of a long journey for you? [[00:17:15](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1035.0s)]
*  Like, why did you decide to do it now? [[00:17:20](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1040.0s)]
*  Is it a technical unlock? [[00:17:22](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1042.0s)]
*  Is it a personal unlock? [[00:17:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1043.0s)]
*  Just kind of like move us from that kind of mehlu of the old days. [[00:17:24](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1044.0s)]
*  Move us from that kind of mehlu of AI research to to world labs. [[00:17:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1049.0s)]
*  Sure. For me is it is both personal and intellectual. [[00:17:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1054.0s)]
*  Right. My entire you talk about my book, my entire intellectual journey is really this passion to seek North stars, but also believing that those North stars are critically important for the advancement of our field. [[00:17:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1061.0s)]
*  So at the beginning, I remembered after graduate school, I thought my North star was telling stories of images, because for me, that's such an important piece of visual intelligence. [[00:17:58](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1078.0s)]
*  That's part of what you call AI or AGI. [[00:18:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1092.0s)]
*  But when Justin and Andre did that, I was like, oh, my God, that's that was my live stream. [[00:18:15](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1095.0s)]
*  What do I do next? [[00:18:20](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1100.0s)]
*  So it came a lot faster. [[00:18:22](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1102.0s)]
*  I thought it would take 100 years to do that. [[00:18:24](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1104.0s)]
*  So but visual intelligence is my passion because I do believe for every intelligent being like people or robots or some other form, knowing how to see the world, reason about it, interact in it, whether you're navigating or or manipulating or making things. [[00:18:27](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1107.0s)]
*  You can even build civilization upon it. [[00:18:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1134.0s)]
*  It visual spatial intelligence is so fundamental. [[00:18:57](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1137.0s)]
*  It's as fundamental as language, possibly more ancient and more fundamental in certain ways. [[00:19:02](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1142.0s)]
*  So so it's very natural for me that world labs is our North star is to unlock spatial intelligence. [[00:19:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1150.0s)]
*  The moment to me is right to do it like Justin was saying compute. [[00:19:19](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1159.0s)]
*  We've got these ingredients. [[00:19:24](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1164.0s)]
*  We've got compute. [[00:19:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1166.0s)]
*  We've got a much deeper understanding of data, way deeper than image that days, you know, compared to to that. [[00:19:28](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1168.0s)]
*  Those days were so much more sophisticated. [[00:19:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1175.0s)]
*  And we've got some advancement of algorithms, including co-founders in world lab like Ben Mildenhall and Christoph Lassner. [[00:19:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1178.0s)]
*  They were at the cutting edge of nerve that we are in the right moment to really make a bet and to focus and just unlock that. [[00:19:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1189.0s)]
*  So I just want to clarify for folks that are listening to this, which is so you're starting this company, World Labs, [[00:19:58](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1198.0s)]
*  spatial intelligence is kind of how you're generally describing the problem you're solving. [[00:20:04](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1204.0s)]
*  Can you maybe try to crisply describe what that means? [[00:20:07](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1207.0s)]
*  Yes. So spatial intelligence is about machines ability to understand, to perceive, reason and act in 3D and 3D space and time to understand how objects and events are positioned in 3D space and time, [[00:20:11](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1211.0s)]
*  how interactions in the world can affect those 3D positions, 3D 40 positions over space time and both sort of perceive, reason about, generate, interact with, [[00:20:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1223.0s)]
*  really take the machine out of the mainframe or out of the data center and putting it out into the world and understanding the 3D, 4D world with all of its richness. [[00:20:33](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1233.0s)]
*  So to be very clear, are we talking about the physical world or are we just talking about an abstract notion of world? [[00:20:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1241.0s)]
*  I think it can be both. I think it can be both. [[00:20:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1245.0s)]
*  And that encompasses our vision long term. [[00:20:47](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1247.0s)]
*  Even if you're generating worlds, even if you're generating content, doing that in positioned in 3D with 3D has a lot of benefits. [[00:20:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1249.0s)]
*  Or if you're recognizing the real world, being able to put 3D understanding into the real world as well is part of it. [[00:20:57](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1257.0s)]
*  Great. So I mean, just for everybody listening, like the two other co-founders, Ben Melton Hall and Christoph Lassner are absolute legends in the field at the same level. [[00:21:05](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1265.0s)]
*  These four decided to come out and do this company now. [[00:21:13](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1273.0s)]
*  And so I'm trying to get dig to like, like why now is the right time? [[00:21:16](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1276.0s)]
*  Yeah, I mean, this is, again, part of a longer evolution for me. [[00:21:20](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1280.0s)]
*  But really after PhD, when I was really wanting to develop into my own independent researcher, both for my later career, I was just thinking, what are the big problems in AI and computer vision? [[00:21:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1283.0s)]
*  And the conclusion that I came to about that time was that the previous decade had mostly been about understanding data that already exists. [[00:21:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1292.0s)]
*  And so I think that's a big problem. [[00:21:40](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1300.0s)]
*  But the next decade was going to be about understanding new data. [[00:21:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1301.0s)]
*  And if we think about that, the data that already exists was all of the images and videos that maybe existed on the Web already. [[00:21:44](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1304.0s)]
*  And the next decade was going to be about understanding new data. [[00:21:50](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1310.0s)]
*  Right. Like people are people have smartphones, smartphones are collecting cameras, those cameras have new sensors, those cameras are positioned in the 3D world. [[00:21:53](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1313.0s)]
*  It's not just you're going to get a bag of pixels from the Internet and know nothing about it and try to say if it's a cat or a dog. [[00:22:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1320.0s)]
*  So how do we treat images as universal sensors to the physical world? [[00:22:05](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1325.0s)]
*  And how can we use that to understand the 3D and 4D structure of the world, either in physical spaces or generative spaces? [[00:22:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1330.0s)]
*  So I made a pretty big pivot post-PhD into 3D computer vision, predicting 3D shapes of objects with some of my colleagues at FAIR at the time. [[00:22:17](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1337.0s)]
*  Then later I got really enamored by this idea of learning 3D structure through 2D. [[00:22:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1345.0s)]
*  So we talk about data a lot. It's, you know, 3D data is hard to get on its own. [[00:22:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1350.0s)]
*  But because there's a very strong mathematical connection here, our 2D images are projections of a 3D world. [[00:22:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1355.0s)]
*  And there's a lot of mathematical structure here we can take advantage of. [[00:22:42](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1362.0s)]
*  So even if you have a lot of 2D data, there's a lot of people have done amazing work to figure out how can you back out the 3D structure of the world from large quantities of 2D observations. [[00:22:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1365.0s)]
*  And then in 2020, you asked about breakthrough moments. [[00:22:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1374.0s)]
*  There was a really big breakthrough moment from our co-founder, Ben Mildenhall, at the time with his paper, NERF, Neural Radiance Fields. [[00:22:57](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1377.0s)]
*  And that was a very simple, very clear way of backing out 3D structure from 2D observations. [[00:23:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1383.0s)]
*  That just lit a fire under this whole space of 3D computer vision. [[00:23:09](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1389.0s)]
*  I think there's another aspect here that maybe people outside the field don't quite understand. [[00:23:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1394.0s)]
*  That was also a time when large language models were starting to take off. [[00:23:18](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1398.0s)]
*  So a lot of the stuff with language modeling actually had gotten developed in academia. [[00:23:22](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1402.0s)]
*  Even during my PhD, I did some early work with Andrei Karpathy on language modeling in 2014. [[00:23:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1405.0s)]
*  LSTM, I still remember. [[00:23:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1410.0s)]
*  LSTM, RNN, GRUs. This was pre-transformer. [[00:23:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1412.0s)]
*  But then at some point, around the GPT-2 time, you couldn't really do those kind of models anymore in academia because they took way more resourcing. [[00:23:36](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1416.0s)]
*  But there was one really interesting thing. [[00:23:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1425.0s)]
*  The NERF approach that Ben came up with, you could train these in a couple hours on a single GPU. [[00:23:47](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1427.0s)]
*  So I think at that time, there was a dynamic here that happened, which is that I think a lot of academic researchers ended up focusing a lot of these problems [[00:23:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1434.0s)]
*  because there was core algorithmic stuff to figure out and because you could actually do a lot without a ton of compute and you could get state of the art results on a single GPU. [[00:24:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1441.0s)]
*  Because of those dynamics, there was a lot of research. [[00:24:09](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1449.0s)]
*  A lot of researchers in academia were moving to think about what are the core algorithmic ways that we can advance this area as well. [[00:24:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1452.0s)]
*  Then I ended up chatting with Fei-Fei more and I realized that we were actually... [[00:24:19](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1459.0s)]
*  She's very convincing. [[00:24:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1463.0s)]
*  She's very convincing. [[00:24:24](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1464.0s)]
*  Well, there's that. [[00:24:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1465.0s)]
*  But like, you know, you were talking about trying to like figure out your own independent research trajectory from your advisor. [[00:24:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1466.0s)]
*  Well, it turns out we ended up kind of concluding on... [[00:24:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1470.0s)]
*  Converging again. [[00:24:33](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1473.0s)]
*  Converging on similar things. [[00:24:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1474.0s)]
*  Thank you. [[00:24:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1475.0s)]
*  Well, from my end, I want to talk to the smartest person I can, Justin. [[00:24:36](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1476.0s)]
*  There's no question about it. [[00:24:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1479.0s)]
*  I do want to talk about a very interesting technical issue or technical story of pixels that most people working language don't realize is that pre-gen AI era in the field of computer vision, [[00:24:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1481.0s)]
*  those of us who work on pixels, we actually have a long history in an area of research called reconstruction, 3D reconstruction, which is, you know, it dates back from the 70s. [[00:24:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1496.0s)]
*  You know, you can take photos because humans have two eyes, right? [[00:25:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1510.0s)]
*  So in general, it starts with stereo photos and then you try to triangulate the geometry and make a 3D shape out of it. [[00:25:13](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1513.0s)]
*  It is a really, really hard problem to this day. [[00:25:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1523.0s)]
*  It's not fundamentally solved because there's correspondence and all that. [[00:25:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1526.0s)]
*  And then so this whole field, which is an older way of thinking about 3D, has been going around and has been making really good progress. [[00:25:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1530.0s)]
*  But when NERF happened, when NERF happened in the context of generative methods, in the context of diffusion models, [[00:25:40](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1540.0s)]
*  suddenly reconstruction and generation start to really merge. [[00:25:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1549.0s)]
*  And now, like within really a short period of time in the field of computer vision, it's hard to talk about reconstruction versus generation anymore. [[00:25:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1554.0s)]
*  We suddenly have a moment where if we see something or if we imagine something, both can converge towards generating it. [[00:26:04](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1564.0s)]
*  And that's just, to me, a really important moment for computer vision. [[00:26:16](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1576.0s)]
*  But most people miss that because we're not talking about it as much as LLMs. [[00:26:20](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1580.0s)]
*  Right. So in pixel space, there's reconstruction where you reconstruct like a scene that's real. [[00:26:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1585.0s)]
*  And then if you don't see the scene, then you use generative techniques. [[00:26:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1590.0s)]
*  Right. So these things are kind of very similar throughout this entire conversation. [[00:26:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1592.0s)]
*  You're talking about languages and you're talking about pixels. [[00:26:36](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1596.0s)]
*  So maybe it's a good time to talk about how spatial intelligence and what you're working on contrasts with language approaches, which of course are very popular now. [[00:26:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1599.0s)]
*  Like, is it complementary? Is it orthogonal? [[00:26:48](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1608.0s)]
*  Yeah, I think they're complementary. [[00:26:51](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1611.0s)]
*  I don't want me to be too leading here. [[00:26:53](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1613.0s)]
*  Maybe just contrast them. [[00:26:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1614.0s)]
*  Everybody says, listen, I know OpenAI and I know GPT and I know multimodal models. [[00:26:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1615.0s)]
*  And a lot of what you're talking about is they've got pixels and they've got languages. [[00:27:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1621.0s)]
*  And doesn't this kind of do what we want to do with spatial reasoning? [[00:27:04](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1624.0s)]
*  Yeah. So I think to do that, you need to open up the black box a little bit of how these systems work under the hood. [[00:27:08](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1628.0s)]
*  So with language models and the multimodal language models that we're seeing nowadays, their underlying representation under the hood is a one dimensional representation. [[00:27:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1632.0s)]
*  We talk about context lengths. We talk about transformers. We talk about sequences. [[00:27:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1641.0s)]
*  Attention. [[00:27:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1645.0s)]
*  Fundamentally, their representation of the world is one dimensional. [[00:27:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1646.0s)]
*  So these things fundamentally operate on a one dimensional sequence of tokens. [[00:27:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1650.0s)]
*  So this is a very natural representation when you're talking about language because written text is a one dimensional sequence of discrete letters. [[00:27:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1654.0s)]
*  So that kind of underlying representation is the thing that led to LLMs. [[00:27:40](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1660.0s)]
*  And now the multimodal LLMs that we're seeing now, you kind of end up shoehorning the other modalities into this underlying representation of a one D sequence of tokens. [[00:27:44](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1664.0s)]
*  Now, when we move to spatial intelligence, it's kind of going the other way where we're saying that the three dimensional nature of the world should be front and center in the representation. [[00:27:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1674.0s)]
*  So at an algorithmic perspective, that opens up the door for us to process data in different ways to get different kinds of outputs out of it and to tackle slightly different problems. [[00:28:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1683.0s)]
*  So even at a course level, you kind of look at outside and you say, oh, multimodal LLMs can look at images too. [[00:28:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1692.0s)]
*  Well, they can, but I think that it's they don't have that fundamental 3D representation at the heart of their approaches. [[00:28:17](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1697.0s)]
*  I totally agree with Justin. [[00:28:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1703.0s)]
*  I think talking about the one D versus fundamentally 3D representation is one of the most core differentiation. [[00:28:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1705.0s)]
*  The other thing is a slightly philosophical, but it's really important to for me, at least is language is fundamentally a purely generated signal. [[00:28:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1712.0s)]
*  There's no language out there. [[00:28:43](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1723.0s)]
*  You don't go out in the nature and there's words written in the sky for you. [[00:28:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1725.0s)]
*  Whatever data you feeding, you pretty much can just somehow regurgitate with enough generalizability the same data out. [[00:28:50](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1730.0s)]
*  And that's language to language. [[00:29:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1741.0s)]
*  And but but 3D world is not there is a 3D world out there that follows laws of physics that has its own structures due to materials and many other things. [[00:29:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1743.0s)]
*  And to to fundamentally back that information out and be able to represent it and be able to generate it is just fundamentally quite a different problem. [[00:29:16](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1756.0s)]
*  We will be borrowing similar ideas or useful ideas from language and LLMS. [[00:29:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1769.0s)]
*  But this is fundamentally philosophically to me a different problem. [[00:29:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1778.0s)]
*  So language one D and probably a bad representation of the physical world because it's been generated by humans and it's probably lossy. [[00:29:42](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1782.0s)]
*  There's a whole nother modality of generative AI models, which are pixels. [[00:29:50](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1790.0s)]
*  And these are 2D image and 2D video. [[00:29:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1795.0s)]
*  And like one could say that like if you look at a video, it looks you know, you can see 3D stuff because like you can pan a camera or whatever it is. [[00:29:57](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1797.0s)]
*  And so like how would like spatial intelligence be different than say 2D video here when I think about this, it's useful to disentangle two things. [[00:30:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1803.0s)]
*  One is the underlying representation. [[00:30:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1810.0s)]
*  And then two is kind of the user facing affordances that you have. [[00:30:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1812.0s)]
*  And here's where you can get sometimes confused because fundamentally we see 2D right. [[00:30:16](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1816.0s)]
*  Like our retinas are 2D structures in our bodies and we've got two of them. [[00:30:22](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1822.0s)]
*  So like fundamentally our visual system perceives 2D images. [[00:30:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1826.0s)]
*  But the problem is that depending on what representation you use, there could be different affordances that are more natural or less natural. [[00:30:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1830.0s)]
*  So even if you are at the end of the day, you might be seeing a 2D image or a 2D video. [[00:30:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1837.0s)]
*  Your brain is perceiving that as a projection of a 3D world. [[00:30:42](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1842.0s)]
*  So there's things you might want to do like move objects around, move the camera around. [[00:30:46](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1846.0s)]
*  In principle, you might be able to do these with a purely 2D representation and model. [[00:30:51](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1851.0s)]
*  But it's just not a fit to the problems that you're asking the model to do. [[00:30:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1856.0s)]
*  Right. Like modeling the 2D projections of a dynamic 3D world is a function that probably can be modeled. [[00:30:59](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1859.0s)]
*  But by putting a 3D representation into the heart of a model, there's just going to be a better fit between the kind of representation that the model is working on and the kind of tasks that you want that model to do. [[00:31:05](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1865.0s)]
*  So our bet is that by threading a little bit more 3D representation under the hood, that'll enable better affordances for users. [[00:31:15](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1875.0s)]
*  And this also goes back to the North Star. For me, you know, why is it spatial intelligence? [[00:31:24](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1884.0s)]
*  Why is it not flat pixel intelligence? [[00:31:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1890.0s)]
*  It's because I think the arc of intelligence has to go to what Justin calls affordances. [[00:31:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1894.0s)]
*  And the arc of intelligence, if you look at evolution, right, the arc of intelligence eventually enables animals and humans, especially human as an intelligent animal, to move around the world, interact with it, create civilization, create life, create a piece of sandwich, whatever you do in this 3D world. [[00:31:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1901.0s)]
*  And translating that into a piece of technology that the native 3Dness is fundamentally important for the floodgate of possible applications, even if some of them, the serving of them looks 2D. [[00:32:05](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1925.0s)]
*  But it's innately 3D to me. [[00:32:27](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1947.0s)]
*  I think this is actually a very subtle and incredibly critical point. [[00:32:32](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1952.0s)]
*  And so I think it's worth digging into. [[00:32:36](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1956.0s)]
*  And a good way to do this is talking about use cases. [[00:32:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1957.0s)]
*  And so just to level set this, we're talking about generating a technology, let's call it a model that can do spatial intelligence. [[00:32:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1959.0s)]
*  So maybe in the abstract, what might that look like kind of a little bit more concretely? [[00:32:47](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1967.0s)]
*  What would be the potential use cases that you could apply this to? [[00:32:52](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1972.0s)]
*  So I think there's a couple different kinds of things. [[00:32:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1976.0s)]
*  We imagine these spatially intelligent models able to do over time. [[00:32:59](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1979.0s)]
*  And one that I'm really excited about is world generation. [[00:33:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1983.0s)]
*  We're all used to something like a text image generator or starting to see text to video generators where you put an image, put in a video and out pops an amazing image or an amazing two second clip. [[00:33:07](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1987.0s)]
*  But I think you could imagine leveling this up and getting 3D worlds out. [[00:33:17](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=1997.0s)]
*  So one thing that we could imagine spatial intelligence helping us with in the future are up leveling these experiences into 3D where we're not getting just an image out or just a clip out, but you're getting out a full simulated but vibrant and interactive 3D world. [[00:33:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2001.0s)]
*  For gaming? [[00:33:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2015.0s)]
*  Maybe for gaming, right? [[00:33:36](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2016.0s)]
*  Maybe for gaming, maybe for virtual photography, like you name it. [[00:33:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2017.0s)]
*  There's I think even if you got this to work, there'd be there'd be a million applications. [[00:33:40](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2020.0s)]
*  For education? [[00:33:44](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2024.0s)]
*  Yeah, for education. [[00:33:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2025.0s)]
*  I mean, I guess one of one of my things is that like we in some sense this enables a new form of media, right? [[00:33:46](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2026.0s)]
*  Because we already have the ability to create virtual interactive worlds, but it costs hundreds and hundreds of millions of dollars and a ton of development time. [[00:33:52](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2032.0s)]
*  And as a result, like what are the places that people drive this technological ability is video games, right? [[00:34:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2043.0s)]
*  Because if we do have the ability as a society to create amazingly detailed virtual interactive worlds that give you amazing experiences, but because it takes so much labor to do so, then the only economically viable use of that technology in its form today is games that can be sold for $70 apiece to millions and millions of people to recoup the investment. [[00:34:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2050.0s)]
*  If we had the ability to create these same virtual interactive, vibrant 3D worlds, you could see a lot of other applications of this, right? [[00:34:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2070.0s)]
*  Because if you bring down that cost of producing that kind of content, then people are going to use it for other things. [[00:34:40](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2080.0s)]
*  What if you could have an indirect, like sort of a personalized experience, 3D experience that's as good and as rich as detailed as one of these AAA video games that cost hundreds of millions of dollars to produce. [[00:34:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2085.0s)]
*  But it could be catered to like this very niche thing that only maybe a couple people would want that particular thing. [[00:34:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2095.0s)]
*  That's not a particular product or a particular roadmap, but I think that's a vision of a new kind of media that would be enabled by spatial intelligence in the generative realms. [[00:35:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2101.0s)]
*  If I think about a world, I actually think about things that are not just scene generation. [[00:35:11](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2111.0s)]
*  I think about stuff like movement and physics. And so like, like in the limit is that included? [[00:35:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2114.0s)]
*  And then the second one is if I'm interacting with it, like, like, are there semantics? [[00:35:18](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2118.0s)]
*  And I mean, by that, like, if I open a book, are there like pages and are there words in it? [[00:35:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2125.0s)]
*  And do they mean like, are we talking like a full depth experiment or are we talking about like kind of a static scene? [[00:35:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2129.0s)]
*  I think I'll see a progression of this technology over time. This is really hard stuff to build. [[00:35:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2134.0s)]
*  So I think the static, the static problem is a little bit easier. [[00:35:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2138.0s)]
*  But in the limit, I think we want this to be fully dynamic, fully interactable, all the things that you just said. [[00:35:42](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2142.0s)]
*  I mean, that's a definition of spatial intelligence. Yeah. [[00:35:47](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2147.0s)]
*  So so there is going to be a progression. We'll start with more static. [[00:35:50](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2150.0s)]
*  But everything you've said is is in the in the roadmap of spatial intelligence. [[00:35:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2155.0s)]
*  I mean, this is kind of in the name of the company itself. World Labs. [[00:36:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2161.0s)]
*  Like the world is about building and understanding worlds. [[00:36:05](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2165.0s)]
*  And like this is actually a little bit inside baseball. I realized after we told the name to people, they don't always get it. [[00:36:08](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2168.0s)]
*  Because in computer vision and reconstruction and generation, we often make a distinction or a delineation about the kinds of things you can do. [[00:36:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2172.0s)]
*  And kind of the first level is objects, right? Like a microphone, a cup, a chair. [[00:36:18](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2178.0s)]
*  Like these are discrete things in the world. [[00:36:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2183.0s)]
*  And a lot of the ImageNet style stuff that Feifei worked on was about recognizing objects in the world. [[00:36:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2185.0s)]
*  Then leveling up the next level of objects, I think of the scenes like scenes are compositions of objects. [[00:36:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2190.0s)]
*  Like now we've got this recording studio with a table and microphones and people in chairs at some composition of objects. [[00:36:36](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2196.0s)]
*  But then like we envision worlds as a step beyond scenes, right? [[00:36:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2201.0s)]
*  Like scenes are kind of maybe individual things, but we want to break the boundaries, go outside the door, like step up from the table, walk out from the door, walk down the street and see the cars buzzing past and see like the leaves on the trees moving and be able to interact with those things. [[00:36:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2205.0s)]
*  Another thing that's really exciting is just to mention the word new media. [[00:37:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2220.0s)]
*  With this technology, the boundary between real world and virtual, imagined world or augmented world or predicted world is all blurry. [[00:37:04](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2224.0s)]
*  You really, the real world is 3D, right? [[00:37:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2234.0s)]
*  So in the digital world, you have to have a 3D representation to even blend with the real world. [[00:37:19](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2239.0s)]
*  You know, you cannot have a 2D, you cannot have a 1D to be able to interface with the real 3D world in an effective way. [[00:37:27](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2247.0s)]
*  With this, it unlocks it. [[00:37:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2254.0s)]
*  So the use cases can be quite limitless because of this. [[00:37:36](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2256.0s)]
*  Right. So the first use case that Justin was talking about would be like the generation of a virtual world for any number of use cases. [[00:37:42](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2262.0s)]
*  One that you're just alluding to would be more of an augmented reality, right? [[00:37:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2269.0s)]
*  Yes, just around the time WorldLab was being formed, Vision Pro was released by Apple and they use the word spatial computing. [[00:37:52](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2272.0s)]
*  We're almost like they almost stole our name. [[00:38:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2283.0s)]
*  But we're spatial intelligence. [[00:38:06](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2286.0s)]
*  Spatial computing needs spatial intelligence. [[00:38:08](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2288.0s)]
*  That's exactly right. [[00:38:11](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2291.0s)]
*  So we don't know what hardware form it will take. [[00:38:13](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2293.0s)]
*  It'll be goggles, glasses, contact lenses. [[00:38:17](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2297.0s)]
*  But that interface between the true real world and what you can do on top of it, whether it's to help you to augment your capability to work on a piece of machine and fix your car, [[00:38:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2301.0s)]
*  even if you are not a trained mechanic or to just be in Pokemon Go, a plus plus for entertainment. [[00:38:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2314.0s)]
*  Suddenly, this piece of technology is going to be the operating system basically for AR VR mix R. [[00:38:43](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2323.0s)]
*  In the limit, like what does an AR device need to do? [[00:38:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2334.0s)]
*  It's this thing that's always on. It's with you. [[00:38:57](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2337.0s)]
*  It's looking out into the world. [[00:38:59](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2339.0s)]
*  So it needs to understand the stuff that you're seeing and maybe help you out with tasks in your daily life. [[00:39:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2340.0s)]
*  But I'm also really excited about this blend between virtual and physical that becomes really critical. [[00:39:05](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2345.0s)]
*  If you have the ability to understand what's around you in real time in perfect 3D, then it actually starts to deprecate large parts of the real world as well. [[00:39:11](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2351.0s)]
*  Like right now, how many differently sized screens do we all own for different use cases? [[00:39:18](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2358.0s)]
*  Too many. [[00:39:22](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2362.0s)]
*  You've got your phone, you've got your iPad, you've got your computer monitor, you've got your TV. [[00:39:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2363.0s)]
*  Your watch. [[00:39:27](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2367.0s)]
*  You've got your watch. [[00:39:28](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2368.0s)]
*  These are all basically different sized screens because they need to present information to you in different contexts and in different positions. [[00:39:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2369.0s)]
*  But if you've got the ability to seamlessly blend virtual content with the physical world, it kind of deprecates the need for all of those. [[00:39:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2375.0s)]
*  It just ideally seamlessly blends information that you need to know in the moment with the right mechanism of giving you that information. [[00:39:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2381.0s)]
*  Another huge case of being able to blend the digital virtual world with the 3D physical world is for alien agents to be able to do things in the physical world. [[00:39:48](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2388.0s)]
*  And if humans use this mix of devices to do things, like I said, I don't know how to fix a car, but if I have to, I put on this this goggle or glass and suddenly I'm guided to do that. [[00:40:02](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2402.0s)]
*  But there are other types of agents, namely robots, any kind of robots, not just humanoid. [[00:40:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2414.0s)]
*  And their interface, by definition, is the 3D world. [[00:40:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2421.0s)]
*  But their compute, their brain, by definition, is the digital world. [[00:40:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2426.0s)]
*  So what connects that from the learning to behaving between a robot brain to the real world brain? [[00:40:31](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2431.0s)]
*  It has to be spatially intelligent. [[00:40:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2439.0s)]
*  So you've talked about virtual worlds, you've talked about kind of more of an augmented reality, and now you've just talked about the purely physical world, basically, which would be used for robotics. [[00:40:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2441.0s)]
*  For any company, that would be like a very large charter, especially if you're going to get into each one of these different areas. [[00:40:52](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2452.0s)]
*  So how do you think about the idea of like deep, deep tech versus any of these specific application areas? [[00:40:59](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2459.0s)]
*  We see ourselves as a deep tech company, as the platform company that provides models that can serve different use cases. [[00:41:04](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2464.0s)]
*  Of these three, is there any one that you think is kind of more natural early on that people can kind of expect the company to lean into? [[00:41:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2474.0s)]
*  I think it suffices to say that devices are not totally ready. [[00:41:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2481.0s)]
*  Actually, I got my first VR headset in grad school. [[00:41:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2486.0s)]
*  And just like that's one of these transformative technology experiences. [[00:41:28](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2488.0s)]
*  You put it on, you're like, oh my God, like this is crazy. [[00:41:31](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2491.0s)]
*  And I think a lot of people have that experience the first time they use VR. [[00:41:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2494.0s)]
*  So I've been excited about this space for a long time. [[00:41:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2497.0s)]
*  And I love the Vision Pro. [[00:41:39](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2499.0s)]
*  Like I stayed up late to order one of the first ones, like the first day it came out. [[00:41:41](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2501.0s)]
*  But I think the reality is, it's just not there yet as a platform for mass market appeal. [[00:41:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2505.0s)]
*  So very likely as a company, we'll move into a market that's more ready than... [[00:41:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2509.0s)]
*  I think there can sometimes be simplicity and generality. [[00:41:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2515.0s)]
*  We have this notion of being a deep tech company. [[00:41:58](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2518.0s)]
*  We believe that there is some underlying fundamental problems that need to be solved really well. [[00:42:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2521.0s)]
*  And if solved really well, can apply to a lot of different domains. [[00:42:07](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2527.0s)]
*  We really view this long arc of the company as building and realizing the dreams of spatial intelligence writ large. [[00:42:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2530.0s)]
*  So this is a lot of technologies to build, it seems to me. [[00:42:16](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2536.0s)]
*  Yeah, I think it's a really hard problem. [[00:42:19](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2539.0s)]
*  I think sometimes from people who are not directly in the AI space, they just see it as like AI as one undifferentiated mass of talent. [[00:42:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2541.0s)]
*  And for those of us who have been here for longer, you realize that there's a lot of different kinds of talent [[00:42:28](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2548.0s)]
*  that need to come together to build anything in AI, in particular this one. [[00:42:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2555.0s)]
*  We talked a little bit about the data problem. [[00:42:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2558.0s)]
*  We've talked a little bit about some of the algorithms that I worked on during my PhD. [[00:42:40](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2560.0s)]
*  But there's a lot of other stuff we need to do this too. [[00:42:44](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2564.0s)]
*  You need really high quality, large scale engineering. [[00:42:46](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2566.0s)]
*  You need really deep understanding of the 3D world. [[00:42:49](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2569.0s)]
*  There's actually a lot of connections with computer graphics because they've been kind of attacking a lot of the same problems from the opposite direction. [[00:42:52](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2572.0s)]
*  So when we think about team construction, we think about how do we find expert, like absolute top of the world, [[00:42:59](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2579.0s)]
*  best experts in the world at each of these different subdomains that are necessary to build this really hard thing? [[00:43:05](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2585.0s)]
*  When I thought about how we formed the best funding team for World Labs, [[00:43:11](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2591.0s)]
*  it has to start with a group of phenomenal multidisciplinary founders. [[00:43:16](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2596.0s)]
*  And of course, Justin is natural for me. [[00:43:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2603.0s)]
*  He just covered your years as one of my best students and one of the smartest technologists. [[00:43:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2606.0s)]
*  But there are two other people I have known by reputation and one of them Justin even worked with that I was drooling for. [[00:43:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2615.0s)]
*  One is Ben Mildenhall. [[00:43:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2625.0s)]
*  We talked about his seminal work in NERV. [[00:43:47](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2627.0s)]
*  But another person is Christoph Lassner, who has been reputed in the community of computer graphics. [[00:43:51](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2631.0s)]
*  And especially he had the foresight of working on a precursor of the Gaussian splat representation for 3D modeling five years [[00:43:59](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2639.0s)]
*  right before the Gaussian splat takeoff. [[00:44:09](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2649.0s)]
*  And when we heard about when we talk about the potential possibility of working with Christoph Lassner, [[00:44:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2654.0s)]
*  Justin just jumped off his chair. [[00:44:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2661.0s)]
*  Ben and Christoph are legends. [[00:44:23](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2663.0s)]
*  Maybe just quickly talk about how you thought about the build out of the rest of the team. [[00:44:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2666.0s)]
*  Because again, there's a lot to build here and a lot to work on, not just in AI or graphics, but systems and so forth. [[00:44:30](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2670.0s)]
*  Yeah, this is what so far I'm personally most proud of is the formidable team. [[00:44:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2677.0s)]
*  I've had the privilege of working with the smartest young people in my entire career, right? [[00:44:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2685.0s)]
*  From the top universities, being a professor at Stanford. [[00:44:50](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2690.0s)]
*  But the kind of talent that we put together here at at World Labs is just phenomenal. [[00:44:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2694.0s)]
*  I've never seen the concentration. [[00:45:01](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2701.0s)]
*  And I think the biggest differentiating element here is that we're believers of spatial intelligence. [[00:45:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2703.0s)]
*  All of the multidisciplinary talents, whether it's system engineering, machine machine learning, [[00:45:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2712.0s)]
*  machine learning, infra to, you know, generated modeling to data to graphics. [[00:45:18](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2718.0s)]
*  All of us, whether it's our personal research journey or technology journey or even personal hobby, [[00:45:26](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2726.0s)]
*  we believe that spatial intelligence has to happen at this moment with this group of people. [[00:45:33](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2733.0s)]
*  And that's how we really found our founding team. [[00:45:40](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2740.0s)]
*  And that focus of energy and talent is is is really just humbling to me. [[00:45:43](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2743.0s)]
*  I just love it. [[00:45:52](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2752.0s)]
*  So I know you've been guided by a North Star. [[00:45:54](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2754.0s)]
*  So something about North Stars is like you can't actually reach them because they're in the sky. [[00:45:56](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2756.0s)]
*  But it's a great way to have guidance. [[00:46:02](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2762.0s)]
*  So how will you know when you've accomplished what you've set out to accomplish? [[00:46:03](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2763.0s)]
*  Or is this a lifelong thing that's going to continue kind of infinitely? [[00:46:07](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2767.0s)]
*  First of all, there's real North Stars and virtual North Stars. [[00:46:12](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2772.0s)]
*  Sometimes you can reach virtual North Star in the world, in the world model. [[00:46:16](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2776.0s)]
*  Exactly. Like I said, I thought one of my North Star that would take a hundred years [[00:46:21](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2781.0s)]
*  was storytelling of images and Justin and Andre, you know, in my opinion, solved it for me. [[00:46:27](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2787.0s)]
*  So so we could get to our North Star. [[00:46:34](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2794.0s)]
*  But I think for me is when so many people and so many businesses are using our models [[00:46:37](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2797.0s)]
*  to unlock their needs for spatial intelligence. [[00:46:44](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2804.0s)]
*  And that's the moment I know we have reached a major milestone. [[00:46:48](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2808.0s)]
*  Actual deployment, actual impact. [[00:46:53](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2813.0s)]
*  Yeah, I don't think we're ever going to get there. [[00:46:55](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2815.0s)]
*  I think that this is such a fundamental thing. [[00:46:57](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2817.0s)]
*  Like the universe is a giant evolving four dimensional structure and spatial intelligence [[00:47:00](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2820.0s)]
*  writ large is just understanding that in all of its depths and figuring out all the applications to that. [[00:47:05](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2825.0s)]
*  So I think we have a we have a particular set of ideas in mind today. [[00:47:10](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2830.0s)]
*  But I think this I think this journey is going to take us places that we can't even imagine right now. [[00:47:14](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2834.0s)]
*  The magic of good technology is that technology opens up more possibilities and unknowns. [[00:47:18](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2838.0s)]
*  So we will be pushing and then the possibilities will be expanding. [[00:47:25](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2845.0s)]
*  Brilliant. Thank you, Justin. Thank you. [[00:47:29](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2849.0s)]
*  This is fantastic. Thank you. [[00:47:31](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2851.0s)]
*  Thank you, Martin. Thank you, Martin. [[00:47:33](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2853.0s)]
*  Thank you so much for listening to the A16Z podcast. [[00:47:35](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2855.0s)]
*  If you've made it this far, don't forget to subscribe so that you are the first to get our exclusive video content. [[00:47:38](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2858.0s)]
*  Or you can check out this video that we've hand selected for you. [[00:47:45](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2865.0s)]
*  Thank you. [[00:47:59](https://www.youtube.com/watch?v=vIXfYFB7aBI&t=2879.0s)]
