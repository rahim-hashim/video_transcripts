---
Date Generated: May 24, 2025
Transcription Model: whisper medium 20231117
Length: 526s
Video Keywords: []
Video Views: 2443
Video Rating: None
Video Description: Beyang Liu, Co-founder and CTO at Sourcegraph, explains the challenges of large language models and delves into the realm of code-building tools for the evolving landscape of AI integration.

Topics Covered:
00:00 - Introduction
00:43 - Large language models and hallucinations
01:43 - Providing context to models
03:26 - Models, security, and privacy
05:22 - Cost of models and pricing schemes 
06:27 - The Bing price update

Resources:
* Find Beyang Liu on Twitter: https://twitter.com/beyang
* Learn more about Sourcegraph: https://sourcegraph.com/

Stay Updated: 
Find a16z on Twitter: https://twitter.com/a16z 
Find a16z on LinkedIn: https://www.linkedin.com/company/a16z 
Subscribe on your favorite podcast app: https://a16z.simplecast.com/ 
Follow our host: https://twitter.com/stephsmithio 

Please note that the content here is for informational purposes only; should NOT be taken as legal, business, tax, or investment advice or be used to evaluate any investment or security; and is not directed at any investors or potential investors in any a16z fund. a16z and its affiliates may maintain investments in the companies discussed. For more details please see a16z.com/disclosures.
---

# The Secret to Building AI-Powered Tools
**The a16z Podcast:** [May 18, 2023](https://www.youtube.com/watch?v=TZm2bow1ytI)
*  2022 was a breakout year for AI. [[00:00:00](https://www.youtube.com/watch?v=TZm2bow1ytI&t=0.0s)]
*  In fact, many have even claimed that ChatGBT is the fastest growing app of all time. [[00:00:04](https://www.youtube.com/watch?v=TZm2bow1ytI&t=4.48s)]
*  So with so much opportunity on the table, AI is the topic of conversation in every boardroom, as CEOs figure out how to best integrate this new superpower. [[00:00:10](https://www.youtube.com/watch?v=TZm2bow1ytI&t=10.96s)]
*  But they're also asking really important questions around data privacy, competition, cost, accuracy, and also doing this all really quickly. [[00:00:19](https://www.youtube.com/watch?v=TZm2bow1ytI&t=19.56s)]
*  Because just like your customers really don't care if your product is built with Angular or React or runs on AWS or Heroku, there will be a whole host of ways that companies differentiate as they look to cleverly embed AI. [[00:00:28](https://www.youtube.com/watch?v=TZm2bow1ytI&t=28.28s)]
*  And here is how Sourcegraph is thinking about that. [[00:00:41](https://www.youtube.com/watch?v=TZm2bow1ytI&t=41.24s)]
*  Sourcegraph today, it's this kind of like general purpose source code understanding engine. [[00:00:43](https://www.youtube.com/watch?v=TZm2bow1ytI&t=43.8s)]
*  As a reminder, the content here is for informational purposes only, should not be taken as legal business tax or investment advice, or be used to evaluate any investment or security, and is not directed at any investors or potential investors in any A16Z fund. [[00:00:48](https://www.youtube.com/watch?v=TZm2bow1ytI&t=48.36s)]
*  For more details, please see A16Z.com slash disclosures. [[00:01:02](https://www.youtube.com/watch?v=TZm2bow1ytI&t=62.68s)]
*  So our first kind of major push, I would say, is this editor extension called Codi. [[00:01:06](https://www.youtube.com/watch?v=TZm2bow1ytI&t=66.44000000000001s)]
*  And essentially, what it does is it's a chat-based interface, but also allows you to search for stuff in context in the code. [[00:01:11](https://www.youtube.com/watch?v=TZm2bow1ytI&t=71.56s)]
*  And the idea is that we wanted something in our editors that took full advantage of the power of language models, but also kind of addressed a lot of the challenges that people have encountered with large language models. [[00:01:20](https://www.youtube.com/watch?v=TZm2bow1ytI&t=80.16000000000001s)]
*  Namely, the tendency to hallucinate facts when they don't really know the answer. [[00:01:34](https://www.youtube.com/watch?v=TZm2bow1ytI&t=94.0s)]
*  And so that's a place where we thought we could be uniquely positioned to help, because Sourcegraph, with all the pieces of context that we have around searching for code and finding references and verifying things actually exist, we are kind of like the perfect fact checker, if you will, for the language model and perfect relevant context provider to the language model. [[00:01:39](https://www.youtube.com/watch?v=TZm2bow1ytI&t=99.19999999999999s)]
*  Let's double click on that, because there are other tools that help you build code using these language models. [[00:02:01](https://www.youtube.com/watch?v=TZm2bow1ytI&t=121.24s)]
*  We'll just throw out a couple. [[00:02:07](https://www.youtube.com/watch?v=TZm2bow1ytI&t=127.72s)]
*  Like a lot of people are familiar with GitHub Copilot. [[00:02:08](https://www.youtube.com/watch?v=TZm2bow1ytI&t=128.64s)]
*  A lot of people are familiar with what Replet is doing with Ghostwriter. [[00:02:11](https://www.youtube.com/watch?v=TZm2bow1ytI&t=131.56s)]
*  But maybe you could actually speak to this idea of fetching the right information. [[00:02:15](https://www.youtube.com/watch?v=TZm2bow1ytI&t=135.52s)]
*  Like, how would something like a Copilot do that? [[00:02:20](https://www.youtube.com/watch?v=TZm2bow1ytI&t=140.32s)]
*  Currently, they don't do Q&A. [[00:02:23](https://www.youtube.com/watch?v=TZm2bow1ytI&t=143.12s)]
*  It's purely kind of like autocomplete driven. [[00:02:24](https://www.youtube.com/watch?v=TZm2bow1ytI&t=144.44s)]
*  And the context that they fetch to do that autocompletion is kind of like recent files that you've opened in your editor. [[00:02:26](https://www.youtube.com/watch?v=TZm2bow1ytI&t=146.88s)]
*  So it's kind of like this very local context, which works amazingly well. [[00:02:32](https://www.youtube.com/watch?v=TZm2bow1ytI&t=152.92000000000002s)]
*  I mean, like huge credit to that team. [[00:02:36](https://www.youtube.com/watch?v=TZm2bow1ytI&t=156.04s)]
*  They've built an awesome user experience. [[00:02:37](https://www.youtube.com/watch?v=TZm2bow1ytI&t=157.44s)]
*  We think that the next evolution of that is providing more relevant context and essentially emulating what a human kind of does when you're trying to write code. [[00:02:39](https://www.youtube.com/watch?v=TZm2bow1ytI&t=159.8s)]
*  Like you as a human, you might go back through some recent history in your editor and see, like, OK, how does that code work? [[00:02:49](https://www.youtube.com/watch?v=TZm2bow1ytI&t=169.2s)]
*  How did that code work? [[00:02:56](https://www.youtube.com/watch?v=TZm2bow1ytI&t=176.07999999999998s)]
*  And use that as like a pattern matching reference point for the thing that you're currently writing. [[00:02:56](https://www.youtube.com/watch?v=TZm2bow1ytI&t=176.76s)]
*  But more often than not, I think you're doing stuff like, you know, go to definition, find references. [[00:03:00](https://www.youtube.com/watch?v=TZm2bow1ytI&t=180.88s)]
*  You know, let me see a couple of examples of how to use this particular API that I just imported. [[00:03:05](https://www.youtube.com/watch?v=TZm2bow1ytI&t=185.12s)]
*  And I think that that's going to lead to much better results. [[00:03:10](https://www.youtube.com/watch?v=TZm2bow1ytI&t=190.72s)]
*  I think it's also going to lead to much more kind of introspectable results. [[00:03:14](https://www.youtube.com/watch?v=TZm2bow1ytI&t=194.39999999999998s)]
*  So getting beyond this like, oh, elements are magic. [[00:03:18](https://www.youtube.com/watch?v=TZm2bow1ytI&t=198.64s)]
*  How do they work? Is it AGI? [[00:03:20](https://www.youtube.com/watch?v=TZm2bow1ytI&t=200.88s)]
*  You know what? [[00:03:22](https://www.youtube.com/watch?v=TZm2bow1ytI&t=202.16s)]
*  Not it's like Cody will actually tell you like, hey, I read these files and these are the files I'm using to generate an answer. [[00:03:22](https://www.youtube.com/watch?v=TZm2bow1ytI&t=202.56s)]
*  And if it completely returns a lie or is wrong, you can usually tell by looking at the context that it read. [[00:03:28](https://www.youtube.com/watch?v=TZm2bow1ytI&t=208.48s)]
*  Like, oh, like that. [[00:03:35](https://www.youtube.com/watch?v=TZm2bow1ytI&t=215.64s)]
*  Why are you reading that file, Cody? [[00:03:36](https://www.youtube.com/watch?v=TZm2bow1ytI&t=216.32s)]
*  That's dumb. [[00:03:37](https://www.youtube.com/watch?v=TZm2bow1ytI&t=217.95999999999998s)]
*  And you can like thumbs down that and we'll take that as like a reference point to improve the product later. [[00:03:38](https://www.youtube.com/watch?v=TZm2bow1ytI&t=218.44s)]
*  A lot of these companies that are integrating AI are building off of just a few models, right? [[00:03:44](https://www.youtube.com/watch?v=TZm2bow1ytI&t=224.52s)]
*  A lot of people are familiar with OpenAI's API that came out recently. [[00:03:49](https://www.youtube.com/watch?v=TZm2bow1ytI&t=229.8s)]
*  But there's also that very interesting dynamic that a lot of the same companies that may even consider themselves competitors are using similar models. [[00:03:53](https://www.youtube.com/watch?v=TZm2bow1ytI&t=233.96s)]
*  And so how did you think about that? [[00:04:03](https://www.youtube.com/watch?v=TZm2bow1ytI&t=243.24s)]
*  And also, there's this kind of layered question as it relates to security and privacy, because depending on the company that you are, your code is actually [[00:04:05](https://www.youtube.com/watch?v=TZm2bow1ytI&t=245.24s)]
*  potentially somewhat all the way to extremely proprietary, right? [[00:04:13](https://www.youtube.com/watch?v=TZm2bow1ytI&t=253.8s)]
*  If you're talking about like a self-driving car company. [[00:04:18](https://www.youtube.com/watch?v=TZm2bow1ytI&t=258.04s)]
*  It's especially pertinent to us because we have a lot of, you know, enterprise customers that are very security and privacy sensitive to the point where, you know, [[00:04:20](https://www.youtube.com/watch?v=TZm2bow1ytI&t=260.2s)]
*  one of the reasons we made it self-hostable is because we wanted to enable companies that didn't want to put their code bases in the cloud to still have like awesome code understanding. [[00:04:29](https://www.youtube.com/watch?v=TZm2bow1ytI&t=269.72s)]
*  And so the space is kind of like fast evolving. [[00:04:41](https://www.youtube.com/watch?v=TZm2bow1ytI&t=281.47999999999996s)]
*  And our mentality is like, look, we have a wide range of customers from like very conservative, large enterprises to like fast moving startups that have different risk and security profiles. [[00:04:45](https://www.youtube.com/watch?v=TZm2bow1ytI&t=285.0s)]
*  The language model in our overall architecture is just one component. [[00:04:55](https://www.youtube.com/watch?v=TZm2bow1ytI&t=295.56s)]
*  And so we want to make it possible to kind of like bring your own language model to the table. [[00:05:00](https://www.youtube.com/watch?v=TZm2bow1ytI&t=300.67999999999995s)]
*  So you're basically saying that you give them the selection or the option. [[00:05:05](https://www.youtube.com/watch?v=TZm2bow1ytI&t=305.47999999999996s)]
*  Am I understanding that correctly? [[00:05:09](https://www.youtube.com/watch?v=TZm2bow1ytI&t=309.15999999999997s)]
*  We'll give you the option. [[00:05:10](https://www.youtube.com/watch?v=TZm2bow1ytI&t=310.68s)]
*  So right now you can use Claude, which is Anthropix flagship model. [[00:05:12](https://www.youtube.com/watch?v=TZm2bow1ytI&t=312.03999999999996s)]
*  You can use Chatjibute, which is kind of the open AI model. [[00:05:17](https://www.youtube.com/watch?v=TZm2bow1ytI&t=317.47999999999996s)]
*  And we're looking to integrate additional models too. [[00:05:21](https://www.youtube.com/watch?v=TZm2bow1ytI&t=321.88s)]
*  And there's also kind of like different models that we plug in in different pieces of code. [[00:05:24](https://www.youtube.com/watch?v=TZm2bow1ytI&t=324.35999999999996s)]
*  Right. [[00:05:28](https://www.youtube.com/watch?v=TZm2bow1ytI&t=328.44s)]
*  So there's kind of like the chat based models, which are often like the largest ones. [[00:05:28](https://www.youtube.com/watch?v=TZm2bow1ytI&t=328.59999999999997s)]
*  But there's also things like the embeddings model. [[00:05:32](https://www.youtube.com/watch?v=TZm2bow1ytI&t=332.52s)]
*  But I think our mentality is just like the language model aspect of this. [[00:05:35](https://www.youtube.com/watch?v=TZm2bow1ytI&t=335.16s)]
*  We want to make as kind of like pluggable as possible. [[00:05:38](https://www.youtube.com/watch?v=TZm2bow1ytI&t=338.52000000000004s)]
*  That's amazing because something that that also relates to is cost. [[00:05:41](https://www.youtube.com/watch?v=TZm2bow1ytI&t=341.08000000000004s)]
*  Right. [[00:05:44](https://www.youtube.com/watch?v=TZm2bow1ytI&t=344.52000000000004s)]
*  Like each of these different models has a different cost. [[00:05:44](https://www.youtube.com/watch?v=TZm2bow1ytI&t=344.68s)]
*  I think a couple of weeks ago being like 5X their pricing overnight. [[00:05:47](https://www.youtube.com/watch?v=TZm2bow1ytI&t=347.24s)]
*  Right. [[00:05:51](https://www.youtube.com/watch?v=TZm2bow1ytI&t=351.40000000000003s)]
*  Like you have a dependency as well, both source graph, but also like that ends up filtering down to your customers. [[00:05:51](https://www.youtube.com/watch?v=TZm2bow1ytI&t=351.64000000000004s)]
*  And so every one of these models, I mean, I think we're still in the early innings and there's going to be so many more developed. [[00:05:58](https://www.youtube.com/watch?v=TZm2bow1ytI&t=358.92s)]
*  And each one will, to your point, it'll have a different security posture. [[00:06:04](https://www.youtube.com/watch?v=TZm2bow1ytI&t=364.36s)]
*  It'll have different pricing scheme. [[00:06:07](https://www.youtube.com/watch?v=TZm2bow1ytI&t=367.40000000000003s)]
*  It'll probably, you know, there'll be a range in terms of its efficacy or specialty. [[00:06:09](https://www.youtube.com/watch?v=TZm2bow1ytI&t=369.24s)]
*  Yeah. [[00:06:13](https://www.youtube.com/watch?v=TZm2bow1ytI&t=373.72s)]
*  You know, it never dawned on me that actually, you know, you could offer the access across the board to all these models, but also kind of relay the transparent pros and cons to the customer base. [[00:06:14](https://www.youtube.com/watch?v=TZm2bow1ytI&t=374.68s)]
*  That's exactly how we're thinking about it. [[00:06:27](https://www.youtube.com/watch?v=TZm2bow1ytI&t=387.32s)]
*  For us, it's kind of like there's so much innovation happening in that space. [[00:06:29](https://www.youtube.com/watch?v=TZm2bow1ytI&t=389.16s)]
*  We don't want to be kind of tied to any one provider. [[00:06:32](https://www.youtube.com/watch?v=TZm2bow1ytI&t=392.52s)]
*  And so I think a lot of the value that we can provide is really about combining the language model with the pieces of context and the structured understanding of code that we have. [[00:06:36](https://www.youtube.com/watch?v=TZm2bow1ytI&t=396.28s)]
*  And it's funny that you mentioned the kind of being price hike. [[00:06:45](https://www.youtube.com/watch?v=TZm2bow1ytI&t=405.47999999999996s)]
*  I thought that was like a big proof point and people notice when chat GPT first came out, I think a lot of people said like, hey, you know, this kind of replaces search engines. [[00:06:48](https://www.youtube.com/watch?v=TZm2bow1ytI&t=408.76s)]
*  Right. [[00:06:58](https://www.youtube.com/watch?v=TZm2bow1ytI&t=418.59999999999997s)]
*  Like I could just chat with this thing and it was tell me the answer instead of me having to go and like click through a bunch of different results and figure out the answer myself. [[00:06:58](https://www.youtube.com/watch?v=TZm2bow1ytI&t=418.76s)]
*  But then as people started to use language models a bit more, they started to run into more hallucinations. [[00:07:07](https://www.youtube.com/watch?v=TZm2bow1ytI&t=427.32s)]
*  And I think it was like the release of Bing where people finally realized like, like being released, they integrated chat GPT or GPT4, you know, one of those like awesome, like open AI models in. [[00:07:12](https://www.youtube.com/watch?v=TZm2bow1ytI&t=432.84s)]
*  But they didn't just like ship a white label chat GPT. [[00:07:25](https://www.youtube.com/watch?v=TZm2bow1ytI&t=445.0s)]
*  They combined that with Bing search on the back end. [[00:07:28](https://www.youtube.com/watch?v=TZm2bow1ytI&t=448.12s)]
*  And I think combining kind of the language model as sort of like the reasoning engine, but you still need kind of like an informational retrieval engine to make that truly powerful. [[00:07:30](https://www.youtube.com/watch?v=TZm2bow1ytI&t=450.68s)]
*  And the unison that that really is valuable. [[00:07:40](https://www.youtube.com/watch?v=TZm2bow1ytI&t=460.12s)]
*  And that's maybe I'm speculating here, but like that maybe had something to do with the Bing price hike. [[00:07:43](https://www.youtube.com/watch?v=TZm2bow1ytI&t=463.08s)]
*  Like it is not true that language models make search engines unnecessary. [[00:07:49](https://www.youtube.com/watch?v=TZm2bow1ytI&t=469.08s)]
*  If anything, they make the search engines more valuable because now all that data that you can search becomes like 10x more powerful because you can use that to get to get to your answer with like one tenth the effort or in one tenth of time. [[00:07:54](https://www.youtube.com/watch?v=TZm2bow1ytI&t=474.12s)]
*  If you like this segment, you're going to love our next video with Hex, a company that's thinking critically about UI and how to personalize their new AI features. [[00:08:06](https://www.youtube.com/watch?v=TZm2bow1ytI&t=486.92s)]
*  You're not going to want to miss this. [[00:08:15](https://www.youtube.com/watch?v=TZm2bow1ytI&t=495.96000000000004s)]
*  And if you like this topic, we go a lot deeper on the podcast, which you can find on Apple, Spotify or wherever you get your podcasts. [[00:08:17](https://www.youtube.com/watch?v=TZm2bow1ytI&t=497.4s)]
