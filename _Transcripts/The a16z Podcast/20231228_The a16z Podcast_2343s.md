---
Date Generated: May 23, 2025
Transcription Model: whisper medium 20231117
Length: 2343s
Video Keywords: []
Video Views: 7355
Video Rating: None
Video Description: Arthur Mensch, co-founder of Mistral and co-author of Deepmind's 2022 "Chinchilla" paper, recently released Mistral-7B, a popular open-source language model.

Their latest offering, Mixtral, a mixture of experts model, is attracting attention in the AI community. Join Arthur and a16z General Partner Anjney Midha in a discussion about the nuances of open source, the comparative performance of open and closed models, and the innovations needed for scaling large language models (LLMs) effectively.

Topics covered:
00:00 - Introduction to scaling laws and their impact
02:14  - Arthur Mensch and the Founding of Mistral
07:57 - Mistral 7b and the launch of Mixtral
13:27 - Misconceptions about open source, the state of open vs. closed models, and future requirements for scaling LLMs
18:41 - Open Source in AI: Scaling laws, Industry Impact, data efficiency, and new model architectures
22:56 - Safety concerns of open source models.
25:17 - Recommendations for policymakers in regulating AI technologies.
33:17 - Predictions on how advancements in LLMs will change user interactions with technology
36:36 - Potential applications in various fields like gaming and enterprise.
38:53 - Call to action for builders, researchers, and developers

Resources: 
Find Arthur on Twitter: https://twitter.com/arthurmensch
Find Anjney on Twitter: https://twitter.com/AnjneyMidha
Learn more about Mistral: https://mistral.ai

Stay Updated: 
Find a16z on Twitter: https://twitter.com/a16z 
Find a16z on LinkedIn: https://www.linkedin.com/company/a16z 
Subscribe on your favorite podcast app: https://a16z.simplecast.com/ 
Follow our host: https://twitter.com/stephsmithio 

Please note that the content here is for informational purposes only; should NOT be taken as legal, business, tax, or investment advice or be used to evaluate any investment or security; and is not directed at any investors or potential investors in any a16z fund. a16z and its affiliates may maintain investments in the companies discussed. For more details please see a16z.com/disclosures.
---

# Safety in Numbers: Keeping AI Open
**The a16z Podcast:** [December 28, 2023](https://www.youtube.com/watch?v=NhASk7rZsmU)
*  Scaling laws. Now these underpin the success of large language models today. [[00:00:00](https://www.youtube.com/watch?v=NhASk7rZsmU&t=0.0s)]
*  But the relationship between datasets, compute, and the number of parameters was not always clear. [[00:00:05](https://www.youtube.com/watch?v=NhASk7rZsmU&t=5.04s)]
*  In fact, in 2022, a pivotal paper came out that changed the way that many people in the research [[00:00:11](https://www.youtube.com/watch?v=NhASk7rZsmU&t=11.44s)]
*  community thought about this very calculus. And it demonstrated that datasets were actually more [[00:00:16](https://www.youtube.com/watch?v=NhASk7rZsmU&t=16.72s)]
*  important than just the sheer size of the model. One of the key authors of this paper was Arthur [[00:00:22](https://www.youtube.com/watch?v=NhASk7rZsmU&t=22.0s)]
*  who was working at DeepMind at the time. Now earlier this year, Arthur banded together with [[00:00:28](https://www.youtube.com/watch?v=NhASk7rZsmU&t=28.32s)]
*  two other researchers, Guillaume Lampel and Timothée Lacroix, two researchers at Meta who [[00:00:32](https://www.youtube.com/watch?v=NhASk7rZsmU&t=32.96s)]
*  worked on Llama. And together the three of them founded a new company, Mistral. That team has been [[00:00:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=38.72s)]
*  hard at work releasing Mistral 7b in September, a state-of-the-art open source model. That quickly [[00:00:44](https://www.youtube.com/watch?v=NhASk7rZsmU&t=44.56s)]
*  became the go-to for developers. And they just released, as in the last few days, a new mixture [[00:00:50](https://www.youtube.com/watch?v=NhASk7rZsmU&t=50.72s)]
*  of experts model that naturally they're calling Mistral. So today you'll get to hear directly from [[00:00:56](https://www.youtube.com/watch?v=NhASk7rZsmU&t=56.8s)]
*  Arthur as he sits down with A16Z general partner, Anjane Mida. As the battleground for large language [[00:01:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=62.48s)]
*  models heats up, to say the least, together they discuss the many misconceptions around open source [[00:01:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=68.72s)]
*  and the war being waged on the industry. Plus the current performance reality of open versus closed [[00:01:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=74.32s)]
*  models and whether that gap will realistically close with time. Plus the kind of compute, data, [[00:01:19](https://www.youtube.com/watch?v=NhASk7rZsmU&t=79.75999999999999s)]
*  and algorithmic innovations required to keep scaling LLMs efficiently. Now it's really rare [[00:01:25](https://www.youtube.com/watch?v=NhASk7rZsmU&t=85.76s)]
*  to have someone at the frontier of this kind of research be so candid about what they're building [[00:01:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=91.60000000000001s)]
*  and why. So I hope that you come out of this episode as excited about the future of open [[00:01:36](https://www.youtube.com/watch?v=NhASk7rZsmU&t=96.4s)]
*  source as I did. Enjoy. As a reminder, the content here is for informational purposes only. [[00:01:41](https://www.youtube.com/watch?v=NhASk7rZsmU&t=101.52000000000001s)]
*  Should not be taken as legal, business, tax, or investment advice, or be used to evaluate any [[00:01:48](https://www.youtube.com/watch?v=NhASk7rZsmU&t=108.48s)]
*  investment or security and is not directed at any investors or potential investors in any A16Z fund. [[00:01:53](https://www.youtube.com/watch?v=NhASk7rZsmU&t=113.12s)]
*  Please note that A16Z and its affiliates may also maintain investments in the companies discussed [[00:01:59](https://www.youtube.com/watch?v=NhASk7rZsmU&t=119.36s)]
*  in this podcast. For more details, including a link to our investments, please see [[00:02:04](https://www.youtube.com/watch?v=NhASk7rZsmU&t=124.56s)]
*  a16z.com slash disclosures. You've got quite the founding team story. You know, we flashback to a [[00:02:09](https://www.youtube.com/watch?v=NhASk7rZsmU&t=129.28s)]
*  few years ago. Labs are building foundation models and the consensus across the research [[00:02:18](https://www.youtube.com/watch?v=NhASk7rZsmU&t=138.64s)]
*  community was that the size of these models was what mattered most. You know, how many million or [[00:02:23](https://www.youtube.com/watch?v=NhASk7rZsmU&t=143.92s)]
*  billion parameters went into the model seemed to be the primary debate that people were having. [[00:02:29](https://www.youtube.com/watch?v=NhASk7rZsmU&t=149.92s)]
*  But it seems like you had a hunch that data sets mattered more. Could you just give us the backstory [[00:02:35](https://www.youtube.com/watch?v=NhASk7rZsmU&t=155.67999999999998s)]
*  on the chinchilla paper you core out? You know, what were the key takeaways in the paper and [[00:02:40](https://www.youtube.com/watch?v=NhASk7rZsmU&t=160.64s)]
*  how was it received? Yeah, so I guess the backstory is that in 2019, 2020, people were relying a lot on [[00:02:44](https://www.youtube.com/watch?v=NhASk7rZsmU&t=164.48s)]
*  the on a paper called Scaling Lows for Large Language Models. That was advocating for basically [[00:02:52](https://www.youtube.com/watch?v=NhASk7rZsmU&t=172.16s)]
*  scaling infinitely the size of models and keeping some number of data points rather fixed. So just [[00:02:58](https://www.youtube.com/watch?v=NhASk7rZsmU&t=178.88s)]
*  saying that if you had like four times the amount of compute, you should be mostly multiplying by 3.5 [[00:03:05](https://www.youtube.com/watch?v=NhASk7rZsmU&t=185.44s)]
*  your model size and then maybe by 1.2. And so a lot of work was actually done on top of that. So [[00:03:11](https://www.youtube.com/watch?v=NhASk7rZsmU&t=191.36s)]
*  in particular, DeepMind, when I joined, I joined a project called Gopher and that's a there was [[00:03:17](https://www.youtube.com/watch?v=NhASk7rZsmU&t=197.84s)]
*  a misconception there. There was also a misconception on GPT-3. And basically in 2021, every paper [[00:03:24](https://www.youtube.com/watch?v=NhASk7rZsmU&t=204.24s)]
*  made this mistake. And at the end of 2021, we started to realize there were some issues. [[00:03:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=211.36s)]
*  And as it turns out, we turned back to the mathematical paper that was actually [[00:03:37](https://www.youtube.com/watch?v=NhASk7rZsmU&t=217.52s)]
*  talking about scaling those and it was a bit hard to understand. And we figured out that actually, [[00:03:42](https://www.youtube.com/watch?v=NhASk7rZsmU&t=222.16s)]
*  if you thought about it a bit more in a theoretical perspective, and if we looked at [[00:03:47](https://www.youtube.com/watch?v=NhASk7rZsmU&t=227.44s)]
*  like empirical evidence we had, it didn't really make sense to actually grow the model size faster [[00:03:52](https://www.youtube.com/watch?v=NhASk7rZsmU&t=232.0s)]
*  than the data size. And we did some measurements. And as it turned out, what was actually true was [[00:03:58](https://www.youtube.com/watch?v=NhASk7rZsmU&t=238.88s)]
*  what we expect, which is in common words, if you multiply by four your compute capacity, [[00:04:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=246.32s)]
*  you should multiply by two the model size and by two the data size. That's approximately what you [[00:04:13](https://www.youtube.com/watch?v=NhASk7rZsmU&t=253.2s)]
*  should be doing, which is good because if you move everything to infinity, everything remains [[00:04:18](https://www.youtube.com/watch?v=NhASk7rZsmU&t=258.08s)]
*  consistent. So you don't have a model which is infinity big or a model which is infinity small [[00:04:22](https://www.youtube.com/watch?v=NhASk7rZsmU&t=262.15999999999997s)]
*  with infinite compression or close to zero compression. So it really makes sense. And as [[00:04:26](https://www.youtube.com/watch?v=NhASk7rZsmU&t=266.24s)]
*  it turns out, it's really what you observe if you do multiple runs. And so that's how we [[00:04:30](https://www.youtube.com/watch?v=NhASk7rZsmU&t=270.88s)]
*  train Chinchilla and that's how we wrote the Chinchilla paper. [[00:04:37](https://www.youtube.com/watch?v=NhASk7rZsmU&t=277.44s)]
*  At the time, you were at DeepMind and your co-founders were at Meta. What's the backstory [[00:04:40](https://www.youtube.com/watch?v=NhASk7rZsmU&t=280.71999999999997s)]
*  around how you three end up coming together to form Mistral after the compute optimal scaling [[00:04:46](https://www.youtube.com/watch?v=NhASk7rZsmU&t=286.64s)]
*  laws work that you just described? So we've known each other for a while because Guillaume [[00:04:52](https://www.youtube.com/watch?v=NhASk7rZsmU&t=292.24s)]
*  and I were in school together and Timothée and I were in master together in Paris. Basically, [[00:04:56](https://www.youtube.com/watch?v=NhASk7rZsmU&t=296.48s)]
*  we had very parallel careers. Timothée and I, we actually worked together as well again [[00:05:01](https://www.youtube.com/watch?v=NhASk7rZsmU&t=301.20000000000005s)]
*  when I was doing a postdoc in mathematics. And then I joined DeepMind as Guillaume and Timothée [[00:05:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=306.48s)]
*  went to become permanent researchers at Meta. And so we continued doing this. I was doing large [[00:05:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=314.16s)]
*  language models in between 2020 and 2023. Guillaume and Timothée were working on solving [[00:05:21](https://www.youtube.com/watch?v=NhASk7rZsmU&t=321.68s)]
*  mathematical problems with large models. And if I understand correctly, I wasn't there, but [[00:05:28](https://www.youtube.com/watch?v=NhASk7rZsmU&t=328.40000000000003s)]
*  they realized they had to have stronger models and they started to do large language models at [[00:05:35](https://www.youtube.com/watch?v=NhASk7rZsmU&t=335.68s)]
*  this point. So I guess a year after I started. And on my side, I was mostly working in a small team [[00:05:39](https://www.youtube.com/watch?v=NhASk7rZsmU&t=339.68s)]
*  at DeepMind. So we did very interesting work on Retro, which is a paper doing retrieval for [[00:05:47](https://www.youtube.com/watch?v=NhASk7rZsmU&t=347.44s)]
*  large language models. We did Chinchilla. Then I was in the team doing Flamingo, which is actually [[00:05:53](https://www.youtube.com/watch?v=NhASk7rZsmU&t=353.44s)]
*  one of the good ways of doing a model that can see things. I guess when Chaggivity went out, [[00:06:00](https://www.youtube.com/watch?v=NhASk7rZsmU&t=360.8s)]
*  we knew from before that the technology was very much game changing, but it was kind of a signal [[00:06:07](https://www.youtube.com/watch?v=NhASk7rZsmU&t=367.76s)]
*  that there was a strong opportunity for building a small team, focusing on a different way of [[00:06:13](https://www.youtube.com/watch?v=NhASk7rZsmU&t=373.12s)]
*  distributing the technology. So we're doing things in a more open source manner, which was not the [[00:06:19](https://www.youtube.com/watch?v=NhASk7rZsmU&t=379.12s)]
*  direction that Google at least was taking. And so we had this opportunity and we left the company [[00:06:24](https://www.youtube.com/watch?v=NhASk7rZsmU&t=384.4s)]
*  at the beginning of last year and created the team that started to work on the 5th of June. [[00:06:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=391.68s)]
*  And if I recall correctly, right before they left, Tim and Guillaume had started to work on Lama [[00:06:37](https://www.youtube.com/watch?v=NhASk7rZsmU&t=397.68s)]
*  right over at Meta. Could you describe that project and how it was related to the Chinchilla [[00:06:44](https://www.youtube.com/watch?v=NhASk7rZsmU&t=404.64s)]
*  scaling laws work you'd done? So Lama was like a small team, [[00:06:49](https://www.youtube.com/watch?v=NhASk7rZsmU&t=409.52s)]
*  reproduction of Chinchilla, at least in its approach of parameterization and all of these [[00:06:55](https://www.youtube.com/watch?v=NhASk7rZsmU&t=415.04s)]
*  things. It was one of the first papers that established that you could go beyond the Chinchilla [[00:06:59](https://www.youtube.com/watch?v=NhASk7rZsmU&t=419.2s)]
*  scaling laws. So Chinchilla scaling laws tell you what you should be training if you want to have [[00:07:05](https://www.youtube.com/watch?v=NhASk7rZsmU&t=425.2s)]
*  an optimal model for a certain compute cost at training time. But if you take into account the [[00:07:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=430.56s)]
*  fact that your model should also be efficient at inference time, you probably want to go far [[00:07:16](https://www.youtube.com/watch?v=NhASk7rZsmU&t=436.15999999999997s)]
*  beyond the Chinchilla scaling law. So it means you want to overtrain the model. So train on more [[00:07:21](https://www.youtube.com/watch?v=NhASk7rZsmU&t=441.44s)]
*  tokens than would be optimal for performance. But the reason why you do that is that you actually [[00:07:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=447.28s)]
*  compress models more. And then when you do inference, you end up having a model which is [[00:07:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=451.76s)]
*  much more efficient for a certain performance. So by spending more time during training, [[00:07:36](https://www.youtube.com/watch?v=NhASk7rZsmU&t=456.96s)]
*  you spend less time during inference and so you save cost. And I think that was something we, [[00:07:42](https://www.youtube.com/watch?v=NhASk7rZsmU&t=462.0s)]
*  well, I guess we observed that at Google also, but the Lama paper was the first to establish [[00:07:47](https://www.youtube.com/watch?v=NhASk7rZsmU&t=467.84s)]
*  it in the open and it opened a lot of opportunities. Yep. I remember both the impact of the Chinchilla [[00:07:53](https://www.youtube.com/watch?v=NhASk7rZsmU&t=473.44s)]
*  scaling laws work on the labs, on multiple labs, realizing just how unoptimal the compute setups [[00:08:00](https://www.youtube.com/watch?v=NhASk7rZsmU&t=480.64s)]
*  were. And then the impact of Lama being dramatic on the industry and realizing how to be much more [[00:08:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=488.4s)]
*  efficient about inference time. So I can imagine that those are some of the top insights on your [[00:08:16](https://www.youtube.com/watch?v=NhASk7rZsmU&t=496.08s)]
*  mind and the top concerns on your mind when you guys left to start Mistral. So let's fast forward [[00:08:21](https://www.youtube.com/watch?v=NhASk7rZsmU&t=501.59999999999997s)]
*  to today. It's December, 2023. We'll get to the role of open source in a bit, but let's just level [[00:08:28](https://www.youtube.com/watch?v=NhASk7rZsmU&t=508.96s)]
*  set on what you've built so far. A couple of months ago, you released Mistral 7B, which was [[00:08:34](https://www.youtube.com/watch?v=NhASk7rZsmU&t=514.96s)]
*  a best in class model. And this week you're releasing a new mixture of experts model. So just [[00:08:40](https://www.youtube.com/watch?v=NhASk7rZsmU&t=520.56s)]
*  tell us a little bit more about Mistral, I believe is what you're calling it and how it compares to [[00:08:47](https://www.youtube.com/watch?v=NhASk7rZsmU&t=527.68s)]
*  other models. Yeah. So Mistral is our new model that wasn't released in open source before in [[00:08:52](https://www.youtube.com/watch?v=NhASk7rZsmU&t=532.0799999999999s)]
*  a usable form. It's a technology called sparse mixture of experts, which is quite simple. You [[00:08:58](https://www.youtube.com/watch?v=NhASk7rZsmU&t=538.24s)]
*  take all of the dense layers of your transformer and you duplicate them. You call these layers [[00:09:03](https://www.youtube.com/watch?v=NhASk7rZsmU&t=543.6800000000001s)]
*  expert layers. And then what you do is that for each token that you have in your sequence, [[00:09:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=548.72s)]
*  you have a router mechanisms, just a very simple network that decides which experts should be [[00:09:15](https://www.youtube.com/watch?v=NhASk7rZsmU&t=555.36s)]
*  looking at which token. And so you send all of the tokens to their experts and then you apply the [[00:09:21](https://www.youtube.com/watch?v=NhASk7rZsmU&t=561.2s)]
*  experts and you get back the output and you combine them and then you go forward in the [[00:09:26](https://www.youtube.com/watch?v=NhASk7rZsmU&t=566.24s)]
*  network. You have eight experts per layer and you execute only two of them. So what it means [[00:09:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=571.52s)]
*  at the end of the day is that you have a lot of parameters on your model. You have 46 billion [[00:09:37](https://www.youtube.com/watch?v=NhASk7rZsmU&t=577.36s)]
*  parameters, but the thing is that the number of parameters that you execute is much lower than [[00:09:43](https://www.youtube.com/watch?v=NhASk7rZsmU&t=583.12s)]
*  that because you only execute two branches out of eight. And so at the end of the day, you only [[00:09:49](https://www.youtube.com/watch?v=NhASk7rZsmU&t=589.2s)]
*  execute 12 billion parameters per token. And this is what counts for latency and throughput and for [[00:09:53](https://www.youtube.com/watch?v=NhASk7rZsmU&t=593.76s)]
*  performance. So you have a model which has the performance of a 12 billion parameter network [[00:09:59](https://www.youtube.com/watch?v=NhASk7rZsmU&t=599.4399999999999s)]
*  that have performance that are much higher than what you could get even by compressing that a lot [[00:10:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=606.24s)]
*  on a 12 billion dense transformer. So sparse mixture of experts is a technology that allows [[00:10:11](https://www.youtube.com/watch?v=NhASk7rZsmU&t=611.92s)]
*  to be much more efficient at inference time and also much more efficient at training time. So [[00:10:18](https://www.youtube.com/watch?v=NhASk7rZsmU&t=618.24s)]
*  that's the reason why we choose to develop it very quickly. Just for folks who are listening, [[00:10:22](https://www.youtube.com/watch?v=NhASk7rZsmU&t=622.16s)]
*  who might not be familiar with state of the art architecture and language models, [[00:10:28](https://www.youtube.com/watch?v=NhASk7rZsmU&t=628.16s)]
*  could you just describe the difference between dense models which have been the primary architecture [[00:10:32](https://www.youtube.com/watch?v=NhASk7rZsmU&t=632.3199999999999s)]
*  to date and mixture of experts? Intuitively, what are the biggest differences between these [[00:10:37](https://www.youtube.com/watch?v=NhASk7rZsmU&t=637.6s)]
*  two architectures? So they are very similar except on what we call the dense network. So [[00:10:42](https://www.youtube.com/watch?v=NhASk7rZsmU&t=642.24s)]
*  the dense transformer, you alternate between an attention layer and a dense layer, [[00:10:49](https://www.youtube.com/watch?v=NhASk7rZsmU&t=649.04s)]
*  generally. That's the idea. A sparse mixture of experts, you take the dense layer and you [[00:10:55](https://www.youtube.com/watch?v=NhASk7rZsmU&t=655.68s)]
*  duplicate it several times. And so that's where you actually increase the number of parameters. [[00:11:01](https://www.youtube.com/watch?v=NhASk7rZsmU&t=661.1999999999999s)]
*  So you increase the capacity of the model without increasing the cost. So that's a way of decoupling [[00:11:05](https://www.youtube.com/watch?v=NhASk7rZsmU&t=665.52s)]
*  the memorization and what you can remember the capacity of the network to its cost at inference [[00:11:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=670.64s)]
*  time. If you had to describe the biggest benefits for developers as a result of that [[00:11:15](https://www.youtube.com/watch?v=NhASk7rZsmU&t=675.36s)]
*  inference efficiency? Its cost and latency. So you can have, usually that's what you look at when [[00:11:19](https://www.youtube.com/watch?v=NhASk7rZsmU&t=679.52s)]
*  you're a developer. You want something which is cheap and you want something which is fast. [[00:11:26](https://www.youtube.com/watch?v=NhASk7rZsmU&t=686.24s)]
*  Generally speaking, just the trade-off is strictly favorable in using mixed trial compared to using [[00:11:29](https://www.youtube.com/watch?v=NhASk7rZsmU&t=689.2s)]
*  a 12 billion dense model. The other way to think about it is that if you want to use a model which [[00:11:36](https://www.youtube.com/watch?v=NhASk7rZsmU&t=696.08s)]
*  is as good as Lama 270B, you should be using mixed trial because mixed trial is actually on [[00:11:42](https://www.youtube.com/watch?v=NhASk7rZsmU&t=702.24s)]
*  par with Lama 270B while being approximately six times cheaper or six times faster for the same [[00:11:47](https://www.youtube.com/watch?v=NhASk7rZsmU&t=707.6s)]
*  price. Could you talk just a little bit about why it's been so challenging for folks to, [[00:11:52](https://www.youtube.com/watch?v=NhASk7rZsmU&t=712.8s)]
*  for research labs and research teams to really get the mixture of experts model right? It sounds like [[00:12:00](https://www.youtube.com/watch?v=NhASk7rZsmU&t=720.16s)]
*  for a while now, folks have known that the dense model architecture that all of us have been using [[00:12:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=726.16s)]
*  in sort of the most notable products or the most well-known products are slow, they're expensive, [[00:12:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=730.8000000000001s)]
*  and they're difficult to scale. And so for a while, people have been looking for [[00:12:18](https://www.youtube.com/watch?v=NhASk7rZsmU&t=738.32s)]
*  an alternative architecture that could be, like you were saying, cheaper, could be faster, could [[00:12:23](https://www.youtube.com/watch?v=NhASk7rZsmU&t=743.6800000000001s)]
*  be more efficient. What were some of the biggest challenges you have to figure out to get the MOE [[00:12:28](https://www.youtube.com/watch?v=NhASk7rZsmU&t=748.64s)]
*  model right? Well, I guess I won't disclose all trade secrets, but there's basically two challenges. [[00:12:33](https://www.youtube.com/watch?v=NhASk7rZsmU&t=753.36s)]
*  The first one is you need to figure out how to train it correctly from a mathematical perspective. [[00:12:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=758.64s)]
*  The other challenge is to train efficiently, so how to use actually hardware as efficiently as [[00:12:44](https://www.youtube.com/watch?v=NhASk7rZsmU&t=764.08s)]
*  possible. You have new challenges coming from the fact that you have tokens flying around [[00:12:49](https://www.youtube.com/watch?v=NhASk7rZsmU&t=769.52s)]
*  from one expert to another. That creates some communication constraints and you need to figure [[00:12:54](https://www.youtube.com/watch?v=NhASk7rZsmU&t=774.16s)]
*  it out. You need to make it fast. And then on top of that, you also have new constraints that apply [[00:13:00](https://www.youtube.com/watch?v=NhASk7rZsmU&t=780.88s)]
*  when you deploy the model. You do need to do inferencing efficiently. And that's also the [[00:13:04](https://www.youtube.com/watch?v=NhASk7rZsmU&t=784.88s)]
*  reason why we released an open source package based on VLM so that the community can take also [[00:13:11](https://www.youtube.com/watch?v=NhASk7rZsmU&t=791.52s)]
*  this code and modify it and see how that works. Yeah, obviously, we're excited to see what the [[00:13:16](https://www.youtube.com/watch?v=NhASk7rZsmU&t=796.88s)]
*  community does with the MOE mixed role release you're putting out this week. Let's talk about [[00:13:21](https://www.youtube.com/watch?v=NhASk7rZsmU&t=801.68s)]
*  open source, an approach and a philosophy that's permeated all the work you've been doing so far. [[00:13:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=807.68s)]
*  Why choose to tackle this increasingly competitive space with an open source approach, [[00:13:34](https://www.youtube.com/watch?v=NhASk7rZsmU&t=814.4000000000001s)]
*  which is quite different from the way everybody else is approaching it? [[00:13:39](https://www.youtube.com/watch?v=NhASk7rZsmU&t=819.9200000000001s)]
*  I guess it's a good question. The answer is that it's partly ideological and partly [[00:13:42](https://www.youtube.com/watch?v=NhASk7rZsmU&t=822.72s)]
*  pragmatical. We have grown with the field of AI. From 2012, we were detecting cats and dogs. [[00:13:47](https://www.youtube.com/watch?v=NhASk7rZsmU&t=827.44s)]
*  And in 2022, we were actually generating text that looked human-like. So really made a lot of [[00:13:57](https://www.youtube.com/watch?v=NhASk7rZsmU&t=837.6s)]
*  progress. And if you look at the reason why we made all of this progress, well, most of it is [[00:14:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=842.8000000000001s)]
*  explainable by the free flow of information. So you had academic labs, you had very big [[00:14:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=848.08s)]
*  industry-backed labs communicating all the time about the results and building on top of each [[00:14:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=854.8000000000001s)]
*  other results. And that's the way we went from, we increased significantly the architecture and [[00:14:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=860.8000000000001s)]
*  training techniques. We just made everything work as a community. And all of a sudden in 2020, [[00:14:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=867.76s)]
*  with GPT-free, this tide kind of reversed and companies started to be more opaque about what [[00:14:36](https://www.youtube.com/watch?v=NhASk7rZsmU&t=876.48s)]
*  they were doing because they realized there was actually a very big market. And all of a sudden, [[00:14:43](https://www.youtube.com/watch?v=NhASk7rZsmU&t=883.12s)]
*  in 2022, on the important aspects of AI and on LLMs, we went beyond Chinchilla, there were [[00:14:48](https://www.youtube.com/watch?v=NhASk7rZsmU&t=888.4s)]
*  basically no communication at all. And that's something that I, as a researcher, and Timothée [[00:14:56](https://www.youtube.com/watch?v=NhASk7rZsmU&t=896.0s)]
*  and Guillaume, and all of the people that joined us as well, deeply regretted because we think that [[00:15:01](https://www.youtube.com/watch?v=NhASk7rZsmU&t=901.0400000000001s)]
*  we're definitely not at the end of the story. We need to invent new things. There's no reason why [[00:15:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=906.1600000000001s)]
*  to stop now because the technology is effectively good, but not working completely well enough. [[00:15:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=910.48s)]
*  And so we believe that it's still the case that we should be communicating a lot about models. [[00:15:16](https://www.youtube.com/watch?v=NhASk7rZsmU&t=916.5600000000001s)]
*  We should be allowing the community to take the models and make it their own. And that's some [[00:15:22](https://www.youtube.com/watch?v=NhASk7rZsmU&t=922.88s)]
*  ideological reason why we went into that. The other reason is that we are talking to developers. [[00:15:29](https://www.youtube.com/watch?v=NhASk7rZsmU&t=929.04s)]
*  Developers want to modify things. And having a deep access to a very good model is a good way [[00:15:36](https://www.youtube.com/watch?v=NhASk7rZsmU&t=936.0s)]
*  of engaging with this community. And I guess addressing their needs so that the platform [[00:15:42](https://www.youtube.com/watch?v=NhASk7rZsmU&t=942.56s)]
*  we're building as well is going to be used by them. So that's also a business reason. Obviously, [[00:15:48](https://www.youtube.com/watch?v=NhASk7rZsmU&t=948.4s)]
*  as a business, we do need to have a valid monetization approach at some point. [[00:15:55](https://www.youtube.com/watch?v=NhASk7rZsmU&t=955.76s)]
*  But we've seen many businesses build open core approaches and have a very strong open source [[00:16:00](https://www.youtube.com/watch?v=NhASk7rZsmU&t=960.56s)]
*  community and also a very good offer of services. And that's what we want to build. [[00:16:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=966.64s)]
*  That resonates. I remember a very detectable shift. You're right. The early days of [[00:16:11](https://www.youtube.com/watch?v=NhASk7rZsmU&t=971.28s)]
*  deep learning were largely driven by a bunch of open collaboration between researchers from [[00:16:19](https://www.youtube.com/watch?v=NhASk7rZsmU&t=979.04s)]
*  different labs who would often publish all their work and share them at conferences. [[00:16:24](https://www.youtube.com/watch?v=NhASk7rZsmU&t=984.24s)]
*  Transformers famously was published and open to the entire research community. [[00:16:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=987.76s)]
*  But that has definitely changed. Yes. So I think there's some level of open sourcing in the eyes. [[00:16:33](https://www.youtube.com/watch?v=NhASk7rZsmU&t=993.1999999999999s)]
*  And so we offer the open the weights and we offer the inference code. That's like the end product [[00:16:39](https://www.youtube.com/watch?v=NhASk7rZsmU&t=999.76s)]
*  that is already super usable. So it's already a very big step forward compared to closed APIs [[00:16:45](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1005.28s)]
*  because you can modify it and you can look at what's happening under the hood, [[00:16:51](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1011.76s)]
*  look at activations and all. So you have interpretability and the possibility of [[00:16:56](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1016.24s)]
*  modifying the model to adapt it to some editorial tone, to adapt it to proprietary data, [[00:17:00](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1020.4s)]
*  to adapt it to some specific instructions, which is something that is actually much harder to make [[00:17:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1026.56s)]
*  if you only have access to a closed source API. And that's something that also goes with our [[00:17:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1030.64s)]
*  approach of the technology, which is to say pre-trained models should be neutral and we [[00:17:15](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1035.8400000000001s)]
*  should empower our customers to take these models and just put their editorial approaches, [[00:17:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1040.64s)]
*  their instruction, their constitution, if you want to talk like Antropiq into the model. So [[00:17:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1047.2800000000002s)]
*  that's the way we approach the technology. We don't want to pour our own biases into the [[00:17:32](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1052.96s)]
*  the pre-trained model. On the other hand, we want to enable the developers to control exactly how [[00:17:37](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1057.92s)]
*  the model behaves and what kind of biases it has, what kind of biases it doesn't have. So we really [[00:17:43](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1063.44s)]
*  take this modular approach and that goes very well with the fact that we release some very strong [[00:17:49](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1069.68s)]
*  open weight models. Could you just ground us in the reality of where these models are today, [[00:17:54](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1074.8s)]
*  just to give people a sense of where in the timeline we are? Is open source really a [[00:17:58](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1078.88s)]
*  viable competitor to proprietary closed models or is there a performance gap? What are the trade [[00:18:04](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1084.0s)]
*  offs or limitations that people should be aware of with open source? So Mixtral is a similar [[00:18:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1088.88s)]
*  performance to GPT 3.5. So that's a good grounding. Internally, we have stronger models that are in [[00:18:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1094.4s)]
*  between 3.5 and 4 that are basically the second or third best model in the world. So really we think [[00:18:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1100.88s)]
*  that the gap is closing. The gap is approximately six months at that point. [[00:18:28](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1108.4s)]
*  And the reason why it's six months is that it actually goes faster if you do open source things [[00:18:33](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1113.0400000000002s)]
*  because you get the community modify the model to just very good ideas that can then be consolidated [[00:18:36](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1116.8000000000002s)]
*  by us, for instance, and we just go faster because of that. So it has always been the case that open [[00:18:43](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1123.2s)]
*  source ends up going faster and that's the reason why the entire internet runs on Linux. I don't see [[00:18:49](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1129.6000000000001s)]
*  why it would be any different for AI. Obviously, there's some constraints that are slightly [[00:18:57](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1137.84s)]
*  different because the infrastructure cost is quite high. To train a model will cost a lot of money, [[00:19:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1142.08s)]
*  but I really think that we'll converge to a setting where you have proprietary models and [[00:19:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1148.56s)]
*  the open source model are just as good. And I think eventually the field will be much more open [[00:19:13](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1153.6s)]
*  because if you want to go beyond the biggest model today, you do need to find new paradigms. [[00:19:17](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1157.52s)]
*  So that means that we also need to do research and that we're very excited by this perspective [[00:19:22](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1162.72s)]
*  because we like a competitive environment and research. Yeah, so let's talk about that a little [[00:19:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1167.76s)]
*  bit more. How are you seeing people use and innovate on the open source models? And are there [[00:19:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1171.8400000000001s)]
*  any use cases that diverge from proprietary closed models at all? I think we've seen several [[00:19:37](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1177.3600000000001s)]
*  categories of usage. There's a few companies that know how to strongly fine tune models to their [[00:19:42](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1182.48s)]
*  needs. So they took Mistral 7b, had a lot of human annotations, had a lot of proprietary data, [[00:19:48](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1188.64s)]
*  just modified Mistral 7b so that it solved their task just as well as GBT 3.5, but only for a lower [[00:19:54](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1194.8000000000002s)]
*  cost and a higher level of control. We've also seen, I think, very interesting community efforts [[00:20:00](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1200.96s)]
*  in adding capabilities to Mistral 7b. So we saw like a context length extension to 128k, [[00:20:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1206.0s)]
*  that worked very well. Again, it was done in the open, so like the recipe was available and this is [[00:20:12](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1212.64s)]
*  something that we were able to consolidate. We've seen image encoders to make it a visual language [[00:20:17](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1217.2s)]
*  model. A very actionable thing that we saw is, I think, the hugging face folks first did the direct [[00:20:23](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1223.04s)]
*  preference optimization on top of Mistral 7b and made a much stronger model than the instructed [[00:20:30](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1230.24s)]
*  model we proposed at the early release. And it turned out it's actually a very good idea to do it. [[00:20:35](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1235.8400000000001s)]
*  And so that's something that we've consolidated as well. So generally speaking, [[00:20:41](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1241.6799999999998s)]
*  the community is super eager to just take the model and add new capabilities, put it on a laptop, [[00:20:47](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1247.52s)]
*  put it on an iPhone. I saw Mistral 7b on an iPhone. I saw Mistral 7b on the stuffed parot as well. [[00:20:53](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1253.28s)]
*  So fun things, useful things, but generally speaking, it's been super exciting to see [[00:20:59](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1259.6799999999998s)]
*  the research community take a hold of our technology. And with Mixtral, which is a new [[00:21:05](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1265.36s)]
*  architecture, I think we're also going to see much more interesting things because [[00:21:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1270.8s)]
*  on the interpretability field, also on the safety field, as it turns out, you have a lot of things [[00:21:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1274.48s)]
*  to do when you have deep access to an open model. And so we're really eager to help that [[00:21:19](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1279.36s)]
*  and to engage with the community. Safety is an important, I think, piece to talk about. [[00:21:24](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1284.96s)]
*  The immediate reaction of a lot of folks is to deem open source less safe than closed models. [[00:21:30](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1290.8799999999999s)]
*  How would you respond to that? So I think we believe that it's actually not the case for the [[00:21:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1298.32s)]
*  current generation of models that we are using today are not that much, are not much more than [[00:21:43](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1303.2s)]
*  just a compression of whatever is available on the internet. So it does make access to knowledge [[00:21:50](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1310.08s)]
*  more fluid, but this is the story of humanity making knowledge access more fluid. So it's no [[00:21:55](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1315.68s)]
*  different than inventing the printing machine where we had a similar debate. It wasn't there, [[00:22:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1322.08s)]
*  but that was the debate we had. So we are not making the world any time any less safer by [[00:22:07](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1327.12s)]
*  providing more interactive access to knowledge. So that's the first thing. Now, the other thing is [[00:22:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1334.1599999999999s)]
*  that you do have immediate risk of misuse of large language models, and you do have them for open [[00:22:19](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1339.1999999999998s)]
*  source models, but also for closed models. And so the way you do address these problems and come up [[00:22:25](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1345.1999999999998s)]
*  with countermeasures is to know about them. So you need to know about breaches basically. [[00:22:32](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1352.24s)]
*  That's the same way in which you need to know about breaches on operating systems and on [[00:22:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1358.72s)]
*  networks. And so it's no different for AI. Putting models under the highest level of scrutiny is the [[00:22:43](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1363.52s)]
*  way of knowing how they can be misused. And it's a way of coming up with countermeasures. And I think [[00:22:50](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1370.4s)]
*  a good example of that is that it's actually super easy to exploit an API. It's super easy, [[00:22:55](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1375.36s)]
*  especially if you have fine tuning access, to make GPT-4 behave in a very bad way. And since it's [[00:23:00](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1380.4s)]
*  the case, and it's always going to be the case, it's super hard to be adversarial and robust. [[00:23:09](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1389.1200000000001s)]
*  It means that we're only trusting the team of large companies to figure out ways of addressing [[00:23:13](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1393.3600000000001s)]
*  these problems. Whereas if you do open sourcing, you trust the community. The community is much [[00:23:19](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1399.2800000000002s)]
*  larger. And so if you look at the history of software in cybersecurity in operating systems, [[00:23:24](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1404.72s)]
*  that's the way we made the system safe. And so if we want to make the current AI system safe, [[00:23:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1411.44s)]
*  and then move on to the next generation that potentially will be even stronger, and then we [[00:23:36](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1416.4s)]
*  can have this discussion again, well, you do need to do open sourcing. So today, [[00:23:42](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1422.4s)]
*  we think that open sourcing is a safe way. Yeah, I think this is not understood widely. [[00:23:46](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1426.88s)]
*  When you have thousands or hundreds of thousands of people able to read team models, because it's [[00:23:54](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1434.88s)]
*  open source, the likelihood that you'll detect biases and built in breaches and risks are just [[00:24:01](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1441.04s)]
*  dramatically higher. And I think if you were talking to policymakers, how would you help [[00:24:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1448.64s)]
*  advise them? How do you think they should be thinking about regulating open source models, [[00:24:16](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1456.16s)]
*  given that the safest way often to battle harden software and tools is to put them out in the open? [[00:24:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1460.8000000000002s)]
*  Well, we've been saying that precisely this that the current technology is not dangerous. [[00:24:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1467.92s)]
*  On the other hand, the fact that we are effectively making them stronger means that [[00:24:35](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1475.68s)]
*  we need to monitor what's happening empirically monitor our performances. The best way of [[00:24:40](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1480.4s)]
*  empirically monitoring software performances is through open source. So that's what we've been [[00:24:44](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1484.88s)]
*  saying. There's been some effort to try to come up with very complex governance structure, where [[00:24:51](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1491.1200000000001s)]
*  you would have like several companies talking together, having some safe space, some safe [[00:24:58](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1498.8000000000002s)]
*  sandbox for red tumor that will be potentially independent. So things that are super complex. [[00:25:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1502.8000000000002s)]
*  But as it turns out, if you look at the history of software, the only way we did software [[00:25:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1510.88s)]
*  collaboratively is through open source. So why change the recipe today, where the technology [[00:25:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1514.72s)]
*  we're looking at is actually nothing else than the compression of the internet. So that's what [[00:25:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1520.56s)]
*  we've been saying to the regulators. Generally, another thing we've added to the regulator is that [[00:25:25](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1525.52s)]
*  if they want to enforce that AI products that needs to be safe, like if you want to have a [[00:25:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1531.3600000000001s)]
*  diagnosis assistant, you want it to be safe. Well, in order to monitor and to evaluate whether [[00:25:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1538.48s)]
*  it's actually safe, you need to have some very good tooling. And the tooling requires to have [[00:25:44](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1544.48s)]
*  access to LLMs. And if you access close source APIs, LLMs, where you're a bit in a in a in [[00:25:49](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1549.68s)]
*  troubled water, because it's hard to be independent in that setting. So we think that independent [[00:25:57](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1557.44s)]
*  controller of product safety should have access to very strong open source models and should [[00:26:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1562.56s)]
*  own the technology. And if open source LLMs were to fail relative to close source, [[00:26:07](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1567.6s)]
*  models, why would that be? Well, I guess the regulation burden is potentially one thing that [[00:26:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1574.64s)]
*  could make it harder to release open source models. It's also generally speaking, it's a very [[00:26:23](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1583.6s)]
*  competitive market. And I think in order for open source models to be widely adopted, they need to [[00:26:30](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1590.16s)]
*  be as strong as open source as a close source model. They have a little advantage because you [[00:26:35](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1595.68s)]
*  do have more control. And so you can do if you're fine tuning and so you can make performance jump [[00:26:41](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1601.76s)]
*  a lot on a specific task because you have deep access. But really, at the end of the day, [[00:26:47](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1607.12s)]
*  developers look at performance and latency. And so that's why we think that as a company, [[00:26:53](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1613.36s)]
*  we need to be very much on the frontier if we want to be relevant. [[00:26:59](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1619.36s)]
*  And given the complexity of frontier models and foundation models in these systems, [[00:27:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1622.48s)]
*  there are just tons of misconceptions that folks have about these models. [[00:27:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1628.8s)]
*  And so if you step back, can we look at the battle that's raging between folks pushing [[00:27:13](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1633.1999999999998s)]
*  for closed source systems versus the open source system? What do you think is at stake here? What [[00:27:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1640.8799999999999s)]
*  do you think the battle is really for? Well, I think the battle is for the neutrality [[00:27:26](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1646.72s)]
*  of the technology. Like a technology by a sense is something neutral. You can use it for bad [[00:27:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1651.12s)]
*  purposes. You can use it for good purposes. If you look at what the LLM does, it's not really [[00:27:36](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1656.24s)]
*  different from a programming language. It's actually used very much as a programming language [[00:27:41](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1661.1200000000001s)]
*  by the application makers. There's a strong confusion made between what we call a model [[00:27:45](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1665.76s)]
*  and what we call an application. And so the model is really the programming language of AI [[00:27:52](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1672.4s)]
*  applications. So if you talk to all of the startups doing amazing products with generative AI, [[00:27:57](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1677.76s)]
*  they're using LLMs just as a function. And on top of that, you have a very big system with filters, [[00:28:03](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1683.28s)]
*  with decision making, with control flow and all of these things. And what you want to regulate, [[00:28:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1690.48s)]
*  if you want to regulate something, is the system. The system is the product. So for instance, [[00:28:15](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1695.44s)]
*  a healthcare diagnosis assistant is an application. You want it to be non-biased. You want it to take [[00:28:21](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1701.76s)]
*  good decisions, even under high pressure. So you want its statistical accuracy to be very high. [[00:28:30](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1710.24s)]
*  And so you want to measure that. And it doesn't matter if it uses a large language model [[00:28:36](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1716.16s)]
*  under the hood. What you want to regulate is the application. And the issue we had, [[00:28:43](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1723.2s)]
*  and the issue we're still having now is we hear a lot of people saying we should regulate the tech. [[00:28:48](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1728.48s)]
*  So we should regulate the function, the mathematics behind it. But really, you never use a large [[00:28:54](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1734.88s)]
*  language model itself. You only always use it in an application in a way with a user interface. [[00:28:59](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1739.92s)]
*  And so that's the one thing you want to regulate. And what it means is that companies like us, [[00:29:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1746.24s)]
*  foundational model companies, will obviously make the model as controllable as possible so that the [[00:29:11](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1751.6000000000001s)]
*  applications on top of it can be compliant, can be safe. We'll also build the tools that allow to [[00:29:16](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1756.4s)]
*  measure the compliance and the safety of the application, because that's super useful for the [[00:29:23](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1763.04s)]
*  application makers. It's actually needed. But there's no point in regulating something that is [[00:29:29](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1769.2s)]
*  neutral in itself. That is just a mathematical tool. So I think that's the one thing that we've [[00:29:35](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1775.68s)]
*  been hammering a lot. I think we've been heard, which is good. But there's still a lot of effort [[00:29:40](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1780.64s)]
*  I guess in making this strong distinction, which is super important to understand what's going on. [[00:29:48](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1788.0s)]
*  So to regulate apps, not math, seems like the right direction that a lot of folks who understand the [[00:29:53](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1793.2s)]
*  inner workings of these models and how they're actually implemented in reality are advocating [[00:30:01](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1801.68s)]
*  for. What do you think is the best way to clear up this misconception for folks who maybe don't have [[00:30:06](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1806.64s)]
*  technical backgrounds, don't actually understand how foundation models work and how the scaling [[00:30:15](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1815.76s)]
*  models work? So I've been using a lot of metaphors, I guess, to make it understood. [[00:30:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1820.72s)]
*  Large language models are like programming languages. And so you don't regulate programming [[00:30:26](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1826.16s)]
*  languages. You regulate malwares. You ban malwares. We've also been actively vocal about the fact that [[00:30:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1831.2800000000002s)]
*  pre-market conditions like flops, the number of flops that you do to create a model, is definitely [[00:30:40](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1840.48s)]
*  not the right way of measuring the performance of a model. We're very much in favor of having [[00:30:46](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1846.08s)]
*  very strong evaluations. As I've said, this is something that we want to provide to our customers, [[00:30:54](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1854.0s)]
*  the ability to evaluate our models in their application. And so I think this is a very strong [[00:30:59](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1859.6s)]
*  thing that we've been stressing. We want to provide the tools for application makers to be compliant. [[00:31:05](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1865.6799999999998s)]
*  That's something we have been saying. And so we find it a bit unfortunate that we haven't [[00:31:13](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1873.68s)]
*  been heard everywhere and that there's still a big focus on the tech, probably because things are not [[00:31:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1880.4s)]
*  completely well understood because it's a very complex field and it's also a very fast-moving [[00:31:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1887.2s)]
*  field. But eventually, I think I'm very optimistic that we'll find a way to continue innovating [[00:31:30](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1890.8s)]
*  while having safe products, but also a high level of competition on the foundational model layer. [[00:31:39](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1899.12s)]
*  Well, let's channel your optimism a little bit. There's very few people who have [[00:31:47](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1907.6s)]
*  the ground level understanding of scaling laws like you, Guillaume, and Tim, and your team. [[00:31:52](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1912.24s)]
*  When you step back and you look at the entire space of language modeling, in addition to [[00:31:58](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1918.8799999999999s)]
*  open source, what are the key differentiators that you see in the next wave of cutting edge models? [[00:32:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1922.32s)]
*  Things like self-play, you have process reward models, the uses of synthetic data. [[00:32:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1928.6399999999999s)]
*  If you had to conjecture, what do you think some of the most exciting or important [[00:32:16](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1936.8799999999999s)]
*  breakthroughs will be in the field going forward? So I guess it's good to start with diagnosis. So [[00:32:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1940.8799999999999s)]
*  what is not working that well? So reasoning is not working that well. And it's super inefficient [[00:32:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1947.36s)]
*  to train a model. If you compare the training process of a large language model to the brain, [[00:32:32](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1952.6399999999999s)]
*  you have a factor, I think, 100,000. So really, there's some progress to be made on [[00:32:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1958.16s)]
*  some of that efficiency. So I think the frontier is increasing data efficiency, [[00:32:44](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1964.64s)]
*  increasing reasoning capabilities. So adaptive compute is one way. And when to increase that [[00:32:50](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1970.3200000000002s)]
*  efficiency, you do need to work on coming up with very high quality data, filtering things, [[00:32:55](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1975.92s)]
*  many new techniques that needs to be invented still. But that's really where the lock is, [[00:33:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1982.3200000000002s)]
*  data is the one important thing. And the ability of the model to decide how much compute it wants [[00:33:07](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1987.68s)]
*  to allocate to a certain problem is definitely on the frontier as well. So these are things that [[00:33:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=1994.1599999999999s)]
*  we're actively looking at. You know, this is a raging debate, right? And we've talked about this [[00:33:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2000.32s)]
*  a few times before, which is, can models actually reason today? Do they actually generalize out of [[00:33:25](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2005.52s)]
*  distribution? What's your take on it? And what do you think is required to exhibit? What would [[00:33:32](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2012.08s)]
*  convince you that models are actually capable of multi-step complex reasoning? Yeah, it's very hard [[00:33:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2018.96s)]
*  because you train on the entire human knowledge. And so you have a lot of reasoning places. So [[00:33:44](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2024.24s)]
*  it's hard to say whether they reason or not, or whether they do retrieval of reasoning. And it [[00:33:49](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2029.04s)]
*  looks like reasoning. I guess at the end of the day, what matters is whether it works or not. [[00:33:54](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2034.48s)]
*  And on many simple reasoning tasks it does. So we can call it reasoning. And it doesn't really [[00:33:59](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2039.44s)]
*  matter if they reason like we do. We don't even know how we reason. So we are not going to know [[00:34:04](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2044.8s)]
*  about how machines reason anytime soon. So yeah, it's a raging debate. The way you do evaluate that [[00:34:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2050.32s)]
*  is try to be as out of distribution as possible. Like working on mathematics is not something I've [[00:34:19](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2059.44s)]
*  ever done, but it's something that Timothée and Guillaume are very sensitive to because they've [[00:34:27](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2067.2s)]
*  been doing it for a while when they were at Meta. That's probably one way of measuring whether you [[00:34:33](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2073.7599999999998s)]
*  have a very good model or not. And actually, if you look at, we're starting to see some very good [[00:34:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2078.24s)]
*  mathematicians. I'm thinking of Terence Tao, who are using large language models for some things. [[00:34:44](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2084.0s)]
*  Obviously not the high level reasoning, but for some part of their proofs. And so I think we will [[00:34:51](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2091.68s)]
*  move up into abstraction. And the question is where does that stop? We do need to find new [[00:34:56](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2096.4s)]
*  paradigms to go one step forward and we will be actively looking for them. [[00:35:02](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2102.96s)]
*  We've talked a lot about developers so far. If you had to channel your product view, [[00:35:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2108.88s)]
*  and just conjecture on what these advances in scaling laws, in representation learning, [[00:35:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2114.32s)]
*  in teaching the models to reason faster, better, cheaper. What will these advances mean for end [[00:35:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2120.72s)]
*  users in terms of how they consume, how they program, and they generally work with models? [[00:35:26](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2126.64s)]
*  What we think is that fast forward five years, everybody will be using their specialized models [[00:35:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2131.2799999999997s)]
*  within parts of complex applications and systems. Developers will be very looking at latency. So [[00:35:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2138.4s)]
*  they will want to have for any specific task of the system, they will want to have the lowest cost [[00:35:45](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2145.2s)]
*  and lowest latency. And the way you make that happen is that you ask for the task, ask for user [[00:35:52](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2152.08s)]
*  preferences, ask for what you want the model to do, and you try to make them as small as possible [[00:35:58](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2158.16s)]
*  and as suitable to the task as possible. And so I think that's the way we'll be evolving [[00:36:04](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2164.16s)]
*  on the developer space. I also think that generally speaking, the fact that we have access to large [[00:36:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2168.64s)]
*  language models is going to reform completely the way we interact with machines. And the internet [[00:36:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2174.88s)]
*  of five years from now is going to be much different, much more interactive, because I think [[00:36:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2180.1600000000003s)]
*  this is already unlocked. I mean, it's just about making very good applications with very fast systems, [[00:36:25](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2185.6s)]
*  with very fast models. So yeah, very exciting times ahead. So what would those interaction [[00:36:30](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2190.88s)]
*  modalities look like? Yeah, so that's very interesting. And I think in games, for instance, [[00:36:35](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2195.92s)]
*  it's going to be fascinating. We've seen some very good applications. You do need to have small [[00:36:40](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2200.72s)]
*  models because you want to have swarms of it and it starts to be a bit costly if it's too big. [[00:36:45](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2205.52s)]
*  But having them interact is just going to make pretty complex systems and interesting systems [[00:36:50](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2210.9599999999996s)]
*  to observe and to use. So we have a few friends making applications in the enterprise space, [[00:36:56](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2216.0s)]
*  with different persona playing different roles, relying on the same language model, [[00:37:04](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2224.72s)]
*  but with different prompts and different fine tuning. And I think that's going to be quite [[00:37:08](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2228.64s)]
*  interesting as well to look at. As I said, complex applications in three years time are just going to [[00:37:14](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2234.16s)]
*  use different parts, different LLMs for different parts. And that's going to be quite exciting. [[00:37:20](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2240.4s)]
*  Well, what's your call to action? To builders, researchers, folks who are excited about the space, [[00:37:25](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2245.8399999999997s)]
*  what would you ask them to do? I would take Mistral models and try to build amazing applications. [[00:37:31](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2251.2799999999997s)]
*  The way many developers had. It's not that hard. The stack is starting to be pretty clear, [[00:37:38](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2258.8s)]
*  pretty efficient. You only need a couple of GPUs. You cannot even do it on your MacBook Pro if you [[00:37:45](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2265.68s)]
*  want. It's going to be a bit hot, but it's good enough to do interesting applications. [[00:37:51](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2271.52s)]
*  Really, the way we do software today is very different from the way we did it from last year. [[00:37:58](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2278.56s)]
*  And so I'm really calling application makers to action because we are going to try to enable them [[00:38:03](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2283.04s)]
*  to build as fast as possible. Thank you so much for listening to the A16C podcast. What we're [[00:38:10](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2290.0s)]
*  trying to do here is provide an informed, clear-eyed, but also optimistic view of technology [[00:38:15](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2295.44s)]
*  and its future. And we're trying to do that by featuring some of the most inspiring people [[00:38:21](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2301.92s)]
*  and the things they're building. And so if you believe in that and you'd like to join us on this [[00:38:26](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2306.96s)]
*  journey, make sure to click subscribe, but also let us know in the comments below what you'd like [[00:38:32](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2312.56s)]
*  to see us cover next. Thank you so much for listening and we will see you next time. [[00:38:37](https://www.youtube.com/watch?v=NhASk7rZsmU&t=2317.52s)]
