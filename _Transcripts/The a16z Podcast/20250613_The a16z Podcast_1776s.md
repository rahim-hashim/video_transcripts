---
Date Generated: June 13, 2025
Transcription Model: whisper medium 20231117
Length: 1776s
Video Keywords: ['a16z', 'andreessen horowitz']
Video Views: 369
Video Rating: None
Video Description: Things in consumer AI are moving fast.
In this episode, Justine and Olivia Moore, investing partners (and identical twins!) at a16z, break down what’s real, what’s overhyped, and what’s next across the consumer AI space.
They cover:
- Veo 3: how Google's video model unlocked a new genre of content
- OpenAI’s Advanced Voice Mode: upgrades, realism, and... um, human-like hesitation
- Apple's AI announcements 
- 11Labs V3: expressive voice tags, real-time interruptions, and narrative tools for creators
- New data from a16z: AI consumer startups are ramping revenue faster than ever—and they show you how
- Justine walks through how she used ChatGPT, Ideogram, and Krea to launch a fully AI-assisted brand prototype (store photos and all)
It’s exhausting (in the best way) to be a creative in the age of AI.
Timecodes: 
00:00 Introduction 
00:28 Meet the Hosts: Justine and Olivia
00:45 Veo 3: The Game-Changer in AI Video
06:34 ChatGPT's Advanced Voice Mode Updates
10:22 Apple's AI Announcements and Siri's Shortcomings
12:18 11 Labs' New Voice Model: 11 V3
15:50 Report from a16z: AI Revenue Growth
23:14 Demo of the Week: AI in Brand Creation
Resources: 
Read ‘What “Working” Means in the Era of AI Apps’: https://a16z.com/revenue-benchmarks-ai-apps/
Find Justine on X: https://x.com/venturetwins
Find Olivia on X: https://x.com/omooretweets
Tools Discussed: 
Veo 3: https://gemini.google/overview/video-generation
OpenAI: https://openai.com/chatgpt
11Labs (V3 voice model) – https://elevenlabs.io/
Ideogram (logo/image generation) – https://ideogram.ai/
Black Forest Labs/Flux Context (image editing via Krea) – https://www.krea.ai/
Flux Context demo (Krea launch post) – https://www.krea.ai/blog/flux-context
Hedra: https://www.hedra.com/
Stay Updated: 
Let us know what you think: https://ratethispodcast.com/a16z 
Find a16z on Twitter: https://twitter.com/a16z 
Find a16z on LinkedIn: https://www.linkedin.com/company/a16z 
Subscribe on your favorite podcast app: https://a16z.simplecast.com/ 
Follow our host: https://x.com/eriktorenberg
Please note that the content here is for informational purposes only; should NOT be taken as legal, business, tax, or investment advice or be used to evaluate any investment or security; and is not directed at any investors or potential investors in any a16z fund. a16z and its affiliates may maintain investments in the companies discussed. For more details please see a16z.com/disclosures.
---

# What You Missed in AI This Week (Google, Apple, ChatGPT)
**The a16z Podcast:** [June 13, 2025](https://www.youtube.com/watch?v=fySodSi4aUU)
*  AI video completely taking over our social feeds in the span of a week, which is absolutely insane. [[00:00:00](https://www.youtube.com/watch?v=fySodSi4aUU&t=0.0s)]
*  VO3 was sort of like the chat GPT moment for AI video. [[00:00:05](https://www.youtube.com/watch?v=fySodSi4aUU&t=5.28s)]
*  The next generation of entrepreneurs are going to be completely AI assisted. [[00:00:09](https://www.youtube.com/watch?v=fySodSi4aUU&t=9.52s)]
*  Like a world of possibilities has been opened up for AI storytelling, especially in video form. [[00:00:14](https://www.youtube.com/watch?v=fySodSi4aUU&t=14.16s)]
*  Yes, it's an exhausting time for AI creatives. It's great, but exhausting. [[00:00:19](https://www.youtube.com/watch?v=fySodSi4aUU&t=19.68s)]
*  I'm Justine. I'm Olivia. [[00:00:23](https://www.youtube.com/watch?v=fySodSi4aUU&t=23.36s)]
*  And this is our very first edition of This Week in Consumer AI. [[00:00:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=30.24s)]
*  We are both partners on the investing team here at A16Z, and we are also identical twins. [[00:00:34](https://www.youtube.com/watch?v=fySodSi4aUU&t=34.96s)]
*  Very confusing. [[00:00:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=40.16s)]
*  Extremely confusing, but should be fun for a podcast. [[00:00:41](https://www.youtube.com/watch?v=fySodSi4aUU&t=41.04s)]
*  We're excited to chat about some of the cool things we saw in the [[00:00:44](https://www.youtube.com/watch?v=fySodSi4aUU&t=44.4s)]
*  wild world of Consumer AI this week, starting with VO3, Google's video model. [[00:00:47](https://www.youtube.com/watch?v=fySodSi4aUU&t=47.84s)]
*  Then we're going to talk through the chat GPT advanced voice mode updates, [[00:00:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=53.519999999999996s)]
*  and Apple's big AI announcements. [[00:00:57](https://www.youtube.com/watch?v=fySodSi4aUU&t=57.12s)]
*  And then we're going to cover 11 Labs' new voice model. [[00:00:59](https://www.youtube.com/watch?v=fySodSi4aUU&t=59.519999999999996s)]
*  We're going to talk about some data that our team put out recently about how fast [[00:01:03](https://www.youtube.com/watch?v=fySodSi4aUU&t=63.12s)]
*  Consumer AI startups are ramping revenue. [[00:01:07](https://www.youtube.com/watch?v=fySodSi4aUU&t=67.12s)]
*  And then we'll talk about Flux's new editing model context and how Justine used it to make [[00:01:09](https://www.youtube.com/watch?v=fySodSi4aUU&t=69.52s)]
*  her own Froyo brand. [[00:01:13](https://www.youtube.com/watch?v=fySodSi4aUU&t=73.52s)]
*  And stay tuned for the end because we have a cool tutorial and some demo [[00:01:14](https://www.youtube.com/watch?v=fySodSi4aUU&t=74.96000000000001s)]
*  footage on how to make your own brand. [[00:01:18](https://www.youtube.com/watch?v=fySodSi4aUU&t=78.32s)]
*  Things are moving so quickly that it feels like we went from exciting but maybe not [[00:01:20](https://www.youtube.com/watch?v=fySodSi4aUU&t=80.16s)]
*  super realistic AI video to AI video completely taking over our social feeds in the span of [[00:01:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=85.28s)]
*  a week, which is absolutely insane. [[00:01:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=90.88s)]
*  Yeah. I've been following AI video for a few years now. [[00:01:32](https://www.youtube.com/watch?v=fySodSi4aUU&t=92.88s)]
*  You probably remember I've been an early user of all these models, and I have wanted them to work [[00:01:37](https://www.youtube.com/watch?v=fySodSi4aUU&t=97.36s)]
*  and to make cool things that everyday people would like for so long. [[00:01:43](https://www.youtube.com/watch?v=fySodSi4aUU&t=103.75999999999999s)]
*  And I would say VO3 was sort of like the chat GPT moment for AI video, [[00:01:47](https://www.youtube.com/watch?v=fySodSi4aUU&t=107.84s)]
*  where we were suddenly seeing all of these VO3 generations blowing up with millions of views, [[00:01:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=113.52s)]
*  channels only featuring VO3 videos, getting hundreds of thousands of subscribers within days. [[00:02:00](https://www.youtube.com/watch?v=fySodSi4aUU&t=120.0s)]
*  Yeah. What's actually different about VO3? [[00:02:05](https://www.youtube.com/watch?v=fySodSi4aUU&t=125.44s)]
*  Yeah. So, okay, I should give the overview first. [[00:02:08](https://www.youtube.com/watch?v=fySodSi4aUU&t=128.4s)]
*  So VO3 is Google DeepMind's latest video model effort. [[00:02:10](https://www.youtube.com/watch?v=fySodSi4aUU&t=130.72s)]
*  Mm-hmm. [[00:02:14](https://www.youtube.com/watch?v=fySodSi4aUU&t=134.56s)]
*  So they released VO2 late last year, which was like the first sort of breakthrough in showing [[00:02:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=135.76s)]
*  that you could get really high quality video, like a consistent scene, consistent characters, [[00:02:20](https://www.youtube.com/watch?v=fySodSi4aUU&t=140.48s)]
*  physics, like things that just looked good. And VO3 is the next iteration of that model series. [[00:02:26](https://www.youtube.com/watch?v=fySodSi4aUU&t=146.96s)]
*  And what's very different about it is it generates audio natively at the same time [[00:02:33](https://www.youtube.com/watch?v=fySodSi4aUU&t=153.68s)]
*  it generates video. So you can actually prompt it with a text prompt to say something like, [[00:02:38](https://www.youtube.com/watch?v=fySodSi4aUU&t=158.08s)]
*  a street style interview where a man and a woman are talking about dating apps. [[00:02:43](https://www.youtube.com/watch?v=fySodSi4aUU&t=163.36s)]
*  Or you can be even more specific and say something like, a street style interview where a man walks [[00:02:48](https://www.youtube.com/watch?v=fySodSi4aUU&t=168.24s)]
*  up to a woman and asks her, what dating apps are you on? And she replies, why are you asking? [[00:02:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=173.44s)]
*  And then gives him a suspicious look. And so you no longer have to go to another platform to do [[00:02:59](https://www.youtube.com/watch?v=fySodSi4aUU&t=179.84s)]
*  an audio voiceover or anything like that. You can get a full featured talking human video with [[00:03:05](https://www.youtube.com/watch?v=fySodSi4aUU&t=185.6s)]
*  multiple characters in one place. They left behind a ball today. It bounced higher than I can jump. [[00:03:10](https://www.youtube.com/watch?v=fySodSi4aUU&t=190.72s)]
*  What manner of magic is that? [[00:03:18](https://www.youtube.com/watch?v=fySodSi4aUU&t=198.32s)]
*  It feels like a real unlock to me as someone who's been following AI video less closely and that [[00:03:20](https://www.youtube.com/watch?v=fySodSi4aUU&t=200.72s)]
*  people are now able to generate in one prompt, a full vlog, a full talking head video, something [[00:03:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=205.12s)]
*  that looks like a podcast. Yes. [[00:03:32](https://www.youtube.com/watch?v=fySodSi4aUU&t=212.0s)]
*  In one go. And I think that's why we've seen things like the stormtrooper vlogs completely [[00:03:34](https://www.youtube.com/watch?v=fySodSi4aUU&t=214.16s)]
*  blowing up on TikTok and Instagram. I told you, Greg. I told you not to touch the nav system. [[00:03:38](https://www.youtube.com/watch?v=fySodSi4aUU&t=218.16s)]
*  I followed the route. You plotted it upside down, Greg. [[00:03:42](https://www.youtube.com/watch?v=fySodSi4aUU&t=222.96s)]
*  Yes. So the interesting thing about VO3 is it's limited to eight second generations only. [[00:03:47](https://www.youtube.com/watch?v=fySodSi4aUU&t=227.6s)]
*  And it doesn't generate audio if you start from an image to video, only if you start from text, [[00:03:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=233.44s)]
*  which means that it's really hard to have longer than an eight second clip with character consistency, [[00:03:58](https://www.youtube.com/watch?v=fySodSi4aUU&t=238.96s)]
*  unless in your text prompt, you're referencing a character that the model already knows. [[00:04:04](https://www.youtube.com/watch?v=fySodSi4aUU&t=244.4s)]
*  Okay. And so that's why we've seen [[00:04:09](https://www.youtube.com/watch?v=fySodSi4aUU&t=249.28s)]
*  all of these hacks of all the viral vlogs featuring like stormtroopers or a yeti. [[00:04:11](https://www.youtube.com/watch?v=fySodSi4aUU&t=251.04s)]
*  You can't see their faces. They're covered by a mask. [[00:04:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=255.76s)]
*  Yes. Or the yeti, the model knows what the yeti looks like or capybara. Like if it's not a human [[00:04:17](https://www.youtube.com/watch?v=fySodSi4aUU&t=257.84000000000003s)]
*  face, I think we're less sensitive to little changes between the eight second clips. And so [[00:04:23](https://www.youtube.com/watch?v=fySodSi4aUU&t=263.76s)]
*  you have people generating minutes long videos that look like a consistent vlog character. [[00:04:28](https://www.youtube.com/watch?v=fySodSi4aUU&t=268.32s)]
*  They've been super fun to watch. And then how do you actually use VO3? It feels like there's been [[00:04:33](https://www.youtube.com/watch?v=fySodSi4aUU&t=273.2s)]
*  some confusion. Yes. So when VO3 first came out, it was only available on the Google AI Ultra plan, [[00:04:38](https://www.youtube.com/watch?v=fySodSi4aUU&t=278.56s)]
*  very confusing, through Flow, Google's new creative studio. And you had to be on the $250 a month plan. [[00:04:45](https://www.youtube.com/watch?v=fySodSi4aUU&t=285.52s)]
*  So there was a lot of hype, a lot of FOMO. Now the model is available via API. So what that means [[00:04:51](https://www.youtube.com/watch?v=fySodSi4aUU&t=291.92s)]
*  is a bunch of consumer video platforms like Hydra or CREA are offering access to VO3 on their $10 a [[00:04:58](https://www.youtube.com/watch?v=fySodSi4aUU&t=298.32s)]
*  month plan. Or some of the more developer oriented API platforms like Fall or Replicate [[00:05:04](https://www.youtube.com/watch?v=fySodSi4aUU&t=304.8s)]
*  are offering generations where you pay per video. It's priced around 75 cents per second today. [[00:05:11](https://www.youtube.com/watch?v=fySodSi4aUU&t=311.2s)]
*  Wow. Okay. So still pretty expensive. Yes. [[00:05:18](https://www.youtube.com/watch?v=fySodSi4aUU&t=318.96s)]
*  You have to be careful about how you prompt it, but the results are amazing. [[00:05:21](https://www.youtube.com/watch?v=fySodSi4aUU&t=321.28s)]
*  And then what do we expect next, either from Google, from creators? What does this mean for AI [[00:05:24](https://www.youtube.com/watch?v=fySodSi4aUU&t=324.64s)]
*  video? Yeah, I think on the creator front, we've already started to see this explosion of basically, [[00:05:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=330.15999999999997s)]
*  I think what people have called faceless channels. So this idea of now you don't have to put your [[00:05:36](https://www.youtube.com/watch?v=fySodSi4aUU&t=336.24s)]
*  own face behind a camera or on a screen to be able to talk about a topic or film a vlog or something [[00:05:41](https://www.youtube.com/watch?v=fySodSi4aUU&t=341.44s)]
*  like that. You can have a fully AI generated character essentially telling your story or acting [[00:05:47](https://www.youtube.com/watch?v=fySodSi4aUU&t=347.68s)]
*  out your narrative for you, which is huge. And I think people are using it to tell extremely funny [[00:05:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=353.44s)]
*  jokes, have these narrative storylines like Greg, the incompetent storm trooper who's crashing all [[00:05:58](https://www.youtube.com/watch?v=fySodSi4aUU&t=358.96s)]
*  of the missions, things like that that people are getting really invested in. In terms of from the [[00:06:03](https://www.youtube.com/watch?v=fySodSi4aUU&t=363.68s)]
*  model providers and the companies, VO3 is clearly very expensive to run. So I would imagine Google [[00:06:08](https://www.youtube.com/watch?v=fySodSi4aUU&t=368.88s)]
*  will want to train the next model that's even bigger and is able to generate longer videos, [[00:06:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=375.68s)]
*  but will struggle with things like coherence and will also struggle with honestly the pricing of [[00:06:19](https://www.youtube.com/watch?v=fySodSi4aUU&t=379.92s)]
*  the model. Hopefully we'll see more sort of condensed, optimized, distilled models that [[00:06:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=385.12s)]
*  are able to do similar things at a lower cost. Yeah, I'm excited for it. Okay, so there was a [[00:06:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=390.0s)]
*  lot of news last week. So this got kind of lost, but I heard there was a big update to chat GPT's [[00:06:35](https://www.youtube.com/watch?v=fySodSi4aUU&t=395.04s)]
*  advanced voice mode. Yes, they announced it on Saturday, which was an interesting choice. [[00:06:39](https://www.youtube.com/watch?v=fySodSi4aUU&t=399.92s)]
*  We're trying to drop. Yeah, I think they actually dropped the improvements last Thursday or Friday. [[00:06:44](https://www.youtube.com/watch?v=fySodSi4aUU&t=404.16s)]
*  It was first only for all paid users, and now I think it started rolling out across the broader [[00:06:48](https://www.youtube.com/watch?v=fySodSi4aUU&t=408.24s)]
*  user base. But essentially they made advanced voice mode a lot more human. The really interesting [[00:06:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=413.36s)]
*  thing was chat GPT was the first one to do what I would call kind of real-time consumer voice, [[00:06:58](https://www.youtube.com/watch?v=fySodSi4aUU&t=418.96000000000004s)]
*  where you could have like a conversation. And this was like last September in the chat GPT app. [[00:07:03](https://www.youtube.com/watch?v=fySodSi4aUU&t=423.84000000000003s)]
*  But then they didn't really improve the product or the model that much, at least from my perspective. [[00:07:09](https://www.youtube.com/watch?v=fySodSi4aUU&t=429.52s)]
*  And we saw Sesame and other open source providers come out with arguably better and way more human [[00:07:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=435.35999999999996s)]
*  like models. We saw Gemini, we saw Grok launch voice products that were much more realistic. [[00:07:22](https://www.youtube.com/watch?v=fySodSi4aUU&t=442.55999999999995s)]
*  So I think it was kind of a question mark for a lot of people what chat GPT was doing with consumer [[00:07:28](https://www.youtube.com/watch?v=fySodSi4aUU&t=448.4s)]
*  voice. And so what were the what makes it better now? Or what were the main upgrades? We should [[00:07:33](https://www.youtube.com/watch?v=fySodSi4aUU&t=453.2s)]
*  actually just maybe talk to it and see. It's live demo time, folks. Hey, chat GPT, are you there? [[00:07:37](https://www.youtube.com/watch?v=fySodSi4aUU&t=457.2s)]
*  Hey there. Yep. I'm here and ready for the demo. What can I help you with today? [[00:07:45](https://www.youtube.com/watch?v=fySodSi4aUU&t=465.28s)]
*  Did they make some improvements to your voice over the last week? [[00:07:49](https://www.youtube.com/watch?v=fySodSi4aUU&t=469.44s)]
*  Yeah, they did. They've been rolling out some updates to make my voice [[00:07:54](https://www.youtube.com/watch?v=fySodSi4aUU&t=474.08s)]
*  sound more natural and expressive. I'm glad you noticed. [[00:07:58](https://www.youtube.com/watch?v=fySodSi4aUU&t=478.08s)]
*  Yeah, I can hear like your voice maybe in flex upwards when you're approaching a question, [[00:08:02](https://www.youtube.com/watch?v=fySodSi4aUU&t=482.0s)]
*  or sometimes you'll say um or ah or something that sounds like a mistake, [[00:08:06](https://www.youtube.com/watch?v=fySodSi4aUU&t=486.88s)]
*  but actually makes you sound more human. [[00:08:10](https://www.youtube.com/watch?v=fySodSi4aUU&t=490.88s)]
*  Exactly. Those little touches are all intentional to make the conversation feel more natural and [[00:08:14](https://www.youtube.com/watch?v=fySodSi4aUU&t=494.24s)]
*  relatable. It definitely makes things a bit more fun and engaging, I think. [[00:08:19](https://www.youtube.com/watch?v=fySodSi4aUU&t=499.68s)]
*  Very cool. Amazing. Yeah, it's crazy to hear. It's always wild when a voice model like coughs, [[00:08:23](https://www.youtube.com/watch?v=fySodSi4aUU&t=503.52s)]
*  or you know, even funner things like taking on an accent or speaking in another language, [[00:08:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=510.08s)]
*  or things like that. But then also, I think just the pure realism of the voice that that [[00:08:35](https://www.youtube.com/watch?v=fySodSi4aUU&t=515.84s)]
*  demonstrated is also extremely impressive. It's so funny too, because when advanced [[00:08:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=520.48s)]
*  voice mode first came out, my feeling was like, wow, this is amazing. This is incredible. This [[00:08:44](https://www.youtube.com/watch?v=fySodSi4aUU&t=524.8000000000001s)]
*  is so human-like. But then like a month or two later, Notebook LM came out. And that was the [[00:08:49](https://www.youtube.com/watch?v=fySodSi4aUU&t=529.6s)]
*  first real voice experience that put in those ums, ahs, pauses, other things that are so human-like. [[00:08:54](https://www.youtube.com/watch?v=fySodSi4aUU&t=534.5600000000001s)]
*  And it was like a, felt like such a huge upgrade. And then when you use advanced voice mode, you're [[00:09:00](https://www.youtube.com/watch?v=fySodSi4aUU&t=540.5600000000001s)]
*  like, this is not that advanced anymore. And so now it's finally there, which is super exciting. [[00:09:04](https://www.youtube.com/watch?v=fySodSi4aUU&t=544.96s)]
*  So it went from advanced voice mode to basic voice mode to advanced voice mode. [[00:09:09](https://www.youtube.com/watch?v=fySodSi4aUU&t=549.28s)]
*  It's advanced voice mode again. I think one of my questions then has been like, what took them so [[00:09:12](https://www.youtube.com/watch?v=fySodSi4aUU&t=552.56s)]
*  long? Because they're on the cutting edge of so many models. And yet it feels odd to me that it [[00:09:18](https://www.youtube.com/watch?v=fySodSi4aUU&t=558.56s)]
*  took maybe six plus months for them to roll out improvements that we saw from other model companies [[00:09:24](https://www.youtube.com/watch?v=fySodSi4aUU&t=564.24s)]
*  much faster. I honestly think a big part of it might have been when they first released advanced [[00:09:28](https://www.youtube.com/watch?v=fySodSi4aUU&t=568.72s)]
*  voice mode, if you remember all the controversy around her. And was this going to be a companion [[00:09:33](https://www.youtube.com/watch?v=fySodSi4aUU&t=573.84s)]
*  that replaced humans and some of what people would think of as kind of scary implications of that? [[00:09:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=580.4s)]
*  It seemed like that maybe spooked them a little bit. And so they didn't want to put anything out [[00:09:45](https://www.youtube.com/watch?v=fySodSi4aUU&t=585.76s)]
*  there that sounded too human. Yeah. I mean that, and then also, I mean, [[00:09:49](https://www.youtube.com/watch?v=fySodSi4aUU&t=589.52s)]
*  OpenAI has been super busy. This has always, I think, been the question about the frontier, [[00:09:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=593.84s)]
*  largely LLM labs, which is like, how do they balance priorities between the North Star of like [[00:09:58](https://www.youtube.com/watch?v=fySodSi4aUU&t=598.64s)]
*  text-based AGI, then what they're doing in video with Sora, all the image stuff they did, [[00:10:04](https://www.youtube.com/watch?v=fySodSi4aUU&t=604.0s)]
*  which we'll talk about a bit later with the 4.0 image model, reasoning, all of those sorts of [[00:10:08](https://www.youtube.com/watch?v=fySodSi4aUU&t=608.4799999999999s)]
*  things. Yeah, totally. It reminds me a little bit actually of one of the other, I say big tech, [[00:10:13](https://www.youtube.com/watch?v=fySodSi4aUU&t=613.52s)]
*  OpenAI is now big tech in some ways. It counts. But the other big tech consumer update this week, [[00:10:19](https://www.youtube.com/watch?v=fySodSi4aUU&t=619.3599999999999s)]
*  which was the Apple Developer Conference, and all of the things that they announced around AI. [[00:10:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=625.36s)]
*  Or didn't announce. Or didn't announce. And the fact that I think that people have been so far [[00:10:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=630.72s)]
*  somewhat disappointed by Apple Intelligence, which is their bundled set of AI features. [[00:10:34](https://www.youtube.com/watch?v=fySodSi4aUU&t=634.96s)]
*  I think we've all been waiting on like the AI version of Siri or some kind of true personal [[00:10:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=640.24s)]
*  assistant on mobile. Yeah. I asked Siri, so I had this the other day where I asked Siri, [[00:10:45](https://www.youtube.com/watch?v=fySodSi4aUU&t=645.36s)]
*  Okay, tomorrow's Monday, what Monday is it of the month? Because SF Street cleaning, [[00:10:50](https://www.youtube.com/watch?v=fySodSi4aUU&t=650.88s)]
*  I had to know if it was going to be the second Monday of the month. And it said, I can't, [[00:10:56](https://www.youtube.com/watch?v=fySodSi4aUU&t=656.16s)]
*  I don't know that. Can I search ChatGBT for you? And I was like, Siri, how can you not answer this [[00:11:00](https://www.youtube.com/watch?v=fySodSi4aUU&t=660.16s)]
*  basic question? Well, okay, it does seem like from a lot of Apple's updates that they put out, [[00:11:06](https://www.youtube.com/watch?v=fySodSi4aUU&t=666.0s)]
*  they're kind of outsourcing a lot of the true AI features to ChatGBT just running on your phone. [[00:11:10](https://www.youtube.com/watch?v=fySodSi4aUU&t=670.0s)]
*  And I think a similar story, it seemed like when they rolled out those AI powered notification [[00:11:16](https://www.youtube.com/watch?v=fySodSi4aUU&t=676.24s)]
*  summaries, where they would group like three or four sets of notifications into one, and they got [[00:11:21](https://www.youtube.com/watch?v=fySodSi4aUU&t=681.12s)]
*  a little jumbled and people got upset, it seems like that spooked Apple a little bit. And they [[00:11:26](https://www.youtube.com/watch?v=fySodSi4aUU&t=686.0s)]
*  keep kind of retrenching on the timeline of releasing AI Siri. So we'll see what happens. [[00:11:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=690.3199999999999s)]
*  They were, at least in the announcement yesterday, leaning into things like updates to Genmoji and [[00:11:35](https://www.youtube.com/watch?v=fySodSi4aUU&t=695.12s)]
*  call transcription. I think the coolest thing I saw was real time translation of [[00:11:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=700.4s)]
*  calls and FaceTime. Yes, across languages. I've been surprised we haven't seen more on that, [[00:11:44](https://www.youtube.com/watch?v=fySodSi4aUU&t=704.56s)]
*  because that feels like a really natural and obvious use case. Especially, I think Google might [[00:11:55](https://www.youtube.com/watch?v=fySodSi4aUU&t=715.68s)]
*  have done a real time translation, but I haven't seen a ton of adoption yet. I did see for the [[00:12:02](https://www.youtube.com/watch?v=fySodSi4aUU&t=722.0799999999999s)]
*  first time, a viral Gen Z TikTok featuring Genmojis, which I'm surprised it took that long to hit, [[00:12:05](https://www.youtube.com/watch?v=fySodSi4aUU&t=725.92s)]
*  because Gen Z loves Genmojis. Yeah, holding out hope for those to make it really big. [[00:12:12](https://www.youtube.com/watch?v=fySodSi4aUU&t=732.24s)]
*  Yes. Okay, and before we get too far off voice, should we talk about 11v3? [[00:12:16](https://www.youtube.com/watch?v=fySodSi4aUU&t=736.88s)]
*  Yes. So 11 Labs, the text to speech company, actually broader AI voice company, [[00:12:21](https://www.youtube.com/watch?v=fySodSi4aUU&t=741.92s)]
*  released their third generation model called 11v3. [[00:12:27](https://www.youtube.com/watch?v=fySodSi4aUU&t=747.36s)]
*  We're off under the lights here for this semi-final clash, the stadium buzzing with anticipation. [[00:12:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=750.32s)]
*  And what makes 11v3 really special is it does a bunch of stuff with voice that you used to have [[00:12:35](https://www.youtube.com/watch?v=fySodSi4aUU&t=755.36s)]
*  to do via speech to text to speech. So before, if you wanted to have a character that was [[00:12:41](https://www.youtube.com/watch?v=fySodSi4aUU&t=761.44s)]
*  crying while talking or had some sort of emotion or even had a weird inflection, [[00:12:48](https://www.youtube.com/watch?v=fySodSi4aUU&t=768.48s)]
*  you would have to record yourself saying it like that, upload it to 11, and then they would [[00:12:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=773.6800000000001s)]
*  translate it into the AI voice. And now, they essentially take all of the weird inflections, [[00:12:58](https://www.youtube.com/watch?v=fySodSi4aUU&t=778.0s)]
*  emotion, even accents, and they turn it into text prompting through these things called tags. [[00:13:05](https://www.youtube.com/watch?v=fySodSi4aUU&t=785.28s)]
*  So basically, the 11, and I'm sure we'll show this, the 11 interface is an editor where you [[00:13:12](https://www.youtube.com/watch?v=fySodSi4aUU&t=792.16s)]
*  can take a sentence that you want the character to say, you pick your voice, you write your sentence, [[00:13:17](https://www.youtube.com/watch?v=fySodSi4aUU&t=797.92s)]
*  and then you can tag it like sadly or resigned or whispering or something like that. [[00:13:22](https://www.youtube.com/watch?v=fySodSi4aUU&t=802.4s)]
*  And you can do sound effects too, right? That is huge. So actually, should I bring up my example of this? [[00:13:29](https://www.youtube.com/watch?v=fySodSi4aUU&t=809.04s)]
*  Go for it. I don't know if it's going to play or not. Let's see. So this is a 20-second clip I made [[00:13:47](https://www.youtube.com/watch?v=fySodSi4aUU&t=827.1999999999999s)]
*  of two characters talking back and forth. And what's the prompt on it? Oh, it's a text prompt. [[00:13:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=833.1999999999999s)]
*  It'll say, hey, y'all, my name is Austin. I'm coming to you live from our family farm in Fort Worth. [[00:13:58](https://www.youtube.com/watch?v=fySodSi4aUU&t=838.16s)]
*  Then he's going to walk through milking a cow and someone's going to interrupt him. [[00:14:02](https://www.youtube.com/watch?v=fySodSi4aUU&t=842.9599999999999s)]
*  Great. Hey, y'all, my name is Austin. I'm coming to you live from our family farm in Fort Worth. [[00:14:06](https://www.youtube.com/watch?v=fySodSi4aUU&t=846.4s)]
*  Today, I'm going to walk through what it's like. Austin, are you faking an accent again? [[00:14:16](https://www.youtube.com/watch?v=fySodSi4aUU&t=856.24s)]
*  It's not faking. I was born here. And everyone knows you don't talk like that. [[00:14:20](https://www.youtube.com/watch?v=fySodSi4aUU&t=860.3199999999999s)]
*  So my favorite thing about that is it showcases a couple of things about the model. [[00:14:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=865.28s)]
*  It can do bad accents. [[00:14:29](https://www.youtube.com/watch?v=fySodSi4aUU&t=869.4399999999999s)]
*  It can do terrible accents. It can do great accents. That was two different characters. [[00:14:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=870.8s)]
*  At first, I prompted the Austin character of having a thick Texas accent. Then I prompted the cows [[00:14:35](https://www.youtube.com/watch?v=fySodSi4aUU&t=875.76s)]
*  mooing. And then you can also prompt interruptions, which is really cool. So a tag is literally like [[00:14:41](https://www.youtube.com/watch?v=fySodSi4aUU&t=881.84s)]
*  starts talking and gets interrupted. And then the next character that comes in, you can say, [[00:14:48](https://www.youtube.com/watch?v=fySodSi4aUU&t=888.16s)]
*  cuts the other character off. And so for narrative storytelling, for ads, marketing, anything, [[00:14:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=893.44s)]
*  it makes it sound like a natural conversation, which we've never had with AI voice before. [[00:14:59](https://www.youtube.com/watch?v=fySodSi4aUU&t=899.12s)]
*  It feels like between this and VO3, like a world of possibilities has been opened up for [[00:15:03](https://www.youtube.com/watch?v=fySodSi4aUU&t=903.12s)]
*  AI storytelling, especially in video form. [[00:15:08](https://www.youtube.com/watch?v=fySodSi4aUU&t=908.88s)]
*  Yes, it's an exhausting time for AI creatives. It's great, but exhausting because there's just [[00:15:11](https://www.youtube.com/watch?v=fySodSi4aUU&t=911.36s)]
*  way too many fun stuff to test. Any other favorite use cases of this? One that I made was one of those [[00:15:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=915.52s)]
*  car extended warranty videos that you could actually make sound as menacing as they somewhat [[00:15:21](https://www.youtube.com/watch?v=fySodSi4aUU&t=921.52s)]
*  feel. I think Eleven's actually doing a competition now where they're soliciting [[00:15:26](https://www.youtube.com/watch?v=fySodSi4aUU&t=926.8s)]
*  the best examples of people using V3 from all around the world. So I'm going to be very curious [[00:15:31](https://www.youtube.com/watch?v=fySodSi4aUU&t=931.4399999999999s)]
*  to see. We've made all sorts of fun stuff, but how the professional narrative builders and [[00:15:36](https://www.youtube.com/watch?v=fySodSi4aUU&t=936.24s)]
*  storytellers are using it, because I think we've just scratched the surface of what's possible here. [[00:15:41](https://www.youtube.com/watch?v=fySodSi4aUU&t=941.8399999999999s)]
*  Amazing. [[00:15:47](https://www.youtube.com/watch?v=fySodSi4aUU&t=947.4399999999999s)]
*  Okay, so you put out some data last week about AI revenue ramp and how fast companies are growing. [[00:15:48](https://www.youtube.com/watch?v=fySodSi4aUU&t=948.16s)]
*  Let's chat through the main takeaways from that. [[00:15:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=953.6s)]
*  Yeah, so basically the methodology here, or maybe even a backup, the purpose here was, [[00:15:55](https://www.youtube.com/watch?v=fySodSi4aUU&t=955.6s)]
*  I think we all have this idea in mind, or maybe we have that idea because we've heard it a billion [[00:16:01](https://www.youtube.com/watch?v=fySodSi4aUU&t=961.28s)]
*  times that we're in a new era of growth now. Thanks to AI, companies are scaling faster than [[00:16:06](https://www.youtube.com/watch?v=fySodSi4aUU&t=966.56s)]
*  ever before. But my question was, what does that really mean? And how fast is that? Is it [[00:16:11](https://www.youtube.com/watch?v=fySodSi4aUU&t=971.76s)]
*  20% faster? Is it 50% faster than what we saw pre-AI? So we are blessed to get to meet tons [[00:16:17](https://www.youtube.com/watch?v=fySodSi4aUU&t=977.28s)]
*  of companies here every day. We meet dozens of companies a week. So we went back and essentially [[00:16:23](https://www.youtube.com/watch?v=fySodSi4aUU&t=983.8399999999999s)]
*  just pulled all the data from companies we've met in the gen AI era, which I would say is the last [[00:16:28](https://www.youtube.com/watch?v=fySodSi4aUU&t=988.48s)]
*  22 to 24 months. And we looked at once they started monetizing, how fast are they growing? [[00:16:34](https://www.youtube.com/watch?v=fySodSi4aUU&t=994.0s)]
*  I would say pre-AI, if you're a B2B startup selling to enterprises, if you got to a million [[00:16:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=1000.9599999999999s)]
*  dollars in ARR in the first year, that's like amazing, best in class. That was like the rule [[00:16:46](https://www.youtube.com/watch?v=fySodSi4aUU&t=1006.48s)]
*  of thumb. I remember that it's the known metric. Very exciting. If you were a consumer startup, [[00:16:51](https://www.youtube.com/watch?v=fySodSi4aUU&t=1011.6800000000001s)]
*  you would not make money for three, five years, maybe longer. The whole idea was to build up a [[00:16:56](https://www.youtube.com/watch?v=fySodSi4aUU&t=1016.24s)]
*  user base and then probably monetize them directly via ads. Or transactions for like a marketplace, [[00:17:03](https://www.youtube.com/watch?v=fySodSi4aUU&t=1023.28s)]
*  maybe. Yes, down the line. And there were counter examples to that, some subscription companies, [[00:17:10](https://www.youtube.com/watch?v=fySodSi4aUU&t=1030.0s)]
*  but that was definitely not the dominant model. That has fully shifted in the AI era. And most [[00:17:14](https://www.youtube.com/watch?v=fySodSi4aUU&t=1034.0s)]
*  companies are now making money directly from consumers via subscription. What we found was [[00:17:19](https://www.youtube.com/watch?v=fySodSi4aUU&t=1039.76s)]
*  actually pretty surprising, which is that the median ARR, annualized revenue run rate, is now [[00:17:24](https://www.youtube.com/watch?v=fySodSi4aUU&t=1044.96s)]
*  $4.2 million at month 12 for consumer startups. The bottom quartile is 2.9 million. And the top [[00:17:31](https://www.youtube.com/watch?v=fySodSi4aUU&t=1051.04s)]
*  quartile is 8.7 million. So like a median company, median B2C company in the age of AI [[00:17:39](https://www.youtube.com/watch?v=fySodSi4aUU&t=1059.6s)]
*  is getting to 4 million ARR after a year. And the best in class companies are getting to 8 million [[00:17:46](https://www.youtube.com/watch?v=fySodSi4aUU&t=1066.7199999999998s)]
*  in a year. Upwards of 8, almost 9. In the pre-AI era, we never would have seen anything like that. [[00:17:51](https://www.youtube.com/watch?v=fySodSi4aUU&t=1071.84s)]
*  And the even more surprising thing is those numbers are twice as high as the B2B benchmarks [[00:17:57](https://www.youtube.com/watch?v=fySodSi4aUU&t=1077.1999999999998s)]
*  in the AI era. So consumer companies are actually ramping revenue faster, which again is like a total [[00:18:03](https://www.youtube.com/watch?v=fySodSi4aUU&t=1083.12s)]
*  reversal from what we saw before. I think there is a couple reasons why this was happening. First, [[00:18:09](https://www.youtube.com/watch?v=fySodSi4aUU&t=1089.2s)]
*  it's like why have consumer AI companies adopted subscription? They were kind of forced to, [[00:18:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=1095.3600000000001s)]
*  because especially in the early era of models, they were so expensive that you as a company [[00:18:20](https://www.youtube.com/watch?v=fySodSi4aUU&t=1100.88s)]
*  had pretty high costs of goods sold. The inference costs, you mean, of running the model. [[00:18:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=1105.8400000000001s)]
*  Historically, software, the benefit was like there was no marginal cost. So you made an app, [[00:18:31](https://www.youtube.com/watch?v=fySodSi4aUU&t=1111.2s)]
*  there's no additional cost to serving the next user. In AI, that is actually not true at all. [[00:18:35](https://www.youtube.com/watch?v=fySodSi4aUU&t=1115.84s)]
*  If you're running inference on a model, it costs you cents, maybe even dollars for each query. [[00:18:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=1120.8799999999999s)]
*  So each user could be costing you dozens of dollars a month. [[00:18:47](https://www.youtube.com/watch?v=fySodSi4aUU&t=1127.76s)]
*  Yeah, absolutely. So a lot of companies had to at least try to charge. And it turns out that these [[00:18:50](https://www.youtube.com/watch?v=fySodSi4aUU&t=1130.6399999999999s)]
*  new products that are AI native are so powerful that consumers are willing to pay. So we also ran [[00:18:55](https://www.youtube.com/watch?v=fySodSi4aUU&t=1135.76s)]
*  some additional data analysis that shows that on average, consumer AI startups are charging [[00:19:00](https://www.youtube.com/watch?v=fySodSi4aUU&t=1140.96s)]
*  $22 a month across the average user, which again is like more than double what they were able to [[00:19:08](https://www.youtube.com/watch?v=fySodSi4aUU&t=1148.32s)]
*  charge pre-AI for subscription companies on average. And why do we think, do we have theories? [[00:19:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=1155.1200000000001s)]
*  I mean, on the creative tool side, what I've seen is like for people who weren't creative, [[00:19:20](https://www.youtube.com/watch?v=fySodSi4aUU&t=1160.8s)]
*  AI tools allow them, like I can make photos or images or art for the first time. I can make [[00:19:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=1165.92s)]
*  videos, I can make animations. And then for creative people, like we have a cousin who's [[00:19:31](https://www.youtube.com/watch?v=fySodSi4aUU&t=1171.76s)]
*  a creative, they can genuinely use this to supercharge their workflows and do their job [[00:19:36](https://www.youtube.com/watch?v=fySodSi4aUU&t=1176.16s)]
*  a lot faster. So they're willing to pay for it. Have we seen examples of that outside of creative [[00:19:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=1180.8799999999999s)]
*  tools yet? It's a good question. We've seen some of it around companion apps, I would say. [[00:19:45](https://www.youtube.com/watch?v=fySodSi4aUU&t=1185.68s)]
*  Where again, the products are just so powerful to have a friend with you 24-7, [[00:19:50](https://www.youtube.com/watch?v=fySodSi4aUU&t=1190.4s)]
*  that people are excited to pay. We've also seen this around categories like language learning, [[00:19:54](https://www.youtube.com/watch?v=fySodSi4aUU&t=1194.72s)]
*  teaching your kid how to read, other things that previously you'd have to pay a human being, [[00:20:00](https://www.youtube.com/watch?v=fySodSi4aUU&t=1200.24s)]
*  I don't know, $50 an hour, if that, to get access to, that now $22 a month with AI feels pretty cheap. [[00:20:04](https://www.youtube.com/watch?v=fySodSi4aUU&t=1204.64s)]
*  Totally. I mean, I'm even thinking some of the things I've seen monetized while are in like [[00:20:11](https://www.youtube.com/watch?v=fySodSi4aUU&t=1211.44s)]
*  nutrition or coaching, where for the first time, thanks to vision models, you can take a picture [[00:20:16](https://www.youtube.com/watch?v=fySodSi4aUU&t=1216.0s)]
*  of what you're eating and have a vision model pull out how many calories are in this, how much [[00:20:20](https://www.youtube.com/watch?v=fySodSi4aUU&t=1220.4s)]
*  protein, and then at the end of a day or week can summarize insights about what you should be eating [[00:20:24](https://www.youtube.com/watch?v=fySodSi4aUU&t=1224.96s)]
*  more or less of, which is something that pre-AI people, like, I don't know, you could take a [[00:20:29](https://www.youtube.com/watch?v=fySodSi4aUU&t=1229.84s)]
*  picture and upload it to a forum, but like, it was not a question. Or you'd have to find a nutritionist, [[00:20:35](https://www.youtube.com/watch?v=fySodSi4aUU&t=1235.36s)]
*  wait weeks to book an appointment, maybe get a referral from your doctor, like it would take [[00:20:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=1240.08s)]
*  forever. So it's really exciting. I think it's monetizing people who never would have paid for [[00:20:43](https://www.youtube.com/watch?v=fySodSi4aUU&t=1243.68s)]
*  that before. Yes. [[00:20:48](https://www.youtube.com/watch?v=fySodSi4aUU&t=1248.0800000000002s)]
*  And then people who would have paid for it are switching over to the AI version or they're willing [[00:20:49](https://www.youtube.com/watch?v=fySodSi4aUU&t=1249.28s)]
*  to pay even more, which is super exciting. The other thing that I think people have questions [[00:20:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=1253.3600000000001s)]
*  about is, or maybe doubts about, would be like, okay, great, they're growing fast, but they're [[00:20:57](https://www.youtube.com/watch?v=fySodSi4aUU&t=1257.76s)]
*  not retaining a lot of users. Right. [[00:21:02](https://www.youtube.com/watch?v=fySodSi4aUU&t=1262.96s)]
*  We did some analysis on this too. There's definitely a lot of tourism, we call it AI tourism [[00:21:05](https://www.youtube.com/watch?v=fySodSi4aUU&t=1265.2s)]
*  behavior in terms of free users, which means you get a lot of hits on your website, essentially, [[00:21:10](https://www.youtube.com/watch?v=fySodSi4aUU&t=1270.24s)]
*  and most of those users don't stick around. But if you look at it on a paid user basis, [[00:21:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=1275.28s)]
*  so once you actually subscribe, consumer AI companies are retaining at the median pretty [[00:21:19](https://www.youtube.com/watch?v=fySodSi4aUU&t=1279.84s)]
*  much just as well as pre-AI consumer companies, which is really exciting. [[00:21:24](https://www.youtube.com/watch?v=fySodSi4aUU&t=1284.32s)]
*  I feel like what we've seen, especially on revenue retention, which is fascinating, is like, [[00:21:28](https://www.youtube.com/watch?v=fySodSi4aUU&t=1288.32s)]
*  you might have more tourists, so you might have more people who subscribe and then cancel, [[00:21:32](https://www.youtube.com/watch?v=fySodSi4aUU&t=1292.8s)]
*  but then for the first time, you have like real sort of upsell activity in consumer subscriptions, [[00:21:37](https://www.youtube.com/watch?v=fySodSi4aUU&t=1297.04s)]
*  whereas like, you know, you're not just paying $10 a month for the app, you're paying $10 a month [[00:21:43](https://www.youtube.com/watch?v=fySodSi4aUU&t=1303.04s)]
*  for the image model, but then if you love it and you run out of credits, you're paying another $10, [[00:21:48](https://www.youtube.com/watch?v=fySodSi4aUU&t=1308.96s)]
*  $12, $50 for additional credit packs before the next month of your subscription starts. [[00:21:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=1313.92s)]
*  Yes. And so that means [[00:21:59](https://www.youtube.com/watch?v=fySodSi4aUU&t=1319.36s)]
*  you see revenue expansion opportunity now in consumer that we only used to see in enterprise. [[00:22:01](https://www.youtube.com/watch?v=fySodSi4aUU&t=1321.12s)]
*  Or honestly in games, what they call like monetizing the whales, the people who were [[00:22:07](https://www.youtube.com/watch?v=fySodSi4aUU&t=1327.1200000000001s)]
*  the really high spenders, which is to me one of the most exciting things about consumer AI [[00:22:11](https://www.youtube.com/watch?v=fySodSi4aUU&t=1331.52s)]
*  products right now. Yeah. And we're seeing, I would say, [[00:22:16](https://www.youtube.com/watch?v=fySodSi4aUU&t=1336.48s)]
*  companies convert consumer revenue to enterprise revenue way faster than they ever did before. [[00:22:19](https://www.youtube.com/watch?v=fySodSi4aUU&t=1339.44s)]
*  Like companies like Canva previously took five, six, seven plus years to really move from consumer [[00:22:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=1345.1200000000001s)]
*  prosumer to enterprise. And now we're seeing companies like 11 Labs is a great example [[00:22:31](https://www.youtube.com/watch?v=fySodSi4aUU&t=1351.84s)]
*  where someone might start using it as a $10 a month plan to make their own fun videos at home. [[00:22:36](https://www.youtube.com/watch?v=fySodSi4aUU&t=1356.8s)]
*  And then turns out they work at some big entertainment company and they bring it [[00:22:42](https://www.youtube.com/watch?v=fySodSi4aUU&t=1362.08s)]
*  in there to work and then they convert to a really high ACB enterprise contract, [[00:22:46](https://www.youtube.com/watch?v=fySodSi4aUU&t=1366.3999999999999s)]
*  which is super exciting. I mean, I feel like we even saw that in the very early days of consumer AI. [[00:22:50](https://www.youtube.com/watch?v=fySodSi4aUU&t=1370.0s)]
*  I remember our friends in at ad agencies or entertainment companies would tell us that they [[00:22:54](https://www.youtube.com/watch?v=fySodSi4aUU&t=1374.72s)]
*  were using mid-journey to mock things up or even using the images in their final work products. [[00:22:59](https://www.youtube.com/watch?v=fySodSi4aUU&t=1379.36s)]
*  So it was like a true enterprise use case, but growing bottoms up, [[00:23:05](https://www.youtube.com/watch?v=fySodSi4aUU&t=1385.4399999999998s)]
*  which is sort of a fascinating motion. Yeah. It's exciting. Consumers back. [[00:23:09](https://www.youtube.com/watch?v=fySodSi4aUU&t=1389.84s)]
*  All right. Awesome. We're moving on to our demo of the week. So one fun fact about us is that we [[00:23:14](https://www.youtube.com/watch?v=fySodSi4aUU&t=1394.24s)]
*  genuinely love, like at least for me, it's probably my number one hobby now, trying out all of the AI [[00:23:20](https://www.youtube.com/watch?v=fySodSi4aUU&t=1400.24s)]
*  creative tools, especially, but also AI, like consumer products more broadly, [[00:23:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=1405.76s)]
*  figuring out how to make cool things and then sharing the workflows to other people whose [[00:23:30](https://www.youtube.com/watch?v=fySodSi4aUU&t=1410.8s)]
*  number one hobby is not doing this. So this week we are going to talk about brand creation and [[00:23:34](https://www.youtube.com/watch?v=fySodSi4aUU&t=1414.8799999999999s)]
*  ideation using AI. I made this new frozen yogurt brand called Melt that I iterated on with ChatGPT. [[00:23:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=1420.64s)]
*  Then I took to ideogram and then I took to CREA to kind of do the final touches and to make these [[00:23:48](https://www.youtube.com/watch?v=fySodSi4aUU&t=1428.64s)]
*  really cool product photos and even store photos. Yeah. And I think that the initial idea about this [[00:23:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=1433.92s)]
*  was seeing Flux Context come out, which is the new image editing model from Black Forest Labs, [[00:23:59](https://www.youtube.com/watch?v=fySodSi4aUU&t=1439.92s)]
*  which is hosted on CREA. And Flux Context, you can kind of think of it like the GPT-40 image model, [[00:24:05](https://www.youtube.com/watch?v=fySodSi4aUU&t=1445.3600000000001s)]
*  where you can upload an image and then you can say, you know, make this Ghibli style was the [[00:24:13](https://www.youtube.com/watch?v=fySodSi4aUU&t=1453.04s)]
*  viral example. You can also say like, take the person from this photo and put them in a new [[00:24:19](https://www.youtube.com/watch?v=fySodSi4aUU&t=1459.04s)]
*  environment or, you know, take the logo and change it slightly. Yeah. Add or remove objects. [[00:24:23](https://www.youtube.com/watch?v=fySodSi4aUU&t=1463.92s)]
*  I've seen it described as kind of like Photoshop, but with natural language prompts. Yes. Like you [[00:24:29](https://www.youtube.com/watch?v=fySodSi4aUU&t=1469.28s)]
*  can edit with words for the first time. And that's, I think that is what makes it different than the [[00:24:34](https://www.youtube.com/watch?v=fySodSi4aUU&t=1474.48s)]
*  40 image model, which is the consistency to which it retains the item or the character or whatever [[00:24:39](https://www.youtube.com/watch?v=fySodSi4aUU&t=1479.28s)]
*  is much, much better. We'll show some examples here. But basically, if you're taking a photo [[00:24:46](https://www.youtube.com/watch?v=fySodSi4aUU&t=1486.72s)]
*  of yourself and uploading it to GPT-40 and saying like, put me in a podcast studio, [[00:24:51](https://www.youtube.com/watch?v=fySodSi4aUU&t=1491.76s)]
*  you will likely end up looking completely different in the new photo than you did in [[00:24:56](https://www.youtube.com/watch?v=fySodSi4aUU&t=1496.48s)]
*  the initial photo or maybe some similar features, but quite different. Whereas this model does an [[00:25:00](https://www.youtube.com/watch?v=fySodSi4aUU&t=1500.08s)]
*  amazing job at maintaining consistency. And so that sparked this idea for me of like, oh, that [[00:25:04](https://www.youtube.com/watch?v=fySodSi4aUU&t=1504.8s)]
*  means that this can actually be used for like brands, new product photos or other sorts of [[00:25:10](https://www.youtube.com/watch?v=fySodSi4aUU&t=1510.0s)]
*  marketing collateral because the logos and the products can be consistent. Awesome. And you know, [[00:25:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=1515.12s)]
*  I'm a huge Froyo fan. I feel like Froyo has gotten an unfair shake in recent years. It's kind of seen [[00:25:20](https://www.youtube.com/watch?v=fySodSi4aUU&t=1520.4799999999998s)]
*  as the little kid thing. And so I wanted to make like a cool, hip, modern, 20s New York Froyo brand. [[00:25:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=1525.84s)]
*  Okay. I went back and forth with ChatGPT on this idea to land on the name Melt, which I love, [[00:25:33](https://www.youtube.com/watch?v=fySodSi4aUU&t=1533.6s)]
*  and to land on the branding of like, this is sort of what the font of the logo will look like. [[00:25:40](https://www.youtube.com/watch?v=fySodSi4aUU&t=1540.8799999999999s)]
*  And then this is the color of the packaging. And then I took that prompt for the logo to ideogram, [[00:25:45](https://www.youtube.com/watch?v=fySodSi4aUU&t=1545.9199999999998s)]
*  which is an image generation and sort of editing canvas. And it's super good, I think, at logos, [[00:25:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=1553.28s)]
*  typography, anything sort of product or word related. And I had it generate sort of this [[00:25:59](https://www.youtube.com/watch?v=fySodSi4aUU&t=1559.4399999999998s)]
*  photo of this Froyo cup that is floating in the air with the Melt logo and branding. [[00:26:06](https://www.youtube.com/watch?v=fySodSi4aUU&t=1566.08s)]
*  Yep. Then I downloaded that photo and I took it to CREA, where I used the Flux Context [[00:26:11](https://www.youtube.com/watch?v=fySodSi4aUU&t=1571.4399999999998s)]
*  new editing model to run all different kinds of scenarios. So what's really cool about that is [[00:26:18](https://www.youtube.com/watch?v=fySodSi4aUU&t=1578.08s)]
*  you can upload the photo and then you can say, take this Froyo and put it sitting on a counter [[00:26:23](https://www.youtube.com/watch?v=fySodSi4aUU&t=1583.84s)]
*  at a trendy restaurant. Put it in the hand of a woman at a park. Or even make the Froyo cup [[00:26:29](https://www.youtube.com/watch?v=fySodSi4aUU&t=1589.92s)]
*  instead of blue, make it white and give it a pink border. Make the Froyo itself purple if they're [[00:26:36](https://www.youtube.com/watch?v=fySodSi4aUU&t=1596.3200000000002s)]
*  having like an Ube Froyo special. And then I think the next step, which I didn't do here, [[00:26:41](https://www.youtube.com/watch?v=fySodSi4aUU&t=1601.2s)]
*  I kind of stopped at the product images. And I actually made an image of the store too. I [[00:26:47](https://www.youtube.com/watch?v=fySodSi4aUU&t=1607.28s)]
*  took the logo and I superimposed it over the store I generated. I know it's like, you want to go there. [[00:26:51](https://www.youtube.com/watch?v=fySodSi4aUU&t=1611.92s)]
*  But the next step even further would be video. So my idea is to take all of those sort of product [[00:26:57](https://www.youtube.com/watch?v=fySodSi4aUU&t=1617.68s)]
*  shots, take it to VO3 or Higgs Field, which does really cool special effects stuff, and have the [[00:27:03](https://www.youtube.com/watch?v=fySodSi4aUU&t=1623.44s)]
*  Froyo cup in action. See how good the model- And have it actually melting over the side. [[00:27:09](https://www.youtube.com/watch?v=fySodSi4aUU&t=1629.84s)]
*  Have it melt. It has to melt. I'm very curious to see, do the models understand the physics of Froyo? [[00:27:13](https://www.youtube.com/watch?v=fySodSi4aUU&t=1633.52s)]
*  Like if it tosses the cup in the air, how does the Froyo land? Does it kind of plop? Like we all know [[00:27:19](https://www.youtube.com/watch?v=fySodSi4aUU&t=1639.52s)]
*  Froyo would in real life. And obviously this was just like a fun experiment for me. I'm not, [[00:27:26](https://www.youtube.com/watch?v=fySodSi4aUU&t=1646.16s)]
*  unfortunately, actually going to be starting a Froyo brand. But it sort of makes you start thinking [[00:27:32](https://www.youtube.com/watch?v=fySodSi4aUU&t=1652.3200000000002s)]
*  about like, why, if you work at an ad agency, for example, and you were mocking up a deck for your [[00:27:36](https://www.youtube.com/watch?v=fySodSi4aUU&t=1656.88s)]
*  client about your latest campaign, why would you not use something like this to show them what it [[00:27:42](https://www.youtube.com/watch?v=fySodSi4aUU&t=1662.4s)]
*  might look like? And you did it in, I mean, less than a couple hours. And honestly, the branding [[00:27:47](https://www.youtube.com/watch?v=fySodSi4aUU&t=1667.2s)]
*  does look more exciting than a lot of kind of professional brands that we see out there. [[00:27:51](https://www.youtube.com/watch?v=fySodSi4aUU&t=1671.28s)]
*  Totally. And so it makes me think about like the next generation of entrepreneurs, like, [[00:27:56](https://www.youtube.com/watch?v=fySodSi4aUU&t=1676.8s)]
*  are going to be completely AI assisted in a lot of these assets that they're putting together. [[00:28:01](https://www.youtube.com/watch?v=fySodSi4aUU&t=1681.52s)]
*  And I think they're going to be able to make full stack AI brands. Like there's also products where [[00:28:07](https://www.youtube.com/watch?v=fySodSi4aUU&t=1687.2s)]
*  you can design with AI. You can make ads with AI. Like we're going to, I think there'll be no reason [[00:28:10](https://www.youtube.com/watch?v=fySodSi4aUU&t=1690.96s)]
*  for any person not to have their own product line, small business, open a store if they want to. [[00:28:17](https://www.youtube.com/watch?v=fySodSi4aUU&t=1697.44s)]
*  Like AI is assisting with these kinds of things too. [[00:28:22](https://www.youtube.com/watch?v=fySodSi4aUU&t=1702.88s)]
*  Totally. Yeah. I think we'll see brands that are like logo, product photo, maybe even product itself [[00:28:25](https://www.youtube.com/watch?v=fySodSi4aUU&t=1705.76s)]
*  designed by AI, vibe coded slash vibe designed website or mobile app, and then kind of drop ship [[00:28:31](https://www.youtube.com/watch?v=fySodSi4aUU&t=1711.2s)]
*  to the end consumer. Social media ads also generated with an AI and avatar that holds it up for you and [[00:28:38](https://www.youtube.com/watch?v=fySodSi4aUU&t=1718.0s)]
*  sells it on Tik Tok. Yeah, it's promoted by AI influencers who are VO3. They don't actually [[00:28:43](https://www.youtube.com/watch?v=fySodSi4aUU&t=1723.84s)]
*  exist. I think that sort of thing is going to be really fascinating to see because it kind of, [[00:28:48](https://www.youtube.com/watch?v=fySodSi4aUU&t=1728.56s)]
*  like, you no longer have to know how to work all of these technical tools that you had to be able [[00:28:53](https://www.youtube.com/watch?v=fySodSi4aUU&t=1733.76s)]
*  to use. Like even Photoshop, there's so many buttons. It's like very complicated. And now [[00:29:00](https://www.youtube.com/watch?v=fySodSi4aUU&t=1740.3999999999999s)]
*  you can just ask for what you want in a text prompt, get something generated and iterate on [[00:29:05](https://www.youtube.com/watch?v=fySodSi4aUU&t=1745.6s)]
*  it until you end up with something that you really love, which I think is crazy powerful. [[00:29:10](https://www.youtube.com/watch?v=fySodSi4aUU&t=1750.8s)]
*  Awesome. [[00:29:15](https://www.youtube.com/watch?v=fySodSi4aUU&t=1755.12s)]
