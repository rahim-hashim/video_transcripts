---
Date Generated: June 07, 2025
Transcription Model: whisper medium 20231117
Length: 3820s
Video Keywords: ['Ben Buchanan', 'Ezra Klein', 'Artificial Intelligence', 'OpenAI', 'Anthropic', 'DeepSeek', 'AI', 'Elon Musk', 'Marc Andreessen', 'Joe Biden', 'National Security']
Video Views: 719758
Video Rating: None
Video Description: Artificial general intelligence — an A.I. system that can beat humans at almost any cognitive task – is arriving in just a couple of years. That’s what people tell me — people who work in A.I. labs, researchers who follow their work, former White House officials. A lot of these people have been calling me over the last couple of months trying to convey the urgency. This is coming during President Trump’s term, they tell me. We’re not ready.
One of the people who reached out to me was Ben Buchanan, the top adviser on A.I. in the Biden White House.  And I thought it would be interesting to have him on the show for a couple reasons: He’s not connected to an A.I. lab, and he was at the nerve center of policymaking on A.I. for years. So what does he see coming? What keeps him up at night? And what does he think the Trump administration needs to do to get ready for the A.G.I. – or something like A.G.I. - he believes is right on the horizon? 
0:00 Intro
1:44 Artificial General Intelligence
3:40 Labor market impact
5:58 Race against China
28:17 A.I. safety vs. AI accelerationism
45:58 A.I. in the federal government
49:46 Making A.I. pro-worker
59:03 The need for better A.I. policy
1:01:46 Book recommendations
Read the full transcript here: https://www.nytimes.com/2025/03/04/opinion/ezra-klein-podcast-ben-buchanan.html
Watch more on @EzraKleinShow 
Thoughts? Guest suggestions? Email us at ezrakleinshow@nytimes.com.
You can find transcripts (posted midday) and more episodes of “The Ezra Klein Show” at nytimes.com/ezra-klein-podcast. Book recommendations from all our guests are listed at https://www.nytimes.com/article/ezra-klein-show-book-recs.
---

# The Government Knows AGI is Coming | The Ezra Klein Show
**New York Times - Ezra Klein:** [March 04, 2025](https://www.youtube.com/watch?v=Btos-LEYQ30)
*  For the past couple of months, I've been having this strange experience where person after person, [[00:00:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=0.0s)]
*  independent of each other, from AI labs, from government, has been coming to me and saying, [[00:00:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=6.88s)]
*  it's really about to happen. [[00:00:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=12.48s)]
*  Artificial general intelligence. [[00:00:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=14.56s)]
*  AGI. [[00:00:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=16.4s)]
*  AGI. [[00:00:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=17.2s)]
*  AGI. [[00:00:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=17.68s)]
*  That is really the holy grail of AI. [[00:00:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=18.16s)]
*  AI systems that are better than almost all humans at almost all tasks. [[00:00:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=20.64s)]
*  And before they thought, you know, may it take five or 10 years, 10 or 15 years. [[00:00:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=25.04s)]
*  Now they believe it's coming inside of two to three years. [[00:00:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=28.8s)]
*  A lot of people don't realize that AI is going to be a big thing. [[00:00:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=32.0s)]
*  Inside Donald Trump's second term. [[00:00:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=35.04s)]
*  And I think they're right. [[00:00:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=37.120000000000005s)]
*  And we're not prepared in part because it's not clear what it would mean to prepare. [[00:00:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=38.64s)]
*  We don't know how labor markets will respond. [[00:00:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=42.24s)]
*  We don't know which country is going to get there first. [[00:00:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=44.24s)]
*  We don't know what it will mean for war. [[00:00:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=46.32s)]
*  We don't know what it'll mean for peace. [[00:00:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=48.08s)]
*  And as much as there is so much else going on in the world to cover, [[00:00:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=49.84s)]
*  I do think there's a good chance that when we look back on this era in human history, [[00:00:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=53.519999999999996s)]
*  this will have been the thing that matters. [[00:00:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=56.480000000000004s)]
*  This will have been the event horizon. [[00:00:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=58.32s)]
*  The thing that the world before it and the world after it were just different worlds. [[00:00:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=59.84s)]
*  One of the people who reached out to me is Ben Buchanan, [[00:01:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=64.88s)]
*  who was the former special advisor for artificial intelligence in the Biden White House. [[00:01:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=66.72s)]
*  He was at the nerve center of what policy we have been making in recent years. [[00:01:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=71.92s)]
*  But there's now been a profound changeover in administrations. [[00:01:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=76.16s)]
*  And the new administration had a lot of people very, very, very strong views on AI. [[00:01:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=80.08s)]
*  So what are they going to do? [[00:01:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=84.24000000000001s)]
*  What kinds of decisions are going to need to be made? [[00:01:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=85.03999999999999s)]
*  And what kinds of thinking do we need to start doing now to be prepared for something that [[00:01:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=87.84s)]
*  virtually everybody who works in this area is trying to tell us as loudly as they possibly can [[00:01:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=92.88s)]
*  is coming? [[00:01:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=98.4s)]
*  As always, my email, esreclinejoe at NYTimes.com. [[00:01:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=99.6s)]
*  Ben Buchanan, welcome to the show. [[00:01:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=107.92s)]
*  Thanks for having me. [[00:01:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=109.28s)]
*  So you give me a call after the end of the Biden administration. [[00:01:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=110.56s)]
*  And I got a call from a lot of people in the Biden administration who wanted to tell me about all [[00:01:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=113.6s)]
*  the great work they did. [[00:01:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=116.72s)]
*  And you sort of seem to want to warn people about what you now thought was coming. [[00:01:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=118.96s)]
*  What's coming? [[00:02:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=124.32s)]
*  I think we're going to see extraordinarily capable AI systems. [[00:02:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=125.44s)]
*  I don't love the term artificial general intelligence, but I think that will fit [[00:02:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=127.76s)]
*  in the next couple of years, quite likely during Donald Trump's presidency. [[00:02:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=131.68s)]
*  And I think there's a view that this has always been something of corporate hype or speculation. [[00:02:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=136.16s)]
*  And I think one of the things I saw in the White House when I was decidedly not in a [[00:02:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=142.07999999999998s)]
*  corporate position was trend lines that looked very clear. [[00:02:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=145.52s)]
*  And what we tried to do under the president's leadership was get the U.S. [[00:02:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=148.96s)]
*  government, our society ready for these systems. [[00:02:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=152.8s)]
*  Before we get into what it would mean to get ready, what does it mean? [[00:02:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=155.12s)]
*  When you say extraordinarily capable systems, capable of what? [[00:02:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=161.28s)]
*  The sort of canonical definition of AGI, which again is a term I don't love, is a system. [[00:02:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=165.60000000000002s)]
*  It'll be good if every time you say AGI, you caveat that you dislike the terms. [[00:02:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=170.0s)]
*  It'll sink in. [[00:02:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=173.44s)]
*  Yeah, people really enjoy that. [[00:02:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=174.0s)]
*  I'm trying to get it in the training data as well. [[00:02:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=175.36s)]
*  A canonical definition of AGI is a system capable of doing almost any cognitive task [[00:02:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=179.36s)]
*  a human can do. [[00:03:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=184.16s)]
*  I don't know that we'll quite see that in the next four years or so, but I do think we'll see [[00:03:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=186.16s)]
*  something like that where the breadth of the system is remarkable, but also its depth, [[00:03:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=190.08s)]
*  its capacity to go and really push, in some cases, exceed human capabilities, [[00:03:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=194.64000000000001s)]
*  kind of regardless of the cognitive discipline. [[00:03:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=199.28s)]
*  Systems that can replace human beings in cognitively demanding jobs. [[00:03:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=201.44s)]
*  Yeah, or key parts of cognitively demanding jobs, yeah. [[00:03:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=206.24s)]
*  I will say I am also pretty convinced we're on the cusp of this. [[00:03:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=208.8s)]
*  So I'm not coming at this as a skeptic, but I still find it hard to mentally live in the world of it. [[00:03:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=213.44s)]
*  So do I. [[00:03:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=220.96s)]
*  So I used Deep Research recently, which is a new open eye product. [[00:03:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=222.16s)]
*  It's sort of on their more pricey tier, so most people I think have not used it, [[00:03:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=225.76s)]
*  but it can build out something that's more like a scientific analytical brief in a matter of [[00:03:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=228.96s)]
*  minutes. [[00:03:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=233.92000000000002s)]
*  And I work with producers on the show. [[00:03:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=234.64000000000001s)]
*  I hire incredibly talented people to do very demanding research work. [[00:03:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=237.60000000000002s)]
*  And I asked it to do this report on the tensions between the Madisonian constitutional system [[00:04:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=241.36s)]
*  and the sort of highly polarized nationalized parties we now have. [[00:04:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=248.72s)]
*  And what it produced in a matter of minutes was, I would at least say, the median. [[00:04:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=253.04000000000002s)]
*  Of what any of the teams I've worked with on this could produce within days. [[00:04:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=258.96s)]
*  I've talked to a number of people at firms that do high amounts of coding, and they tell me that [[00:04:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=263.76s)]
*  by the end of the year, by the end of next year, they expect most code will not be written by human beings. [[00:04:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=269.28s)]
*  I don't really see how this cannot have labor market impact. [[00:04:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=274.96s)]
*  I think that's right. [[00:04:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=278.71999999999997s)]
*  I'm not a labor market economist, but I think that the systems are extraordinarily capable. [[00:04:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=279.76s)]
*  And sometimes I'm very fond of the quote from William Gibson, the future is already here. [[00:04:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=286.0s)]
*  It's just unevenly distributed. [[00:04:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=290.32s)]
*  And I think unless you are engaging with this technology, you probably don't appreciate how [[00:04:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=291.84s)]
*  good it is today. [[00:04:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=295.84s)]
*  And then it's important to recognize today is the worst it's ever going to be. [[00:04:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=297.12s)]
*  It's only going to get better. [[00:05:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=300.56s)]
*  And I think that is the dynamic that in the White House we were tracking and that, again, [[00:05:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=302.4s)]
*  the next White House and our country as a whole is going to have to track and adapt to in really [[00:05:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=309.12s)]
*  short order. [[00:05:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=314.56s)]
*  And what's fascinating to me, where I think is in some sense the intellectual through line for [[00:05:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=315.2s)]
*  almost every AI policy we considered or implemented, is that this is the first [[00:05:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=319.76s)]
*  revolutionary technology that is not funded by the Department of Defense, basically. [[00:05:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=324.64s)]
*  And if you go back historically, last 100 years or so, nukes, space, early days of the internet, [[00:05:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=329.59999999999997s)]
*  early days of the microprocessor, early days of large scale aviation, radar, GPS, the list is very, [[00:05:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=334.8s)]
*  very long. [[00:05:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=339.52s)]
*  All of that tech is fundamentally comes from DOD money. [[00:05:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=340.56s)]
*  But the central government role gave the Department of Defense and the US government an [[00:05:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=344.4s)]
*  understanding of the technology that by default it does not have an AI and also gave the US [[00:05:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=349.52s)]
*  government a capacity to shape where that technology goes that by default we don't have an AI. [[00:05:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=354.8s)]
*  There are a lot of arguments in America about AI. [[00:05:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=358.88s)]
*  The one thing that seems not to get argued over that seems almost universally agreed upon and is [[00:06:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=361.44s)]
*  the dominant, in my view, controlling priority and policy is that we get to AGI, a term I've heard [[00:06:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=367.44s)]
*  you don't like, before China does. [[00:06:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=372.96s)]
*  Why? [[00:06:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=376.32s)]
*  I do think there are profound economic and military and intelligence capabilities that would be [[00:06:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=377.44s)]
*  downstream of getting to AGI or transformative AI. [[00:06:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=386.0s)]
*  And I do think it is fundamental for US national security that we continue to lead AI. [[00:06:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=389.28s)]
*  I think the quote that certainly I thought about a fair amount was actually from Kennedy [[00:06:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=396.47999999999996s)]
*  in his famous Rice speech in 62, the we're going to the moon speech. [[00:06:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=401.84s)]
*  We choose to go to the moon in this decade and do the other things, [[00:06:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=405.52s)]
*  not because they are easy, but because they are hard. [[00:06:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=409.91999999999996s)]
*  Aaron remembers it because he's saying we're going to the moon. [[00:06:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=413.44s)]
*  But actually at the end of the speech, I think he gives the better line. [[00:06:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=415.52s)]
*  For space science, like nuclear science and all technology, has no conscience of its own. [[00:06:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=418.23999999999995s)]
*  Whether it will become a force for good or ill depends on man. [[00:07:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=425.76s)]
*  And only if the United States occupies a position of preeminence, can we help decide [[00:07:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=430.88s)]
*  whether this new ocean will be a sea of peace or a new terrifying theater of war. [[00:07:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=440.0s)]
*  And I think that is true in AI, that there's a lot of tremendous uncertainty about this technology. [[00:07:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=447.28000000000003s)]
*  I am not an AI evangelist. [[00:07:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=452.24s)]
*  I think there's huge risks to this technology. [[00:07:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=454.0s)]
*  But I do think there is a fundamental role for the United States in being able to shape where it goes, [[00:07:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=456.32s)]
*  which is not to say we don't want to work internationally, [[00:07:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=464.72s)]
*  which is not to say we don't want to work with the Chinese. [[00:07:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=466.48s)]
*  It's worth noting that in the president's executive order on AI, there's a line in there saying we [[00:07:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=468.32s)]
*  are willing to work even with our competitors on AI safety and the like. [[00:07:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=472.56s)]
*  But it is worth saying that I think pretty deeply there's a fundamental role for America here [[00:07:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=475.68s)]
*  that we cannot abdicate. [[00:08:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=480.48s)]
*  Paint the picture for me. [[00:08:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=481.68s)]
*  You say there'd be great economic, national security, military risks if China got there first. [[00:08:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=483.2s)]
*  Help me help the audience here imagine a world where China gets there first. [[00:08:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=488.64s)]
*  So I think let's look at just a narrow case of AI for intelligence analysis and cyber operations. [[00:08:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=493.59999999999997s)]
*  This is I think pretty out in the open that if you had a much more powerful AI capability, [[00:08:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=499.44s)]
*  that would probably enable you to do better cyber operations on offense and on defense. [[00:08:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=504.71999999999997s)]
*  What is a cyber operation? [[00:08:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=508.96s)]
*  Breaking into an adversary's network to collect information, [[00:08:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=510.08s)]
*  which if you're collecting in a large enough volume, AI systems can help you analyze. [[00:08:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=513.04s)]
*  And we actually did a whole big thing through DARPA, the Defense Advanced Research Project Agency, [[00:08:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=517.36s)]
*  called the AI Cyber Challenge to test out AI's capabilities to do this. [[00:08:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=522.24s)]
*  That was focused on defense because we think AI could represent a fundamental shift in how [[00:08:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=526.0799999999999s)]
*  we conduct cyber operations on offense and defense. [[00:08:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=530.96s)]
*  And I would not want to live in a world in which China has that capability on offense [[00:08:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=533.04s)]
*  and defense and cyber and the United States does not. [[00:08:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=537.04s)]
*  And I think that is true in a bunch of different domains that are core to [[00:08:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=539.36s)]
*  national security competition. [[00:09:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=544.0s)]
*  My sense already has been that most people, most institutions are pretty hackable [[00:09:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=545.84s)]
*  to a capable state actor. [[00:09:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=552.48s)]
*  Not everything, but a lot of them. [[00:09:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=554.72s)]
*  And now both the state actors are going to get better at hacking. [[00:09:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=557.44s)]
*  And they're going to have much more capacity to do it in the sense that [[00:09:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=561.84s)]
*  you can have many more AI hackers than you can human hackers. [[00:09:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=565.9200000000001s)]
*  Are we just about to enter into a world where we're just much more digitally [[00:09:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=569.12s)]
*  vulnerable as normal people? [[00:09:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=573.4399999999999s)]
*  And I'm not just talking about people who the states might want to spy on, but, [[00:09:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=575.04s)]
*  you know, you will get versions of these systems that just all kinds of bad actors will have. [[00:09:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=578.8s)]
*  Do you worry it's about to get truly dystopic? [[00:09:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=582.8s)]
*  What we mean, canonically, when we speak of hacking is finding vulnerability in software, [[00:09:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=585.36s)]
*  exploring that vulnerability to get illicit access. [[00:09:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=590.88s)]
*  And I think it is right that more powerful AI systems will make it easier to find [[00:09:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=593.92s)]
*  vulnerabilities and exploit them and gain access. [[00:10:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=600.24s)]
*  And that will yield an advantage to the offensive side of the ball. [[00:10:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=603.28s)]
*  I think it is also the case that more powerful AI systems on the defensive side [[00:10:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=606.16s)]
*  will make it easier to write more secure code in the first place, reduce number of [[00:10:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=610.72s)]
*  vulnerabilities that can be found, and to better detect the hackers that are coming in. [[00:10:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=614.32s)]
*  We tried as much as possible to shift the balance towards the defensive side of this. [[00:10:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=617.76s)]
*  But I think it is right that in the coming years here, this sort of transition period [[00:10:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=622.4s)]
*  we've been talking about, that there will be a period in which sort of older legacy [[00:10:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=626.4s)]
*  systems that don't have the advantage of the newest AI defensive techniques or software [[00:10:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=631.12s)]
*  development techniques will on balance be more vulnerable to a more capable offensive actor. [[00:10:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=635.28s)]
*  The flip of that is the question which I know a lot of people worry about, [[00:10:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=640.8s)]
*  which is the security of the AI labs themselves. [[00:10:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=643.76s)]
*  It is very, very, very valuable for another state to get the latest open AI system. [[00:10:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=646.5600000000001s)]
*  And, you know, the people at these companies, and I've talked to them about this, [[00:10:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=654.48s)]
*  on the one hand know this is a problem. [[00:10:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=659.6800000000001s)]
*  And on the other hand, it's really annoying to work in a truly secure way. [[00:11:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=661.76s)]
*  I've worked in the SCIF for the last four years, a secure room where you can't bring [[00:11:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=666.48s)]
*  your phone and all that. [[00:11:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=670.24s)]
*  That is annoying. [[00:11:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=671.44s)]
*  There's no doubt about it. [[00:11:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=672.08s)]
*  How do you feel about the vulnerability right now? [[00:11:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=673.6s)]
*  Of AI labs? [[00:11:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=676.0s)]
*  Yeah. [[00:11:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=676.72s)]
*  I worry about it. [[00:11:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=677.12s)]
*  And I think it's a hacking risk here. [[00:11:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=677.9200000000001s)]
*  I also, you know, if you hang out in the right San Francisco house party, [[00:11:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=679.52s)]
*  they're not sharing the model, but they are talking to some degree about the techniques [[00:11:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=682.88s)]
*  they use and the like, which have tremendous value. [[00:11:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=686.4s)]
*  I do think it is a case to come back to this kind of intellectual through line of this is [[00:11:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=688.5600000000001s)]
*  national security relevant technology, maybe world changing technology that's not [[00:11:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=693.84s)]
*  coming from the auspices of the government and doesn't have the kind of government [[00:11:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=698.24s)]
*  imprimatur of security requirements. [[00:11:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=701.6s)]
*  That shows up in this way as well. [[00:11:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=704.16s)]
*  We in the national screen memorandum, the president's side tried to signal us to the [[00:11:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=705.92s)]
*  labs and tried to say to them, we're as the US government want to help you in this mission. [[00:11:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=709.76s)]
*  This was signed in October of 2024. [[00:11:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=715.6s)]
*  So there wasn't a ton of time for us to build on that. [[00:11:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=717.1999999999999s)]
*  But I think it's a priority for the Trump administration. [[00:11:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=719.92s)]
*  And I can't imagine anything that is more nonpartisan than protecting [[00:12:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=723.04s)]
*  American companies that are inventing the future. [[00:12:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=727.12s)]
*  There's a dimension of this that I find people bring up to me a lot. [[00:12:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=729.2s)]
*  And it's interesting is that that processing of information. [[00:12:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=732.72s)]
*  So compared to, you know, spy games between the Soviet Union and the United States, [[00:12:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=736.8000000000001s)]
*  we all just have a lot more data now. [[00:12:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=743.0400000000001s)]
*  We have all the satellite data. [[00:12:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=745.6800000000001s)]
*  We, I mean, obviously we will not eavesdrop on each other, [[00:12:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=748.0s)]
*  but obviously we eavesdrop on each other and have all these kinds of things coming in. [[00:12:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=750.64s)]
*  And I'm told by people who know this better than I do that there's just a huge [[00:12:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=754.96s)]
*  choke point of human beings and they're, you know, [[00:12:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=758.4s)]
*  currently fairly rudimentary programs analyzing that data. [[00:12:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=761.04s)]
*  And that there's a view that what it would mean to have these truly intelligent systems [[00:12:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=764.48s)]
*  that are able to inhale that and do pattern recognition [[00:12:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=769.92s)]
*  is a much more significant change in the balance of power [[00:12:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=773.52s)]
*  than people outside this understand. [[00:12:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=776.48s)]
*  Yeah, I think we were pretty public about this. [[00:12:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=778.56s)]
*  And the president signed a national security memorandum, [[00:13:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=780.0799999999999s)]
*  which is basically the national security equivalent of an executive order [[00:13:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=782.88s)]
*  that says this is a fundamental area of importance for the United States. [[00:13:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=786.72s)]
*  I don't even know the amount of satellite images that the United States collects every [[00:13:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=790.88s)]
*  single day, but it's a huge amount. [[00:13:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=794.0s)]
*  And we have been public about the fact that we simply do not have enough humans [[00:13:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=795.44s)]
*  to go through all of this satellite imagery and it would be a terrible job if we did. [[00:13:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=799.44s)]
*  And there is a role for AI in going through these images of hot spots around the world, [[00:13:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=803.36s)]
*  of shipping lines and all that, and analyzing them in an automated way [[00:13:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=811.76s)]
*  and surfacing the most interesting and important ones for human review. [[00:13:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=815.36s)]
*  And I think at one level you can look at this and say, [[00:13:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=819.28s)]
*  well, it doesn't software just do that. [[00:13:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=823.44s)]
*  And I think that at some level, of course, is true. [[00:13:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=825.12s)]
*  At another level, you could say the more capable that software, [[00:13:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=827.44s)]
*  the more capable the automation of that analysis, [[00:13:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=830.48s)]
*  the more intelligence advantage you extract from that data. [[00:13:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=834.08s)]
*  And that ultimately leads to a better position for the United States. [[00:13:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=836.8000000000001s)]
*  I think the first and second order consequences of that are also [[00:14:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=840.48s)]
*  striking. [[00:14:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=844.96s)]
*  One thing it implies is that in a world where you have strong AI, [[00:14:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=846.88s)]
*  the incentive for spying goes up. [[00:14:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=852.0s)]
*  Because if right now we are choked at the point of we are collecting more data than we can analyze, [[00:14:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=855.04s)]
*  well, then each marginal piece of data we're collecting isn't that valuable. [[00:14:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=860.56s)]
*  I think that's basically true. [[00:14:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=864.48s)]
*  I think there's two countervailing aspects to it. [[00:14:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=865.68s)]
*  The first is you need to have it. [[00:14:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=868.16s)]
*  I firmly believe you need to have rights and protections that hopefully are pushing back and [[00:14:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=871.68s)]
*  saying, no, there's key kinds of data here, including data on your own citizens, [[00:14:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=876.0799999999999s)]
*  and in some cases, citizens of allied nations that you should not collect, [[00:14:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=880.0799999999999s)]
*  even if there's an incentive to collect it. [[00:14:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=883.52s)]
*  And for all of the flaws of the United States, [[00:14:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=884.9599999999999s)]
*  intelligence, oversight process, and all the debates we could have about this, [[00:14:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=888.16s)]
*  that I think is fundamentally more important for the reason you suggest [[00:14:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=891.1999999999999s)]
*  in the era of tremendous AI systems. [[00:14:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=894.56s)]
*  How frightened are you by the national security implications of all this? [[00:14:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=896.4s)]
*  Which is to say that the possibilities for surveillance states. [[00:14:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=899.84s)]
*  Sam Hammond, who's an economist at the Foundation for American Innovation, [[00:15:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=904.5600000000001s)]
*  he had this piece called 95 Theses on AI. [[00:15:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=907.9200000000001s)]
*  And one of them that I think about a lot is he makes this point that a lot of laws right now, [[00:15:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=910.5600000000001s)]
*  if we had the capacity for perfect enforcement, [[00:15:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=917.9200000000001s)]
*  would be constricting, like extraordinarily constricting. [[00:15:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=922.64s)]
*  Laws are written knowing that human labor is scarce. [[00:15:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=926.48s)]
*  And there's this question of what happens when the surveillance state gets really good? [[00:15:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=930.88s)]
*  What happens when AI makes the police state a very different kind of thing than it is now? [[00:15:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=937.04s)]
*  What happens when we have warfare of endless drones? [[00:15:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=943.52s)]
*  The company Andoril has become a big, you hear about them a lot now, [[00:15:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=947.52s)]
*  they have a relationship, I believe, with OpenAI. [[00:15:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=951.52s)]
*  Palantir is in a relationship with Anthropic, right? [[00:15:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=954.0s)]
*  We're about to see a real change in this in a way that I think is, [[00:15:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=957.12s)]
*  from the national security side, frightening. [[00:16:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=962.72s)]
*  And there I very much get why we don't want China way ahead of us. [[00:16:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=964.88s)]
*  Like, I get that entirely. [[00:16:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=967.6s)]
*  But just in terms of the capacities it gives our own government, [[00:16:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=970.0s)]
*  how do you think about that? [[00:16:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=974.32s)]
*  I would decompose essentially this question about AI and autocracy [[00:16:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=976.16s)]
*  or the surveillance state, however you want to find it, into two parts. [[00:16:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=979.36s)]
*  The first is the China piece of this. [[00:16:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=982.64s)]
*  How does this play out in a state that is truly in its bones in autocracy [[00:16:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=984.56s)]
*  and doesn't even make any pretense towards democracy and like? [[00:16:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=989.8399999999999s)]
*  And I think we can probably agree pretty quickly here. [[00:16:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=993.8399999999999s)]
*  This makes very tangible something that is probably core to the aspirations of their society, [[00:16:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=996.3199999999999s)]
*  of like a level of control that only an AI system could help bring about that I just find terrifying. [[00:16:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1004.4s)]
*  As an aside, I think there's a saying in both Russian and Chinese, [[00:16:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1011.12s)]
*  something like heaven is high and the emperor is far away, [[00:16:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1014.4000000000001s)]
*  which is like historically even in those autocracies, there was some kind of space [[00:16:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1017.2s)]
*  where the state couldn't intrude because of the scale and the breadth of the nation. [[00:17:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1021.2800000000001s)]
*  And it is the case that in those autocracies, [[00:17:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1027.6000000000001s)]
*  I think AI would make the force of government power worse. [[00:17:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1031.04s)]
*  Then there's more interesting question in the United States, [[00:17:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1034.0s)]
*  basically what is the relationship between AI and democracy? [[00:17:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1035.76s)]
*  And I think I share some of the discomfort here. [[00:17:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1038.64s)]
*  There have been thinkers historically who have said, you know, [[00:17:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1043.1200000000001s)]
*  part of the ways in which we revise our laws, our people break the laws, [[00:17:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1045.68s)]
*  and there's a space for that. [[00:17:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1049.76s)]
*  And I think there is a humanness to our justice system that I wouldn't want to lose [[00:17:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1051.0400000000002s)]
*  and to the enforcement of justice that I wouldn't want to lose. [[00:17:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1058.16s)]
*  And we tasked the Department of Justice and running a process and thinking about this [[00:17:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1061.0400000000002s)]
*  coming up with principles for the use of AI in criminal justice. [[00:17:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1066.24s)]
*  I think there's in some cases advantages to it, like cases are treated alike with the machine. [[00:17:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1070.16s)]
*  But also I think there's tremendous risk of bias and discrimination and so forth [[00:17:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1076.56s)]
*  because the systems are flawed and in some cases because the systems are ubiquitous. [[00:18:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1080.8s)]
*  And I do think there is a risk of a fundamental encroachment on rights [[00:18:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1085.12s)]
*  from the widespread unchecked use of AI in the law enforcement system [[00:18:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1090.08s)]
*  that we should be very alert to and that I as a citizen have grave concerns about. [[00:18:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1093.52s)]
*  I find this all makes me incredibly uncomfortable. [[00:18:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1098.0s)]
*  And one of the reasons is that there is a, what's the right way to put this? [[00:18:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1102.48s)]
*  It's like we are summoning an ally, right? [[00:18:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1111.04s)]
*  We are trying to build an alliance with another, like an almost interplanetary ally. [[00:18:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1113.68s)]
*  And we like we are in a competition with China to make that alliance, [[00:18:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1118.8799999999999s)]
*  but we don't understand the ally. [[00:18:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1122.24s)]
*  And we don't understand what it will mean to let that ally into all of our systems [[00:18:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1124.56s)]
*  and all of our planning. [[00:18:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1127.76s)]
*  As best I understand it, every company really working on this, [[00:18:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1129.28s)]
*  every government really working on this believes that in the not too distant future, [[00:18:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1131.92s)]
*  you're going to have much better and faster and more dominant decision making loops [[00:18:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1136.4s)]
*  by being able to make much more of this autonomous to the AI, right? [[00:19:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1141.44s)]
*  Once you get to the, what we're talking about is AGI, [[00:19:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1144.72s)]
*  you want to turn over a fair amount of your decision making to it. [[00:19:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1146.96s)]
*  So we are rushing towards that because we don't want the other guys to get there first [[00:19:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1150.96s)]
*  without really understanding what that is or what that means. [[00:19:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1155.44s)]
*  It seems like a potentially historically dangerous thing that AI reached maturation [[00:19:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1160.48s)]
*  at the exact moment that the US and China are in this like Thucydides trap style race [[00:19:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1167.2s)]
*  for superpower dominance. [[00:19:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1172.88s)]
*  That's a pretty dangerous set of incentives in which to be creating the next turn in [[00:19:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1175.44s)]
*  intelligence on this planet. [[00:19:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1184.96s)]
*  Yeah, there's a lot to unpack here. [[00:19:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1186.5600000000002s)]
*  So let's just go in order. [[00:19:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1187.68s)]
*  But basically bottom line, I think I in the White House and now post White House, [[00:19:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1188.72s)]
*  greatly share a lot of this discomfort. [[00:19:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1193.92s)]
*  And I think part of the appeal for something like the export controls is it identifies [[00:19:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1196.3200000000002s)]
*  a choke point that can differentially slow the Chinese down, create space for the United [[00:20:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1202.08s)]
*  States to have a lead, ideally in my view, to spend that lead on safety and coordination [[00:20:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1207.1999999999998s)]
*  and not rushing ahead, including again, potential coordination with the Chinese [[00:20:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1213.1999999999998s)]
*  while not exacerbating this arms race dynamic. [[00:20:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1217.76s)]
*  I would not say that we tried to race ahead in applications to national security. [[00:20:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1221.04s)]
*  So part of the national security memorandum is a pretty lengthy kind of description of [[00:20:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1226.48s)]
*  what we're not going to do with AI systems and a whole list of prohibited use cases [[00:20:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1231.28s)]
*  and then high impact use cases. [[00:20:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1235.44s)]
*  And there's a governance and risk management framework. [[00:20:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1236.72s)]
*  Yeah, but you're not in power anymore. [[00:20:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1238.56s)]
*  Well, that's a fair question. [[00:20:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1240.08s)]
*  Now, they haven't repealed this. [[00:20:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1241.84s)]
*  The Trump administration has not repealed this. [[00:20:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1242.8799999999999s)]
*  But I do think it's fair to say that for the period while we had power, the foundation [[00:20:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1244.48s)]
*  we were trying to build with AI, we were trying, we were very cognizant to the dynamic you were [[00:20:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1249.92s)]
*  talking about, a race to the bottom on safety. [[00:20:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1253.92s)]
*  And we were trying to guard against it even as we tried to assure a position of US preeminence. [[00:20:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1256.3999999999999s)]
*  Is there anything to the concern that by treating China as such an antagonistic competitor on [[00:21:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1260.64s)]
*  this who we will do everything, including export controls on advanced technologies, [[00:21:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1267.92s)]
*  to hold them back, that we have made them into a more intense competitor? [[00:21:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1272.72s)]
*  I mean, there is a, I do not want to be naive about the Chinese system or the ideology of [[00:21:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1277.5200000000002s)]
*  the CCP. [[00:21:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1284.48s)]
*  They want strength and dominance and to see the next Arabian Chinese era. [[00:21:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1285.6000000000001s)]
*  So maybe there's nothing you can do about this. [[00:21:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1289.04s)]
*  But it is pretty damn antagonistic to try to choke off the chips for the central technology [[00:21:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1291.36s)]
*  of the next era to the other biggest country. [[00:21:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1300.8799999999999s)]
*  I don't know that it's pretty antagonistic to say we are not going to sell you the most [[00:21:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1305.2s)]
*  advanced technology in the world. [[00:21:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1308.8799999999999s)]
*  That does not in itself, that's not a declaration of war. [[00:21:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1310.72s)]
*  That is not even self declaration of a cold war. [[00:21:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1314.72s)]
*  I think it is just saying this technology is incredibly important. [[00:21:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1317.1200000000001s)]
*  Do you think that's how they understood it? [[00:22:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1320.0s)]
*  This is more academic than you want. [[00:22:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1322.0800000000002s)]
*  But my academic research when I started as a professor was basically on the [[00:22:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1323.44s)]
*  Thucydides trap or what in academia we call a security dilemma of how [[00:22:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1327.8400000000001s)]
*  nations misunderstand each other. [[00:22:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1330.8000000000002s)]
*  So I'm sure the Chinese and the United States misunderstand each other at some level in [[00:22:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1332.0800000000002s)]
*  this area. [[00:22:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1336.88s)]
*  But I think the plain reading of the facts is that not selling chips to them, I don't [[00:22:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1337.2800000000002s)]
*  think is a declaration of war. [[00:22:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1341.68s)]
*  I don't think they do misunderstand us. [[00:22:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1342.64s)]
*  I mean, maybe they see it differently, but I think you're being a little... [[00:22:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1344.24s)]
*  Look, I'm aware of how politics in Washington works. [[00:22:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1348.16s)]
*  I've talked to many people doing this. [[00:22:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1350.56s)]
*  I've seen the turn towards a much more confrontational posture with China. [[00:22:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1351.6s)]
*  I know that Jake Sullivan and President Biden wanted to call this strategic competition [[00:22:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1355.68s)]
*  and not a new cold war. [[00:22:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1361.04s)]
*  And again, all that, I think it's true. [[00:22:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1362.08s)]
*  And also we have just talked about, and you did not argue the point, that our [[00:22:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1364.56s)]
*  dominant view is we need to get to this technology before they do. [[00:22:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1369.76s)]
*  I don't think they look at this like, oh, nobody would ever sell us the top technology. [[00:22:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1374.0s)]
*  I think they understand what we're doing here. [[00:22:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1377.52s)]
*  To some degree. [[00:22:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1379.6s)]
*  I don't want to sugarcoat this. [[00:23:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1380.4799999999998s)]
*  I'm sure they do see it that way. [[00:23:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1381.6s)]
*  On the other hand, we set up an AI dialogue with them. [[00:23:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1383.6799999999998s)]
*  And I flew to Geneva and met them and we tried to talk to them about AI safety and the like. [[00:23:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1387.28s)]
*  So I do think in an area as complex as AI, you can have multiple things be true at the [[00:23:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1391.76s)]
*  same time. [[00:23:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1397.6s)]
*  I don't regret for a second the export controls. [[00:23:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1398.32s)]
*  And I think, frankly, we are proud to have done them when we did them because it has [[00:23:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1401.04s)]
*  helped ensure that here we are a couple of years later, we retain the edge in AI for [[00:23:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1405.92s)]
*  as good as a talent as DeepSeek is. [[00:23:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1409.92s)]
*  What made DeepSeek such a shock, I think, to the American system was here's a system [[00:23:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1411.8400000000001s)]
*  that appeared to be trained on much less compute for much less money. [[00:23:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1416.88s)]
*  That was competitive at a high level with our frontier systems. [[00:23:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1421.28s)]
*  How did you understand what DeepSeek was and what assumptions it required that we [[00:23:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1424.64s)]
*  rethink or don't? [[00:23:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1431.84s)]
*  Yeah, let's just take one step back. [[00:23:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1433.04s)]
*  We're tracking the history of DeepSeek here. [[00:23:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1434.64s)]
*  So we've been watching DeepSeek in the White House since November of 23 or thereabouts [[00:23:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1436.08s)]
*  when they put out their first coding system. [[00:24:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1440.64s)]
*  And there's no doubt that the DeepSeek engineers are extremely talented and they got [[00:24:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1442.64s)]
*  better and better at their systems throughout 2024. [[00:24:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1447.92s)]
*  We were hardened when their CEO said, I think the biggest impediment was the [[00:24:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1450.48s)]
*  impediment to what DeepSeek was doing was not their inability to get money or talent, [[00:24:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1454.08s)]
*  but their inability to get advanced chips. [[00:24:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1457.76s)]
*  Clue, they still did get some chips that they some they bought legally, some they smuggled. [[00:24:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1459.52s)]
*  So it seems. [[00:24:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1463.1999999999998s)]
*  And then in December of 24, they came out with a system called version three, DeepSeek [[00:24:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1464.8s)]
*  version three, which actually I think is one that should have gotten the attention. [[00:24:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1469.12s)]
*  It didn't get a ton of attention, but it did show they were making strong algorithmic [[00:24:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1472.32s)]
*  progress and basically making systems more efficient. [[00:24:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1476.8s)]
*  And then in January of 25, they came out with a system called R1. [[00:24:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1479.52s)]
*  R1 is actually not that unusual. [[00:24:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1482.8s)]
*  No one expect that to take a lot of computing power just as a reasoning system that [[00:24:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1484.32s)]
*  extends the underlying V3 system. [[00:24:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1488.64s)]
*  That's a lot of nerd speak. [[00:24:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1492.32s)]
*  The key thing here is when you look at what DeepSeek has done, I don't think the media [[00:24:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1493.6000000000001s)]
*  hype around it was warranted and I don't think it changes the fundamental analysis of what [[00:24:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1497.44s)]
*  we are doing. [[00:25:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1501.6000000000001s)]
*  They still are constrained by computing power. [[00:25:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1502.48s)]
*  We should tighten the screws and continue to constrain them. [[00:25:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1504.64s)]
*  They're smart. [[00:25:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1507.2s)]
*  Their algorithms are getting better. [[00:25:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1507.84s)]
*  But so are the algorithms of US companies. [[00:25:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1509.1200000000001s)]
*  And this I think should be a reminder that the ship controls are important. [[00:25:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1510.96s)]
*  China is a worthy competitor here and we shouldn't take anything for granted. [[00:25:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1515.3600000000001s)]
*  But I don't think this is a time to say the sky is falling or the fundamental scaling [[00:25:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1518.88s)]
*  laws have broken. [[00:25:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1522.56s)]
*  Where do you think they got their performance increases from? [[00:25:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1523.3600000000001s)]
*  They have smart people. [[00:25:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1526.16s)]
*  There's no doubt about that. [[00:25:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1526.8s)]
*  We read their papers. [[00:25:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1527.52s)]
*  They're smart people who are doing exactly the same kind of algorithmic efficiency work [[00:25:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1528.56s)]
*  that companies like Google, Anthropic, and OpenAI are doing. [[00:25:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1533.28s)]
*  One common argument I heard on the left. [[00:25:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1536.24s)]
*  Lena Kahn made this point actually in our pages. [[00:25:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1538.88s)]
*  This proved our whole paradigm of AI development was wrong. [[00:25:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1543.2s)]
*  That we were seeing we did not need all this compute. [[00:25:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1547.1200000000001s)]
*  We were seeing we did not need these giant mega companies. [[00:25:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1549.2800000000002s)]
*  That this was showing a way towards a decentralized, almost solar punk version of AI development. [[00:25:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1552.4s)]
*  And that in a sense the American system and imagination have been captured by these three [[00:25:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1558.96s)]
*  big companies. [[00:26:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1565.2s)]
*  But what we're seeing from China was that that wasn't necessarily needed. [[00:26:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1566.64s)]
*  We could do this on less energy, fewer chips, less footprint. [[00:26:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1571.1200000000001s)]
*  Do you buy that? [[00:26:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1575.76s)]
*  I think two things are true here. [[00:26:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1577.0400000000002s)]
*  The first is there will always be a frontier or at least for the foreseeable future, there'll [[00:26:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1578.0800000000002s)]
*  be a frontier that is computationally and energy intensive. [[00:26:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1582.4s)]
*  And our companies, we want to be at that frontier. [[00:26:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1587.3600000000001s)]
*  Those companies have very strong incentive to look for efficiencies and they all do. [[00:26:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1589.92s)]
*  They all want to get every single last juice of insight from each squeeze of computation. [[00:26:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1594.24s)]
*  They will continue to need to push the frontier. [[00:26:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1599.92s)]
*  And I don't think there's a free lunch waiting in terms of they're not going to need more [[00:26:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1601.68s)]
*  computing power and more energy for the next couple of years. [[00:26:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1605.44s)]
*  And then in addition to that, there'll be a kind of slower diffusion that lags the frontier [[00:26:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1607.76s)]
*  where algorithms get more efficient, fewer computer chips are required, less energy is [[00:26:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1612.08s)]
*  required. [[00:26:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1615.68s)]
*  And we need as America to win both those competitions. [[00:26:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1616.32s)]
*  One thing that you see around the export controls, the AI firms want the export controls. [[00:26:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1619.84s)]
*  When DeepSeek rocked the US stock market, it rocked it by making people question Nvidia's [[00:27:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1625.36s)]
*  long term worth. [[00:27:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1630.1599999999999s)]
*  And Nvidia very much doesn't want these export controls. [[00:27:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1631.36s)]
*  So you at the White House, I'm sure at the center of a bunch of this lobbying back and [[00:27:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1633.6s)]
*  forth. [[00:27:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1637.04s)]
*  How do you think about this? [[00:27:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1638.0s)]
*  Every AI chip, every advanced AI chip that gets made will get sold. [[00:27:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1640.48s)]
*  The market for these chips is extraordinary right now. [[00:27:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1644.24s)]
*  I think for the foreseeable future. [[00:27:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1647.36s)]
*  So I think our view was we put the export controls on. [[00:27:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1648.8s)]
*  Nvidia didn't think that the stock market didn't think that we put the export controls [[00:27:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1652.8s)]
*  on the first ones in October 2022. [[00:27:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1656.24s)]
*  Nvidia stock has 10x since then. [[00:27:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1658.48s)]
*  I'm not saying we shouldn't do the export controls, but I want you to take the strong [[00:27:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1660.72s)]
*  version of the argument, not the weak one. [[00:27:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1663.04s)]
*  I don't think Nvidia's CEO is wrong that if we say Nvidia cannot export its top chips [[00:27:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1664.96s)]
*  to China, that that in some mechanical way in the long run reduces the market for Nvidia's [[00:27:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1672.1599999999999s)]
*  chips. [[00:27:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1677.28s)]
*  Sure. [[00:27:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1677.9199999999998s)]
*  I think the dynamic is right. [[00:27:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1678.24s)]
*  I'm not suggesting if they had a bigger market, they could charge on the margins more. [[00:27:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1679.6799999999998s)]
*  That's obviously the supply and demand here. [[00:28:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1683.6s)]
*  I think our analysis was considering the importance of these chips and the AI systems [[00:28:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1685.4399999999998s)]
*  they make to US national security. [[00:28:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1690.3999999999999s)]
*  This is a trade off that's worth it. [[00:28:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1692.0s)]
*  And Nvidia again has done very well since we put the export controls out. [[00:28:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1693.84s)]
*  And I agree with that. [[00:28:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1698.0s)]
*  The Biden administration was also generally concerned with AI safety. [[00:28:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1699.04s)]
*  I think it was influenced by people who care about AI safety. [[00:28:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1702.48s)]
*  And that's created a kind of backlash from the accelerationist or what gets called the [[00:28:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1705.5200000000002s)]
*  acceleration aside of this debate. [[00:28:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1712.96s)]
*  So I want to play a clip for you from Mark Andreessen, who is obviously a very significant [[00:28:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1714.88s)]
*  venture capitalist, a top Trump advisor, describing the conversations he had with the Biden [[00:28:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1720.0800000000002s)]
*  administration on AI and how they sort of radicalized him in the other direction. [[00:28:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1724.88s)]
*  Ben and I went to Washington in May of 24. [[00:28:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1728.88s)]
*  And we couldn't meet with Biden because as it turns out at the time, nobody could meet [[00:28:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1732.16s)]
*  with Biden, but we were able to meet with senior staff. [[00:28:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1736.32s)]
*  And so we met with very senior people in the White House, in the inner core. [[00:28:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1739.1200000000001s)]
*  And we basically relayed our concerns about AI. [[00:29:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1743.76s)]
*  And their response to us was, yes, the national agenda on AI, as we will implement in the [[00:29:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1746.48s)]
*  Biden administration and in the second term, is we are going to make sure that AI is going [[00:29:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1750.64s)]
*  to be only a function of two or three large companies. [[00:29:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1755.1200000000001s)]
*  We will directly regulate and control those companies. [[00:29:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1759.3600000000001s)]
*  There will be no startups. [[00:29:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1762.3200000000002s)]
*  This whole thing where you guys think you can just start companies and write code and [[00:29:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1763.7600000000002s)]
*  release code on the Internet, those days are over. [[00:29:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1766.48s)]
*  That's not happening. [[00:29:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1768.0s)]
*  The conversation he's describing there, were you part of that conversation? [[00:29:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1769.0400000000002s)]
*  I met with him once. [[00:29:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1773.0400000000002s)]
*  I don't know exactly, but I met with him once. [[00:29:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1773.92s)]
*  Would that characterize the conversation he had with you? [[00:29:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1776.4s)]
*  He talked about concerns related to startups and competitiveness and the like. [[00:29:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1779.3600000000001s)]
*  My view on this is you look at our record on competitiveness, it's pretty clear that [[00:29:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1784.32s)]
*  we want a dynamic ecosystem. [[00:29:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1789.4399999999998s)]
*  So the AI executive order, which President Trump just repealed, had a pretty lengthy [[00:29:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1790.96s)]
*  section on competitiveness. [[00:29:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1795.4399999999998s)]
*  The Office of Management and Budget Management Memo, which governs how the US government [[00:29:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1797.36s)]
*  buys AI, had a whole carve out in it or a call out in it saying, we want to buy from [[00:30:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1801.4399999999998s)]
*  a wide variety of vendors. [[00:30:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1806.08s)]
*  The Chips and Science Act has a bunch of things in there about competition. [[00:30:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1808.1599999999999s)]
*  So I think our view on competition is pretty clear. [[00:30:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1811.52s)]
*  I do think there are structural dynamics related to scaling laws and the like that will [[00:30:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1814.24s)]
*  force things towards big companies that I think in any respects we were pushing against. [[00:30:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1817.6799999999998s)]
*  I think the track record is pretty clear of us on competition. [[00:30:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1825.12s)]
*  I think the view that I understand him as arguing with, which is a view I've heard [[00:30:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1828.72s)]
*  from people in the AI safety community, but it's not a view I'd necessarily heard from [[00:30:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1832.72s)]
*  the Biden administration, was that you will need to regulate the frontier models of the [[00:30:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1835.1999999999998s)]
*  biggest labs when it gets sufficiently powerful. [[00:30:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1842.24s)]
*  And in order to do that, you will need there to be controls on those models. [[00:30:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1844.88s)]
*  You just can't have the model weights and everything floating around so everybody can [[00:30:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1850.4s)]
*  run this on their home laptop. [[00:30:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1853.44s)]
*  I think that's the tension he's getting at. [[00:30:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1856.48s)]
*  It gets at a bigger tension we'll talk about in a minute, but which is how much to regulate [[00:30:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1858.96s)]
*  this incredibly powerful and fast changing technology such that on the one hand, you're [[00:31:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1863.36s)]
*  keeping it safe, but on the other hand, you're not overly slowing it down or making it [[00:31:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1868.48s)]
*  impossible for smaller companies to comply with these new regulations as they're using [[00:31:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1872.56s)]
*  more and more powerful systems. [[00:31:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1877.2s)]
*  In the president's executive order, we actually tried to wrestle with this question and we [[00:31:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1879.52s)]
*  didn't have an answer when that order was signed in October of 23. [[00:31:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1882.64s)]
*  And what we did on the open source question in particular, and I think we should just be [[00:31:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1885.84s)]
*  precise here at the risk of being academic again, what we're talking about open weight [[00:31:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1889.04s)]
*  systems. [[00:31:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1893.2s)]
*  Can you just say what weights are in this context and then what open weights are? [[00:31:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1893.84s)]
*  So when you have the training process for an AI system, you run this algorithm through [[00:31:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1898.32s)]
*  this huge amount of computational power that processes the data. [[00:31:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1903.12s)]
*  The output at the end of that training process, loosely speaking, and I stress this is the [[00:31:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1906.8s)]
*  loosest possible analogy, they are roughly akin to the strength of connections between [[00:31:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1911.28s)]
*  the neurons in your brain. [[00:31:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1916.24s)]
*  And in some sense, you could think of this as the raw AI system. [[00:31:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1917.6799999999998s)]
*  And when you have these weights, one thing that some companies like Meta and DeepSeek [[00:32:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1922.1599999999999s)]
*  choose to do is they publish them out on the internet, which makes them, we call them [[00:32:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1927.28s)]
*  open weight systems. [[00:32:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1931.12s)]
*  I'm a huge believer in the open source ecosystem. [[00:32:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1932.6399999999999s)]
*  Many of the companies that publish the weights of their system do not make them open source. [[00:32:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1935.12s)]
*  They don't publish the code and the like. [[00:32:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1938.56s)]
*  So I don't think they should get the credit of being called open source systems at the [[00:32:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1939.92s)]
*  risk of being pedantic. [[00:32:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1942.8799999999999s)]
*  But open weight systems is something we thought a lot about in 23 and 24. [[00:32:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1944.24s)]
*  And we sent out a pretty wide ranging request for comment from a lot of folks. [[00:32:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1947.92s)]
*  We got a lot of comments back. [[00:32:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1954.96s)]
*  And what we came to in the report that was published in July or so of 24 was there was [[00:32:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1957.3600000000001s)]
*  not evidence yet to constrain the open weight ecosystem, that the open weight ecosystem [[00:32:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1962.4s)]
*  does a lot for innovation and the like, which I think is manifestly true, but that we should [[00:32:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1967.68s)]
*  continue to monitor this as the technology gets better, basically, exactly in the way [[00:32:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1971.5200000000002s)]
*  that you described. [[00:32:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1974.3200000000002s)]
*  So we're talking here a bit about the sort of race dynamic and the safety dynamic. [[00:32:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1975.3600000000001s)]
*  When you were getting those comments, not just on the open weight models, but also when [[00:33:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1981.2s)]
*  you were talking to the heads of these labs and people were coming to you, what did they [[00:33:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1984.8s)]
*  want? [[00:33:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1989.76s)]
*  What would you say was like the consensus, to the extent there was one from AI world, [[00:33:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1990.72s)]
*  of what they needed to get there quickly? [[00:33:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=1996.0800000000002s)]
*  And also, because I know that many people in these labs are worried about what it would [[00:33:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2000.24s)]
*  mean if these systems were unsafe, what was what you would describe as their consensus [[00:33:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2004.24s)]
*  on safety? [[00:33:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2008.4s)]
*  I mentioned before this core intellectual insight of this technology for the first time [[00:33:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2010.8s)]
*  maybe in a long time is a revolutionary one, not funded by the government and its early [[00:33:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2015.52s)]
*  incubator days. [[00:33:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2021.2s)]
*  That was the theme from the labs, which is sort of a like, don't you know we're inventing [[00:33:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2023.76s)]
*  something very, very powerful? [[00:33:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2028.72s)]
*  Ultimately, it's going to have implications for the kind of work you do in national security, [[00:33:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2030.72s)]
*  the way we organize our society and more than any kind of individual policy request, they [[00:33:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2034.96s)]
*  were basically saying, get ready for this. [[00:34:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2042.48s)]
*  The one thing that we did that could be the closest thing we did to any kind of regulation [[00:34:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2044.92s)]
*  was one action, which was after the labs made voluntary commitments to do safety testing, [[00:34:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2048.64s)]
*  we said you have to share the safety test results with us and you have to help us understand [[00:34:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2055.42s)]
*  where the technology is going. [[00:34:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2059.6s)]
*  And that only applied really to the top couple of labs. [[00:34:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2061.16s)]
*  The labs never knew that was coming, weren't all thrilled about it when it came out. [[00:34:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2064.0s)]
*  The notion that this was kind of a regulatory capture that we were asked to do this is simply [[00:34:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2069.12s)]
*  not true. [[00:34:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2073.36s)]
*  But I, in my experience, never got discrete individual policy lobbying from the labs. [[00:34:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2074.36s)]
*  I got much more, this is coming, it's coming much sooner than you think, make sure you're [[00:34:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2080.0s)]
*  ready. [[00:34:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2084.92s)]
*  To the degree they were asking for something in particular, it was maybe a corollary of [[00:34:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2085.92s)]
*  we're going to need a lot of energy and we want to do that here in the United States. [[00:34:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2091.7200000000003s)]
*  And it's really hard to get the power here in the United States. [[00:34:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2094.8s)]
*  But that is has become a pretty big question. [[00:34:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2097.6400000000003s)]
*  If this is all as potent as we think it will be, and you end up having a bunch of the data [[00:35:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2100.76s)]
*  centers containing all the model weights and everything else in a bunch of like Middle [[00:35:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2105.1200000000003s)]
*  Eastern petro states, because speaking hypothetically, because they will give you huge amounts of [[00:35:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2112.36s)]
*  energy access in return for just at least having some purchase on this AI world, which [[00:35:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2119.0s)]
*  they don't have the internal engineering talent to be competitive in, but maybe can get some [[00:35:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2124.68s)]
*  of it located there. [[00:35:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2128.36s)]
*  And then there's some technology. [[00:35:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2129.8s)]
*  There is something to this question. [[00:35:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2132.4s)]
*  Yeah. [[00:35:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2134.4s)]
*  And this is actually, I think an area of bipartisan agreement, which we can get to, but this is [[00:35:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2135.4s)]
*  something that we really started to pay a lot of attention to in later part of 23 and [[00:35:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2139.6s)]
*  most of 24, when it was clear this was going to be a bottleneck. [[00:35:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2143.8s)]
*  In the last week or so in office, President Biden signed a AI infrastructure executive [[00:35:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2147.64s)]
*  order, which has not been repealed, which basically tries to accelerate the power development [[00:35:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2152.2s)]
*  and the permitting of power and data centers here in the United States, basically for the [[00:35:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2156.88s)]
*  reason that you mentioned. [[00:36:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2161.48s)]
*  Now, as someone who truly believes in climate change and environmentalism and clean power, [[00:36:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2162.68s)]
*  I thought there was a double benefit to this, which is that if we did it here in the United [[00:36:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2168.0s)]
*  States, it could catalyze the clean energy transition and like in these companies for [[00:36:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2171.72s)]
*  a variety of reasons in general are willing to pay more for clean energy and on things [[00:36:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2176.64s)]
*  like geothermal and the like. [[00:36:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2181.3199999999997s)]
*  Our hope was we could catalyze that development and bend the cost curve and have these companies [[00:36:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2183.7599999999998s)]
*  be the early adopters of that technology so we'd see a win on the climate side as well. [[00:36:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2188.0s)]
*  So I would say there is a there are warring cultures around how to prepare for AI. [[00:36:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2192.48s)]
*  And I sort of mentioned as safety and AI accelerationism. [[00:36:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2197.92s)]
*  And Genevieve answers went to the sort of big AI summit in Paris and I'll play a clip [[00:36:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2201.56s)]
*  of what he said. [[00:36:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2206.4s)]
*  I'm not here this morning to talk about AI safety, which was the title of the conference [[00:36:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2208.6s)]
*  a couple of years ago. [[00:36:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2214.56s)]
*  I'm here to talk about AI opportunity. [[00:36:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2215.56s)]
*  When conferences like this convene to discuss a cutting edge technology, oftentimes I think [[00:36:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2218.92s)]
*  our response is to be too self-conscious, too risk averse. [[00:37:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2224.12s)]
*  But never have I encountered a breakthrough in tech that so clearly calls us to do precisely [[00:37:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2229.12s)]
*  the opposite. [[00:37:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2233.7999999999997s)]
*  Now, our administration, the Trump administration believes that AI will have countless revolutionary [[00:37:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2234.7999999999997s)]
*  applications in economic innovation, job creation, national security, health care, free expression [[00:37:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2240.52s)]
*  and beyond. [[00:37:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2246.92s)]
*  And to restrict its development now will not only unfairly benefit incumbents in the space, [[00:37:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2247.92s)]
*  it would mean paralyzing one of the most promising technologies we have seen in generations. [[00:37:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2254.52s)]
*  What do you make of that? [[00:37:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2260.72s)]
*  So I think he is setting up a dichotomy there that I don't quite agree with. [[00:37:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2263.48s)]
*  And the irony of that is if you look at the rest of his speech, which I did watch, there's [[00:37:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2267.52s)]
*  actually a lot that I do agree with. [[00:37:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2271.68s)]
*  So he talks, for example, I think he's got four pillars in the speech, one's about centering [[00:37:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2273.48s)]
*  the importance of workers, one's about American preeminence and like, those are entirely consistent [[00:37:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2276.64s)]
*  with the actions that we took in the philosophy that I think the administration, which I was [[00:38:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2282.7599999999998s)]
*  a part espoused, and I certainly believe insofar as what he is saying is that safety and opportunity [[00:38:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2286.92s)]
*  are in fundamental tension, then I disagree. [[00:38:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2292.52s)]
*  I think if you look at the history of technology and technology adaptation, the evidence is [[00:38:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2295.4s)]
*  pretty clear that the right amount of safety action unleashes opportunity and in fact unleashes [[00:38:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2301.04s)]
*  speed. [[00:38:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2307.08s)]
*  One of the examples that we studied a lot and talked to the president about was the [[00:38:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2308.16s)]
*  early days of railroads. [[00:38:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2313.12s)]
*  And in the early days of railroads, there were tons of accidents and crashes and deaths, [[00:38:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2315.0s)]
*  and people were not inclined to use railroads as a result. [[00:38:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2318.88s)]
*  And then what started happening was safety standards and safety technology, block signaling [[00:38:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2322.84s)]
*  so that trains could know when they were in the same area, air brakes so that trains could [[00:38:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2327.62s)]
*  break more efficiently, standardization of train track widths and gauges and the like. [[00:38:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2331.44s)]
*  This was not always popular at the time, but with the benefit of hindsight, it is very [[00:38:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2337.84s)]
*  clear that that kind of technology and some degree policy development of safety standards [[00:39:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2341.52s)]
*  made the American railroad system in the late 1800s. [[00:39:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2347.88s)]
*  I think this is the pattern that shows up a bunch throughout the history of technology. [[00:39:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2351.28s)]
*  To be very clear, it is not the case that every safety regulation, every technology [[00:39:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2355.04s)]
*  is good. [[00:39:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2359.52s)]
*  And there are certainly cases where you can overreach and you can slow things down and [[00:39:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2360.52s)]
*  choke things off. [[00:39:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2362.7599999999998s)]
*  But I don't think it's true there's a fundamental tension between safety and opportunity. [[00:39:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2363.84s)]
*  That's interesting because I don't know how to get this point of regulation right. [[00:39:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2367.8s)]
*  I think the counter argument to Vice President Vance is nuclear. [[00:39:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2371.6400000000003s)]
*  So nuclear power is a technology that both held extraordinary promise, maybe still does, [[00:39:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2378.0s)]
*  and also you can really imagine every country wanting to be in the lead on. [[00:39:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2385.7200000000003s)]
*  The series of accidents, which most of them did not even have a particularly significant [[00:39:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2390.16s)]
*  body count, were so frightening to people that the technology got regulated to the point [[00:39:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2396.28s)]
*  that certainly all of nuclear's advocates believe it has been largely strangled in the [[00:40:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2402.8s)]
*  crib from what it could be. [[00:40:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2407.32s)]
*  The question then is when you look at the actions we have taken on AI, are we strangling [[00:40:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2408.68s)]
*  in the crib and have we taken actions that are akin to... [[00:40:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2413.6s)]
*  I'm not saying that we've already done. [[00:40:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2416.16s)]
*  I'm saying that, look, if these systems are going to get more powerful and they're going [[00:40:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2417.76s)]
*  to be in charge of more things, things are both going to go wrong and they're going to [[00:40:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2421.5200000000004s)]
*  go weird. [[00:40:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2424.1600000000003s)]
*  It's not possible for it to be otherwise, right? [[00:40:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2425.1600000000003s)]
*  To roll out something this new in a system as complex as human society. [[00:40:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2426.96s)]
*  And so I think there's going to be this question of what are the regimes that make people feel [[00:40:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2432.0s)]
*  comfortable moving forward from those kinds of moments? [[00:40:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2436.44s)]
*  Yeah, I think that's a profound question. [[00:40:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2439.1600000000003s)]
*  I think what we tried to do in the Biden administration was set up the kind of institutions in the [[00:40:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2440.6000000000004s)]
*  government to do that in as clear-eyed tech savvy a way as possible. [[00:40:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2446.36s)]
*  Again, with the one exception of the safety test results sharing, which some of the CEOs [[00:40:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2450.52s)]
*  estimate cost them one day of employee work, we did not put anything close to regulation [[00:40:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2454.48s)]
*  in place. [[00:41:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2460.0800000000004s)]
*  We created something called the AI Safety Institute, purely national security focused, [[00:41:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2461.0800000000004s)]
*  cyber risks, bio risks, AI accident risks, purely voluntary. [[00:41:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2465.0s)]
*  And that has relationships, memorandum of understanding with Anthropic, with OpenAI, [[00:41:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2469.1200000000003s)]
*  even with XAI, Elon's company. [[00:41:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2473.2400000000002s)]
*  And basically, I think we saw that as an opportunity to bring AI expertise into the government [[00:41:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2476.2000000000003s)]
*  to build relationships with the public and private sector in a voluntary way. [[00:41:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2481.6800000000003s)]
*  And then as the technology develops, it will be up to now the Trump administration to decide [[00:41:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2485.2000000000003s)]
*  what they want to do with it. [[00:41:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2489.52s)]
*  I think you are quite diplomatically understating, though, what's a genuine disagreement here. [[00:41:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2490.52s)]
*  And what I would say Vance's speech was signaling was the arrival of a different culture in [[00:41:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2496.2400000000002s)]
*  the government around AI. [[00:41:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2501.4s)]
*  There's been an AI safety culture where, and he's making this point explicitly, that we [[00:41:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2503.08s)]
*  have all these conferences about what could go wrong. [[00:41:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2507.24s)]
*  And he is saying, stop it. [[00:41:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2510.16s)]
*  Yes, maybe things could go wrong, but instead we should be focused on what could go right. [[00:41:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2512.32s)]
*  And I would say, frankly, this is like the Trump Musk, which I think is in some ways [[00:41:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2516.64s)]
*  the right way to think about the administration. [[00:42:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2520.7599999999998s)]
*  Their generalized view is something goes wrong, we'll deal with the thing that went wrong [[00:42:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2522.6s)]
*  afterwards, right? [[00:42:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2525.4s)]
*  But what you don't want to do is move too slowly because you're worried about things [[00:42:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2527.44s)]
*  going wrong. [[00:42:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2531.6s)]
*  It's better to break things and fix them than have moved too slowly in order not to [[00:42:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2532.6s)]
*  break them. [[00:42:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2537.36s)]
*  I think it's fair to say that there is a cultural difference with the Trump administration [[00:42:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2538.36s)]
*  and us on some of these things. [[00:42:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2541.44s)]
*  But I also, we held conferences on what you could do with AI and the benefits of AI. [[00:42:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2543.68s)]
*  We talked all the time about how you need to mitigate these risks, but you're doing [[00:42:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2548.96s)]
*  so so you can capture the benefits. [[00:42:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2553.52s)]
*  And I'm someone who reads an essay like Dario Amade's Sea of Anthropics, Machines of Love [[00:42:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2555.52s)]
*  and Grace about the upside of AI. [[00:42:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2560.52s)]
*  And so there's a lot in here we can agree with. [[00:42:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2562.44s)]
*  President's executive order said we should be using AI more in the executive branch. [[00:42:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2565.2400000000002s)]
*  So I hear you on the cultural difference, I get that. [[00:42:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2569.68s)]
*  But I think when the rubber meets the road, we were comfortable with the notion that you [[00:42:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2573.08s)]
*  could both realize the opportunity of AI while doing it safely. [[00:42:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2578.2s)]
*  And now that they are in power, they will have to decide how do they translate Vice [[00:43:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2581.48s)]
*  President Vance's rhetoric into a governing policy. [[00:43:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2585.12s)]
*  My understanding of their executive order is they've given themselves six months to [[00:43:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2588.64s)]
*  figure out what they're going to do. [[00:43:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2591.7999999999997s)]
*  And I think we should judge them on what they do. [[00:43:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2592.7999999999997s)]
*  Let me ask about the other side of this, because what I liked about Vance's speech is I think [[00:43:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2594.88s)]
*  he's right that we don't talk enough about opportunities. [[00:43:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2598.72s)]
*  But more than that, we are not preparing for opportunities. [[00:43:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2603.04s)]
*  So if you imagine that AI will have the effects and possibilities that its backers and advocates [[00:43:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2605.44s)]
*  hope, one thing that that implies is that we're going to start having a much faster [[00:43:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2613.84s)]
*  pace of the discovery or proposal of novel drug molecules, a very high promise. [[00:43:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2619.04s)]
*  The idea here from people I've spoken to is that AI should be able to ingest an amount [[00:43:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2625.84s)]
*  of information and build sort of modeling of diseases in the human body that could get [[00:43:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2629.76s)]
*  us a much, much, much better drug discovery pipeline. [[00:43:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2634.7200000000003s)]
*  If that were true, then you can ask this question, well, what's the choke point going to be? [[00:43:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2637.88s)]
*  And our drug testing pipeline is incredibly cumbersome. [[00:44:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2642.18s)]
*  It's very hard to get the animals you need for trials, very hard to get the human beings [[00:44:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2646.2999999999997s)]
*  you need for trials. [[00:44:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2650.72s)]
*  You could do a lot to make that faster, to prepare it for a lot more coming in. [[00:44:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2651.98s)]
*  And this is true in a lot of different domains, right? [[00:44:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2656.8199999999997s)]
*  Education, et cetera. [[00:44:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2660.66s)]
*  I think it's pretty clear that the choke points will become the difficulty of doing things [[00:44:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2662.14s)]
*  in the real world. [[00:44:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2667.8599999999997s)]
*  And I don't see society also preparing for that, right? [[00:44:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2669.7s)]
*  We're not doing that much on the safety side, maybe because we don't know what we should [[00:44:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2672.8599999999997s)]
*  do, but also on the opportunity side, you know, this question of how could you actually [[00:44:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2675.54s)]
*  make it possible to translate the benefits of the stuff very fast? [[00:44:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2680.18s)]
*  Seems like a much richer conversation I've seen anybody seriously having. [[00:44:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2684.8199999999997s)]
*  Yeah, I think I basically agree with all of that. [[00:44:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2687.8599999999997s)]
*  I think the conversation when we were in the government, especially in 23 and 24, was starting [[00:44:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2690.22s)]
*  to happen. [[00:44:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2695.96s)]
*  I looked at the clinical trials saying, you've read about health care for however long, I [[00:44:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2697.16s)]
*  don't claim expertise on health care. [[00:45:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2700.64s)]
*  But it does seem to me that we want to get to a world where we can take the breakthroughs, [[00:45:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2702.2400000000002s)]
*  including breakthroughs from AI systems, and translate them to market much faster. [[00:45:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2708.32s)]
*  This is not a hypothetical thing. [[00:45:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2711.94s)]
*  It's worth noting, I think quite recently, Google came out with, I think they call it [[00:45:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2713.04s)]
*  the co-scientist, NVIDIA and the ARC Institute, which does great work, had the most impressive [[00:45:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2717.0s)]
*  bio design model ever that has a much more detailed understanding of biological molecules. [[00:45:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2722.72s)]
*  A group called Future House has done similarly great work in science. [[00:45:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2729.08s)]
*  So I don't think this is a hypothetical. [[00:45:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2731.7999999999997s)]
*  I think this is happening right now. [[00:45:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2732.7999999999997s)]
*  And I agree with you that there's a lot that can be done institutionally and organizationally [[00:45:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2734.12s)]
*  to get the federal government ready for this. [[00:45:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2738.8999999999996s)]
*  I've been wandering around Washington, DC this week and talking to a lot of people involved [[00:45:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2741.2s)]
*  in different ways in the Trump administration or advising the Trump administration, different [[00:45:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2745.48s)]
*  factions of what I think is the modern right. [[00:45:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2749.88s)]
*  I've been surprised how many people understand either what Trump and Musk and Dozier are [[00:45:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2755.0s)]
*  doing or at least what it will end up allowing as related to AI, including people I would [[00:46:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2761.7200000000003s)]
*  not really expect to hear that from, not tech right people. [[00:46:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2766.2000000000003s)]
*  But what they basically say is there is no way in which the federal government as constituted [[00:46:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2769.1600000000003s)]
*  six months ago moves at the speed needed to take advantage of this technology, either [[00:46:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2776.9599999999996s)]
*  to integrate it into the way the government works or for the government to take advantage [[00:46:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2781.6s)]
*  of what it can do. [[00:46:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2785.08s)]
*  That we are too cumbersome to endless interagency processes, too many rules, too many regulations. [[00:46:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2786.6s)]
*  You have to go through too many people that if the whole point of AI is that it is this [[00:46:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2793.7599999999998s)]
*  unfathomable acceleration of cognitive work, the government needs to be stripped down and [[00:46:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2799.08s)]
*  rebuilt to take advantage of it. [[00:46:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2804.96s)]
*  And like them, hate them, what they're doing is stripping the government down and rebuilding [[00:46:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2807.7200000000003s)]
*  it. [[00:46:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2812.56s)]
*  And maybe they don't even know what they're doing it for. [[00:46:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2813.56s)]
*  But one thing it will allow is a kind of creative destruction that you can then begin to insert [[00:46:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2815.12s)]
*  AI into at a more ground level due by then. [[00:47:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2820.8s)]
*  It feels kind of orthogonal from what I've observed from Dozier. [[00:47:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2824.12s)]
*  I mean, I think Elon is someone who does understand what AI can do, but I don't know how starting [[00:47:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2826.64s)]
*  with USAID, for example, prepares the US government to make better AI policy. [[00:47:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2831.84s)]
*  So I guess I don't buy it that that is the motivation for Dozier. [[00:47:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2837.84s)]
*  Is there something to the broader argument? [[00:47:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2842.32s)]
*  And I will say I do buy not the argument about Dozier, but sort of make the same point you [[00:47:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2844.2400000000002s)]
*  just made. [[00:47:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2848.04s)]
*  What I do buy is that I know how the federal government works pretty well. [[00:47:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2849.6000000000004s)]
*  And it is too slow to modernize technology. [[00:47:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2853.96s)]
*  It is too slow to work across agencies. [[00:47:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2856.8s)]
*  It is too slow to radically change the way things are done and take advantage of things [[00:47:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2859.52s)]
*  that could be productivity enhancing. [[00:47:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2864.44s)]
*  I couldn't agree more. [[00:47:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2866.64s)]
*  The existence of my job in the White House, the White House Special Advisor for AI, which [[00:47:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2868.32s)]
*  David Saxe now is, and I had this job in 2023, existed because President Biden said very [[00:47:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2871.54s)]
*  clearly publicly and privately, we cannot move at the typical government pace. [[00:47:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2877.2s)]
*  We have to move faster here. [[00:48:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2881.36s)]
*  I think we probably need to be careful. [[00:48:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2882.48s)]
*  I'm not here for stripping it all down, but I agree with you. [[00:48:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2884.92s)]
*  We have to move much faster. [[00:48:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2887.72s)]
*  So another major part of Vice President Vance's speech was signaling to the Europeans that [[00:48:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2889.22s)]
*  we are not going to sign on to complex multilateral negotiations and regulations that could slow [[00:48:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2896.4599999999996s)]
*  us down and that if they passed such regulations anyway in a way that we believe is penalizing [[00:48:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2902.14s)]
*  our AI companies, we would retaliate. [[00:48:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2908.12s)]
*  How do you think about the differing position the new administration is moving into vis-a-vis [[00:48:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2912.7599999999998s)]
*  Europe and its approach, its broad approach to tech regulation? [[00:48:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2917.98s)]
*  Yeah, I think the honest answer here is we had conversations with Europe as they were [[00:48:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2920.66s)]
*  drafting the EU AI Act, but at the time that I was in the EU AI Act was still kind of nascent [[00:48:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2926.66s)]
*  and the act had passed, but a lot of the actual details of it had been kicked to a process [[00:48:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2935.1s)]
*  that my sense is still unfolding. [[00:48:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2939.8199999999997s)]
*  Speaking of slow moving bureaucracies. [[00:49:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2942.66s)]
*  Exactly. [[00:49:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2944.66s)]
*  Exactly. [[00:49:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2945.74s)]
*  So maybe this is a failing on my part. [[00:49:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2946.74s)]
*  I did not have particularly detailed conversations with the Europeans beyond a general kind of [[00:49:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2948.1s)]
*  articulation of our views. [[00:49:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2951.8999999999996s)]
*  They were respectful. [[00:49:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2953.42s)]
*  We were respectful, but I think it's fair to say we were taking a different approach [[00:49:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2954.8199999999997s)]
*  than they were taking and we were probably insofar as safety and opportunity are a dichotomy, [[00:49:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2958.58s)]
*  which I don't think they are a pure dichotomy. [[00:49:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2963.8199999999997s)]
*  We were ready to move very fast in the development of AI. [[00:49:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2967.1s)]
*  One of the other things that Vance talked about and that you said you agreed with is [[00:49:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2970.06s)]
*  making AI pro-worker. [[00:49:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2973.14s)]
*  What does that mean? [[00:49:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2976.3799999999997s)]
*  It's a vital question. [[00:49:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2977.8599999999997s)]
*  I think we instantiate that in a couple of different principles. [[00:49:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2978.8599999999997s)]
*  The first is that AI in the workplace needs to be implemented in a way that is respectful [[00:49:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2982.3799999999997s)]
*  of workers and the like. [[00:49:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2987.94s)]
*  And I think one of the things I know the president thought a lot about was it is possible for [[00:49:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2988.94s)]
*  AI to make workplaces worse and in a way that is dehumanizing and degrading and ultimately [[00:49:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=2994.54s)]
*  destructive for workers. [[00:50:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3001.0s)]
*  So that is sort of a first distinct piece of it that I don't want to neglect. [[00:50:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3002.14s)]
*  The second is I think we want to have AI deployed across our economy in a way that increases [[00:50:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3006.3399999999997s)]
*  workers agencies and capabilities. [[00:50:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3013.3399999999997s)]
*  And I think we should be honest that there's going to be a lot of transition in the economy [[00:50:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3015.3799999999997s)]
*  as a result of AI. [[00:50:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3018.8199999999997s)]
*  You can find Nobel Prize winning economists who will say it won't be much. [[00:50:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3020.3799999999997s)]
*  You can find other folks who will say it'll be a ton. [[00:50:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3023.54s)]
*  I tend to lean towards the it's going to be a lot side, but I'm not a labor economist. [[00:50:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3025.44s)]
*  The line that Vice President Vance used is the exact same phrase that President Biden [[00:50:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3030.38s)]
*  used which is give workers a seat at the table in that transition. [[00:50:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3034.5s)]
*  And I think that is a fundamental part of what we're trying to do here. [[00:50:38](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3038.38s)]
*  And I presume what they're trying to do here. [[00:50:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3041.62s)]
*  So I sort of heard you beg off on this question a little bit by saying you're not a labor [[00:50:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3043.06s)]
*  economist. [[00:50:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3045.98s)]
*  I will say that I am not a labor economist. [[00:50:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3046.98s)]
*  I will promise you the labor economists do not know what to do about AI. [[00:50:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3049.2200000000003s)]
*  You were the top advisor for AI. [[00:50:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3052.34s)]
*  You were at the nerve center of the government's information about what is coming. [[00:50:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3055.02s)]
*  If this is half as big as you seem to think it is, it's going to be the single most disruptive [[00:51:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3061.14s)]
*  thing to hit labor markets ever given how compressed the time period in which it will [[00:51:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3070.02s)]
*  arrive is, right? [[00:51:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3076.06s)]
*  It took a long time to lay down electricity. [[00:51:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3077.1s)]
*  It took a long time to build railroads. [[00:51:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3080.12s)]
*  I think that is basically true, but I want to push back a little bit. [[00:51:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3082.54s)]
*  So I do think we are going to see a dynamic in which it will hit parts of the economy [[00:51:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3084.86s)]
*  first. [[00:51:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3088.94s)]
*  It will hit certain firms first, but it will be an uneven distribution across society. [[00:51:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3089.94s)]
*  I think it will be uneven. [[00:51:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3093.1800000000003s)]
*  And that's I think what will be destabilizing about it in part, right? [[00:51:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3094.58s)]
*  If it were just even, then you might just come up with an even policy to do something [[00:51:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3097.94s)]
*  about it. [[00:51:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3102.3s)]
*  Sure. [[00:51:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3103.3s)]
*  But precisely because it's not even and it's not going to put, I don't think, 42% of the [[00:51:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3104.3s)]
*  labor force out of work overnight. [[00:51:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3107.62s)]
*  No. [[00:51:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3109.06s)]
*  Let me give you an example of the kind of thing I'm worried about. [[00:51:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3110.54s)]
*  And I've heard other people worry about. [[00:51:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3112.7s)]
*  There are a lot of 19 year olds in college right now studying marketing. [[00:51:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3115.82s)]
*  There are a lot of marketing jobs that AI frankly can do perfectly well right now as [[00:52:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3126.18s)]
*  we get better at knowing how to direct. [[00:52:13](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3133.62s)]
*  I mean, one of the things that just slow this down is simply firm adaptation. [[00:52:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3136.02s)]
*  Yes. [[00:52:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3138.86s)]
*  The thing that will happen very quickly is you will have firms that are built around [[00:52:19](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3139.86s)]
*  AI, right? [[00:52:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3143.06s)]
*  It's going to be harder for the big firms to integrate it. [[00:52:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3144.06s)]
*  But what you're going to have is new entrants who are built from the ground up with their [[00:52:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3145.78s)]
*  organization is built around one person overseeing these seven systems. [[00:52:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3150.7400000000002s)]
*  And so you might just begin to see triple the unemployment among marketing graduates. [[00:52:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3155.6600000000003s)]
*  I'm not convinced you'll see that in software engineers because I think AI is going to both [[00:52:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3162.7400000000002s)]
*  take a lot of those jobs. [[00:52:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3167.94s)]
*  And AI will also create a lot of those jobs because there's going to be so much more demand [[00:52:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3169.02s)]
*  for software. [[00:52:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3171.9s)]
*  But you could see it happening somewhere there. [[00:52:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3172.9s)]
*  There's just a lot of jobs that are doing work behind a computer. [[00:52:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3175.7400000000002s)]
*  And as companies absorb machines that can do work behind a computer for you, that will [[00:53:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3180.34s)]
*  change their hiring. [[00:53:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3187.7400000000002s)]
*  You must have heard somebody think about this. [[00:53:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3189.62s)]
*  You guys must have talked about this. [[00:53:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3191.2200000000003s)]
*  We did talk to economists and try to texture this debate in 23 and 24. [[00:53:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3192.66s)]
*  I think the trend line is even clearer now than it was then. [[00:53:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3197.9s)]
*  I think we knew this was not going to be a 23 and 24 question. [[00:53:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3200.26s)]
*  Frankly, to do anything robust about this is going to require Congress. [[00:53:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3203.2200000000003s)]
*  And that was just not in the cards at all. [[00:53:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3206.42s)]
*  So it was more of an intellectual exercise than it was a policy exercise. [[00:53:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3208.26s)]
*  Policies begin as intellectual exercises. [[00:53:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3212.2200000000003s)]
*  I think that's fair. [[00:53:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3214.82s)]
*  I think the advantage to AI that is in some ways a countervailing force here is that it [[00:53:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3215.82s)]
*  will increase the amount of agency for individual people. [[00:53:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3222.5s)]
*  So I do think we will be in a world in which the 19-year-old or the 25-year-old will be [[00:53:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3225.2s)]
*  able to use a system to do things they were not able to do before. [[00:53:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3229.16s)]
*  And I think insofar as the thesis we're batting around here is that intelligence will become [[00:53:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3232.9199999999996s)]
*  a little bit more commoditized. [[00:53:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3238.54s)]
*  What will stand out more in that world is agency and the capacity to do things or initiative [[00:54:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3240.2799999999997s)]
*  and the like. [[00:54:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3246.16s)]
*  And I think that could, in the aggregate, lead to a pretty dynamic economy. [[00:54:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3247.16s)]
*  And the economy you're talking about of small firms and a dynamic ecosystem and robust competition, [[00:54:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3251.16s)]
*  I think on balance and an economy scale is not in itself a bad thing. [[00:54:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3256.64s)]
*  I think where I imagine you and I agree and maybe Vice President Vance as well agree is [[00:54:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3260.72s)]
*  we need to make sure that for individual workers and classes of workers, they're protected [[00:54:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3265.44s)]
*  in that transition. [[00:54:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3269.0s)]
*  I think we should be honest. [[00:54:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3270.2s)]
*  That's going to be very hard. [[00:54:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3271.2s)]
*  We have never done that well. [[00:54:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3272.8799999999997s)]
*  I couldn't agree with you more. [[00:54:34](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3274.3599999999997s)]
*  Like in a big way, Donald Trump is president today because we did a shitty job on this [[00:54:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3275.64s)]
*  with China. [[00:54:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3279.8s)]
*  This is a kind of like the reason I'm pushing on this is that we have been talking about [[00:54:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3281.8s)]
*  this, seeing this coming for a while. [[00:54:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3285.76s)]
*  And I will say that as I look around, I do not see a lot of useful thinking here. [[00:54:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3288.1600000000003s)]
*  And I grant that we don't know the shape of it. [[00:54:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3292.6400000000003s)]
*  At the very least, I would like to see some ideas on the shelf for if the disruptions [[00:54:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3294.88s)]
*  are severe, what we should think about doing. [[00:54:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3298.7200000000003s)]
*  We are so addicted in this country to an economically useful tale that our success is in our own [[00:55:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3302.0800000000004s)]
*  hands. [[00:55:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3309.08s)]
*  It makes it very hard for us to react with either compassion or realism when workers [[00:55:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3310.08s)]
*  are displaced for reasons that are not in their own hands because of global recessions [[00:55:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3316.48s)]
*  or depressions, because of globalization. [[00:55:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3320.44s)]
*  There are always some people like the agency, the creativity, and they become hyperproductive [[00:55:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3323.92s)]
*  and look at them. [[00:55:28](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3328.72s)]
*  Why aren't you them? [[00:55:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3329.72s)]
*  But I'm definitely not saying that. [[00:55:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3330.72s)]
*  I know you're not saying that. [[00:55:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3331.72s)]
*  But it's very hard. [[00:55:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3333.3199999999997s)]
*  American way of looking at the economy that we have a lot of trouble doing. [[00:55:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3335.56s)]
*  You know, we should do some retraining, right? [[00:55:40](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3340.4s)]
*  Are all these people going to become nurses? [[00:55:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3342.16s)]
*  Right? [[00:55:44](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3344.16s)]
*  I mean, there are things that I can't do. [[00:55:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3345.16s)]
*  Like, how many plumbers do we need? [[00:55:46](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3346.7599999999998s)]
*  I mean, more than we have, actually. [[00:55:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3348.08s)]
*  But does everybody move into the trades? [[00:55:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3350.08s)]
*  What were the intellectual thought exercises that all these smart people at the White House [[00:55:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3352.24s)]
*  who believe this was coming? [[00:55:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3356.16s)]
*  What were you saying? [[00:55:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3357.48s)]
*  So I think, yes, we were thinking about this question. [[00:55:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3359.12s)]
*  I think we knew it was not going to be a question we were going to confront in the president's [[00:56:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3362.7599999999998s)]
*  term. [[00:56:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3366.4399999999996s)]
*  I think it was we knew it was a question that you would need Congress for to do anything [[00:56:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3367.4399999999996s)]
*  about. [[00:56:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3370.4399999999996s)]
*  I think I, insofar as what you're expressing here seems to me to be like a deep dissatisfaction [[00:56:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3371.68s)]
*  with the available answers. [[00:56:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3375.9199999999996s)]
*  I share that. [[00:56:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3377.8399999999997s)]
*  I think a lot of us shared that. [[00:56:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3378.8399999999997s)]
*  You can get the usual stock answers of a lot of retraining. [[00:56:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3380.7999999999997s)]
*  I share your sort of doubts that that is the answer. [[00:56:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3384.3999999999996s)]
*  You probably talked to some Silicon Valley libertarians or something and they'll say, [[00:56:27](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3387.48s)]
*  they'll say, well, universal basic income. [[00:56:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3391.04s)]
*  I think I believe and I think the president believes there's a kind of dignity that that [[00:56:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3392.88s)]
*  work brings and doesn't have to be paid work, but there needs to be something that people [[00:56:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3397.52s)]
*  do each day that that gives them meaning. [[00:56:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3401.44s)]
*  So insofar as what you were saying is like there's a you have a discomfort with where [[00:56:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3403.88s)]
*  this is going on the labor side. [[00:56:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3408.2s)]
*  Speaking for myself, I share that. [[00:56:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3411.32s)]
*  I guess I don't know the shape of it. [[00:56:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3412.7999999999997s)]
*  I guess I would say more than that. [[00:56:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3414.4s)]
*  I have a discomfort with the quality of thinking right now, sort of across the board, but I [[00:56:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3416.2s)]
*  will say on the Democratic side, right, because I have you here as a representative of the [[00:57:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3420.92s)]
*  past administration. [[00:57:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3423.96s)]
*  I have a lot of disagreements with the Trump administration, to say the least. [[00:57:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3425.68s)]
*  But I do understand the people who say, look, Elon Musk, David Sacks, Mark Andreessen, JD [[00:57:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3431.2s)]
*  Vance at the very highest levels of that administration are people who spent a lot of time thinking [[00:57:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3437.48s)]
*  about AI and have like considered very unusual thoughts about it. [[00:57:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3442.32s)]
*  And I think sometimes Democrats are a little bit institutionally constrained for thinking [[00:57:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3446.4s)]
*  unusually. I take your point on the export controls. [[00:57:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3450.04s)]
*  I take your point on the exact orders of the the safety Institute. [[00:57:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3452.52s)]
*  But to the extent Democrats are the party want to be imagine themselves to be the party [[00:57:36](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3456.48s)]
*  of the working class. [[00:57:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3461.7200000000003s)]
*  And to the extent we've been talking for years about the possibility of AI driven displacements. [[00:57:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3463.44s)]
*  Yeah, when things happen, you need Congress, but you also need thinking that becomes policies [[00:57:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3468.96s)]
*  of Congress do. [[00:57:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3473.16s)]
*  So I guess I'm trying to push like, was this not being talked about? [[00:57:54](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3474.04s)]
*  There were no meetings. [[00:57:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3478.7200000000003s)]
*  There were no you guys didn't have Claude write up a brief of options. [[00:58:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3480.04s)]
*  Well, you know, we definitely have Claude write up a brief because we had to get over [[00:58:03](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3483.2400000000002s)]
*  government use of AI. [[00:58:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3486.56s)]
*  See, but that's like itself slightly damning. [[00:58:08](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3488.16s)]
*  Yeah, I mean, I think, you know, as I agree that the government has to be more forward [[00:58:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3491.56s)]
*  leaning on basically all of these dimensions. [[00:58:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3496.96s)]
*  It was my job to push the government to do that. [[00:58:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3498.52s)]
*  And I think on things like government use of AI, we we made some progress. [[00:58:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3501.08s)]
*  So I don't think anyone from the Biden administration, lest of all me, is coming out and saying we [[00:58:24](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3504.96s)]
*  solved it. I think what we're saying is like we were building a foundation for something [[00:58:30](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3510.32s)]
*  that is coming that was not going to arrive during our time in office and that the next [[00:58:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3513.96s)]
*  team is going to have to as a matter of American national security and in this case, American [[00:58:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3517.72s)]
*  economic strength and prosperity address. [[00:58:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3523.64s)]
*  I will say this gets to something I find frustrating in the policy conversation about AI, which [[00:58:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3527.08s)]
*  is you sit down with somebody and you start the conversation and like the most transformative [[00:58:53](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3533.12s)]
*  technology perhaps in human history is landing into human civilization in a two to three [[00:58:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3538.24s)]
*  year time frame. [[00:59:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3545.32s)]
*  And you say, wow, that seems like a really big deal. [[00:59:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3546.32s)]
*  What should we do? [[00:59:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3550.08s)]
*  And then things get a little hazy, right? [[00:59:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3551.08s)]
*  Now, maybe we just don't know. [[00:59:15](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3555.24s)]
*  But what I've heard you kind of say a bunch of times like, look, we have done very little [[00:59:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3556.48s)]
*  to hold this technology back. [[00:59:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3560.24s)]
*  Everything is voluntary. [[00:59:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3561.88s)]
*  The only thing we asked was a sharing of safety data. [[00:59:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3563.2799999999997s)]
*  Now, income, the accelerationists, you know, Mark Andreessen has criticized you guys extremely [[00:59:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3566.24s)]
*  straightforwardly. [[00:59:31](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3571.64s)]
*  Is this policy debate about anything? [[00:59:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3573.3199999999997s)]
*  Is it just the sentiment of the rhetoric? [[00:59:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3575.2s)]
*  Right. Like if it's so big. [[00:59:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3579.16s)]
*  But nobody can quite explain what it is we need to do or talk about, except for maybe [[00:59:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3583.6s)]
*  export chip controls. [[00:59:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3587.48s)]
*  Like, are we just not thinking creatively enough? [[00:59:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3589.0s)]
*  Is it just not time? [[00:59:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3591.2s)]
*  Like, match the kind of calm, measured tone of the second half of this with where we started [[00:59:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3592.08s)]
*  for me. [[00:59:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3597.48s)]
*  I think there should be an intellectual humility about before you take a policy action, you [[00:59:58](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3598.48s)]
*  have to have some understanding of what it is you're doing and why. [[01:00:02](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3602.68s)]
*  So I think it is entirely intellectually consistent to look at a transformative technology, [[01:00:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3605.12s)]
*  draw the lines on the graph and say, this is coming pretty soon without having the 14 [[01:00:10](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3610.56s)]
*  point plan of this is what we need to do in 2027, 2028. [[01:00:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3614.84s)]
*  I think chip controls are unique in that this is a robustly good thing that we could do [[01:00:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3617.76s)]
*  early to buy the space I talked about before. [[01:00:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3622.2400000000002s)]
*  But I also think that we tried to build institutions like the AI Safety Institute that would set [[01:00:25](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3625.12s)]
*  the new team up, whether it was us or someone else, for success in managing the technology. [[01:00:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3629.48s)]
*  Now that it's them, they will have to decide as the technology comes on board, how do we [[01:00:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3633.8s)]
*  want to calibrate this on regulation? [[01:00:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3637.92s)]
*  What are the kinds of decisions you think they will have to make in the next two years? [[01:00:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3639.84s)]
*  You mentioned the open source one. [[01:00:42](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3642.76s)]
*  I have a guess where they're going to land on that. [[01:00:43](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3643.96s)]
*  But that I think there's there's an intellectual debate there that is rich. [[01:00:45](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3645.6000000000004s)]
*  We resolved it one way by not doing anything. [[01:00:49](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3649.0800000000004s)]
*  They'll have to decide do they want to keep doing that. [[01:00:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3650.84s)]
*  Ultimately, they'll have to answer a question of what is the relationship between the public [[01:00:52](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3652.84s)]
*  sector and the private sector? [[01:00:56](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3656.28s)]
*  Is it the case, for example, that the kind of things that are voluntary now with the [[01:00:57](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3657.82s)]
*  AI Safety Institute will someday become mandatory? [[01:01:01](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3661.2400000000002s)]
*  Another key decision is we tried to get the ball rolling on the use of AI for national [[01:01:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3664.04s)]
*  defense in a way that is consistent with American values. [[01:01:07](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3667.76s)]
*  They will have to decide what does that continue to look like and do they want to take some [[01:01:11](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3671.36s)]
*  of the safeguards that we put in place away to go faster? [[01:01:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3674.92s)]
*  So I think there really is a bunch of decisions that they are teed up to make over the next [[01:01:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3677.7200000000003s)]
*  couple of years that we can appreciate their coming on the horizon without me sitting [[01:01:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3681.96s)]
*  here and saying, I know with certainty what the answer is going to be in 2027. [[01:01:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3686.32s)]
*  And then also final question, what are three books you'd recommend to the audience? [[01:01:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3689.7200000000003s)]
*  One of the books is The Structure of Scientific Revolutions by Thomas Kuhn. [[01:01:33](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3693.92s)]
*  This is a book that coined the term paradigm shift, which basically is what we've been [[01:01:37](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3697.76s)]
*  talking about throughout this whole conversation of a shift in technology and scientific understanding [[01:01:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3701.44s)]
*  and its implications for society. [[01:01:47](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3707.08s)]
*  And I like how Kuhn in this book, which was written in the 1960s, gives a series of historical [[01:01:48](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3708.84s)]
*  examples and theoretical frameworks for how do you think about a paradigm shift. [[01:01:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3715.52s)]
*  And then another book that has been very valuable for me is Rise of the Machines by [[01:02:00](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3720.44s)]
*  Thomas Ridd. [[01:02:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3724.56s)]
*  And that really tells the story of how machines that were once the playthings of dorks like [[01:02:06](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3726.12s)]
*  me became in the 60s and the 70s and the 80s things of national security importance. [[01:02:12](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3732.08s)]
*  We talked about some of the revolutionary technologies here, the internet, microprocessors [[01:02:17](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3737.2000000000003s)]
*  and the like that emerged out of this intersection between national security and tech development. [[01:02:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3740.8s)]
*  And I think that history should inform the work we do today. [[01:02:26](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3746.32s)]
*  And then the last book is definitely unusual one, but I think is vital. [[01:02:29](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3749.96s)]
*  And that's A Swim in the Pond and the Rain by George Saunders. [[01:02:32](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3752.82s)]
*  And he's this great essayist and short story writer and novel writer. [[01:02:35](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3755.8s)]
*  And he teaches Russian literature. [[01:02:39](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3759.96s)]
*  And he in this book takes seven Russian literature short stories and gives a literary interpretation [[01:02:41](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3761.7s)]
*  of them. [[01:02:50](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3770.68s)]
*  And what strikes me about this book is he's an incredible writer. [[01:02:51](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3771.68s)]
*  And this fundamentally is the most human endeavor I can think of. [[01:02:55](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3775.9s)]
*  He's taking great human short stories and he's giving a modern interpretation of what [[01:02:59](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3779.2799999999997s)]
*  those stories mean. [[01:03:04](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3784.04s)]
*  And I think when we talk about the kinds of cognitive tasks that are a long way off for [[01:03:05](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3785.04s)]
*  machines, I kind of at some level hope this is one of them, that there is something fundamentally [[01:03:09](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3789.6s)]
*  human that we alone can do. [[01:03:14](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3794.08s)]
*  I'm not sure that's true, but I hope it's true. [[01:03:16](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3796.3599999999997s)]
*  I'll say I had him on the show for that book. [[01:03:18](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3798.3599999999997s)]
*  It's one of my favorite ever episodes. [[01:03:20](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3800.16s)]
*  People should check it out. [[01:03:21](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3801.92s)]
*  Ben Buchanan, thank you very much. [[01:03:22](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3802.92s)]
*  Thanks for having me. [[01:03:23](https://www.youtube.com/watch?v=Btos-LEYQ30&t=3803.92s)]
