---
Date Generated: July 09, 2025
Transcription Model: whisper medium 20231117
Length: 3937s
Video Keywords: []
Video Views: 151228
Video Rating: None
Video Description: Donald Trump and Zohran Mamdani are both proof of how the ability to capture attention is power. And the attention economy isn’t reshaping just politics; it’s also reshaping the actual economy: the crypto market, A.I. venture capital, and how people, especially Gen Z, are making career decisions. @KylaScanlon has emerged as a leading theorist on the economics of attention and is herself a member of Gen Z. She is the author of the book “In This Economy?” and Kyla’s Newsletter on Substack. I asked her on the show to walk us through her theory of the attention economy.
0:00: Intro
1:17: The Gen Z economy
8:50: The AI ‘fog’ on the future
20:00: AI and consensus reality
26:40: Attention is infrastructure
36:35: How Trump embodies the algorithm
48:00: Digital ease and nihilism
56:36: Everything feels like crypto now
59:45: Optimism for the real world
1:04:25: Book recommendations
Read the full transcript here: https://www.nytimes.com/2025/07/08/opinion/ezra-klein-podcast-kyla-scanlon.html
Watch more on @EzraKleinShow 
Thoughts? Guest suggestions? Email us at ezrakleinshow@nytimes.com.
You can find transcripts (posted midday) and more episodes of “The Ezra Klein Show” at nytimes.com/ezra-klein-podcast. Book recommendations from all our guests are listed at https://www.nytimes.com/article/ezra-klein-show-book-recs.html
---

# How The Attention Economy is Devouring Gen Z | The Ezra Klein Show
**New York Times - Ezra Klein:** [July 08, 2025](https://www.youtube.com/watch?v=cZO1B4fZlOw)
*  The last few episodes of the show have been about attention, but about attention in terms of something else. [[00:00:00](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=0.0s)]
*  Attention in terms of Zoran Mamdani and Donald Trump. [[00:00:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=6.08s)]
*  Attention in terms of the big, beautiful bill. [[00:00:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=9.64s)]
*  But I wanted to do an episode that was about attention in terms of itself. [[00:00:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=12.92s)]
*  If we're going to say attention is currency, if we're going to say it's power, well, what kind of currency is it? [[00:00:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=18.080000000000002s)]
*  What kind of power is it? [[00:00:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=23.92s)]
*  I'm a pretty loyal reader of Kyla's newsletter by Kyla Scanlon, which often feels to me like it's being sent back in time from some future economy. [[00:00:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=26.240000000000002s)]
*  And in a way it is. Kyla is very much a member of Gen Z. [[00:00:36](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=36.480000000000004s)]
*  Bart coin has been one of the most stable assets of this entire time, which I think says a lot about this entire time. [[00:00:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=40.88s)]
*  And the economy she is reporting on, the economy she is theorizing, an economy where attention drives capital as opposed to capital driving attention. [[00:00:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=47.8s)]
*  Kyla is also the author of the book In This Economy. [[00:00:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=56.31999999999999s)]
*  And you might have heard some of her different coinages like by obsession. [[00:00:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=59.31999999999999s)]
*  She's a fascinating person to talk about this with. [[00:01:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=62.599999999999994s)]
*  As always, my email is zorclineshow.nytimes.com. [[00:01:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=65.08s)]
*  Kyla Scanlon, welcome to the show. [[00:01:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=74.2s)]
*  Thanks for having me. [[00:01:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=75.72s)]
*  What is different about the economy that you live in, that you see, that you feel Gen Z is experiencing from the way us like 40 and 50 year olds described or understood the economy? [[00:01:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=77.0s)]
*  So one of my pieces that went far was a Gen Z and the end of predictable progress. [[00:01:29](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=89.56s)]
*  And it was based on my research over the past year. [[00:01:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=95.08s)]
*  I've been traveling like on a quasi book tour, you know, going to a lot of college campuses and going to a lot of conferences. [[00:01:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=97.24s)]
*  And I've been talking to young people about how they experience the economy and how they think about their future. [[00:01:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=102.75999999999999s)]
*  And so for them, it doesn't feel like there's that quote unquote path of predictable progress that like maybe their parents had or their grandparents had. [[00:01:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=108.03999999999999s)]
*  And of course, every generation has had its own challenges. [[00:01:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=114.75999999999999s)]
*  But for Gen Z, you don't have that predictable return on a college education anymore because of things like AI, because of how expensive college has gotten. [[00:01:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=117.4s)]
*  You don't necessarily have a path toward buying a house that feels even remotely approachable. [[00:02:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=126.11999999999999s)]
*  And, you know, if you think about retirement or just moving through a career path, that also feels really far away. [[00:02:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=132.92s)]
*  And so that whole piece was like, well, what does it look like if this path that everybody has followed has kind of disappeared, more or less? [[00:02:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=139.95999999999998s)]
*  Let me stay on the topic of the feel of it. [[00:02:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=147.32s)]
*  So then what does it feel like if you can't see your way to a house, if you're not sure what the career paths are, if you're not sure what AI will do? [[00:02:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=150.36s)]
*  Like, if you had to describe the emotional structure of the conversations you have with people on the tour, what are the dominant emotions? [[00:02:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=159.16000000000003s)]
*  I think there's a lot of worry. I mean, I think everybody picks up on this. [[00:02:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=166.76000000000002s)]
*  Like, there are so many think pieces about like, the kids are not all right, right? [[00:02:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=169.96s)]
*  Like, there's a lot of nihilism. There's a lot of concern. There's a lot of fear. [[00:02:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=173.88000000000002s)]
*  There's a lot of anxiety. And you sense that when you talk to people because like, they don't really know what to do because this path that has sort of been instilled in you from the time that you were little, like go to college, graduate, buy a house. [[00:02:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=177.72s)]
*  It's just it's out of reach. And so when you can't get that, it feels far away. Right. [[00:03:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=191.72s)]
*  And so David Brooks was writing about the rejection generation that I think encapsulated it really well because he was like, the Gen Zers are facing like rejection after rejection. [[00:03:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=197.95999999999998s)]
*  Like, it's hard to get into college. And then when you graduate college, it's hard to get a job. [[00:03:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=207.32s)]
*  And so I think that element of always being rejected from everything or at least feeling like you're being rejected from everything creates those elements of nihilism that show up and how Gen Zers might spend or savor and bust. [[00:03:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=211.23999999999998s)]
*  Tell me about your barbell theory of Gen Z. [[00:03:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=222.28s)]
*  Essentially, there's like two ways that people seem to be responding to the uncertainty in the economy and the lack of a path of predictable progress. [[00:03:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=225.16s)]
*  One path is tool belt pragmatism. [[00:03:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=234.20000000000002s)]
*  So people going back to the trades, like becoming a plumber, electrician, great. [[00:03:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=236.76000000000002s)]
*  Taking a path that isn't as speculative and uncertain as, you know, getting a bunch of debt and going to college. [[00:04:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=241.64000000000001s)]
*  Other people are going a meme coin gambling, sports betting type of route. [[00:04:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=249.24s)]
*  And so you have these two ends of the extreme of risk. [[00:04:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=255.64s)]
*  But both of those are responses to that path of get a college education, get a white collar job and go off into the sunset, not really working anymore. [[00:04:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=259.88s)]
*  How much is this a narrative and how much is it a reality? [[00:04:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=272.52s)]
*  So if you look at unemployment for Gen Z or new college graduates, recently, the unemployment rate new college graduates is up a bit. [[00:04:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=275.47999999999996s)]
*  But it's not 30 percent or 40 percent. [[00:04:44](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=284.68s)]
*  I've seen people debating the housing question, you know, we're millennials or now Gen Zers. [[00:04:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=287.64s)]
*  Are they really so far behind other generations on housing and won't all those houses get passed on anyway? [[00:04:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=292.6s)]
*  So is this really a problem? [[00:04:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=297.24s)]
*  So when you is there a divergence in your view between the data on the economy that people in Gen Z are in and how they feel about it? [[00:04:58](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=298.92s)]
*  Or does it match? [[00:05:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=309.24s)]
*  I still think there are some elements of a disconnect, right? [[00:05:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=311.4s)]
*  Like people might be feeling a certain way because of social media that doesn't always match the data. [[00:05:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=314.92s)]
*  But I think when we look at some data points like the college wage premium, so basically how much more you make with a college degree than not. [[00:05:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=319.96s)]
*  And that's eroded over the past couple of years. [[00:05:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=327.64s)]
*  And so you're graduating with a college degree, very expensive. [[00:05:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=330.84s)]
*  You're not making as much as you might expect. [[00:05:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=333.8s)]
*  Housing is still quite expensive. [[00:05:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=335.96s)]
*  Eventually those homes will pass on. [[00:05:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=337.96000000000004s)]
*  But I think the median age to buy a house now is like 54 years old. [[00:05:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=340.28000000000003s)]
*  And in the 1980s, I believe it was 34. [[00:05:44](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=344.92s)]
*  And so there are some data points that support the fact that there are these elements of nihilism and perhaps reasons for feeling nihilistic that weave into how Gen Z experiences the economy. [[00:05:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=348.04s)]
*  But I think it's all exacerbated by things like social media for sure. [[00:05:58](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=358.84000000000003s)]
*  Like there is elements of narrative that might sweep beyond the data. [[00:06:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=362.84000000000003s)]
*  But the data tells the story too. [[00:06:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=367.08s)]
*  You also talk about how there's not just one Gen Z. [[00:06:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=369.24s)]
*  There are multiple. [[00:06:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=372.68s)]
*  Yeah. [[00:06:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=373.96s)]
*  What are they? [[00:06:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=374.28s)]
*  Yes. [[00:06:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=375.71999999999997s)]
*  So I'm an ancient Gen Z. [[00:06:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=376.03999999999996s)]
*  I'm an elder millennial. [[00:06:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=379.0s)]
*  So I graduated right into the pandemic. [[00:06:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=381.15999999999997s)]
*  And so I'm part of the Gen Z ones. [[00:06:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=383.15999999999997s)]
*  So those that were, you know, you remember a time in college where you weren't in Zoom, like you were pre-pandemic. [[00:06:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=385.64s)]
*  You were in the workforce during the pandemic. [[00:06:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=393.0s)]
*  And then Gen Z one and a half would be where like my little brother is. [[00:06:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=395.56s)]
*  And so he was in college during the pandemic. [[00:06:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=399.24s)]
*  And so that shaped both his relationship with institutions and his relationship with digital. [[00:06:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=401.48s)]
*  And so he got a lot of education via Zoom and he relied on digital tools, as we all did during that time, to forge friendships and to forge connections. [[00:06:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=406.6s)]
*  And then Gen Z 2.0 is the people that are in college now and high school now. [[00:06:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=417.08s)]
*  And they're the first part of that generation that is entirely digital. [[00:07:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=421.96s)]
*  So for them, like that digital seems to be an extension of reality. [[00:07:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=427.08s)]
*  So Rachel Johns-Faz was the first person that kind of came up with bucketing the Gen Z's. [[00:07:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=431.23999999999995s)]
*  She had Gen Z 1.0 and Gen Z 2.0. [[00:07:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=436.2s)]
*  And I stuck a Gen Z one and a half in the middle because I think it deserves a bit more splicing. [[00:07:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=438.28s)]
*  But that's how you can think of it is like the relationship with technology and the relationships to institutions. [[00:07:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=444.12s)]
*  And the pandemic is such a big player in that, right? [[00:07:29](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=449.47999999999996s)]
*  To be to graduate before the pandemic, to be in school during the pandemic is the implicit argument here that Gen Z is just going to be a very different generation because it had this shock that other generations didn't, right? [[00:07:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=452.35999999999996s)]
*  That the pandemic hit at a much more formative time for essentially all Gen Zers. [[00:07:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=466.52s)]
*  And what came before them, what's going to come after them is going to be less volatile. [[00:07:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=472.2s)]
*  Than what they went through. [[00:07:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=479.47999999999996s)]
*  Yeah, I think so. [[00:08:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=481.88s)]
*  I think Gen Z is the beta generation, the beta tester generation rather. [[00:08:03](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=483.15999999999997s)]
*  So they're the ones who were like, is TikTok good for the brain? [[00:08:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=487.32s)]
*  We'll see. [[00:08:10](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=490.84s)]
*  And, you know, can students do Zoom classes and still get an education? [[00:08:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=492.2s)]
*  We'll see. [[00:08:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=496.91999999999996s)]
*  Is unfettered access to the internet? [[00:08:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=498.2s)]
*  Okay, we'll see. [[00:08:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=500.2s)]
*  Like we've tested a lot of things on Gen Z. [[00:08:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=501.96s)]
*  Smartphones in schools. [[00:08:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=503.96s)]
*  Right. [[00:08:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=505.32s)]
*  And we're learning. [[00:08:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=505.96s)]
*  We're learning. [[00:08:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=507.08s)]
*  A lot of schools are starting to ban smartphones. [[00:08:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=507.8s)]
*  But yes, I think Gen Z is the generation that hopefully will take a lot of lessons for [[00:08:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=510.28s)]
*  Gen Alpha and perhaps not put them through what the Gen Zers have gone through from a [[00:08:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=515.3199999999999s)]
*  digital mental perspective. [[00:08:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=520.76s)]
*  How does AI fit into the job market that young people are both seeing and sensing? [[00:08:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=523.3199999999999s)]
*  So AI is interesting because there's all these stories about how AI is going to replace entry [[00:08:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=531.64s)]
*  level jobs and these companies are going to automate all this work with AI like Salesforce [[00:08:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=537.48s)]
*  I think has automated. [[00:09:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=542.76s)]
*  So they say like 30 to 50 percent of their works or something like that. [[00:09:03](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=543.72s)]
*  And so if you're a young person and you're looking at that, you're like, oh no, like [[00:09:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=547.24s)]
*  these entry level jobs that I rely on to get on the bottom rung of my career ladder are [[00:09:10](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=550.76s)]
*  going to be taken away from me. [[00:09:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=556.2s)]
*  And so I think that also creates an element of fear. [[00:09:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=558.6s)]
*  It's like, well, where do you even enter the workforce if the entry level jobs are supposedly [[00:09:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=561.32s)]
*  going to be done by AI? [[00:09:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=566.36s)]
*  This is where I think the feeling of it is important. [[00:09:28](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=568.9200000000001s)]
*  When I both feel this a bit myself, but when I talk to people who are starting out more [[00:09:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=571.72s)]
*  in their careers, my sense of the moment is it's a little bit for a lot of people like [[00:09:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=578.2800000000001s)]
*  looking at a wave in the distance and you turn on the news and they keep telling you, [[00:09:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=587.48s)]
*  you have a tsunami warning. [[00:09:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=591.24s)]
*  And you're like, well, is that wave going to turn into a tsunami? [[00:09:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=592.36s)]
*  And if so, how quickly and do I have time to get out or am I in a high enough area? [[00:09:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=596.84s)]
*  And you don't really know, but that it has become this fog between you and a stable [[00:10:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=602.84s)]
*  vision of your own future. [[00:10:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=609.48s)]
*  Right. [[00:10:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=611.64s)]
*  When I started out in journalism, it wasn't clear that I could succeed in journalism, [[00:10:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=611.96s)]
*  but it was never because there might be a massive technological shock to journalism [[00:10:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=617.96s)]
*  in which a computer would do my job instead of me. [[00:10:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=622.92s)]
*  And obviously things like that happen in manufacturing with both globalization and [[00:10:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=626.04s)]
*  automation. [[00:10:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=630.12s)]
*  But I think it's some of that, that there is just this ambient uncertainty. [[00:10:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=631.16s)]
*  It feels like that moment of like liquidness, or I think fog is probably the better metaphor, [[00:10:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=637.48s)]
*  is very present for people. [[00:10:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=645.24s)]
*  Yeah. [[00:10:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=647.8s)]
*  And if you look at the money that the companies are spending, that's concerning too. [[00:10:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=648.04s)]
*  When you see Mark Zuckerberg spending billions of dollars to poach people from open AI, [[00:10:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=653.64s)]
*  it's like, well, clearly something is happening here. [[00:10:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=659.5600000000001s)]
*  Clearly he has some sort of plan. [[00:11:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=662.52s)]
*  Will that plan work? [[00:11:04](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=664.52s)]
*  Who knows? [[00:11:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=665.5600000000001s)]
*  Because the metaverse didn't work out. [[00:11:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=666.12s)]
*  And so I think the overwhelming narrative is that, oh gosh, well, if you majored in [[00:11:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=668.2s)]
*  computer science, you're out of luck, man. [[00:11:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=673.32s)]
*  Good luck out there. [[00:11:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=675.72s)]
*  Or if you majored in arts, or if you're trying to be an artist, too bad, AI is going to do [[00:11:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=676.9200000000001s)]
*  your job. [[00:11:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=681.5600000000001s)]
*  And so I think right now we're at this phase of technology where we're trying to establish [[00:11:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=682.6800000000001s)]
*  the human part of it, and we're not doing a good job at figuring out where humans need [[00:11:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=686.9200000000001s)]
*  to be in the technology equation. [[00:11:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=692.2800000000001s)]
*  And instead we're like, no, we're just going to automate everything. [[00:11:34](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=694.2800000000001s)]
*  And sorry, we don't have a plan for people. [[00:11:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=697.5600000000001s)]
*  This really frightens me, actually, is that if AI was going to hit like COVID hit, and just put [[00:11:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=700.6s)]
*  50% of the population out of work, we would do something about it. [[00:11:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=705.5600000000001s)]
*  But if it moves slowly and just eats a category and a tranche of jobs at a time, we're going to [[00:11:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=711.32s)]
*  blame the people who don't have jobs. [[00:11:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=719.72s)]
*  We're going to say, well, most people who graduate with a marketing degree got a job, [[00:12:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=722.36s)]
*  so you're just not working hard enough, you're not smart enough, you're not one of the good [[00:12:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=726.5200000000001s)]
*  ones. [[00:12:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=729.08s)]
*  We're so used to doing that in this economy, blaming every individual for what happens [[00:12:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=729.8000000000001s)]
*  often when it's very sectoral, very technological. [[00:12:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=734.28s)]
*  And I talked to a lot of politicians about this. [[00:12:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=739.1600000000001s)]
*  And they're kind of abstractly worried about it. [[00:12:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=742.0400000000001s)]
*  And none of them have an inkling of a policy answer for it. [[00:12:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=745.48s)]
*  What do we do if AI, which seems totally possible, just doubles 18 to 24-year-old unemployment [[00:12:29](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=749.8000000000001s)]
*  in the next six years or triples it? [[00:12:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=758.52s)]
*  What policy would we deploy for that? [[00:12:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=761.08s)]
*  And nothing. [[00:12:44](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=764.04s)]
*  Yeah. [[00:12:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=765.88s)]
*  I'm not surprised to hear that. [[00:12:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=768.6s)]
*  I don't know if anybody has a good answer. [[00:12:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=771.96s)]
*  The common answer you'll hear is UBI, like universal basic income, right? [[00:12:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=773.8s)]
*  We'll just set aside $1,000 a month for everybody and that'll be that. [[00:12:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=777.96s)]
*  And I don't think that's the right answer either. [[00:13:03](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=783.08s)]
*  Because to be human is to work and to have meaning and to have purpose. [[00:13:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=785.72s)]
*  And so if we all of a sudden just say, no, you don't have meaning and you don't have [[00:13:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=792.12s)]
*  purpose, that feels really bad. [[00:13:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=796.84s)]
*  And so I worry, even if we do have a policy response, the upheaval, the societal upheaval [[00:13:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=799.4s)]
*  that could happen if all of a sudden we're like no jobs for everybody could be really bad. [[00:13:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=806.52s)]
*  And then there's the other side of the coin where there's a good paper that was published [[00:13:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=810.6800000000001s)]
*  in the National Bureau of Economic Research that talks about nails, [[00:13:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=815.8000000000001s)]
*  like hammer nails, where once I think 0.5% of GDP, like in the 1800s, like the nail part. [[00:13:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=818.9200000000001s)]
*  That's a lot of GDP, actually. [[00:13:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=825.8000000000001s)]
*  Yeah, right. [[00:13:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=826.9200000000001s)]
*  But that just shows technology is always shifting and changing and no longer nails [[00:13:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=827.5600000000001s)]
*  like that big of our economy. [[00:13:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=831.72s)]
*  We develop new parts of our economy just like we did with the internet. [[00:13:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=833.48s)]
*  And so that's kind of what we have to hope for is that new jobs will be established with AI [[00:13:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=836.28s)]
*  rather than no jobs at all. [[00:14:00](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=840.36s)]
*  Which maybe they will, but it's that disruption period that is very scary, I think. [[00:14:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=842.04s)]
*  You mentioned UBI. [[00:14:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=848.52s)]
*  I've been around a lot of you, but I discussed my wife wrote a book on giving people money [[00:14:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=849.4s)]
*  a couple years back. [[00:14:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=853.7199999999999s)]
*  My old colleague Dylan Matthews, I thought, had a great line on this, which he said that [[00:14:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=855.16s)]
*  UBI is simultaneously too much and too little of a solution for the AI problem. [[00:14:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=859.48s)]
*  Because if you imagine you're a unionized truck driver, an interstate truck driver, [[00:14:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=865.64s)]
*  you're making $88,000 a year. [[00:14:29](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=869.9599999999999s)]
*  And your job is automated by a driverless truck, which we are currently pretty close [[00:14:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=872.28s)]
*  to being able to do. [[00:14:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=878.36s)]
*  In fact, maybe already can do it. [[00:14:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=879.16s)]
*  And then what? [[00:14:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=882.04s)]
*  And a UBI in a far-fetched scenario where we actually pass one is going to give you [[00:14:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=882.5999999999999s)]
*  $22,000 a year and also going to give me $22,000 a year. [[00:14:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=887.9599999999999s)]
*  So it's not enough of a solution for you. [[00:14:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=891.56s)]
*  It didn't replace your income or give you your dignity back. [[00:14:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=893.56s)]
*  And it's too much solution for me. [[00:14:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=897.48s)]
*  Like I didn't lose my job. [[00:14:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=899.4s)]
*  And the UBI thing always just struck me as a very strange, like, fanciful response to AI. [[00:15:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=901.4000000000001s)]
*  It might be good for other reasons, but AI is not going to put everybody out of work [[00:15:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=908.6s)]
*  all at once. [[00:15:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=914.0400000000001s)]
*  AI is going to make workers more productive, which will slow down the hiring of new workers. [[00:15:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=915.48s)]
*  And that's just a very, it's actually just a much harder problem to solve or to address. [[00:15:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=922.2800000000001s)]
*  How do you think we should address it? [[00:15:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=927.96s)]
*  I have no idea. [[00:15:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=930.6800000000001s)]
*  So even like in talking to the policy makers, there hasn't been anything floated that, [[00:15:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=932.2800000000001s)]
*  like, is this just something that we're all just going to stare at each other until it's here? [[00:15:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=938.0400000000001s)]
*  I think that going to some of your work on attention, you're going to need a focusing [[00:15:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=942.12s)]
*  event. [[00:15:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=946.84s)]
*  And we don't know what it will be yet. [[00:15:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=948.52s)]
*  Where something happens that clicks into place that this is a problem we need to deal with. [[00:15:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=951.24s)]
*  Now that people are really losing their jobs now. [[00:15:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=957.8s)]
*  And it's going to depend on how big that event in that trend are. [[00:16:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=961.4799999999999s)]
*  So a lot of people lost their jobs to the movement of factories to China. [[00:16:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=967.64s)]
*  We didn't really do that much for them. [[00:16:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=973.8s)]
*  No, we just failed to respond to that. [[00:16:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=976.04s)]
*  And it was very destabilizing over time in our politics. [[00:16:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=978.68s)]
*  I was talking to somebody who's in this world and he was a big skeptic [[00:16:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=982.12s)]
*  that AI was going to take away jobs, even though he was a big believer in AI. [[00:16:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=986.76s)]
*  And his argument to me was like, look, you're going to have so much capital investment [[00:16:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=991.64s)]
*  in data centers and all this. [[00:16:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=995.8s)]
*  We're going to need so many electricians we're going to meet. [[00:16:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=997.24s)]
*  And it struck me as very fanciful in this idea that we're going to turn all of these [[00:16:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1000.36s)]
*  comms majors into electricians really quickly. [[00:16:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1005.0s)]
*  So to me, I just haven't heard a solution that really makes sense. [[00:16:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1008.04s)]
*  And my worry, it's weird to be hoping for much more disruption rather than less. [[00:16:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1014.04s)]
*  But I think we would have a much better chance of responding to it well [[00:17:00](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1020.76s)]
*  if the disruption is significant enough to be undeniable. [[00:17:04](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1024.68s)]
*  Then if it is slow and a lot of little pieces happening kind of all at once, [[00:17:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1028.28s)]
*  but nobody can quite prove what it's coming from. [[00:17:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1033.32s)]
*  My confidence is higher in an almost emergency scenario of this [[00:17:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1038.36s)]
*  than it is in the accretion that I think we're likely to get. [[00:17:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1041.96s)]
*  Yeah. So you'd rather have a flood than a slow drip. [[00:17:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1047.0s)]
*  I think so. [[00:17:29](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1049.3999999999999s)]
*  Yeah. [[00:17:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1050.12s)]
*  What do you think would work? [[00:17:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1050.6s)]
*  I don't know either. [[00:17:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1052.36s)]
*  That's like the hard part of all. [[00:17:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1053.24s)]
*  It's so easy to diagnose problems and it's much harder to come up with solutions, it turns out. [[00:17:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1055.1599999999999s)]
*  But I don't know. [[00:17:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1060.9199999999998s)]
*  I mean, I think the physical world element of AI is also interesting too. [[00:17:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1061.56s)]
*  Like it does require a significant amount of resources. [[00:17:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1066.04s)]
*  The data centers are massive and they're quite loud if you're near them. [[00:17:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1069.0s)]
*  I think we are speed running it. [[00:17:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1073.8000000000002s)]
*  Like I wouldn't be surprised if we see a flood rather than a slow drip [[00:17:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1075.4s)]
*  just based on the amount of money that's going into it. [[00:17:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1079.3200000000002s)]
*  My version of what I think is going to happen, or one, [[00:18:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1082.8400000000001s)]
*  let's call it plausible scenario for what will happen, [[00:18:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1086.3600000000001s)]
*  is that it's going to be during the next economic downturn [[00:18:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1089.0s)]
*  when companies need to squeeze their labor forces. [[00:18:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1093.64s)]
*  That they're going to make a big transition to AI. [[00:18:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1097.56s)]
*  And so if you imagine the mixture, attentionally, of a recession, [[00:18:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1100.28s)]
*  which focuses a lot of coverage and interest on the economy, [[00:18:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1106.52s)]
*  and watching companies do what they've done in past recessions, [[00:18:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1112.6s)]
*  which is using the recession as a moment to make a technological jump [[00:18:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1115.32s)]
*  into some higher productivity technology like AI, [[00:18:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1119.24s)]
*  that I think is going to be the kind of scenario [[00:18:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1122.44s)]
*  where this becomes a really dominant conversation. [[00:18:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1125.5600000000002s)]
*  And by the way, you can imagine another category of answer to it, [[00:18:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1129.72s)]
*  which is regulations about how you can and cannot use AI to replace people, [[00:18:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1134.28s)]
*  and various kinds of protectionism. [[00:18:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1139.88s)]
*  There was a somewhat famous interview from a couple years back [[00:19:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1142.1200000000001s)]
*  between Tucker Carlson and Ben Shapiro, [[00:19:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1145.48s)]
*  where Carlson basically says trucking is one of the most common jobs [[00:19:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1148.3600000000001s)]
*  for men in most states. [[00:19:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1154.76s)]
*  Oh, I would absolutely outlaw driverless trucks. [[00:19:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1156.28s)]
*  And Shapiro's like, you would? [[00:19:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1160.36s)]
*  And Carlson's like, yeah, what's wrong with you that you wouldn't? [[00:19:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1161.4s)]
*  I think debates like that, should we actually welcome this productivity increase, [[00:19:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1164.52s)]
*  or should we stop it, will become much more salient, [[00:19:29](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1169.96s)]
*  and in a way that people are not yet ready for, [[00:19:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1173.48s)]
*  because they're so used to technology just being adopted as opposed to debated. [[00:19:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1175.8s)]
*  Yeah, not all progress is progress. [[00:19:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1180.92s)]
*  Right. Yeah. [[00:19:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1183.8s)]
*  I mean, I think that's the rub of it. [[00:19:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1185.8s)]
*  It's like, because what's also interesting about AI is like, [[00:19:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1189.24s)]
*  yes, it's being used to replace some jobs, [[00:19:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1192.36s)]
*  but it's also being used in ways that are spreading misinformation [[00:19:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1194.9199999999998s)]
*  and kind of capturing people. [[00:19:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1199.32s)]
*  People have sent 3 million messages to the AI chicken on Instagram. [[00:20:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1201.8s)]
*  Right? [[00:20:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1206.52s)]
*  And so you also have to question like not... [[00:20:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1207.1599999999999s)]
*  Just a hell of a sentence that I don't really understand, to be honest. [[00:20:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1209.1599999999999s)]
*  Really? [[00:20:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1212.4399999999998s)]
*  But I mean, I can too. [[00:20:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1213.0s)]
*  I guess there's a chicken that is AI generated on Instagram. [[00:20:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1216.12s)]
*  And you can message it and talk to it. [[00:20:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1220.12s)]
*  It says like, bok bok? [[00:20:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1222.04s)]
*  I don't actually know quite how it messages back, [[00:20:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1224.44s)]
*  but there have been 3 million messages exchanged with the chicken. [[00:20:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1227.32s)]
*  And there's all sorts of like AI slot videos on TikTok. [[00:20:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1232.36s)]
*  And that's a big part of it too. [[00:20:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1237.16s)]
*  Being a person, you find meaning within work, [[00:20:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1240.2800000000002s)]
*  but you also find meaning within how you spend your leisure time. [[00:20:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1242.8400000000001s)]
*  And increasingly people spend it scrolling, understandably. [[00:20:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1246.76s)]
*  Right? [[00:20:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1251.0s)]
*  I was on a plane ride yesterday for five and a half hours, [[00:20:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1251.4s)]
*  and the woman next to me was very nice, [[00:20:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1254.1200000000001s)]
*  but she was scrolling on TikTok for the entire five and a half hours. [[00:20:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1255.96s)]
*  And you can just only imagine how AI will accelerate the addictiveness of stuff like that, [[00:20:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1259.3200000000002s)]
*  as well as the impact it'll have to the labor force. [[00:21:04](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1264.2s)]
*  You talk about how AI is going to create this abundance of intelligence [[00:21:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1267.0s)]
*  that will create a scarcity of truth. [[00:21:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1271.0s)]
*  Tell me about that. [[00:21:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1273.72s)]
*  So yeah, I think truth is really valuable. [[00:21:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1275.08s)]
*  It's the most important commodity of the present moment. [[00:21:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1277.4s)]
*  And it's something that is increasingly scarce. [[00:21:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1280.76s)]
*  And once you lose it, it's very difficult to regain it. [[00:21:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1283.48s)]
*  And so I think AI is going to create a lot of information and a lot of noise. [[00:21:28](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1288.2s)]
*  And it'll be increasingly important for people to be able to sort the truth out from that, [[00:21:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1292.84s)]
*  because the AI does hallucinate quite a bit. [[00:21:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1298.1999999999998s)]
*  If you've ever talked to Chachi BT, it does make stuff up. [[00:21:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1300.52s)]
*  And you can be like, hey, you made that up, and it'll correct itself. [[00:21:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1303.32s)]
*  But you still have to be able to source what the truth is and what that means. [[00:21:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1306.36s)]
*  I think that's also the problem with social media, too. [[00:21:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1312.04s)]
*  It's like those algorithms are designed, [[00:21:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1314.1999999999998s)]
*  and the incentives are perhaps not aligned to the user. [[00:21:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1317.08s)]
*  They're aligned toward the corporation. [[00:22:00](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1320.6799999999998s)]
*  And so anything that people can get addicted to, [[00:22:03](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1323.56s)]
*  and there's a monetary incentive for them to get addicted to it, it's going to happen. [[00:22:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1326.9199999999998s)]
*  And so I think there is a world where the AI can be a source of truth, [[00:22:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1331.8799999999999s)]
*  but right now I don't think it is. [[00:22:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1336.04s)]
*  But people take everything it says at face value. [[00:22:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1338.36s)]
*  The number of at grok, is this true? [[00:22:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1341.32s)]
*  That happens on Twitter, where people are asking the AI to validate a tweet, [[00:22:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1343.9599999999998s)]
*  rather than go and do the research themselves and work that muscle in their brain. [[00:22:28](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1348.68s)]
*  It's concerning, because you do have to have a radar for truth, [[00:22:34](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1354.6000000000001s)]
*  because it's so easy to get taken advantage of right now. [[00:22:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1358.2s)]
*  There's just so much information, there's so much noise, and it's just nonstop. [[00:22:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1362.2s)]
*  And it's very easy to make mistakes, and a lot of people do. [[00:22:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1367.0800000000002s)]
*  And you have to be able to know what's true and what isn't, [[00:22:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1371.96s)]
*  and have your own moral and value compass. [[00:22:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1375.24s)]
*  So I guess maybe here would be an optimistic version of this, which is, [[00:22:58](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1378.28s)]
*  I think a very standard story about social media, [[00:23:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1382.28s)]
*  is it shattered the thing we now call consensus reality. [[00:23:04](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1384.52s)]
*  And how much we ever had consensus reality, I think you can debate, [[00:23:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1388.76s)]
*  but probably more at some other points in history than at this point in history. [[00:23:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1391.48s)]
*  And that what is AI, but an articulator of consensus reality? [[00:23:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1397.0s)]
*  Right, what is AI, but when you say, hey, is it true? [[00:23:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1402.76s)]
*  It gives you this sort of middle common denominator vision of truth, [[00:23:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1406.76s)]
*  which is going to miss perspectives that are maybe valuable at the margins, right? [[00:23:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1413.7199999999998s)]
*  I think there's a worry that AI will make us all more like media, [[00:23:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1419.1599999999999s)]
*  like AI is a technology of intellectual mediocrity, right? [[00:23:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1422.76s)]
*  It sort of coheres everybody on the same set of consensus ideas. [[00:23:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1427.6399999999999s)]
*  But we've been sitting here for so long lamenting the destruction of that consensus reality. [[00:23:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1433.08s)]
*  Maybe this world where everybody's asking, chat GPT or Grok, [[00:23:58](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1438.6s)]
*  is this true? Is exactly the thing we've been yearning for. [[00:24:03](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1443.1599999999999s)]
*  Maybe. [[00:24:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1447.4799999999998s)]
*  I think it has to get there. [[00:24:10](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1450.4399999999998s)]
*  Can't blame me for trying. [[00:24:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1451.8s)]
*  I think there's a lot of value in the optimism, but I think what you were maybe [[00:24:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1453.7199999999998s)]
*  talking about is sort of like dead internet theory almost, [[00:24:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1458.84s)]
*  where there is this intellectual flattening of the public, [[00:24:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1462.28s)]
*  and then maybe people don't come up with new ideas and they don't challenge themselves. [[00:24:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1465.3999999999999s)]
*  There's a bunch of articles talking about how the college students are having a tough time [[00:24:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1470.04s)]
*  because AI is making things a bit too easy. It's a little too frictionless. [[00:24:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1475.3999999999999s)]
*  And I think I worry about that too, like the cognitive effect it could have. [[00:24:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1479.72s)]
*  I noticed it in myself, if I overuse AI in terms of research, [[00:24:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1483.24s)]
*  which I do use it, I do use it. I notice the lack of sharpening of my own toolkit. [[00:24:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1487.24s)]
*  You've written a lot about this world in which it seems to you, [[00:24:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1495.48s)]
*  like the social incentive for thinking is being diminished. [[00:25:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1501.32s)]
*  Well, I mean, I have to be cautious of broad generalization. So like most of my, [[00:25:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1505.72s)]
*  I make videos about the economy, right? [[00:25:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1511.24s)]
*  And newsletters. [[00:25:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1513.24s)]
*  And newsletters and wrote a book. [[00:25:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1514.6s)]
*  And you're multi-platform. [[00:25:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1516.28s)]
*  But like I spend a lot of time on social media. And the reason I make videos on social media is [[00:25:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1519.24s)]
*  so I can understand the mechanisms. So every day I post a video on Instagram or TikTok. [[00:25:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1524.1999999999998s)]
*  And that way I can see how people respond and I can sort of get a radar for like how social media [[00:25:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1530.36s)]
*  is interpreting one side of a conversation. And so then in terms of the social incentive [[00:25:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1535.08s)]
*  for thinking, I mean, I do worry that social media has created elements of polarization. [[00:25:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1540.12s)]
*  That's been very widely discussed by a lot of people. [[00:25:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1545.2399999999998s)]
*  And I think AI could exacerbate that and make it more challenging for people to [[00:25:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1548.52s)]
*  go out and seek information. Like there's a lot of value in memorizing things. [[00:25:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1555.7199999999998s)]
*  So that way you can like pull forward that fact rather than going in and Googling. [[00:26:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1562.6s)]
*  But, you know, these arguments are also old, right? Like people did say the same stuff about [[00:26:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1566.28s)]
*  Googling. It's like making people dumb. And so perhaps it's just that same argument rehashed. [[00:26:10](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1570.92s)]
*  So I think AI is also bridged to this other argument you're making, which is that attention [[00:26:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1575.8s)]
*  is infrastructure. And one of the things you write in that is that traditional economic substrates [[00:26:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1583.72s)]
*  are land, labor, capital, bedrock inputs to make stuff. But now the foundational input is attention. [[00:26:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1590.52s)]
*  Walk me through that. [[00:26:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1599.96s)]
*  Yes. So that's an argument that you used to need things to kind of like raise money or like move [[00:26:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1601.4s)]
*  through the world. And now increasingly you can just have attention. And the idea is that attention [[00:26:50](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1610.12s)]
*  is increasingly becoming an infrastructure of sorts that people have to build upon. So no longer [[00:26:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1616.76s)]
*  is the economic foundation something like land, which is very physical labor, a person, capital, [[00:27:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1622.12s)]
*  actual money, it's attention and then narrative. So the story that you tell to gain that attention [[00:27:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1627.08s)]
*  is the capital that inflates the attention itself. And then increasingly now we have speculation on [[00:27:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1632.12s)]
*  top of both of those. So speculation is kind of like the operating layer, right? So it operationalizes [[00:27:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1638.92s)]
*  the attention and makes it move throughout the world because now you can attach actual dollar [[00:27:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1644.6s)]
*  signs to how much attention you're gathering. So things like production markets would be the [[00:27:28](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1648.9199999999998s)]
*  best example. So Polymarket has a substack and they wrote about a man that bet on Mamdami in the [[00:27:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1652.6s)]
*  mayoral race in New York, and he made like $300,000 off of it. And what he was doing was [[00:27:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1660.52s)]
*  essentially seeing where attention was going and trying to make inverse bets off that and seeing [[00:27:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1665.8799999999999s)]
*  where the story, the narrative was wrong. And he was able to operationalize that attention going [[00:27:50](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1670.12s)]
*  in the wrong direction, the story is being incorrect through speculation via predictive markets. [[00:27:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1675.8s)]
*  Does that make sense? Yeah. So this is sort of a weird way, it sounds to me, in which [[00:28:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1681.8799999999999s)]
*  I think we think of the attentional economics and revolution as being primarily about digital media, [[00:28:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1686.52s)]
*  but it sounds to me like the way you're describing it, I think this is true, [[00:28:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1692.52s)]
*  is that it's like the weird bastard child of digital media and financialization of everything, [[00:28:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1695.88s)]
*  that it's the ability to endlessly bet, right? The venture capitalists are betting, [[00:28:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1702.6s)]
*  the day traders are betting, the crypto people are betting. In a way, when we just give things [[00:28:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1707.0s)]
*  our time, we are sort of making a bet about what's important. Right, because that's like where, [[00:28:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1711.72s)]
*  so influencers, you get money through views, like that's the monetization of the attention [[00:28:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1717.88s)]
*  economy more or less, but now we're able to bet on where attention goes. So like influencers, [[00:28:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1722.6799999999998s)]
*  very box situation, like you have a video that does a million views, you make your money, [[00:28:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1728.28s)]
*  blah, blah, blah. But people can like bet on how much views your video might get. And so that [[00:28:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1732.6799999999998s)]
*  creates this multi-dimensional aspect to the attention economy. Well, and creates a feedback [[00:28:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1737.9599999999998s)]
*  loop too. I mean, polling has always had a bit of this quality, but I really watched with Mamdani [[00:29:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1742.6799999999998s)]
*  and Trump, the way the betting markets drive now feedback loops, where people see something [[00:29:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1747.4s)]
*  happening and then they begin posting more on it. And then the thing begins happening more and you [[00:29:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1755.0800000000002s)]
*  can see it in the betting market. And so they begin posting more on it or giving more money to [[00:29:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1759.0s)]
*  it or whatever it might be. And one, it turns attention into capital, right? Because money [[00:29:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1762.52s)]
*  follows it. And two, it just makes it realer, right? It is a way of something that's starting [[00:29:28](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1768.44s)]
*  small can become exponential just through these feedback loops. Again, if it's sufficiently [[00:29:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1775.4s)]
*  viral and people can keep picking it up. Yeah. And they do because it gathers like [[00:29:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1781.16s)]
*  when money goes, attention follows. When attention goes, money follows. And so it does create this [[00:29:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1785.88s)]
*  really quite nice, in terms of structure, not nice in terms of effects, but like nice feedback loop [[00:29:50](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1790.92s)]
*  that's really interesting to watch. And it was very interesting to watch what happened with Mamdani [[00:29:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1797.0800000000002s)]
*  and the prediction markets and how that moved him. And increasingly prediction markets, I think [[00:30:04](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1804.52s)]
*  it's always kind of been this way, but it's not what people think, right? Like they're not betting [[00:30:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1809.96s)]
*  on what they think. They're betting on what they think other people think. And so they're essentially [[00:30:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1814.12s)]
*  betting on the attention economy itself and using the stories that people are telling about said [[00:30:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1818.6s)]
*  attention economy to determine where their money should go. And then more money follows. It's crypto [[00:30:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1823.8799999999999s)]
*  in a sense. But so you said attention is a foundational input. That's clearly true for a [[00:30:29](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1829.8799999999999s)]
*  certain set of products. Does your theory of attention is as a major infrastructure input, [[00:30:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1833.88s)]
*  does it say anything about the big parts of the economy that we just don't pay that much [[00:30:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1841.64s)]
*  attention to that don't have big narratives around them? Or does that just that's just sort [[00:30:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1845.8000000000002s)]
*  of not part of this theory? So there's the physical world and there's the digital world. [[00:30:50](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1850.1200000000001s)]
*  The attention economy really applies to the digital world. There's elements of attention [[00:30:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1854.8400000000001s)]
*  that can serve the physical world. Like if care workers need a new policy passed around them, [[00:30:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1859.4s)]
*  the more attention that they can have on things like that, the better, [[00:31:04](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1864.3600000000001s)]
*  because that's how you get things done is a bunch of people talking about it. But yes, [[00:31:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1867.3200000000002s)]
*  the attention economy primarily sits within the digital world and the physical world [[00:31:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1871.72s)]
*  for now is free of it. There's a real thing happening here, but there's also a very speculative [[00:31:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1876.1200000000001s)]
*  attentional thing happening here. One thing about AI as a technology is that the leading figures of [[00:31:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1882.36s)]
*  it are very big influencers on social media. Sam Altman is probably the most masterful, [[00:31:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1890.1999999999998s)]
*  the CEO is alongside Elon Musk at driving attention to whatever he wants it to be on. [[00:31:36](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1896.4399999999998s)]
*  But the world of AI people are just extremely dominant on social media, on YouTube, right? [[00:31:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1903.9599999999998s)]
*  AI is a technology, but it's also a very compelling storyline in a way that very few other technologies [[00:31:50](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1910.5200000000002s)]
*  have been. How do you think that plays into this? Yeah, I mean, the entire S&P 500 is a bet on if [[00:31:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1919.0s)]
*  the AI will make it, right? And so there is a lot of money making really big bets and there is a lot [[00:32:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1928.68s)]
*  of incentive for them to keep attention on it and to hype it up as much as possible. I remember this [[00:32:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1934.76s)]
*  one interview that Sam Altman did where he talks about how AI is going to require a reordering of [[00:32:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1940.92s)]
*  the social contract. And so to go back what we were talking about at the beginning of the conversation, [[00:32:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1947.32s)]
*  when you hear something like that, you're like, oh, what does that mean for me in the 40 years [[00:32:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1951.8s)]
*  I have left on earth or 60 years or however long? And so I think for the AI universe, they do a great [[00:32:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1957.24s)]
*  job at keeping attention on them. And that's actually one very useful part about the image [[00:32:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1963.72s)]
*  generation and the video generation is that you're able to direct a lot of eyeballs towards your AI [[00:32:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1968.44s)]
*  model and then also use that AI model in a workplace. Hype is very valuable. So there's [[00:32:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1974.04s)]
*  a company called Cluey that raised, have you heard? Yeah, they raised $15 million from A16Z. [[00:33:00](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1980.2s)]
*  They're interesting. They have a lot of really, how would you say, engaging videos and they were [[00:33:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1987.08s)]
*  able to raise a bunch of money just on the back of those videos for essentially what is an AI [[00:33:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1995.1599999999999s)]
*  node taker. But they were able to capture attention. They were able to capture the $15 million because [[00:33:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=1999.56s)]
*  in this world where chat GPT or open AI and anthropic are so far ahead, the people that will [[00:33:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2005.3999999999999s)]
*  win in the AI world are those that can differentiate. And the way that you differentiate is through [[00:33:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2011.32s)]
*  attention. And then you get the special. What do they do to capture attention? Those videos. Roy Lee, [[00:33:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2015.72s)]
*  who's a CEO, he drew a, can I say dick? Sure. He drew a dick on the whiteboard. So it's just like [[00:33:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2021.56s)]
*  very- They have this line, cheat on everything, right? Yeah. And so it's just, the cheat on [[00:33:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2031.4s)]
*  everything is very inflammatory within itself, right? And so they mastered attention. Like, [[00:33:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2036.52s)]
*  they got two newsletters out of me and plenty of think pieces out of other people as well. [[00:34:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2042.6s)]
*  And it was just based off these videos. It's Jake Paul, Jake Paul, the boxer. He was a big YouTuber. [[00:34:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2047.6399999999999s)]
*  He was like one of the first Gen Z influencers and he got very popular through stunts and virality. [[00:34:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2054.2s)]
*  And you see startups now copying this Jake Paul playbook. We're going to be in your face. We're [[00:34:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2060.68s)]
*  going to be loud because in a world where it's difficult to differentiate AI products, because [[00:34:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2065.96s)]
*  it's all essentially the same technology underneath, you have to be able to draw [[00:34:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2071.0s)]
*  eyeballs. And that's where you get the speculative capital from venture capital. [[00:34:34](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2074.84s)]
*  Here's a question I have, even when I just try to think about the way attention and speculation [[00:34:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2079.48s)]
*  are matter in the economy. You know, the old book, James C. Scott's Seeing Like a State, [[00:34:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2085.0s)]
*  right? That the state has to make things legible to itself. The algorithm has to make [[00:34:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2089.96s)]
*  things legible to itself. And so those of us following along in life through the algorithm, [[00:34:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2094.36s)]
*  we'll see the things are legible to the algorithm. Clueless is very legible to the algorithm, [[00:35:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2101.0s)]
*  right? Because it has this high engagement strategy. On the other hand, 15 million bucks [[00:35:04](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2104.84s)]
*  from A16Z, it's nothing, right? On the list of AI investments, it's pennies. And most of these [[00:35:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2111.16s)]
*  companies making a ton of money or raising a ton of money, many of them are in stealth mode [[00:35:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2119.56s)]
*  because they don't want other people copying them, right? There's a lot happening that is [[00:35:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2125.0s)]
*  less attentionally salient. But because it's not visible to the algorithm, like we can't even [[00:35:28](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2128.84s)]
*  really discuss it. It is very hard to tell when you are overestimating the role of attention in [[00:35:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2135.0s)]
*  the economy, because the nature of the things that get attention, as you can see them more clearly, [[00:35:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2143.1600000000003s)]
*  and there are all these things that don't. Like an economics of attention needs to be able to [[00:35:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2149.56s)]
*  distinguish when attention is also misleading you. Like, how do you think about that? [[00:35:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2155.0s)]
*  Yeah, no, it's something I've thought a lot about because I do, you know, I do make videos [[00:36:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2161.64s)]
*  on social media. And so I can fall into the trap of thinking that that's the entire universe. I [[00:36:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2165.72s)]
*  think most people who use social media can fall into that trap. But there are a lot of companies [[00:36:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2169.88s)]
*  outside of the attentional universe that are creating very real things. But I think what's [[00:36:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2175.32s)]
*  been really interesting about the Trump presidency is that he's expedited the value of attention. [[00:36:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2181.16s)]
*  And so I think for him, like attention is the value creation. It's not like the path to value [[00:36:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2187.24s)]
*  creation. And so he has also established some sort of playbook within politics that people are [[00:36:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2192.12s)]
*  starting to follow. And so there's always going to be pockets of the attention economy that are [[00:36:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2198.3599999999997s)]
*  outside of the attention economy, right? But I think more and more things are falling within [[00:36:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2203.3999999999996s)]
*  the purview, including politics increasingly. [[00:36:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2209.56s)]
*  You have this line on Trump, you said, Trump is the first human algorithm hybrid president, [[00:36:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2213.64s)]
*  governing via truth, social truths, bond market reactions and direct market signals, [[00:36:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2219.72s)]
*  a feedback loop in a suit. Tell me about that. [[00:37:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2225.88s)]
*  I mean, the guy he uses truth social is his policy platform. Like we got an announcement about [[00:37:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2229.8s)]
*  a bombing of Iran via truth social. And so I think for him, like he's able to use this platform [[00:37:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2236.28s)]
*  that he owns as a way to spread messages and get his point of view out there to move markets, [[00:37:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2244.28s)]
*  which are quite responsive to him, to give his opinions on Elon Musk, to give his opinions on [[00:37:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2253.7200000000003s)]
*  the big, beautiful bill and tariffs. And so he uses truth social just as an extension of the [[00:37:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2259.4s)]
*  presidency in a way that we've never really seen a president do. Like we've never had a president to [[00:37:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2265.88s)]
*  tweets so much or truth so much, I suppose. [[00:37:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2272.04s)]
*  I refuse to use these stupid bespoke verbs. You had another line that I thought was very [[00:37:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2275.6400000000003s)]
*  perceptive on this where you said that the way things typically have worked is that events create [[00:38:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2282.6800000000003s)]
*  narratives. And the way they seem to work in the Trump presidency is that narratives create events. [[00:38:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2288.6s)]
*  I think it's all kayfabe to a certain extent. [[00:38:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2294.6s)]
*  What is kayfabe? [[00:38:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2296.9199999999996s)]
*  There's the theatrics. Like the show must go on type of thing in WWE. Like they're always in [[00:38:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2297.72s)]
*  character. They're always doing stunts and performance. And it's just always a show. [[00:38:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2302.8399999999997s)]
*  There's this great essay by Roland Boris that I always talk about, but it's called the world [[00:38:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2307.9599999999996s)]
*  of wrestling and how increasingly elements of politics then have elements of wrestling. [[00:38:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2312.12s)]
*  There's this theatric pursuit of justice, this theatric pursuit of truth, and you can align it [[00:38:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2318.8399999999997s)]
*  with how wrestling has a heel. And there's always a bad guy that you have to defeat. And then you [[00:38:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2326.2799999999997s)]
*  defeated the bad guy and you did a great job. And now on to your next opponent, which is kind of how [[00:38:50](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2330.68s)]
*  Trump moves throughout his presidency. He got bored of the war, essentially. [[00:38:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2335.96s)]
*  Yeah. I feel like this is one of the really interesting things. It feels like we get a [[00:39:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2341.64s)]
*  spectacle and then we move on from it because the policy never had a strategy. [[00:39:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2345.96s)]
*  Attention economy stuff. [[00:39:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2349.64s)]
*  Yeah. So did we destroy Iran's nuclear? There was a three-day news cycle here at [[00:39:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2351.0s)]
*  Feltamir, a four-day news cycle. We bombed Iran. Then there was an intelligence leak. [[00:39:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2358.36s)]
*  We only set it back by a few months. Then there was a Trump administration yelling at the intelligence [[00:39:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2363.32s)]
*  leak. And now we just moved on to debating the big, beautiful bill. It's not that past policy [[00:39:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2367.8s)]
*  efforts didn't create spectacles. They did. But the spectacles were yoked to some kind of [[00:39:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2373.64s)]
*  strategy and end goal. I mean, the terrorists have had this feeling too. What is our tariff [[00:39:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2378.44s)]
*  policy at this point? And what is it trying to achieve? Does anybody actually know? Could anybody [[00:39:44](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2384.8399999999997s)]
*  give me an account of our global tariffs and where they think they're going to be in 30 days or 60 [[00:39:50](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2390.2799999999997s)]
*  days or 90 days? There's something with the way things rise and fall now that genuinely feels [[00:39:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2394.04s)]
*  different. It's like once you've gone through the big storyline, it's like the thing has gone, [[00:40:00](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2400.12s)]
*  even if the policy has not been decided or the goal has not been reached, it's like the decay rate [[00:40:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2405.96s)]
*  has really accelerated. [[00:40:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2413.08s)]
*  Yeah. No, it feels that way. And I think it creates so much fatigue in people that are [[00:40:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2414.8399999999997s)]
*  paying attention, right? Because you're like, oh my gosh. And I think a big part of that is [[00:40:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2419.24s)]
*  the attention economy. Trump, he gets it. He gets how people work. He gets how people [[00:40:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2424.92s)]
*  consume information. And he knows that in order to keep people engaged, you have to keep moving [[00:40:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2431.4s)]
*  the storyline along. The guy is a reality TV star, literally. And so I think he understands that [[00:40:36](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2436.36s)]
*  better than any president we've ever had. And there are valuable parts to that playbook, right? [[00:40:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2442.36s)]
*  Like there is value in using social media as a tool to spread a message and to capture [[00:40:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2448.7599999999998s)]
*  people's attention and then send them somewhere rather than just dragging them along to the next [[00:40:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2454.9199999999996s)]
*  storyline. But yeah, I mean, I'm curious for you, you said past policies have had some sort of [[00:40:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2459.64s)]
*  spectacle. Like have you ever seen anything quite like what we're seeing now? [[00:41:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2466.9199999999996s)]
*  No, but it's hard for me to describe the difference because I don't know, it's like the [[00:41:10](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2470.92s)]
*  Obamacare fight was like a year, but it was driving for a year to an outcome. [[00:41:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2478.36s)]
*  There is this way in which it feels like the Trump administration loses interest before the outcome [[00:41:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2485.96s)]
*  is reached. What you just said a minute ago was that Trump gets this better than anybody alive. [[00:41:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2490.6s)]
*  He gets it. He gets how to engage you. Let me try this on you because I do believe it. [[00:41:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2498.52s)]
*  Everybody always says, everybody, but you know, pundits. He's trying to distract you. The Trump [[00:41:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2505.4s)]
*  administration is trying to distract you. Muzzle velocity, they're flooding the zone. Trump isn't [[00:41:50](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2510.92s)]
*  trying to distract you. Trump is himself distracted. He doesn't understand this better [[00:41:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2515.4s)]
*  than anybody else does. He embodies it. He has like, as you say, like you said a feedback loop [[00:42:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2521.8s)]
*  in a suit, but I don't even think it's that. He's just very, very, very distractible. Listen to him [[00:42:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2528.2s)]
*  talk. The way his mind works, he cannot follow oftentimes the thing he is talking about for more [[00:42:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2535.0s)]
*  than a couple of sentences before he wanders down another pathway. In the first term, somebody who [[00:42:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2543.3999999999996s)]
*  worked for him told me that to try to brief Donald Trump on policy is like chasing squirrels [[00:42:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2551.32s)]
*  around a garden. They just keep running in different directions. And so I think there's [[00:42:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2558.6800000000003s)]
*  a sense sometimes that Donald Trump is conceptually in control of events, right? That he has got some [[00:42:44](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2564.6800000000003s)]
*  plan, but I don't think it's that at all. I think that he starts things and then loses interest. [[00:42:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2572.2000000000003s)]
*  Now, in cases where there's like another part of the administration or the government that will [[00:42:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2579.6400000000003s)]
*  try to like drive the thing to its conclusion, it keeps going, right? Congress has a process to try [[00:43:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2585.0s)]
*  to decide if this bill is going to pass or not pass. Or Stephen Miller is very focused on his [[00:43:10](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2590.76s)]
*  hatred of immigrants, and he's going to keep using machinery of government to prosecute that as long [[00:43:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2598.6800000000003s)]
*  as he can. But Trump just sort of phases in and out of how much he cares about things. [[00:43:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2603.72s)]
*  What happened to Doge, right? That was like a big project, and Elon Musk was running it. [[00:43:29](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2609.48s)]
*  It very much could have continued at its level of aggression after Elon Musk left. A lot of people [[00:43:36](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2616.7599999999998s)]
*  thought it would. But we actually don't hear nearly as much about government reform and waste and [[00:43:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2623.3199999999997s)]
*  fraud and abuse as we did a couple of months ago, because clearly just Trump has moved on, [[00:43:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2629.16s)]
*  and other parts of the administration has moved on, and nobody actually owns the thing to drive it. [[00:43:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2633.08s)]
*  I think that the difficulty with Trump is that he really is like the algorithm. [[00:43:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2639.4s)]
*  And the algorithm just like lives for the moment. It's about the current thing. [[00:44:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2647.16s)]
*  And when the current thing moves on, it moves on, and so does he. [[00:44:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2652.52s)]
*  Yeah, no, I mean, that's a good point. So it sort of refutes the idea like, oh, he's not doing it [[00:44:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2657.24s)]
*  on purpose. It's just how he is. And I think part of it might be that perhaps I have a hope [[00:44:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2661.24s)]
*  that some elements of it is on purpose, because then it feels like there's more control happening [[00:44:28](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2668.6s)]
*  versus like it is really just a funhouse going on in the government. Because obviously things [[00:44:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2672.9199999999996s)]
*  have very lasting impacts. And I think your point, he is the algorithm. There is that element of [[00:44:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2680.4399999999996s)]
*  instant gratification that you see within him. Because he wasn't able to fix the war. He was [[00:44:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2686.84s)]
*  like, ah, never mind. But now what's going to happen to Iran? Are they going to continue to [[00:44:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2692.44s)]
*  develop these weapons? And what does that mean? And there's all of these real answers that we [[00:44:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2699.6400000000003s)]
*  still have to seek. And because I think everyone does get kind of yanked around in terms of trying [[00:45:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2706.2000000000003s)]
*  to follow what's happening next, it does create a very distracted, overwhelmed and fatigued public. [[00:45:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2713.4s)]
*  And then you have things like the big, beautiful bill, a bunch of Americans haven't even heard [[00:45:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2720.44s)]
*  about. So when you then get to thinking about, okay, like imagine Trump as like a golem summoned [[00:45:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2724.52s)]
*  by the attention economy. We are being governed by the human embodiment of the Twitter algorithm. [[00:45:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2732.52s)]
*  I actually believe this. So then it creates this interesting question, because on the one hand, [[00:45:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2740.68s)]
*  Trump is completely dominant over events. And on the other hand, he's not that successful. He's [[00:45:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2746.12s)]
*  unpopular. I mean, we're going to see what happens with the big, beautiful bill. But his ability to [[00:45:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2752.8399999999997s)]
*  actually drive all the way to the outcomes he wants is often weak. It looks like Republicans are headed [[00:45:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2759.8799999999997s)]
*  for a pretty bad midterm. Tom Tillis, the North Carolina senator, just said he's not running for [[00:46:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2765.64s)]
*  reelection. Because Trump threatened to primary him. But that's exactly what I mean. Trump got mad [[00:46:10](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2770.12s)]
*  at Tom Tillis for like a second, because Tillis is not going to support the level of Medicaid cuts in [[00:46:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2780.36s)]
*  the bill. Threatened to primary him, putting at risk a North Carolina Senate seat that could [[00:46:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2785.24s)]
*  become the deciding line between Democrats recapturing the Senate and not. That's not a [[00:46:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2793.0s)]
*  person acting out of anything more than a momentary incentive. That is a person who [[00:46:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2799.88s)]
*  is not thinking forward into his own future. Like the whole Trump experience in a way is like, [[00:46:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2809.48s)]
*  what would it be like to really live in the algorithm? What does the algorithm miss? What [[00:46:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2815.0s)]
*  can't it see? Like attention and its opposite. Like are simultaneously more salient than they [[00:46:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2819.0s)]
*  ever were before. Yeah, totally. I mean, and it kind of like, so Trump, yes, he's like very focused [[00:47:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2826.12s)]
*  on, you know, I guess he's a squirrel, so the next nut or whatever. And I think, you know, that gets [[00:47:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2831.64s)]
*  into the digital economy aspect of things. And then the physical world kind of falls apart, [[00:47:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2838.84s)]
*  because then we get science cuts, we get cuts to solar power, all these things that have real [[00:47:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2844.36s)]
*  world consequences, but because it's not within that algorithm, because it's not aesthetically [[00:47:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2851.4s)]
*  pleasing or whatever, you know, it gets ignored and forgotten about. And I think that is like [[00:47:36](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2856.36s)]
*  the biggest consequence of the Trump presidency is that he seems to forget that the physical [[00:47:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2861.48s)]
*  world needs investment just as much as his digital presence. Give me your theory of friction. [[00:47:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2866.6800000000003s)]
*  So basically, the idea of friction is that there is value in things being like a tiny bit difficult. [[00:47:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2872.6800000000003s)]
*  And so when we use digital tools, like there really isn't a lot of friction, like dating apps, [[00:47:58](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2878.92s)]
*  it makes dating very easy. DoorDash makes things coming to your house very easy. So you can kind [[00:48:03](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2883.96s)]
*  of have this like frictionless existence. You also have an algorithm that's designed around you. And [[00:48:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2889.1600000000003s)]
*  so you can be served anything within your echo chamber. And you don't ever have to, if you don't [[00:48:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2894.76s)]
*  want to kind of think outside of whatever you want to be thinking about. Whereas in the physical [[00:48:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2898.6s)]
*  world, there's a lot of friction. So if anybody's flown over the summer, it might have been a [[00:48:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2904.12s)]
*  challenging experience because we don't have enough air traffic controllers, we don't have enough [[00:48:29](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2909.3199999999997s)]
*  people doing maintenance on the plane. And it's just like little things like that, that, you know, [[00:48:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2913.16s)]
*  feel like they should be simpler. And they feel like they should be running smoother and they're [[00:48:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2918.92s)]
*  not because they're not part of the digital universe, they get so much money and investment. [[00:48:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2923.3199999999997s)]
*  And so it's this idea that there's a bunch of friction in the physical world, [[00:48:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2928.2s)]
*  and perhaps not enough in the digital world. Do you think those things are connected that [[00:48:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2931.96s)]
*  there's become so much friction in the real world, in the real world of building things [[00:48:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2937.64s)]
*  and accomplishing things, that it's created this like flight to the digital world that people are [[00:49:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2942.4399999999996s)]
*  over invested in the digital world, because we have done such a bad job managing friction in [[00:49:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2949.0s)]
*  the real world? Yeah, I mean, it's easier to be online, you don't have to like reckon with stuff, [[00:49:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2955.88s)]
*  unless you want to. And so I think you can create this curated experience, like my boyfriend talks [[00:49:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2961.4s)]
*  about it all the time. He's like, you can just have this perfect appearance. And like, wait, [[00:49:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2967.48s)]
*  you're in people write about this too, like your Instagram page is your best moments ever. And so [[00:49:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2971.7200000000003s)]
*  you can kind of have this life that isn't your life. Whereas in the physical world, you might [[00:49:36](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2976.92s)]
*  just be dealing with like headache after headache, like how do I pay this bill? How do I make rent [[00:49:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2981.56s)]
*  this month? You know, how to make sure I'm still succeeding in my job, all of those things. [[00:49:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2985.7999999999997s)]
*  So for you, there's a connection between friction and meaning or frictionlessness [[00:49:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2991.4s)]
*  and meaninglessness. Yeah. How do you draw that? I mean, I think the idea is that when things are [[00:49:57](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=2997.24s)]
*  a little too easy, it's tough to find meaning in it. Like if the way I think might be best to [[00:50:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3005.56s)]
*  visualize it is WALL-E. So like if you're able to kind of lay back and, you know, watch a screen on [[00:50:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3013.08s)]
*  your little chair and just have smoothies delivered to you, like it's tough to find meaning within [[00:50:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3019.24s)]
*  that kind of WALL-E lifestyle, because everything is just a bit too simple. Like the good parts of [[00:50:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3026.2s)]
*  life often come through the hardest struggles. And I think that that is where people do find [[00:50:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3032.28s)]
*  a lot of meaning. And that's what all the greats write about is like the struggle is the path. [[00:50:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3039.88s)]
*  Keep pushing the rock up the hill more or less. And so I think that's how I think about it, but [[00:50:44](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3044.76s)]
*  I don't have data to back that up. No, but you do have literary analysis that I've enjoyed. [[00:50:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3051.8s)]
*  You have a great piece, or I thought it was a great piece, on the screw tape letters. [[00:50:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3056.92s)]
*  Best book. Which is, well, why don't you describe what that book is for people who have not heard [[00:51:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3061.4s)]
*  of it? Yes. It's one of my favorite books in the whole world. You've read it? I have not read it. [[00:51:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3065.0s)]
*  Oh, you should. You should really read it. I will. It's actually one of my recommendations [[00:51:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3071.32s)]
*  for her here. But it's this demon called Screwtape, and he's writing these letters to [[00:51:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3076.6800000000003s)]
*  his demon nephew Wormwood. And it's all about how you demonize this human. So Wormwood has a human [[00:51:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3083.64s)]
*  within his care, and his whole thing is to bring him into hell and away from God. [[00:51:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3090.68s)]
*  And the way that you demonize somebody, you would think it would make them, you'd kill somebody. [[00:51:34](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3094.7599999999998s)]
*  You would want them to go kill somebody, right? That's how you would think of it. [[00:51:40](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3100.2s)]
*  But it's really just keeping that person stagnant. So all of Screwtape's letters to Wormwood are like, [[00:51:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3103.16s)]
*  no, just keep him not feeling anything. Keep him in one place. Don't let him fall in love. [[00:51:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3108.8399999999997s)]
*  Don't let him get passionate. Just keep him baseline. Keep him bored. Don't keep him [[00:51:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3115.16s)]
*  doing his prayers. Let him forget all meaning and purpose within his life. And that's when he'll [[00:52:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3121.24s)]
*  come to us, the demons. And then towards the end, Screwtape gets mad at Wormwood, [[00:52:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3127.0s)]
*  and they eat each other, essentially. Spoiler. [[00:52:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3131.96s)]
*  But it's a good metaphor for how badness moves through the world. Badness does [[00:52:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3136.2s)]
*  usually end up eating other forms of badness. Not to call Trump and Musk demons, but they're [[00:52:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3144.44s)]
*  infighting now. Trump is threatening to deport Musk. And so, not that they're bad actors per se, [[00:52:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3151.4s)]
*  but people who are trying to find perhaps bad parts of people are always going to find that [[00:52:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3159.0s)]
*  in another person, and they turn on each other eventually. Did you listen to my colleague, [[00:52:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3165.7200000000003s)]
*  Rostov, that's a podcast with Peter Thiel? I have seen clips. I'm not listening to the whole [[00:52:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3169.64s)]
*  thing yet. So this is Thiel's view of the Antichrist, largely, right? This is sort of his [[00:52:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3174.44s)]
*  theory of we will be lulled into the Antichrist one-world government by the environmentalists [[00:53:03](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3183.24s)]
*  promising us peace and safety. And there's something very strange about it. And he's out [[00:53:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3194.04s)]
*  there funding Palantir and surveillance technologies that sure seem to me like what [[00:53:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3198.84s)]
*  would create a one-world dangerous government. But I guess from this screw-tape letters, [[00:53:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3202.84s)]
*  if you're going to imagine that the worst thing for society is stagnation, that the true path away [[00:53:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3210.84s)]
*  from godliness is a kind of decadence, that there's a connection between those two theories. [[00:53:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3217.1600000000003s)]
*  But I would say the way that CS Lewis is writing screw-tape, or at least the way that I interpreted [[00:53:45](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3225.7200000000003s)]
*  it, was that if you do have people that are numb to the world around them, it becomes difficult [[00:53:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3231.1600000000003s)]
*  for them to push back if there is a Palantir takeover or something like that. So I think the [[00:53:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3239.6400000000003s)]
*  two worlds can coexist. And there's also the sense that there's some kind of corrosive [[00:54:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3245.8s)]
*  meaninglessness in the society we're building, in the absence of certain kinds of struggles, [[00:54:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3253.88s)]
*  certain kinds of social structures. I'm not sure we know how to pull those things apart. [[00:54:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3260.12s)]
*  But like when you said at the beginning of the conversation that the thing you hear a lot is [[00:54:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3264.36s)]
*  nihilism from young people. And the thing in a way that AI feels to me like it pushes is nihilism, [[00:54:28](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3268.76s)]
*  is a kind of sense of like, well, if this can do so much of my work for me, what am I exactly? [[00:54:38](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3278.36s)]
*  I don't think any of us know how to put this on the chart. But it certainly feels to me like [[00:54:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3286.92s)]
*  people are acting from a sense of its truth. Yeah, it's like one of those things that you can [[00:54:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3293.8s)]
*  feel when you talk to people. There is this element of fear and worry. And one thing about [[00:55:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3301.4s)]
*  the US is we don't really have a social safety net. And so if you do fall because of AI, [[00:55:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3309.56s)]
*  how do you climb your way back up? Who knows? And so I think people are trying to find truth [[00:55:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3315.96s)]
*  and meaning while having this technology that's incredibly hypnotic and will get more so hypnotic [[00:55:23](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3323.32s)]
*  with things like AI that also might take your job. And so it's a bunch of forces all at once [[00:55:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3331.16s)]
*  that is perhaps a bit too much for humans. We really haven't evolved that much since we're [[00:55:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3337.56s)]
*  hunter gatherers. And now we're being tasked with like in this hotel I stayed in New York, [[00:55:43](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3343.7999999999997s)]
*  they had all these headlines on the wall from the New York Times. And it was like- [[00:55:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3351.48s)]
*  Great paper. [[00:55:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3355.0s)]
*  Great paper. But it was, you know, people are looking for Amelia Earhart and basically [[00:55:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3356.04s)]
*  everything from like 1912 to now, like they had just these headlines in this picture. But [[00:56:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3361.56s)]
*  and I was looking at that and it was like the saddest headlines ever. And I was like, [[00:56:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3366.84s)]
*  I feel like I see all of those headlines just in one day now. You know, and it's like that [[00:56:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3369.56s)]
*  that was like 100 years of headlines. And I feel like I see all of that just in a day. And that's [[00:56:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3373.88s)]
*  a lot for the human brain to process considering we haven't really kept up evolutionarily. [[00:56:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3378.92s)]
*  You know, there's something in this you often make the argument that everything feels like [[00:56:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3384.2s)]
*  crypto now. And that feels relevant somehow here, where crypto has this quality of so much [[00:56:28](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3388.52s)]
*  energy and hustle and money and attention, all circling a kind of nothing at the core. [[00:56:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3399.7999999999997s)]
*  Uh, particularly as I think the more idealistic dreams of what it could do have faded and now [[00:56:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3407.8s)]
*  it's just pretty clearly a vehicle for speculation. And there's this way in which I think a lot of [[00:56:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3414.12s)]
*  things are developing a little bit of that quality, like politics sometimes develops that quality, [[00:56:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3419.16s)]
*  like it does really matter. But there is this kind of nihilism people can sense in it that [[00:57:04](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3424.68s)]
*  I think is really depressing, right? It really, really depresses people [[00:57:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3433.2400000000002s)]
*  and the economy, right? If you feel like you've put in all this work in your education and your [[00:57:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3437.08s)]
*  learning, and now the deal you're promised isn't really there. And we're inventing a, [[00:57:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3441.08s)]
*  like a computer program that can write your essays and do your learning [[00:57:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3451.16s)]
*  and produce the kinds of things we are asking you to produce better than you can. [[00:57:36](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3456.2000000000003s)]
*  This like, so you're still running really fast. You're still trying to get grades. You're still, [[00:57:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3461.2400000000002s)]
*  you know, like trying to achieve the thing. But what, what is at the core of that, right? [[00:57:44](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3464.6800000000003s)]
*  If it becomes a little bit less obvious. And I think hollowness is something people [[00:57:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3471.1600000000003s)]
*  sense really well and is very, very, very dangerous. [[00:57:58](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3478.28s)]
*  Yeah. No, I mean, I think, so I used to work in crypto and was like, once very excited about it. [[00:58:03](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3483.08s)]
*  And I was like, this thing is going to be cool and we're going to have alternatives and it's, [[00:58:11](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3491.24s)]
*  and it has increasingly become just purely a speculative asset. And there is that element [[00:58:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3496.12s)]
*  of hollowness in it. Like I know a lot of people still work in crypto and they're like working on [[00:58:22](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3502.2799999999997s)]
*  very cool projects and there's a lot of optimism sometimes, but you do see a lot of people in the [[00:58:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3506.68s)]
*  space being like, well, what is behind all, like what's behind the screen door or the curtain? [[00:58:31](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3511.96s)]
*  And I think that sort of speculative hollowness, as you've pointed out, does show up in how people [[00:58:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3517.08s)]
*  are trying to navigate their lives because it's like, what is next? What does this mean? [[00:58:44](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3524.6s)]
*  And I think part of it is this like broken ladder problem, right? So like you graduate from college, [[00:58:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3532.12s)]
*  do you get a job? 23% of Harvard MBAs were unemployed three months after graduation. Those [[00:58:58](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3538.76s)]
*  are the cream of the crop, right? If they can't find jobs, like that might be tough for you. [[00:59:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3545.32s)]
*  And you're like, you just see all this data and you're like, oh no, housing, career progression, [[00:59:09](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3549.7200000000003s)]
*  because people are taking longer and longer to retire. And so I think all of those points [[00:59:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3555.4s)]
*  can create that feeling of hollowness. Like what is it all for? [[00:59:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3560.84s)]
*  I have this sense that we are undergoing a kind of correction where interest and attention are [[00:59:24](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3564.28s)]
*  moving back into things that are just more difficult and more real. Like I would not have [[00:59:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3577.4s)]
*  thought I would publish a book on like zoning reform and the policies under which we can build [[00:59:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3589.32s)]
*  transmission lines. And it would become like a big national bestseller and throw off endless [[00:59:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3596.6800000000003s)]
*  discourse. And we're talking the day after Gavin Newsom signed a bill, really, really [[01:00:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3602.2000000000003s)]
*  changing the California Environmental Quality Act, right? So things are happening. [[01:00:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3608.92s)]
*  There's so much energy around, even just a conversation about how do we do things in the [[01:00:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3612.6000000000004s)]
*  real world, right? It was pent up, right? It's not my book that did this. It's that people wanted [[01:00:18](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3618.12s)]
*  there to be attention on this. And the book was a focusing event. [[01:00:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3625.4s)]
*  And even like with my thing, with abundance, I've noticed like the discourse that you would find if [[01:00:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3630.2s)]
*  like the only place you followed it is people screaming at each other on X. Like it's a very [[01:00:34](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3634.44s)]
*  polarized discourse with like aggressive defenders and aggressive critics. Whereas then in like the [[01:00:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3639.48s)]
*  world as I watch it actually filter through, it's like, I find moderates picking up parts of it. I [[01:00:46](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3646.28s)]
*  find leftists like Zoran Mamdani picking up parts of it. I find Gavin Newsom doing parts. It's just [[01:00:51](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3651.32s)]
*  everything is much more complex than the simulacra. Something you need to fuse the dynamics of the [[01:00:55](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3655.8s)]
*  tension economy and the real economy of the dynamics of performative politics and real politics. [[01:01:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3662.6800000000003s)]
*  So eventually, you know, the next Democratic or maybe even non-democratic president will be [[01:01:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3668.44s)]
*  better at managing both performative policymaking and spectacle, which obviously Joe Biden was [[01:01:14](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3674.68s)]
*  not even in the game on with strategies to actually try to get things done, right? Which he was [[01:01:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3680.68s)]
*  better on. I think that, you know, attention has become like more like capital and you need to know [[01:01:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3687.3199999999997s)]
*  how to raise it. But just like with capital to succeed in the long run, you also need to know how [[01:01:35](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3695.3199999999997s)]
*  to spend it. And I think right now there's a lot more sophistication in the raising of attention [[01:01:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3701.88s)]
*  than the spending of attention. And I think that's going to be a, it's like a societal learning [[01:01:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3707.1600000000003s)]
*  we're all going through together and not painlessly. But I wonder if like pretty impressive [[01:01:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3714.6800000000003s)]
*  things can't lie on the other side of it, right? If we could get some politicians who understood [[01:02:02](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3722.04s)]
*  both sides of it, more business leaders who understood both sides of it. The thing I'll say [[01:02:06](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3726.04s)]
*  about OpenAI and Sam Altman, as I said a few minutes ago, and it's true for Elon Musk too, [[01:02:10](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3730.92s)]
*  Sam Altman very, very good with attention, but OpenAI keeps releasing impressive products. [[01:02:15](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3735.64s)]
*  Elon Musk very good with attention, but SpaceX keeps doing impressive things in space. [[01:02:20](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3740.92s)]
*  That there is this way in which like the future belongs not to the influencers, but to the [[01:02:26](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3746.44s)]
*  influencers who can deliver. It's maybe not enough to deliver without being an influencer, [[01:02:33](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3753.16s)]
*  but it's also not enough to be an influencer without being able to deliver. I think that's [[01:02:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3757.56s)]
*  my optimistic take. Yeah. I mean, I think attention is a precursor to power rather than a byproduct [[01:02:42](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3762.12s)]
*  now. So it's like, as you're saying, like, you know, the more attention that you can raise, [[01:02:48](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3768.04s)]
*  like narrative is a form of capital. Mimetic storytelling is really useful. And then that way [[01:02:52](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3772.2799999999997s)]
*  you can like build all of that around yourself. And then it makes getting into power a bit easier. [[01:02:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3776.84s)]
*  The way that I think about it is there's extractive speculation and then there's strategic [[01:03:03](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3783.24s)]
*  speculation. So extractive would be like, you know, Trump kind of dragging people from one thing to [[01:03:08](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3788.2799999999997s)]
*  an extra, you know, clearly marketing campaign, just sort of like dragging people along. And then [[01:03:13](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3793.48s)]
*  they end up somewhere where they're like, where am I? But strategic would be, you know, like your [[01:03:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3799.0s)]
*  book, which got a lot of attention, got a lot of discourse, you know, reaching Gavin Newsom, right? [[01:03:25](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3805.08s)]
*  And like that was a really good use of the attention economy. I don't think it was intentional [[01:03:30](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3810.12s)]
*  on your part, but it was incredible, like the amount of discourse. And then now you've changed [[01:03:34](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3814.92s)]
*  policy, which is the ultimate goal, right? I don't want to take too much credit for this. It was [[01:03:39](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3819.4s)]
*  hopefully helpful, but a lot of people, shout out to us. Fair, but a lot of people work on this for [[01:03:44](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3824.12s)]
*  a long time. Of course. But you know what I'm saying? But you get what I'm saying? Yeah. Right? [[01:03:49](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3829.3199999999997s)]
*  Like, like there has to be an, as you're saying, like there has to be an end goal, but you can [[01:03:53](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3833.16s)]
*  still use the framework of the attention economy to get people to that end goal. And that's what [[01:03:56](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3836.68s)]
*  has to happen. Like the bones are still important and I think they're not going away for a bit. [[01:04:01](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3841.56s)]
*  But the question will be, where do they go from here? And you have to be able to send them somewhere. [[01:04:07](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3847.3199999999997s)]
*  And then always our final question. What are three books you'd recommend to the audience? [[01:04:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3852.9199999999996s)]
*  Yes. So I really like C.S. Lewis. And so I'd recommend the Screwtaped Letters. [[01:04:16](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3856.52s)]
*  And then I'd also recommend a Grief Observed, which is by him also. It's like a really nice [[01:04:21](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3861.4s)]
*  read on grief, because grief can feel very lonely when you're going through it. Like if you've ever [[01:04:27](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3867.64s)]
*  gone through a loss, it's just, it's devastating. And you feel like you're the only person that's [[01:04:32](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3872.76s)]
*  kind of experienced something so big and heavy and people are telling you it's going to be fine. [[01:04:37](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3877.2400000000002s)]
*  And you're like, no, it's not. And he just writes in a way that makes you realize you're not alone [[01:04:41](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3881.4s)]
*  in that. And my last book recommendation is Jonathan Livingston Seagull by Richard Bach, [[01:04:47](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3887.4s)]
*  which is about this seagull that, you know, everyone's like, you're never going to be able [[01:04:54](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3894.04s)]
*  to fly that far. You're never going to be able to do all of this. And he just takes it upon himself [[01:04:59](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3899.88s)]
*  to fly and I won't ruin the ending. But it's this really nice read on the power of people taking a [[01:05:05](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3905.1600000000003s)]
*  chance, but then what happens when we forget why we took that chance in the first place. [[01:05:12](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3912.76s)]
*  Kyle Scanlon, thank you very much. [[01:05:17](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3917.96s)]
*  Thank you. [[01:05:19](https://www.youtube.com/watch?v=cZO1B4fZlOw&t=3919.6400000000003s)]
