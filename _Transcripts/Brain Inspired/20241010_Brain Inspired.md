---
Date Generated: October 13, 2024
Transcription Model: whisper medium 20231117
Length: 4779s
Video Keywords: []
Video Views: 179
Video Rating: None
Video Description: This is the second conversation I had while teamed up with Gaute Einevoll at a workshop on NeuroAI in Norway. In this episode, Gaute and I are joined by Cristina Savin and Tim Vogels to discuss how artificial intelligence has influenced their neuroscience research, thoughts about brains and minds, and productivity.

Show notes: 
https://braininspired.co/podcast/196/

Patreon for full episodes and Discord community: 
https://www.patreon.com/braininspired

The Transmitter is an online publication that aims to deliver useful information, insights and tools to build bridges across neuroscience and advance research. Visit thetransmitter.org to explore the latest neuroscience news and perspectives, written by journalists and scientists. 

Read more about our partnership: https://www.thetransmitter.org/partners/

Sign up for the “Brain Inspired” email alerts to be notified every time a new “Brain Inspired” episode is released: https://www.thetransmitter.org/newsletters/ 

To explore more neuroscience news and perspectives, visit thetransmitter.org.

Apple podcasts: 
https://itunes.apple.com/us/podcast/brain-inspired/id1428880766?mt=2
Spotify: 
https://open.spotify.com/show/2UZj8c8Ap5oc2gh2rJxLLe
---

# BI 196 Cristina Savin and Tim Vogels with Gaute Einevoll and Mikkel Lepperød
**Brain Inspired:** [October 10, 2024](https://www.youtube.com/watch?v=jba080cZK8w)
*  This is Brain Inspired, powered by the transmitter.
*  Hey, it's me again. I'm on dry land. I hope that you are somewhere.
*  So this is the second conversation I had while teamed up with Gaute Einvall
*  at a workshop on neuro-AI in Norway called Validating Models.
*  How would success in neuro-AI look like?
*  Gaute creates his own podcast called Theoretical Neuroscience.
*  Go listen to it. I link to it in the show notes,
*  along with a handful of other relevant links to the good people you're about to hear.
*  That's at braininspired.co.uk slash podcast slash 196.
*  Thank you for supporting Brain Inspired, and thank you to the transmitter.
*  And we are back. We're still on a boat. I'm here with Gaute Einvall again.
*  We still have our, what is it, sea legs? Is that what they're called?
*  Absolutely. I think we all sort of after when we got off the boat, right?
*  We sort of all sort of like a little bit. It's interesting because I want to go vestibular system.
*  Balance system is a little bit out of whack.
*  Yeah.
*  Even back on land, we still have some oscillations.
*  Yeah. I was that last day we had another couple sessions or one last session
*  in a conference room off the boat, and I was a chair of one of the panels and moderated some things,
*  and I was standing up there sort of swaying still, you know, so that was fun.
*  Okay. So in the last episode, you heard from Andreas Tullius and Ken Harris.
*  In this episode, Gaute and I had a conversation with Christina Sauvin or Sabin and Tim Vogels.
*  And at the end of our conversation, we'll sort of wrap things up with Mikhail again,
*  who helped organize he and Conrad Kurding helped organize this workshop.
*  So I'll just start by saying we're not going to give huge introductions here,
*  but Christina gave a talk and about and researches more the theoretical side.
*  So she's right up your alley, Gaute, for your theoretical neuroscience podcast.
*  But she uses recurrent neural networks to study how learning works in a very theoretically driven way.
*  And I do want to say something about Tim.
*  Yeah, Tim has been working on synaptic plasticity for many years.
*  So I know, I mean, some of his work back from when he worked with Wilhelm Gelsner,
*  who educated many of the people working on synaptic plasticity in Europe.
*  So there he did some really interesting work, I think, on how networks sort of gets into this balanced state by self-tuning.
*  And vice versa, inhibitory plasticity.
*  And now he's sort of using this AI tools sort of to, or at least optimization tools to sort of to not just,
*  well, actually explore the whole space of possible synaptic plasticity rules.
*  So that was sort of, but it's really, yeah, his group in Austria is doing really excellent work,
*  I think, when it comes to exploring synaptic plasticity in its many facets.
*  I think even more so than the first one, the audio quality in this is sort of in and out.
*  There's a lot more creaking and noises.
*  This was in the night and we were, the sea was angry that evening, it seems.
*  It's actually, when I talk to the people on the boat about it, so say this, oh, this, because we pass Follas.
*  So it's like a well-known sort of stretch of ocean where it sort of often gets rough.
*  So this was sort of, so he said, oh, it's only going to last an hour or two, they said.
*  And then, thankfully, our discussion didn't get rough.
*  No, so that's no, no, no, it didn't.
*  So it was a little bit, it was also late in the night.
*  So that was also another reason for bumpiness maybe or, yeah.
*  All right. Anyway, final thoughts.
*  I mean, this was just an excellent workshop, excellent amount of people, excellent people.
*  It was just a lot of fun and I learned a lot.
*  Actually, and I like in a final comment there because when I asked Mikkel, because I think what people really liked,
*  what that was really was a wide variety of people there.
*  They had really different backgrounds.
*  And also one of Mikkel's worries, as he mentions, I think, was that people were not going to able to communicate,
*  to have some common ground to sort of to discuss.
*  But that was not the case at all.
*  And interestingly, he also said that some of the people he invited was actually,
*  he had heard on your brain and brain inspired podcast and got sort of.
*  So maybe that's also you can take some credit for the excellent selection of researchers who was invited.
*  Thankfully, I can take credit instead of be at fault because it worked out well.
*  That's true. Absolutely.
*  OK, enjoy our second discussion here.
*  We're going to ask you some general questions, many questions about the relationship with neuro and AI.
*  And we're going to start being a bit personal.
*  It's a bit late in the evening and both is maybe even more than when we did the other recording.
*  So but anyway, so in all sense, has neuro AI changed the way you ask questions or do do your science?
*  Kristen, you want to start?
*  I can go first. I would say that we were doing conceptually what we're now doing with neuro AI many years before the term was invented.
*  So like there are different flavors of neuro AI.
*  So there's the we kept talking about it throughout the week.
*  So there's the AI to neuro in data science terms and in theory terms.
*  And there's the other way around. And we do a little bit of everything.
*  But before there was AI, there was machine learning, and we did exactly the same things with a different set of tools.
*  So from my perspective, our fundamental structure of our approach hasn't really changed, but the tools have gotten better.
*  But how about for you in particular, you personally on a personal level?
*  No, this is specifically about the research that we do in my group.
*  Just briefly mention what your research in the group is.
*  So my my group is sort of like fundamentally interested in understanding principles of computation in the context of adaptive behavior.
*  And we're interested in sort of like normative, mechanistic interpretation.
*  So we make circuit level models of learning of memory of task dependent adaptation, attention, things like that.
*  So in normative, you mean that you ask how is this helpful for the animal?
*  Yes, exactly. So normative, we mean that we think that these are fundamental computation for the animals and through evolution, development, etc.
*  They've been optimized to do them well.
*  So then looking at the machine learning optimal solution of the same kind of problems should give us indication about the essence of the computation that they're doing.
*  And I think that it's really important for those computations to be like very important for the animal.
*  This wouldn't happen for everything, but that's kind of the approach.
*  But deep learning itself has not.
*  You're saying the machine learning tools that existed before deep learning were sufficient for what you do?
*  I'm saying that the structure of the approach, how we ask this kind of question has unchanged.
*  So before deep learning, we would formalize our normative descriptions of the task in probabilistic terms.
*  And you would use tools from Bayesian machine learning to say what the optimal solution looks like and sort of like try to make the maps to circuit function.
*  Now we have a richer set of tools.
*  So Bayesian machine learning, that's sort of like using machine learning techniques to help to make the map more efficient.
*  Techniques to help to find these probabilistic functions.
*  Yeah. So as I said, the tool, we have more tools and we have more powerful tools.
*  But the way we approach the questions hasn't really fundamentally changed.
*  I think I would agree with that.
*  Wait a second.
*  This is for what we do in my group. I'm not saying that this is a general statement.
*  What about you, Tim?
*  Based on your talk, I was thinking that you would have a different answer.
*  No, I thought maybe this is for the listeners.
*  That's what the introduction is for.
*  Okay.
*  You want to just give a brief roundup of what that is?
*  So my lab is similarly interested in circuit dynamics and the interaction between network level activity and plasticity rules.
*  So how do plastic synapses change the dynamics and how do the dynamics change the synapses?
*  Yeah.
*  And I think I spent a lot of my time as a PhD student and as a postdoc tuning spiking networks at times for months.
*  And now I don't have to do that anymore, I guess in part because I'm not the one doing the programming,
*  but also in part because the tuning part is being taken over by machine learning methods.
*  So how does AI change the way I approach a question?
*  I don't think about how painful the tuning is going to be anymore.
*  Parameter fitting.
*  Looking back, does that feel silly that you spent that much time or was that a valuable?
*  I think it was valuable. I think actually I had a blast doing it.
*  It was frustrating, but it was also rewarding. And I don't regret having tuned for six months.
*  But also, I mean, when I remember one of the papers that you wrote with Henning Speckle and also in the group Wolfram Gerstner,
*  was this really cool thing where like inhibitory plasticity does the tuning for you.
*  That came out of this.
*  Yeah, but that was, so this sort of, if you had the good AI tools then, maybe you wouldn't have thought about this.
*  No, I think I still would have thought about it.
*  Okay.
*  But we may not have hand tuned the rule.
*  Okay. Yeah.
*  And yeah, I think we will still.
*  So it didn't really, the absence of AI didn't help you to prevent?
*  I don't think so. I think there's other ways. You asked the other question, how has AI negatively affected your...
*  I was about to just go ahead and bring that up because yeah, I thought go ahead, you're going to answer it anyway.
*  I think there is a push, there's some pressure to use ML tools as a scientist.
*  And if you don't, you're not considered interesting.
*  But is that ML tools or is that specifically like deep learning?
*  I don't think it has to be deep learning. I think it has to be some flavor of large amounts of compute.
*  So if you don't, you don't agree?
*  No.
*  If you don't put in your CV somewhere that you've used 600,000 hours of CPU time, you're not available.
*  I don't put that on my CV. That's pushing.
*  So...
*  And I'm saying this facetiously, but there is a truth to that.
*  So now I know why I haven't gotten the grants lately.
*  This has not been on my CV.
*  I do think that the community has gotten more machine-like in the sense that it's driven by fashions.
*  And so the particular brands of deep learning have become fashionable and it's easy to publish certain things and very difficult to publish things with other tools.
*  But for me, the consequence of this fashion-driven research enterprise has been a reduction in the entropy of our approaches.
*  I agree. And there are some people that are... Sorry to interrupt.
*  Sorry. There are some people in our community that are very clearly very deep thinkers and very, you know, theoretically minded scientists that are our seniors that wouldn't get a job today because they're not using ML to further...
*  So I mean, it does, right? When the reduction in entropy... meaning that there's more things...
*  Basically, I don't think there is one way of doing research that solves all of the questions.
*  I think that there is strength in diversity in the community for the approaches because for different kind of questions, certain different approaches are better or sort of like make more sense.
*  And it's also sort of longer term. We want to preserve knowledge about lots of different ways in which to do things because they might become relevant again.
*  One of the things that I learned when I was an undergrad from one of my professors, I did computer science as an undergraduate, was about the sort of like really old ways of doing like memory storage.
*  Did they teach you how to do this?
*  Yeah, we had to learn this in school. And it's like, OK, why are we learning how...
*  Grad school.
*  No, undergrad, sorry.
*  She studied in Romania, so she's a hardcore...
*  Hardcore what?
*  We had to learn this in kindergarten.
*  It was sort of like we were learning in the computer science classes in undergraduate about the history of different operating systems and how they handled memory things and things like that.
*  That was like, OK, but we have better computers. We know how to do this better. Why are we learning these things?
*  And the moment when mobile phones came on, which had like very different resource constraints, all of these old tricks that were completely irrelevant for a number of years became all of a sudden like super relevant and super important again.
*  And I think this is the kind of thing that we also want sort of like as a community of scientists, we want to explore sufficiently many different things that like to be able to do sort of like long term selection, like this cross breeding of ideas.
*  If everybody like is, it's an echo chamber, everybody thinks exactly the same way. You have lost something really fundamental about the process of doing science.
*  I think there used to be a period about 10 years ago or so that there was a bit of a maybe a snobbery towards people that were purely numerical.
*  And that has flipped. And now there is a snobbery towards people that are not purely numerical. So that just theory will simply not get you there.
*  Well, neither of those are healthy.
*  No, no, clearly not.
*  That's exactly the point. Entropy is the answer.
*  Many approaches.
*  Yeah.
*  Actually, also in physics, it used to be that people who just do too much numerics, they were like number crunchers and not theorists.
*  Are you a theoretical physicist or are you even a physicist?
*  Exactly.
*  But one thing that I mean in your talk, you have used machine learning as a tool to explore the space of possible parameters that could tune the plasticity.
*  Right. And I mean, you were alluding to that earlier as well.
*  But so for you, it's really just changed the way you approach things. But as a tool.
*  Well, like my students can do things that I would have never been able to do.
*  They maneuver vast landscapes of parameters that I could only dream of.
*  Right.
*  And they have the means to not only just travel through them, but actually find meaningful combinations.
*  And that's just.
*  Well, that's so that's the whole point, right?
*  Because you've got to explore such a large landscape of possible combinations of parameters, you found the ones that actually work.
*  And the backstory of this, of course, is that there is a I'm just going to repeat the term.
*  I know it's said over and over.
*  There's a zoo of quote unquote plasticity rules in terms of the duration between pre and post spikes that then lead to strengthening or weakening synapses.
*  And it used to be that, you know, listen, Lomo, sorry, that's a technical sort of very specific thing.
*  That was the rule.
*  But since then, there have been lots of rules that have been found.
*  And what you use machine learning for was to explore the capacity, essentially the possibility of the rule space.
*  We added another 10,000 basically.
*  Yeah, it's sort of interesting.
*  It has some analogy or analogies to sort of like when we used to do like modeling of by physical detail, neuro modeling.
*  Right.
*  Then there was only like a handful of models that people used, like maintenance and off scale, a few cells.
*  And and so so we did.
*  Yeah.
*  So there was like a few cells that everybody used, essentially.
*  And suddenly you got this automated way.
*  So to make these neural models, right.
*  So you got like the blue brain project produced a lot of of neural models and also the Allen Institute.
*  And so suddenly you go from like three or a handful of neural models to like a whole.
*  So has it made life more complicated?
*  I think for morphologically plausible modeling, certainly.
*  I think choosing what model you want to use has not gotten easier.
*  But also for you to in this like this to this synaptic plasticity rules, right.
*  You showed us.
*  No, I think for us it's gotten a little easier because I mean, we have different questions, but they're certainly more satisfying because when you found a single rule that worked, it was almost certain that you were wrong.
*  And and the experiments were incredibly arduous to do.
*  And now that's not I mean, now we're still wrong.
*  But you have a space of hypothesis.
*  Yes.
*  I think that's actually one of the good ways of using these more powerful tools that we've inherited from the deep learning revolution is to explore options that you wouldn't have thought of otherwise.
*  They're not so expensive to explore as well, right?
*  Timewise.
*  Yeah. And it's sort of like practical for a PhD student to do that and get the PhD in a reasonable amount of time.
*  So sorry. So what I'm hearing from you both and I think that everyone in neuroscience would agree is that the new brand of deep learning machine learning on steroids and AI as great as tools.
*  However, it seems like you both agree that there's something lost in terms of the knowledge of the other spaces of possible solutions to things and approaches.
*  I don't know if it's lost for us because we already have.
*  We're old enough to know things, but I don't worry about sort of like the incoming PhD students who like have have been trained like know how to train convolutional neural network or whatever.
*  They know how to run some deep learning or the diff and they come to their PhD and expect that to be the essence of what you do worry about that.
*  I do worry about that.
*  So it's like we were talking about sort of like negative impacts.
*  I think I don't know if we are just old, right?
*  We just sound old.
*  We're older and younger.
*  And it's just saying that you guys are the young.
*  Let me finish the thought.
*  So I think there's like with really powerful tools, they're as good as that as you sort of like your uses of them are.
*  So like it's it's it has the potential of mixing substantially better.
*  But but in in the wrong hands, it could like also make things much worse.
*  So so my worry about sort of like our ability of our students to critically think they use these tools in a reasonable way.
*  So so like the focus now for like if you're thinking about a junior person trying to get into this field is like it's not how you use its tools.
*  Like you can go to the Internet and sort of like learn how to do that in a week.
*  That's not the educational component.
*  The educational component is how to think hard about the problems and the use of these tools in a meaningful way.
*  And that's hard because the objects are increasingly complicated.
*  So like reasoning about them is hard.
*  I remember this.
*  I read this this line of Linus Pauling.
*  He was the guy who sort of like found the structure protein.
*  Right. So he said that like when he sort of did this X-ray of this, he had to do so much manually and it was so many.
*  So he had so much time to think about things.
*  So he was worried that these with the new tools where you get this extra spectra out or like automatically.
*  But wasn't it wasn't it Socrates who said that he worried that writing would make us dumb.
*  Yeah.
*  I mean, I was thinking you sort of from this this paper that you mentioned of where you tune this inhibitory plasticity to get to the balance state.
*  Right. So I mean, in this process of tuning by hand, you thought about it much more.
*  For the ISP paper, we didn't tune.
*  That was the beautiful thing was the inhibitory synaptic plasticity paper.
*  OK.
*  We tuned for the balance paper the two years before that.
*  Yeah. OK. So then you tune that.
*  But then then for the did you learn much about it?
*  And then you get like the dynamics of the network on the ocean.
*  So that's still do in fact.
*  And it's but you do that also with the machine learning techniques.
*  I think my students do.
*  Yeah. They sort of have like an intimate.
*  I think so. Yeah.
*  I keep thinking about this.
*  Like this was it took another Clark quote about any sufficiently advanced technologies not indistinguishable from magic kind of comment.
*  I sometimes I feel that these these sort of like the at least Transformers and some of these like really big LLM and things like that feel like magic to me.
*  And I wonder how many of the neuroscience users of that technology treated a little bit like magic that you you're so detached from how it does things.
*  What are its limit cases?
*  What are the things that it could could possibly go wrong?
*  Then you kind of take for a given that whatever that thing spits out is the truth.
*  So I think that's that's kind of the thing that I think is the most important thing.
*  The truth.
*  So I think that's that's kind of another thing that we're kind of losing with with all of this complexity that the wearability to sanity check the process becomes very, very hard.
*  So I guess I mean you both say that sort of like that it has improved the methods for doing what you already were interested in in some sense.
*  Right.
*  And then so that's like an improvement of tools.
*  But and I guess I mean these tools will lead to new discovery, hopefully new discoveries in the future.
*  But has it already have some examples of where it has already changed the way you think about the brain and cognition or well, so we've been talking about the tools.
*  And the other side of that is this continue this continually growing people are very excited about sort of using deep learning models as a proxy to model brain areas and they understand brain areas and or cognitive functions better.
*  And that's sort of the that's a different passive neuro neuro AI.
*  So the you know, that's where I was thinking like, well, has it has it changed the way that you thought about how brains function in sort of not as not from the tool front, but from the using them as models of brain function.
*  So like when I said normative, we are actually doing that to some extent.
*  And there is one example where I was like, OK, I started my faculty job saying that we're going to do interesting mathematically tractable things.
*  And this is going to not be a deep learning lab.
*  It was sort of like forcefully and sort of like then students came into the lab and they really, really, really wanted to do it.
*  And sort of like then I had to do deep learning, do deep learning methodology.
*  And we tried to think really hard about how to do that in a way that's not stupid and trivial.
*  So like I couldn't stand by my original statement, but I was pleasantly surprised in a couple of occasions.
*  They were doing deep learning after you left for a for home or something.
*  But that must be a serious these days. Doesn't every student want to come in and do deep learning?
*  This is the problem partly.
*  Not to my lab, I have to say. No, but I do spiking networks.
*  There's no, but I just I don't know. Everyone wants to apply it to everything.
*  So I imagine it's going to happen sooner or later.
*  There is one example where sort of like there's a problem that we've been thinking for a very, very long time.
*  And and using tools from deep learning to ask those questions gave us qualitatively different solutions.
*  And that's sort of like trying to think about how the brain inferred is inferred from noisy observation,
*  things that are important for like latent states in the world that are important to drive behavior.
*  And we and others have a cottage core.
*  Like there's an entire nation computational neuroscience, engineering, probabilistic representation.
*  So how would neurons go about encoding beliefs about the state of the world?
*  You're on that paper with Ralph Hefner.
*  Yeah, for my things. It took us I don't know how many years to write.
*  Yes. But like those are sort of like very constructive, like me as an experiment, as a theorist,
*  I go about and say, like, how would I go? What do I think are the things that are important?
*  I know math. These I think are the things that are important according to math.
*  And this is how maybe I could map them into into neurons and neural activity.
*  And in a recent project where we're trying to understand the behavior of animals making inferences about changes in the context,
*  we have to take your hands off this. It's going to keep creaking.
*  Sorry about that. Yeah.
*  So we went a different route because the task was sufficiently complicated that it wasn't obvious how to apply the traditional approach.
*  We we try to train some deep reinforcement learning agents to do the task.
*  And at the level of behavior.
*  So when we're analyzing this recurrent neural network the same way as we do the animals,
*  their behavior looks close to optimal probabilistic.
*  But if you open the box and look exactly what they're doing, it's nothing like any of the solutions that we have imagined empirically.
*  So so this kind of like taught us a big lesson that this sort of like perfect mathematical elegance in the map to to the neural activity was probably a futile endeavor altogether.
*  And that there are kind of this not so obvious ways in which to achieve functionally the same thing.
*  And we wouldn't have ever come up with those kind of solutions on our own without the use of these technologies.
*  But I think those examples are still rare.
*  Are you still are you thinking how does the neuron implement backprop?
*  Some people think that right.
*  I don't care at all.
*  Yeah, I don't care at all.
*  No, in terms of finding parameters.
*  Yeah, no, I just like I'm like meh.
*  It doesn't I don't know.
*  You need to be sort of like like to care about how if you care about learning at the circuit level, I think you do need to care about how does task relevant information shape synaptic
*  plasticity in a way to drive behavior towards good states and back up our best for time in this case are mathematical tools to formalize that problem in precise ways.
*  I guess I mean, you're just in your project.
*  You were just interested in getting a good solution.
*  So it is like in this I say in war, love and optimization, everything is it's OK.
*  Yeah.
*  And not everything is is global.
*  Right. There's a lot of local learning.
*  There is not not backprop biology.
*  Right.
*  I just published a paper on the archive that says like at least 50 percent of what they see in terms of learning effects can be explained with local changes and local rules.
*  And but that's a question of what's happening in real race.
*  Yeah, yeah, exactly.
*  So how is backprop implemented is not that interesting a question for me.
*  Yeah. So Tony's either would have totally like this answer.
*  I still believe that there's a sufficiently large amount of of goal directed learning happening that we need to figure that out.
*  Yeah.
*  Tony's going to be on my podcast again.
*  So he's been on it before, but I don't know if it'll come out before this chat or after it depends on how long they keep inviting us to the same neuro AI meetings and they keep putting his talk before mine.
*  So he gives an entire amazing talk about how the brain does very little plasticity and it's all sort of like evolutionary inductive biases.
*  And then I go say I'm going to give you a talk about plasticity.
*  Are you going to that this year?
*  Because it's at the end of this month.
*  I was asked to go and I was like I don't know.
*  No, we've already done a new CL1 this year.
*  So what meaning is this?
*  It's the Cold Spring Harbor.
*  Spiking networks, ironically called spiking networks.
*  No, this is a neuro AI.
*  There's a neuro AI.
*  Something subtitled.
*  Yeah, subtitled spiking networks.
*  Yeah, there you go.
*  So yeah, but anyway.
*  Ironically, no spiking networks.
*  So it doesn't sound like it sounds like you don't give a damn about no, I'm just kidding.
*  It doesn't sound like, you know, like this deep learning revolution has changed the way that you think about brain function.
*  No, I don't know that it has.
*  I'm still interested in the same things.
*  I'm interested in local changes in plasticity rules and neuromodulated changes to activity that will then produce local changes in plasticity.
*  I wouldn't say the same like for us.
*  So sort of like what's changed is the scale of our ambitions.
*  So with this set of tools, we attempt to understand adaptive behavior of much higher complexity than we would have without it.
*  That doesn't speak to like the way that you sort of internally think about how brains function.
*  No, no, this is why I said that our methodological approach only has gotten richer, but it's like structurally hasn't changed.
*  But I mean, you have sort of, I mean, you are sort of like what you're doing, like he's pointing at Tim, folks.
*  What? Tim? Yeah, Tim. Tim.
*  You have sort of worked a lot with like with spiking networks of like integrating fire type and which is sort of like it's not like multi compartmental modeling, but it's still quite biophysical.
*  Right. And you think the or it's sort of like physical right.
*  I mean, they are real things.
*  So do you think, I mean, do you think that this focus on AI and will sort of actually, I mean, suppress or like the activity?
*  I mean, that's no, I don't think so.
*  Look, I mean, that's part of part of the appeal of I think the questions that we're asking in my lab is that we're not competing with the big companies.
*  We're not competing with DeepMind.
*  They don't give a shit about spiking networks because so far they haven't been proven to be computationally viable.
*  And one of the questions in my talk was can't you find a function or a task that is actually computationally interesting?
*  All the neural tasks you have memorizing something are totally boring for someone who's doing AI.
*  But you still have this potential for super-sensory AI.
*  That's an argument that people make for spiking.
*  I don't know.
*  That's making spiking networks the water carrier for big AI.
*  And I don't, that's not my interest.
*  I want to understand how the brain works.
*  Sure. Yeah. Cool.
*  So do you think, I mean, I think that's part of the appeal of the big companies is that they're not competing with the big companies.
*  So how do you see, well, these are exciting times in AI.
*  So how do you see the relationship between AI and neuroscience in the spec like that in the years to come?
*  Long-term future.
*  By the way, sorry, Kristina, you got the, I think you almost got the quote verbatim.
*  It's Arthur C. Clarke.
*  It's any sufficiently advanced technology is indistinguishable from magic.
*  Sounds like you got it verbatim.
*  Yeah.
*  Yes.
*  I think about that a lot.
*  Sorry to interrupt.
*  Thank you.
*  So the future of the interaction between AI and neuroscience, I think that's actually where at the moment where this is like maximally unclear.
*  And one reason for that is...
*  Maximum entropy, isn't that what you like to say?
*  Like, I think that's the question.
*  But this is an accidental happening.
*  So on one side, AI is in this phase of young enthusiasm and exuberance.
*  So like you blink and the entire sort of like set of those fanciest architectures, fanciest trick has already changed.
*  Like you can't keep up with the literature, the things change so fast.
*  So it's hard to say what like AI would be like if it were to be like, you know, like a science fiction, like a science fiction, like a science fiction.
*  So that's kind of a big source of uncertainty because we don't know why, like where that's going.
*  Presumably, like as this thing matures, you're going to see the same kind of things that you see in maturing other fields.
*  So it's going to be less about like changing our mind about how we want to approach this every every few months.
*  So I think that's the kind of thing that's going to be happening.
*  So it's going to be less about like changing our mind about how we want to approach this every every few months and more
*  about sort of like converging to a set of good solutions and trying to build the foundational understanding of why they work.
*  We're not there yet.
*  But you so you think that this recent exuberance will die down in the next couple of years?
*  I think we're just going to switch course.
*  I think general artificial intelligence is not far off.
*  Oh, geez, hot take.
*  I'm gonna not say that.
*  At least in parts.
*  We're gonna have a remote control.
*  Washing carol?
*  So what do you find is general?
*  Is creativity in creative?
*  I don't know that we're gonna be
*  using this as humans for a while.
*  Because creativity is
*  not part of your definition of general.
*  Yeah, I would say.
*  Transferable skills, fine.
*  Creativity and...
*  I'm not too sure that that's true. I think LLMs do
*  something good, but it's not
*  general intelligence.
*  But we're closer to it than
*  I think we can project
*  like we can project two years
*  down the road. And so
*  what the relationship is between AI and
*  neuroscience is entirely
*  dependent on how
*  for the next two years
*  is gonna be entirely dependent on
*  how quickly
*  tools from AI are gonna become
*  ever more powerful.
*  To understand relationships
*  in neural recordings
*  that we can't even fathom yet.
*  Yeah, I mean, we're gonna become users
*  of this technology, that's for sure.
*  But...
*  We already are.
*  To an even larger scale. So it's gonna be kind of the bread and butter
*  that you need to know how to do these things.
*  But...
*  NLP is spiking...
*  I do wonder, what's
*  purpose does basic
*  research in neuroscience serve?
*  If you have
*  a functional model of
*  general artificial intelligence.
*  A lot of the original
*  motivations of why I got
*  into this field was
*  this is the most intelligent
*  system that we know, so if you want to
*  understand principles of intelligence, looking
*  at the brain is a good idea.
*  But if we have
*  an artificial model of that, that we're satisfied
*  with to some degree,
*  I think it's not clear exactly how
*  to assess that. But assuming that
*  that would be the case, then I think
*  the computational neuroscience
*  community would have to have some really
*  serious soul searching about
*  what are our questions, what
*  purpose do we serve now?
*  And...
*  Like what
*  Ken and Andreas
*  were saying earlier about sort of like, maybe
*  this becomes more about
*  circuit level and
*  molecular, sort of like, going more
*  low level. So systems neuroscience will
*  not have that much of a purpose
*  in basic research terms, but you're
*  going to have to go down
*  to get to the clinical applications
*  part of the process. Might be one
*  way this would play out. That would make me
*  very miserable and I might have to change fields.
*  But who knows.
*  But sort of, I mean, one thing that
*  we have seen is, for example, talking about Andreas
*  that he's sort of been making these
*  foundational models which are extremely
*  good, based on deep networks,
*  extremely good at predicting, like
*  in neural activity
*  and neural responses based on
*  visual input.
*  But it's difficult to interpret.
*  So this thing of
*  getting increasing predictability
*  and losing... So the older models
*  were sort of not as good at predicting
*  things, but you can sort of think about things
*  like receptive fields and Gabor functions
*  and... So are you more comfortable
*  maybe? Are you comfortable about sort of having
*  less interpretable models, but
*  more?
*  I think
*  interpretability is a concern.
*  I think, like,
*  what modern
*  deep learning tools are providing us,
*  which is kind of going back to the general
*  intelligence discussion, are
*  extremely powerful statistical
*  descriptors of large quantities
*  of data. So
*  there's a very big difference between
*  like very good statistical
*  descriptions of the data set
*  and a process model that describes
*  the causal relationships that
*  generated that data. Like, those could
*  be completely different solutions,
*  solution classes.
*  So I think
*  ultimately we want to
*  understand how things work and we need process
*  models. So that
*  it can't be the end of the story
*  because it just
*  summarizes exceptionally well
*  a large amount of data.
*  But it also won't work to replicate what
*  computer science has done, which is
*  to create systems that we then don't
*  really understand.
*  So our goal is to understand the brain, so
*  it won't help to simply replicate
*  the brain in silico.
*  Yeah.
*  There's another famous quote, like,
*  I don't understand what I can't create. But I think
*  the fact that I can create something doesn't
*  necessarily mean that I understand it.
*  Yeah, you said that. Right assignment is wrong.
*  The converse is not true.
*  But also I think if you have like this,
*  at least if you have like a
*  biophysical model,
*  the network model, which of course
*  is just as complicated as a deep
*  network in some sense. But at least
*  if you're able to make this model
*  predict experiments, then you can
*  start, it's like a white box, you can start
*  playing with it, turning it
*  around. So in that sense
*  it's like a beautiful research
*  animal in some sense.
*  It is a beautiful research animal, I agree with that.
*  A one-to-one map of the world is
*  going to be as...
*  The best model of a cat
*  is the cat. Preferably the same cat.
*  I don't know, is it?
*  Is that Schrödinger?
*  I don't remember who that is, but
*  this is a quote from the very first summer
*  school ever on computational neuroscience
*  that I attended.
*  I keep collecting these.
*  Yeah, someone else, I don't have any good quotes.
*  I like the other one better with a cat,
*  which goes, science is like looking for a
*  black cat in a dark room, and it's
*  not even a cat.
*  And I think that's what we're asking,
*  right? What's the relationship with AI
*  between AI and neuroscience?
*  It's not even a cat.
*  But going back to the original question, what's
*  the future of the relationship between AI
*  and neuroscience? I don't know,
*  but I'm kind of excited to find out.
*  I think this is going to be fun,
*  whatever crazy thing happens.
*  Do you have an AGI take?
*  No. Ten gave heads, Christina gave heads.
*  No, I don't
*  have anything
*  worthwhile to say about this.
*  So I think
*  it's telling that we can all
*  three, because I think it's, first of all,
*  I think that we have a misconception of what
*  intelligence is, but we all have a different definition
*  and we have to operationalize it, et cetera, et cetera.
*  But I think this, what I think of
*  AGI is like way
*  far away, and we can all three disagree, and
*  none of us knows anything.
*  That is exciting. I should mention
*  that, I mean, I used to do
*  Convince Matter Physics back in the days
*  before I got, that was a postdoc, I took a PhD
*  and was even an OK postdoc doing this.
*  So I switched at the late stage.
*  And of course,
*  and this was at the time when
*  I would say we sold the Schrodinger equation
*  and we sold it. But there was
*  no mystery at the end of the rainbow.
*  And then you come to
*  neuroscience and we understand
*  so little, but it's fantastic. There's no rainbow.
*  Rainbow, yeah.
*  You're trying to indent the rainbow.
*  I think it's fantastic.
*  At the end of it, somewhere far out there
*  there's consciousness.
*  Right? Yeah, sure.
*  There's no rainbow, but there are leprechauns everywhere.
*  I think so. That's fun though.
*  I agree with Christina. I mean, it's fun that we are
*  and it's a big privilege to really
*  be at the frontier of this sort of
*  of this big unknown.
*  So we already,
*  I mean, we already kind of talked about what
*  they believe neuroscience can learn
*  from AI, and that's really in the form of tools.
*  I mean, that's just
*  mostly a tool.
*  Yeah, I wish there was more the other way
*  around. And like we have
*  What AI can learn from neuroscience?
*  Yes, so ways in which
*  knowledge from neuroscience informs
*  architectural choices, for instance,
*  in deep learning or other
*  algorithmic
*  quirks. I think it's sort of like
*  there is a transfer the other way
*  around, but it's kind of subtle
*  and it's not like one thing that made a
*  humongous impact, but it's sort of like
*  in subtle ways it affects a lot of things
*  that are happening in the environment.
*  Like what?
*  Like neurons
*  and attention being the immediate obvious
*  things, but also sort of like
*  the way they approach interpretability
*  of their trained recurrent neural
*  networks is essentially by treating it
*  like a brain in doing neuroscience
*  experiments. They do ablation
*  experiments. They do
*  in silico mapping of receptive fields
*  and things like that. So
*  I remember in earlier days
*  five years back when they
*  first start, like deep learning first
*  started to be really, really successful
*  and I was looking at what they're doing
*  with the networks trying to understand
*  their properties like
*  you're using experimentalist tools
*  to try to understand something really complicated
*  and failing in exactly the same way as
*  the neuroscience community does.
*  That hurts on the inside.
*  Yeah.
*  This is kind of the point that it's not
*  that there's no flow of information
*  it's just that it's hard
*  to pinpoint this is one thing
*  that completely made the difference, but in subtle
*  ways we're influencing
*  how the process works
*  in a lot of ways.
*  It's not subtle how AI is influencing
*  neuroscience. I mean someone had to argue
*  that the brain is not a transformer
*  today. You know, like they actually
*  spend a whole talk arguing that we're not
*  transformers.
*  He stated it. I don't think he was trying to
*  I don't think that was a
*  position difficult to defend.
*  No, but the fact that it was defended
*  for that period of time.
*  But there are also neuroscientists to make models for how transformers
*  can be implemented both at the
*  neuron circuit level and at
*  neural area level.
*  Yeah. We do
*  have models of contextual modulation
*  of visual processing
*  for instance that are circuit level models.
*  They're not transformers in the details
*  but they're transformers in the spirit in the sense
*  that I have
*  top down information that
*  decides what kind of things from
*  my input stream is task
*  relevant, what kind of bits are not, and I
*  preferentially transfer
*  the bits that I care about.
*  And the dynamics of that
*  is what we have circuit models for and
*  related to actual neural data.
*  So like
*  again, it's
*  what counts as similar enough
*  and it's similar in spirit
*  inspiration or is similar
*  in spirit but not in
*  the details, something to
*  be ignored. I don't know.
*  I mean, changing topic a little bit.
*  This
*  I mean you, Kristian, I just
*  got tenure. Congratulations.
*  Very good.
*  Which is sort of like a milestone
*  obviously if you want to stay in
*  academia. I mean you have a permanent job
*  only for a few years. Four years.
*  Exactly. So you're rather
*  newbies in terms of tenure.
*  Right? And that
*  also means that because this question of what does
*  it mean to be productive in science and
*  from an operational point of view, if you
*  want to stay in academia, sort of being able to
*  qualify, getting tenure is a good thing.
*  Right? And you have to be show up
*  with like papers and grants and stuff
*  to get to that. But now
*  you have sort of, at least
*  you have just been for a few weeks and
*  you have now time to, you can sort of
*  do different things with your career.
*  I mean you can sort of be involved in many projects
*  and ambience like spread your
*  thin. We were always doing that
*  for more than six. Yeah.
*  Exactly. Yeah, I think
*  actually the time before tenure
*  for me was
*  probably much more diverse
*  in what I was doing. Is that because you were
*  trying to find the thing?
*  No, also I was doing things like the Imbizo
*  or the summer school in
*  South Africa that I started to
*  co-direct
*  or
*  worldwide neural. These things were
*  not necessarily
*  directly career relevant
*  but they were fun
*  and they sort of served
*  as an outlet for what is
*  otherwise a relatively
*  you know, computational
*  neuroscience doesn't have a direct impact on
*  many things.
*  We will get that.
*  And
*  those
*  additional hobbies
*  quote unquote, served
*  that purpose. If you're on
*  tenure track American professor you don't have
*  time to have hobbies. So I
*  did like, my
*  entire career has been about doing too many
*  things at the same time. And
*  like that's a bad strategy. They tell you not to
*  do it but it was sort of like
*  just happened to me. It's kind of
*  with how my brain works. I have lots of
*  spread around interests. I don't care about
*  one thing but about a range
*  of things. And we had lots of collaborators
*  so that mushroomed even more
*  projects. So it just happened.
*  But do you think it actually was, did you think
*  you did your best,
*  did you do your best work in that way or do you think
*  now that you can
*  focus on fewer things? I find myself
*  being swallowed up by administrative
*  chores since I have tenure.
*  So it is now said that
*  the time of the juniors has to be protected
*  and so here's the administrative load
*  increased. So
*  what I used to spend on the InBZone, which
*  I have just retired from, or
*  World Wide Neuro, I now spend on
*  hiring committees and grant
*  committees and all kinds of
*  nonsensical
*  less
*  immediately relevant
*  things.
*  Wait, before we start, were you going to ask about productivity?
*  Let me finish
*  the question, the answer to the question.
*  So basically because I was
*  putting up my documents for tenure not
*  so long ago and I was like
*  had to think
*  retroactively, it's like what it is
*  exactly that we've achieved, where is
*  this going, things like that. There was a lot
*  of social searching involved. And I
*  think I came up with the conclusion that
*  doing fewer things
*  better is something that
*  I would like to try in
*  the incoming years.
*  They're practical things so you can't
*  trim down as much as you want
*  potentially.
*  I just wanted to ask immediately, and then we can
*  come back to this, because
*  so what then, what advice would you give
*  to people going in now, given
*  reflecting on your own,
*  are you going to say don't do what I did?
*  I do tell people that on a
*  regular basis, but this is not what I'm going to tell
*  today.
*  So I think
*  taking the time to find
*  a good question before you jump
*  into doing frantically
*  things
*  is something
*  that I try to encourage
*  my starting PhD
*  students to do.
*  How do you know what a good question is when you don't know anything?
*  Yes, so this is the second
*  immediate advice that I give to those
*  people is read literature
*  broadly. Maybe
*  this is like old grumps talking,
*  but I do feel
*  that in graduate school I spend
*  a good fraction of my time
*  reading papers.
*  There used to be this sort of like
*  ten advice,
*  what was it called?
*  Ten
*  rules
*  for blah, blah, blah.
*  There was ten rules for becoming
*  a great writer, and one of those
*  was like read ten papers a day.
*  Okay, nobody can read ten papers
*  a day, what are you talking about?
*  These papers are getting so complicated
*  it takes a week to read, but I think
*  a milder version
*  of that advice is very good.
*  You need to know what the field is about
*  and people tend to read
*  very narrowly. So exactly in the niche
*  of what the project is about,
*  but missing a lot
*  of really important connections because
*  they just don't have to.
*  Of course now you have two excellent podcasts in the field.
*  Brain inspired.
*  Brain inspired.
*  And chat GPT.
*  That's not a podcast.
*  That's kind of
*  a thing,
*  Tim's new app to summarize.
*  What is the new app?
*  Topotopic.
*  Tell us about it.
*  I will link to it in the show notes.
*  I just want to say that
*  the challenge there is because
*  the field has mushroomed a lot more
*  productions, so basically
*  there are a lot more papers to read in general.
*  But that's maybe one of the places
*  where deep learning might help because
*  if you have summarization tools,
*  you can get at least a
*  superficial breadth.
*  And tweet prints.
*  I think a hugely
*  interesting way of...
*  Like the pre-print
*  on Twitter.
*  Or now on Macaron.
*  A summary.
*  Quick summaries on Twitter.
*  I really enjoy those.
*  Okay.
*  I should maybe start doing those.
*  What would be your advice to...
*  Drink.
*  I think drink from the firehouse.
*  I don't know.
*  I really...
*  I really
*  don't know.
*  I find the...
*  I find the term
*  work-life balance really problematic.
*  Especially for
*  young PIs.
*  But also for grad students
*  and post-docs. I think the only
*  work in your life is that you have to
*  sleep enough. That's the only
*  work time. Everything else is sort of life.
*  Probably.
*  Wait a second. I'm trying to understand this.
*  The work is the...
*  Sleeping. I find sleeping is my
*  worst chore in the day. I set an alarm
*  clock in the evening so that I go to bed at 12.
*  Because otherwise you're going to keep working?
*  No, I just keep staying up.
*  That's really the only thing that I
*  violently dislike in my day.
*  Going to bed.
*  Have you ever tried to bring the cocaine away?
*  No, but I think
*  what would be my advice? Do what
*  you're interested in. Run as hard
*  as you can. Don't take prisoners.
*  Drink from the firehouse. I don't know.
*  Do you think work-life balance has gotten out of
*  control? I think I'm going
*  to get slaughtered if I say that
*  seriously. But there's
*  things can...
*  I think what is considered work has been
*  a little bit corrupted
*  in a way. Because
*  you can't be at
*  the same time a student and a worker
*  in my opinion. So you have to
*  decide whether you want to be a graduate
*  student and
*  take on what you get as
*  a privilege of being taught something.
*  Or you decide that
*  everything you do after you
*  reach your lab
*  is work. And then
*  it's a 9 to 5 job. But you can't
*  have the cake and eat it.
*  I think.
*  And so if you decide
*  that you're actually a graduate student
*  or a scholar
*  of some capacity
*  to whom society
*  gives relatively
*  large amounts of money for
*  very little productivity compared to
*  a baker or a builder
*  or various
*  other jobs.
*  Postdocs, NPIs as well.
*  A relatively large amount of money?
*  I would say so. Okay, we're food.
*  I certainly got
*  a lot less money than what grad
*  students are getting today.
*  As a grad student.
*  When you are in
*  the US and you're not working in
*  Austria, it's a European-US
*  thing, right? Yeah, I don't know.
*  I think
*  it's a life choice you make
*  at the end of the day.
*  And you are going into a field
*  that is A, very competitive, but
*  B, very privileged in that
*  we're sitting
*  on a ship
*  talking about science. It's the first time for me
*  that I've been on a boat at a conference.
*  Same. Me too. Same.
*  A friend of mine,
*  Guillaume Lajoie, always says, I fucking love science.
*  And he fucking loved
*  science always, even
*  when he was being paid very moderately.
*  And to keep that in mind,
*  to call that back into your own
*  memory, into your own everyday,
*  that you're not
*  in fact doing something
*  because you're being forced to,
*  but that you're doing it by choice
*  is an incredible privilege.
*  Christina, you look like you're chomping at the bit there.
*  Yeah, no, I think I agree with this.
*  I think that like, being in graduate school
*  is very intense
*  and very hard.
*  And if your heart is not really in it,
*  and you're doing it as a job,
*  then probably there are better ways of getting
*  the same amount of money with
*  better benefits
*  and better life by all.
*  I think sometimes people get into
*  graduate school either as inertia,
*  they were doing well.
*  Maybe 70% of people, I would guess.
*  Or because of the sort of like social pressures
*  that they won the title,
*  but they don't really enjoy the process.
*  Those are overlapping populations.
*  There might be, but
*  I kind of feel sad about those people.
*  You are sort of clearly
*  both extremely motivated
*  and sort of have made it
*  also in the sense that you've got excellent
*  academic jobs.
*  But I mean, there are also people who sort of,
*  I mean, they're not that,
*  at full health, they have some like health
*  limitations, or maybe like some family obligations.
*  So are you saying that
*  Or maybe they're just lazy.
*  Yeah, lazy I don't know.
*  Pointing a gun to them.
*  Really? That's impossible to do.
*  That's an affliction.
*  So I mean, there are sort of, should you say,
*  if you cannot put in like...
*  I'm not saying that you need to work 12 hours a day.
*  I'm just saying that the hours a day
*  that you work, you need to be
*  100% in it.
*  That those need to count.
*  Whereas, what's a job
*  that would not apply to?
*  Most jobs are
*  from 8 to whatever,
*  9 to 5. And then
*  if you work in a shop, or
*  maybe like a
*  I don't know if this is airable.
*  This is not airable.
*  But basically,
*  there are plenty
*  of things that you can do at 80%
*  and get away with it.
*  And I don't think you can do science
*  at 80% and get away with it
*  as a career. Like you might
*  get a PhD that way, but you're not going to
*  be very successful.
*  And to be fair, at the postdoc level, I think
*  there is a lot of people who are putting in
*  120% and they're not getting
*  jobs, and they're not getting invited
*  and their interviews go poorly.
*  Because the bottleneck is
*  getting a PI position
*  and that's incredibly tough.
*  There's firehose that won't turn on.
*  Yeah, no.
*  Or that is passing them.
*  I say to people
*  ask me that taking a PhD
*  or you learn how to program code, whatever,
*  that's a safe investment
*  regardless. But going on a
*  postdoc, maybe that's
*  a little bit, I mean, if you're aiming for
*  academia, there's a bottleneck
*  and there are many more postdocs than
*  PI jobs, permanent jobs.
*  I was ignorant to the cliff
*  that I was standing on when I started my postdocs.
*  Until I had kids,
*  I actually had no
*  risk management
*  plan.
*  But you didn't really need to.
*  I was young and immortal.
*  Because I did my PhD in Germany
*  and the German system
*  has
*  a lot more
*  insight into this
*  because it's so difficult to get a
*  permanent academic position in Germany.
*  People start a PhD
*  largely with the expectation
*  they were going to work into industry.
*  And the transfer work
*  skills and what you're learning being used
*  for lots of different things
*  is kind of like part of the memo.
*  It's not an afterthought or plan B.
*  It's like the default
*  and if anything else happens,
*  that's good, but it's not really expected.
*  In the US, we're still sort of
*  selling the academic path
*  as the default
*  and everything else is plan B,
*  although the numbers are really not
*  in any way
*  reflecting that.
*  I'm slightly
*  afraid to ask your productivity question
*  given there.
*  The slow productivity
*  thing that I talked about,
*  I mentioned that as I read this book about
*  slow productivity.
*  We have just a few more minutes if you guys are good for just a couple more minutes.
*  Then we'll go to the next one.
*  I read this book
*  on slow productivity.
*  The basic idea
*  is that it's
*  easy to measure productivity
*  if you're a farmer or producing
*  industrial things.
*  But the knowledge work is not so easy
*  to measure.
*  And then you get these proxies
*  that are many papers
*  that look visible and you work a lot.
*  Then you think about
*  and you sort of read, for example,
*  about the lifestyle
*  of Darwin, who was sort of
*  like, I would say, productive, had a quite productive
*  scientific life. He didn't work
*  that many hours, right?
*  He sort of had like every morning and then he did
*  some... But it was like this,
*  he was
*  sort of like focusing on a few things
*  and then sort of doing high
*  quality work. So is it
*  something you do?
*  But I guess you feel
*  pressure to get in grants
*  and have students. It is like, success
*  is often measured now in
*  how many students you have and how many grants
*  you get in and how many papers you...
*  Yeah, I need to get enough money
*  for my students to have jobs
*  to be able to graduate.
*  So there are external pressures.
*  It's not like you can take your
*  time. I wonder sort of like
*  these historical examples
*  whether it's fair to make those
*  comparisons. I do think it's
*  the better way of doing science, but the
*  sociology doesn't work. And the reason
*  for that is a lot of the very
*  successful scientists in that period
*  were like independently
*  rich and they did this as a hobby for fun.
*  So they did it whenever they wanted. They had
*  the time and the leisure
*  to do that. And it wasn't
*  sort of like, I need to desperately
*  get some stuff done.
*  We're in much more sort of like
*  externally driven...
*  How do you think about productivity
*  personally then?
*  I think Darwin might be
*  an extreme version, but I do think
*  you actually make better science that way.
*  But screw it,
*  we're not in that system anymore.
*  The sociology
*  doesn't work.
*  Until as a culture, as a
*  field, we decide that
*  we are going to change the incentive
*  structure in a way to make that
*  a feasible
*  MO.
*  We're going to have to do
*  what the external pressures force
*  you to do. I can't
*  stop doing certain
*  things. It's just not going to work.
*  So my
*  postdoc advisor, Wolfram
*  Gursener, when I joined his lab, told me
*  three rules for his lab.
*  Or there was four actually, but three
*  big ones. Show up in the lab
*  once a day.
*  One paper per year
*  with your name and my name on it.
*  Doesn't matter what positions.
*  And if you want
*  to go to a conference, you have to present your own
*  work. And then on top
*  of it, we couldn't speak anything but English
*  in front of open doors. That was rule number four.
*  But that was it.
*  I kind of try
*  to propagate this, and I think that's
*  for postdocs a great
*  rule. One paper per year is doable.
*  Not necessarily as a first author,
*  because sometimes they support grad students.
*  But if you're a postdoc
*  for four years and you've got four papers out of it,
*  that's really productive.
*  If that's the rule, then it
*  says nothing about the quality of the work.
*  No, but it does, because one paper per year is
*  not a lot if it doesn't have to be a first author.
*  But it takes a lot just to write
*  the paper and shape the paper and get the paper
*  out the door. So that in itself is a lot of work.
*  So if you're
*  working to
*  get a paper out, that's
*  different than working to answer
*  a question.
*  Presumably you want to be doing both.
*  Yeah, no, but I think you front
*  load with work and then you end up with
*  papers. And so maybe I'm speaking because
*  of conformational bias because I was in Wolfram's
*  lab for four years and I have four papers.
*  It worked out.
*  But
*  this plus minus one seems
*  to work okay
*  also in my lab. The postdocs seem to
*  they're not slacking off.
*  They're working and at the end of the day
*  they're ending with about a paper per year.
*  But you were doing monkey physiology, which is
*  the hardest thing.
*  Yeah, monkey physiology doesn't work on that type of job.
*  And this was a theory lab, right? This was a theory lab.
*  Experimental labs are probably structured
*  easy. What you do is easy.
*  Exactly. It's not real work.
*  I have to clean monkey cages.
*  It's hard work. Scrape that.
*  Never mind.
*  Alright, so actually
*  I have one more
*  just kind of fun question. Yeah, please go ahead.
*  I asked this of them earlier.
*  And that is
*  how do you know
*  when or if you
*  have a good idea
*  scientifically without
*  doing any work to vet it?
*  You just, you know, you're in
*  the shower, you're daydreaming, whatever.
*  You have this idea, how do you know
*  if it's any good? If it's coming back.
*  If it's coming back the next
*  day? Yeah. If you think of it again? Yeah.
*  So you don't write it down?
*  No, I write them down. But I used to write
*  them down religiously. But then you can just read
*  it and it comes back. So that's, so every idea
*  is good. Every idea you write down must be right.
*  No, no. Now what I usually do is I text
*  them to a student of mine or a post
*  talk and then they're like, you're insane.
*  Or you're stupid,
*  more likely. Or they just
*  don't respond because
*  it's... You're not even
*  wrong. They're busy
*  writing that paper they have to write.
*  Exactly right.
*  But if it comes back usually,
*  I think a good idea will
*  avail itself a few...
*  Because if it's a good idea, you think about it
*  for quite a while. Yeah. And then...
*  I sometimes discover, like, I look at
*  old notes like a year
*  before and stuff like that. I was like, oh
*  I had this idea before. I completely forgot that.
*  You must write better notes than I do.
*  I write terrible notes. Otherwise I would
*  have done it the first time around and I wouldn't have wait for
*  a year. But for me, it's like
*  ideas that I find good.
*  They don't have to be right.
*  They have to be good. It's ideas
*  that I'm itching to find the answers.
*  I keep thinking about it. I really want
*  to do the numerics right now. I want
*  to do the math right now. I want to talk my
*  students into doing it right now.
*  I get this sort of like
*  vibe. Wouldn't it be cool if we could do this?
*  Yeah.
*  It's not that all of the things that we do
*  are like that. But I think
*  what keeps me going is the things
*  that feel like that.
*  Good. Alright guys, keep going. Thank you
*  for your time.
*  Thanks a lot. Perfect. It's been fun on the boat.
*  Thank you. It's been more wiggly
*  than the average on the boat.
*  It's been super wiggly right now.
*  Because we're outside, right?
*  So we're here with Mikael again, the organizer,
*  the brains behind
*  the conference. I know you had help.
*  And Tonya and everyone was
*  a great help in putting it together.
*  Alright, so now you've
*  had this thing. Was it
*  a success? So the title, right?
*  Validating Models. What would success look like
*  in neuro-AI? And the last
*  thing that I brought up and the very last
*  thing that we did was this panel discussion
*  about
*  what would success look
*  like in neuro-AI?
*  And there was a wide variety of responses actually.
*  So we've had a lot of great
*  talks and great discussions throughout
*  the trip. And Gauta,
*  you can chime in here too, but I
*  just wanted to get your sort of reflection on how you
*  think it went. And
*  so a boat this year. Gauta
*  thinks spaceship next year.
*  Outer space. Yeah, sort of talk to yourself.
*  You have to sort of like space station.
*  Yeah, yeah. Exactly.
*  There's no arguing.
*  Next year we all get our
*  own speed boats and we all have like headsets
*  and screens, you know?
*  Racing and giving talks.
*  Yeah. It's a good idea.
*  So what do you think?
*  Was it a success? Was the workshop a
*  success? How are you feeling that it went?
*  I think it was a great success. I think
*  everyone really enjoyed the
*  conference or
*  the workshop in terms
*  of the scientific material, but also
*  in terms of the kind of
*  social aspect
*  and just the trip
*  has been really great.
*  But in terms of the science,
*  I think there's been,
*  you know, I had two big worries.
*  Like one would be
*  like high
*  winds and waves.
*  Oh, the weather was great. Bad weather.
*  So everyone got seasick.
*  That would be terrible, right?
*  So that didn't happen. So yeah, that's a success.
*  The second thing
*  I was worried about would
*  be that, you know,
*  all the talks were off target or
*  that
*  no one would discuss or talk.
*  It would be just like another
*  science conference where
*  everyone just gives all their
*  data and there's like impossible
*  to respond to it because there's so much details.
*  I think this format where you had
*  first, I mean everybody had like a 40 minute
*  allocation
*  slot, but then a 20 minutes
*  for presentation and then 20 minutes
*  for discussion. That was very successful.
*  Yeah, that was good.
*  Yeah, for this meeting it was
*  perfect. Did you learn anything?
*  Is it going to change the way that you
*  approach anything in your own work?
*  Because I'll start off by saying like
*  I made connections and had conversations
*  that gave me new avenues of
*  thinking about my own work. So that's
*  been super valuable to me.
*  I mean, so
*  one thing, I mean, we're just
*  we're thinking about the workshop
*  kind of topic. I think
*  continuing
*  kind of, you know, probing the
*  the community and
*  kind of the people doing the
*  science on how we should do it right
*  I think has been a major
*  kind of insight that this
*  really is an important thing to do
*  like to ask
*  these critical questions on
*  how kind of, you know, if you take
*  a step back, like what's
*  you know, what would it
*  look like if your model were
*  actually doing, you know,
*  something like the brain is doing
*  and how would you measure that or
*  you know, where is your satisfaction
*  criteria? I was surprised.
*  I mean, when you were asking when you were
*  leading the panel debate at the end, Paul, that
*  how many of you
*  feel that you sort of know
*  what success would look like? There
*  were about eight hands that went up. So I
*  Yeah, just
*  repeat the question. Yeah, the question was
*  so it was on a scale of one to
*  ten. If you feel and
*  if you're eight or higher in terms
*  of feeling that you know
*  what success would look like
*  then raise your hand. Yeah. And how
*  many, what fraction of the participants?
*  Well, there are about 30 here. Yeah.
*  So it's almost a third. 27.
*  I would expect that
*  I would
*  expect that that number to be higher and that it would
*  rather be that
*  people have different opinion about what the success
*  would be like. Well, everyone who did raise their hand
*  did seem to have a different opinion. But I
*  would expect that if people
*  were honest that it would be about that
*  number. Really? Yeah. I didn't raise
*  my hand. No. No, I don't
*  I can't articulate it. No. And that's a
*  problem. I know that's a problem. And so
*  it's a good, this is a good venue
*  to explore that. Yeah, that's true. So that was
*  a little bit surprising for me. I think
*  sort of, yeah.
*  That was maybe. You raised your
*  hand, Galte. Maybe because I'm
*  sort of a little bit like an outlier
*  here and participants in terms of
*  I sort of, I come from this like
*  this physics side of modeling
*  and I do sort of like physics type modeling
*  the brain as a physical system.
*  Not that I'm not interested in what
*  the functions are and the other models. But this
*  and here the success is sort of
*  a little bit clearer in the sense that you try to
*  mimic, mimic
*  sort of physiological data. That's why
*  you like Stefanos, sorry, Andreas
*  works so much. Yeah, exactly. So
*  that was sort of, so I think maybe that's
*  so maybe when you come from physics,
*  the idea of what the success
*  is, whether it's a good
*  idea or not, is this is more
*  clear, it's more imprinted in us. Well, and that's
*  why when I drew that awful diagram,
*  it had a lot of different little lobes
*  of what, of success and
*  how those lobes could
*  maybe attach to the different goals
*  from the way people use
*  AI as tools or models and stuff.
*  But Mikko, you also raised
*  your hand, didn't you? When you felt,
*  when I asked that question,
*  don't I remember, you don't have to articulate it,
*  but don't I remember you raising it? Because I think the question
*  was, do you feel like, yeah,
*  not can you articulate it? So you, you're
*  an eight or above? Yeah. Yeah.
*  Yeah. That was, yeah.
*  I mean,
*  that has to do with, you know, what I was
*  doing and thinking about before I started
*  this workshop because, I mean, I
*  was thinking a lot about it
*  before,
*  before I started the workshop. So
*  if you would
*  add like a confidence score, you know,
*  as well. That is the confidence score.
*  That's why it's a one to ten.
*  No, no, it's a confidence that you know what it would
*  look like, but it's not a confidence
*  of how sure you would,
*  you know, how sure you are
*  that it's actually achievable.
*  Achievable. Achievable. So that is a different
*  thing. Yeah, that's a different thing,
*  right? I mean, so I know what success would look like.
*  I'm not quite sure. If it's possible,
*  right? Because some of the,
*  I mean,
*  and you could say success would look like,
*  success would look like us building
*  a perfect brain like that.
*  I mean, no one would argue that that's not
*  success, but... No, I would argue that's not...
*  No, no, but if you build a perfect brain, then
*  what you're left with is a brain, not
*  necessarily the understanding of it's
*  functioning, how it works, right? Sure, but
*  you would argue that
*  you would need to understand, you
*  know, how to build a brain if you were
*  supposed to build. I mean, I'm not talking
*  about kind of growing it from like you
*  putting some, you know, genes together,
*  and like, that's not...
*  But if you can like build a robotic
*  brain or whatever like that, then... Or even make a very
*  detailed model, and it's true that that would be very hard
*  to understand, but then you could start
*  that as a starting, probing,
*  and it would be the perfect
*  test animal, as we discussed. But the model has to behave
*  correctly. Absolutely, so it has to
*  fit all the experiments.
*  But it would be like, it would be a...
*  If it would be a perfect brain, that would be
*  a success, I think, like if you could build it, but you
*  wouldn't be like... I mean, that's...
*  Well, some people had this idea that
*  it really...
*  Success would mean that you could make
*  a model of an individual, right?
*  And that's, I mean, individual brain,
*  like Conrad's brain, right?
*  And yeah, so that was like this...
*  And I think that
*  sort of... That
*  is sort of very... That I don't think is very
*  realistic. I'm thinking more in terms of sort of
*  like more some kind of
*  average brain, some general properties,
*  and maybe sort of what is the difference between a
*  healthy brain and maybe like
*  a psychotic brain,
*  or like different kinds of brain states,
*  and sort of like more like the average
*  kind of... So actually, mimicking
*  a particular brain would mean that
*  you need to rewind the whole...
*  The whole... I mean,
*  replay the whole history probably with environmental
*  inputs. Shouldn't we start with a below
*  average brain, like mine, though?
*  Isn't that more feasible?
*  I don't know.
*  It's... You know what?
*  The Tolstoy saying that it's like
*  there's only...
*  They never wrote about happy families, because
*  it's not like happy families, only happy
*  in the same way. There's so many ways
*  to be unhappy. So maybe that's
*  the same thing that unhealthy
*  brains... There's so many ways to be below
*  average. Yeah, yeah, below average.
*  Any parting thoughts
*  speaking of... We have to leave happy, so
*  this conference... This is happy.
*  How do you want to... This has really been
*  a great success. I've talked to people
*  even when you're not there.
*  That's the criteria, right?
*  Yeah.
*  They are extremely happy and learning.
*  Everything was perfect.
*  So how do you have any...
*  Do you have any plans
*  for... You don't have to do it
*  today, now we are still at
*  the... The thing is, you have to
*  keep it kind of small
*  for it to be useful.
*  I think that was one of the success
*  criteria actually. Keeping it small
*  enough that we could
*  become like a
*  small group of friends basically.
*  But I know what you're going to say. You're going to say
*  because you said it during the panel that you'd like
*  to have more people from the computer science
*  side.
*  Yeah, yeah, yeah.
*  I think that would be really interesting
*  to see. But I don't
*  know how that would look like though. I mean
*  it would be... It would have to be people
*  from the other side.
*  Or computer scientists that are genuinely
*  interested in the topic.
*  So it couldn't
*  be like a bunch of people that were just
*  hoping maybe that they can get some cool
*  ideas from neuroscience and just take it
*  and build something. But
*  preferably be someone that wants
*  to be in the community. That would be really cool.
*  That's always a challenge I think.
*  You have to sort of... On one hand you want
*  a broad set of perspectives.
*  On the other hand you want people
*  to have some interface so they actually
*  can sort of communicate, right?
*  So that's sort of a...
*  So if it's too broad then you're not able to...
*  Like half of the audience doesn't
*  understand what the other half of the audience is talking
*  about. And then it's like difficult to get...
*  One thing I
*  really want to say that I... One thing
*  that I think is really important
*  and I think has also been a really
*  big part of this success is to
*  bring people with different backgrounds together.
*  And it's
*  important that they have some
*  common focus or else they will
*  just stop by each other.
*  So if you have a
*  focus that will make people
*  think in some parallel
*  or same direction.
*  It's great.
*  And you did that because there are people
*  working on synapses and spiking.
*  There's people working on
*  quabino normorphic essentially.
*  And so what you
*  call... You set it up as like the implementation
*  level. There are people at the representation
*  level, the algorithmic level, the computational...
*  So we had
*  just a wide variety. Like I said
*  before, I'm repeating myself now, but I think
*  that you achieved that already.
*  Yeah, yeah. And so that's definitely
*  like one of the coolest things
*  with scientific
*  interaction or
*  conversation or like this sociology
*  of bringing together people
*  from different mindsets
*  and having them talking
*  together. I think like there's
*  some magic that can happen there.
*  Yeah. Great. Thanks
*  a lot, Mikael. Yeah, thanks for the invitation.
*  On behalf of the participants and on behalf of the field
*  to be a little bit pompous.
*  Yeah, exactly. Pompous. Pompous Gauta.
*  Exactly. That's the new one.
*  All right. Thanks, Mikael.
*  Thank you.
*  Thank you.
*  Thank you.
*  Thank you.
