---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 3997s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 9441
Video Rating: None
---

# BI 119 Henry Yin: The Crisis in Neuroscience
**Brain Inspired:** [November 11, 2021](https://www.youtube.com/watch?v=m5Xs_KxJ-X8)
*  So how come neuroscientists have failed so badly at explaining behavior?
*  So obviously they've been trying to do this for at least a century,
*  and a lot of smart people have worked very hard,
*  but the result is, I would say, very disappointing.
*  I think it's healthy in the sense that, okay, so there are people who are perhaps mainstream,
*  and they believe that the paradigm is healthy.
*  They want to maintain the status quo.
*  Others, people like me, perhaps in the minority,
*  but we think there's a crisis, and we would like to start a revolution.
*  I think it's exciting, and I'm quite optimistic.
*  This is Brain Inspired.
*  Hello, it's Paul, and today I bring you Henry Yin.
*  Henry runs his lab at Duke University,
*  where he studies learning and behavior in rodents,
*  using techniques like optogenetics and electrophysiology.
*  But that's not why he's on the podcast today.
*  He's on the podcast because he's written a few pieces
*  in which he argues that we need a new paradigm in neuroscience to explain behavior,
*  that essentially we are barking at the wrong tree,
*  trying to study the brain like an input-output device,
*  which creates representations of objects in the world
*  and then programs the body to act accordingly.
*  Instead, Henry looks to control theory
*  and suggests that the brain is basically one big, hierarchical set of control loops,
*  each of which is trying to control its input,
*  so that the input matches a set of internal reference signals.
*  So control theory came out of the early cybernetics work,
*  but Henry argues that they made a key mistake due to their engineering-like approach,
*  and the mistake was that they failed to consider that the reference signal,
*  the signal that the system needs to control itself to obtain,
*  is generated internally by our autonomous biology.
*  Instead, the cybernetics approach and much of the rest of neuroscience,
*  Henry argues, places the reference signal outside of the body
*  in the hands of our experimental control, but we need to be looking inside.
*  Okay, so that will make more sense when Henry explains it more,
*  and I link to his work in the show notes at braininspired.co.slash podcast slash 119,
*  where you can join the awesome group of Patreon supporters as well.
*  Thank you, Patreon supporters.
*  Also, just a quick announcement.
*  I am finally going to be releasing my Brain Inspired course,
*  which is all about the conceptual landscape of neuro-AI,
*  so all the topics that we talk about on the podcast,
*  but in the form of a series of video lessons.
*  So next week on my website, I'll be releasing a limited-time video series,
*  and in those three short videos,
*  I'll discuss why this marriage between neuroscience and AI is so exciting.
*  I'll show some examples of what to expect from the course,
*  some of the topics that the course contains,
*  and then the details of the full content of the course and how to purchase it,
*  but the videos will only be available from November 17th to November 20th.
*  So if you're interested, head to braininspired.co slash bi-workshop,
*  like braininspired-workshop, bi-workshop,
*  and I'll put that link also in the show notes for this episode.
*  And it's during that time span, November 17th through 20th,
*  that the course will actually be available to purchase
*  while the video series is live.
*  So check that out if it sounds interesting.
*  All right, here's Henry.
*  Henry, thanks for being here.
*  So I know that by day, you are not a crisis counselor,
*  but the main topic I suppose that we're going to talk about today is,
*  comes from a chapter that you wrote in a book on perceptual control theory,
*  and the title of the chapter is The Crisis in Neuroscience.
*  So there's a lot to talk about actually.
*  It's really interesting stuff.
*  But by day, can you tell us a little bit about what you do in the empirical side?
*  Yes, by day, I'm a systems neuroscientist.
*  I work on the role of the basal ganglia circuits in behavior,
*  in particular, instrumental goal-directed behavior.
*  And I use mice for the most part in my research.
*  Oh, yeah, so I'm an experimental neuroscientist.
*  Was it your research that brought you to think about these things that you write about?
*  You've been writing about these topics since at least 2013.
*  I'm not sure if you wrote about it earlier as well.
*  Yeah, I've been thinking about these topics for probably since graduate school,
*  so for probably 20 years or so.
*  And I started writing about them, as you said, in 2013 or a little earlier than that.
*  Yeah, so it's been a while.
*  Okay, well, let's not wait any longer then.
*  What is, and there's a lot to unpack,
*  so I don't expect you to summarize the entire chapter here,
*  but can you give us the overall picture of what the crisis in neuroscience is that you write about?
*  So I used the word crisis in a Koonian sense,
*  so it's based on Koon's book on scientific revolutions.
*  So the idea is that, as we all know, there's a scientific paradigm,
*  which is a set of common assumptions that most scientists in the field take for granted.
*  And when you have a crisis, it's usually due to discrepancies between new observations and the accepted model,
*  these assumptions that everybody accepts.
*  So then the idea is that you can either maintain the status quo or you can start a scientific revolution.
*  So that's sort of the nature of the crisis in general in science.
*  And the question that I raised in the chapter was,
*  so how come neuroscientists have failed so badly at explaining behavior?
*  So obviously, they've been trying to do this for at least a century,
*  and a lot of smart people have worked very hard.
*  But the result is, I would say, very disappointing.
*  After a century of work, there is no accepted model of any behavior.
*  The things that we have learned about the brain don't seem to explain how behavior works.
*  So that is disappointing and surprising, in my opinion.
*  And so I think that's basically the crisis.
*  And I think the reason, of course, is not because the brain is too complicated.
*  It's not because, as people normally say, you know, the brain is the most complex object in the universe,
*  and therefore it will take forever to understand how it works.
*  I don't think that's the reason, although that's the common excuse.
*  So I think the problem is that the accepted paradigm in neuroscience and in psychology is wrong.
*  And I would call this paradigm the linear causation paradigm,
*  which essentially you accept that the organism, you know, receives inputs and generates outputs.
*  The input is sort of sensory in nature and the output is motor.
*  So the output is behavior and there is a causal relationship so that the inputs are somehow responsible for the outputs.
*  And so the goal in neuroscience is simply to discover the function that will link the inputs with the outputs.
*  So the input would be the cause, the output would be the effect.
*  And according to this paradigm, the brain or the nervous system is somehow responsible for a sensory motor transformation.
*  It will, you know, compute various things, it would probably take many steps, but somehow the product is your behavior.
*  And so I argue in the chapter that this assumption is basically wrong.
*  And that's the reason that people have failed to explain behavior.
*  It's not because the brain is too complex.
*  How did you get into control theory?
*  Yeah, good question.
*  So I talked about control theory as an alternative explanation.
*  So that is the model that I would use to explain behavior because there is only one class of systems in the universe
*  that actually does not obey this kind of linear causation model.
*  So cause-effect explanations do not really apply when you have a closed-loop negative feedback control system.
*  And that's why I talked about control theory.
*  But it's interesting and we'll talk more about the control theory approach.
*  You do an analysis on the cybernetics of old Norbert Wiener and company and describe what they got wrong.
*  So, I mean, cybernetics, it seems like is having kind of a comeback.
*  But I suppose you're worried that it's coming back and is still wrong.
*  What was what's the difference between that old cybernetics approach of control theory?
*  What did they get wrong? What were they missing that that you argue for?
*  Well, I think let's start with the basic control loop model.
*  So the control, the basic control loop is quite simple.
*  In fact, I think its simplicity is part of the problem because everybody assumes that they understand it when they don't.
*  So the basic control loop has essentially three components.
*  You have this input function. You have a comparison function.
*  You have the output function.
*  And the comparison function will take the input and compare it with some reference input,
*  reference signal and generate the error signal, which is really the discrepancy, the difference between these two signals.
*  And then the signal is used to drive the output.
*  And if there is negative feedback, then the output will have a certain effect on the input.
*  And so that closes the loop.
*  I think the problem with cybernetics and with, you know, with Wiener's model is he was actually
*  under the influence of the linear causation paradigm.
*  And so his approach is very much the standard engineering control theory approach.
*  And the problem is not the, you know, with the with the mathematics or with the equations of control.
*  The problem is what I would call a systems identification problem,
*  where they are accustomed to treating the reference input as the input to the controller.
*  So, in other words, if you are a user of some servo system, then, you know, let's say you're using,
*  for example, a thermostat, then, of course, you as a user, you would set the temperature.
*  And it seems like the setting when you set the temperature, that's the input to the system.
*  And of course, the output is whatever the AC will do to control the temperature.
*  Now, this is quite misleading because the reference signal in a biological organism is actually inside the organism, right?
*  Yeah, literally, it's inside of your brain.
*  It's not something that you can inject into the system as if you're God.
*  But we do generate those signals, those reference signals, in a sense, we autonomously generate them.
*  So the key is autonomy.
*  The key is that the reference signals are extremely important in control systems and they must be generated within the system.
*  And that's actually, according to my model, at least, that's the job of the nervous system.
*  So essentially, what you have is a hierarchy of neural control systems which can generate different reference signals at each level.
*  And these reference signals are usually changing all the time,
*  with the exception of a few or relatively few homeostatic control systems which are important for things like body temperature.
*  Yeah, so I guess the big picture is that you conceive of the brain or brains in any species, I suppose,
*  as a set of hierarchical control systems with each level having its own reference signals.
*  Right.
*  I think that's straightforward to understand for homeostatic mechanisms, like you mentioned, our internal thermometer, right?
*  Our temperature reference signal.
*  But then you extend it to behavior, right?
*  So you make the comparison between the classical neuroscience model, which you've already described,
*  where we see something happen and then we have some sort of internal representation or model of that thing.
*  And then we act on it.
*  But in your scheme, we have no internal model of what we're acting on.
*  Or do I have that wrong?
*  Do you have room for a model that's generated through these hierarchical control processes?
*  Or is it control processes all the way down or up?
*  Great question.
*  I think first we have to be clear on what a model is.
*  If we're just talking about representations, then yes, we have representations.
*  We need representations.
*  But I think what you're talking about is very common in the field of motor control,
*  where they're using all these models, which in my opinion are completely unnecessary.
*  And their models are actually very detailed models of the external environment.
*  Right.
*  And that's actually due to a mistake in the analysis of the interaction between the system and the environment,
*  which I mentioned in the chapter.
*  So this is actually a direct consequence of the cybernetic model.
*  This need for just sort of computing the environmental properties, I think it's imaginary.
*  And it doesn't work very well in practice.
*  So for example, in robotics, if you rely on this kind of inverse and forward computation,
*  the computational challenge would quickly overwhelm you.
*  And that's why we still don't have very good robots.
*  Especially when the wind blows.
*  Yes, exactly.
*  Especially in any kind of unpredictable environment, when the disturbance cannot be computed ahead of time.
*  So we've talked about homeostatic mechanisms and you've talked about the motor domain.
*  Do you think of...
*  I guess my question is how much of...
*  Well, let me back up.
*  It seems that there is room, and I know you said the brain is not too complicated,
*  but it is pretty complex.
*  And it seems like there's room for a lot of different kinds of representations
*  and a lot of different algorithms being run.
*  And I'm wondering how much of the brain do you see as devoted to control systems?
*  Well, first, the principle is that in a control system,
*  what is controlled is the input and not the output.
*  And if you accept that, you have to understand that basically you can only control what you're able to sense.
*  So that means to the extent that you need to control some complex variable,
*  you must have a fairly good representation of it.
*  And so that means the input function.
*  So I mentioned earlier that you have three components.
*  I would say that the input function is by far the most complex part of a control system in the brain.
*  The comparison function is relatively trivial because you're just doing the subtraction.
*  Yeah, you found out there's a linear relationship.
*  Yeah.
*  Right. And the output function, there could be some complexity,
*  but for the most part, it would probably involve some integration or maybe differentiation or a combination.
*  But the input function is tricky because there you do need to represent whatever variable that you're trying to control.
*  A simplest example, of course, is temperature.
*  And that's not a big deal.
*  But of course, if you're trying to represent, if you're trying to control something more complex,
*  for example, if you're trying to follow someone, then you have to represent this person somehow.
*  Right. And that's not as easy because the sensory representations and the higher level object invariant representations are needed.
*  And essentially, then you just do perform control on that variable.
*  And then, so as that person ducks around a corner, you actively try to, I guess your reference signal would be to have them in zero degree line of sight, right?
*  Directly in front of you, let's say.
*  Right.
*  And when they turn a corner, your brain's job as a control system then is to move your body so that it returns it to direct line of sight.
*  Exactly. And then you would have problems if, for example, there's something that's blocking your view, right?
*  You might need some memory, things like that.
*  Right. Well, yeah.
*  So first of all, watch out people.
*  If Henry's following you, it's really just a scientific experiment.
*  It's don't be creeped out.
*  But so you just mentioned memory.
*  What about the case where, and I don't want to badger you all day with this kind of questioning, but what about the case where you're not actually following the person,
*  but you have to imagine where they might be going based on their history, right?
*  Or they love ice cream.
*  And so you imagine they're going to the ice cream shop.
*  And you have to sort, then you have to, do you not have to then represent, let's say, the path to the ice cream shop, right?
*  To then close in on that person.
*  Is that still a control problem?
*  Do you see that as a control problem that is just a hierarchical version of it?
*  Yeah, I think what you're suggesting is that can you predict where they are going to be in the future?
*  And then act accordingly.
*  Of course, it's a control problem.
*  But I think the difference is that, you know, the you don't you're not getting direct sensory input.
*  But instead, you're trying to predict based on your experience and learning where they're going to be.
*  That's a slightly different problem.
*  But in principle, the control problem is still the same.
*  But the prediction problem.
*  Yeah, I mean, I think the prediction problem, it's not excluded from the model.
*  I would say that, you know, in the control hierarchy, you do have so-called imagination,
*  which is basically when a control loop is able to send its output to its own input function without going through the world, through the environment.
*  So that's called imagination.
*  And then, you know, for these higher functions, you do need memory, as I said.
*  So I don't I think these can be viewed as additional functions that you add to the control loop in order to help you control.
*  But to be honest, I'm currently I'm not concerned with these questions because I think they are sort of advanced.
*  They're not necessarily difficult, but I think it's more important to understand the basic function of the nervous system,
*  which I argue is to control various inputs.
*  That's my perspective.
*  Yeah. So this is in some sense, this is a unified grand theory of the brain, I suppose.
*  Yes, indeed.
*  Okay. All right. Great.
*  You mentioned the word prediction and you were talking about it for a moment there.
*  So I want to go ahead and I'll interrupt us and play you a question from a listener, actually.
*  This is the person who recommended you come on the podcast.
*  So then you can answer the question and then we'll get back on track here.
*  Okay.
*  Hi, Dr. Yin. My name is Jeffrey Short and I'm a mechanical engineer who's just started to explore the field of neuroscience.
*  I really appreciate the thought-provoking perspective you shared in the book chapter as I try to get audience into the field.
*  My question is around the potential role of prediction in a hierarchical control system model of the brain.
*  As I'm sure you know, there are other models involving minimization of error resulting from comparison of top down and bottom up signals.
*  Many of the other ones I've seen so far, though, emphasize prediction.
*  For example, Paul recently had a Neil Seth on the podcast who spoke about a predictive control based model.
*  I didn't see any mention of prediction in the model you put forward in the chapter, though.
*  So can you comment on why you favor a model that doesn't emphasize prediction and if there are any experiments that could be or have been done to my credence, either way?
*  Thank you.
*  Do you feel like taking a stab at that?
*  Yeah, I suppose I can do that.
*  So, yeah, as I said, I'm not against prediction.
*  I think there is a role for prediction in this type of model.
*  But what people often call prediction is actually not prediction.
*  So at least it's not achieved by predicting the future.
*  What people are usually talking about is can be achieved, at least, by controlling a different set of variables.
*  So in other words, what through learning what you're trying to control changes.
*  So you're trying to control another aspect of the environment that, of course, is maybe causally related to the variable that initially you were trying to control.
*  The classic example is Pavlovian conditioning, where you have, let's say, a bell and food, right?
*  Meat powder.
*  And there, I think what's happening is you are reorganizing the input function of the control system so that you're no longer trying to control for the impact of the food in your mouth.
*  It's dry meat powder.
*  So normally you have to salivate.
*  And instead, the input function now is incorporating the auditory input.
*  And so whenever the auditory input, the neutral stimulus is presented, now you're turning on this kind of meat powder controlling system.
*  So that's a very good example of prediction.
*  And people traditionally have viewed Pavlovian conditioning as sort of a simple example of prediction.
*  And there are a lot of models that attempt to explain Pavlovian conditioning.
*  But I think, according to my analysis, it's really representing an attempt to control a different aspect of the environment.
*  So I'm not against prediction, but I think there is a very important alternative that people have not really thought about, which is
*  just online control of a different set of sensory variables that are actually predictive.
*  So that's, for example, when you see a dark cloud, then you turn on your avoidance control systems in order to avoid the rain.
*  But that's after learning the causal relationship, the predictive relationship between the cloud and the rain.
*  So in essence, you spend your life learning.
*  Well, a large part of learning is generating new reference signals and or adjusting your reference signals.
*  Do I read you correctly?
*  Yes, that's correct.
*  So in the chapter, you talk a little bit about how we can move forward without giving a full-blown research program, for instance.
*  But I know that in your own research that you're using these principles and applying them to study behavior.
*  So I'm wondering if you can just summarize what you think the way forward is.
*  Well, you ask very difficult questions.
*  So my vision for the future of neuroscience, in other words.
*  Well, because you outline like first steps in the chapter, right?
*  And some principles that you could follow.
*  And, you know, essentially you give three steps of what we'll need to be looking for and how to test for control variables, right?
*  Yes, I think to begin with, we have to first identify the control variables.
*  And I would start with very basic variables that are not learned or perhaps don't require too much learning because they're easier to study.
*  And then you have to apply the test for the control variable in order to study those.
*  And of course, then you would have to discover the different components of the control system and how they're implemented by the brain.
*  Yeah, so. The test for the control variable is simply a test that is mandatory when you're analyzing biological control systems.
*  And you first have to come up with a hypothesis about what the control variable might be.
*  And because we know that the output of a controller will systematically mirror the environmental disturbance.
*  So once you know what the control variable might be, then you can introduce disturbance to that variable so that you would see if there's any resistance from the control system.
*  And if you're correct, then of course, you would have compensatory outputs that will resist the effect of the disturbance.
*  So you basically you're applying disturbances that would affect the control variable as if it were not if it were not under control.
*  And if you're experiencing some sort of compensatory output, then that is probably the right control variable.
*  If not, you have to start over and repeat this whole process.
*  You have to come up with a different hypothesis about the control variable.
*  So, yeah, so initial steps toward a whole new neuroscience.
*  But one of the things you write in the chapter toward the end is if the above analysis is correct, then a disturbingly large proportion of work on the neural substrates of behavior will have to be discarded.
*  So is the chapter being well read?
*  And if so, what kind of feedback are you getting from the neuroscience community and or other communities?
*  Oh, no.
*  First of all, I don't think many have read the chapter, but obviously you have.
*  And, you know, I get this uncomfortable feeling that maybe after this more people will read it.
*  Likely so.
*  But you wrote it so it can't be that uncomfortable, right?
*  Right. But, you know, these book chapters, they're not usually read by a lot of people.
*  OK.
*  And so so far, I haven't received much feedback from other neuroscientists, at least.
*  I'm not sure if most of my colleagues even know that I wrote this.
*  So it's hard to anticipate what people might say.
*  I don't know.
*  I mean, what is your reaction?
*  You were once upon a time you were a neuroscientist.
*  Well, right.
*  And we could use some of my own work as needing to be discarded, for example, under this proposed paradigm.
*  So I have multiple thoughts.
*  So that's why I asked you how much of the brain do you think is devoted to this control aspect?
*  Because it's hard to reconcile, for example, what I consider my own rich subjective experience, right?
*  My thoughts and my imagination.
*  It's hard to reconcile that with a control system approach.
*  So it seems like there needs to be and I don't know how you get from a hierarchical control system to what I consider my fairly rich subjective experience.
*  Do you do you see a path forward through that?
*  And, you know, that's just one example.
*  There are, of course, other examples like, you know, different areas of the brain being devoted to different cognitive functions, etc.
*  But but to you, these are all in the service of control.
*  Right.
*  I'm not sure exactly which aspects of your subjective experience is well, like right now, I can I would control.
*  OK, I'm sure you're talking about a lot of sensory experience like you.
*  You see that desk over there.
*  You're not actively trying to control it, right?
*  Right.
*  But I would say that, well, yeah, I mean, it seems like your sensory system can provide you with a lot of options and each of those perceptions might in principle be controllable.
*  So remember, the principle is that you can only control what you can perceive.
*  So, you know, of all the perceptions that you have right now, it could be very rich subjective experience.
*  I'm not you, of course, so I don't know for sure.
*  And some of them could be controlled.
*  And and of course, we can demonstrate that.
*  So the question is really what happens when you try to control one of these perceptions?
*  So, for example, if I don't like that desk, it's offensive.
*  I could turn around or I can walk out or, you know, or if the temperature in the room is too low, if you're cold, then you can leave or you can put on the sweater.
*  And these are all behaviors that I think are generated by control systems.
*  But I'm not sure if the richness of your subjective experience per se is incompatible with the control hierarchy in any way.
*  Well, what about let's say let's OK, so I know that these words are fraught, but the concept of mental representation, right?
*  So I can close my eyes.
*  And we talked about imagination earlier.
*  I can close my eyes and I can imagine my future house, a giant mansion on a hill, you know, in Costa Rica or something like that.
*  So it's that kind of subjective experience as well.
*  Just being it feels like I have a rich representation of not only, you know, my immediate perceptual experience, but of possibilities and I can, you know, of memories, etc.
*  Those feel like they are mental representations.
*  And, you know, the concept of representation, I know, is philosophically tricky as well.
*  Actually, I don't think representations are tricky in any way.
*  I think they're just literally true because you have signals in your brain that represent things, including this big mansion.
*  You know, for example, if that's a real goal that you have and you're working very hard, you're interviewing all these people, and let's say your podcast becomes the most popular show.
*  And then first you can reach that goal, right?
*  If you're actually doing this for that house.
*  Now, so in that sense, yeah, I mean, I think goals, especially in humans, could be relatively abstract and fancy.
*  But that in itself, I think is sort of independent of whether you can exert control over it.
*  In fact, I think, you know, some goals, obviously you do try to control.
*  I mean, that's the definition of goal-directed behavior.
*  Goal-directed behavior is just a control process.
*  And we say that because you're always comparing your ongoing inputs with your desired state.
*  So let's say you imagine that there's this nice house that you like, but your current house is too small.
*  And that's something that you're working toward.
*  So that's what I mean by a control process.
*  You know, whether you can imagine something 40 years from now or have fantasies about, you know, anything in the world,
*  I don't think that's so relevant because that in itself does not falsify any control model.
*  I guess my recurring question is just, you know, how much to think about the brain's functioning as being devoted to control processes.
*  Yeah, as I said, I think the input function is the most complex part.
*  And all these rich representations that you mentioned are really part of the input function.
*  Even when you imagine things, you're using perceptual channels.
*  They're just vague sort of perceptions.
*  And the source is not coming is not in the external world, but coming from your own brain.
*  So that's the major difference.
*  And that's why imagination, imaginary inputs and actual perceptual inputs will compete because they use the same perceptual channels at the higher levels.
*  So that's why when you're daydreaming, you can't perceive what's in front of you.
*  So I think that actually supports the idea that, you know, even imaginary imaginations can be used as some sort of input to a higher level control system.
*  I actually I buy that.
*  Before we move on, the word you dropped the word teleology in the chapter and I believe you've used it in the past as well.
*  And actually, my last guest, Johannes Jaeger, talks a lot about how we need to and a lot of other people seem to be talking about this.
*  Although this is my bias, I suppose, as my own interests have taken me down a path that is that is crowded with teleology advocates.
*  But can you talk a little bit about why we need to reinvigorate the notion of teleology and accept it as a valid scientific concept?
*  Yes, I think teleology simply means goal directed.
*  So, of course, there's a long history of teleology, but, you know, TELOS is basically the goal or end state.
*  So that has always been a dominant concept used to explain behavior.
*  But I think something happened, you know, after Galileo and Newton.
*  So in physics, in the modern scientific revolution, right, the first scientific revolution, the findings of Galileo and others appear to falsify this notion of teleology,
*  because the Newtonian physical laws do not contain any element of the final cause.
*  So final cause is that for the sake of which.
*  So, for example, Aristotle's example was, I'm running in order to become healthy.
*  And so what follows in order, in other words, the state of being healthy is the goal or TELOS.
*  And so that's the purpose of your behavior and your behavior is explained by this purpose.
*  Now, according to modern physics, that can't possibly be true because, again, as I mentioned, there's linear causation.
*  So F equals MA, there's no final cause there.
*  So it seems like everything in the universe can be explained by these simple physical laws.
*  And you don't need teleology to explain behavior.
*  And therefore, people have reached the conclusion that you have to abandon teleology.
*  In fact, the whole history of modern psychology and neuroscience is the history of various attempts to abandon teleology,
*  both in the vocabulary and also in the mechanistic explanations.
*  And so in my chapter, I argue that this is simply wrong.
*  This is a huge mistake because it's very simple.
*  It's that teleology is the main property of control system.
*  So you have everything in the universe basically follows Newtonian laws, with some minor exceptions.
*  But the problem is that there is this class of systems called feedback control systems,
*  which are sort of the exception in that you have to use circular causation to describe their properties
*  because at the same time that the input is affecting the output, the output is also affecting the input.
*  Actually, the way that the output is affecting the input is quite different.
*  But they're certainly simultaneous.
*  And because you have these two equations, things are changing simultaneously.
*  You can't use linear causation to describe the properties of this type of system.
*  So that's the exception.
*  So basically, that means in physics, you study, you know, open loop or things with no feedback, if you will.
*  And in biology, everything has feedback.
*  Everything is teleological.
*  So I would say that, yeah, in that sense, Aristotle was right.
*  There is final cause as long as you're talking about control system.
*  Of course, he didn't know how it worked.
*  So that's the distinction.
*  Because the way that it was used by people like Aquinas and a lot of people in history
*  was to argue that, OK, this is sort of a religious argument.
*  So this is the basis for how God is all knowing and knows the purpose for everything on Earth.
*  And the reason that the rock is falling is because God intended the rock to fall.
*  So that's sort of another type of misunderstanding, in my opinion.
*  And that's also why there is this conflict between the so-called scientists and people who believe in teleology.
*  Because teleology is considered to be unscientific.
*  So I'm not advocating teleology per se.
*  I'm just saying that the properties of teleological systems are basically the properties of control systems.
*  And if you think that the nervous system is a control hierarchy, then obviously you have to agree that it's teleological.
*  Because, yeah, but it's literally true.
*  Because the way these things run is that you need this internal state, this internal reference signal,
*  to be there first before you can generate the right behavior to reach the desired state.
*  OK, so the telos is not the reference signal per se, but it is the end result of controlling for the reference signal.
*  Is that fair to say?
*  Right. I mean, I think before you understand control systems, you always get confused about the consequence and the purpose.
*  As if they were sort of the same thing.
*  But of course they're not, because one is just the signal inside of your brain.
*  And you might fail. You mean it's not like you're guaranteed to succeed in your attempt to control, right?
*  And of course this also explains the difference between accidental and intentional behavior and all that.
*  So I think, yeah, traditionally people get very confused about the concept of purpose, of consequence, of goal.
*  But once you understand control systems, it's not a big deal. It's very straightforward.
*  So anyway, that's just my take.
*  I know that a lot of philosophers will have a problem with this.
*  I guess I don't care.
*  Oh, all right, great. I like the attitude.
*  I want to ask you about AI actually, but one more thing on the neuroscience side, or at least one more thing.
*  We can talk about more if you like.
*  Thinking about the circular causation in biological autonomous agents.
*  One of the things that you advocate is that actually what we need to do is instead of studying 40 different animals and averaging their behavior or looking for effects through that.
*  That what we need to do is it would be more fruitful to study one individual, but to do it for a long time and study it continuously in a continuous timeframe because of the circular causation,
*  because the inputs are affecting the outputs and the outputs are affecting the inputs because of the closed loop control circuit.
*  Yeah, that's a tough question. So traditionally, as you know very well, for example, in monkey work.
*  Two is the golden number in monkeys.
*  It's funny because a lot of people, a lot of neuroscientists, they like to criticize monkey research because the end is too low.
*  I hear that a lot. They use two animals or maybe three monkeys.
*  How can you believe the data because there's so few animals?
*  I think that's completely misguided because it's not really the number of animals.
*  It's actually in the way it's the amount of data that you collect and but more importantly the quality of the data.
*  So in the traditional analysis, you're basically doing some sort of input output analysis.
*  You're manipulating the input because the input is the so-called independent variable.
*  And then you have output, behavioral output, which is dependent variable.
*  So you're always testing the effect of variable X on measure Y, essentially.
*  And so what you're trying to identify is the function that will connect these two.
*  So if I vary the amount of reward, what happens to the fine rate of the cell?
*  That's kind of where if I manipulate the attentional demand of some task, what happens to the firing rate and that sort of research.
*  This is difficult.
*  Yeah, if what I suggest is correct, then all this work is not worth your time.
*  And the problem is, of course, that the variable that you're manipulating is not necessarily the input.
*  Usually people are trying to identify some effective stimulus, but the effective stimulus as traditionally defined is something that will reliably produce the behavior that you like to study.
*  And then in reality, it's actually not the input from the perspective of the organism, but it's the sort of the inferred input from the perspective of the scientist, of the observer, the third person perspective.
*  And that's very dangerous because there is an illusion, what I think Bill Powers called the behavioral illusion.
*  So basically, if you treat the disturbance, which is the input from the eyes of the observer as the input and the behavior as the output, it looks like you have identified the organism function or the neural function that's expressing the behavioral output or neural output as a function of the input.
*  But that's the illusion.
*  This is not true.
*  In reality, this function does not describe the property of the organism.
*  It actually describes the environmental feedback function.
*  It's mirroring the environmental feedback.
*  So when the disturbance is considered the independent variable, the output, the dependent variable, this function that you discover is not the real input output function.
*  Whenever there is control, it actually reflects the inverse of the environmental feedback function.
*  I know that that's not very easy to understand.
*  But basically, what you think is a property of the nervous system, if you use this approach, is actually a property of the environment.
*  Right.
*  So this is probably the most vicious.
*  Misstep.
*  Yes, the vicious trap in the history of neuroscience.
*  All right.
*  So anything else from the chapter?
*  So, you know, we didn't cover you actually give a lot of examples from history.
*  You talk about Sherrington, Sherrington, Sherrington and his experiments and Adrian and lots of people from the history as well.
*  Give me examples of how they how some famous people got it wrong from this perspective.
*  And there's a lot more in the chapter.
*  Did we miss anything that you think we should cover here?
*  Or do you think you've dug yourself a deep enough hole?
*  Oh, I think one of the things I suggest, if I remember correctly, for future research is this concept of using continuous measures.
*  Right.
*  I think you mentioned that.
*  And just sorry, I have to use the monkey experiment again.
*  So I use the monkey example.
*  As you know, you do chair training.
*  The monkey is restrained and then usually only a limited set of behaviors are measured.
*  Let's say hand movements.
*  Are you pressing a button or moving a joystick or eye movements, saccades?
*  But the most important problem, the most important limitation is that the measures are discrete events.
*  There are timestamps.
*  And then what you do is you require your single neural network to be able to measure the time.
*  And in neuron activity, you get the single units and you plot these peri-event histograms.
*  I'm sure you did this.
*  I'm quite familiar, yes.
*  And so there's this strange assumption that essentially the only thing that matters in behavior are these timestamps.
*  These events which are actually, of course, created by the scientist.
*  But it's not, I think, a reflection of the actual behavior of the animal.
*  It's whatever the scientist considers important or relevant in this particular behavioral task.
*  And then what you look at is the neural activity before or after or peri this event.
*  And then you reach conclusions based on various manipulations.
*  So I think that is very problematic.
*  And this has nothing to do with the theory of control or anything like that.
*  I'm just saying that this is a clear limitation of the experimental approach that you're not even attempting to measure behavior.
*  So I think that's a big problem because traditionally, whenever you look at the relationship between neural activity and behavior,
*  you use this kind of approach.
*  And your conclusion, I think, is going to be very limited because you're not looking for, you know, you're not measuring behavior continuously.
*  You might be recording your activity continuously.
*  So, for example, in our work, one of the things that we found was that when we measured behavior, behavioral variables continuously, for example, kinematics,
*  and we actually allow the animal to move, then there is a remarkable linear relationship between the neural activity, between firing rate and kinematics.
*  And this kind of correlation is much higher than anything ever reported in the history of neuroscience.
*  So I think that in itself is a major discovery, is the nature of this correlation, because it's completely unknown.
*  You understand that for many decades, neuroscientists have been trying to find a relationship between neural activity and behavior.
*  And for the most part, they failed.
*  Whenever they come up with a correlation or coding or encoding, so to speak, the relationship seems quite, let's say, subtle.
*  I mean, there's no clear relationship. The correlations are low.
*  And in part because of these failures, they have largely given up.
*  But our results suggest that, in fact, every time you measure behavior properly, there is a remarkable linear relationship between certain variables, behavioral variables, and the neural activity.
*  And this is not that surprising because behavior is continuous.
*  Even though we might represent behavior as discrete events at a very high level, for example, that might be what you're consciously aware of.
*  That's not necessarily the case when you're measuring the actual behavior generated.
*  There is a duration, there's a start, you know, it starts at some point, it takes some time, and then it stops.
*  So calling this a discrete event, I think, is misleading.
*  And at least our results show that you can get very interesting data if you simply measure, if you attempt to measure the behavior.
*  And I think once you get these novel results, then you have to explain them.
*  So how do you explain the fact that you have neural activity that actually slightly precedes the kinematics that's achieved by the body?
*  And it's basically a direct representation of something that hasn't been achieved, but is, you know, with the short lag, it is being achieved by your body.
*  So how is that possible? How do you achieve the desired positions if these signals are not literally the representation of the descending reference signals?
*  So, Henry, by the way, I love the chapter and I also recommend it, of course, to everyone else.
*  Can I ask you about how this relates to current artificial intelligence?
*  So on the one hand, you have reinforcement learning.
*  And in this sense, this is, and I know that you've made robots or a robot using, and I'll link to that paper as well, using this kind of control theory approach.
*  And the robot, I know, is made of, you know, very cheap parts, but actually performs really well in this continuous manner.
*  And it's a system of hierarchical control processes.
*  So what I'm curious about is how this kind of approach could help inform artificial intelligence?
*  It's a great question, but it's too big. It probably requires a separate session.
*  I guess the short answer is that, yeah, I don't think current AI is very useful.
*  And so the main problem is actually the same problem that I talked about before.
*  So, for example, reinforcement learning is just another example of the classic paradigm.
*  It's an attempt to do, to explain teleology without using teleology.
*  And so that's why reinforcement, the concept of reinforcement is circular.
*  So actually, that's sort of my background.
*  I did learning theory, reinforcement learning.
*  So we can talk about that in the future, maybe.
*  So, yeah, obviously there are limitations there.
*  I will say that what people don't realize is how bad these systems are,
*  like how bad current AI is, how bad reinforcement learning is.
*  And that's because they never think about the computational power and the energy environment and things like that.
*  So obviously there has been progress. So it's better than, let's say, 20 years ago.
*  But I think a lot of it, a lot of the progress is just in computational power.
*  So if you basically use computers from 20 years ago,
*  if you're forced to use those computers and you were to run these current AI, it just wouldn't work.
*  But I don't think, for example, that the biological brain has a lot of computational power.
*  It's significant, but it's not even close to what these digital computers can do.
*  So I think in a way, current approaches in AI and robotics are irrelevant.
*  But again, that's why I don't know if I'm comfortable talking about that.
*  It's a really big question. It's complicated.
*  And again, I don't want to offend everybody.
*  Of course, there are AI people who care about efficiency, but they just don't have enough constraints.
*  Do you know whether there are AI competitions that respect power usage, power consumption, and sort of normalize for that?
*  Or whether, you know, like not that you can aim to use a system that uses the same amount of power as the human brain, for instance, right?
*  Or something like that. But there could be.
*  I think you should. Honestly, I think that you should try to do that.
*  And if you have such a constraint, then you probably come up with smart design.
*  And so at least, you know, something in the ballpark, I would say.
*  Yeah.
*  Which is interesting because everybody cares about energy these days, right?
*  Well, that's what we say.
*  AI is where they don't care about energy use or electricity.
*  So. So let me put it this way in terms of well, AI and robotics.
*  I mean, you can ask any expert in robotics whether it would be trivial to build, let's say, a robot with more than 50 degrees of freedom.
*  And I guarantee you that they will say that it's extremely difficult, at least if not impossible.
*  To my knowledge, nobody has done it. But using our approach, it would be trivial.
*  That's the major difference. And it doesn't even require much computational power.
*  It doesn't require anything that's significantly different from what we used in the published paper.
*  But that's all I can tell you. But you can ask an AI expert or a robotics expert how difficult that would be.
*  And I imagine they would tell you that it's impossible.
*  So, all right, Henry, there's been a lot of pessimism, I'll say.
*  But I want to come back to as a last moment, I want to come back to Kuhnian revolutions and crises.
*  Because on the one hand, crisis, that sounds bad. On the other hand, I hear a lot of this sort of talk in neuroscience for one reason or another.
*  Yours is a specific, unique take, actually, which is why it's so interesting.
*  But it's also a sign potentially of a healthy field, right?
*  Because if people are turning inward and thinking, oh, we're doing this wrong,
*  because what happens after a crisis is the revolution and then a new paradigm.
*  So what I'm wondering is whether you feel optimistic about the future or if you feel like we're going to be mired in this crisis moving forward for another century or so.
*  I would say that overall I'm very optimistic. I think there is going to be a revolution.
*  That's the short answer. On the other hand, I do think there are a lot of obstacles in part because a lot of people don't think there's a crisis.
*  A lot of people, they're also optimistic, but for the wrong reasons, they think the current paradigm is good.
*  And now that we have all these new techniques in neuroscience, you just have to use these new techniques.
*  You can generate big data. Obviously, the brain is so complex so we can map everything.
*  We can map all the connections, all the snaps, we can record all the activity from every cell, that sort of thing.
*  Obviously, as I mentioned in the chapter, I think that's a misguided approach.
*  You never make any progress in science that way.
*  For the same reason, Galileo did not measure every object in the universe.
*  He didn't drop every stone in the world and measure how long it took them to fall.
*  So I don't think that's the right approach, but I think it's healthy in the sense that, okay, so there are people who are perhaps mainstream and they believe that the paradigm is healthy.
*  So they want to maintain the status quo.
*  And there are others, people like me, perhaps in the minority, but we think there's a crisis and we would like to start a revolution.
*  So I think that's healthy because there could be competition so we can see who will get there first.
*  So, yeah, I think it's exciting and I'm quite optimistic.
*  Oh, that's okay. That's a great place to end it.
*  Henry, thank you for coming on the show and thanks for your thoughtful work.
*  Okay, thank you. Thanks for having me.
*  Thank you for your support. See you next time.
*  The last blank page led me into the snow
*  The covers of the past
*  They take me where I go
*  You
