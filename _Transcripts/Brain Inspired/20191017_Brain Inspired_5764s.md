---
Date Generated: April 21, 2024
Transcription Model: whisper medium 20231117
Length: 5764s
Video Keywords: ['Science', 'Technology', 'Education']
Video Views: 99
Video Rating: None
---

# BI 050 Kyle Dunovan: Academia to Industry
**Brain Inspired:** [October 17, 2019](https://www.youtube.com/watch?v=osx4wrBGAyY)
*  You have a basal ganglia and there seems to be some sort of important, really useful trick
*  that evolution has come up with that relies on this sort of inhibit until there's good
*  reason not to mechanism.
*  And I think that that could be a profound insight for the decision-making component
*  of artificial agents.
*  I really feel like I re-entered that frame of mind that I had when I started my PhD
*  program, young, bright-eyed.
*  From the time of Benjamin LeBette, I had those really fascinating experiments that just totally
*  captured my imagination as an undergrad.
*  There is no free will.
*  There is no free will.
*  Yeah.
*  Think of that.
*  That is crazy.
*  It's crazy, right?
*  It's super crazy.
*  Yeah.
*  This is Brain Inspired.
*  Hello good people.
*  Today's episode is a little different.
*  My guest is Kyle Dunovan.
*  I am Paul Middlebrooks.
*  Welcome to the show.
*  I say it's different because Kyle is one of many people who originally went the academic
*  route and got his PhD doing computational neuroscience and did a stint as a postdoc,
*  still in academia, but then opted not to pursue a faculty position to start his own lab and
*  instead got a job in industry in the AI machine learning world.
*  In his academic life, he focused on the basal ganglia and how its circuitry functions to
*  help us make decisions and withhold our actions.
*  But in his newer life, he finds himself working a lot on natural language processing using
*  modern machine learning and AI techniques.
*  And we talk about all of that, but I say it's a different episode because in between the
*  science discussion, we talk a lot about some of his experiences traversing the academic
*  terrain and transitioning to industry and his thoughts on a range of related topics.
*  Many of you have written to me asking for a conversation like this, so you should have
*  plenty to chew on here.
*  If you're strictly here for the science, this may not be your favorite episode, but don't
*  worry, I'll be back to diving deep into neuroscience and AI topics in upcoming episodes.
*  If you do like this kind of episode or don't, please let me know.
*  Email paul at braininspired.co.
*  I really enjoyed talking with Kyle, commiserating with him a lot, and I'd be happy to have more
*  shows like this in the future if you want more like this.
*  Quick news, I've mentioned I'm creating a little course related to neuroscience and
*  AI.
*  This thing will be a work in progress.
*  And if you want to stay abreast of the progress, learn when I release early beta versions as
*  I create it, I made a page for it on the website at braininspired.co.
*  slash course where you can go and enter your email address.
*  And then as things happen, if they're worthy of sharing, I will email you.
*  If you support the show on Patreon, like those beautiful embodied minds, Marika, Alessandro,
*  Paul and James recently did.
*  Thank you guys.
*  If you already support the show or decide to, then there's no need to do anything.
*  I'll be giving you the option to consume and participate as things develop.
*  All right, show notes for this episode are at braininspired.co.
*  slash podcast slash 50.
*  Thank you for listening.
*  Please enjoy the thoughts, feelings, exasperation, redemption, and insight of Kyle Donovan.
*  Kyle Donovan, academia defector.
*  What I would say too many people in academia would call an academic failure.
*  Welcome to the show, man.
*  Thank you very much for having me.
*  So Kyle, you got a PhD at the University of Pittsburgh and Carnegie Mellon University
*  where I got my PhD actually.
*  Same program.
*  You're just a few years.
*  Yeah, I was at the CNUP and the CNBC.
*  Yeah.
*  Oh, wow.
*  Yeah.
*  I think you got your PhD or you went to graduate school I think right as I was leaving.
*  Okay, yeah, 2011.
*  Yeah, I'm bad with dates, but it was somewhere around there.
*  Yeah, I think I remember running into you at an SFN conference.
*  I think, yeah.
*  Yeah, very good.
*  Anyway, you got your PhD there and then you stayed on to do a postdoc also in Tim Versteinen's
*  lab.
*  We are going to talk about your research today, which I'm familiar with and also reading it
*  again because I've been out sort of out.
*  I'm still writing a paper, but made me feel anxious and excited all at once, which is
*  an interesting feeling.
*  Yeah, that's the natural feeling that you're supposed to get when you're in the research
*  mode.
*  I know.
*  I kept having these thoughts like, oh, I've got to do this with my data.
*  Oh, I've got to look for that.
*  Anyway, but these days you work in, I guess you'd say industry, you work at the machine
*  intelligence research and applications lab at Intrepid Corp.
*  I actually invited you on the show.
*  We'll talk about all this, but for a little perspective, it's maybe going to be a bit
*  of a different kind of show.
*  We'll see.
*  But from someone who's been sort of on both sides of the fence, let's say.
*  We'll talk about your research and we'll talk about what you're doing now.
*  All this is super interesting.
*  I also have all sorts of other kinds of questions.
*  Yeah, yeah.
*  To start off, I've been interviewing some people who will be giving keynote talks at
*  the Cognitive Computational Neuroscience Conference coming up here.
*  I noticed you had some papers in last year.
*  Did you attend that conference?
*  Yeah, I was at the first, the sort of inaugural conference for CCN.
*  That's right.
*  Was it in Philadelphia?
*  Yeah, it was in Philly.
*  Yeah, it was a bittersweet experience for me because I had sort of, you know, I kind
*  of knew that I was jumping ship shortly after and it was a really cool experience.
*  I don't know, maybe had it started earlier and I had attended earlier in my career, I
*  don't know.
*  It was pretty exciting.
*  a lot of interesting intersections between machine learning, cognitive science, neuro,
*  very much up my alley.
*  Yeah, I mean, there's another conference starting that's like that.
*  It's like exciting times.
*  I don't know why I quit.
*  I know.
*  Yeah, I guess buyers remorse now.
*  Sure.
*  So isn't it absurd that so many people in academia call people who leave academia academic
*  and that there's like this stigma associated with leaving the world of academia?
*  What sort of fucked up insecurity is that?
*  Yeah, it is a pretty pervasive response to leaving.
*  I think everyone that I know, it was sort of in my cohort or people that I knew that
*  left before me got that reaction from one person or another when they said they were
*  leaving.
*  I was just, I was, I don't know, revisiting this medium article written by one of your
*  former guests, Mark Humphries.
*  It's called Academia is the Alternative Career Path.
*  And I remember when it, I forget, maybe a year or two ago when he wrote it, I read it
*  and it was just this gobsmacking epiphany of like, oh my God, like it sort of points
*  out how ludicrous it is for that to be your reaction given that the numbers are so, you
*  know, dramatically skewed against making it from grad student to postdoc and then even
*  slimmer chance still from postdoc to assistant professor.
*  And then, you know, by the time you get to associate tenured professor, you're talking
*  like, I don't know, seven to 10% generously.
*  It's just to be made to feel like you failed as the 90% people who don't make it there.
*  It's just, it's a little ridiculous, but.
*  You don't feel like a failure, do you?
*  I do not, no.
*  It's a big smile on your face.
*  So the thing is, I have never spoken to anyone who has left academia who hasn't been super
*  happy about the decision, you know, which is a 100% rate here.
*  Yeah, which there's got to be something to that.
*  Yeah.
*  You know, I before leaving, but after having made the decision to not pursue this sort of
*  tenure track application circuit, I, you know, for the first time in a long time, felt like
*  I was really launching into the dark with my eyes closed.
*  Like I did not have the slightest clue as to like where to start, like what kind of
*  application do I need to put together?
*  It's, I mean, a very different process than what is required to start, you know, putting
*  together a packet that, you know, makes you competitive in the academic job market.
*  Right, right, right.
*  And so you don't really receive any, you know, any training to like as to how to get going
*  in this other direction that 90% or whatever of us need to go.
*  And I fortunately had some, you know, some pretty close friends who had had done this
*  just before me and had gotten jobs as machine learning engineers or, you know, in that
*  general space.
*  And so they were, you know, tremendous resource for me.
*  But, you know, still it was it was a I felt like I was really going out on a limb.
*  Yeah, we'll get into this a lot more, I hope, coming up here.
*  So we'll take a step back.
*  Let's talk about the times before you were a failure.
*  Good times. Yeah. So your most recent research focused on how mechanisms in our basal ganglia
*  using the action selection circuitry and plasticity that's based on dopamine could tie
*  together decision making and learning to carry out the algorithms that we think are important
*  in decision making.
*  For instance, the algorithm is the sequential sampling often modeled with the drift diffusion
*  model or stochastic accumulators.
*  And the goal is to make a correct choice there.
*  And in learning, there are various reinforcement learning algorithms with the goal of optimizing
*  reward. And you're still I guess you're still I mean, you just had a recent papers come out
*  this year. So are you still publishing papers and writing?
*  I am. And mine's like two years ago.
*  Yeah, that's that's another thing that is sort of unique to academia is that once you leave the job,
*  it sort of follows you around for years and years.
*  I after leaving, I had I moved to D.C.
*  from Pittsburgh with my girlfriend and was still sort of like, you know, remotely working in the
*  lab, sort of tying up projects that we were sort of in the finishing stages of.
*  And there was there was two, I think one was a revised and resubmit.
*  And we got that, you know, the revisions done and sent back.
*  And then there was one more that we, you know, I finished up some analyses here, but I was still applying for jobs at the time.
*  So there was relatively minimal overlap.
*  It just so happened that I had a couple of papers like really in the final stages when I when I left.
*  Well, the really in the final stage, there's the key because they're always I'm doing air quotes, but they're always in the final stages.
*  They've been in the final stages, I think, since I, you know, like submitted my dissertation.
*  Yeah. You know, years, but really in the final stages for those last couple of months.
*  I mean, so I don't know, can you just talk a little bit more about about the work?
*  Because it's actually really interesting.
*  And it's from straight from your dissertation.
*  So you guys propose this model that combines the decision making and reinforcement learning stuff going on in Basel Gangli.
*  It got me like I said, it got me all excited again about this stuff and anxious and anxious.
*  Well, I'm right.
*  I'm revising for resubmission a paper on response inhibition because in monkeys and I recorded neurons.
*  And so it's a cross between a response inhibition and a decision, perceptual decision making task.
*  So it's just like that's yeah.
*  So it's right up my alley.
*  This could actually have been the poster that I saw of yours at SFN.
*  I don't know if that's probably was it was a modeling poster.
*  Yeah. Yeah.
*  It was sort of like a tractor networks with some stop signal.
*  Yes. This was.
*  Yeah. OK. Yeah.
*  It's all coming back to me because I remember I remember speaking with and Tim came by the poster, too.
*  Yeah. Yeah.
*  Yeah. We talked for a while.
*  Well, that's interesting.
*  Yeah. This was like 12 years ago.
*  And that's right. That's the modeling work that I'm still.
*  You're still you know, it's really in the final stages.
*  It's really in the final stages now.
*  Every email from my old advisors.
*  Boy, this is really coming together now.
*  Yeah, that sounds familiar.
*  Yeah. Yeah.
*  It's always coming together.
*  Yeah. So anyway, what?
*  Basil Ganglia. Cool stuff.
*  Yeah. Yeah. Basil Ganglia.
*  He's rolling his eyes.
*  I mean, I have such a mixed relationship with the Basil Ganglia.
*  It's one of those, you know, it's like this fascinating but still totally mysterious.
*  Like you big of this Lee involved network in the brain.
*  I mean, it's it's in essentially every vertebrate species has some like homolog of the Basil Ganglia
*  and in all of those species that it receives like, you know, I think conservatively,
*  like 90 percent of cortex sends inputs to the striatum and maybe the subthalamic nucleus.
*  And so it's this, you know, incredibly important network.
*  It's also think of some neurological ailment or disease.
*  And it's you know, Basil Ganglia is probably involved or the dysfunction of is probably involved.
*  And it just it also seems to be involved in, you know, everything from motor control,
*  planning, reinforcement learning, decision making, basic inhibitory control.
*  So it's it's really a challenging sort of a tall order to pin down really,
*  you know, what is it responsible for?
*  And, you know, if it is indeed responsible for that thing,
*  how does it carry out the information processing steps?
*  And, you know, a lot of my earlier research sort of, you know, in grad school
*  was more sort of on the cognitive algorithm side, the the information processing recipe,
*  if you will, for, you know, basic kinds of perceptual and value based decision making
*  as well as inhibitory control.
*  And that work sort of explored, you know, OK, how could we start putting these,
*  you know, functions together, learning and decision making functions that
*  have to be together at some point?
*  That's right. Yeah. At some point, there has to be a nexus where you learn to control
*  your decisions, learn to inhibit unwanted behaviors.
*  And so traditionally, these have sort of been independent streams of research.
*  And so it was it was really fun to start sort of patching together these these formal
*  computational models that have been used like, you know, for a long time in science.
*  In the postdoc, I started working with a mathematician, Jonathan Rubin,
*  at the University of Pittsburgh.
*  And he had collaborations with Jiao-Shing Wang, who has done this like very biologically
*  detailed and sophisticated modeling work on basal ganglia.
*  And so we sort of picked up where one of Jonathan Rubin and Jiao-Shing's previous
*  projects had left off.
*  They had this this really elaborate spiking neural network of cortex, basal ganglia,
*  and the thalamus.
*  And we started exploring, OK, what if instead of just doing the neural network modeling,
*  we sort of treated that model like a participant and we used these models from cognitive science
*  to try to understand what algorithm it was carrying out and sort of what parameters of
*  that cognitive algorithm were modulated when we tinkered or played with some of the
*  bells and whistles in the neural network.
*  So we were doing this experiment in the context of a value-based decision-making
*  task where the network makes two alternative force choice decisions and then it gets some feedback.
*  And there's some dopaminergic error signal telling it, you know, it's right or wrong.
*  And that modulated the weights of these cortex-distratum connections.
*  And then, you know, it would proceed to the next decision and repeat.
*  And then over the course of many decisions, we now had sort of a time course of like, OK,
*  well, you're seeing changes in behavior.
*  If we fit the cognitive model to the network's behavior, what happened to the algorithm?
*  What was that feedback responsible for?
*  And how did the learning affect the sort of behavioral algorithm for how it treated the
*  evidence and how it converted that new evidence into a decision and got better
*  at achieving its goal of maximizing reward?
*  Yeah, this is really nice work.
*  I mean, the paper you're referring to, I guess, is the most recent paper.
*  Is that the PLOS paper with Jonathan Rubin and Tim?
*  I'll link to it in the show notes.
*  I'll link to the sort of the whole series of these papers.
*  I mean, it's really exciting work being done in the basal ganglia these days.
*  So I've talked a lot about the hippocampus.
*  I've had a lot of guests who talk about and work on the hippocampus.
*  And of course, the neocortex is everyone's favorite part of the brain.
*  But, you know, I had Rafal Bogach on the show and he's done a lot of the basal ganglia
*  optimization work that you guys refer to a lot.
*  But what do you think?
*  Is the AI world neglecting the basal ganglia as a source of inspiration beyond?
*  So, I mean, there's the classic dopamine and reinforcement learning story.
*  And that's kind of where it stops with AI.
*  Yeah, I mean, I think so reinforcement learning as sort of like a class or category
*  of computational models has been profoundly influential.
*  Like, you know, if you go back to just 2014, the DeepMind AlphaGo success sort of kicked off
*  the reinforcement learning frenzy.
*  But yeah, I think there is something special and unique about the architecture of the
*  basal ganglia that is not present in any of these artificial agents.
*  And one unique aspect of this network is that if you think intuitively about how you behave
*  and act in the world, you sort of think about doing stuff like in order to move your arm,
*  you need to move your arm.
*  But really what you need to do is remove this dramatic, profound, sustained inhibition of
*  the arm flexor extensor muscles, which the basal ganglia is sort of exerting all the time.
*  It's always preventing output until you've sort of received enough sensory input or some
*  internal motivation enough to release it.
*  To overcome it.
*  Yeah.
*  So you're bringing this indirect pathway in the basal ganglia, which we will not get into the
*  actual anatomy of it.
*  But yeah, it's kind of constantly on inhibiting actions.
*  And you really have to overcome it with a more what's called the direct pathway in the
*  basal ganglia.
*  Yeah, this sort of this disinhibition.
*  And so there is this remarkable finding that if you are a vertebrate, a member of a vertebrate
*  species, you have a basal ganglia.
*  And there seems to be some sort of important, really useful trick that evolution has come
*  up with that relies on this sort of inhibit until there's good reason not to mechanism.
*  And I think that that could be a profound insight for the decision making component of
*  artificial agents.
*  Right?
*  Like you're sort of applying a threshold by default and you're sort of requiring this
*  burden of evidence in order to execute a decision.
*  Otherwise, the agent sort of isn't allowed to.
*  That's yeah, right.
*  It's like you kind of think of a decision as starting from zero, right?
*  And then you think, oh, OK, now, if I get enough evidence for this thing, I'm going
*  to do that.
*  But really what you're saying is that the basal ganglia ensures that we start at some
*  level that then there's a lot of give and take that can go on.
*  Yeah, it's like you're starting negative.
*  And you have to get positive or you have to sort of like, you know, pass that, like get
*  out of the red zone in order to make a choice.
*  Yeah.
*  I wonder if I mean, I'm just thinking of the cuff here.
*  So I just interviewed Raya Hadsall, who is a robotics person at DeepMind.
*  And she does a lot of deep reinforcement learning in the robotics world.
*  And I wonder if something like the basal ganglia functioning is going to become more important
*  when there is more embodiment in the world.
*  Right.
*  Well, yeah.
*  I mean, you can pretty easily imagine the incentive for like, you know, making sure
*  a robot is really, really sure before it hauls off and does something in the real world.
*  Right.
*  Like there's actual physical consequences to our fragile human bodies when we're
*  operating amongst, you know, really powerful mechanic bodies.
*  Yeah.
*  Well, I mean, you know, I mean, you could it's an important mechanism as well.
*  So we're talking about the decision making and essentially, well, I guess we're talking
*  about it both because you're inhibiting a response or deciding to respond or overcoming
*  the inhibition to a response.
*  But then you're also choosing which response to make.
*  But it's also valuable in non embodied systems, of course, you know, just making decisions
*  or not in a.
*  That's right.
*  Yeah.
*  But it might just become more apparent.
*  So I'm sort of picturing like, when is the Basal Ganglia going to get its due in AI?
*  You know?
*  Yeah.
*  I mean, it's sort of funny because reinforcement learning has really taken the AI world by
*  storm.
*  But, you know, if you if you go just, you know, one one department to the left, like
*  you're in neuroscience, like the first stop in reinforcement learning in a neuroscience
*  department is the Basal Ganglia.
*  Right.
*  It's sort of the most famous or infamous, depending on who you ask, you know, circuit
*  for controlling that that algorithm, that that learning algorithm.
*  Yeah.
*  So it is it's I find it a little unusual that it hasn't, I don't know, been been picked
*  up or experimented with.
*  We had we had sort of grand plans to collaborate with some roboticists at CMU on developing
*  a, you know, some differentiable architecture to mimic some of the sort of direct indirect
*  pathway anatomy in an artificial agent.
*  It never really took off.
*  But yeah, it maybe it's just a very hard problem.
*  And people have tried unsuccessfully.
*  And, you know, all that work has just been shelved.
*  Yeah.
*  But I guess we'll never know.
*  Well, we will know.
*  Hopefully, hopefully we'll know.
*  I mean, you know, everyone's interested in the core.
*  And there's this, like I said, this, you know, the hippocampus is really hot right now.
*  And then you have these other regions.
*  And of course, people are going to talk about amygdala soon.
*  And if you're in a motion.
*  But and then there's the cerebellum in the back of the head, too.
*  And you have I just interviewed Philip Alvelda, and these haven't been aired yet.
*  You know, but and he's really interested in the cerebellum's role and prediction and all
*  this, you know.
*  So there's just so many avenues to go down here.
*  Right.
*  Yeah.
*  So, I mean, this is this was another bittersweet aspect of leaving neuroscience when I did,
*  which is that I really feel like in the last, like, I don't know, two to five years,
*  somewhat gradually, like people have really started to challenge and question some of
*  the just the most fundamental assumptions that a lot of the famous findings that we
*  sort of think about in the history of neuroscience are based on.
*  And now, so like just like thinking about what the relevant unit of measuring functional
*  neural activity is like, should we be focusing on single neurons or should we be talking
*  about population codes?
*  Is it useful to measure an average firing rate over some amount of time?
*  Yes, I'm speaking to my reviewers.
*  Yes, it's useful.
*  No, it's not useful, but we do it.
*  Yeah, we do.
*  And so I think people like Conrad Cording and Jonathan Pillow and John Cerencis have
*  in their own particular domains where they have pet peeves, whether that be methodological
*  or the measurement techniques that are used or on the analytical side or just the theoretical
*  side of like what we should be asking.
*  A lot of these people have been really fun to watch and read and listen to.
*  And I've found, you know, found that to be refreshing.
*  Yeah.
*  So what was it that made you really decide that it was time to move on?
*  I mean, I found myself in the 90% of people who just, you know, I did not really.
*  Were you doing job search or?
*  No, so I was sort of coming to a natural conclusion of my postdoc in Tim's lab.
*  Yeah, yeah.
*  It's going to all sound very familiar to me, I'm afraid.
*  Yeah, well, so it, you know, I was finishing up projects and thinking about next steps.
*  And the original plan was, I think, you know, I started thinking like, okay, I'm going to
*  start putting together an academic job packet of, you know, here's like a packet of my
*  like teaching experience and student reviews of my teaching and my research and extra curricular
*  stuff and, you know, everything that sort of goes into like a personal statement, everything.
*  You were starting.
*  Yeah.
*  Yeah. Well, thinking about it, at least.
*  And then I sort of, you know, I thought, okay, well, you know, maybe industry wouldn't be so
*  bad. And that idea sort of crept into my head. And then I thought, okay, maybe I'll just do a split.
*  I'll apply to some industry and some academic positions and just see how it all shakes out.
*  And then that turned into like, wow, like, I am going to be grinding to get this academic job,
*  you know, application in to, you know, like a ton of places because the hit rate is going to be so
*  low. And I'm probably not going to make it this this round anyway. I probably,
*  I really felt like I probably wouldn't get any invitations to give a job talk just because
*  I don't have a nature neuro paper and the field was crowded.
*  There was a backup to at that time of for crouched.
*  And, you know, there are people who are just going to be a lot more filled out in their CVs
*  than I was going to be. And I, you know, came to that realization and I thought, well, you know,
*  I might as well just apply it on the industry side and see how that goes. Because I'd always
*  been curious about it. Working in that space, I'd heard from several friends that they were
*  having the times of their lives doing whatever they were doing. And so,
*  but it was scary for sure. I was, I was very nervous the whole time.
*  You also came. So I think that you and I share this in common, correct me if I'm wrong,
*  but did you have maybe a somewhat of a chip on your shoulder that was driving you because of
*  like how you managed to get into grad, like how you had to fight me? I don't know if you had to
*  fight but. Well, so I got really lucky getting into grad school. I think I was super green. I
*  also, you know, I didn't have a ton of research experience. Like, I like, you know, most people
*  who ended up getting into grad school knew a professor who knew somebody at Pitt and, you know,
*  that person recognized this person's name. And, you know, it's just academia is just like industry.
*  It's all about, you know, it's all political. Yeah, such bullshit. Which is something you really
*  learn after, you know, going through it, because I don't know why people think about it or, you know,
*  if it's portrayed this way, or it's just an erroneous assumption that somehow it is,
*  it's cordoned off from all of that nonsense, but it is, if anything, you know, more inundated with
*  it. It's a hard pill to swallow that realization. Yeah. Yeah. So I don't know, it ricochets you in
*  a way that leaves you feeling pretty jaded about how, I don't know, it feels like it sort of fails
*  to live up to what it's sold to you as, which is this, you know, very like a meritocracy, basically,
*  that really is just as susceptible to prestige and the politics of the rest of the world.
*  That was awesome. You know, there are lots of reasons, and I don't need to tell my story here,
*  but that was one of the things that really hit me. It's like, oh, that's awful. Do I really want
*  to play this game and constantly push against this? And the answer was no, that clearly was no.
*  That's right. Yeah. But that was one factor for me. Yeah. One thing I wanted to make sure that I
*  said here was that I really loved my job. Like, I really like doing research. I really, I still find
*  questions about the brain absolutely fascinating because they are. Like, it's just, it was,
*  you know, I was really lucky to get to spend that much time focusing on, like,
*  solely focusing on something that was really truly just intrinsically fascinating. But
*  I don't think that, you know, I feel like I entered the program, you know, my training
*  and the pipeline for what I thought was to become a lifetime academic. And I don't feel
*  like academia held up its end of the bargain. Oh, well said. Yeah. I think a lot of grad students
*  enter a PhD program. They spend some of them 60 hours a week grinding for very little pay and,
*  you know, trying to live up to these sort of monstrous expectations of how they should
*  spend their time and just spreading themselves way too thin, doing the bare minimum of what
*  either their advisor or their program expects of them. And the underlying assumption
*  that justifies all of that work is that this is helping me move myself along through the ranks
*  of academia and it will contribute to my success in getting a tenure track job or whatever they
*  want to do. And for most people, that assumption is just false. It's just, it's a false assumption
*  that the people who did make it in academia, they're, you know, the people who preceded
*  these students and are responsible for training them, they benefit from that false assumption.
*  And in most cases, or in my experience, those programs are more than happy to let
*  these students sort of operate under this false assumption because it is cheap expert labor.
*  Yeah, that sure is. Before we move on, so I interrupted you because I just want to talk
*  about me, right? So, but you said you got lucky because of maybe, you know, you knew someone,
*  but you're a dropout, right? Well, yeah, so I was a pretty miserable high school student and then I
*  I had aspirations to be a famous metal guitarist. I really felt like my hardcore band in Western
*  Nebraska was on the come up. So I stayed and went to community college in my hometown.
*  And in the band, you stayed, you're in the band? Yeah, that's right.
*  Oh man, we were called, I was in a lot of bands, but I think the one at that time was a Deadwood
*  Calamity. We'll play on words of Deadwood, South Dakota Calamity chain. Oh, nice. Yeah,
*  we thought we were pretty cool. But yeah, it sounds pretty cool.
*  Anyway, that was my reason for staying in Scotts Bluff, Nebraska and going to Western
*  Nebraska Community College, which I did not graduate from. I think I rounded that out with
*  a C and Algebra 2 and maybe a C plus and an Intro to Education. And then was able to get into
*  state college in Omaha, Nebraska, UNO there. I was not the sort of, you know, high flying straight A
*  student who was always destined for the ivory towers by any means. I had a late intellectual
*  blooming where I got introduced to neuroscience through philosophy of mind, this sort of this
*  really cool class called Limits of Consciousness. And the professor was just this profound influence
*  on me. And he really like took an interest in me because he saw that I, you know, was interested
*  in the class. I think after the first class, I went to the registrar's office and changed my
*  major to neuroscience and it was pretty much, you know, that was it for me. I just really,
*  you know, launched into it. Then, you know, after having that really spontaneous shift
*  and, you know, my interests and priorities, I did well in school, you know, completing that major
*  and had some really awesome advisors like write me letters of rec and stuff.
*  Oh yeah, that helped me too.
*  Yeah, that was a big plan for me.
*  I root for guys like you because that's guys like me, guys and gals like me, right? That, you know,
*  what I screwed myself over innumerable ways and it's a minor miracle that I got into grad schools.
*  Yeah, so I think for a long time, I think and I think a lot of people have this assumption that
*  like to be an academic or a scientist or a researcher that you have to be really smart.
*  And yeah, but look at us, huh?
*  Exactly. We're very dumb and we're doing, you know, we're still doing science.
*  But I really, I think that is one of the saddest, one of the saddest misconceptions about science
*  is that you have to be this disaffected, socially aloof, like brilliant egghead. And really,
*  I've seen a lot of scientists who were definitely, you know, intellectually superior
*  to everyone else in the room, but like really were not cut out to be good scientists.
*  There were people who were, you know, fell well below them on the sort of, you know, intellectual
*  ladder, but were curious, driven, motivated, you know, really, really interested in asking
*  deep scientific questions and then doing the legwork to get a reasonable answer
*  that really exceeded those quote unquote brilliant peers of theirs.
*  Yeah, I agree. I mean, one of my lessons, one of the things I learned, I suppose, was that
*  you don't have to be brilliant to get a PhD. And what a PhD means is that you are probably above
*  average intelligence, but it means that you worked really hard and you have some grit and there's
*  some drive, right? Because it seems like if you just continue working hard, you're going to get
*  the PhD. So to me, it's like not magical. You know, it takes the magic away from the PhD.
*  Yeah. Getting the PhD definitely, you know, it, I don't know, it lifts that spell,
*  so to speak. Like it really, you see it as an indication of work ethic much more than,
*  you know, intellectual. Yeah. Which is, I respect. So, you know,
*  absolutely. Yeah. And I think you in carrying out the process, you do develop a, like a deep
*  appreciation for work ethic over a lot of other things and things like, I think curiosity and
*  motivation, the ability to self-motivate and follow through. This is a big deal because
*  without that, I mean, you know, you can be really, really smart and not capable of finishing anything
*  and you're not worth much as an expert at that point. Yeah. I mean, at least in experimental
*  neuroscience, I suppose. I shouldn't speak for all PhD efforts, but I, I have the feeling that it
*  generalizes as strong in me. So I. Yeah. No, I will say that I, I'm not envious of,
*  I think you have a background in, in electrophys. Yeah. I don't want to talk about it. It depresses
*  me. No, that, that, that is a, I'm under no illusions that my PhD was as hard as somebody
*  who had to train monkeys to do human tasks. Oh, I don't know. I mean, I'm not sure if hard is
*  the word, but again, it's persistence and well, don't make me cry here, Kyle. Let's move on.
*  Yeah. So, but, but, so, okay. So you got into grad school and you worked hard and stuff and you
*  loved your job. I did. Yeah. What's one of, we have all had scientific moments, right? You know,
*  like that, that special, like, oh, the, the, the really like this, I'm going to remember this.
*  Can you give me an example of a scientific moment that you've had? Yeah. I, I think, yeah, I think
*  I've had a few that fall into some different categories. One was mentoring. So like when I
*  got to sort of late grad student postdoc phase, I, I had a couple, like really, really bright
*  undergraduate mentees that would sort of week after week come to our meetings with progress or,
*  wow, that's impressive. You know, like questions that were, I mean, both of the, the students I'm
*  thinking of were, I mean, way, way, way smarter than I was. So it was sort of a, a mentoring
*  challenge to like, how do I, how do I like sort of steer, steer these, you know, students without
*  getting it in their way? Like, how do I contribute in ways that they will benefit from without,
*  you know, and I needed to remind myself not to pretend that I was smarter than them. And so
*  it was a real pleasure getting to get to know these really bright kids and help them
*  learn how to do good science within the confines and constraints of, of scientific,
*  I don't know, institutions. And they are, you know, both of them are in grad school now.
*  And doing really interesting work. So those interactions were things I really valued a lot.
*  The people, yeah.
*  The people, yeah. And I don't know, I think you get so jaded by the end of a PhD that I think for
*  me anyway, it took that, that sort of naive childlike wonder of a mentee to like get me,
*  you know, excited again about the process. I know it's so important.
*  You gotta get your kicks through other people.
*  Gotta get my kicks, yeah.
*  It was, I don't know, it was, it was exactly what I needed at the time. And it was a nice healthy
*  reminder that it wasn't all so broken. There was like really smart people who were going through
*  the system with the best of intentions to do really good, solid scientific work. And, you know,
*  had an ethical head on their shoulders. So it was, it was rewarding and refreshing. And it was a
*  good reminder that science wasn't totally broken.
*  Which you knew, which you knew in your heart of hers.
*  I was deep down, but I needed just a, you know, a quick little pick me up. But, you know, I also
*  had personal scientific moments, as you say, like I think, again, this was early postdoc. I had,
*  I can't remember if somebody recommended the article to me or I was reading it for,
*  you know, journal club or something. But I was exposed to some of Eve Martyr's work on
*  under-determinancy in neural circuits. So this phenomenon of a complex system being
*  capable of producing more or less the same output under different parametric regimes.
*  So like a simple example is a single neuron, let's say that has sodium and potassium channels.
*  And you're trying to fit, you know, those two free parameters, let's say sodium conductance
*  and potassium conductance based on, you know, the neuron, how well the neurons firing rate
*  matches some data. But there are multiple different pairs of values that sodium and
*  potassium conductance can take on that all lead to the exact same firing rate. So how do you know
*  when you fit that model, some empirical firing rate data, that the two values that you ended up
*  with are, you know, good values for what the system has in the real world, right? Like,
*  so it's this sometimes called slackness or sloppiness in neural systems.
*  Multiple, multiple realisability, I believe it goes by that name as well.
*  That's right. And so it totally changed how I looked at neuroscience research and really
*  shaped how I digested other papers that I was reading. Like, is this, you know, this model,
*  is this, you know, is this model too complex for the sort of limited amount of data that it's,
*  that it's being informed by or fit to? So I think I sort of viewed a lot of
*  Eve Marger's work in that domain as sort of like meta research, sort of like guidelines or like
*  limits or constraints on like what you could really say in the field of theoretical neuroscience,
*  where you are really dealing with the most complex system that we know about. And the
*  current approaches just don't really seem to be respecting that complexity in a way that I thought
*  was necessary. And then so that insight was really profound. I think Eve Marger's work is just
*  brilliant across the board. And she works on crabs. She's like, has this, this remarkable ability to
*  pull out these really broad, you know, sweeping insights that apply to the whole field of
*  neuroscience and all it encompasses from this dramatic gastric ganglion of crustaceans.
*  I just think she's brilliant. There's hope there too for everyone, because there's still an infinite
*  amount of room to make progress in these sorts of things. Yeah, for sure. And like I said, I think
*  that some of those important questions are starting to get asked and the appropriate
*  challenges are starting to be lodged. You know, again, some of the status quo methods that
*  we've relied on for a while that may not be really telling us what we think it's telling us.
*  In some sense, though, neuroscience really is a young field in that, you know, people just,
*  20 years ago, we're just getting like single neuron responses, right? And that was,
*  you know, you spent six months doing this, and then you take a victory lap,
*  you know, and all you have to do is like record one cell, and then sort of characterize it. And
*  you'd have these classic papers. Yeah, I know. And even when I came into grad school, I remember
*  having lunch with a pretty high profile scientist in the CNBC at the time. And they told me that if
*  you weren't measuring single neuron activity, that you weren't doing real neuroscience.
*  That really stuck with me. I know who that was.
*  It really left a bitter taste in my mouth. And I want to think in my heart that he's sort of
*  had a coming to Jesus moment in the past couple of years. But I think that might be giving him too
*  much credit. I don't know if senility might be maybe that is the coming to Jesus moment.
*  But I respect that person, actually. But yeah, for another thing I realized going through and
*  getting a PhD, you know, you get your PhD, and you're supposed to know something, but it seems
*  like the more you learn, the less you actually know. And there are lots of things that I wish
*  I had known going in to graduate school, for instance. Yeah. I mean, is there something that
*  comes to mind that that you wish you'd known going into neuroscience research? I wish that I had known
*  that some of the assumptions weren't gospel, like some of the some of the everybody sort of
*  took for granted, shouldn't actually be taken for granted. And I think that would free up a lot of
*  interesting research questions to be explored. But I do, I think in the last five years, there's been
*  sort of some very highly respected people in the field coming forward and saying like, we really
*  got to reevaluate the question set. And I but I wish that that had that had happened a little bit
*  earlier. I think that's a very recent phenomenon. But I'm sure it's not because all the groundwork
*  was already there for that to happen. Yeah, I don't know. I mean, I think I think it depends on,
*  you know, neuroscientists is such a broad, you know, like catch all fields, there's really so
*  many sub disciplines where it's probably more true in some sub disciplines of the larger field where
*  some of the basic assumptions were more wrong and more recently challenged, whereas other sub
*  sub fields might have had an earlier sort of realization that they needed to reevaluate.
*  But I think at least in terms of computational neuroscience, and decision and learning questions
*  within that domain have gotten a real rejuvenation, just in terms of like, what's
*  fair game in terms of how to recast the modeling enterprise and like, what constitutes a model?
*  Like, I think the new trend of applying deep neural networks to empirical questions about
*  neural systems is really interesting. I think you had Dan Yamins on the podcast, and he was he gave
*  a part of a panel at the first CCN conference. And I think the question that these three panelists
*  were were tasked with answering in their own unique way was, what would a good model of the
*  brain look like? And what would that even look like? Right? As soon as you build a really, you
*  know, like a high fidelity model of the brain, now you've got a system that is as complex as
*  the system that you're trying to glean insights about. So it's like this, you know, it's this catch
*  22 that the closer you get to the system, the less tractable that that model system is to answer
*  your questions. And so, Dan Yamins had this like, what I thought was a really brilliant argument that
*  what we currently do is we have these toy tasks for our models to solve like a two alternative
*  forced choice task. It's a far cry from anything we really experience in the real world. You know,
*  we're usually talking about one or two relevant feature dimensions on which the agent is supposed
*  to base their decision, all that stuff. It's incredibly, you know, sterilized.
*  Well, it's abstracted. You have to a more optimistic way of saying that would be it's
*  abstracted. And yeah, yeah. And we've certainly learned, you know, something using this approach.
*  But I do think that we're reaching a point where we have sort of we've extracted a lot of information
*  for about the basic, you know, mechanisms of these simple behaviors. But to scale up to something
*  more interesting and generalizable, it's going to require a slightly different approach and,
*  you know, maybe a dramatically different approach. And Dan Yamins argument was that, well, okay,
*  if you want to test a model at scale, you need a more complex task. And one benefit that comes
*  from that is that the more complex the task, the harder it is to solve, the fewer strategies there
*  are available to solve that task. And so if you build a complex, let's say, you know, a neural
*  network based agent, and you ask it to solve a really complex task, you can you can say something
*  very explicit about the strategy it used to solve it, if it if it did, in fact, find a solution.
*  And you can also maybe not know everything about the strategy, the information processing,
*  the sort of fine grained relationship between structure and function. But you can start to
*  glean insights about what's necessary in terms of, like, you know, in architecture, in order to,
*  you know, implement a particular information processing strategy. And you can see that
*  instead of like optimizing over different values of a parameter, you can start optimizing over
*  different architectural, different architectures of the of the network. So throw in different
*  activation units, throw in different connection motifs, and and see how that changes the efficacy
*  of the agent and solving the task. So I just I thought that was a reference to the question
*  I thought that was a refreshing perspective, flipping the problem on its head in a way that
*  felt like you could really pull out some useful information and you could do it in a way
*  that was not so abstracted or oversimplified. Yeah.
*  You talked about buyer's remorse earlier. And, you know, in another, in some sense,
*  what I'm seeing going on now, and I know I can see the way that you're talking about these things,
*  you think, oh, this is exciting stuff, and it is exciting stuff. And I think, man, if I could start
*  over, what would I how would I proceed, you know, and I get a lot of feedback I get on the show is,
*  you know, people say, oh, I like your show, yada, yada, you know, whatever. But please, like,
*  I need advice that people want to hear, like, what, how should I proceed? How should I go about
*  doing this? Like, how do I get to the so that I'm working on neuroscience and AI? So if you
*  were going to start over right now, how would you lay it out for yourself?
*  Yeah, I would, I would take more computer science. I don't think it's, it's certainly not necessary
*  to be a precocious math wizard or computer science nerd. Like I didn't start programming
*  until I was in grad school. And I actually have like a really embarrassingly low level of formal
*  math education. Like I was I was sort of told from a pretty young age that I was not a math
*  person. And I was really bad at it. And so I sort of operated under that assumption for a really
*  long time. And but when I was in grad school, I had a lot of free time in my earlier, like stages
*  of training that I, you know, I just I knew that I really was interested in computational approaches,
*  whatever, you know, that interest meant at the time is kind of superficial, but I knew I really
*  wanted to, I don't know, try my hand at it. And so I spent a lot of time reading about Bayesian
*  statistics, and then sort of tinkering around with MATLAB. And then I switched to Python. And then
*  that really just hooked me. I just totally fell in love with with, I don't know that
*  coding that work was fun. Yeah, coding was was a good time. And learning to do it was a pretty
*  rewarding experience, right? You succeed or you fail. Usually you fail a lot and then you succeed,
*  but it's this sort of in the weeds tinkering until it it works. And that that's fun once it pays off.
*  But there's quicker feedback, I feel like in coding than there is in research, which helps.
*  There is Yeah, it is a way to bootstrap some quick feedback into your life. If part of your
*  work in doing neuroscience research involves coding, that is, you know, a clear and frequent
*  success or fail signal that if, if there are people that haven't gone to grad school yet,
*  listening to this, just trust me, you yearn for feedback in a way that you, you never knew you
*  could. You go, you know, without sort of forcing something like that into your life, you could go
*  like, you know, months, if not years, without really any clear guidance from the world around
*  you. You know, just to play devil's advocate, I wonder if it's not swinging too far into the
*  computer science direction these days, where someone might be more valuable or as valuable or,
*  you know, have a different kind of value if they do go then sort of the more neuroscience biology
*  route. I don't I wouldn't do that either. But yeah, I mean, I like, I really think that, you know,
*  that that's an irreplaceable part of doing neuroscience research, you have to have people
*  who are experts in, in collecting, you know, empirical data in running sound experiments
*  and designing them in. And that is a whole other skill set that is, you know, requires just as much
*  rigorous training and attention to detail. And it can't be taken for granted. Absolutely. And
*  you certainly don't need to like be a coding genius to do useful neuroscience research. I
*  feel really strongly about that. I do think that like, as the, you know, the computational
*  abilities continue evolving, right, like just the the scale of our computing and analytics ability
*  right now is something that should be taken advantage of in academia in a way that I,
*  I think in a lot of psychology and biomedical, including neuroscience programs, it, at least
*  during the graduate training is not it's not taught, it's not emphasized. And I think academia
*  is is going to pay a price for neglecting it. But to answer your question, no, I think, you know,
*  the like wet lab work is is, you know, just as necessary as it always has been.
*  Everything is necessary. There's just too much to do. One of the things I appreciate about the
*  computer science tract as well is that I think that it's really good practice for thinking at
*  the algorithmic level, let's say, between the higher computational level and the lower
*  implementation level. And I, I feel like that's been a value. It's maybe ushered in this new sort
*  of approach that has been sweeping through the neuroscience AI world. Yeah, I mean, that's where
*  I spent a lot of my time. That's really where I lived intellectually throughout most of my,
*  you know, academic research life. Well, that's why I'm reading your stuff. And I'm thinking,
*  oh, it's so cool. It's because I was more on the mechanism implementation more so, although I deal
*  with the modeling and all that stuff as well. Yeah, I mean, it really forces you to wrestle
*  with the trade offs that at each of those levels and, you know, on the other side of that coin to
*  really value what, you know, each of each of those sort of, you know, I have a friend who is
*  now also post-doctor research scientist or something working with him. And he's a, he's a
*  Mar denialist that you just, you know, I think mostly just to piss me off. But just for clarity,
*  we're speaking about David Mar and Tomaso Poggio's levels of analysis where you have different ways
*  of approach, different levels of understanding. And from the implementation, the meat of the brain
*  figuring out how the neurons work through the algorithmic level where you propose the steps
*  that are necessary to then the computational level, which is the actual goal of the task,
*  let's say, but that's a very poorly. I mean, that's the gist of it. Like, I think I find that such a
*  useful, if albeit imperfect and, and coarse way of framing a lot of problems in neuroscience,
*  because you are inherently up against a system that is, you know, we are interested in the more
*  high level abstract components of the whatever the implementation level is, the output is of interest.
*  And really the computational goal informs the, you know, how we are going to probe the system
*  for possible mechanisms that could be performing, you know, whatever algorithmic steps are necessary
*  to complete that goal. And no, it's not, it's not a hard truth that, you know, these levels of analysis
*  exist or should be adhered to rigidly or anything. It's a continuum, right? Like there are ways that
*  you could cast the same question at any different point, you know, along that continuum. But I do
*  think it's a useful construct for framing questions very precisely and setting out scientific goals
*  for yourself, whether it's in the theoretical modeling space or empirically having those
*  different levels in the back of your mind have always been helpful in clarifying what I'm
*  looking for. Yeah, I agree. And you were talking about, you know, are we even asking the right
*  questions? I had that just before even before graduate school as a tech as a technician in a
*  lab, and we were learning about plasticity. And I actually asked in the class, which I was, you know,
*  wasn't officially in the class, I asked, I don't know the question, but I, I suggested that we were
*  asking the wrong questions. And, and the professor who was my boss, actually, he was like, what do you
*  think the right questions are? I don't know, man. But one of the things that I love too about,
*  so I really appreciate approaching it from these different levels. And one of the things I love
*  thinking about is that all of these things that are becoming really popular right now and
*  reinforcement learning and the way to think about them, they're probably all wrong. And,
*  and, and, but they're so useful. And it's just another, another step in the learning.
*  I mean, that's the, that's the adage, right? You learn is wrong. And that's just something
*  you should accept. But some are useful, you should strive for that instead. Like if you,
*  if you are setting out to, to construct or develop the right model that is that is somehow capital T
*  true, you will become a zealot and you will, you know, martyr yourself for the cause and it will
*  be to the detriment of, you know, the scientific literature that you're contributing to if you're
*  just hell bent on proving the veracity of your likely pigeonholed idea. But if you set out to
*  build useful models, usually what I find is that engenders a kind of mentality where people set out
*  to, you know, they publish on a model and then they, as fast as they can turn around a publication
*  to show how it was wrong and how they change it. Right. And that is useful. I find that really
*  useful. It's very useful. And you have to publish. So you can't just not publish it. That's right.
*  Yeah. How do you, how does one escape or prevent academic burnout? This is something I faced and
*  it contributed to my exit. Yeah, that's a tough one. I think you, you know, in order to really
*  successfully avoid getting burned out in academia, you are going to face a lot of
*  friction because in order to do that, to be like sane and have like a reasonable work-life balance,
*  you have to buck some of the expectations that the institution holds of you. And, you know,
*  you could spread yourself way too thin, just living up to the bare minimum expectations. And
*  so you have to learn how to say no. You have to set out clear expectations yourself for what you're
*  willing to do, when you're willing to do it, what kind of work schedule you feel comfortable
*  having. I think there's a lot of uncomfortable conversations you will likely need to have with
*  that are worth it. Yeah, that are absolutely worth it because, you know, like that could be the
*  difference between you soldiering on and staying in a job that is a great job and is something
*  that a lot of people love to do, but sort of reach that point where they, they, you know,
*  sort of graduate out of academia where there's just no room for them anymore. And it's challenging
*  not to get burned out. There's actually a whole suite. I think there's maybe five or six books
*  I have on a list now that I wish I had read as a kid, you know, although they probably wouldn't
*  have sunk in, but before going to graduate school, before getting into research that, that are,
*  like one of the books is called Essentialism. And one of the tenets is to do like what's essential.
*  And part of that is setting boundaries and saying no and being steadfast about it. And if I had
*  known this sort of stuff that helps with your own, A, productivity, B, just knowing what to focus on,
*  when, what's important, that sort of stuff is that, that stuff is what I feel like would have been a
*  true game changer for me going in. Absolutely. And like you mentioned productivity, like I think,
*  you know, a lot of people get wrapped up in this, I don't know, they sort of get blinders on and
*  they think, okay, I'm just going to stay here and tell this works. I can't tell you how many times
*  I literally spent the night in the lab, just like, I don't know, I mean, hounding on this code,
*  like just twisting its arm every which way. And most times I would, you know, fail. I would go
*  home in the morning, I would sleep, I would wake up at some ungodly, you know, afternoon hour,
*  I would go back to the problem and I would get it to work in an hour. Oh, I know. And I just,
*  had I just gone home at five. Had you just known how the brain works before? That's right. That's
*  how learning works, you know? That's right. It's so interesting. If I could have just taken a page out of my own book.
*  Yeah. So yeah, it's but it's I think it's a big problem too. And these are things that I learned
*  by the time I left academia is when I felt like, oh, okay, now I could start academia and be okay.
*  Yeah. Yeah. No, I think, you know, maybe this is this is out of left field. But for most of the
*  students that I mentored or helped to mentor, my advice to them was take a year at least like take
*  a year and really figure out if if this is one necessary for what you want to do. And if it is
*  like, you know, be selective, like figure out where you want to go find a program that you feel like
*  you fit into. I really took a lot of that stuff for granted. I was just like, if I get into grad
*  school, I'll be super lucky. And if I don't, then I'll just go playing guitar somewhere. Like I
*  don't know. Like, I just I really didn't pay attention to a lot of what I now see is the
*  relevant dimensions of a program or a lab that was going to be helpful in getting me to where
*  I wanted to go. And, you know, I ended up working with people who I, you know, I respect and I
*  learned an immeasurable amount from. But, you know, when I was going into my PhD,
*  I really had no idea what I was doing. I didn't really know what I wanted to do. I had no idea
*  what I was I was in for once I got there. And anything somebody told me, I was just like, well,
*  I guess I better do that because you're a low person on the totem pole. Like you have no idea
*  you are suffering from what is just the worst case of imposter syndrome. Like, and oh, yeah,
*  you just think you're lucky to be there. So you better, you know, like save face. And, you know,
*  for another week until you're found out. So that's right. That's right. Yeah, I would advise any,
*  you know, new or aspiring PhD neuroscientist to know that they're an adult and they can say no,
*  it's you know, that you are not this isn't like indentured servitude or it shouldn't be. And so
*  I think if you if you push back and you, you know, hold your ground, most people
*  might be uncomfortable with it, but they will respect it ultimately, and you're better off for
*  it. So, you know, on the other hand, I've had people write in and say that they need the sort
*  of heavy handed, they need to please their advisor. And that's something that they thrive on, which
*  that's not me. So I can't really speak to that. But, but some and I've seen but I know that type
*  of Yeah, of person. Yeah. Well, I mean, I think, you know, I have, I've used that as a reward
*  signal before, you know, I find value in being valued. And so I, I can, I can sympathize with
*  that perspective. Sure. But I think, you know, in academia, it can become a an unhealthy learning
*  signal. I mean, it can really, I've seen people just destroyed one day and on cloud nine, the next
*  because of two different conversations they had with their advisor back to back. And it was like,
*  if you're living and dying on the opinion of somebody who's, you know, this volatile, like you,
*  you really need to step back and get some perspective because it's it's just not a healthy,
*  especially for the, you know, the longevity of a PhD program. That's that's an untenable
*  situation. Just emotionally. Yeah, don't don't keep a noose around the office.
*  What do you what do you think about the idea of and I'm sorry, I know I could just talk about
*  this all day. So I'm sorry. I couldn't do that. Okay. What do you think the idea of enforcing
*  something like a regular sabbatical type get out, not get away, but something where because,
*  okay, so in your graduate, I'm thinking of graduate school and beyond, but you're so focused and you
*  get so narrowly focused on your project that one of the most beneficial things is to step outside
*  and gain perspective from a broader perspective. And people pay lip service to that in graduate
*  school, especially with all the the latest thing is collaboration interdisciplinary. Yeah. Which
*  sometimes is true. And sometimes it's not. But to enforce just to have to be forced out of your
*  bubble and then take a damn week somewhere else. Yeah, I don't know. Oh, no, I think that's super
*  valuable. And I think going further than that, there's this tendency in academic research that
*  I have found not to be present in, you know, in my work, intrepid is like, in in academia, you,
*  whether it's a model, a data set, you know, whatever your research, you know, project is,
*  there's this tendency to just, just keep cranking on it until it's, you know, you get a significant
*  result or you get a fit that is going to satisfy, you know, your randomly selected reviewers, like,
*  and really, when it just requires what the responsible thing to do is to just
*  bail. Yeah. And if there was, you know, if there were more forums for no results, you could just
*  push it. That's right. Right. Push it to, you know, some pre print server or whatever, which I think
*  is more common now, which I think is another thing that's Yeah, and I just, you should always
*  publish on a pre print server, like whether or not it's the final thing, you should do that.
*  You should publish your code in all but some, you know, exception cases, you should publish the data,
*  like, and then, you know, not just publish those things, but you should fully document them. And
*  yes, I have, you know, we're all guilty, repeated offender of not having documented my code well
*  enough. But I, you know, I go through efforts to make it, you know, easy to download install,
*  to include tutorials with a lot of the GitHub repos that are associated with my papers. But
*  anyway, my point is that you should pivot. I apologize to use such a tired ass.
*  It's almost like bringing it bring you back from the dead, actually. I haven't heard it in a while.
*  Yeah. Okay. Well, yeah, well, give pivot a reboot. But yeah, it's just it's time to move on. But,
*  you know, people will spend years like years and years and years revamping an analysis or a story,
*  the narrative needs to be right. It's like, No, what needs to happen is this data needs to be
*  available, or the results need to be, you know, public. So somebody can know whether or not to
*  run the same study, and you should move on. Like, it's just, yeah, sometimes a week of fresh air
*  would would do the project good. I think in many cases, it's just this persistent hammering away
*  at the same nail that had like broke four years ago, and you should just get a new nail and hammer
*  on that for a while. Yeah. What's the what's the name for when you you're beating your head against
*  the wall? And you and then you go home in the morning and you sleep and then you wake up and
*  you come back and you solve it immediately and it's some stupid error? Like, is there a name for that?
*  Graduate school. Oh, there you go. Yeah, sorry. Hey, Kyle, what are you doing these days? What's
*  your job? So I work in machine learning research lab within a software company. And most of our
*  goals center around understanding how information is represented and flows through social media
*  networks. And so a lot of natural language processing, information retrieval, representation
*  learning plays a big part. But yeah, it's it's new and fun. What what in your neuroscience
*  background have you brought with you that is that is helpful? And what maybe isn't helpful? Do you
*  have a sense of that yet? I mean, you're coding all day now, right? Yeah, yeah, yeah, quite a bit,
*  which is not that different from grad school and post, you know, from it's like, there are some
*  differences. There's also like some unique things, I think about our particular lab that aren't
*  necessarily present in all industry roles. Like I think, because the the team that I work on is
*  very much in the experimental research and development side of things, we're not sort of
*  patching updates and like, you know, building building tools that go immediately into some
*  product that goes to market, but we're sort of exploring new tools and abilities and algorithms
*  that could potentially fit into some of our like suite of products or would be useful
*  for some customers. And so a lot of the day to day stuff isn't so different from an academic setting.
*  I think there's a clearer line that exists between there's an easier work life distinction,
*  where I go to work at a certain time and I come home and I'm done working and done working. Yeah,
*  yeah, which is this weird thing that that happens when you leave work, you just use you are done.
*  And that's nice. But yeah, so things that directly carried over. So I mentioned
*  representation learning, which is sort of in the context of language and text data,
*  how do you find a useful representation for let's say, a word or collection of words, like a tweet
*  or something that allows you to perform computations on that representation, computations that
*  preserve some of the meaning or its relation to other words or concepts or where it fits in the
*  larger space of a language. So you're doing like natural language processing, a lot of what you're
*  doing is that? Yeah, almost exclusively. Are you using deep networks to do that? Or are you using
*  lots of different techniques? Some I mean, we've you know, there's this, I don't know why this is
*  a trend, but like all of the state of the art, most of the state of the art natural language
*  models are named after Sesame Street characters. So Bert and Ernie and Elmo and I didn't realize
*  that I didn't put together. Yeah, yeah. So we I mean, we have experimented with some of those
*  models and, you know, have have played around with them. That is, in so far that they are neural
*  networks related to, you know, computational neuroscience. Another, I guess, maybe less obvious
*  neuraly or biologically plausible suite of models is what are called sparse, sparse distributed
*  representations. Yeah. I think you had Francisco Weber on. I also had Jeff Hawkins who like,
*  yeah, that's right. Francisco's business is based on the Numenta technology that Jeff Hawkins develops.
*  Yeah, the the HTM. Man, you know, some people that know my show. Geez, thanks. Yeah, yeah. Hey,
*  I was I was a big fan. So yeah, we have found those those kinds of models to be particularly
*  useful. And one of the things you have to wrestle with in machine learning industry role is you are
*  in a space where, you know, your competition is Google. And most companies don't have the
*  compute resources, time, like, you know, engineering staff to actually compete in developing like the
*  next, you know, BERT, right? It's just not a sort of plausible or sort of useful goal to set out to
*  to achieve as a smaller company. So like, one of the things we've really focused on is like,
*  how can we how can we build efficient or interpretable models that achieve in many cases,
*  roughly equivalent prediction power? They're they're roughly as precise, maybe not always.
*  But sometimes, you know, these these really sophisticated and computationally expensive
*  neural network models utterly fail on on somewhat simple tasks. They are undeniably impressive in
*  many ways. But if your goal is to classify the sentiment of a tweet, you can achieve that in
*  much more efficient ways. So we sparse sparse coding models have proven to be really, really
*  useful in some of these NLP tasks that and yeah, it was useful knowing something about how sparse
*  coding is carried out in neural systems. And especially in a space like the the space of
*  possibilities is vast in language. I mean, it is in many cognitive domains. But I think that the
*  sparse distributed representation representations are specifically, particularly useful in that realm.
*  Yeah, I mean, if you think about the the challenge of understanding language, right, if you if you
*  try to think about what I don't like to think about it, it's too much. It's too much like it is. So
*  so I didn't do any language related research before. And this this has been such a sort of
*  eye opening, you know, experience like getting spun up on NLP. And I work with several computational
*  linguistic researchers who are, you know, it's so I'm learning a ton. But yeah, this, you know,
*  think about the just a single word, right, the the orthographic representation of let's say,
*  you know, the word race, right, or bank is another common example, a ton of different meanings that,
*  you know, totally depend on the words adjacent to, you know, it in a sentence. So how do you get
*  a machine to respect the different meanings of the word race or bank based on the context?
*  Sparse coding is, I think, you know, Francisco Weber, and the semantic folding or Yeah,
*  theory also, you know, exploits this property of sparse coding, but you can basically, you know,
*  build up contextually reinforced concepts for encoding a particular word, right. So you basically
*  pay attention to what things are activated on the left and the right of this instance of the word
*  race. And that can that can really pull out one of those meanings that is, you know, very distinct
*  from the others. Fascinating stuff. Isn't it fun to also it's probably just fun to be working on
*  something new and different. It is. It's so refreshing. So I like I get to do a ton of the
*  same things that, you know, really contributed to my loving, you know, my old job. Yeah, yeah.
*  And so that's been it. I really feel like I re entered that frame of mind that I had when I
*  started my PhD program. Young bright eyed. Yeah, you guys don't know this, but Kyle's wearing just
*  this super dark makeup now. He's all goth. Yeah. I also, you know, transition to, you know, I guess
*  reverted back further into my scene emo stage, playing metal. Yeah. Are you playing these days?
*  Yeah. Oh, yeah. I never stopped playing, I guess. Right. I did. I did not play. I stopped playing
*  guitar. I probably hadn't really played guitar in like a three year stretch. That's too long.
*  It's way too long. But yeah, I am I am playing a lot now. Cool. Metal, though. Metal. No, not always.
*  I mean, I do like classical guitar and some jazz, some fusion. Oh, all right. Get pretty,
*  pretty nerdy elevator music going on. I have a goal to do it 30 minutes every day and I never,
*  never even pick it up. So, you know, there's always hope tomorrow. There's always hope tomorrow. It's
*  on my schedule. So we, you know, I don't want to take more of your time here. Let me, let me just
*  ask you some, some and you can answer these quickly or or go into more depth and then I'll
*  let you go because I know you got to do some more fun coding tonight, probably. Yeah, by the way,
*  it's is it 1130 now, your time? 1130. Yeah. Okay. This is super late for me. It's 930 for me.
*  What's one trait? What's one trait of our intelligence or cognition that you think is
*  going to be really hard to build into AI? Yeah. So, and I think there's even been, you know,
*  maybe in the past month, some, some actual progress on this particular problem. But the,
*  the problem of stringing together, forming some continuity between domains of narrow intelligence,
*  you know, when it comes to any sort of concept or idea or experience, we can represent that thing
*  with, you know, any number of sensory and perceptual modalities. We can, we can represent
*  it by recalling memories. We can understand how the current context should influence our
*  interpretation of that thing. And so just that, that sort of confluence of different angles with
*  which to represent or interpret or process, you know, one thing, you know, we can do each of those
*  things in isolation right now, right with, with sort of human level expertise or precision
*  or robustness, but really to string together like memory perception, like all the different
*  forms of perception, judgment, reason, all of those things, to get those to sort of work in concert
*  seems like a pretty high bar. You know, I think the problem is, is termed catastrophic for getting
*  in a neural network, you train it to do one thing, but if you need it to do another task,
*  retraining it on the new task causes some, you know, performance degradation in the first task
*  it learned. Now there's, there's solutions for this that, you know, I think there's some meta
*  reinforcement learning agents that sort of learn to hold some of the, the pathways, the, the, the
*  weights constant while learning the new task. And that preserves relevant learning that contributed
*  to performance on the first one, but the ceiling on how many tasks you can, you can cram into a
*  neural network seems to be pretty low at this, at this stage. Yeah. You wouldn't want just one
*  neural network doing it all anyway. Like you said, you want to piece things together. Yeah. Yeah. I
*  think that's a reasonable solution. Like what, you know, one, one way is just sort of cashing away
*  the sort of the weight regime that a trained neural network, you know, finished a task on. And then
*  when it re-encounters something that seems similar to that, you know, re-initializing the
*  network to some somewhere in the neighborhood of that, that trained regime. But yeah, I think this
*  is, this is a sort of research avenue that's, that's getting really interesting. There's
*  what is it? Progressive networks or? Yeah, this was, this was Raya Hadsall's work. I just, so,
*  oh, no way. Yeah. She worked on these progressive networks, but I mean, that is not brain like at
*  all because you're actually adding in new networks, you know, but it's a solution. So, yeah. So this
*  is on my reading list, but I haven't tackled it yet. Oh yeah. Well, or you could just listen to the
*  episode before this. Yeah. I'm stoked. That's fantastic. Anyway. So, you know, like, you know
*  what I didn't mention and I just wanted to get in it. So are you working on Jupiter notebooks these
*  days? What do you do with Jupiter? So in procrastinating on my dissertation, I was
*  writing this package for controlling the interface for Jupiter themes, for, for, for Jupiter notebooks.
*  Yeah. I called it Jupiter themes and much to the chagrin of, of one of my fellow, like, grad
*  students and in the lab, it, somebody posted it on Reddit and then that Reddit post found its way
*  onto the front page of Hacker News and the repo just like really exploded. Like he had, he, he
*  had woken up to this on the front page of Hacker News and, and came into the lab and told me,
*  and then I checked and like, I don't know, had gained several thousand stars on GitHub. But
*  anyway, it, I ended up supporting it for a while. Currently, it's got somewhere upwards of like a
*  hundred un, unresponded to bug reports. So it's, it's, it's floundered a little bit, but I, I am
*  sort of off and on working on, uh, uh, like a sister project for Jupiter lab. So, you know,
*  to control the sort of interface and style of, of the, the new version, the sort of, you know,
*  younger, fresher, cooler, uh, Jupiter interface. This is, this drew, grew out of your passion for
*  Python, I suppose. It, yeah, it did. I also am, I'm a little bit particular about my syntax
*  highlighting and, and interface themes. I just, I don't know the, the, the, the out of the box Jupiter
*  notebook theme is just absolutely hideous. Like they did so many things that are amazing, but
*  good God, it's like, I mean, your eyes would start bleeding after like a full day of coding on that
*  thing. Yeah. That's why I don't do full days. Yeah. Well, that's, that's another solution.
*  Okay. Last question here, Kyle. So, um, you entered in, you were, you were saying that the,
*  you know, philosophy of mind got you interested in neuroscience. Um, I, you know, of course,
*  I think the idea of consciousness and figuring out how it works and stuff, I think that that gets a
*  lot of people actually interested in neuroscience. Yeah. You lose that really quickly. You do. Yeah.
*  It's, it's beaten out of you. It's beaten out of you. Yeah. Well, there's a, there's a whole little
*  problem of facts that get in the way of, uh, and not current knowledge, but do you think that, um,
*  do you think there's any hope for understanding consciousness in general? Let's just pretend like
*  we both know what I'm mean when I say consciousness. Um, you know, and, and if so, is AI going to help
*  us get there just understanding what it is, or is it going to come from neuroscience or how,
*  where is it going to come from? I don't know. I, I think my views on this is that it's, it's
*  certainly not necessary for, you know, I think we could, we could plausibly build an AGI,
*  an artificial general intelligence that was truly an AGI and, and had no, no inner experience. Yeah.
*  But, you know, I, I don't know, like, you know, it's, it's very possible as well that it's just
*  sort of this epiphenomenal thing that just comes with the territory of something that is capable
*  of, of general intelligence. I, I think the question or the jury is still out on that,
*  but I, I don't rule it out by any means. I think, and I do think it should be within the sort of
*  fair game of, of questions to ask from a scientific perspective. And I think people have
*  tried. There's the, it's an information theory based theory of, of consciousness. It's,
*  it's a formal theory. Integrated information theory. Yes, that's the one. What's the guy's name?
*  Tononi, Giuliano. That's right. So people have, have, have taken a stab at formalizing
*  consciousness. I don't know if anything's really fit the bill yet, but I think it, it shouldn't be
*  as taboo as it currently is in, in science. And maybe it is more of a philosopher's game.
*  You can certainly approach it from a formal computational angle in philosophy. But yeah,
*  I mean, I think from the, from the time of Benjamin Labette had those really fascinating
*  experiments that I just totally captured my imagination as an undergrad. There is no free will.
*  There is no free will. Yeah. Think of that. That is crazy. It's crazy. It was just super crazy. Yeah.
*  Anyway, I think, I think there's, there's certainly room in the enterprise of neuroscience for
*  exploring deep questions like that. He is Kyle Dunovan. You can find him on Twitter at Dunovan
*  K. And of course I'll link to all this stuff in the show notes. Kyle, man, I, you know, I could
*  go twice as long, but it's late and I, I'm happy for you that you are in a happy place and I really
*  enjoy talking with you. I appreciate it, man. Oh, thanks for having me on. It was a pleasure.
*  Brain Inspired is a production of me and you. You can support the show through Patreon for a
*  microscopic two or $4 per month. Go to braininspired.co and find the red Patreon button there.
*  Your contribution will help sustain and improve the show and prohibit any annoying
*  advertisements like you hear on other shows. To get in touch with me, email paul at braininspired.co.
*  The music you hear is by The New Year. Find them at thenewyear.net. Thanks for your support. See you next time.
