---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 4478s
Video Keywords: ['Science', 'Technology', 'Education']
Video Views: 9530
Video Rating: None
---

# BI 078 David and John Krakauer: Part 2
**Brain Inspired:** [July 17, 2020](https://www.youtube.com/watch?v=4INaiYXOpZE)
*  Is there something special about brain-mind-like phenomena that are completely different from the history of scientific logical discovery, such that they'll always be outside of our reach? And I can't understand where that belief would come from.
*  I don't think they're out of our reach at all. I'm just saying that the coarse-grained objects we use to describe mind phenomena will not feel the same way that people who like to look at eye movements and stretch reflex and even the cerebellum, where they feel like they can couch their understanding of their behavioral output in terms of their circuitry. And all I'm saying is if that's what you want, you're not going to get it.
*  There are on the table here three positions, at least. One is, let's call it unfairly, the sort of microscopic reductionist who says it has to be as low as you can go.
*  Which is what John thinks I am.
*  Which I don't think he thinks I am. That person in the end just has the total physics envy and wants to do quantum mechanics.
*  This is Brain Inspired.
*  Welcome, everyone, to the second part of my conversation with David and John Krakauer. I'm Paul Middlebrooks. This second part picks up right where we left off in the first part, and I highly recommend you listen to that first part to best absorb this second part.
*  In this episode, we talk more specifically about brains and minds, how complexity thinking can help, what it might look like to attain a satisfying understanding of various mental processes, and how or whether that understanding will include any account of brain processes.
*  You'll hear my own inability to communicate what would serve as a satisfying account of the relation between brain and mind.
*  But thinking clearly about these things is its own goal. For me, that's maybe the main goal. And I'm going to keep pushing forward until hopefully I'll get there.
*  Speaking with David and John is a wonderful exercise toward that goal. And the mode of thinking they execute makes it feel like we're headed in the right direction. Makes me optimistic. I'll get my own thinking to a satisfying place. We'll all get there, won't we? Enjoy.
*  You know, it's interesting, I don't know, Paul, if you've read the new history of neuroscience, Matthew Cobb's book, The Idea of the Brain.
*  No, but isn't it just a list of metaphors? I've not read it.
*  Yeah, but it's actually, well, no, I think actually, it's a scaffold for thinking. And it's very good. I love the history part and the early present.
*  I think once it gets into current neuroscience and prediction of the future, it gets more impoverished. But I don't know whether that's Matthew Cobb or whether the field itself is sort of asymptomatic.
*  But it is a good book. I really do recommend it. It's got lots of delicious, rich stuff in it. And he's done a good job. It's not easy to synthesize all that material. But I tell you what's fascinating about it is that he has a section at the end of the book where he talks about the future.
*  And it's very interesting that he begins by talking about emergence, but then drops it like a bad smell, right? It's like, well, I think he says something like emergence is that unsatisfactory explanation before we get to the real explanation, right?
*  And then he moves on to where he feels like the real progress we made is let's get back down to the circuits and the neurons themselves. Let's study cognition in a fly, where we have the sort of Sheratonian connectivity map.
*  And then we'll do some sort of extrapolation to cognition in humans. In other words, you see this tension in the field between not really wanting to talk about coarse graining and psychological terms and derived measures and saying, surely we can avoid that awful fate for our field.
*  By going into a fly or a worm, where we can have the same level of connectivity detail and intuition as we did for the stretch reflex. But now we can apply that understanding to something that we call cognition.
*  And then somehow extrapolate from that higher up the neural axis. In other words, you see that there's this tension that just won't go away. And if I David, it would be silly to do Navy of Stokes worrying about the details.
*  But mind is a historically fundamentally mysterious thing because it's there. OK, so let me see if I can articulate my own internal struggle with this sort of mapping and know what I want.
*  I want some sort of it can be coarse level, but I just want a way to think about the mapping between them. I don't need it doesn't need to come from the circuit level, but it does need to connect them.
*  And one of the things I was going to ask you both about is whether complexity holds promise for a connecting between these levels or if it if complexity like you just mentioned is is assigned the liberation of levels and for us to somehow be happy with understanding things at different levels without the connection.
*  No, I think both. No, I know. I don't think we should be happy. And John and I talk about this a lot. I think that and that gets to these two kinds of emergence camps. There's one group probably I'm in that's very interested in how you connect them.
*  And there's a camp that John might be in which says what's the best one to use in any given level? And I think that's both necessary. So I mean, for us, you know.
*  You know, the gold standard was the derivation of, you know, the ideal gas laws in thermodynamics from statistical mechanics. So that once you've got that equation, you don't have to worry about the individual particles because it has that right property of sufficiency.
*  But you didn't know why. And it was it was useful to know why. And some of us want to know about that, but the origin of levels, that's sort of what I work on. And I think that they're both are necessary. So I wouldn't forfeit one for the other.
*  I hope we do get into brain mind because I have my own totally quirky ideas that I'd like to air. And and I've never understood. I don't know if that's appropriate, but John wants to jump in. But I would like to say a couple of things about that.
*  Let's just go. I mean, we're going on our own own own course. There's there's no specific path.
*  OK, so I do want to talk about this because I've listening to people. I'm always amazed that they don't do the empirical thing, which is to look for prequels or precedents. And I want to mention too, and I think I don't have an answer at all, but I just want to point out an insight.
*  You mean historical.
*  Yes, or parallel in other fields, things that look like it. OK, OK. And and I sort of want to be Persian and argue for a triadic perspective.
*  And I and it has come to the rescue of two other areas which suffered from the same problem. The first one, the one I know best because I work on the evolution of intelligence is evolution.
*  And it was how do you relate physical matter and the structure physical matter we'd call an adaptation to fitness. And for the longest time.
*  God was invoked. In other words, it was impossible. I mean, there's no way to explain the structure of matter in its relation to function other than invoking an omniscient, omnipotent being.
*  OK, and Darwin came to the rescue by introducing a third principle, which was natural selection and natural selection mediated the interaction between physical matter and fitness or replication or success.
*  OK. Hardware and software hardware, physical matter, right, does functional things in the world.
*  It adds numbers together, allows you to type, allows us to have this conversation online and what mediates them is the algorithm.
*  Algorithms configure or the operating system configure physical matter to allow them to be functional.
*  Functional. Now, David Ma sort of was kind of getting there when he recognized the three levels, right, the sort of physical level, the functional level and the algorithmic level.
*  But he didn't talk about it in the Percy in terms of threeness as the resolving level. And you'll see that they have two things in common, right.
*  So their third party means of configuring the matter to achieve the function, right.
*  So natural selection is not present in the organism, it's present in the environment.
*  The programmer is not present in the machine, but in the environment.
*  And so I just want to say, I don't think mind emerges from brain mind.
*  And that is the thing that I've always found missing in the mind brain is the third part, which is I think it's pointless to talk about mind without talking about environment in the same way that in evolution you couldn't talk about adaptation and fitness without talking about selection.
*  And I find that quite promising as an avenue. I don't know how it would play out.
*  Is this like a Wittgenstein Ian?
*  You must have someone to speak to else you can't think somewhat.
*  Actually, it's interesting as a private language issue.
*  It is somewhat related. His was much more along the lines of the scandal of induction.
*  Right. I don't know what I'm pointing at, but I do think it's social, but not social in the sense of human to human, but the ecological sense of social to environment.
*  And I don't know what John thinks about that.
*  You think about that, but that's the bit that I've seen missing from a lot of the philosophy of mind.
*  It's such a huge area, right?
*  You know, cultural production of mind, embodiment, environment.
*  I definitely agree that the computation might be distributed far more than you think.
*  But I do feel like we have to worry about the brain fundamentally when it comes to the most impressive cognitive feats that we see.
*  For example, prospective memory that has been where you can make a cup of coffee with interruptions.
*  You know where you are in the sequence.
*  You know the sequence you have to go through to get an envelope and a stamp and then put the letter in the envelope and then you put the stamp on the envelope and then you walk from the post office and you put it in the post box.
*  I know this sounds very old fashioned, but these abilities are very much associated with the prefrontal cortex.
*  You know, Steve Wise and Richie Parsingham have spoken about the fact that the agranula prefrontal cortex only exists in primates.
*  Right. And they talk about one shot learning and prospective memory and all the kinds of cognitive operations and the ability to model the world in a very elaborate way that you could see in primates.
*  So in other words, even if it's true that there are all these, I mean Darwin in the Matthew Cobb book, Matthew Cobb says about Darwin that he wasn't really interested in how the brain and the mind connected.
*  He actually admitted that, but he wanted to know how you could have gotten there gradually right through evolution.
*  Right. Darwin actually deliberately explicitly tabled how you got mind from brain.
*  But he just said you have to get it from there because the evolution has to operate on physical stuff.
*  Right. So but so in other words, I would say all this embodiment stuff and all this.
*  It's different.
*  I'm just saying it doesn't preclude the fact that if we're going to really understand things like cognition as we define it, we're going to have to understand the prefrontal cortex.
*  Well, let me just it's a very interesting example that just to draw your mole example to your brain example.
*  So for you, it was sufficient.
*  You didn't want to talk about the genetics or the musculature of the mole limb.
*  You just wanted to talk about selection pressures, whereas developmental geneticists would say to you, no, you have to talk about the development of those limbs and the conserved structures in these, you know, regulatory kernels.
*  And you're doing the same for the brain.
*  And I think you're right that both are required.
*  Just to be clear, just for the analogy, I would say that the prefrontal cortex, what it does, depending on how you coarse grain it, is like the claws, the fur and the snout on the mole.
*  Right.
*  Right. That if and there are theories that have been given as to why one shot learning and other such things had to be done on sparse savannahs where you just wouldn't have a chance to learn slowly.
*  Associative learning would have just you die.
*  Right. So you have to come up with a way to quickly learn and flexibly make choices.
*  And so I just think in the end, we're going to have to describe that behavior, have a computational theory of that behavior, and then just get confirmation, I think, through correlation with properties of the prefrontal cortex.
*  We're never going to look at all those millions of connections in prefrontal cortex and go, ah, one shot learning, prospective memory.
*  You're just not going to derive it anywhere more than from a deep neural net.
*  You're going to work out what it's doing.
*  But I think it will have some confirmatory role about your algorithmic explanation for how you do those cognitive operations.
*  No, I think I agree with all of that.
*  I'm just saying that, again, just by analogy, that the dualities of matter and fitness and hardware and software, which actually have the same qualities, how does software work exactly?
*  A resolve by introducing the third element, the environment.
*  And it's hard for me to imagine a concept of mind without using and it doesn't it's not about so much embodiment or but without using environmental social concepts.
*  That's the sense in which I'm saying that you need to introduce this third element to bridge the two.
*  So it's not environment as constraint and as an organizing principle.
*  No, it's simply that it's actually the selection principle.
*  I mean, it's the way in which you mind in some sense programs brain, right?
*  It's sort of you.
*  There has to be something that mediates causally that interaction.
*  That just seems to me very similar to the Lily crap and curd in view that we just want to know what was operating on the network to get it to its final consolidated performance.
*  It doesn't I don't see how what you're saying is going to get us to say, I understand how perspective memory works.
*  I understand how these ability to task switch work.
*  No, it doesn't. It doesn't help with that at all.
*  I agree with that. It's a different point.
*  It's just I don't think the word how does mind emerge from brain is complete.
*  That's all I'm saying. It's just not a meaningful sentence to me without the third element that you're right.
*  Do you think that you would have detractors of that view?
*  It's almost hot to logical, right? Because you have to have environment.
*  Well, it's odd that people say it so often, isn't it?
*  I agree. I mean, it's hard to imagine that there would be that people use it all the time.
*  How does mind emerge from brain?
*  And all I'm saying is I don't find that a meaningful statement.
*  Well, they do.
*  But they do. I mean, I think that David, I think I don't I mean, they want there to be just like, how do you get stretch, stretch reflex behavior from a circuit?
*  In other words, you see a neurologist bang on someone's tendon and they are moves or the knee moves and they want to go.
*  How did that movement arise from spinal tissue?
*  And people will then say, well, there are these neurons which connect.
*  And I think what they mean is that they want.
*  How does the organization of parts through their interaction lead to a behavior?
*  And in this case, they want the parts to be neurons and their configuration to be their connectivity into a circuit.
*  And they want that configuration of connectivity through the parts to lead to the behavior.
*  And they want to have an explanation like that all the way up to what the prefrontal cortex might do.
*  I've offered a compromise by saying that if you think about it as trajectory through state spaces derived from millions of neurons through some sort of dimensionality reduction that you can visualize like a Feynman diagram,
*  that you can have a functional flavored explanation that uses words and uses a neural derived object.
*  And that is about as good as it's ever going to get.
*  If you want to do it in terms of connectivity and you could argue that the neo-Sherringtonian project to people like Olaf Spawns is really to use connectivity metrics between macroscopic areas.
*  The way that Sherrington talked about neurons connecting in a reflex arc is just not going to work in my view.
*  And again, so everything you just said, I agree with.
*  I think I'm addressing a slightly different question.
*  So no one says how does software emerge from hardware?
*  No one says that.
*  But if you if you had hardware and you shocked a particular part of it and the software told you that it just had an out of body experience or exactly.
*  You know, you talked a part of it and the software made an eye movement and said, I intended to make that eye movement because it experienced an eye movement or a phosphine or something that we consider mind process.
*  Where does the environment?
*  But that's exactly the point, Paul, that you're right.
*  That's exactly what would happen, right?
*  If you perturb the hardware, you perturbed the software.
*  That's exactly right.
*  But we don't use that language that software is emergent from hardware because we know how we make software and we know how we make hardware and we know how programming works.
*  And that's I guess what I'm saying that that language doesn't feel correct because there's a missing third element.
*  And the question I guess I'm asking is that the causal efficacy of the environment in mediating mind brain, would it lead to a similar change of language?
*  It wouldn't feel right to say, does it emerge from mechanism, even though John's narrative just now sounds totally reasonable at this point in time.
*  I mean, I agree with that.
*  But we're also living in the age of the brain computer.
*  This is the most recent metaphor.
*  I don't think it's a metaphor.
*  People have said this to me before.
*  I also disagree with it entirely.
*  I don't think that's the right point.
*  I think that what it's interesting, by the way, I guess, in interest of mine, what computers do that's so interesting, I think, and that's interesting partly because we built them, is that they show how physical matter can give rise to properties like teleology agency and function.
*  And it's the first one of the first significant devices in the history of human beings that has those properties.
*  And so I don't mind if the steam engine was an earlier metaphor for some element of agency.
*  Right.
*  It's just that the computer has it in spades.
*  And so it's a useful one.
*  I don't think calling something a metaphor discredits it because the computer does possess so many of these properties we care about.
*  But you're mapping it on to hardware and software, and I don't know that that is the correct mapping.
*  Sure.
*  But that may be true.
*  A lot of people have said that that's incorrect and so much that they're mixed inextricably in a biological tissue.
*  As they are in the machine, as they are in a computer.
*  Right.
*  But I also get a little annoyed when people conflate computational with computer.
*  Yeah, that's right.
*  In other words, of course, and I agree with Gary Marcus makes a very strong statement something about this, which is cognition is computation over representations.
*  And I just don't know.
*  Now you can be in the camp of extreme embodiment or like Paul Cizek, who's in denial about cognition and just tries to fight it.
*  You know, and all those people who just want to somehow tuck it away and deny it and turn it into sort of some sensory motor affordance.
*  I mean, like I think you had is it Mike Rescola on your show?
*  Yeah, Michael Rescola.
*  Yeah, very smart guy.
*  And I agree with him that any attempt to do away with representation is an utter failure.
*  Right.
*  And so once you accept that you have to represent things and we can have a discussion about what that means, David and I have talked about that a lot.
*  And you just say that you compute over representation, that is, you take symbols and you operate on those symbols and change them.
*  That have semantic content.
*  You know, and yes, numbers are semantic.
*  Numerals are syntactic.
*  Right.
*  And I just don't know how else you can think about it.
*  Right.
*  You operate over representation, then you transform them.
*  OK, it's interesting to point out just to both of you that these terms you're using representations that are transformed.
*  I'm not using that.
*  OK, Josh, come out of logic.
*  Yeah.
*  And which is basically what we're talking about when we talk about computers.
*  Don't get carried away with a particular hardware device that we're typing on.
*  Right.
*  What a computational device, at least in the Turing sense, has to do with, right, is do you have sufficient input?
*  Right.
*  Do you have the appropriate sequence of transformations of physical matter to arrive at an answer that's correct in finite time?
*  And that's true if I'm reaching for an orange, if I'm, you know, there is a much more general concept of what we mean by computation.
*  It shouldn't be confused with particular implement that we happen to be operating on today.
*  And I also think there's something that I struggle with, but I think is fundamental to all this, is there's probably an ontological reason.
*  I mean, the other nice thing about the Matthew Cobb book is he just shows you that very thoughtful people going back to the Greeks and onwards were worried about the mind brain divide.
*  They were never worried about the equivalent divides in their legs or their arms.
*  Right.
*  In other words, there was always a sense that there was something that had to be Lord Adrian versus Kenneth Craig.
*  They had this debate.
*  So there's the sophistication of the discussion of the difference has not increased.
*  I think the only real insight is that algorithms are by definition substrate independent.
*  OK, that's that's what an algorithm is.
*  It's a series of steps that abstract away from how they're physically instantiated and abacus, the calculator, your fingers, right.
*  But notice again, it's interesting that the one concrete tangible example we have of the interface between the logical.
*  Seemingly immaterial and the material is that one.
*  I think John's absolutely right.
*  So when you talk about algorithms, they have precisely that property that we're trying to pursue.
*  It's not that hardware is brain software is mine.
*  Not at all.
*  It's just that they give us a vocabulary and a set of fairly well understood real physical devices that have some of the properties that we're pursuing.
*  And the interesting thing is, is that the more mind like the words you use, the more mind phenomena you care about, Paul,
*  the more substrate independent algorithmic you can sound right.
*  In other words, it's you're not going to write a poem or a story about the stretch reflex and you're not going to necessarily come up with a substrate independent description of the stretch reflex anymore.
*  But the more complex the behavior becomes, the more one can begin to use vocabulary that floats free of the substrate.
*  Right. It's back to what we were talking about before.
*  Why is that? Why is it that you can get more and more free of the actual substrate and more algorithmic, the more cognitive and mind like you become?
*  One answer to that is our cognitive limitations.
*  No, because we actually do quite a good job.
*  And just like William James did, I'm just saying you say that because you'd like to have a neural connectivity story about it.
*  I mean, this this this cognitive limitation thing is tricky.
*  Right. And certainly in relation to this question, you know, are we smart enough to be able to understand what mind is, et cetera?
*  And it's again, I just want to I was thinking in terms of empirical precedent.
*  Right. It's important to point out that the example I gave for functional states of matter was not resolved until the 19th century.
*  OK, that's quite recent.
*  So there's a temporal nature of limit.
*  Right. Einstein's theory of general relativity worked out in 1915.
*  We didn't understand the nature of space time until the early 20th century.
*  And Einstein couldn't have done it without Riemann, which happened in the 1850s.
*  So there is a temporal aspect to this.
*  So that's very important.
*  The question is, is there an absolute right?
*  Is there something special about brain mind like phenomena that are completely different from the history of scientific logical discovery, such that they'll always be outside of our reach?
*  And I can't understand where that belief would come from.
*  I don't think they're out of our reach at all.
*  I'm just saying that the coarse grained objects we use to describe mind phenomena will not be will not feel the same way that people who like to look at eye movements and stretch reflex and even the cerebellum where they feel like they can couch their understanding of their behavioral output in terms of their circuitry.
*  And all I'm saying is if that's what you want, you're not going to get it.
*  Right. That's absolutely right.
*  Yeah, I think that might be right as well.
*  But I wonder if there is a happy medium where going back to and I don't mean to perseverate on this, but you know, just from a very selfish standpoint, I still would like a mapping.
*  It doesn't have to.
*  I don't have to map it onto the circuit, but I want just a way of formulating a question.
*  You know, because of poor.
*  Let me just it's interesting, though.
*  Do you feel that way about the concepts of temperature and heat?
*  Well, I was going to say, you said now that we understand space and time, and I don't know that we understand.
*  I'm yet right.
*  Right. We did.
*  We know we have a better explanation.
*  Yes, but let me just that's absolutely true.
*  I think all of these theories are very approximate and they get better and better.
*  But I just want to get at that point that you make about I guess we have to call this something like satisfiability or something, which is which you want this molecular.
*  And I I'm just curious because I do, too.
*  I'm the person who's interested in mappings.
*  But it is interesting that I want to just ask you, is this a general feeling you have or is it special for mind brain?
*  Because is it important to you that there is a statistical mechanical theory that explains bulk average properties of molecules and their energy that allows you to use concepts like temperature and pressure and heat?
*  Does it matter to you?
*  So sorry, does it matter that I use the coarse grained explanation of what heat is to perform work?
*  Is that the sorry, is that the question?
*  Yeah, I think it's again, the sort of mediating between you and John's position on this, which is that we now know, of course, that there is such a connection.
*  And it's very important that justifies in some sense the higher level theory.
*  But for most people doing work, they're quite happy to deploy the high level theory and telling them there's one errant molecule in a room doesn't do it for them.
*  It doesn't make much difference.
*  And I guess that's what I'm asked.
*  Is it do we feel once that the you know, that renormalization has been done right that we can dispense with the micro?
*  I mean, let me give you an example, Paul.
*  I think, you know, I did a lot of reading on the sort of the philosophy and the history of the action potential.
*  Okay.
*  And it's very interesting that in what's his name, he wrote that history of neurology in the 1950s.
*  Blanky.
*  Shouldn't have had that glass of red wine.
*  But anyway, at one point, he says that the action potential was a huge advance that would help us understand how the brain works.
*  Reduction. Yeah.
*  No, no, no, no, no.
*  But I find this kind of statements fascinating because what they do is they take a very useful horizontal piece of work that locally describes transmission and then makes this huge vertical claim for it.
*  Okay.
*  And what I'm saying is, is I can't decide whether you're saying you'd like the mapping is just because the whole field wants to always have a vertical claim for horizontal work.
*  And, you know, in the history of the action potential, you know, in 1952, when that paper was published, they didn't know about ion channels.
*  They just knew that there was sort of voltage sensitive changes in permeability of the membrane.
*  And we could write out an equation for propagation of the action potential.
*  Now, if you were to still explain to someone how an action potential works, you wouldn't start describing the details of the ion channel subunits.
*  It depends on what level you're explaining.
*  If you just wanted to explain the action potential propagation, I can assure you, you will not write a sentence where you include the ion channel composition.
*  Here's another one.
*  I just wanted to finish this.
*  In other words, it's nice to know that the reason why you have permeability changes is due to the existence of ion channels.
*  It's nice to know that there's something there doing it.
*  But to actually explain how you get the action potential propagating, you don't need to know that detail.
*  So in other words, when you ask your question, you have to ask in two ways.
*  Does that detail simply give you solace?
*  That there's a foundation upon which this abstraction is built?
*  Or does it actually add substantively to the sentence of understanding that you're going to utter when it comes to the action potential?
*  I'm going to say to you, the answer, Paul, is no.
*  Here's an example.
*  That's good.
*  Here's another example.
*  I hate to be in the middle.
*  I'm such an idiot.
*  I love getting piled on by the crack hours.
*  No, you're not because I'm sort of somewhere between you and John on this, which really annoys me.
*  I want to be more extreme than both of you.
*  Natural selection is a good example.
*  So when Darwin formulated the theory, he had this nutty theory of genetics.
*  He had the theory of pangenes.
*  And it was based essentially on a fluid metaphor.
*  It's continuous.
*  It's called blending inheritance.
*  And it didn't in any way, his completely erroneous theory of how inheritance works, by the way, completely erroneous, compromise the integrity of his higher level selection theory.
*  And of course, during the modern synthesis, people like Wright and Holden came along and said, you know, it doesn't work, man.
*  Blending inheritance will not work.
*  It will produce this kind of average quantity in the world.
*  They then reconciled the theory with Mendel's contributions, which are particulate and so on.
*  And now two points to make at the level of organisms.
*  It made absolutely no difference.
*  It didn't compromise.
*  The theory, Darwin say, was not changed by Wright and Holden.
*  What they did is reconcile genetics with the theory and the theory of population genetics, which tries to explain the distribution of genes using natural selection.
*  Does have to have both.
*  That's critical.
*  Right. So the object under analysis is the gene, of course.
*  But at the phenotypic level, sometimes called the phenotypic gambit, you can kind of get away with it.
*  But ignoring it and game theory, evolutionary game theory doesn't have any genetics in it.
*  So it's worth bearing in mind.
*  It's very level dependent in terms of what you should and should not include.
*  And I think that the mistake that is made all the time is confirmatory reconciling facts do not figure in the explanation.
*  And those get collapsed.
*  Right. And the existence of ion channels is a nice confirmation and verification.
*  It may help you poison someone, but it doesn't change the qualitative nature of the way you think about the propagation of an action potential.
*  You just need to know about varying voltages and capacitance.
*  Do you see? And so when you ask your question.
*  Wait, what's the question? I forgot the question.
*  We all have. That's the joy of it.
*  The question is, is you want there to be some mapping between presumably structures and circuits and mind phenomena.
*  And I'm just saying that I don't always have an intuition why that mapping between level and minus one and level N.
*  Is going to qualitatively change the intuitive nature of the explanation you construct at level N.
*  My bet is that there is a in plus one over two level between these two.
*  That is satisfactory.
*  I mean, so this we can go back to David's question about understanding heat versus the molecular collection of molecules and that actually.
*  So so I'm fine with that. I can I can use heat and I don't need to understand the molecules to use the heat.
*  And but I but I also wonder because I mean, I don't understand heat at core level, but I use it a lot.
*  So I have a sense that I understand it and I don't need to explain the molecules to use it because it's I can always use it the same way.
*  And I can take you know, there are you know, I can take the the explanation.
*  I can take that mapping and think, OK, I'm satisfied with that without being an expert.
*  But do you think do you think that if you if I asked you that the dog chased the cat.
*  And I said, do you understand what I said?
*  And you went, yes, I know what that means.
*  And then I said, but do you understand the particular syntactic structure of English that tends to be subject, verb, object?
*  And did you know that there's this universal feature?
*  These are syntactical rules of English.
*  And I said, so you don't really understand the dog chased the cat as well as I do,
*  because I'm a linguist who can talk about syntax and objects and subjects and verbs.
*  It would be very odd thing for me to say.
*  Right. It's not I know extra facts about language and I can use.
*  But to say that you would understand the dog chased cat better if you were a linguist would be a very odd thing.
*  And that's what you seem to be forced to adhere to.
*  So I actually we can have a running bet.
*  I believe and I don't know that we'll get I kind of doubt that we'll get there in my lifetime.
*  But I believe that there is not some sort of one to one correspondence where I can look at a circuit and the and know the one million two hundred fifty thousand neurons firing in this particular pattern corresponds to the feeling of love or something.
*  I don't think that there's going to be that mapping.
*  That's not what I'm looking for.
*  And I think you're misconstruing my desire as that is like mapping onto the physical substrate.
*  What I'm betting on and I believe that will there will be described one day is in the in between way.
*  I gave you that I gave you I told you about trajectories and state spaces.
*  Dynamical this goes exactly back to that.
*  But that's a usage case.
*  And but that hasn't happened in mind yet.
*  I mean it's well that's happened looking at state trajectories.
*  Well there are people who are coming up with similar kind of dynamical systems view of prefrontal cortex and beginning to talk in that way.
*  So in other words it wouldn't it's so far you're right.
*  It's been sort of convolutional neural networks for vision and recurrent neural networks for motor cortex.
*  But I have a feeling that you know there are people like Shaoxing Wang and others who are beginning to worry about prefrontal cortex.
*  And so it may well be that you'll have an object that is a mixture of psychological language and neuro dynamics that would satisfy you.
*  I want to add something else to this conversation now which is functionalism and degeneracy because I think we in complex systems it's right.
*  Sorry wait so just in complex systems.
*  No not correct.
*  It's right to have this debate because I feel that even if you adhere to and I'm just going to caricature this as Paul versus John here.
*  I don't think it's fair to say because but nevertheless there's another one which is completely orthogonal to this.
*  So if you think about telescopes right there are radio telescopes and there are optical telescopes about cars.
*  There are electrical cars and there are cars that use a combustion engine.
*  They are not at all the same. Not at all.
*  They use completely different principles.
*  They achieve.
*  That's the moles.
*  Wait a second. Yep.
*  They achieve the same objective.
*  So functionalism.
*  So now if we're talking about mind phenomena I think there's an argument that deep neural networks which have absolutely nothing to do with brain.
*  I mean really nothing.
*  And certainly not at the material level not at the level of mechanism the geometric topological correspondence is spurious.
*  Maybe in some cases maybe it isn't.
*  We can all agree on that.
*  Right. We probably agree on that although there might be some cases are probably going to give us much deeper insights into mind than neuroscience.
*  And we haven't talked about that.
*  So that's not about mind emerging from brain matter.
*  That's mind emerging from something completely different.
*  But I mean it follows.
*  I mean the thing is David is if you believe in terms of psychological algorithmic descriptions of mind phenomena it kind of follows that you could get them in some other way.
*  Now there are some people who say no the one way that you know again because I'm actually used to be and I think Paul knows this you know very much default functionalist but I'm willing to believe now that you can have fun.
*  What David Barack and I are calling neuro functional explanations.
*  They're functional explanatory objects with neural flavor.
*  Right.
*  You can have them both.
*  So in other words I think that the question is is whether to have that neuro functional object you have to have glia for example.
*  What if it turns out that even though the explanatory object is quite abstract and it's a dynamical system plus words.
*  But what if actually the tissue itself has properties that you need that go beyond neural populations and abstractions of connections vessels glia local field potentials if active transmission.
*  In other words it may be that the dynamical object that you end up coming up with can only be built out of biological tissue.
*  David does this accord with your view of the environment playing an interactive part in this or is it a separate issue.
*  I think it's a separate issue.
*  I don't agree with John and I can't really think of because of universality I can't really think of any anything like it.
*  And the ideas I understand it is that there's something super special about molecules which mean that functions which are very divorced from them that operated very aggregate coarse grained levels are actually dependent on them.
*  So it's sort of getting your it is what you want Paul is having your cake and eating it theory.
*  But I don't quite know how that could work.
*  I'm not aware of any such physical system.
*  I mean to understand it you're saying that you think that if I come up with some neuro functional object.
*  Yeah by definition you should be able to swap out the constituents.
*  Exactly. Yeah.
*  In strong functionist language.
*  Yes. Yes I think so.
*  I don't see what's special.
*  Just to mediate between you two then.
*  So John I tend toward this now as well that there may be something that is.
*  And this goes back to like the critical point of operation and what it takes to be in that area of operation and it could take something as I don't want to say complex because we're talking about complexity but as massively intertwined and evolved over such a long period of time to sit at that right state it might take the metabolism and the structure.
*  I don't know.
*  Doesn't doesn't pull.
*  So I'm someone who's worked on critical points.
*  Well not not for just critical points but I mean something like mind right.
*  So there's lots of things that operate at critical points that aren't mind.
*  Well that's a critical insight right.
*  Which is excuse the pun which is that this is precisely the point people got very excited about things like heavy tails right.
*  And then they realized that well actually we have no essential limit theorem for that too.
*  And so that's not a surprise.
*  Critical points got people excited rightly and people like John Begg and others who've been arguing for the brain being by a critical point.
*  But now we know of course that local area networks are by a critical point and social systems are by a critical point.
*  In fact everything that's evolved is by a critical point.
*  Small world and critical point.
*  Right. And so actually I don't think that these features they are fascinating by the way.
*  But I don't think they are the tool that allows us to distinguish between you know mind brain like phenomena and other complex phenomena.
*  They're just too ubiquitous.
*  So I think criticality is a bit of a red herring.
*  Moreover it's now been shown that deep neural networks are nowhere near critical points right.
*  Which have many of the characteristics that people have interested in mind are interested in.
*  And you can actually contrive statistical models where they are but none of the learned trained ones are.
*  So I think that is.
*  What I was saying is actually it's not true.
*  So far you know there's been no successful really cognitive general AI achievement.
*  And you know as I was saying Jeff Hinton says you know that's the last thing we're going to get.
*  And what does he know?
*  Yeah. Now the question is what is the impediment?
*  Is it architecture? Is it not knowing the right algorithms?
*  Or is there something that you can currently make with biological tissue?
*  Obviously by definition I'm not trying to say that you couldn't abstract away an object that behaves like the objects that currently only neural tissue can make.
*  But as long as once we work out what it's made what that object looks like we'll be able to make it in another way.
*  I think you seem to be saying that by definition if you can abstract to an algorithmic level.
*  If you can come up with a coarse grained description by definition it should be made out of different.
*  It should be duplicable with a different substance.
*  I do believe that. I think your first part of your argument I think I share which is that we're just not sufficiently clever engineers to know how to do that.
*  We're still missing something.
*  Missing a lot.
*  Can I ask you guys kind of a ridiculous question but a break from the seriousness maybe.
*  I just had the other day this daydream where I imagined a functionalist future where we all accept functionalism.
*  We build powerful AI and we accept because of their predictive ability.
*  We accept that they have better purchase on our own interests and we allow ourselves to be governed by their organization.
*  But we already are.
*  Well OK but let's say it's more concrete and more.
*  I mean that's that's a whole different conversation.
*  But OK let's say everyone anyway the dystopian vision I had was where we accept a functionalist account.
*  Everything that they are doing makes it seem as this.
*  Now I just realized this is like the terrible zombie analogy but but it seems you know we interact with them.
*  You know they're the robots whatever you know whatever pick your favorite television show.
*  And we we allow for the fact that we assume they have consciousness and mind and on our level whatever that means.
*  And so we could be in a place where we're actually giving ourselves up to the organizational principles of these things that we functionally define as having minds.
*  But in reality there's you know it's vacant.
*  There's nothing there.
*  I think that's completely impossible.
*  That's that's an example of giving an example.
*  It just doesn't make any sense on its face.
*  I know I just I realized it's the zombie thing.
*  I had with mind you know just like when Lake and Gershwin and Tenenbaum wrote their BBS paper on what you what would be needed to have general A.I.
*  And they basically come up with a set of behavioral criteria.
*  You know and it's very similar to arguments and I wouldn't dare go there with David here about what life is.
*  Do you get is it a different defined property or is it a cluster of properties or whatever.
*  But I think that if you had your tick box your checklist as they had in their BBS article about what would be necessary intuitive sociality intuitive physics modeling of the world rather than classifying it.
*  One short learning you know extrapolation planning I mean whatever their list entails.
*  I think that was four out of five or so.
*  They and you had these robots that did that.
*  They have mind as far as I'm concerned.
*  Right.
*  So we're agreeing then we're agreeing.
*  I think there's this very there's this interesting question I think.
*  I'll give another example from computing which I'm not sure is a good one or not.
*  So it might be that one day there's a certain class of computational problem that can be solved by quantum computer.
*  So right.
*  So there are problems now that we might call them be complete.
*  I don't know if this is true or not or at least extremely difficult to compute in any reasonable amount of time that a quantum computer could compute in our lifetime.
*  And that would be a good example I think of John's position where this class of function.
*  Which you could describe hardware independently simply couldn't be realized in anything that had this property of entanglement and spooky action in a distance and massive parallelism that comes out of the quantum domain.
*  So that is perhaps an example of where the physicality imposes constraints and what's realizable in the logical space.
*  But as far as I'm concerned unless you believe as Penrose does this applies to mind brain which it might I don't know everything we're talking about is a question of the mind.
*  Everything we're talking about is classical.
*  So then I'm not aware of any fundamental physical limitation that's analogous in mind brain.
*  So that's why I think I'm a functionalist.
*  Does timing matter to speed of information processing matter because you could have the exact same structure and do it very slowly.
*  Is there a role because I know you're very interested in time and that's part of the complexity story as well David.
*  How do you you know like John mentioned I had Uri Hassan on and he talks about at different hierarchical levels in the brain operate on different time scales seem to map on operating on to different time scales.
*  And I thought well you know there could be something to that.
*  There could be something to that.
*  But the more recurrent something is it could operate on a slower dynamical time scale and somehow that is a maps on to cognitive processing.
*  But but I wonder if if you think of time that way as well in the information processing and computation.
*  Yeah I've I've I've had a much more modest approach to time scales and computation.
*  I've worked a lot on molecular computation molecular information processing where time is exploited.
*  So the half life of a molecule is actually part of your box of tricks right.
*  You can use that to solve problems you can you can actually make a frequency decoder by exploiting relative decay times.
*  And so I'm kind of into that ingenuity of messing with time scales.
*  And clearly life is all about that right.
*  It's just been tinkering from the beginning with these properties of molecules and all of these time scales.
*  But that's not the same thing as saying it has to be done that way.
*  And so you know when human beings play chess.
*  You know we have a brain with all these time scales in it right with the time scale of you know synaptic chemistry in the time scales of someone.
*  But you know AlphaGo works at equilibrium right.
*  I mean once it's been trained it's basically there is no time scale right.
*  Time's gone. So we do know that you can solve complicated problems with no temporal dynamics that are interesting.
*  So I don't know but the scales that I care about things often it matters a lot.
*  Does it matter for mind?
*  For mind I mean again timed hierarchical systems as you go up the hierarchy they operate more slowly on bigger spectrums.
*  I mean that's the whole point of a hierarchical system is the time horizons you operate on go up as you go up the hierarchy.
*  So you know you could argue that when you have when you are worrying about where you're going to college in a few years time versus your stretch reflex.
*  Those are just years versus seconds.
*  Does that map onto our experience though?
*  What do you mean?
*  Mental experience to do you know our sense of time and the rate at which we are thinking right.
*  So this is this mapping from brains to mind that I want.
*  I think it does matter. It's interesting you say this as a paper that Jeffrey West and I have been thinking about writing for years which we never will.
*  I don't know maybe I know which is this interesting right.
*  So you can say you know Jeffrey has this very nice result which is that smaller organisms have higher heart rate rates.
*  We know that's not his result but if you rescale things according to the alimetric theory the total number of heartbeats in a lifespan is more or less invariant.
*  It's a bit like a photon being massless this thing pops out which is quite surprising right.
*  So a very tiny organism just beats much more quickly than us and lives a shorter time and we beat slowly and live a longer time.
*  It turns out that all sums up to the same number of heartbeats.
*  It's just got some shocking results that falls out of the theory and the question we've been discussing is maybe we there are similar in variances with respect to thought that a mayfly or something that seems from our perspective to live only a few days.
*  Actually thinks it lives a hundred years right from the mayfly's perspective it feels the same.
*  Well there's some evidence you know from Parkinson's disease right.
*  You know again Oliver Sacks talked a lot about these patients in awakenings.
*  He tells a funny story where somebody he sees somebody like this in the waiting area and he asked them what you're doing.
*  I think I was going to scratch or pick my nose right and basically he just caught him in this extremely drawn out.
*  But the point has been made that they don't feel that they're taking forever to pick their nose right.
*  Right so maybe your subjective experience of time does relate in some way to the speed of your physiology.
*  Right so that exactly that's the question.
*  So in the case of heartbeats is a very simple calculation by the way but we would do this properly for thought the way we have to do it is we have to calculate you know distances between neurons how quickly an impulse is propagated etc.
*  To see whether or not effectively as John just pointed out the sensation the subjective sensation of time was an invariant that falls out of a lot of tree we kind of cool and useless.
*  Cooling cooling nuclei cooling the brain maybe is looking at the speed of computations with cooling.
*  But you might not get it so you guys are talking about synaptic transmission rates and it might be more of a recurrence architectural feature you know circuit to circuit level.
*  True but I think that what's great about this conversation and I may say is that your consistent requirement for something I think.
*  I don't know whether it's the wrong question in other words that mind and brain will always have their separate vocabularies and their central frameworks that do and they can we simply have to feel reassured like David saying talk about temperature talk about volume talk about pressure.
*  It's better to talk about weather prediction of those terms and just feel reassured that it's consistent with statistical mechanics.
*  And I wonder whether the only way that we're going to get some neural information into our functional list explanations is that they'll look a little bit like a dynamical system is my guess I'm beginning to be willing to believe that we might be we might be able to think we might have a Feynman diagram way of thinking about things about mind.
*  Which are very heavily derived from your old data and David Barack as I said I'm working with has convinced me that maybe we would at least be happy with neuro functional objects not functional one so in other words you don't have to be a pure function.
*  Functionism has two meanings one is you think just in terms of processes rather processors.
*  The strong version of functioning as David's one which is that there should be many ways to implement it that isn't wedded to one physical implementation instantiation.
*  But I don't think you necessarily wanting that I think you'd be happy if you just had something in the explanation you gave to people.
*  That had something that was nearly derived in the explanation right that didn't have to use psychological words and I'm actually being very serious maybe we've reached a point where we'll have not just psychological functional words will have nearly derived objects in the sentence just like we have the.
*  Motor neuron in the stretch reflex sentence I'm really not sure whether that would count as what we call in the paper a first level explainer.
*  Right it's interesting I obviously here as a five there were phases where people became very enamored of dynamical systems.
*  Yeah right and I think we're over that a little bit and I think that the it's interesting I I'm not sure this is exactly the same thing but I'll give an example it's an argument I had a meeting at Harvard with George Whitesides.
*  And we were talking about the merits of information theory versus dynamics.
*  And he works in in in nanobiology and extraordinary engineer and cell biologist and he hated information theory and I think I had a similar argument with the soul institute with I don't know if it was such an about this it might have been.
*  People like dynamical systems because it feels closer to the matter you know it's got that quality about it and George felt that why do you need information theory is just a secondary imposition.
*  This observer dependent just describe it all in terms of the dynamics these functional concepts that you are imposing a useless.
*  The system isn't doing anything it's just colliding it's just a Bay Newton's laws and so dynamical systems are the right way to describe it so it's a kind of a weird reductionism that's not microscopic reductionism.
*  The kind that John is described but the point about dynamical systems of the kind that we study is you can't always write a Hamiltonian you can't always write an energy function down.
*  So you don't always have an action principle so you can't always say this is what the system is minimizing that's the point to which it is tending and what Shannon gave us was a framework where we could actually write down.
*  Variational principles on top of dynamical systems so you can say as a bill that will do you'll say that dynamical system is maximizing mutual information or tissue will say that's not because it is implementing the information bottleneck or what have.
*  And so you need this language.
*  To give you the variation architecture that is the optimization language but why don't have a but but but why do you know the words again when we use narrative.
*  Or words like William James did get no formalism attached to it but you're still doing understanding work I mean you look at even bar does incredible work on the stomatogastric ganglion right where she shows unbelievable redundancy in what the constituent neurons do.
*  But there's an invariance at the level of the pattern.
*  Yeah.
*  And the pattern and you know Eric Smith your very own Eric Smith has made a beautiful case for ecosystems and in physics that you should treat the pattern as the entity of explanation rather than component processes so when you look at even martyrs work.
*  It's the pattern generated by a lot of swapping out that you can do at the level of the so the invariance isn't at the level of the components.
*  No I don't think that's so in other words why can't we just all I was saying is if there was a neural pattern language.
*  No I know I know what you're saying why isn't that okay.
*  Yes, no there's nothing that's great I'm not I just want to make a point here that there are on the table here.
*  Three positions at least one is let's call it unfairly the sort of microscopic reductionist who says it has to be as low as you can go.
*  Which is what John thinks I am.
*  That person in the end just has the total physics envy and wants to do quantum mechanics.
*  Okay, and they should, but they can't so they do neuroscience or whatever they do.
*  So okay so then you have the aggregated middle ground which is a dynamical system which says you know what we can do is we can like Shadland and others which is very interesting so we can project onto this manifold which captures the information is dynamically sufficient.
*  In other words, the observable my eye goes left or right.
*  I get it just from tracking this this this.
*  Just be very careful though is there's a difference.
*  I mean, I don't know what Mike has done most recently, but before what he did was quite traditional that he would record from single units, see what they coded for, and then derive a psychophysical model of diffusion to bound in this case with two parameters that were confirmed by the neural data.
*  There was no theory of the config now there is now now now we have tried so now I would say that it might comes up with a sort of you're right now that I think about you know a dynamical system.
*  Then I think it's closer to a neural pattern language I think it begins to get to being a first level explainer exactly so so that's the I just want to introduce this third one so you're right so.
*  That's his point this predictive low dimensional manifold that you move around on okay and it's useful is great I love it but then that the problem is it doesn't tell you that sort of stuff where you should move.
*  It doesn't tell you what the system does I can't just be teleological wait wait wait but what's so beautiful about.
*  The Hamiltonian right what's so beautiful about using information theory here is it tells you that something is being maximized under constraints and that's a different language again and so I guess to be a pluralist here.
*  I think there are multiple different pattern languages right there's the lowest level Lego building blocks that as you say John the sort of dynamical system motifs but there's a higher level yet which tells you what the system is moving towards an action principle.
*  But I would say that but I would say that once you get to that you don't need you may not need to talk about neurons at all you can do you might know this this is exactly the mapping that I'm seeking right these sorts of levels and John you're enamored with dynamical system.
*  I'm not I'm not I'm not I'm not it's not so much and now I'm just saying that as a functionalist you was much more interested in just looking at behaviorally inspired cost functions.
*  And psychological like errors and rewards and motivation I was very much in that world and you can build cost functions out of those behaviorally derived measures.
*  Because of my work with David thinking about this I've been willing to see specially after Mark told me that he began to chew it with these trajectories it felt very fine menace.
*  You know I think we all should be willing to change our minds I thought to myself hmm it does seem as he was beginning to think.
*  With a new really derived object which is different from the behaviorally derived objects that I work with.
*  So I began to think that maybe with an intern era where we can have two types of explanatory object on the same plane.
*  I behaviorally derived one and a neuro derived one where they're actually on a level playing field.
*  See that that's not something.
*  I was really entertaining as much as I've been willing to working with David Barack and talking to the people who are doing this kind of work.
*  That maybe you and I think maybe at the moment that's going to be the closest to your wish is that you have a hybrid functional object that is made out of behavioral variables and neuro ones but dynamical ones.
*  It doesn't have to be dynamics but this is exactly the sort of thing that I'm talking about that to my level of satisfaction would be some sort of bridging.
*  But it's not bridging because it's a flat evidential landscape.
*  In other words they're both being used to explain they have been derived you know deriving from behavior and deriving from neurons you could say one came up vertically the other one was horizontal.
*  But the space they occupy is not vertical with respect to each other.
*  I think they're level with each other.
*  Is that okay?
*  Yeah I'm okay with that.
*  But it's interesting that I just maybe I have not been explaining myself well and this partly because it's an unknown territory and so it's impossible to explain what you don't know how it's going to look right.
*  So I don't think it's going to be a dynamical systems state space trajectory that's going to make me feel like I like that's going to be the bridge some you know I'm going to say bridging again but some sort of mapping some different kind of
*  understanding and David was just saying that there's going to be multiple levels.
*  How many levels are there going to be?
*  How many do we need?
*  As many as infinite.
*  I actually don't I have to say I don't think because of this feature so it's interesting this question right because we do know that there are an infinite number of models if you're allowed to have an infinite number of parameters.
*  So right so you can always fit a phenomenon in a particular space.
*  So I think it has to do with what satisfies our desire for understanding and I mean this gets to pedagogy.
*  This is kind of a weird digression but I've always thought that great teachers can explain the same idea in multiple different ways.
*  I've just been reading a book called 99 variations of on a proof.
*  And it's it's an illusion to a French novelist Roman Queneau's book called Exercises in Style and he shows that you can solve this cubic equation prove this cubic equation 99 different ways right and who knows if that's the upper bound but they all illuminate what a cubic is and what a solution means and different human beings on this planet will like those proofs to different degrees.
*  I love that.
*  I mean that's like ultra pragmatism I would say that there will be a few things that will be there that are going to be there.
*  I mean that's like ultra pragmatism I would say that there will be a few favored levels for the best effective theories that you can do pragmatic work with.
*  You can transmit understanding and you can do it in a way that's not too much of a problem.
*  I mean the best effective theory is one that leads to the most fruitful number of conjectured hypotheses right.
*  So in other words it seems to me that it would be very odd to not all come out of the same place.
*  I don't think that's true I mean I gave the example earlier of Newton you know the way you did this is just take conic sections you get circles you get ellipses you get conic orbits you get ellipses you get ellipses you get ellipses you get ellipses you get ellipses and so on.
*  And then you can do it algebraically and you do it with calculus and it just turns out to be much more efficient than doing it geometrically.
*  But I I think that's really the point.
*  I think that's really the point.
*  I think by virtue of the preferential attachment nature of culture that right that there is a kind of winner takes all dynamic there will be a few preferred formalisms.
*  But I'm not sure they'll be preferred because they're the best.
*  I think that's really the point.
*  So in the case of just to bring it back to heat again we all feel comfortable with this idea of you know what heat is relative to the collection of molecules.
*  Is that it?
*  I mean we all agree that's fine we're all comfortable with it.
*  Are there more levels that need to be addressed?
*  I think that's the point.
*  I think that's the point.
*  I think heat is relative to the collection of molecules.
*  Is that it?
*  I mean we all agree that's fine.
*  We're all comfortable with it.
*  Are there more levels that need to be had that could be had will be a better explanation.
*  There might be there might be more parsimonious means of describing it.
*  I mean it's true.
*  Perhaps there is something about the simplicity of the phenomenon that doesn't permit right.
*  Well that's what I'm saying.
*  That analogy might not be right between brain and mind.
*  But you take the example that I gave of a cubic.
*  Right.
*  Pretty simple thing.
*  Right.
*  And you can just multiply proofs.
*  And so I don't know.
*  I don't know what the best analogy is.
*  I think also I mean it's been I read it a while back but you know Rosa Cowell and Dan Tammons wrote about you know the ventral pathway.
*  Does it count as an understanding rather than what we've been saying which is just you know an opaque fit.
*  Right.
*  And I actually think they make a good case.
*  But at one point Rosa Cowell and Dan Tammons talk about the contravariance principle that the more the more complex a phenomenon becomes.
*  And I'm sure I'm mangling this that the number of ways to actually get it done goes down.
*  Right.
*  That simple things can be done in a lot of ways complicated things complex things reduce the number of degrees of freedom you have available to get it built.
*  And so one of the reasons they argue that there's genuine insight given from their work on the ventral stream.
*  And they make you know is that the best predictor of the neural responses in the ventral stream is now given from a deep neural network that was trained on images.
*  In other words it is kind of fascinating that if you want to predict when you go into an area of the ventral stream what the neurons will look like you're going to get a better prediction from your deep neural network.
*  Right.
*  Then from what you think.
*  So so they argue that first of all it is at a level of abstraction because there are no neurons with biophysics in that system.
*  But they then say that the reason why that may be happening is that things like object recognition in a layered system that aren't that many ways to actually do it.
*  But that's not true though.
*  I mean I don't quite understand what they're talking about because.
*  Let me let me jump in real quick here because I'm out of time just about.
*  Let's end on this.
*  But so so David let me give you the last word there and I'll just throw in what if it's the case that object recognition is just easy.
*  And so there are like many different ways to do it.
*  And then David this is a complexity question so I'll let you address the many ways versus few ways to do complex things.
*  Well I mean I don't have a definitive answer.
*  I simply say that if you have some Boolean function it can be realized in an infinite number of ways.
*  I don't understand this idea that complex things have few ways of being.
*  Well I mean just like converging evolution that you know wings right that they end up having a similar shape.
*  It's not like you can have.
*  But they're realized totally different.
*  Yeah but their shape is.
*  Well whatever.
*  Well that's the function.
*  Right.
*  I don't know.
*  I haven't read the paper but I bet it's wrong.
*  Thank you very much for putting up with us Paul.
*  Thank you Paul.
*  That was fun.
*  No thanks.
*  I appreciate you guys piling on me there for a long time.
*  That was great.
*  I'm baking.
*  Are these new Mexican photons?
*  You've seen me moving like a sundial.
*  Brain Inspired is a production of me and you.
*  I don't do advertisements.
*  You can support the show through Patreon for a trifling amount.
*  And get access to the full versions of all the episodes.
*  Plus bonus episodes that focus more on the cultural side but still have science.
*  Go to BrainInspired.co and find the red Patreon button there.
*  To get in touch with me email Paul at BrainInspired.co.
*  The music you hear is by The New Year.
*  Find them at thenewyear.net.
*  Thank you for your support.
*  See you next time.
