---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 4799s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 5811
Video Rating: None
---

# BI 126 Randy Gallistel: Where Is the Engram?
**Brain Inspired:** [January 31, 2022](https://www.youtube.com/watch?v=D4Fbfs0MEBk)
*  Usually when I ask neuroscientists how you encode a number either in a synapse or however
*  many synapses they think might be necessary, that's a conversation stopper.
*  All I get is hand waves, you know, well, you see there are lots of synapses and it's a
*  pattern of synapses.
*  Well, could you say something about the pattern?
*  I mean, how does the pattern for 11 different for the pattern from 3, for example?
*  Could you shed a little light on that?
*  People do not want to answer that question.
*  The engram is the low-hanging fruit because it has a really simple job to store the information,
*  just like DNA's job is to store the information.
*  What is the role of synaptic plasticity?
*  I honestly have no idea.
*  Since I literally believe that an associative bond never formed in the brain of any animal
*  and since the plastics synapse is transparently conceived of as an associative bond, right?
*  I certainly don't think that's what they are.
*  Could they play a role in the computations carried out in signals?
*  Sure.
*  This is Brain Inspired.
*  Hey everyone, it's Paul.
*  Engram, it's a term coined by Richard Seaman in the early 1900s and it refers to the physical
*  substrate that stores the information that makes up our memories.
*  In other words, the trace of our memories.
*  We still don't have a definitive answer to the question of how our brains store memories,
*  what makes up the engram.
*  Many neuroscientists would say a given memory resides in a specific pattern of neurons and
*  the activity of those neurons and that the formation of new memories and changes in existing
*  memories, that is, learning, depends on changes in the connections between neurons, synaptic
*  plasticity.
*  And of course, training deep learning artificial networks is fueled by adjusting the weights
*  between their units to learn tasks.
*  But not everyone agrees with this story, that memories are somehow stored in neural connectivity
*  patterns and the activity of the neurons in those patterns.
*  As Tomas Ryan puts it, and Tomas will be on my next episode, at what level does an engram
*  lie?
*  Is an engram in the cell or is a cell in the engram?
*  Randy Gallistole is my guest today.
*  He's a distinguished professor emeritus at Rutgers, and he's been at this for over 60
*  years.
*  And he's been arguing much of those 60 years that the engram must lie within the cell,
*  not that a cell is in the engram.
*  And his argument, which you'll hear him flesh out, is that brains are computational organs,
*  and to compute, you need symbols, namely numbers.
*  And Randy thinks the only reliable way to store numbers over long periods of time, which
*  is necessary, and to be able to read from those numbers and write new numbers, is to
*  use subcellular molecules like DNA or RNA or something similar.
*  He also details his arguments in a great book, Memory and the Computational Brain with Adam
*  King, which was published over 10 years ago.
*  I recommend that book.
*  I have distinct episodic memories reading that book in my office in Nashville, for example,
*  and I've gone back to it multiple times since then.
*  It goes over the fundamentals of information theory and uses examples from animal behavior
*  like navigation and foraging to argue his case.
*  So today we talk about some of those ideas, some of the evidence to support those ideas,
*  and a host of other bells and whistles, including his long, successful career, studying the
*  many abstract processes underlying our learning, memory and behavior.
*  You can find show notes at braininspired.co slash podcast slash 126.
*  On the website, you can also choose to support the podcast through Patreon and join our braininspired
*  discord community if you want and get access to all the full episodes I publish through
*  Patreon, or just to throw a couple dollars my way each month to express your appreciation.
*  I appreciate you listening.
*  I hope this podcast is enriching your minds and bringing you some joy.
*  Here's Randy.
*  Randy, you're 80.
*  You just told me you're 80 years old.
*  Yes.
*  Well, when did you turn 80?
*  Back in May.
*  Okay.
*  Well, happy belated 80th.
*  Thank you.
*  So I know that you have been interested in memory since the 1960s.
*  At what point, so we'll get to the big idea here in a moment, but at what point in your
*  career did you start questioning the typical neuroscience story about memory?
*  Way back in the 60s, when I was an undergraduate in Tony Deutsch's lab and deciding that I
*  wasn't going to be a social psychologist, I was going to be a physiological psychologist,
*  as we called them in those days.
*  And now we call them behavioral neuroscientists.
*  And I really became an apostate during while running my first experiment, which was a runway
*  experiment with rats and I would watch them.
*  And just watching the rats, I became absolutely persuaded that they knew what they were doing.
*  It wasn't habits.
*  I had already become enamored of Hull's vision of a mathematically rigorous theory of mind
*  and brain, what we would now call computational neuroscience.
*  But I had already become an apostate from the rest of his doctrine because with all
*  it was all habits.
*  And of course, there are many computational neuroscientists for which that's still true.
*  That's what I mean when I said a moment ago before we were recording that nothing has
*  changed in the 60 years.
*  I go to meetings now and I listen to some of the talks.
*  I think this is the same shit I was listening to in 1963.
*  Well, so, you know, one of the things that you talk about in your book, Memory and the
*  Computational Brain, Why Cognitive Science Will Transform Neuroscience, is that there
*  is this large gap between cognitive science and neuroscience.
*  And I heard you talk recently and you've written about this as well, that actually even back
*  that was 2009, 2010 when that book came out and computational neuroscience was still a
*  small swath of neuroscience writ large, right?
*  But that's changed, hasn't it?
*  There's computational neuroscience, which to me seems like is the majority of neuroscience.
*  What's your view on that?
*  Has computational neuroscience come along?
*  Well, in terms of the number and quality of people doing it, yes.
*  I certainly don't see it as dominating neuroscience.
*  I mean, neuroscience.
*  You know, I assume you go to the annual, you know, the meeting, the Society for Neuroscience,
*  there are 30,000 people there, right?
*  I mean, there are two poster sessions a day in this.
*  The poster sessions are so big that even if you trotted, you couldn't go buy all the posters,
*  right?
*  And there are two of them every day and so on.
*  And, you know, computational neuroscience is kind of smaller than that big picture.
*  And also, when I think about it, computational neuroscience, I guess, or at least certainly
*  my worldview was dominated by vision people back in the day, right?
*  I mean, they still is.
*  They've been very computational now for decades.
*  In fact, there's a fascinating book by Hugo and Wiesel, which they reproduce their papers.
*  It was clearly a project of David Hubel and they reproduces 25 of their classic papers.
*  And there are introductions and epilogues to each paper by Hubel.
*  And he repeatedly rants against the mathematician, you know, the fact that all the engineers and
*  mathematicians have come into vision, right?
*  Because like so many of the early people, he really didn't know much mathematics, right?
*  Right.
*  And these days, you cannot do cutting edge vision without a fairly serious mathematics
*  education, right?
*  But that was already true 30 years ago.
*  So I think what you're reacting to is now, of course, there are many people doing computational
*  neuroscience and focusing on learning and memory, which did not used to be true.
*  I mean, those fields used to be completely non-mathematical, right?
*  I've had more than one colleague and friend tell me they went into this business precisely
*  because they didn't have to learn mathematics.
*  Right.
*  Yeah.
*  That's right.
*  Yeah.
*  Well, I mean, it seems like these days and again, this is my own bias because I learned
*  computational neuroscience through my career, my short kind of academic career.
*  But going in, I didn't really, I had some mathematics background, but I didn't have
*  modeling background.
*  I didn't have a real a good footing in the computational world.
*  So I kind of learned that through my training.
*  But didn't you, you kind of applied yourself and learned some necessary mathematics a little
*  bit later in your career, no?
*  Oh, yeah, for sure.
*  I've been learning various bits of mathematics throughout the last 60 years.
*  I, for example, I mean, I had the calculus as an undergraduate, but I didn't have linear
*  algebra.
*  And I took the undergraduate linear algebra course at Irvine after I was already in a
*  tenured associate professor during my first sabbatical when I was working with Duncan
*  And studying also linear systems theory, which I also basically taught myself.
*  I went partly, of course, Duncan was two orders of magnitude better mathematician than I ever
*  imagined I would ever be.
*  But he was incredibly good at explaining things.
*  And I was teaching myself by reading various textbooks on linear systems theory.
*  And there was stuff, for example, I remember I could not wrap my mind around the convolution
*  integral.
*  So I said, Duncan, can you explain what convolution is?
*  And he sat me down and I remember a half hour later, I absolutely understood what convolution
*  was.
*  Wow.
*  And that was on a, did he use a blackboard or did he use PowerPoint?
*  I'm just kidding.
*  I think it was basically just verbal, although he may, this was a long time ago talking about
*  it, it would have been the blackboard.
*  There may have been some recourse to the blackboard, but mostly, well, anyway, somehow
*  he found there were examples that made it clear.
*  And then I was able to use it.
*  And that was a real satisfaction.
*  If you had to go back, would you enter by studying mathematics first?
*  Because I ask because you have a deep knowledge of the behavior surrounding learning and memory,
*  which you also had to have to get to where you are.
*  Yeah, sure.
*  Sure.
*  Well, that was, I mean, first of all, that was what I took courses in.
*  And second of all, I mean, that's what I taught for 50 years, right?
*  So, the behavior, the more mathematical treatment, I rarely taught at the undergraduate level,
*  right?
*  Because it would take a very special undergraduate seminar to do it.
*  I did teach it at the graduate level.
*  And as every teacher knows, you don't really understand the subject until you've tried
*  to teach it.
*  Right.
*  I mean, it's, you get sometimes as an experience where you're busy explaining, this happened
*  to me even when I was teaching introductory psychology, I'm halfway through an explanation.
*  And all of a sudden, a little voice says, you know, what you're saying doesn't make
*  sense to you.
*  Yeah, it's a terrible thing.
*  That's true.
*  You really find out what you don't know.
*  This argument has just gone off the tracks.
*  Well, this idea of the brain as a computing device, among other things, has dominated
*  your thoughts for a few decades now, right?
*  Oh, since way back.
*  Since way back.
*  Yeah.
*  I was in graduate school at Yale, a very behavior school in Neil Miller's land.
*  You know, he was Hull's most prominent student.
*  But as I said, I'd already become a heretic as an undergraduate.
*  So I wasn't buying it.
*  Nor was I buying it when I took the advanced course of learning from Alan Wang.
*  Meanwhile, I was building special purpose computers to run the experiments I was running.
*  And I was reading the theory of computation and books on how computers worked and so on.
*  And Chomsky was coming along.
*  I went to a talk with this guy I'd barely heard of, Noam Chomsky.
*  He came to speak at Yale.
*  I'd just been reading the stuff that Skinner and Osgood had written on language.
*  I didn't know anything about language, but I thought, this is rubbish.
*  And so I went to hear this talk by Chomsky.
*  I was an instant convert.
*  OK, this isn't rubbish.
*  So I embraced the computational theory of mind.
*  And I've thought since those days.
*  I mean, many of these days, most neuroscientists pay lip service, at least, to it.
*  But many of them would immediately add, yes, the brain computes.
*  But it doesn't compute the way a computer computes.
*  Yeah, this is the story.
*  And having studied how computers compute.
*  And I mean, I've programmed all the way down to the machine level.
*  So I know what goes on under the hood and so on.
*  And I've always thought, well, wait a second.
*  There isn't any other way to compute.
*  I mean, tell me how it is you compute, but not the way computers compute.
*  I thought Turing settled that.
*  Well, so I had a brain inspired listener question about Chomsky's influence on you.
*  So really, you remember going to a talk and having that sort of solidify your approach?
*  Oh, yeah, I remember being very impressed.
*  And then I read his, well, it didn't come out till later.
*  But when it came out, I read his reflections on language.
*  But also at Penn, Penn was a cognitive science was very much a happening thing at Penn.
*  And I had colleagues like Lila Gleitman and Henry Gleitman and Duncan Luce.
*  So I was strongly influenced by them.
*  And Dick Neisser was on sabbatical there the second year I was an assistant professor.
*  So I was influenced by all of those people and all of those people were influenced by Chomsky.
*  I mean, Chomsky sort of ran through the way we all thought.
*  There's a kind of interesting story about that.
*  Some years later, after I'd been publishing a bunch of stuff, and it isn't quite a number of years later,
*  no one whom I'd met once or twice and who I've often corresponded with subsequently.
*  But he wrote me a very polite letter.
*  It's a letter, I think this was before email, gently complaining that I was channeling him without ever citing him.
*  OK. And I was very embarrassed.
*  And I thought, you know, he's absolutely right.
*  So I wrote back apologizing and saying, look, you're so much a part of the intellectual milieu in which I swim.
*  I just didn't occur to me to acknowledge or even recognize my intellectual debts.
*  Anyway, interesting. So, OK, well, maybe we can return to Chomsky later.
*  But because I know you wrote a manuscript in 2006, I believe, where you acknowledged the reflections on language and how that also influenced you.
*  But I assume you got the letter before 2006 because.
*  Oh, yeah, for sure. It was a long time ago.
*  So memory in the computational brain, of course, you you detail your ideas in that book.
*  But you've also continued writing.
*  And there's a recent 2017 piece on the coding question where you revisit these ideas and you've continued to give talks about them.
*  So maybe just in the broadest strokes, could you summarize your the idea and your position?
*  And then we can kind of go through some of the details as needed.
*  So. Computation is operations on symbols.
*  Right. Before the emergence of computing machines, symbols and representations,
*  all those things were regarded as handwaves.
*  Right. But with computing machines, when someone said, well, what do you mean by symbol?
*  You say, well, you see this bit register, you see that pattern of ones and zeros that's been put into that, those switches.
*  That's the number eight. That's what I mean by a symbol.
*  Right. There's nothing even faintly mystical about it.
*  It's a it's a fundamental.
*  In this sense, symbols are the stuff of computation where I'm using stuff in the physical sense.
*  Right. It's there.
*  The material realization upon which computational operations operate.
*  And once I got into information theory, I realized, yeah, right.
*  And an even better way of putting it, and this became apparent in the book with Adam King,
*  that these symbols carry forward in time information in Shannon's sense of the term.
*  So that you can quantify, you can say, look, this physically realized thing is carrying this amount of information.
*  So so you could wave aside all the fears about dualism and so on that tormented.
*  The behaviors were all terrified by the specter of dualism. Right.
*  And so it was as far as I was concerned, the computers just put paid to those worries.
*  Right. You had a completely physical theory.
*  It was I thought then and still think gave you a viable theory of mind.
*  My when I at Stanford and Yale and the behavior of states, if you said, well, the rat expects to find food at the end of the runway.
*  You can see they were saying, well, I don't think we maybe should have admitted him.
*  Somebody who's so soft headed as to talk about expectations.
*  Because it was related to theory of mind or because because.
*  Before the appearance of computers.
*  I mean, Skinner denounced expectations in the most uncompromising terms as unscientific.
*  Right. So you couldn't see them.
*  You couldn't feel they had no business in science.
*  And of course, as soon as you began programming computers,
*  you would set up one number that was going to be compared to another number.
*  It's such a case. And so then I would just turn them and say, hey, look, here's my program.
*  It runs on that machine. I don't think there's a ghost in that little computer I built.
*  This number is what it expects.
*  And this is the operation by which it compares another number to that to decide whether what it expects was actually the case.
*  And the story get off my back.
*  Yeah. But is that is that a redefinition of expectation over the years toward a more because, you know,
*  the word expect one conjures a notion of someone having a subjective feeling of expectation.
*  Right. But now when someone says expect, at least in the cognitive science, computational neuroscience world,
*  all you think of is like a predictive processing, numerical abstract process.
*  Sure. Now, these days where everybody's talking about prediction error,
*  they're taking for granted that there's an expectation and the terms in which I'm talking about it.
*  I'm never worried about these phenomenological things, right.
*  What does an expectation feel like?
*  Not the kind of question I'm interested in.
*  Because I don't think it's possible to get a hold of it in a strong way for just the reasons you were pointing out.
*  That is, look, all I need for expectation is what I just described.
*  Right. And it's perfectly clear.
*  And there's no problem with it now that we have computing machines and we see this going on all the time.
*  When people ask, well, does a computer feel the way I feel when I have expectation?
*  I think I don't know and I don't care.
*  It's not the kind of question I'm interested in.
*  Right. In fact, if you notice what I've worked on almost entirely, particularly in recent years,
*  the last few decades, it's what I call the psychophysics of the abstract quantities,
*  distance, duration, probability, numerosity and so on.
*  The quantities that are a fundamental part of our experience, but they have no qualia.
*  Right. I mean, what?
*  Oh, no, you said qualia.
*  Well, I said it precisely to say that if you work on those things, you don't worry about qualia because they have no qualia.
*  I mean, what does the duration feel like?
*  Right. So all the philosophers that are beating themselves up about what's it like to be a bat?
*  And they're all worried about qualia.
*  Well, qualia just isn't something I worry about because, first of all, I think the qualia are the things that have qualia are of relatively minor interest.
*  If you want to know what behavior is founded on, it's founded on the abstractions I was just talking about, the probabilities,
*  the numbers, the durations, the directions, the distances, all these abstractions.
*  They're what drive behavior all the way down to insects.
*  Right. As you probably know, I'm a huge fan of the insect navigation literature.
*  You like the bees, you like the ants, you like the butterflies, the beetles, the dung beetles walking backwards with their ball of dung.
*  Walking home backwards.
*  Maybe the central argument or one of the central arguments is that the story in neuroscience that the numbers and the numerical abstract symbols,
*  I should just say symbols, are encoded in the synapses, right, in the connections between neurons among populations of neurons.
*  But you have a hard time believing that that could be the case.
*  Well, actually, I usually when I ask neurosciences how you encode a number either in a synapse or however many synapses they think might be necessary.
*  That's a conversation stopper.
*  I don't know if you ever viewed my YouTube of my talk at Harvard where John Lisman was the discussant.
*  And I posed that question at the end of my talk saying, John, when you get up here, you'll tell us how you store a number in a synapse.
*  And he got out and gave a lengthy discussion in which he never brought that topic up.
*  And this was a very unusual and that I got a rebuttal.
*  I got another chance to speak.
*  And I said, John, I'm going to give you another chance.
*  How do you store a number in a synapse?
*  Come on, John.
*  And the audience began to laugh.
*  And he stood up and he would not answer the question.
*  And I had a somewhat similar experience with Jean-Pierre Chonjure much more recently.
*  In fact, the question made him so angry that he wouldn't allow the debate to be uploaded to YouTube.
*  Oh, wow. I was going to say I didn't see that one.
*  So and I've gone so far often in my talks to say, come on, guys, I can offer you two alternatives.
*  I mean, it's not as if it's impossible to think of an answer of what I just said.
*  And I often proceed to say, well, look, the synapse is usually conceptualized by computational neuroscience as a real valued variable.
*  And distance, direction, probability, they're all real valued variables.
*  Right. So you can always represent a real valued variable by a real valued variable.
*  Right. So we could say, well, if the synapse is this if the weight is this big, then the distance is that far.
*  Right. And if the weight is this big, you want to go there.
*  I found practically no one wants to go there.
*  Oh, you don't want to go there.
*  Here's a radically different alternative. Suppose we have a bank.
*  The people who talk about the synaptic plasticity are very vague about how many states a synapse can assume.
*  But one school of thought thinks they're binary. All right.
*  Fine. I like that. That's a switch.
*  OK, so we'll have an array of binary synapses.
*  And we throw this synapse to this state and this synapse to the zero state.
*  And now we've got something just like a computer register.
*  You like that story? No, most people don't like that story.
*  All right. What's your story?
*  And at that point, all I get is hand waves.
*  Well, you see, there are lots of synapses and it's a pattern of synapses.
*  Well, could you say something about the pattern?
*  I mean, how does the pattern for 11 different for the pattern from three, for example?
*  Could you shed a little light on that? People do not want to answer that question
*  because the answer to that question is to admit that there are symbols in the brain.
*  And even to this day, many people do not want to go there.
*  And what's your answer?
*  My answer is that isn't in the synapses.
*  I mean, I point out that there are several labs around the world that are busy studying
*  how to use bacterial DNA as the memory elements in a conventional computer.
*  Right. Any engineer, anybody familiar with the computing machines that actually work?
*  And we know how they work.
*  You know, once you show them a polynucleotide and explain that any nucleotide can be adjacent
*  to any other nucleotide, any engineer worth a site says, well, I could store numbers in that.
*  It's like no, but it's a business.
*  In fact, one of the people who introduced me in a talk I gave a couple of years ago
*  in the introduction showed a very grainy video of a running horse where the video,
*  the entire video had been passed through bacterial DNA.
*  Right.
*  Just to drive home the fact that if you're looking for a place to store numbers, well,
*  that's enough.
*  Well, we know, yeah, we know DNA stores the genetic code, but there are other possibilities as well.
*  I'm wondering what your current, so DNA is one possibility, right,
*  where a code could be stored intracellularly.
*  And to you, the key, I don't know if, I don't know your current thoughts on this because it used
*  to be that you didn't know that there were, you know, a handful of intracellular mechanisms
*  whereby you might store these things.
*  Proteins degrade a little too fast, right, but then there are polymerases
*  like RNA could be one of the, a substrate.
*  DNA could be a substrate, but is DNA fast enough?
*  What's your current thinking on what might be the substrate?
*  Well, my, I'm still sticking with polynucleotides, though I lean much more strongly to RNA than to DNA,
*  probably complexed with a protein to stabilize it.
*  My thinking has taken a huge boost lately from a wonderful paper by a young guy in Gabby Maiman's lab
*  the Rockefeller named Hessemadeen Akhlagpur.
*  It's just appeared in the Journal of Theoretical Biology in the last couple of weeks.
*  And he's an astonishing guy because he has a truly deep knowledge of theoretical computer science,
*  much deeper than mine.
*  I mean, he really knows the lambda calculus, right, whereas for me it's just kind of a name.
*  But at the same time, he really, he has a much deeper knowledge of RNA biology than I do.
*  But the most astonishing thing is that he, I mean, those two things are about as far apart as
*  conceptually, as you can readily imagine.
*  But he has this very rare mind that can bring those two things together.
*  And he lays out a detailed story about computation performed at the RNA level in which RNA is both the
*  symbols and the machinery that operates on the symbols.
*  And he builds this on the lambda calculus.
*  And he lays out in his appendix in great detail an RNA machine that will add arbitrarily large numbers.
*  Now, for all those computational neuroscientists out there in your audience, I claim that that has never
*  been done by a CNN and that it never will be done.
*  By at least by a non-recurrent, you know, by a straight through CNN.
*  And even if it's done by a recurrent one, right, they're going to resort to that old recycling,
*  you know, because you're going to have to store that addition is inescapably serial, right?
*  So you've got to do the earlier, the less significant digits first.
*  And you have to store that result and then transfer the carry to the next one and so on.
*  So you need memory.
*  And so how do you get memory?
*  Well, that's where recurrent nets come in, right?
*  You keep sending them around the loop, which in this paper by Akhlappu,
*  that I recommend in the strongest terms, he also has a wonderful discussion of dynamic systems
*  and why they're not stable, right?
*  The very guy Moore who proved that they were Turing complete also argued very strongly
*  that they weren't stable.
*  So they weren't physically realizable.
*  The Turing complete ones were just a kind of mathematical dream.
*  They weren't physically stable.
*  Well, I didn't know about that more recent paper.
*  You used to hang your hat on and maybe you still do the Purkinje cell finding in the cerebellum.
*  And maybe you'll just add this more recent finding with RNA to your talks now.
*  You're absolutely right.
*  I mean, I still think Frederick Johansson's discovery of the development of that preparation,
*  which was the culmination of a 40-year effort in Jerry Hessell's lab,
*  I still think that what he has done is hand the molecular biological community
*  what they need on a platter.
*  And for the first time, I think we could actually know the physical basis of memory
*  while I'm still sentient.
*  And that would be a miracle because he's identified the beginning and end of an
*  intracellular cascade.
*  And one of the steps in that cascade clearly contains the N-gram that encodes the CSUS
*  interval.
*  I think his PhD work proved that beyond reasonable argument.
*  And molecular biologists know how to follow intracellular cascades, right?
*  I mean, he identified the postsynaptic receptor at the start of this cascade.
*  And this is a metabotropic receptor, right?
*  Which means that it transfers the message from an extracellular source to an intracellular
*  signaling chain.
*  And there's almost certainly a G protein on the inside of the membrane.
*  And that transforms and gooses the next thing and so on.
*  And molecular biologists have been tracing these cascades now for decades.
*  And see, it's always been how would I know that I'd gotten to the N-gram?
*  But Hansen has solved that problem for them if only they realize it.
*  Because he proved that the information about the CSUS interval is not in the incoming
*  signal that triggers this cascade, right?
*  But he also identified a potassium channel, an inward rectifying potassium channel at
*  the other end of the cascade.
*  A channel that's a key to producing the pause, the timed pause that comes out of the cell,
*  right?
*  All right, so you're following this cascade.
*  And until you get to the N-gram, the information about the duration of the interval won't be in
*  any step you see, right?
*  And on the other side of the N-gram, the information will be in the chain, right?
*  Because it's there by the time you get to this potassium channel.
*  So you're following the cascade and at some point say, whoa, wait a second, look at that.
*  This step is informed by the N-gram, all right?
*  So the N-gram lies between the preceding step and this step.
*  Whoa.
*  But yeah, so there wasâ€¦
*  Is the more recent theoretical biology paper with the RNA, does it address the reading and
*  writing mechanisms?
*  Because that's what you'd have to follow, right?
*  To address reading and writing.
*  Well, keep in mind, in fact, I strongly suspect if I can guess how things will play out, that
*  we will discover the N-gram before we understand either the writing or the reading mechanism.
*  And again, I would appeal here to the history of DNA, right?
*  The N-gram is the low-hanging fruit because it has a really simple job.
*  Its only job is to store the information, right?
*  Just like DNA's job is to store the information.
*  So we are still learning how that stored information gets translated into actual organisms,
*  right?
*  Now, we've made enormous progress in that, but there's still a very long way to go.
*  And this has been going on now for decades, right?
*  For 40, 50 years, ever since 1953.
*  So the DNA story, that emerged pretty quickly, right?
*  That the basic, okay, here's how the information is encoded.
*  Here's how it's carried forward in time.
*  The story about how it's read is five orders of magnitude more complicated, right?
*  I mean, you can explain DNA to a smart undergraduate in half an hour, right?
*  If he then asks or she then asks, okay, how do you get an I?
*  Then you say, well, okay, come to my advanced graduate seminar and
*  then we will spend the whole seminar discussing what we understand about how you get from a gene
*  to an I, right?
*  One of the astonishing things we've learned is that there is one gene,
*  there's a gene you turn it on, you get an I wherever you turn it on, right?
*  When I was being taught biology, we were being taught one gene, one protein,
*  which is of course still true.
*  But everyone took it to be a corollary that if you thought there could be a gene for an I,
*  you were stupid.
*  Because no one could imagine what, I mean, there was this huge gap between, okay, you've got,
*  we're coding for a sequence of amino acids, right?
*  An I isn't a sequence of amino acids.
*  Now, again, I would say the reason they couldn't imagine how it's done is they didn't know enough
*  computer science, right?
*  Because it turns out that the protein that that gene encodes for isn't a building block in the I,
*  it's transcription factor, right?
*  It's all transcription factors.
*  You have to go five or six steps down before you get past the transcription factors.
*  Now, anybody who knows how relational databases work would say, well, duh.
*  I mean, or how a function works, right?
*  When you call the name of a function in MATLAB, that just accesses the code for that function, right?
*  Yeah, and on and on.
*  And on and on.
*  That's how you build complex operations out of simple operations, right?
*  And that's what computation is all about.
*  Let me try this out on you because just thinking about this, talking about the,
*  I know you just said that the read mechanism is orders of magnitude more complicated,
*  and then the write mechanism must be even more complicated, I would imagine.
*  Until we know what the n-gram is, I think I refuse to think very long about this issue
*  because I think I don't know what it is I need to know in order to think productively about it.
*  Yeah.
*  Because the write mechanism has to translate from an incoming code in the spike train.
*  And since we still don't, despite the Rieke et al. book, which I worship,
*  and from which I learned my information theory, I have friends, many friends,
*  even my collaborator, Peter Latham, who thinks it's a great book, but I think they're well,
*  it's just about the fly sensory neurons.
*  Right? I say bullshit. It's the answer to how spike trains carry information, period. Right?
*  It's all in the interspike intervals. Well, and there's several bits per interspike interval.
*  Well, there's no agreement about that. Right? So until there's agreement about how the information
*  is encoded in the incoming signal and agreement about how it's encoded in the incoming signal,
*  and agreement about how it's encoded in the written thing, you can't think productively
*  about what could the machinery look like that would take this code and produce that code
*  any more than you could get from DNA to homeobox genes, right? Without knowing all the very
*  complicated stuff that goes on in between. And then knowing how homeobox genes work, right? I mean,
*  they code for abstractions, anterior, distal. It's as if somebody went to an anatomy lesson
*  back in the pre-Cambrian, right? And they said, well, we got a code here for, we got to have a
*  code for on the end of whatever it is we're building. We have to have another code for
*  anyway, you get my drift. Yeah. Well, let's pretend for a moment just as a thought experiment.
*  It doesn't have to be RNA, but there's some intracellular mechanism, right? Yeah. And
*  you just mentioned, so this is going to be kind of a long winding thought train here, but you had
*  just mentioned about the receptors and how there is this enormously complex cascade from receptors
*  to intracellular processes. And anyway, that that's a long cascade. You also mentioned
*  convolutional neural networks in a derisive way, playfully derisive way. However, thinking about
*  a read-write mechanism. So you probably know that, given a large enough neural network,
*  that they are universal function approximators, right? They can transform from input to output
*  and mathematically proven that they're universal function approximators. Talking about the cascade
*  from extracellular membrane protein to intracellular happenings sounds eerily like a neural network
*  kind of process because you have all these interacting subcomponents, right? The other thing
*  that you mentioned that we just talked about briefly is that the majority product from DNA,
*  from genes is recursive, is transcription factors, which feeds back onto the DNA,
*  which regulates the protein synthesis, and the next protein is another transcription factor.
*  That sounds eerily like recurrent neural networks, right? Feeding back. So these processes are,
*  one could make a very loose argument that they are, oh, what's the word? Not similar, not analog,
*  analogous in some fashion. Yeah, I agree. They are analogous. They clearly are.
*  You, those analogies are traced out in the Peter Stirling and Simon Loughlin book on,
*  right, in which they argue that compute with chemistry, it's cheaper.
*  I think they're spot on by that. I would add 10 orders of magnitude cheaper, right?
*  I think they don't slam just on how much cheaper, but they do these dynamic systems analogs. Now,
*  this same Akhla Pur guy has a brand new blog post. I just got, I just saw it yesterday,
*  day before yesterday, in which he takes up that proof of a universal function
*  approximator. And it shows, first of all, that it's not really true. It's only true on the
*  closed interval, not the open interval. So, but second of all, he revisits the argument. So,
*  all the processes that you're describing are dynamic systems forms. Yeah, yeah. And he revisits
*  why you can't really do computation with stored information with dynamic systems.
*  He has a much more sophisticated technique on this, take on it, anchored in a much deeper
*  understanding of the foundations of theoretical computer science. But my much simpler argument,
*  which I know he agrees with, is like those proofs said, well, what do we mean by a universal,
*  by a function approximator? A function approximator gets an input vector, and it generates an output
*  vector. Okay. That's the way a mathematician thinks about it. But it sure as hell not the
*  way a computer scientist thinks about it. Because there's no memory in that, right? And a computer
*  scientist is very aware that in your average computation, information comes in some of which
*  was acquired 50 years ago. As we sit here talking, right? As I'm summoning up the words from in the
*  English language, right? I learned most of them when I was less than five years old, right? So,
*  they've been rattling around in there now for 75 years. However, now I'm forgetting many of them.
*  Oh, it doesn't get better. Let me tell you. Dang it. I'm beginning to have noticeable word
*  finding problems. And for someone whose verbal facility was always one of their great strengths,
*  it's very painful. I'm sorry. Yeah. I couldn't, the other day I was explaining something and I
*  couldn't summon the word factorial. I wanted to say the Stirling approximation. I couldn't say
*  what it was an approximation to because I couldn't return the word factorial. Oh, geez.
*  Anyway, the point is that real world computations require memory because you get one bit of
*  information, you put it in memory, you get another bit maybe 10 days later, maybe a year later, maybe
*  20 years later, you put that memory and so on. If you look at most of what we do, it's putting
*  together at a given moment information that was acquired at many different times in the past.
*  And that's what brains, when you're talking about real, so I hope it's clear why this makes that
*  proof totally irrelevant, right? Because that proof assumed that all that information had been
*  very thoughtfully assembled for you by some genius and packaged into one humongous vector
*  and that we fed it to the computer and it generated in the neural net and then generated an output
*  vector. Well, of course, that's where you have to think about the system when it has no memory.
*  But that's, of course, just why in throwing out the memory, they threw out the baby with the bath,
*  right? Well, the memory would be in the distributed connections, right? The distributed weight,
*  connection weights. That's a finite state machine in the proper definition of a finite state machine,
*  which is not that it's finite. A finite state machine is a Turing machine that cannot read
*  what it has written. That's mathematically equivalent to the usual definition. But if
*  you're thinking about these things, it shows you the huge difference between a Turing machine and
*  a finite state machine. It can only go from state to state with some transition rule and
*  probability and so on. Let me hammer on this a bit. So if your iPhone or your mobile phone with
*  its camera were a finite state machine, then it would have stored in its wiring diagram
*  every picture that you're ever going to take with that phone.
*  I don't think so. You can take more different pictures with that phone than there are elementary
*  particles in the knowable universe. That's my definition of a true infinity, right?
*  Okay, so we didn't put all the possible pictures in the wiring diagram of that phone, right?
*  We put in something that would convert quantum catches to switch throwers, to memory elements.
*  And of course, then the phone immediately gets busy running some compression algorithm
*  because there's huge redundancy in the pixels. But a device without memory can't do any of that,
*  right? No memory, no iPhone. So just stepping back because often on this podcast, we talk about
*  the current successes of the deep learning folks. And a lot of that is being applied
*  to neuroscience to understand how brains function. And I know that you are aware of
*  the line of deep learning wherein from like Alex Graves and so on where external memory has been
*  supplied to the neural network. But the book Memory and the Computational Brain was actually
*  written before the quote unquote deep learning revolution when deep learning started to dominate.
*  So for fear that this diatribe could take the rest of the time.
*  I'll keep it short.
*  Yeah, you keep it short. I'm curious about your thoughts on the success and the ubiquity now of
*  deep learning and its application to understanding how neuroscience how brains might function.
*  Well, trying to keep it short, you remember them?
*  You don't have to keep it short.
*  But I know we all have this line from the graduate plastics.
*  Now, my wisdom distilled down to a very few words would be adversarial images.
*  Sure. But what happens when that gets solved? But okay, well, yeah.
*  When? Well, I have solved that. I should have done air quotes.
*  So the last time I checked, no solution was in sight. And it reflects a deep truth about how
*  those systems work. Right. Most people don't realize that when the image recognition
*  system inside Elon Musk's car warns the rest of the system that there's a stop sign there, right?
*  That system because it's a deep neural net. And because they don't know how to extract shape,
*  what it's really decided is like these pixels are stop signish.
*  This region of the pixels has the statistics of a stop sign. Right.
*  If you were to say, well, is it octagonal? The net would respond, what's an octagon?
*  What's an octagon? And even if you explain what an octagon is, the net would say, look, I don't do
*  shape. And at least I have noticed, and I think others will have noticed that the hype about we
*  were going to have auto self-driving in the next five years has died down very considerably,
*  because the adversarial images taught the malevolent smart, but malevolent high school
*  students of which there is too great a supply, how to go out and hack every stop sign in town,
*  right? With a, you get yourself a tape, you get yourself a crayon and you make various
*  graffiti on the stop signs and Elon Musk's cars will blow right through the stop signs. Right.
*  Okay. So, hey guys, I think it's wonderful that you got the system to work to where you do. I'm not
*  discounting this achievement, but when you start telling me this is how the brain
*  works and that means the brain has no memory, I say, I don't think so, because you can't do
*  deep learning. I taught Jay McClellan years ago and he and I have been arguing ever since.
*  He's one of the ones who's working on building math and reasoning into the network.
*  I keep telling him, hey, Jay, forget math and reasoning. Look, the ant and the bee do
*  dead reckoning. Why don't you try that? I want to see how dead reckoning works in a system that has
*  no memory. I've been taunting, I've been trolling him with that challenge now for 20 years.
*  He doesn't bite. Because I think like anyone, you look at dead reckoning and say, whoa,
*  we are going to have to store the current location. Right. I mean, there's no way of getting around it
*  and that's going to extend over hours. Well, and yet, okay, so over hours is a point you might
*  bring up again here because I wanted to ask you, first of all, whether you're aware of,
*  and then secondly, your thoughts on there have been deep learning networks paired with
*  reinforcement learning techniques in the AI world that have used convolutional neural networks
*  and used LSTMs that have done path integration in little maze environments, virtual maze environments.
*  Yeah. And that's not, pardon? Toy environments in which-
*  Okay. Yeah, yeah. Well, yeah, sure.
*  ... tile the maze. Come on. In order to make it fit into the reinforcement learning thing, they say,
*  well, look, here's how we represent the maze. Right? You see this tile, we tile it, right? And
*  then each tile knows, well, then it gets interesting. I think very few of them actually
*  give the tiles metric information. That is, I know that the A star algorithm, which is how
*  the Google Maps finds routes, of course has metric information, right? It's all there in the cost
*  function. So that's why Google sent around cars with GPSs, right? To record extremely precise
*  metric information all over the world. But in the ones that I've seen, the reinforcement learning
*  ones, they say, well, when you're in state one, you learn to do action one. And when you're in state
*  two, you learn to do action two. First of all, they don't seem to realize that this is essentially
*  identical to Clark Cole's theory. That's where when I say, hey, I was listening to this nonsense
*  60 years ago. But, you know, they don't put in any metric information. Come on. I'm a sailor. I'm a
*  navigator. I'm a backcountry skier. I ski alone in the backcountry. Hey, you know, you don't tile
*  the winter wilderness. You say, okay, I'm headed this way. The sun's over there.
*  You work the way navigation has always worked. What direction am I going? How far am I going?
*  However, the average human is easily lost in that scenario, whereas the average bee or ant
*  isn't lost, right? Well, there are plenty of humans aren't lost either. I'm by no means the only one
*  who does backcountry skiing even alone. And of course, Joshua Slocum sailed alone around the
*  world, right? Using totally traditional navigational methods, boasting with some good reason about his
*  accomplishments. But the reason people don't know how to do this in the modern world is they always
*  live in cities and they get from one place to another on taxicabs and subways. So they're never
*  called upon to do this. But when I was in college, I worked one summer for a month until I turned
*  them into the Better Business Bureau with Collier's Encyclopedia selling encyclopedias door to door
*  under the tutorship of a man who had been doing this all his life. And in those days, you sold
*  these in newly built suburbs, which had all these twisty roads and cul de sacs and so on. And
*  you came in and you went all around and so on. And this guy was intensely proud of the fact that he
*  always knew exactly how to get back out of there. And we would be driving around, I'd be totally
*  lost. And he'd say, which way is the entrance? I said, I have no idea. And he would point at me,
*  he knew which way it was to the entrance within 10 degrees, no matter how long we'd been in there.
*  So it's a matter somewhat of talent. Some people have more talent for it. But it's also a matter of
*  habit. Right? I mean, if you walked alone in strange foreign cities, maybe the first time
*  you got seriously lost, but you learn something from it. Now, when you leave the hotel and you
*  walk down and you get to the first corner, you turn around and look back. It's just what the bees do.
*  When they leave the hive, they turn around and look back.
*  But the fact that we can basically unlearn that skill and you'd have to learn it back,
*  it could argue multiple different things. The question that I want to ask you is if
*  you think that there could be multiple memory mechanisms. Obviously, quote unquote memory,
*  there are multiple types of memory defined and that is continuing to change what kinds of memory
*  that we have. So, you know, for example, something like episodic memory, where you can recall
*  an event, right? And I know that you don't care about mental phenomenon.
*  I believe only in episodic memory. Christel, Jonathan Bristol has demonstrated it beautifully
*  in rats. And of course, Nicky Clayton and Tony Dickinson demonstrated it spectacularly in those
*  food cashing birds, right? I'm totally on board with episodic memory, but it's all numbers.
*  Right. Yeah, okay. So, I'm thinking more of the-
*  Location, right? Amount, texture, what goes into an episode, right? Numbers.
*  So, to your mind, there is one memory mechanism in all brains?
*  That's what I think is by far the most likely. Of course, I don't know and of course, it's
*  conceivable that there are different learning mechanisms. But once you grasp how simple and
*  how fundamental memory is, memory understood the way I understand it, right? Which is just
*  Shannon's memory is a medium of communication. It's the machinery, the medium, the material stuff
*  by which the past communicates with the future. Right? Now, Shannon, in his opening paragraphs,
*  pointed out that, hey, look, if you're in it, if communication is what you're about, and he might
*  have stood up and said, I'm a communication engineer, and they pay me here at Bell Labs
*  for communication. If communication is what it's about, you don't give a shit about the content.
*  Right? That was a truly profound insight. And I don't see why that doesn't apply just as much
*  to the brain as it does to computing disks. Right? When I go buy a new stick of gum to
*  save a terabyte of information, right? They don't ask me, well, are you going to use this for
*  word processing or spreadsheets or MATLAB files? It's all just information when it comes to
*  communication. And memory is communication. So it's a really, I think DNA is again, look,
*  evolution solved this problem once. It found a really good solution. That was probably 2 billion
*  years ago. It seems animals have been navigating since the pre-Cambrian, we can tell just from
*  their tracks in the mud. Right? So you can't navigate without a map, without a memory.
*  All these. So in one of your other questions, you asked about how about skills, right?
*  Motor skills. Yeah. If there is going to be a case where it's different, then I would say, well,
*  that could easily be where, but I kind of doubt it because I think skills can be, and I'm a student
*  of the motor literature. I've written about it at some length occasionally. I think skills can be
*  learned as parameter tuning. That is you've got a system that's an incredibly versatile
*  memory system. This stuff was all in my first book. And the best part-
*  The organization of learning? No, the organization of action. There's another book
*  10 years before that. Okay. Got you.
*  But I, and what I'm saying is, this is not original with me. This is very much there in the literature
*  that was in that book. And it's there in say, even martyrs work, right? With the stomatogastric
*  ganglion, right? You've got this set of oscillators, a very simple circuit, right? But there's
*  oscillators and some feedback. Feedback is important. Don't get me wrong, but only
*  under certain circumstances. And there's of course inputs, inhibitory inputs and what have you.
*  But the way the system is basically controlled is by signals that come down from higher in the
*  nervous system and adjust the parameters. Right? So, and parameters, we're back to numbers, right?
*  What are parameters? They're numbers. So I have a memory from, well, I don't know if it was three
*  or four years ago. So my memory for time is not great, but we held, my wife and I held a chili
*  cook-off at our house. And I won't tell you how my entry did. I can tell you I didn't win the trophy,
*  but there was a particular entry that tasted a lot, the flavor was dominated by celery.
*  And I remember this and I think it got last place. It was just overwhelming celery.
*  She was a vegetarian and kind of a holistic medicine also person. But anyway, I was talking
*  to her about it the other day and I can remember that she felt a little sad about this. But I have
*  this episodic memory and we don't need to go on about episodic memory. I have this experiential
*  memory of what that was like and the flavor of the celery and me not winning also, you know,
*  and all that kind of, and I can picture our house and stuff. So I guess the question is,
*  does the intracellular numerical mechanism account for that type of experiential memory?
*  Well, not without some spelling out of additional hypotheses. So, but I did address your question at
*  considerable length in the near final chapter of my 1990 book entitled the Unity of Remembered
*  Experience. That book has been cited many thousands of times, but as near as I can tell,
*  no one ever read that chapter. If they did, they dismissed it because it addresses exactly the
*  question you're posing. How do these diverse aspects of an experience and the experience
*  extends over time and space and involves many different components, the taste of the celery
*  and so on. How do they all get knit together? And I argue there that first of all, they're
*  not knit together by associations because that brings you into an explosion, right? You have a
*  combinatoric explosion, you get this net of accountably many associations. The unity, the
*  phenomenological unity arises in the process of recollecting the experience and that you use time
*  and place indices, all memories on this story have a timestamp and a location stamp. And I present,
*  I review experimental evidence for that claim. And this is now of course 30 years old.
*  And there's more evidence for it of a somewhat similar nature has emerged
*  in the intervening 30 years. But I spell out in some detail how you could use if every memory,
*  if they're all in separate bins and separate neurons and so on, but they all have as one of
*  their fundamental components, a time and a location stamp, which plays the role of the
*  the operon in DNA, right? It's the address. Then you can move among these memories in
*  recollecting an experience that is you because episodes are always located in at a time and in
*  a place they're located in space time, right? And so you can retrieve the facts if using those
*  indices. As I read the hippocampal literature, the neurons, I think, I see. I think someday there
*  some well, I actually I can I can tell the guy who died, Howard, I can bum,
*  I can Howard, I can bum, he was starting to argue this same sort of thing. And I wrote him, I said,
*  Hey, Howard, go read my chapter. This is what I was arguing 30 years ago. And he wrote back and
*  he said, Yeah, I've been reading it. You're right. You were. I guess I'll set you in the in the
*  future. And then he died. Totally aside. Yeah, but this happens over and over. And you've been
*  around long enough to have experienced this personally, where new ideas are not new ideas.
*  They've been written about it buried in chapters. So how many times has this happened to you?
*  Oh, I don't get uptight about it, for one thing, as I because I'm a sinner. I'm both a sinner and
*  sinned against as witness that you're asking us right the Chomsky. Yeah. And and I, I wasn't angry,
*  I just I thought Howard and I could make common cause here. Right. And I was deeply disappointed
*  when he died. You got you got to stay alive. You got to stay with me here.
*  Yeah. So I think that's the general answer. I mean, take celery for a moment for a specific
*  thing. So it has qualia of case, but then notice color, right? And there's one thing we've known
*  now for more than a century color is represented in our brains with three numbers. And recently,
*  the story for both taste and odor has emerged the same. They're all vector representations,
*  the dimensionality of the spaces is higher. But these days, Doris, so and lots of people are
*  pushing vector representations really hard. And of course, vectors, they're just strings of numbers,
*  right? And, and they represent faces and Chuck Smith has argued that the same story is true for
*  odor, even in drosophila. So again, the celery, it's all numbers, right? It's the tastes are
*  represented in a four dimensional space colors are represented in a three dimensional space
*  faces are represented in a 50 dimensional space. You get the idea. Two more questions and then I'll
*  let you go and I appreciate you hanging around with me. One. What is the role of synaptic
*  plasticity? No one knows least of all me. I thought I assumed that you were going to say
*  encoding, writing. I honestly have no idea. I since I literally believe that an associative
*  bond never formed in the brain of any animal. And since the plastics in apps is transparently
*  conceived of as an associative bond, right? I certainly don't think that's what they are.
*  Could they play a role in the computations carried out and signals? Sure.
*  You have any seems likely that they probably do. But do I have any good ideas what that role
*  might be? No. Does anyone else? I don't know. I don't follow the literature very carefully. But
*  everybody seems so hung up on the idea that they're associative bonds that I think until they dig
*  themselves out of that conceptual hole, they're never going to find out what they're really about.
*  What's keeping you up at night these days? What are you thinking hard about that's just beyond
*  reach to you? Oh, well, how to get the molecular biologist to realize that
*  Frederick O. Hudson has offered them the world on a plate. How's that fight going? Very slowly.
*  Oh, and they're hung up for what is best I can make out or quasi metaphysical reasons. So for
*  example, don't ask Ryan, who he'll be he'll be on the next episode. Okay, so you can follow up on
*  this. So you can ask him what his problem with Randy story is, because he and I have been arguing
*  for us. But he I never heard of him. I had given talks at MIT, where I imagine he was present. And
*  I met Tony Gow a few times, but on whose lab he came out of. But he emailed me that the day it was
*  unembargoed his science paper when he was still in Tony Gow's lab, showing that they could make
*  the plastic synapses go away and the information was still there. And the email said, I think
*  you'll find this interesting. And I wrote back, Yes, I find this very, very interesting indeed.
*  Okay, so he and I agree that the information isn't stored in the synapse in the plastic synapses.
*  And he admits that he does not have a story about how the information is stored.
*  The Ngram. He's all focused on these cell assemblies. He's focused on this sparse coding.
*  And I say, Yeah, Thomas, Thomas, that's all very interesting. But we both think that the real name
*  of the game is looking for the Ngram. And those cell assemblies, they aren't the Ngram. Your own
*  work shows that it must be inside those cells. I can't get him to go to and it's all hung up about
*  information. He doesn't like the idea that we have to think in terms of Shannon information.
*  He's read Dennett and he believes that there's in semantic information. And I know Dennett very
*  well. We have a lengthy email correspondence in which I'm trolling Daniel St. Daniel.
*  Fact is, you have no idea what you mean by semantic information. And Dennett more or less admits
*  that that's true. I said, Thomas, you know, Shannon information is the only game in town.
*  Semantic information is just philosophers hand waving.
*  So but but the recent optogenetic work where, you know, particular cells and networks of cells,
*  they can excite the they can excite behavior that is informed by the stored information.
*  They've shown that over and over again. And now people are showing it in the hippocampus, right?
*  But that doesn't change your story. It doesn't change your view.
*  Because it doesn't even address the question I'm posing, which is,
*  all right, you excite those cells, and the output signals from that cell is informed by acquired
*  information. Where is it? Did some neighboring cell say, Oh, Joe, you need to know this,
*  right? Or as your own experiments tend to show, they got that information from inside themselves.
*  Well, once you get inside a cell, it's all molecules, right? Very big, complicated molecules
*  and networks of molecules, networks of molecules, even railroads and structures build, I mean,
*  the ribosome, for example, but, but basically, we're down to the molecular level of structure,
*  right? And, and I keep saying, Tomas, your own work shows that that's the case, I cannot persuade
*  him. And it's just driving me nuts. I mean, your work is five or six years old now. And I thought,
*  Oh, wow, this is the breakthrough. Now all those insanely ambitious molecular biologists, they'll
*  jump on this. And they'll trace that cascade. And they'll use this ability to, to observe
*  single molecules fluorescing inside individual cells. I mean, they've created the most astonishing
*  tools. And once they get to the end, then they can slice and dice it with CRISPR and so on. And they
*  can find out the code. It seems to me like this is so obvious. I cannot.
*  Well, Randy, you've learned multiple things throughout your career. Why don't you just go
*  learn molecular experimental molecular biology and start on it?
*  And, you know, it takes a long time to become a molecular biologist. And besides that, I would
*  have to get a grant and so on. I mean, that's the other thing. And there's no way with somebody
*  with my background could get a grant. I mean, this effort, although it seems to me obvious,
*  what the general strategy is, I don't mean to minimize how difficult it would be. Yeah.
*  And the kind of resources I mean, you need the kind of money that only a molecular biologist
*  can get. I mean, people like me, we get the rounding error in molecular biology grants, right?
*  So you're not going to pursue that cascade with $20,000 a year, right? It's going to be more like
*  $5 million a year, right? And it needs to become competitive, which it always does in molecular
*  biology. That is, if one or two of the smartest young upstart started doing this, then the rest
*  of the field would say, Oh, shit, maybe I'm missing the train. Maybe, maybe I better get
*  on that train before it leaves the station, right? I'm trying to stir up that kind of anxiety.
*  But so far, I've not succeeded.
*  Well, you've been driving your train for a long time along those those very tracks. So
*  this is a great place to leave it. I'm gonna play that last little clip there for Tomas when we
*  talk perhaps and respond. Thank you for the very, very fun conversation. Keep up the good fight,
*  Randy. I appreciate it. I enjoyed this enormously. Thank you.
*  Thank you for your support. See you next time.
*  The
*  Art
