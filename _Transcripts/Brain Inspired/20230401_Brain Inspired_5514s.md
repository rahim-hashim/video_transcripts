---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 5514s
Video Keywords: []
Video Views: 977
Video Rating: None
---

# BI 164 Gary Lupyan: How Language Affects Thought
**Brain Inspired:** [April 01, 2023](https://www.youtube.com/watch?v=qJlK1dKYWZU)
*  We think we're all talking about the same things, but often we're just sort of using
*  the same words, right?
*  And maybe often reaching similar understandings, but underneath there's this vast variability.
*  It always struck me as strange to think that, okay, if you have no grounding to the external
*  world, you can't have any meaning at all.
*  But then, okay, how much grounding do you need?
*  Like if you put in a little bit, now suddenly everything is grounded out and then meaning
*  just magically appears?
*  That doesn't seem right.
*  It doesn't really make sense that you can take a thought and beam it into someone's
*  brain and have that thought make sense to the other person.
*  But of course, with language, that's kind of how it is.
*  This is Brain Inspired.
*  I'm Paul.
*  Welcome, everyone.
*  My guest today is Gary Lupien, who runs the Lupien Lab at University of Wisconsin-Madison,
*  where he studies how language and cognition are related.
*  In some ways, this is a continuation of the conversation I had last episode with Ellie
*  Pavlik in that we partly continue to discuss large language models.
*  But Gary is more focused on how language and naming things, categorizing things, how that
*  changes our cognition related to those things.
*  How does naming something change our perception of it, and so on.
*  He's interested in how concepts come about, how they map on to language.
*  So we talk about some of his work and ideas related to those topics.
*  We actually begin the discussion with some of Gary's work related to the variability
*  of individual humans' phenomenal experiences, our subjective experiences, and how that affects
*  our individual cognition.
*  For instance, some people are more visual thinkers, others are more verbal.
*  And there seems to be an appreciable spectrum of differences that Gary is beginning to experimentally
*  test.
*  And of course, we cover a lot more topics related to language and cognition.
*  Show notes for this episode are at braininspired.co.
*  slash podcast slash 164.
*  On the website, braininspired.co, you can also learn how to support this podcast to
*  help keep it running.
*  Thank you in advance if you make the decision to take that generous action.
*  Thanks to Gary for being generous with his time.
*  And here he is.
*  So I was in a, let's call it a disagreement with my wife the other day.
*  And I was tasked with expressing my feelings to her.
*  And of course, I failed, as I always do, because they're ineffable and words don't really do
*  justice.
*  You know, I felt limited.
*  If I started using words to describe what I was feeling, it was going to limit the actual
*  experience that I had had or was having.
*  And I feel, maybe this whole time you can just disabuse me of this notion, I feel that
*  words are limiting in terms of cognition.
*  Yes, they're highly abstract, but they don't capture the essence of what I'm feeling.
*  You know, feelings are a whole other bag of tricks here.
*  But why is it that I think that the most interesting things are ineffable and words don't capture,
*  like categorizing it using words is maybe limits it, if that makes sense.
*  Yeah, yeah, yeah.
*  The way I tend to think of it is that the currency of language is categories.
*  And that makes it really great for conveying certain types of information and really bad
*  at conveying other types.
*  And so whether language is good for communicating depends on what one's talking about.
*  Now when it comes to feelings, or for example, faces, some faces are notoriously hard to
*  describe in language.
*  And it's not just a problem of English.
*  No language is good at describing faces because what distinguishes one face from another,
*  for the most part, is not categorical.
*  And so the best we can do with language is, and this is very telling of how language works,
*  is when it comes to describing a face, is to remind someone of a face that they know,
*  and then say, well, it's kind of like this person, but, and then put a little, you know,
*  nudge them in some direction, but older, or friendlier.
*  We're good at interpreting something like friendly.
*  It's interesting that we are good at that in terms of having some visual appearance.
*  Despite this, we figure out ways, and this is what a lot of what good writing is about,
*  of conveying things like feelings, visual descriptions, using language.
*  But it's hard.
*  Doing that effectively is hard work.
*  I think of language as a series of cues that we exchange with one ourselves.
*  It's little cues for constructing mental representations.
*  And a lot of what we talk about is actually, it lends itself to kind of categorical cues
*  that language is really about.
*  But yeah, I mean, and my other response is, well, compared to what?
*  So when it comes to conveying our emotions, well, what's the alternative?
*  I mean, you can do a lot with your face, but it doesn't have that sense of being about
*  something in particular, right?
*  So, you know, in many cases, language might be the best we can do even for conveying kind
*  of ineffable things.
*  So my wife is not dumber than me just because she uses words to express things that I can't?
*  I mean, well, no.
*  But is it do you feel like it works?
*  Like, is from her able to communicate?
*  Yeah, she's able to communicate her emotions with her feelings.
*  And yeah, she's great at it.
*  And I'm terrible at it.
*  And, you know, I mean, I think it's an angel story.
*  But yeah, there's skill in, you know, on your end as well, right, in interpreting it.
*  So she might be really good at it, but like it takes skill to to be on the on the receiving
*  side, on the comprehending side and actually taking those words and constructing something
*  that is meaningful to you.
*  And presumably, right, even if it's meaningful to you, but it's totally different from what
*  she was intending.
*  Like, we'd say that that's not a totally successful act of communication.
*  But yeah, but often we can kind of meld our minds in that way with language.
*  So I just waited out in deafening silence and then eventually it goes away.
*  I thought that was the right thing to do.
*  But OK, so we have, you know, a ton of stuff that we can talk about it.
*  Maybe I'll I don't know if I want to start with inner speech.
*  I was going to bring this up later.
*  I was telling I had Ellie Pavlik on the podcast and I was telling her that I was going to
*  have you on and that you're interested in this phenomenal variability, like the variability
*  in all of our phenomenal subjective experience.
*  And part of that is our inner speech that I know that you're interested in.
*  And I was telling her that I feel like when I find myself talking to myself during a task
*  or something, using language in my head, I feel dumb.
*  This is not all about me being dumb, but, you know, a good portion of it is.
*  But I feel like why am I talking to myself?
*  That seems in the same token.
*  You know, I remember my dad back when we didn't have iPhones, but there were GPS systems that
*  you could put in your car and they were specific for GPS and they would talk to you and he
*  would talk back to it.
*  And I thought, oh, man, that's unfortunate.
*  So so is inner speech a sign of intelligence or the opposite?
*  And then we'll talk about variability in our fundamental experience.
*  I suppose.
*  So I had a paper that I wrote a while now ago and as a postdoc about talking to yourself
*  in the context of visual search.
*  So can repeating the name of something help you find it?
*  And for whatever reason, like a year after it came out, it suddenly started getting all
*  this media attention.
*  And even now, like a dozen years later, like when you Google talking to yourself, like
*  this stuff comes up and the framing is often you're not crazy if you talk to yourself,
*  right?
*  Science has shown.
*  And it gets away from the core narrative.
*  It's like, you know, if you talk to yourself, it means you're a genius.
*  It's like, that's not what the paper is about at all.
*  But I think I think there is.
*  Yeah, there's well, there are two things.
*  There's the actual overtly talking to yourself and that, you know, at least in our culture,
*  that's discouraged and that's kind of often seen as like, oh, you know, is there something
*  wrong with this person?
*  Because we expect it to be inhibited, right?
*  And then there is inner speech, right?
*  The kind of covert experience that really a large majority of people have.
*  And one thing I've learned since we started studying it is that, you know, we all tend
*  to think, reflect on our experiences.
*  The common thing to do is to think that, well, what we have is the typical thing.
*  And then you realize, you know, that, well, there's a distribution and you're somewhere
*  on it.
*  And so I thought my inner speech was typical, but it seems that it's kind of like on the
*  low end, you know, there are questions that on these questionnaires where like most people
*  put themselves as a 10 on a one to 10 scale, like that they do this constantly.
*  And I put myself as something like a five, but I thought that that's where most people
*  were.
*  So I think intuitively it seems kind of silly.
*  Like how can you learn something from yourself that you didn't already know?
*  But of course that's the wrong way to think about it because there's no central you, right?
*  That knows everything.
*  And that's why, you know, when you're writing, like everyone seems to have this experience,
*  right?
*  By writing, it helps you organize your thoughts.
*  And so I think of talking to yourself as a similar type of thing.
*  You're linearizing things, you're making connections that you're obviously capable of making, but
*  may not have made prior to actually kind of pushing it out and back in.
*  So Dan Dennett has this in his Consciousness Explained book, here's this little figure
*  of, I remember the caption, this cognitive auto-stimulation.
*  And it's like a little schematic brain with like these kind of semi-connected parts.
*  And then, you know, there's an arrow that comes out of the mouth and back into the head,
*  right?
*  Andy Clark has also written a lot about this idea.
*  So yeah, I mean, I think of language as a technology.
*  And when we talk to ourselves, whether overtly or covertly, right, we're using that technology,
*  you know, to help ourselves think through things.
*  And it's good for some things, less good for other things.
*  What is it good?
*  I mean, so I appreciate language as an abstraction.
*  And a lot of your work has shown that labeling things helps you do things faster and helps
*  your cognition about those abstract general concepts.
*  But I feel like the majority of stuff that's at least interesting to me, labeling, one
*  thing about abstraction is it takes away details, right?
*  And so you're kind of simplifying everything to a degree that might hinder thinking about
*  it.
*  And so I'm not sure how to think about this, like where you think the balance is.
*  Yeah.
*  I think about it being less about removing details and more about highlighting dimensions
*  or details that are relevant for a certain task.
*  So you might, for example, realize that there is a connection between two situations or
*  two processes, that there's some underlying similarity.
*  And it helps you kind of reach some conclusion, draw some inferences that you otherwise wouldn't
*  make.
*  And so you are, in a way, ignoring certain details.
*  I think it's rare that we actually get rid of them.
*  We hang on to lots of things, even if they're not relevant to current tasks, because they're
*  relevant for other tasks.
*  So for example, if we have a task of understanding what someone's saying, so knowing what words
*  they're saying, it might not be relevant what their voice sounds like, but you can't help,
*  but also attend to the qualities of their voice.
*  Because at the same time, those things are important for identifying where they are and
*  where you should turn your head to face them, who they are.
*  And those kinds of things can help you actually can help feed into the meaning because you
*  can deploy different priors depending on the last conversation you had with this person
*  or what you think this person is likely to know based on the specific jargon they're
*  using.
*  And all of that kind of becomes relevant, even for something as simple as knowing what
*  word is this person saying, going from the raw speech to some more invariant representation.
*  So I don't think we're really throwing away the details, but yeah, we're weighing different
*  dimensions.
*  And so yeah, I'm happy, by the way, to circle back to inner speech later, because I think
*  there's a lot to be said about that kind of variability and what it means about studying
*  connections between language and cognition.
*  Oh, okay.
*  I was about to bring us right back to that, because I mean, this kind of ties into the
*  idea of the dimensionality of language, right?
*  So we all have different phenomenal experience.
*  And one way to look at that is that our phenomenal experience is important.
*  And however different, however subtle those differences are, whether or not they make
*  a difference to our cognition is something that you could tell me and you know, what
*  you've come to think about this.
*  But then I also thought, well, it may be that we all have the same high dimensional stuff
*  going on under the hood, but our phenomenal access to various parts of it differs.
*  And that's what leads to the differences in subjective experience.
*  So maybe you can just elaborate on that.
*  That's a ridiculous idea.
*  No, it's not a ridiculous idea.
*  And it's really an empirical question.
*  There's probably some of both.
*  I mean, that's kind of a boring answer.
*  So as far as variation in visual imagery, inner speech, there's certainly work suggesting
*  that in some cases, the best explanation might be different access.
*  But there's also work showing different performance on objective behavioral tasks.
*  So we find, for example, differences between subjectively reported inner speech, relationship
*  between that and how well people can judge whether two words rhyme.
*  They're kind of what's called verbal working memory.
*  There's also lots of correlations between subjectively reported inner speech and other
*  aspects of subjective experience that we might or might not take at face value.
*  So for example, earworms, you know, getting songs stuck in your head, very common experience.
*  People who report not really having much inner speech also report that they know what this
*  is about, but they report that this doesn't happen to them very often.
*  Something that, especially in the college student population, this experience of thinking
*  about a recent conversation you've had and thinking about like, well, maybe I should
*  have said this and that.
*  Huge endorsement of how often does this happen to you?
*  Most people are saying all the time, all the time.
*  People with less inner speech are saying, eh, you know, not much.
*  Right?
*  I missed the, what about the earworm?
*  What was the relation between getting stuck in your head and inner speech?
*  Just that people with less inner speech are less likely to experience it.
*  So I wouldn't say never, but yeah.
*  But there's absolutely value in trying to understand the sort of cognitive profile,
*  differences in cognitive profiles using objective assessments.
*  So more of this has been done in the visual imagery realm than in the inner speech realm.
*  And there you find really interesting patterns where in some cases you find objective differences.
*  So different patterns of recall memory, for example, less visual imagery, less details
*  in recall, even when that is the task, recall in as much detail as you can, you know, some
*  experience.
*  In some cases, no differences in the kind of gross level performance.
*  But then when you start going deeper into, well, how are people doing the task?
*  What are the correlations between tasks?
*  You find differences suggesting that people are using different strategies and it's in
*  line with what they report.
*  So it's a case where we should take people's self-report seriously because, you know, they're
*  doing some memory tasks and you ask them, well, how did you do that?
*  And they tell you how they did that.
*  And it's not how people with typical visual imagery do it.
*  And then you sort of do a follow-up study.
*  Well, you know, if they did it using this kind of strategy, then they should find interference
*  with these types of stimuli.
*  And you find indeed that the results bear it out.
*  So these differences have consequences.
*  But it's lots and lots of unknowns.
*  Another relevant area is synesthesia, where at one time people thought, oh, you know,
*  yeah, people are having these different phenomenal experiences, but they're not really like perceptual.
*  And then it's not that hard to design some actual psychophysics studies to test whether
*  people's attention, for example, is being kind of involuntarily grabbed by, you know,
*  where someone who has various forms of space-time synesthesia, where, you know, thinking about
*  a certain month is associated with a certain part of space.
*  And then you can see that indeed, unlike people who just, who don't report having this phenomenal
*  in the synesthetes, you cue them with a month and their attention kind of automatically
*  goes to that part of space, even when it's completely irrelevant to the task.
*  Yeah.
*  So what are you thinking in terms of how wide the variability is in our interdifference
*  in our differences between people in their subjective experiences?
*  Is it a subtle thing?
*  Is it a wide landscape?
*  I think it's relative to our expectation.
*  My hunch is that it's much more than we expect.
*  I stumbled on this video just yesterday.
*  I can't believe I haven't seen this before.
*  It's a bit of Richard Feynman.
*  It's like a six minute clip called Ways of Thinking, where he makes this point that,
*  and I'll post a link to it or something.
*  People can watch it themselves.
*  I'll link to it.
*  Yeah, sure.
*  Yeah.
*  He talks about kind of how some experiences in his life that led him to think that there
*  is this huge variability in how people experience different types of thought, even when they
*  come to the same conclusion, right?
*  And that we think we're all talking about the same things, but often we're just sort
*  of using the same words, right?
*  And maybe often reaching similar understandings, but underneath there's this vast variability.
*  And it can be studied experimentally.
*  And so one thing that excites me so much is that it really is an empirical question.
*  And I think one angle we've taken is focusing on this hidden aspect where these kinds of
*  variability that seem to exist that people are unaware of, because there's lots of variability
*  in behavior that we all know, right?
*  We all know that some people go to bed later than other people, morning people.
*  The reason we know this is we get lots of feedback from the world.
*  We know that people have different food preferences, right?
*  And so there is a tendency even there to think that others are more like you.
*  If you like chocolate, you think more people like chocolate than if you personally don't
*  like chocolate, right?
*  But when it comes to these hidden differences, right, like visual imagery, synesthesia,
*  inner speech, one can compare notes.
*  One can study it, but we tend not to.
*  And we just project our own experiences onto the world.
*  And one reason why I think we can keep going around about our life and not realizing that
*  people have these different experiences is that their consequences on behavior are not
*  as big as one would expect because it's a more robust system.
*  So if there were lots of things that really, really required vivid visual imagery, then
*  people who didn't have vivid imagery wouldn't be able to do those things.
*  And they know that.
*  But in fact, a lot of the things that we assume require imagery, actually there are many ways
*  of doing them without the use of imagery.
*  And so it kind of opens the door to studying this diversity of solutions.
*  We draw in this paper, we have hidden differences.
*  We draw a comparison to what's been called cryptic variation in genetics.
*  You do gene knockouts and you find that for a lot of things, you don't find any observable
*  effects on behavior.
*  And the question is, why should it be that way?
*  Why have this redundancy?
*  One answer is that while you have this redundancy to ensure that different developmental trajectories
*  can all lead to a functioning organism, that if you had to do things in a very, very precise
*  way, you would not have sufficient robustness basically.
*  And so as a consequence, you find that there are multiple pathways.
*  And so knocking out various genes often doesn't have any consequence because they're just
*  one kind of path of many to getting that development right.
*  And I think of these hidden phenomenal differences as kind of repeating that same process, but
*  at a higher, at the next level where, okay, you have a functioning organism and you have
*  to maybe in your culture learn to read or learn to do math.
*  And well, there are actually many ways of getting there.
*  And so despite different starting points and different trajectories, you can't get there,
*  but you don't necessarily do it in the same way.
*  I had Dean Buonamano on the podcast a long time ago, and I don't remember how, but I
*  later learned that he has aphantasia, I believe is the term for it, where he doesn't have
*  any visual imagery.
*  And I think that is so insane to me to be able to think without visual imagery.
*  But that's why I was asking about is it just a matter of whether we're accessing it phenomenally
*  or whether it's actually going on under the hood and we don't really know about it or
*  you know, I guess this is the multiple-realizability issue.
*  Yeah, yeah.
*  I think for certain kinds of questions, the access question might not really matter, right?
*  If the work is being done by the part that we are conscious of, by kind of interacting
*  with the sort of visual images that we consciously experience, then even at some lower level,
*  it's an identical system, right?
*  Not having phenomenal access is what might make the difference.
*  Well, that's what you're finding is you're finding these behavioral differences based
*  on whether someone is having phenomenal access to it.
*  Yeah, yeah, yeah, exactly.
*  So but it's not to say, right, that these differences in phenomenology need not imply
*  that visual processing in some people is fundamentally different.
*  I don't think that's the case.
*  Yeah.
*  But, okay, yeah.
*  So would the conclusion be that consciousness has a function?
*  Oh, yeah, I think absolutely consciousness has a function.
*  So I sort of reject the zombie thought experiment, right?
*  Sure.
*  Logically, of course, we can think of such a creature, but I think someone who is unconscious
*  without the phenomena would not just behave in all the same ways.
*  Yeah, but I also like on the other hand, I think there's absolutely such a one could
*  make the mistake in the other direction and put too much too much weight on conscious
*  experiences.
*  Whereas in reality, a lot of these are, you know, post hoc rationalizations.
*  And the reason we do something isn't.
*  Yeah.
*  So should I feel okay about having inner?
*  Should I be talking to myself more internally or externally or less?
*  What should I be doing?
*  Well, okay.
*  So one thing that we've been really interested in is the relationship between language, both
*  publicly used language, but also inner speech and kind of aligning our minds, right?
*  So Andy Clark and I have this essay in Aeon about telepathy, kind of the thought experiment,
*  right?
*  We both have this intuition that, you know, it doesn't really make sense that you can
*  take a thought and beam it into someone's brain, right?
*  And have that thought make sense to the other person.
*  But of course, with language, that's kind of how it is, right?
*  We have words that are supposed to denote some sort of thought and we use them and then
*  the other person, you know, understands those words are meaningful to the other person to
*  some extent, right?
*  And so if you can beam words from brain to brain, right, that would sort of work, but
*  that's not really telepathy.
*  That's just like fancy texting, right?
*  That's not that interesting.
*  The whole point is of telepathy, of the trope of telepathy is that you can take language
*  out of the loop and be able to communicate with someone who doesn't share your language
*  with an alien, whatever.
*  And so, you know, we argue that we have no reason to think that this would work.
*  But that language may, it could be that that's the best we have, right?
*  And that it is what allows us to align our mental states sufficiently to achieve at least
*  some level of understanding.
*  And so the idea, there's an experimental angle to this question, which is if people use more
*  language, are they more aligned?
*  And so we do have some preliminary data showing that people who report using more inner speech
*  are more similar in their responses to things, in their similarity judgments.
*  They are sort of more aligned, which is what you would expect given that language is this
*  categorical system.
*  And so if you are kind of thinking more categorically, whatever that means, you're more likely to
*  align because it's easier to align on categories than on particulars.
*  And yeah, so we're exploring this idea.
*  And so one implication is that using more inner speech might cause you to sort of align
*  more with other people, which, you know, if you are trying to be wildly original and express
*  some idea that is as new as possible, maybe that's not what you want.
*  If you want to express an idea in a way that can be understandable to the most people,
*  maybe that is what you want.
*  So it depends.
*  How would this, if we had brain-to-brain interfaces, right?
*  I mean, would that just further the, I guess, would there be more particulars that were
*  aligned in that case?
*  Or, you know, where we didn't have to, where we had this telepathy, it's not telepathy,
*  it's actual brain-to-brain interfaces at some degree, to some degree, right?
*  Yeah.
*  I mean, in this essay, in the second half, we sort of explore the idea of, you know,
*  if you just had this kind of as an implant, you know, when you're an infant or something,
*  you grow up with it, both of us can imagine that, you know, we're really good at taking
*  in new channels of information and just making them work.
*  And so there's lots of work even, you know, with adults on sensory substitution and just,
*  people are very flexible in learning to use these new channels of information.
*  But I think it would be a learning process, just like learning language is this protracted
*  learning process where over time you sort of align with other people and you learn how
*  to use it.
*  And so, I mean, this is pure speculation.
*  I think with this sort of brain-to-brain interface, it would be sort of like that, right?
*  Just like we learn to, you know, use the expression on someone's face together with what you're
*  saying to kind of build a larger, more multimodal meaning.
*  So you can imagine adding to that some channel of, you know, the flow of neural information
*  that would help you kind of build rapport and maybe disambiguate certain things, add
*  details to certain things.
*  But the question of, you know, so let's say, right, you want to beam a thought to me about
*  your experience after watching some kind of movie, right?
*  Your experience of that movie is based on all sorts of other memories and other movies
*  and, you know, your likes and dislikes and all of this stuff.
*  And so for that to make sense to me, like, would you in essence have to beam all of your
*  memories, right?
*  Because that movie experience is contextualized within everything else.
*  And so an isolated mental state, that's why it wouldn't really have much meaning outside
*  of the context of everything else in your head.
*  And so with language, we can decontextualize it to some extent, but, you know, that's why
*  it's hard to communicate about things like feelings because they're much more embedded.
*  Yeah.
*  So, but if I'm describing my experience of a film or something to you, in some sense,
*  it's nice to use language, which is this low dimensional abstract thing, because instead
*  of imparting my experience, what I'm doing is I'm allowing you to form your own experience
*  based on my low dimensional description, right?
*  So it's so that you can move through your own world and understand it in your own way.
*  And that way it's kind of special, kind of beautiful.
*  Yeah.
*  Yeah.
*  Yeah, absolutely.
*  And so Mark Dingamon's also from a few years back has a nice, I think it's published as
*  a chapter on telepathy and taking a different angle where a common treatment of telepathy
*  treats it as this sort of a brain dump, right?
*  Like one person transmits a thought or some series of thoughts to another person, right?
*  Whereas actual communication is this interactive process and we make meaning together.
*  And there's also something that he studied a lot is conversational repair.
*  So it's not a smooth process.
*  So we ask, huh?
*  And we raise our eyebrows and we realize that what we're saying doesn't quite make sense
*  given the flow of the conversation and we backtrack and we say, and that's an inherent
*  part of kind of meaning making.
*  And a single channel kind of direct communication wouldn't work that way.
*  And so describing a movie, right, you could imagine it as a back and forth, right?
*  And that makes it more of what you're saying.
*  It's sort of you're interfacing with the other person's background knowledge and experiences
*  and you tailor the message to them.
*  Yeah.
*  Yeah.
*  We don't have to perseverate on this, but I keep coming back to this thought about inner
*  speech and language and the relation between language and cognition.
*  And wasn't it Albert Einstein?
*  We always have to talk about Einstein.
*  He's the classic example.
*  Wasn't it him that didn't speak until he was 10 or something like that?
*  Like his language development was super late.
*  Am I wrong about that?
*  I've heard the same story.
*  I don't know about 10.
*  I feel like it's one of those like, you know, words for snow examples where every iteration
*  number goes up and up.
*  But yeah, I've heard that too, that he was like 50.
*  He was 50 before he started speaking.
*  Yeah.
*  Yeah.
*  But then I thought, well, he's a good example of someone who I suppose thought very spatially
*  and he's the go-to for an example of someone who's brilliant, right?
*  He wasn't fettered by language.
*  Yeah.
*  I mean, natural language is good for certain things, right?
*  And you know, math is not a natural language, right?
*  And so there is, well, so I think there's a reason why math is difficult for us, for
*  most of us and requires formal instruction, right?
*  We can talk more about that later, but it's very, I would say it's very unlike natural
*  language.
*  There is a link between spatial imagery, which is different from kind of static visual imagery
*  and math.
*  And you see this both in actual studies, but also in just self-reports of many mathematicians
*  talking about the usefulness of spatial imagery, which naively, I think to many people outside
*  of math might think, oh, you know, what's so spatial about like, okay, geometry, sure,
*  but what's so spatial about algebra?
*  But all of these have spatial analogs, transformations, and it's very useful often to think about
*  it spatially.
*  So I think one reason why we can be as good at math as at least some of us are, some humans,
*  is that we can rely on our spatial cognition, which presumably evolved for other things
*  and can be kind of hijacked for math.
*  But yes, it's pretty different from language.
*  Yeah.
*  Total aside, are you Russian?
*  What is your background?
*  My background?
*  Yeah.
*  Yeah, yeah.
*  So I originally from, yeah, the then Soviet Union from Belarus.
*  Okay.
*  I'm trying to place that slight, slight accent.
*  Slight accent, yeah.
*  Yeah, nine.
*  I came when I was nine, nine, ten.
*  Yeah, whether people can detect it sort of depends on where they're from.
*  I lived in New York on the East Coast.
*  There's probably a bit of that and some of the Russians.
*  Oh, okay.
*  I think you say cognition like Paul Chisek and I think he has some Slavic cognition, which
*  is...
*  Cognition.
*  I always say cognition, so I don't know.
*  Maybe I'll start saying cognition.
*  Cognition, yeah.
*  Okay, yeah.
*  These are the important hard-hitting questions.
*  You trained under Jay McClelland.
*  Yes.
*  He must be delighted about these large language models and their abilities and people's excitement
*  about trying to look for somewhat symbolic and conceptual forms of representation in these
*  models.
*  Are you still in touch with him?
*  Occasionally, yeah.
*  When I reach out, he's great at responding and if I'm in the area, I try to see him.
*  My in-laws are in the Santa Cruz area, so I'm over there at least before the pandemic
*  was over there more regularly and so we've met up.
*  But yeah, it's fun to see all that's been happening.
*  Compare that to my grad school experiences.
*  Yeah.
*  Oh, yeah.
*  Yeah.
*  Well, yeah.
*  You're part of a large body of people who are playing with these large language models
*  and I don't know if you're trying to trick them or what your angle is, but what is your
*  view on large language models in general?
*  Then I'm curious whether the success of these language models have altered your thinking
*  at all about language and cognition.
*  Yes.
*  Yes.
*  Well first, my general sense is that of excitement and I'm kind of giddy.
*  Are you?
*  Just because it's so cool to see it.
*  It's also tinged with some frustration which probably other folks in the podcast have also
*  voiced, right?
*  That there is this predominantly engineering approach to them.
*  I think it's effective, these sort of benchmarks and it's been very effective at improving
*  performance but it's come at the cost of efforts into kind of using them to do signs.
*  I think it's not because we can't, it's because so much effort has been focused on having
*  the bolded line in the tables, beating the benchmark, beating the previous result.
*  When I was in Grad School of J, we used neural nets to gain insight.
*  The focus is to use them as scientific tools and they were toy models, they couldn't do
*  The symbolic models at the time, I felt, didn't give much insight but they could do stuff.
*  If you want a model of poker, there was no connection this model of poker or even a model
*  of driving, not really.
*  If you want a program to drive a car, you have to do it symbolically.
*  It's now kind of flipped, right?
*  Where the models that work really, really well in many contexts at least are not the
*  symbolic ones.
*  So that's been an interesting reversal.
*  So there are still people calling for neuro-symbolic AI.
*  I mean, do you think that that is a past concern now and that we can just solve everything
*  with scale and neural nets?
*  I think probably not scale, but I think it depends on what question one is trying to
*  answer.
*  So for example, speaking a little bit for Jay, for a long time now, he's been very interested
*  in math and how people do math.
*  So math is at a certain level is obviously symbolic, but his question and it resonates
*  with the way that I approach this, although I haven't been studying math at all, is, okay,
*  we have this neural network of a brain and somehow we're able to do something like symbolic
*  computation algebra.
*  I would say that we're not very good at it, but of course, compared to other animals,
*  we are.
*  And some of us are really, really good at it.
*  And we can invent machines that are even better at it, but we did the inventing.
*  And so we absolutely want to understand how this emerges from a neural network.
*  And so understanding the emergence of symbolic or symbolic-like behavior is, I think, a really
*  important goal.
*  But what's unsatisfying is if you get to start with all the symbols, if you just build it
*  in.
*  And so yeah, you can add a calculator to chat GPT and have it detect any time you're asking
*  a question that involves arithmetic, just plug in the calculator and it would work much
*  better than trying to learn math from language.
*  But that wouldn't be that interesting scientifically.
*  So I think if you're going to focus on things where our cognition is most symbol-like, that's
*  great as a research question.
*  But I think you want to try to understand how that emerges from neural networks, but
*  not necessarily from just ingesting data.
*  To a large extent, I'd say that the most symbolic parts of our thinking are those that are formally
*  taught.
*  And this is a controversial statement.
*  Many people don't agree with this.
*  I would defend that statement that things like formal logic, yes, we can do it.
*  We're not that good at it.
*  It's stuff that we are taught how to do.
*  Part of that teaching, I think, involves kind of mapping between the things that we are
*  good at and trying to use those for doing these kind of, I'd say, less natural operations.
*  So it's striking, right?
*  A really simple electronic circuit can do arithmetic much better than our huge brain.
*  But in learning how to do arithmetic, we learn little algorithms and tricks, and also, of
*  course, writing things down on paper to overcome the limitations of our working memory and
*  so on and be able to do that despite that.
*  But most of us wouldn't discover that on our own.
*  So yeah.
*  That's one of the most useful parts of language, I suppose.
*  Are you an extended cognition advocate, a la Andy Clark?
*  I mean, it depends.
*  Yes, I think for the most part, yeah.
*  It depends on what you mean by that.
*  But I think it's absolutely the case, yeah, that we have incorporated all kinds of tools,
*  one of them into just our kind of typical environment.
*  Yeah.
*  You used the word, oh, sorry.
*  Go ahead.
*  I was going to say you used the word emergence a few times when talking about symbols.
*  What do you see as the relationship between a symbol and the sub-symbolic entities that
*  have rise to that emergent property?
*  Is a symbol an emergent property of sub-symbolic processes?
*  In a sense, everything is an emergent property.
*  But is that how you think of a symbol or do you think of it as an abstract concrete entity?
*  I think of it as an emergent sort of chunk.
*  So it's been really interesting.
*  You asked earlier about whether these large language models have kind of changed how I
*  think of that.
*  So one specific thing, and then I'll circle back to the symbol point, is seeing just how
*  much perceptual information seems to be embedded in language so that, of course, these language
*  models, their only exposure to the world is through language, the pure language models.
*  And yet they come to have all this knowledge about what things look like, spaces, navigating
*  through spaces.
*  And it's not hard to find gaps, but that they should know anything at all is remarkable.
*  And it's one thing if it's just repeating something it's heard, but that's not, I think,
*  what's happening.
*  And there is a very strong analogy here too.
*  For example, Marina Bedney's work on how much blind people, congenitally blind people,
*  know about the visual world.
*  We have somewhat different takes on the role of language in this process.
*  So it's clear, I think, both of us, that it's coming from language, but she puts more emphasis
*  on the inferential processes than the learning from statistical co-occurrence.
*  And so putting aside the question of whether humans learn all this perceptual stuff from
*  language itself, what the models make clear is that the information is out there, that
*  it can be in principle learned from language.
*  And I think in many cases we do, in fact, learn a lot of it from language.
*  For blind people, learning about the visual world through language is one example.
*  Of course, so much of the visual world that we can experience, but we don't, and yet we
*  can talk about it.
*  We have, I would say, real knowledge about things that we've never personally seen.
*  And we learn that through language.
*  And so it kind of, I think, changed my expectation of just how much of this type of information
*  is embedded in language.
*  So yeah, that's kind of changed.
*  I think it's changed my view on embodiment a bit.
*  I think prior to this, I would have thought of it as being more central than it is.
*  And there is the question, of course, of, okay, obviously the language that these models
*  are trained on comes from humans who are embodied and as a result, arguably infuse their language
*  with all of this information about appearances, about moving through the world, about space.
*  And had they not been embodied, like, okay, of course, the information in language would
*  be different.
*  But that's also true of people learning language, right?
*  So people are learning language from others.
*  And so it would be different if we found that models producing language and learning from
*  language produced by other models converge on the same thing.
*  But the point that, oh, it's because humans are producing language and that's why the
*  models can succeed is, to me, a kind of a sterile point because it's humans are learning
*  language and are learning from language that is produced by other humans as well.
*  So I don't know if that totally makes sense.
*  So the idea that, oh, we personally must be embodied for this and that bit of language
*  to make sense, I think is in some ways challenged by the success of large language models.
*  Well, okay, so you just used the term make sense, which relates to the idea of meaning.
*  And I mean, is one way to think of language like is so it's its own level of abstraction
*  and connection and you can learn all the structure and in the world.
*  Are these language models missing meaning and is embodiment and grounding important
*  for meaning?
*  Of course, you know, because the language model, perhaps it's only great at the statistical
*  regularities of language and that's its own structure.
*  But then the connection to meaning is through embodiment or grounding.
*  Yeah, yeah.
*  So this is obviously a contentious issue and it depends on what one means by meaning.
*  So it always struck me as strange to think that, okay, if you have no grounding to the
*  external world, you can't have any meaning at all.
*  But then, okay, how much grounding do you need?
*  Like if you put in a little bit now, suddenly everything is grounded out and then meaning
*  just magically appears, that doesn't seem right.
*  And then I also find myself reflecting on how people actually use language and how much
*  of language is pretty abstract and not about concrete things in the world.
*  And so many of the words we use, right, the way that we tend to use them, they might have
*  certain more literal meanings, but the way that we tend to use them really are about
*  the more abstract aspects that are about the words relationship to other words.
*  In fact, so Mark Brisbett and his colleagues who collected the large scale data on concreteness
*  judgments that many people use, so tens of thousands of words, you know, rate this word
*  on a concrete to abstract scale.
*  There's a little, I think, insufficiently widely known fact about those ratings, which
*  is that the way that they defined whether a word is concrete or abstract is that concrete
*  words are things that, words denoting things that you could point to or enact, right?
*  So jump is fairly concrete in that, you know, if you couldn't use the word jump, you could
*  just like jump around and to convey the idea of jumping.
*  So that's the one end of the scale.
*  And then abstract, they defined as words, meanings of which you would need to describe
*  with other words, right?
*  And so the reason this is important is that when you actually look at the distribution
*  of words that people use, it skews pretty heavily on the abstract end.
*  So these are words that, yeah, that, you know, and obviously in child directed speech,
*  it's a bit different, it's more concrete.
*  But yeah, if you, we did these few of these little exercises where you take a passage
*  of text and you remove the most concrete words from it and compare that to removing the most
*  abstract words from it.
*  And removing the most concrete words removes some details.
*  Removing the most abstract words, even just focusing on content words, not like the, right?
*  You just have no idea what this is about anymore.
*  So really so much of meaning is this in these abstract words, which, you know, those meanings
*  are the relations between words.
*  So yeah, I have no personally no trouble in saying that there is a huge amount of real
*  meaning just in those connections.
*  And yeah, you know, once you, yeah, yeah.
*  It depends on what you mean by meaning, I suppose.
*  It all comes back to that.
*  Yeah, yeah.
*  And I think, you know, the way that, for example, language is often studied, let's say, word
*  learning in kids, I think reference is overemphasized in part because like it just makes it easier
*  to run the experiments, right?
*  So you study how kids learn, you know, in a lab, a word for some novel object, right?
*  So you have some concrete object and it's not because most researchers, I think language
*  development researchers think that that's all there is.
*  It's just that it's more tractable, you know, than to study the more abstract parts of word
*  meaning and how, you know, words become associated with one another.
*  But I think that that among other things led to an overemphasis on kind of concrete reference,
*  right, as a key part of meaning.
*  Do you think that language models have anything to say about the way that language develops
*  in children?
*  Because they learn so differently.
*  And then, so I was talking, you know, I had Ellie Pablak on recently and some of her work
*  is, her conclusion from some of her work is that it's possible that these large language
*  models could kind of learn backwards from humans, right, where they get the grounding
*  later.
*  I don't know how much grounding they would need, like you were alluding to, but basically
*  like learn perfect language, whatever that is, and then get the grounding later.
*  But do you see any way to tie language model, quote unquote, learning to the way that humans
*  learn?
*  Yeah, so that actually makes a lot of sense to me that there is a lot of work showing
*  that kids learn, yeah, that there is a big concrete disadvantage, that children's early
*  words are more, they tend to be nouns, they tend to be concrete nouns.
*  When they start learning verbs, they tend to be the more concrete verbs.
*  So there is lots of evidence pointing to the importance of grounding.
*  I don't know if it's really about grounding or about kind of what kids use language for,
*  right, which is-
*  For getting what they want.
*  Getting what they want, exactly.
*  And so, you know, they don't need to talk about this sort of stuff, right, that we're
*  talking about now, right there.
*  It's for getting what they want, getting attention, right, getting, you know, and so, yeah, yeah.
*  So in a sense, I agree on this with Elida, it's a kind of a backwards process.
*  Yeah, it would be interesting to know whether in these language models, I feel like there's
*  probably work on this, there is also a concreteness advantage.
*  So even though there's no, like, even if there's no reference to the real world, right, more
*  concrete words tend to be used in more predictable contexts, right?
*  They have narrower meanings and so they're easier to predict.
*  And so if you're just learning through prediction, there's reason to think that that would be
*  easier to learn.
*  But as far as parallel, so, yeah, I mean, there's a, it's kind of become a trope that
*  like, oh, kids don't learn language in anything like the way that models learn.
*  I mean, I think when it comes to language use, that's true.
*  But I think kids are predictive learners.
*  They also, you know, are learning from examples and generalizing from examples.
*  And a lot of kids' early language is very stereotyped and it's not as creative and
*  productive as is often made out.
*  And when you know the child's environment, like, you know, when they say something new,
*  I mean, when they start going to school and they're learning from other kids and stuff,
*  it's all, you lose track of it.
*  But like, how old are your kids?
*  I know you have.
*  Right.
*  Sorry.
*  Yeah.
*  Yeah.
*  Yeah.
*  Uh, we have two boys.
*  One is, uh, turning three, uh, in a couple of months and one is five and a half.
*  So in kindergarten.
*  Uh, yeah.
*  Okay.
*  Yeah.
*  So it's, it's, it's been fun to watch and, uh, the, but I was going to say that earlier
*  on when they're saying fewer different things, right, you, you can often kind of track
*  where they got something from, right?
*  It's like, oh yeah, that phrase, you know, that's clearly from this TV show.
*  Right.
*  And they're only using this word within this phrase.
*  And then, you know, a month later, right.
*  It branches out and now, you know, it's being used in a more expanded context, but
*  it's not like they learned this word.
*  And from the beginning, they have some, you know, full knowledge of how the word is
*  used and it's really brittle and narrow.
*  And then often, you know, if you ask them, uh, right, like often they use words
*  without full understanding of what they're saying.
*  Like, that's a thing.
*  Yeah.
*  Yeah, exactly.
*  So do we.
*  Uh, but we, we probably have a higher threshold for it.
*  Like we have some social monitoring, right?
*  Like we don't want to be called out or kids don't have it as much.
*  Yeah.
*  Yeah.
*  Right.
*  Um, so, but, but, um, I wanted to just briefly return to the emerging symbols.
*  So I think what's been so interesting for me, um, watching these language models is
*  just the effectiveness of prediction.
*  Right.
*  And, uh, I wouldn't want to say that like, that's all there is to human learning, but
*  I think that that's a lot of what human learning is about.
*  And, uh, I think it means something to find that, Hey, these, this, this process
*  of predicting works really, really well.
*  Right.
*  Does that mean same thing with reinforcement learning, right?
*  Does that mean that there is something, you know, that nature is trying to tell
*  us something, right?
*  If it works really well across a bunch of contexts, right.
*  Uh, could it be that it works really well because it's a really good way of
*  solving a bunch of problems and biological evolution is likely to have,
*  uh, found a similar solution.
*  And so when it comes to language learning, of course, predicting the next word or the
*  surrounding words is generally not the point, but it turns out that it's a really
*  good way of learning structure.
*  And so, uh, if you start being able to predict things really well, it probably
*  means you've learned some useful internal model, not just of language, but to some
*  extent of the world.
*  And, uh, if it turns out that, uh, symbols are a useful part of that model, well,
*  you're learning symbols.
*  Um, and so I, yeah, that that's kind of how it is.
*  So, yeah, the, this, this idea that like, Oh, it's just autocomplete, therefore
*  it can't have meaning.
*  I feel like it, it sort of misses the point because the goal is not predicting.
*  That's just the loss function.
*  Um, but in trying to predict, that's just a really good way of learning
*  underlying structure.
*  And if you can predict really, really well in lots of other contexts, we call
*  that some degree of understanding, right?
*  So, you know, uh, even if it's hard to talk about.
*  Yeah.
*  So you don't think that, sorry, this is a, it could be a off the walk question,
*  but you don't think life is necessary for, um, understanding, meaning, et cetera.
*  I don't know.
*  It's it.
*  Yeah.
*  It's, it's kind of, yeah, above my pay grade.
*  I don't know.
*  Overly philosophical.
*  Come down on one side or the other, man.
*  Yeah.
*  Uh, so, you know, so far these models are not actual, uh, actors agents, right?
*  Uh, they, they respond to our prompts, right?
*  They're not actually creating anything on their own.
*  Uh, and people are, and so, uh, right.
*  So I don't know.
*  I mean, I, I find myself often landing on the side of like, I think humans
*  understand far less than we give ourselves credit for, right?
*  And there's way less understanding in us.
*  And so we're probably overestimating our own understanding and underestimating
*  like understanding in, in these sorts of models.
*  Um, and so you, you know, so I think the models are learning certain, um, world
*  sort of world models, right?
*  In the same, some of the same ways that we are learning world models, but we
*  have lots of goals and we are kind of agents in the world and we effect change,
*  right?
*  In, in a way that these models don't.
*  And so, um, like they don't, we, we sort of make stuff, we make meaning, right?
*  In the way that these models don't, right?
*  They're just responding to our own prompts.
*  Um, and if you get, you know, two models talking to one another, right?
*  It's, it's not very deep, uh, right?
*  Like it's, it, it, it, it becomes kind of circular.
*  Um, of course, lots of our conversations, human to human
*  conversations aren't very deep either.
*  So, yeah,
*  speaking of circular, um, so this is something that I also asked Ellie, uh,
*  the other day, so you have these language models, they're generating a bunch of
*  text, they're trained on the corpora of web text, uh, text from the worldwide web.
*  But then, so they're generating this text, that text is going to go onto the web
*  and future models are going to be trained by the text that they generate.
*  What effect does that have on, um, us as a society, but also on the nature of the
*  way that language changes and evolves throughout time?
*  Yeah, yeah, I, I've, I've thought about it.
*  Uh, I don't have an answer, right?
*  It seems like it would just kind of create the circularity and probably
*  amplify existing biases.
*  Um, I think there's a fun, right?
*  It's fundamentally different from, you know, uh, a chess or go model playing
*  itself, right?
*  Because that's a closed world with a definite kind of reward function.
*  And so you can learn from exploring this world, um, and, and, and reach new insights.
*  If you're just using language without any connection to anything, I don't see how
*  you can, uh, go beyond just kind of reinforcing, uh, kind of existing biases.
*  Um, but if you now combine these models with, uh, other sources of data, right.
*  Um, you know, now maybe you can kind of break out of that circularity.
*  Right.
*  And so, um, right.
*  I mean, one can flip that question around and ask, okay, well, how is it that humans
*  are not, um, running into that same problem because we are learning language
*  from other people and then we are producing, uh, the training set.
*  Uh, and presumably it's because we're also interacting with the larger world,
*  having different experiences and sharing those experiences with one another, right.
*  Inventing new technologies, uh, interacting with those technologies and, uh, you know,
*  uh, disseminating that new stuff to other people.
*  And so we're not just kind of rehashing the same thing over and over and over again.
*  Yeah.
*  Like if I, if I go, I don't know, take up surfing or something, I'm going to learn
*  new vocabulary, but I also might create a new word for, uh, when the water is choppy
*  and it's cold and I had a bad run or something, you know, I might call that a bloonk or
*  something.
*  Yeah.
*  Yeah.
*  So a language model, I suppose you could, you could build in that generative
*  neologism, um, objective into the language model, but then man, that'd be scary if,
*  if they would, it seems like they would run wild and our language would change really
*  quickly.
*  Yeah.
*  Yeah.
*  Yeah.
*  Yeah.
*  That's a really interesting idea.
*  Uh, so I've been very intrigued by lexical innovation language change.
*  So, um, one way to think about, right.
*  So, oh, you know, we invent words for kind of things that we already know.
*  Um, uh, and, uh, I, I don't think that's right.
*  So that could be true for the, you know, if someone invents a word, it presumably
*  reflects some idea that they've already had and, and, you know, that they find
*  useful to have a word for, but in general, the words that we encounter are not things
*  that we necessarily already had a concept for.
*  Uh, we learn the concept, many concepts, I think in the course of learning those words.
*  Right.
*  And so if that word happens to become a kind of part of the, the, the, the
*  part of our core vocabulary that every speaker has to know, then you have to
*  learn those words just in the process of learning the language.
*  And so you, as a speech community end up aligning on those concepts.
*  Um, and so, yeah, so I could imagine, you know, these models through kind of being
*  exposed to way more texts than any individual human, right.
*  Can kind of build a new chunk and say, okay, well, here's some useful regular,
*  some regularity that is frequent, but doesn't have a word for is not lexicalized.
*  And, you know, here I'm going to invent this word and then use it in context.
*  And people, uh, many words we learn just passively by kind of reading and
*  encountering them in context, right.
*  And so now, you know, people are exposed to this and so that could be kind of cool.
*  Um, I hadn't thought of that before.
*  That's, that's an interesting, uh, kind of influence on, yeah, on lexicalization
*  language change.
*  What is a concept and how do you think about it relative to a symbol?
*  Um, so I know, I know a lot of your work is, you know, focuses on whether what
*  you're like, what you were just alluding to, I mean, you've done research on this,
*  what, you know, the, the back and forth between concepts and language and the idea
*  that you exposes that, um, we don't have these inherent innate concepts and then
*  just map our words onto them that there's it's more of an interaction.
*  Yeah.
*  Yeah.
*  Um, so I, I, I think of concepts and I should caveat it by recognizing that
*  there are different, um, different meanings of concept as used by psychology
*  and philosophy, and so I'm talking about concepts as sort of internal mental
*  entities.
*  Um, so I think of them as just mental representations of categories.
*  Uh, right.
*  And so they're not, and again, with symbol, different people use
*  symbol differently, right?
*  One distinction between how at least some people use symbol and how I use concept
*  is, um, a concept isn't a, you know, a, a, a, a singular kind of undifferentiated
*  node, right?
*  So it's perfectly sensible for me to say, okay, you know, you have a concept of a
*  dog, but then some dogs are typical dogs and other dogs are kind of atypical dogs.
*  And, you know, some dogs look more similar to cats and other dogs, you know,
*  look very different from cats, right?
*  So it's not, uh, like it, it doesn't require some single node that is the
*  dog, right?
*  Dog, you know, in, in all caps.
*  Um, but there is a sense in which we can have a thought about dogs that is somewhat
*  distinct from thoughts about a specific dog, right?
*  And so, and that, that's something that language is really good at instantiating.
*  So even if a speaker has a specific dog and, you know, they're thinking of a
*  specific dog, they use the word dog, right?
*  And it activates a representation in the hearer of a dog that is more abstracted
*  and more categorical, uh, than what would be activated by, for example,
*  seeing a specific dog.
*  And so that's kind of, so I think of language as, as being sort of like a, a
*  cue or an operator, right?
*  For instantiating a mental state, uh, that in some cases, maybe we'd be able to
*  instantiate that mental state even without language, but I think often, uh,
*  we, we wouldn't, even if we could in practice, we would not, um, right.
*  And, um, and in the course of learning a word for something we are learning, and
*  then also in using the word regularly, we're learning to instantiate that more
*  categorical mental state that isn't one not kind of as focused on a specific
*  experience, a specific exemplar, uh, specific situation have, um, sorry, I'm
*  kind of jumping around here, but I have a couple more kind of open ended broad
*  questions and then in the last few minutes, I have some, uh, questions from
*  Patreon listeners that I'll ask you.
*  Um, has, how was I, how was I going to phrase this?
*  Has the advent of like these large language models changed the way you view
*  language in terms of how special it is, the, you know, within the hierarchy of
*  awesome human cognitive abilities is language still up there or, you know, for
*  me, like seeing these language models, it's like, oh, okay, it justifies
*  that language is not that great.
*  Oh, yeah.
*  I, so I have the opposite actually, uh, kind of takeaway, which is it, um, kind
*  of vindicates the idea that there is something really, uh, well central, I
*  think to language.
*  So for example, you know, it's, it's been really cool to see the, the
*  generative art models, right?
*  And, uh, that's awesome.
*  Like, uh, I think they probably have a whole lot to teach us about actually the,
*  the nature of, you know, visual information.
*  Uh, but, uh, it's not a coincidence.
*  I think that, that they're using language as an interface, right?
*  So, you know, you're training them on, on these, um, captions and images.
*  And one could say, okay, well, of course, you know, we want them to use language
*  because if we want people to use them, right, kind of for them to be useful,
*  like it's helpful to be able to use language to prompt them to produce
*  certain kinds of visual, uh, visual apps, right?
*  But, but language is, I think actually a much more central part of these models,
*  right?
*  Because, you know, if I want to generate, um, you know, a, a, uh, a
*  piranha riding on a unicycle, okay.
*  And, uh, this is something that good one do.
*  Uh, and, uh, well, where did they get that concept of, you know, piranha
*  riding unicycle, right?
*  That doesn't come purely from the visual information.
*  I'd argue that you can't get it from the visual information alone.
*  Um, it comes from training on vision and language.
*  And so language is not just being used as an interface.
*  Language is actually what is in these models, creating a lot of these categories
*  that we can then deploy, right.
*  And use, um, it's, it's incredible actually to that, you know, the sense of
*  like a fish riding a unicycle and a horse riding a unicycle, it's a different type
*  of riding, right, visually.
*  And it's really cool that it often gets that right.
*  Uh, and that's, I think kind of unexpected, but, uh, but that sort of verb ride.
*  Right.
*  Like that's not in the visual world, right?
*  That's a word meaning and, um, the models learned it to some extent because it's
*  there, right.
*  And were it not for language, like, how do you get riding out of the visual data?
*  I like, I don't know.
*  I don't think there is a way.
*  Um, so yeah, so it's, it's kind of showing that language is, uh, this
*  actually much more central way of organizing information than, um, you know,
*  than one might think.
*  Um, and I don't know, I don't think the.
*  And so for example, with the older kind of just the regular supervised vision
*  classification models, right.
*  Trained on image net or whatever.
*  And, um, uh, you know, you show an image and it tells you that it's a dog or
*  whatever, uh, in my discussions with, with folks, um, working with these models,
*  I got the sense that they weren't thinking of the language as playing any role,
*  that these are not in any sense, language models, right?
*  They're just vision models.
*  And of course, to be useful, you wanted to output a verbal label, but that label
*  had nothing to do with language.
*  And I mean, I think that's, that's not really right because, uh, in that
*  supervised learning process, right.
*  You're telling the model that, uh, whatever, you know, horses or dogs or
*  whatever, like are a thing.
*  And that's a lot of what language is telling us also, right.
*  That, you know, were it not for the encounter with these words, it might not
*  occur to you to treat all examples of this thing as having anything in common.
*  Um, and so this guides your learning and that supervision signal is telling you,
*  you still have to figure out what they all have in common.
*  You still have to do the learning.
*  The model still has to do that learning, but it's at least telling you that, okay,
*  treat all of these as being the same sort of thing.
*  Uh, you know, and here's the signal telling you that like, which things
*  should be treated as the same.
*  And I think that's a lot of the role that language is playing, uh, natural
*  language in human learning.
*  But is there any detriment to that?
*  Is there anybody, any, I'm sorry, I'm pushing you on this.
*  Like, um, so, you know, I'm kind of playing devil's advocate, but, you know,
*  by throwing out, by, by only looking at the commonalities and calling everything,
*  you know, all dogs, dogs, you know, or whatever, is there any detriment in
*  terms of cognition?
*  Yeah, for sure.
*  For sure.
*  So, um, I mean, I think you see that in, um, sort of the domain of social categories,
*  right?
*  So we learn, um, gender also, right?
*  So we learn these labels and, um, we sort of tend to then automatically
*  classify people, right?
*  As members of that category.
*  Uh, right.
*  And, you know, that has consequences for treating people, right?
*  It doesn't mean you can't then treat them as, you know, uh, or, or also
*  represent them as an individual, but there's a consequence to initially
*  classifying them.
*  Uh, so you see that in, um, it was been called the other race effect, right?
*  That it's harder for people to recognize, uh, individuals of the other race.
*  It's actually, it's not, it's more accurately called the minority race effect
*  because, um, it's, so the idea is that, you know, oh, in the U S let's say, you
*  know, white faces are a majority group.
*  And so whether you yourself are white or black, you know, that the white faces
*  are the majority group.
*  So if you see a white person, you're less likely to classify them as a, as a white
*  person, because that's just the kind of the default category.
*  And so what's the alternative is to kind of represent them as an individual.
*  You see a member of minority group, right?
*  The first kind of classification is that they are a member of this group.
*  It becomes harder to represent the individual details.
*  Um, and when the category gender category also becomes salient, uh, it doesn't
*  mean that you're only representing that person as a male or female, but it means
*  that you're representing them as a male who is, you know, and connecting it to
*  other details.
*  And so there are consequences, absolutely.
*  Uh, of yeah, and often negative consequences of this sort of categorization.
*  Okay.
*  So you're giddy about the large language models you're impressed.
*  And, um, but I, but I think I've heard you say that you're not giddy about the
*  idea of artificial general intelligence.
*  So, um, if, if I have that right, maybe, um, well, do I have that right?
*  And if so, um, why not?
*  If you're so giddy about these large language models, aren't you, aren't we
*  just one step away now from AGI?
*  Well, so, uh, I, I find the talk of AGI to be kind of uninformed because it assumes
*  a certain, I think shallow view of what intelligence is, right?
*  That, uh, first of all, they're sort of like, okay, you know, Humans are
*  generally intelligent.
*  And so, you know, you know, when will these AI models be generally intelligent?
*  And then this idea that like, well, there's nothing special about the level
*  of human intelligence.
*  And so once they're on that track, right.
*  Uh, you know, one step below human intelligence, uh, then it's just a matter
*  of days before they're at human intelligence and exceeding human intelligence.
*  And I think it, that reasoning makes sense when applied to some, uh, close class
*  domain, like playing a particular game, right?
*  It's true that there's nothing presumably special about the human level of go or
*  chess playing, and once you're good enough, you can quickly exceed it.
*  But I think that logic doesn't apply to actual natural intelligence, right?
*  Because like, you know, we, we don't have a good way of, um, well, we, some people
*  think they understand human intelligence.
*  I think they're wrong and have been misled by a kind of reliance on, uh,
*  intelligence testing and IQ tests, right?
*  Which, you know, at their best, right.
*  Maybe can be good at measuring, right.
*  Certainly culturally valued, uh, skills, um, and ways of thinking, but there's
*  nothing general about it, um, right.
*  It's, it's just about like, sure.
*  IQ tests in many contexts are predictive of, um, you know, success in certain types
*  of jobs and so on, because like we value certain skills and so we design tests to
*  test those skills, but what is general?
*  I, I don't think there's anything general about it.
*  Um, and so, uh, I, I feel like the discussions of AGI are often predicated
*  on the kind of shallow view of human intelligence.
*  Um, and so, you know, I, I also, I like to kind of give, you know, think in terms
*  of a thought experiment, right.
*  Where, okay, you know, if you think that there's certain, something about the
*  human brain that gives us general intelligence or, uh, well, you know, go
*  back 50,000 years, right.
*  You know, if you observe people, you know, they would not do well on IQ test.
*  Uh, right.
*  And so they have the same brains.
*  Obviously the cultural technologies are different.
*  You know, they are way better at certain things that now we don't care about,
*  uh, way worse at other things.
*  You know, they're not doing math.
*  They're not doing science, right.
*  Um, the hardware is the same, right.
*  And so would you then come, would you then conclude that they are
*  not generally intelligent?
*  Right.
*  And, and it just, the whole kind of thing doesn't, doesn't really, uh, make much
*  sense, make much sense to me.
*  Uh, and, uh, and, and then the thing that like, so I think these large language
*  models, right, are showing that, yeah, you can learn, for example, to produce
*  all these grammatical sentences from, from just input and for, so they have a
*  lot to teach us about like what is needed and perhaps not needed, uh, to say
*  learn language, but so far, right.
*  They're not doing things in the world, uh, the way that animals and, uh, you
*  know, human and non-human animals are.
*  And it's not clear how good they are at doing things in the world.
*  So I think we're not even at the, not only are we not kind of at the top of that,
*  that curve, uh, we're not even like really on it yet.
*  Yeah.
*  But I like that you, um, highlighted the distinction between humans 50,000 years
*  ago, let's say, and today, um, because it, so I, I, I agree with you.
*  I don't bind to AGI or generality in general, but what it does highlight for
*  me and what I've been enjoying thinking about recently is the vast capacity for
*  that range of cognition that our brains endow us with.
*  I'll say our brains.
*  I guess that could be controversial for some people, but it's the capacity that
*  is, um, more impressive to me than the actual doing of any one given kind of
*  task or range of tasks.
*  Um, but, but I don't know if that makes sense to you or if you agree with that.
*  Yeah.
*  Yeah.
*  Uh, no, it, it, it is amazing.
*  Um, I wonder, right.
*  Um, kind of continuing that thought experiment, uh, if you had to make a
*  prediction based on the behaviors of people 50,000 years ago, right.
*  Would these animals, which are anatomically modern humans, right.
*  Would they, you know, go to the moon and, you know, be doing modern
*  physics and all this stuff, right?
*  Like what reason would someone have to, to make that predictions, you know,
*  confidently, right?
*  Um, right.
*  Right.
*  Uh, and, uh, you know, I think 50,000 years ago, like humans are on a very
*  different trajectory from other animals.
*  Right.
*  Um, but, but based on the level of technology and kind of actual, uh, you
*  know, uh, uh, scientific achievements, right.
*  Not, you know, totally different from now.
*  So I, I don't know.
*  I think, uh, I find kind of the discussions of the intelligence within
*  the context of artificial general intelligence to be kind of very narrow
*  and focused on not just the humans of the present, but particular kinds of
*  humans of the present, right.
*  And so valuing very specific types of intelligence and not others.
*  And yeah, this guy, this guy.
*  Yeah.
*  Um, so I, I, uh, so I'll end, um, before I ask you a few like
*  specific patron questions.
*  I began with Ellie public asking her if I had to freeze her for how long she
*  would like me to freeze her and then thaw her out to continue to then like wake up
*  and continue her research career.
*  And that kind of morphed into, um, her.
*  So seven and a half years, because she said in five to 10 years, she feels like
*  we'll have a good understanding of how language models work.
*  Um, where do you, do you think it's, is that, is that, um, too long of an
*  estimate or, you know, do you think that we'll understand how language
*  bottles work in the near future, far future?
*  How long would you like to be frozen?
*  Um, I, I mean, I, I don't think that's actually, uh, that's not my primary goal
*  to understand how language models work.
*  I think that time estimate seems plausible to me.
*  Um, but I'm not sure that understanding how they work, I think it'll be very
*  satisfying.
*  I don't know that it would, it would change much.
*  Um, so let's say we have a, for your own, for your own career and goals, how long
*  would you, like if, if you had to be frozen and then wake up and continue asking
*  the questions that you're asking and, uh, you know.
*  Yeah.
*  Yeah.
*  Um, I'd be curious.
*  Okay.
*  I'll say a hundred years, a hundred years.
*  Oh, I like that.
*  All right.
*  Yeah.
*  So I think that'll give opportunity to see how language has changed in
*  response to all of this technology.
*  Um, I'm really curious actually about, um, the use of these language models.
*  Like some uses are striking as kind of like time-saving, time-saving, but
*  uninteresting, like, okay, you can write emails faster.
*  Like, okay.
*  You know, other uses are sort of much more interesting.
*  So for example, um, one of the remarkable aspects of these models, uh, that I, I
*  didn't see coming is that just, okay.
*  So you've been trained on this enormous, enormous corpus of data, but you can
*  access very specific things in this precise and kind of, I don't know,
*  uncanny way, right?
*  So, uh, use of these models for indexing information.
*  And so I could imagine people using them more for, uh, basically feeding
*  in their individual information.
*  So people have been playing around with this, feeding in their journal entries
*  to these language models, their notes, right?
*  And then having the model use that information, um, right.
*  When person indexes it, right?
*  So it's not just indexing kind of knowledge at large, it's indexing
*  your own personal knowledge.
*  And so you can imagine interfacing, um, this with, you know, people's, um, right.
*  So external memories, so photos, recordings, um, and, and having that be
*  a much more integral part of our workflow.
*  Um, uh, and, and that could really transform, right?
*  Like I'm thinking of education, you know, what it means now, like even now, right?
*  With all the technology and the students, college students, you know, they're
*  taking notes, right?
*  If they're typing notes, okay, it's easier to search through those notes, but
*  you have to come up with your own like ways of organizing, but that could all be
*  presumably even with current, current technology automated, right.
*  And indexed probably in a more effective way than what we do as individuals.
*  Um, and so having all of this available to us and kind of integrated, um, you
*  know, I could see that feeding back in and kind of making us, I don't know, smarter,
*  you know, in certain ways.
*  Um, so that could be cool to see how that develops over the next century.
*  So a hundred years, I would kind of, I would kind of be, uh, hesitant or scared.
*  A hundred years is things could be so dramatically different that I would worry
*  that I wouldn't be able to function in society, but I like it.
*  Yeah.
*  Yeah.
*  I think honestly, I mean, if, if, uh, if, if the past, uh, uh, if you look at how
*  people get the future wrong, right.
*  Uh, when predicting the future, I think there is a systematic bias, right?
*  Like people actually, people's predictions of technology, some of them are pretty good,
*  but people tend to really underestimate social change, right?
*  So you have like, you know, Victorian era predictions of like, okay, flying things.
*  We have flying things.
*  Okay.
*  But then it's like, everyone is still dressed the same way and there are like
*  traditional gender roles, you know, that, that has not changed, but now like the
*  mailman flies around, right?
*  Like, so, uh, uh, so I think the, the, the, the hardest things to adjust to will
*  probably be the social thing.
*  Gary, thank you so much for dancing around so many of these topics with me
*  before I let you go, um, you, you have a kind of a psychedelic, I can tell it's
*  a brain on your shirt.
*  Uh, it looks like a cool shirt.
*  Can I see the, what, what, what is the shirt?
*  What is that?
*  What is the shirt?
*  It's just brain.
*  Um, uh, it's a, it's a, it's a figure one brain map.
*  So there used to be this, uh, site called woot.
*  Uh, it was bought up by Amazon at some point and, uh, they kind of
*  disassembled it, but, uh, they had, um, so I have a whole lot of t-shirts from it.
*  They sold t-shirts.
*  Uh, it was like people submitted designs and then everyone voted, uh, and the top
*  three designs got printed and then they sold the t-shirts.
*  So this was someone's design.
*  Um, but, uh, they've, they haven't been around for a long time and, uh, all of
*  these shirts, uh, I think will soon have to be retired because yeah, they're
*  not being replaced.
*  Oh, that's cool.
*  I don't have a lot.
*  It's a, it's a cool shirt.
*  Yeah.
*  Different ones.
*  Yeah.
*  Thanks.
*  Yeah.
*  All right.
*  Well, thanks.
*  Thanks again for your time.
*  Uh, appreciate it and good luck, uh, moving forward.
*  Yeah.
*  Yeah.
*  This was Son.
*  Thanks.
*  I alone produce brain inspired.
*  If you value this podcast, consider supporting it through
*  Patreon to access full versions of all the episodes and to join our discord
*  community, or if you want to learn more about the intersection of neuroscience
*  and AI, consider signing up for my online course, neuro AI, the quest
*  to explain intelligence, go to brand inspired.co to learn more to get in touch
*  with me, email Paul at brand inspired.co you're hearing music by the new year.
*  Find them at the new year.net.
*  Thank you.
*  Thank you for your support.
*  See you next time.
