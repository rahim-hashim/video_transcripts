---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 7425s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 20507
Video Rating: None
---

# BI 109 Mark Bickhard: Interactivism
**Brain Inspired:** [June 26, 2021](https://www.youtube.com/watch?v=LZVZxLGRRt4)
*  Living beings are far from thermodynamic equilibrium.
*  Far from thermodynamic equilibrium processes have to be maintained far from thermodynamic equilibrium.
*  And some far from equilibrium processes contribute to their own maintenance. They are self-maintenant.
*  I may or may not get it right, but I've got to have a coherent, consistent metaphysics in order to do this.
*  The history of Western science is a history of substance models being replaced by process models.
*  The one domain in which that hasn't yet occurred is mine.
*  But I think there's a fundamental reason for why that's the last one.
*  The fundamental reason goes like this.
*  This is Brain Inspired.
*  Hey everyone, it's Paul.
*  Today I bring you a Tour de Force, a doozy, an epic episode.
*  I have Mark Bichard on the podcast.
*  Mark is Professor of Cognitive Robotics and the Philosophy of Knowledge at Lehigh University.
*  He's been at this for a long time, thinking and writing about the fundamental problems that we face.
*  He's been at this for a long time, thinking and writing about the fundamental problems that we face.
*  Trying to account for both natural and artificial intelligence.
*  Among his many publications, he co-wrote a book in 1995 called Foundational Issues in Artificial Intelligence and Cognitive Science, Impass and Solution.
*  That book still holds up well.
*  He's developed over the years an all-encompassing approach to brains, minds, and intelligence.
*  He's working on a new big book summarizing all the facets of that approach.
*  That approach goes by the name interactivism, which has lots of ins and outs and consequences and predictions, a handful of which we cover.
*  It's impossible to quickly summarize the entire thing here in the introduction.
*  But at the core of interactivism is Mark's conception of representation.
*  How our mental and brain processes connect with the things that they're supposed to be about, the things they're supposed to represent.
*  So most notions of representation focus on how brain processes could encode or map onto or correspond to the things in the world.
*  As an example, the apple we see causes visual neurons to become active.
*  And somehow there's a mapping from the apple in the world to our representation of that apple in our brain.
*  How this is supposed to happen has caused much ink to be spilled over the years.
*  The interactivism account of representation, however, avoids this by suggesting that representations are anticipations of possible interactions with the environment.
*  And that those possible interactions with the environment can either help or hinder an organism in its ongoing requirement to maintain itself in a thermodynamically far from equilibrium state.
*  That is to say, to stay alive. So that's a bit of a mouthful, I know.
*  But that framework of representations is surrounded by all sorts of other ideas, many of which we discuss.
*  And we also compare interactivism with other frameworks like inactivism, predictive processing, and the free energy principle.
*  And of course, we talk about what interactivism has to say about how brains function and the current direction, the current course of efforts in artificial intelligence.
*  So it's a long episode that touches on a lot of topics.
*  But if you take nothing else from this episode, which is unlikely, I think, but if you take nothing else, I think that you should take an appreciation for the scope and the breadth required to formulate such an all encompassing framework that that Mark has done with his interactivist approach.
*  You'll hear it goes all the way from foundational metaphysical philosophical considerations to theory to reconciling that theory with actual brains.
*  And that alone, appreciating all that is worth the price of admission and worthy of admiration.
*  So lots more to explore in the show notes. If this what's your appetite, go to brandinspired.co.uk slash podcast slash one oh nine to get all the full length episodes.
*  Support the show on Patreon. Yes, this particular one went even longer.
*  And and that extra material is through the Patreon supporter feed.
*  On principle, I don't do advertisements on brand inspired, but I do a few extra things for Patreon supporters like having a little bit of extra time in most episodes.
*  Thank you for listening. And here's Mark.
*  Mark, it's been, I guess, 26 years now since the book Foundational Issues in AI and artificial intelligence and cognitive science came out.
*  I thought I would just start by reading a few just a couple quotes from that book just to kind of start us off here because I'm not sure how much has changed.
*  So, OK, from that book, you and your co author, Lauren Turveen, is that right?
*  Yeah, wrote. And this is the end of the book.
*  Artificial intelligence and cognitive science contain their share, perhaps more than their share, of bluster, puffery and scam.
*  But these are not the basic problems.
*  The most fundamental problem is the inheritance of a millennia old false tradition of the nature of representation.
*  So that gets right to the heart of what we're going to be talking about here.
*  I believe a lot today.
*  But then I'm going to read one more quote before we really before we really start off.
*  This is just a little bit later in that same section.
*  Artificial intelligence and cognitive science can accomplish many things from within the encoding approach,
*  but they cannot accomplish any of their ultimate aspirations for understanding the mind and for creating artificial mentality from within that approach.
*  So we're interested here on this podcast in both understanding the mind and in creating artificial mentality.
*  So this is perfect. You're a perfect guest. Thanks for being here. Welcome to the podcast.
*  Hey, you know, before we really get into the details, you know, you've been working on this for quite some time.
*  And I know I think I heard that you have been working.
*  I know you're working on a book.
*  And I think I heard you mention that you've been working on the book for 30 years. Is that right?
*  Yes, that's right.
*  Because often in most of your publications now, one of the references is always in preparation.
*  That's right.
*  When is that book going to be finished, man?
*  Well, actually, I'm starting to think not too far in the future.
*  Most of it is now text. It was 1300 pages of draft.
*  Wow. It is now.
*  But, you know, maybe 500 pages of that was notes.
*  So it is now about 1000 pages of actual text.
*  There's two parts to it. I haven't yet written an intro, you know, kind of an overview and a summary.
*  But also I need to reread it several times for flow.
*  And there's a there's a reading group organized in Waziti University in Istanbul that's been reading it like 20, 30 pages a week since October.
*  We're about halfway through.
*  And they keep giving me all kinds of suggestions and criticisms.
*  So I can't keep up with them.
*  But so the intro, the summary, the flow, and then taking into account this reading group comments is what's left.
*  So maybe in a year, year and a half, I don't know, you know, a thousand pages that even takes a while just to do the rereading for flow.
*  You bet. Was that a mistake offering it to the reading group to let them to open that chapter, open that book?
*  No, it's it's it's really been interesting because I mean, some of their critiques and questions and puzzles have been very useful.
*  I mean, even the critiques show me places that I haven't been clear enough.
*  Luckily enough, so far, they haven't uncovered some fundamental awful error.
*  Although they've tried, they try yet. I was going to say yet.
*  Yes, right. Are you using an editor at all?
*  Or is this all, you know, with your writing abilities and I mean, it's kind of, you know, no, no, no, no.
*  I have five books and they've all been accidents.
*  Every one of them started out intending to be an article or a chapter and then grew.
*  Well, this one is my first on purpose deliberate book and I knew it would grow, but I had no idea it would grow this much.
*  Well, would this one be the magnum opus? Would you consider it in a way?
*  In a way, yeah. Can you think back to what really started you down this path?
*  Did you did you have an aha moment about metaphysics or about substance versus process metaphysics or whatever you're working on?
*  Or was it, you know, did these ideas sort of slowly develop these ideas that have been recurrent in your work for, you know, many years?
*  Well, there have been several aha experiences.
*  The one regarding process was actually in the 60s.
*  Yeah, a short time ago. Yeah.
*  I mean, my training is in psychology, not in philosophy.
*  Aren't you a cognitive or a psychotherapist or is a psychiatrist?
*  My training was originally in psychotherapy and statistics and methodology and developmental.
*  I was at the Committee on Human Development at Chicago, which is very interdisciplinary, but also very developmental.
*  So it was kind of a mixed bag.
*  But I think that has served me well in the sense that, you know, I haven't felt limited to some smaller category.
*  But anyway, you know, I read a lot of stuff back then.
*  It was the beginnings of cognitive science.
*  There were little boxes connected with arrows all over the place.
*  And the things supposedly going on in those boxes were not only themselves mysterious, but they weren't always even consistent from one box to another.
*  They were completely different levels and modes of analysis and so on and so on.
*  And so I realized, look, I may or may not get it right, but I've got to have a coherent, consistent metaphysics in order to do this.
*  So you started with metaphysics, you thought, because this is foundational.
*  I mean, it's actually that's in the title of your book.
*  But I mean, these are some fundamental things. And that's where you started, huh?
*  Yes, yes. And I mean, I could try to recapitulate some of the thinking I went through.
*  Please. Yeah.
*  Now, interestingly enough, although this has not been the focus, but in the 60s, my my basic exploration was phenomenological and phenomenologically experiences a flow.
*  And what we experience is a flow that we don't completely determine.
*  So there's got to be something else that co determines it with us.
*  And that has to be a flow.
*  So it has to be process in some sense.
*  Now, what kind of a process? Well, who knows?
*  I mean, that that's to be explored.
*  That's what science is for, among other things.
*  But that's that was my original adoption of a process framework.
*  And then for about 10 plus years, I had a kind of a slogan.
*  I was looking abstract machine theory as my my technical surrogate for process.
*  And my slogan was, if I can't translate it into abstract machine theory, I don't yet know what I'm talking about.
*  OK. And some things took me 15 years to try to translate into abstract machine theory.
*  But in the early 80s, I realized, look, abstract machine theory doesn't do it yet either because it's strictly discreet.
*  And for some phenomena, that works all right.
*  But for some phenomena, you have to have continuity and you have to have timing.
*  And there's there's a footnote in my 1983 book where I point that out that you got to have timing, otherwise a whole lot of stuff doesn't work.
*  And so I had to shift to dynamic systems theory.
*  So dynamic systems theory is kind of now my technical surrogate for process.
*  I mean, this is it's kind of dynamical systems theory is I don't know if exploded, but in the past 15 years or so in neuroscience, I mean, I'm I'm a neuroscientist by training.
*  And but I didn't really get into the dynamical systems theory stuff.
*  But in the last 15 or so years, it's really come on to the scene, especially with these really large multi neuron recordings that are being used these days because you have to have something to deal with such a large population.
*  And it kind of naturally lends itself to the state space and dynamical systems theory.
*  So no, exactly right. There is a limitation to dynamical systems theory in a pure sense.
*  Dynamical systems theory cannot account in itself for normativity for things like representation.
*  So it captures dynamics, but not all dynamics are normative.
*  So you need something more than just dynamical systems theory.
*  Well, let's go. You want to just start with some metaphysics, then process versus substance and build our way up to normativity.
*  And actually, let me show you. I am reading all your stuff.
*  I mean, you're not going to read this, but I actually made and this is great for this is an audio only podcast.
*  I actually started a mind map of all the concepts that you have to relate to each other, you know, just to help me guide me.
*  And it all starts with process metaphysics. So so process versus substance metaphysics.
*  Why does that matter? And what you know, what do we need to know there?
*  Well, substance metaphysics is is inherited from the Greeks.
*  There are also process philosophers, even among the pre Socratic.
*  So like Heraclitus has the famous, not quite accurate quote of you can't step in the same river twice.
*  But then my Parmenides comes along.
*  Parmenides argued for something that's really sort of strange sounding when you first hear it.
*  He argued that change doesn't exist and metaphysical metaphysically cannot exist.
*  So one of his core arguments was suppose you consider two fundamental metaphysically fundamental whatever's A and B for A to change into B,
*  A would have to disappear into nothingness and B would have to appear out of nothingness.
*  Nothingness can't even exist, so it can't serve as any sort of intermediary like that.
*  And this framework also leads to the sort of infamous quote of from nothingness, nothingness comes,
*  which is kind of one of the classic anti emergentist phrases.
*  So in order for B to come out of nothingness, that would have to be emergence in some sense or another.
*  And this sounds weird until you realize he's not talking about higher level stuff.
*  He's talking about A and B as the most metaphysically fundamental, whatever they are.
*  And Democritus and Empedocles, among others, came along and some people take them to be arguing against Parmenides,
*  but other people take them to be furthering the Parmenidian framework.
*  Parmenides, of course, knew that the world appeared to change and he had a whole, I mean, these guys wrote in poetry.
*  He had a whole set of poems addressing appearance, which we don't have.
*  We don't know what he said about that, how he tried to explain the appearance of change.
*  But we do know what Democritus and Empedocles did.
*  What they did was to say, OK, in the case of Empedocles, there are these four metaphysically fundamentals,
*  their substances, their stuffs, earth, air, fire and water.
*  They don't change ever.
*  And so they're consistent with Parmenides.
*  But the appearance of change is superficial relative to those.
*  So the mixtures of them can change.
*  We can get different mixtures and remixtures of earth, air, fire and water.
*  And Democritus had little atoms, indivisibles, and they never change, but their configurations can change.
*  So change only occurs at the upper levels, not at the fundamental metaphysical levels, according to either one of these guys.
*  And then Aristotle comes along and he mostly modified Empedocles more than Democritus.
*  So he ended up with stuffs and substances.
*  And it was much more sophisticated than Empedocles and involved some revisions.
*  So his earth, air, fire and water for Aristotle could change into each other, but he still maintained the Parmenidian restriction to there's always an unchanging substrate.
*  And for Aristotle, this now gets translated as matter.
*  And for the next 2000 years, it was assumed that Aristotle assumed something that people called prime matter.
*  And it was the unchanging substrate for everything else.
*  So for 2500 years, that has been a fundamental assumption.
*  It has shifted in the last several hundred years to atoms and then to particles, some subatom particles.
*  But it's still the same assumption. They're particulars, they're entities, they're things.
*  They exist independent of everything else in the world.
*  They've been process thinkers since Heraclitus, but they sort of popped up here and there and come up with some version of process or some intuition in a process direction.
*  They've never really dominated. They've never really completely caught on.
*  So process has been around for this 2500 years, but it's always been very much a minority kind of position.
*  So here we are today with a particle version of this Parmenidian heritage.
*  And there are two problems and a major, major disabling that it yields.
*  Two major problems. One is if you actually have dimensionless particles.
*  And that's all there is in the universe. Nothing would ever happen.
*  Dimensionless particles can't ever hit each other.
*  They have cross section zero and they can't attract and they can't repel because the particles are all there is.
*  Now, in kind of a contemporary hybrid version, people think of dimensionless particles connected by fields.
*  Fields descendant from Maxwell, who introduced a completely new kind of metaphysics, which happens to be a process metaphysics.
*  Fields are processes. So if you've got particles plus fields, the fields can account for attraction, repulsion, all kinds of things.
*  But fields are processes. So that's already major, a major, major shift.
*  Furthermore, according to our best contemporary physics, there are no particles at all.
*  Anyway, so both logically and in terms of physics, we're forced to a process framework.
*  Now, that's handy because I mean, it's not only more true and more consistent and logically acceptable,
*  but it's also very handy because if we go all the way back to Parmenides, B cannot emerge out of nothing.
*  And with Democritus or Aristotle, nothing can emerge.
*  It can't even change, let alone emerge. If you get impetitually in Earth, Air, Fire and Water, you can't get a fifth substance.
*  So emergence is precluded. And as a matter of fact, although they didn't use the word emergence,
*  Parmenides and arguments are explicitly against emergence. B cannot emerge out of nothingness.
*  Essentially, everything has to have already existed innately for all time.
*  Exactly. Since the beginning of time, which is a real problem because we need emergence to handle things that didn't exist 13 billion years ago.
*  Right. Right. So moving into a process metaphysics, I argue, defeats the arguments against emergence.
*  The arguments against emergence in the 90s. I did a lot of work on this.
*  And I was trying to find the most what I considered to be the most powerful arguments against emergence that I could find in the literature.
*  And the most powerful ones that I thought were there were by Yagwan Kim.
*  And I don't know if you want me to get into any of the details, but basically all of Kim's arguments presuppose a particle metaphysics.
*  It seems like a lot of the so I mean, many of the things that we may eventually talk about a lot of modern theories of how brains function and how to build A.I.
*  Many of them seem to rest on this fundamental assumption of a substance metaphysics.
*  And that's why I suppose that's why I mean, you keep you come back to this often in the literature.
*  I mean, this is like starting with first principles. Right. And that's why it's important is that the flaws begin with the metaphysical assumptions.
*  Right. No, exactly. I mean, metaphysics constrains our thinking that even constrains our research empirical methodology.
*  It sometimes even forces a particular position, but more commonly it constrains it.
*  And if it constrains us away from things like emergence, which pretty clearly in some sense have to occur, you know, it constrains us into a realm of nothing but the possibility of errors, various kinds of errors.
*  Now, that doesn't mean it can't be powerful. I mean, the particle framework, the substance framework.
*  Framed the development of science in Western thought.
*  And clearly that's been very powerful, but it has its own limitations and a whole philosopher of biology pointed out the history of Western science is a history of substance models being replaced by process models.
*  You know, the substance flow distant being replaced by combustion for fire, the substance caloric being replaced by kinetic energy for temperature for heat, the substance vital fluid being replaced by various sorts of open systems for life.
*  The one domain and hold and go this far, but I take it this far. The one domain in which that hasn't yet occurred is mine.
*  We are still substances, substance thinkers and structuralist thinkers with respect to mind.
*  And, you know, partly that's just a delay. Not all of these other shifts took place simultaneously either.
*  But I think there's a fundamental reason for why that's the last one.
*  The fundamental reason goes like this.
*  If you accept the Parmenidean, democracy and pedically in Aristotelian framework.
*  This was all part of the early development of naturalism.
*  Naturalism being differentiated out of, you know, spirits and gods and all this kind of stuff.
*  And the basic idea was you don't need to appeal to the world of spirits and gods and so on.
*  The natural world contains its own explanations.
*  I mean, that's basically what naturalism means.
*  Now, of course, that leaves open what is the natural world.
*  But nevertheless, that's the spirit behind it.
*  And it's taken various forms depending on how we think of what the world is.
*  It's taken on the form of atomisms, materialisms, physicalisms of various sorts, et cetera, et cetera, et cetera.
*  But the basic idea is the natural world is things, causal processes, causal relations among the things and facts about the things.
*  That's it.
*  But notice there's nowhere in that conception of the natural world any normativity, no mind, no intentionality.
*  No good, bad, no true, false.
*  So it completely excluded or at least split off the world of normativity.
*  So now we have two realms.
*  We have the quote unquote natural world and we have the normative intentional world.
*  And metaphysics ever since then has been constrained to this split framework.
*  And that only leaves three possibilities.
*  You either have a dualistic metaphysics like Aristotle or Descartes with, you know, physical substance and mental substance.
*  There's a way in which even the logical positivists in the early part of the 20th century had a dual framework.
*  Or you try to make do with just one side of it.
*  So you can be Hobbes or Hume on most interpretations and try to make do just with the physical world realm.
*  Or you can be an idealist like Green and Bradley or Hegel or somebody like that or Strawson today or various other people who try to make do just with the mental normative side.
*  But notice it would be kind of nice if we could connect the two realms via emergence.
*  But emergence is precisely what is precluded by the basic parmenity and arguments that led to all this.
*  Just to be clear because they're different types, you know, people mean different things when they say emergence.
*  So, you know, whether it's epistemological emergence or ontological emergence, maybe it would behoove us to for you to just say a word of what you mean by emergence in this case.
*  Yeah, the literature is confused and confusing.
*  And part of the reason for it is the heritage of what's called British emergentism.
*  So the vitalist came along the 19th century and said vital fluid, that's life.
*  The British emergentist said, oh, well, we're going to be more scientific, more naturalistic than that.
*  We're going to propose that life is emergent.
*  What did they mean by emergence?
*  What they meant by emergence was roughly the following.
*  Everything is atoms.
*  Everything is particles.
*  And certain kinds of configurations of particles.
*  Fit some kind of laws that have already been there.
*  And that's the sense in which this is supposed to be naturalistic because they're supposed to be natural laws.
*  And when those configurations come into existence, those laws apply and they make certain things happen that would otherwise not happen without those laws.
*  There's several things that follow from this.
*  But one is those laws are what philosophers sometimes call brute.
*  They're just there.
*  There's no explanation for them.
*  There's no deriving them.
*  You know, but they have important consequences because life would be an example of an important consequence.
*  One of these brute laws applying to configurations that happen to constitute you and me and so on.
*  OK, so.
*  During the 20th century, most philosophers rejected emergence, but what they were rejecting was British emergentism.
*  And when people now talk about strong emergence, they usually are talking about British emergence.
*  And when they talk about epistemological emergence, they mean, oh, well, it's best to treat it as emergence simply because it's so complex that our cognitive abilities can't handle the complexity.
*  Notice that is not an exhaustive dichotomy because it leaves out the possibility that there is a kind of emergence that can be deduced or derived and explained by the fact that it's not a complex.
*  But nevertheless, is more than just epistemological.
*  And so that's why the literature gets very confused, because this third possibility just isn't there in that standard way that standard dichotomous way of thinking about this.
*  People starting, you know, 60s, 70s, even the physicists like a condensed matter physicists talk about emergence.
*  They are not talking about British emergence.
*  They're talking about this other kind that I just outlined of something emerges in the sense that it's a property of the whole.
*  It's not there in any of the pieces or parts, but it it's not brute in the British emergent sense.
*  So condensed matter physics, you know, they they make great efforts to try to derive the sorts of things that can happen in condensed matter physics.
*  You get emergent new kinds of properties.
*  That's the realm of emergence that I'm talking about.
*  I'm talking about emergence that gives you new properties, new consequences in the world.
*  But that doesn't mean they're not deriving.
*  As a matter of fact, I hope they are deriving.
*  If they're not, we're back to some sort of dualistic metaphysics about the world.
*  Right. So we haven't even mentioned the word interactivism yet.
*  And this is all wrapped up in your interactivism approach to all of this, which in that I suppose emergence has a it's the third way where and you can correct me if I'm wrong, where it's highly dependent on the environment and the organization of the things surrounding the entity.
*  So there's a natural fundamental interaction of an entity with its environment and that process that's happening and emergence occurs through that interaction.
*  Yes, or perhaps in that interaction in that.
*  Sure. OK. Yeah.
*  A pure prepositional issue that I think has a lot of depth to it is we usually talk about emergence from.
*  Uh huh.
*  But notice emergence from means that whatever is emergent is a separate substance from whatever it emerges from.
*  Right. And so that very way of talking about it, I think, is itself highly misleading.
*  So I've come to try to say emergence in it's a property that is emergent in some organization of process.
*  And yes, once we've got emergence, it becomes possible to try to account for normative emergence and thereby reconnect those two realms.
*  And once we got at least the bare possibility of normative emergence, it become possible to account for particular normative emergencies.
*  So the first one I try to account for is normative function.
*  And the next one I try to account for is representation, which is the normativity of truth and falsity as as emergent in a particular normative function.
*  Yeah. So you just kind of defined what representation is for you in the interactive interactivism world, which is having a truth value is essentially what you would say constitutive of a representation.
*  Yes.
*  Representation ever since the Greeks has been taken to be a normative representation.
*  Yes.
*  Representation ever since the Greeks has been taken to be well, I mentioned like represents like.
*  And then, you know, we receive essences, which are kind of like for Aristotle receiving essences was something like receiving geometric axioms or or concepts in geometric axioms.
*  And then deriving theorems like Euclid.
*  And so we derive theorems about the world on the basis of our receiving essences.
*  I mean, there's a whole connected framework here that we've we've still inherited and we still work with it.
*  I mean, Helmholtz model of perception was receiving sensations and then unconscious inferences that constructed a world for us.
*  I mean, that's that's the normativity of the normative representation.
*  So this is the development of what you call encoding ism, right?
*  Exactly.
*  So the reason they call it encoding ism is that this idea of representation being constituted in some sort of correspondence.
*  Notice that the signet ring is a structural correspondence.
*  But even with Locke, it's a causal correspondence.
*  And it's gotten more sensitive to the world.
*  And it's gotten more sophisticated.
*  Then we talk about lawful correspondences.
*  We talk about information semantics, correspondences of being in covariance with each other.
*  That's perhaps the most sophisticated today is covariance correspondences.
*  And these correspondences are all factual.
*  I mean, you know, there's either a logical or a logical correspondence.
*  And these correspondences are all factual.
*  I mean, you know, there's either a causal connection or there isn't.
*  There's either an informational covariance or there isn't.
*  There's either and so on and so on and so on.
*  They're all factual.
*  So they all fall within the factual realm.
*  They cannot account for the normative realm.
*  They're factual.
*  They don't know how to cross over into the other metaphysical realm.
*  David Hume would be happy with this.
*  Well, actually, Hume said, I mean, this is not quite a quote, but it's close.
*  Hume basically said, hey, I have no idea how perception works.
*  I'm just going to assume it.
*  I don't need a model of how perception works for my purposes, for Hume's purposes.
*  But he did have an argument that I think applies here.
*  Well, he didn't have an argument.
*  He made a claim that applies here where he said, no ought from is, no norms from facts.
*  So he expressed this dualistic, this metaphysically dualistic split.
*  And he never actually provided an argument for it.
*  His argument consists of a phrase that goes something like, what seems altogether inconceivable, quote unquote.
*  And what seems altogether inconceivable is how you could ever validly get or soundly get, he didn't really make the distinction, from facts to norms.
*  From is to ought.
*  From is to ought.
*  And people have spent a lot of time trying to figure out, is there really an argument there behind Hume that's a good argument?
*  Oh, yeah.
*  There's whole books written about it.
*  Yeah.
*  I should say eventually we're going to get to the fundamental tenets of interactivism being that representation is born of a set of anticipatory possibilities.
*  So I just want to jump the gun and say we're going to get there.
*  Let me just jump to that.
*  And then I can come back to a more careful, formal framework if we'd like.
*  Living beings are far from thermodynamic equilibrium.
*  They have to be.
*  Far from thermodynamic equilibrium processes have to be maintained far from thermodynamic equilibrium.
*  And some far from equilibrium processes contribute to their own maintenance.
*  They are self-maintenance.
*  They need more.
*  They need constant input of wax.
*  Exactly.
*  But they are given the opportunity to maintain their own self-maintenance.
*  So, one of my canonical examples there is the candle flame that keeps itself going by maintaining its own combustion threshold temperature, etc., etc., etc.
*  Candles are self-maintenant, but there's a limitation to the self-maintenance.
*  If the wax is running out, they don't have any alternative things they can do.
*  But they are given that they are self-organizingly self-maintenant.
*  They self-organize into a self-maintenant process.
*  And notice self-maintenance is emergence here.
*  It's a property that is realized in the organization of the candle flame.
*  It's not emergent from.
*  It's not some substance over and above the candle flame.
*  It's a property that's realized in the organization of the flame itself.
*  Which includes its environment and the properties and the organization of its surrounding environment.
*  One of the phenomena here that I could get into later in more detail is that when you're in a process framework,
*  assumptions that are taken for granted within a substance framework become at least problematic or at least require their own explanation if they exist at all, like boundaries.
*  What's the boundary of a candle flame?
*  Right.
*  And so on. We can get into that more later if you like.
*  OK, so candle flames, if they're running out of wax or out of luck, unless the candle happens to be on a wooden desk.
*  That happened in an adjoining cubicle at the University of Texas when I was there my very first year.
*  Some guy in an adjoining cubicle went away for the weekend leaving a candle burning sitting on his desk.
*  Oh, my gosh.
*  Either an old rickety dry desk or a highly lacquered desk.
*  Either way, whatever it was, there was a fire.
*  Yeah, it got put out because there was huge damage.
*  But, you know, wow, I have to always put that exception in.
*  But even if it's running out of wax, if it has something else combustible, something else.
*  Yeah, but that's a different kind of flame right there.
*  But OK, yeah, that's right.
*  OK, but Don Campbell's bacterium has options.
*  It can shift what it does in order to maintain its emergent property of being self-maintenant.
*  So the bacterium can swim.
*  And as long as it's swimming up a sugar gradient, it will tend to keep swimming.
*  If it finds itself swimming down a sugar gradient, it will tend to tumble.
*  So it can contribute to its own far from equilibrium self-maintenance.
*  Exactly, because it switches what it does.
*  Swimming is a self-maintenant process if it's going up the sugar gradient.
*  It's detracting from its self-maintenance if it's going down the sugar gradient.
*  And it can detect that and shift what it does.
*  So it self-maintains its condition of being self-maintenant.
*  And that is normative to you.
*  Yes. I call that recursive self-maintenance.
*  And it is normative.
*  It's normative not in some absolute sense.
*  It's not like there's some absolute good or bad.
*  But it's normative in the sense that it's normatively good relative to the persistence of the bacterium.
*  There is a truth value to the persistence of the bacterium relative to the sugar gradient and its surroundings.
*  Well, indirectly, yes.
*  But I'll get to a stronger sense, I think, of truth value in just a moment.
*  The sense in which it's a relative notion, a relational notion of normativity, is illustrated by the parasite.
*  So if you've got a parasitic worm, the heartbeat of the worm is normatively functional for the worm, but it's normatively dysfunctional for the host.
*  So you can get normativity relative to one thing and dysfunctional normativity relative to something else in the same phenomena.
*  I suppose symbiosis would be a much more happy normativity for everybody.
*  Right. OK.
*  So normativity in the full truth functional sense, I can get out of this level of analysis that I've just done, but it doesn't do much because these kinds of relationships are they're changeable, but they're relatively static.
*  I could say, for example, that if if the bacterium keeps swimming, there's some sort of an assumption, some sort of a presupposition that this is a good condition for swimming.
*  And if it happens to be swimming up a sugar gradient, that presupposition is true.
*  If it happens to be swimming up a saccharin gradient, that presupposition is false.
*  So here we have a very primitive version of truth and falsity.
*  A somewhat less primitive version occurs when we have more complicated agents.
*  So the bacterium pretty much just switches from one thing to another, switches from swimming to tumbling to whatever.
*  It's a switching mechanism.
*  Triggers.
*  Triggers trigger the switches in a more complicated agent like the frog.
*  There's more than one thing it could do at any given time.
*  And so it needs some sort of indications of what it could do right now and here, here and now.
*  It does the frog no good to flick its tongue in a direction in which there's no fly or worm.
*  So it has to have some indications of which directions might yield eating if it were to flick its tongue.
*  It does me no good to open the refrigerator for a beer if I'm out in the middle of the forest because there's no refrigerator there.
*  So I've got to have indications of what I could do.
*  You would be demonstrating poor situational knowledge, as you call it, in that instance.
*  Well, exactly. Yes, exactly.
*  So we've got to have these indications for any kind of complex agent.
*  And notice this takes the triggering relationship in the bacterium and splits it into two parts.
*  It splits it into an indication and then a selection among the indicated possibilities.
*  And my claim is that the indication aspect of this is what gives us finally something resembling full representational truth value.
*  The selection aspect of this leads us off in the direction of the exploration of motivations.
*  Because motivations are precisely that. They're selections of what to do next.
*  Motivation. I'll say a word or two about that.
*  Motivations are often thought of in terms of drives or something like that.
*  They're energy that makes us do something rather than nothing.
*  But since we're far from equilibrium systems, we can't do nothing.
*  If we do nothing, we're dead. If we do nothing, we go to equilibrium.
*  So the problem of motivation has to be, you know, textbooks on motivation, some of them at least know this and talk about it.
*  Motivation has to be a selection process, not a drive process.
*  Anyway, that's that's the selection aspect of it.
*  The indication aspect of it, the indications as indications can be true or false for the frog.
*  If you've got some evil biologists sitting around tossing pebbles in front of the frog,
*  frogs will tend to try to flick their tongue at the pebbles.
*  And notice that makes the indication of tongue flicking followed by eating false.
*  They might try to swallow the pebble. I don't know. I don't really know what frogs do with that.
*  You're not an evil biologist, huh?
*  Right. Yeah, I'm not.
*  Furthermore, I'd have to be further evil because I'd have to dissect the frog to see what happened to the pebble.
*  Yeah.
*  Anyway, so anyway, those indications can be true.
*  They can be false. They can branch.
*  There can be two or three flies and a worm.
*  All possibilities. A hawk shadow flies overhead and the frog better jump in the water rather than take any of those tongue flicking possibilities.
*  They can also iterate.
*  So the frog might have an indication that it could move a little to the left.
*  And if it did so, then two more flies and a different worm come into range.
*  So they can branch, they can iterate.
*  And notice if branching and iterating can occur, you can get webs and potentially extremely complicated webs.
*  And I certainly claim that human beings have extremely complicated webs of interconnected realms of potential ways of interacting with the world.
*  And that's that's what I call situation knowledge.
*  It's knowledge about the interactive potentialities, the structure, the organization of interactive potentialities given our current situation.
*  So that's representational.
*  That has truth value.
*  It's not canonically representational yet because it's not a correspondence model.
*  It's not an encoding model.
*  Those kinds of models, I argue, have all kinds of problems of their own.
*  And it doesn't account for canonical kinds of representation like representations of small objects that takes further developments of the model.
*  So, number one, it's not a correspondence model because it's it's indications of possibility.
*  It's modal. It's not correspondences to actuality.
*  It's internal in that sense.
*  Yes. Now, it can involve correspondences to actuality in the sense that if the frog engages a certain visual interactions that differentiate a fly,
*  there will be a kind of correspondence with that fly.
*  But that correspondence is not itself representational.
*  It's a detection. And detections don't necessarily represent what they detect.
*  It's a differentiation and differentiations don't represent what they differentiate.
*  But on the basis of such a detections or differentiations, the frog can set up an indication that it could flick its tongue a certain way and eat.
*  That does have truth value.
*  So there's a split here between what I call contact.
*  That's the detection differentiation and content.
*  That's the part that has truth value and standard ways of thinking about representation.
*  And the frog and the frog representation conflate the two standard ways of thinking about representation say, oh, well, the frog represents the fly and engages in Helmholtz and unconscious inference to conclude that it could flick its tongue a certain way and eat.
*  No, no, doesn't need any of that.
*  And furthermore, metaphysically, that can't work.
*  Correspondence is factual, not modal, not normative.
*  So, I mean, I can go on and on and on about the problems with the correspondence models.
*  The correspondence models have been known since the Greeks.
*  And many hundreds and hundreds of people have tried to resolve them without success.
*  My claim is that it's impossible to resolve them.
*  So long as you restrict yourself to a correspondence models correspondence models simply can't work.
*  They are restricted to the factual realm.
*  And as Hume showed, you can't get out of the factual realm into the normative realm without implicit definition and you can't get implicit definition without process, because implicit definition is relational.
*  And Kim showed that that is as long as you got a particle model configurations or relations don't get you anywhere, and so on and so on.
*  I mean, it's all intertwined and tied together.
*  I mean, I could say a whole lot more about what's wrong with correspondence models.
*  Let me just say a word or two about how this model of representation can represent more familiar notions of representation.
*  So my canonical example here is the child's toy wooden block as a kind of canonical example of representing a thing in some sense of the word thing.
*  Not in the Aristotelian sense, not in the metaphysical sense, but in the representational sense, the cognitive sense.
*  OK, so we got a toy wooden block.
*  The toddler can do all kinds of visual scans with it.
*  It can manipulate the block.
*  Each manipulation turns up a different visual scan possibility.
*  Each visual scan possibility evokes indications of further manipulations and therefore further possible visual scans, et cetera, et cetera, et cetera.
*  We have kind of a sub web of the overall web of possibilities, and it has two crucial properties.
*  One is it's internally reachable.
*  Every place in that web is potentially reachable from every other place.
*  Starting with any particular visual scan, you can achieve any other visual scan with the appropriate manipulations.
*  It has other interesting properties. It has a mathematical group structure, et cetera, et cetera, et cetera.
*  But the other property is that it's invariant.
*  It's invariant with respect to moving the block around or me moving around and leaving the block there.
*  So it's invariant with respect to all kinds of spatial translations.
*  I can put it away.
*  An unusual three year old to actually put it away.
*  But, you know, I could.
*  And it's still there.
*  And if I've got object permanence in the Jean Piaget sense, I know it's still there in the toy box and I could go back and get it.
*  So that invariance gives me a sense of my world beyond what I can actually perceptually access.
*  I know that the toy block is in the chest, the toy chest, even though I'm in a completely different room.
*  So my world in my situation knowledge extends into a different room and in the toy box that I cannot perceptually access right now.
*  All of that extension is sets of possibilities, sets of anticipations of what actions can be had.
*  And in this sense, it is you mentioned Piaget, but it's pragmatic also, you know, in the sense of of purse and John Dewey and Gibson's affordances.
*  And so it's a very action embedded system that some people talk about the these frameworks as the constituting the pragmatic term.
*  And incidentally, Piaget was influenced by Baldwin and Baldwin was influenced by purse.
*  OK, so the dissent there from Percy and pragmatism is direct.
*  Well, not quite. It's got one or two intermediaries.
*  But anyway, it's clear. And yes, so purse Dewey, the whole pragmatist tradition is made use.
*  I mean, it doesn't mean anything and everything in the pragmatist tradition.
*  Right. It would be something I would agree with.
*  But in this particular case, I can basically steal Piaget's model of the representation of a little toy wooden block precisely because it's an action based model.
*  Let's see. So let's see. Have we have we gotten up to the looks like we've gotten through most of the important ideas to that encapsulate interactivism.
*  What have we missed here that I mean, to cut you off?
*  Are we missing something important before we go on to talk about how it relates to other systems and brains and A.I.?
*  Well, up to the cognitive part, I don't know that we've missed anything.
*  Obviously, there's there's more to the model because then on the basis of this, I talk about the macro evolution of the nervous system and the emergence of social realities, persons, language, et cetera, et cetera, et cetera.
*  But that may not be as directly relevant to the connections to alternatives here.
*  Yeah. Well, so I don't I mean, there's a lot more to be had, obviously, but you've taken us through a bunch of the important concepts to situate interactivism.
*  Maybe one way to also, you know, I was going to ask you about its relation to inactivism because both interactivism and inactivism, sort of the embodied cognition kind of framework, both of them see both of them see cognition.
*  And life, life processes as inseparable as right.
*  Completely intertwined.
*  And in fact, you've said that that's kind of the central insight in both interactivism and inactivism.
*  So how are they? How do they differ then?
*  Well, there's several ways that they differ.
*  Some more basic than others.
*  But I think one way to illustrate how they differ in in a relatively basic way can be illustrated by going back to the history of inactivism.
*  Inactivism started with autopoiesis.
*  Autopoiesis grew out of what was called second order cybernetics.
*  And second order cybernetics differentiated the observer as a special sort of metaphysical category.
*  All distinctions were made by an observer.
*  So second order cyberneticians like this.
*  Notice it makes the observer metaphysically different from everything else.
*  You can't account for the distinctions internal to the observer in those terms.
*  There's more details of that argument, but the intuition, I think, is clear.
*  Autopoiesis with Maturana and Varela endorsed this and built on it.
*  And at a conference one time, I even heard Maturana acknowledge that this commits to an idealism.
*  And he had his own reasons for liking the fact that it committed to an idealism, which I think were not terribly good reasons.
*  But he also said he would never admit it out loud in the Northern Hemisphere because idealism was not considered to be a legitimate sort of position.
*  So he was he was advocating a model that he said was an idealistic model, but he didn't want to take it that far publicly.
*  So anyway, OK, so there's Maturana and Varela.
*  This idealism sticks around.
*  All kinds of little stories I could tell here, but let me just skip ahead.
*  The idealism is maintained with Varela when Varela initiated inactivism.
*  And it was maintained in a specific way.
*  Varela was strongly influenced by phenomenological approaches, by Buddhism, et cetera.
*  But the idealism is more than just a kind of an influence from that.
*  He explicitly endorsed Chalmers arguments.
*  Now, we haven't said anything about Chalmers, but Chalmers argues for an explicit dualism.
*  It's what's called a property dualism. It's not a substance dualism.
*  But mental properties are their own metaphysical realm.
*  They happen to be connected to, say, brain processes in this universe.
*  But there's no metaphysical necessity for them being so connected.
*  So in that sense, insofar as there is emergence there, it's a kind of British emergence.
*  And Chalmers even says, look, in some other universe, there could be beings that are causally identical to you or me.
*  And there's nobody home. There's nothing there.
*  That's the notion of a metaphysical zombie.
*  And all kinds of lead things follow from that. What's special about brains?
*  Well, who knows? But maybe there's nothing special about brains.
*  Maybe this kind of dualism, this property dualism, is everywhere, in which case you get a kind of panpsychism.
*  Oh, no.
*  And Chalmers has explicitly explored that possibility. I mean, I can go on.
*  Anyway, one of Chalmers' conclusions is the best we can do to study consciousness is to try to figure out the correlations between conscious phenomena and brain phenomena, nervous system phenomena.
*  There are correlations. Those are empirical. We can hopefully discover them.
*  We can't explain them. We can't ever bridge that gap.
*  And Varela explicitly endorses that.
*  So to the extent that inactivism is based on an explicit endorsement of property dualism, that doesn't mean you can't do anything.
*  But what you're doing is limited, quote unquote, to a descriptive approach.
*  You can describe the mental phenomena. You can describe the phenomena of the way people interact with each other in the world.
*  But you can't ever explain them in terms of things going on in the brain, even if you can come up with the correlations.
*  Those still won't be explanations.
*  So there is a fundamental difference.
*  In one of my papers, I talk about the fact that inactivism has split into several categories.
*  Yeah. The one that I think is metaphysically clearest is de Paolo and de Ager.
*  And they are very clearly in my judgment, purely descriptive.
*  I at least attempt to be an emergentist model and try to account for these phenomena.
*  It also means that their descriptions become sort of stipulative. They're not really explanatory.
*  What you are going to call meaning making is not explicable in terms of underlying nervous system or bodily processes.
*  It's rather explicable from this descriptive perspective in terms of what sorts of behaviors and interactions I'm going to call meaning making.
*  Now, you know, that's not necessarily the end of everything, but I take it to be a real limitation.
*  It makes a whole lot of the descriptive processes purely stipulative.
*  And, you know, some stipulations work better than other stipulations.
*  So you can still make assessments about how useful they are, but you can't make an assessment about how correct they might be because they're not grounded in anything more basic.
*  So there's I mean, I could go on, but there's a fundamental difference from inactivism.
*  Let me ask you, because I want to get on to relating the brain where the brain comes into all this.
*  But before that, I'm just you know, I had this in the back of my head, whether you know, we talk about far from equilibrium, thermodynamic equilibrium systems.
*  And this is just a completely naive question on my on my part.
*  But I'm wondering if we can say anything about the qualities that covary as a function of the distance from that equilibrium.
*  Right. So do do systems that are farther from thermodynamic, thermodynamic equilibrium, do they demand a more complex web, a more complex situation, knowledge to update?
*  I mean, has that ever I don't even know if that's even been considered.
*  Not in and of itself. I mean, thermodynamic equilibrium is a thermodynamic notion.
*  Being not at thermodynamic equilibrium is a thermodynamic notion.
*  Being far from thermodynamic equilibrium is an additional concept. It's an additional property.
*  So the physicists make a distinction between being not at equilibrium and being far from equilibrium.
*  Most of the literature doesn't really know about this distinction or honor.
*  Being not at equilibrium basically means you are close enough to equilibrium that mathematically linear approximations work just fine.
*  OK. Being far from thermodynamic equilibrium means being far enough that you have to use nonlinear mathematics to talk about what's going on.
*  And all kinds of new things emerge when you're talking about nonlinear mathematics.
*  So living systems are all far from equilibrium. They're not near equilibrium.
*  A potential problematic example here would be like a robot that can detect when its battery is getting low and go to a charging station.
*  There's two senses in which that's not far from equilibrium.
*  One sense is the battery is never far. It's always near equilibrium.
*  And so it's reversible. That incidentally is a property of far from equilibrium is that it's nonreversible.
*  If you go to equilibrium, you cannot go back. Whereas if it's near equilibrium linearly, you can go back.
*  I see.
*  Another problem with the robot is its battery may be near equilibrium but not at equilibrium.
*  But the rest of the body is energy well. It's at equilibrium or close to it.
*  And so there is no irreversibility at the level of the whole body.
*  There is also not an irreversibility even at the level of the battery because it's still in the linear realm.
*  So irreversibility is the critical locus, so I claim, of normativity.
*  It's got to be maintained because you can't go back.
*  You're dead.
*  Exactly. And that also illustrates the sense in which it's relative. It's not absolute.
*  There's nothing to say that the candle flame is absolutely good.
*  But there is something to say that some things contribute to the persistence of the far from equilibrium candle flame and some things detract from it.
*  So it's normative relative to the persistence of the candle flame.
*  And it's relative to in an quote unquote important sense simply because the candle flame is far from equilibrium and it cannot be reversed.
*  You could always light it again, I suppose, if it goes out.
*  But, you know, that's a different process. Right. You've broken the continuity.
*  My naive thought was just that it takes more energy and potentially more complexity to maintain oneself far from equilibrium.
*  Right. So that that might take more hierarchical recursion than processes that are true.
*  That's true. I talk about that using the word autonomy.
*  Yeah.
*  And a lot of folks use the notion of self-maintenance.
*  Some of them, I think, have actually borrowed it from me, although it goes back to at least Aristotle.
*  Aristotle talks about it.
*  And they certainly use the word autonomy, but we use them in slightly different ways.
*  A lot of people talk about self-maintenance in a way that is derivative within autopoiesis, where autopoiesis is the reconstruction of components.
*  And these folks like Alvaro Moreno, also in San Sebastian, or DiPaolo and DeJager, will acknowledge you can't do autopoiesis without being far from equilibrium.
*  You can't. The work of autopoiesis can't happen.
*  And so they will tend to define self-maintenance in terms of being roughly equivalent to autopoiesis and autonomy as being autopoiesis.
*  The trouble is, and here's another difference from inactivism, although inactivists have recognized this and tried to do things with it, but I don't think they've succeeded.
*  But if you take the classical notion of autopoiesis as the construction of the constituents, nothing can change.
*  If you construct new constituents, it's a different system.
*  It's not autopoetic anymore.
*  So DiPaolo said, OK, we have to add on top something like adaptability.
*  But it's kind of an ad hoc addition to try to account for learning, development, things like that.
*  And Moreno has a book out in which he has a maintenance of what he calls constraints.
*  So it's no longer components.
*  But he's one of the ones that made this criticism decades ago that autopoiesis can't account for learning and development.
*  And his model of constraints has exactly the same problem.
*  If you're maintaining the structure of constraints, where's the learning and development?
*  And so what Moreno does is add what he calls regulation, which is roughly the equivalent of DiPaolo's adaptability.
*  And again, it's kind of an ad hoc thing on top of it.
*  And in my judgment, it basically, A, doesn't work and B, is ad hoc.
*  So to the extent that it does explain stuff, it's an ad hoc explanation.
*  Whereas self-maintenance, as I'm talking about it, is maintenance of the relation of being far from equilibrium.
*  It's relational to the environment intrinsically. It's not the maintenance of anything internal.
*  And when you are maintaining a relation, the relata may well change.
*  So if I've got a pan balance and I'm trying to maintain the relation of the pan balance being balanced,
*  and one of the pans is organism and the other pan is environment and environment comes along and dumps some extra weight on that pan,
*  the maintenance of the relation is not necessarily changing something in the external pan.
*  The maintenance of the relation is maybe adding something to my pan to maintain the balance.
*  So now I no longer have the same thing in my pan. It's not the same components.
*  It's not the same constraint relations, but it does maintain the balance.
*  And conversely, you can have things going on inside the organism that change things in the environment in order to maintain the balance.
*  We call it, among other things, niche construction.
*  So maintaining the balance is a point that I claim of being fundamental importance that so far none of the inactivist literature that I know of has really caught up with.
*  And they confuse themselves with this autopoiesis heritage, as far as I can tell.
*  And even though they've recognized some of the problems with the autopoiesis heritage, their solutions are ad hoc.
*  You just add on top some sort of adaptability process or you add on top some sort of regularity process without realizing that if you're maintaining the balance, not the constituents, that comes for free.
*  It's just automatic in that way of thinking about the metaphysics.
*  I'd like to transition us into talking about brains.
*  And I'm going to I'm going to do it by way of another comparison, I suppose, because you even recently have compared interactivism to the predictive brain, Bayesian brain, free energy principle approach, which is wildly popular in neuroscience right now.
*  So I thought maybe you could spend a moment just comparing what's different and potentially what's different between interactivism.
*  And I'm just going to say the probabilistic brain writ large.
*  And I'm going to let you focus on whichever one of those free energy principle or etc.
*  Yeah, no. Again, I think a historical perspective is useful here.
*  Sure.
*  The predictive brain folks say, OK, this has arisen out of early Helmholtzian models.
*  Early Helmholtz models presumed that we receive inputs we engage in unconscious inference on the basis of sensations that yield perceptions.
*  OK, so they shift.
*  They shift on the basis of McKay's work in the 60s.
*  McKay introduced analysis by synthesis.
*  McKay said, look, analyzing an input stream is not just a passive process.
*  It's a predictive process.
*  We understand in an analytic sense the input stream if we can predict it.
*  I think there's several steps forward in that notion.
*  One is we now have an active brain.
*  It's not a passive deductive system.
*  So it's actively engaged in the construction of predictions.
*  There is a problem with it, however, McKay actually had a strong influence on my own thinking.
*  I liked this active part, but I realized, look, predicting the inputs gets us back to empiricism.
*  And so that's a serious problem.
*  So I think there's both a step forward as well as a step in the wrong direction right there.
*  OK, then we get to the question, well, what's doing the predicting?
*  Something has to come up with the predictions.
*  And this field seems to have, oh, well, there's a second step introduced by Powers in the early 70s.
*  He has a book called Behavior, the Control of Perception.
*  And these folks may have come up with this all by themselves.
*  I'm not sure. I've talked about Powers as being an early version of this.
*  And I've seen in some of the recent predictive brain stuff that they've referenced Powers.
*  I don't know if they got it from me or they simply just covered it on their own.
*  But Powers, Behavior, the Control of Perception says, look,
*  Well, Powers was a cyberneticist and Behavior, the Control of Perception is basically a feedback notion.
*  We do things in the world to control the perceptions that we have.
*  And so in that sense, it's consistent with the McKay version, but carries it further.
*  It's not just predicting the inputs. It's also producing the inputs.
*  OK, what's doing the predicting?
*  Well, you need some sort of decision theory, some sort of decision process.
*  Well, decision theory is all over the place, depending on what we can assume and what kind of information we have.
*  There's linear models. There's Maximin.
*  I mean, I teach this stuff. I have a degree in statistics.
*  And one of the powerful decision rules is Bayes.
*  So for reasons that, frankly, I don't fully understand, Bayes has become the big deal.
*  It's taken to be powerful. It's taken to constitute cognition.
*  And it may constitute some cognition, but it is, quote, just, unquote, a decision rule.
*  And it's a decision rule that can't work unless you have certain sorts of information.
*  So suppose you don't have priors. Well, maybe you need to use linear models.
*  Suppose you don't have and so on and so on. Maybe you need to use Maximin, et cetera.
*  You may need to use some other decision rule in order to make a maximally rational, logically rational decision.
*  But nevertheless, they talk about Bayes.
*  Well, Bayes as a decision rule presupposes lots of stuff and it yields.
*  It enables lots of stuff. One of the things that it enables that is all over the place in this literature is you need priors.
*  Where do they come from? Well, maybe the priors come from a higher level base.
*  Where do those priors come from? Maybe they come from a still higher level base.
*  This can't go on forever. So at some point you need innate priors.
*  And they acknowledge that. Friston acknowledges that, how everybody acknowledges you need innate priors at some ultimate level.
*  Otherwise, there's an infinite homuncular kind of regress.
*  Exactly. And innate priors gives you all kinds of problem in its own right.
*  But there's an even more fundamental problem. All of these distributions, prior distributions, posterior distributions, our probability distributions, what are they distributed over?
*  They're distributed over spaces of hypotheses. Where do those spaces of hypotheses come from?
*  They don't even address that issue, let alone explain it.
*  Well, presumably they would come from innate priors built into...
*  They've got to be innate, right. Right. They've got to be innate because by default.
*  But that means that everything you can do, all of the decisions you can make have to be among hypotheses that are all innate, including the innate hyperpriors.
*  So all of the representational issues have to be innate.
*  I mean, in a sense, it's a total reductio of the whole framework, in my judgment.
*  And this is where interactivism, which allows the emergence of representation, differs.
*  So maybe you could say a word about how that differs. How interactivism avoids those innate priors.
*  Well, okay, I will. But just a moment. Let me mention a couple of other problems here.
*  Friston et al. talk about all of the reciprocal projections in the brain.
*  And maybe these hierarchies of reciprocal projections capture the progressively higher level Bayesian processes.
*  So you get signals going up and predictions going down, and then you get error signals going up to the next level, predictions going down, and so on and so on.
*  And presumably you can adjust the parameters of the probability distributions over the innate probability spaces, which they never say, to come up with ways that successfully predict everything.
*  Well, first of all, even in the visual system, which is sort of the canonical version of this, not everything is a simple hierarchy.
*  It goes all over the place. It's a very complicated, partially ordered hierarchy.
*  They never address the partial ordering and what that's doing there. Furthermore, a whole lot of the projections in the brain are not two node.
*  They're multiple node. So like prefrontal to basal ganglia to thalamus back to prefrontal.
*  That's at least three nodes, if not four or five, depending on the interconnections within the basal ganglia.
*  How do you how do you do a Bayesian modeling of that?
*  I have no idea how you do a Bayesian modeling of that, and they never address it.
*  If we go to Friston more particularly, Friston argues for his free energy on two grounds.
*  One is, look, calculating minimal Bayes error is a complicated, intractable calculation.
*  Minimal free energy is an upper bound on Bayes error.
*  So if you calculate minimal free energy, it's roughly the equivalent of calculating minimal Bayes, but it's no longer intractable.
*  So it's computationally much to be preferred.
*  I don't disagree with the math. I mean, I have a math degree, so I can actually read his stuff without getting entranced and befuddled by them.
*  The math is really not all that complicated. It's pretty simple math.
*  He maintains that, but yeah, it does stop a lot of people, I think, from diving deeper.
*  The other ground is his notion of free energy is based on the underlying model of living systems being ergodic.
*  And he only says that one or two places, but it's very clear.
*  And all of his mathematics is based on the assumption that it's ergodic.
*  Ergodic is kind of a steady state of probabilistic.
*  In being a steady state, it's its own version of the autopoiesis notion of constructing the internals or the alvaro merino version of constructing and maintaining the constraints.
*  There's no growth. There's no learning.
*  Now, in more recent Friston, he introduces still a further distinction, which is basically just a classification distinction within the variables of what he calls input variables and output variables.
*  So now you've got the internal stuff. You've got the input output, which exists on the surface of the system.
*  And then you've got the external variables. And he calls this a Markov blanket.
*  I don't know exactly why he calls it a Markov blanket, except that Markov systems could capture the ergodicity in that the Markov can change, but it changes in a consistently probabilistic way.
*  So maybe that's where he got it. But I've never seen his own explanation for where he got it.
*  A Markov blanket, you know, he claims can do all kinds of things, but he also acknowledges, well, look, it doesn't apply to a candle flame because a candle flame doesn't have any boundaries.
*  He also says it has problems applying to even organs within an organism for similar sorts of boundary reasons, but not identical boundary reasons to which my comment is anything that applies to rocks.
*  And he says it applies to rocks, but does not apply to candle flames is not even a candidate for applying to living things.
*  I mean, it's just a very mathematically complex appearing, although it's not genuinely complex, version of the problem of continually constructing exactly the same components over and over and over again.
*  Only in this case, well, here's what ergodicity is. Suppose you've got an ensemble of a bunch of random variables.
*  Suppose you do a cross section analysis of a single time, a synchronous production of all those random variables.
*  That's going to give you some probability distribution.
*  Suppose now you pick one of those random variables and you do an across time analysis of what it produces.
*  If those two probability distributions are the same, that's an ergodic process.
*  So that's precisely the sense in which it doesn't change. If it were to change, you wouldn't have those sameness.
*  And so it's, you know, it sounds like process, but it's really static process.
*  Whereas the model that I'm proposing does not try to predict inputs.
*  Number one, so that's one in some ways subtle, but I argue very important distinction.
*  And number two, it self organizes these predictive or anticipatory setups in the brain.
*  The brain has to be ready for some things and will thereby not be ready for other things.
*  And if those setup processes for which I use the word microgenesis, which I actually stole from some of the brain literature, although I use it in a slightly different way.
*  Oh, I didn't realize that.
*  Yeah. Well, Brown and some others have talked about microgenesis for decades, but it's never become a dominant framework.
*  Deacon talks about microgenesis.
*  There's quite a few people who talk about microgenesis, but they don't.
*  They tend to talk about it in the sense that the brain has to set up the way it's going to do things.
*  But it's micro in the temporal sense in the way it's usually used.
*  So the setup process takes a little bit of time.
*  It takes some milliseconds or something like that.
*  And there are very interesting studies that show this.
*  There's a book called The First Half Second that has some very, very interesting.
*  It's an edited book, has some very interesting chapters in it that shows some of the things that can happen if you interfere during that microgenetic microgenetic first half second.
*  Just to give you an example, you flash a square.
*  It takes about half a second for the person to become aware that there's a square.
*  But the input, the perceptual input also not only goes to the occipital region, it also goes through the ascending reticular system and there then goes to the occipital lobe.
*  And we don't seem to become aware of it until that ascending reticular system signal gets there.
*  So now if you flash a square and then within that half second, like a tenth of a second later, you flash a circle, the person will be aware of a circle at the time they would have otherwise reported a square.
*  So, I mean, there's all kinds of weird things happening there that are very interesting.
*  I'm using microgenesis both on this kind of temporal macro sense as well as a micro spatial sense.
*  And the micro spatial sense says, look, the brain has to set up what it's going to do, not only in the macro spatial sense, the whole nervous system, but any local patch in the brain will do some things at one time and some different things at a different time.
*  It's not just that a process of different inputs, it can process differently and it has to set up how it's going to process.
*  Those setups are anticipatory because it may be anticipating the near future flow correctly, or it may be anticipating the near future flow incorrectly.
*  And there we get truth value.
*  Right.
*  How does it do the setup? And that's where I get into all the specifics about synapses not being the fundamental.
*  It is a functional unit, but it's not the fundamental unit.
*  And from an evolutionary perspective, it's a late development.
*  Yeah, let's well, let me let me just back up because the picture that you paint of the brain and its functioning is an interesting one because I mean, like you were just describing a little bit, you point out the the micro and macro scales, the spatial and temporal scales from from small to large and how these things function slowly, large and slow versus smaller and smaller and faster and faster.
*  And you paint a picture of these large, slow processes like neuromodulators, volume transmission type of processes and even slower oscillations, slower, larger oscillations, quote unquote programming via their modulatory roles programming the smaller, faster processes.
*  And there's this kind of this hierarchy of programming that's happening.
*  So maybe you can just elaborate on that.
*  I think that's what you're about. Yeah, I use the word programming with scare quotes because I think I just use air quotes, but yeah, it's only approximately correct.
*  But whenever you have dynamic systems that are always active, they don't turn each other on and off.
*  They're never in there. They're always doing something.
*  So they modulate each other.
*  And in fact, what they're always doing is oscillating at various frequencies, even conceivably multiplexed frequencies, all kinds of complexities from a macro evolutionary perspective.
*  The most primitive way this happens is in terms of gap junctions and volume transmitters.
*  Those are the earliest volume transmitters are basically descended from colony cell colony modulators.
*  Yeah, and it's exactly the same chemicals in many cases.
*  Synapses have evolved within that framework.
*  So they are a further specialization of function within that volume transmitter framework.
*  And synapses take many forms, including synapses that are full volume transmission in the sense that the transmitter substances fully diffuse out of the synapse to restricted ones, in which case that the synaptic cleft is partially blocked.
*  But there are some gaps that allow some of the transmitter substance to diffuse and so on and so on.
*  So the volume transmitters are faster precisely because I mean, excuse me, slower precisely because they're bigger.
*  And we're talking about diffusion. So diffusion across the synaptic cleft is much faster than a diffusion of volume transmitter diffusion throughout dozens or hundreds of neurons.
*  And a gap transmitter is even faster. There isn't even any volume transmitter.
*  And incidentally, gap connections also have different forms that seem to be functionally different.
*  We don't know very much about that yet, but the brain has all kinds of functional ways of functioning.
*  And even gap junctions are not all of a piece. They're not all of a single kind.
*  And then along come astrocytes and other glia.
*  I love telling audiences, you've got little things that are crawling around inside your brain right now, microglia.
*  But they are you, so it's okay.
*  Well, they're you.
*  It gives some people kind of the creeps until I tell them, well, look from an embryological perspective, microglia share their embryological origins with white blood cells.
*  And so they do sort of serve a white blood cell function within the brain, but they serve more than that because microglia also eat synapses, among other things.
*  So they have to do on an even slower time scale with the sort of functional architecture of the brain.
*  Synapses are not soldered connections. They will partially form and then never completely join.
*  They will form and then pull apart. They will form. And then a microglia comes along and eats them.
*  I mean, it's not even a steady state. It's at best a sort of an approximate steady state over time.
*  And astrocytes modulate this kind of activity.
*  But astrocytes also influence concentrations of volume transmitter concentrations, ion concentrations, all kinds of concentrations in the intercellular fluid.
*  The intercellular space itself may well be functional, and we know almost nothing about that.
*  But the intercellular fluid contains polysaccharides, it contains lots of molecules, and they're not identical from one region of the brain to the other.
*  I've never come across anybody studying how they might change, but they clearly influence the diffusion processes and diffusion paths and temporal parameters and so on.
*  So they have to be functional in some sense. How changeable they are, I don't know.
*  So anyway, now we've got all kinds of things influencing each other on multiple spatial and temporal realms.
*  They're all dynamic. They don't stop. They're not passive threshold switches.
*  So what kind of way of is there? How can we model these kinds of dynamic influences of one kind of dynamic process on another dynamic process?
*  Well, dynamic processes in this sense don't so much turn each other on and off.
*  They change the parameters of how the dynamic processes proceed.
*  And changing the parameters can have huge consequences, especially if the dynamic processes are nonlinear.
*  But changing or setting the parameters of a dynamic process is basically the equivalent of programming the dynamic process.
*  That's why I use the word programming.
*  And programming is also it is not only an approximation in that sense.
*  It's also an approximation in the sense that for simplicity's sake, I'm just talking about the large slow processes, setting the parameters for the small fast processes.
*  But the whole thing is a self-organization processes of all levels influencing all levels.
*  There is no direct one way command process there.
*  So then the the locus of cognition you take away from the synapse.
*  And I mean, do you do you put it onto the highest, quote unquote, modulatory processes that are setting the parameters?
*  Well, I think there is cognitive processes there.
*  You have you also have microgenesis with larger scale things going on in the brain.
*  And those can also be anticipatory and therefore have truth value in a sort of zooming out.
*  Do you see all of it as a flow process?
*  Yes, a hierarchical kind of flow process that is mediated and primarily via action.
*  Yes, roughly speaking.
*  Roughly speaking, yes. And even internal action and interaction prefrontal to Caudate to thalamus back to prefrontal was one of the first loops we knew of way back in the 70s.
*  Where head of the Caudate was being recognized with some surprise as doing things cognitive, not just behavioral.
*  So this fits with the PHA notion of thought as internal interaction.
*  It is literally internal interaction prefrontal is action cortex, and it interacts with other things going on in other parts of the brain.
*  And we now know of lots of those loops, loops and loops and loops now.
*  Yes, yes, yes. Well documented.
*  So where is cognition?
*  Let me back up.
*  I kind of want your broad view on how you think neuroscience is doing the current state of neuroscience, which is very much focused on measuring spikes and correlating the amounts of spikes with perceptual processes and actions in the world.
*  And oscillations kind of have come and gone a little bit.
*  The heyday of oscillations was probably 10 years ago, maybe they're still around.
*  But, you know, just what's your take on the current state of neuroscience if you if you are keeping up with it?
*  Well, these things keep getting progressively discovered more and more and more.
*  We knew about synapses back in the 70s.
*  We knew sort about the existence of volume transmitters and we knew about gap junctions.
*  That was it.
*  It became increasingly apparent that these were critically important like volume transmitters.
*  So I have a quote from the early 90s in which somebody says, Look, what we really need is some model of volume computation.
*  Notice the attempt to combine what we knew about the brain with the standard models of trying to think about what the brain's actually doing.
*  Computationalism.
*  Exactly.
*  And we're still there.
*  I mean, the whole astrocyte stuff started in the in the 90s.
*  It goes back a bit earlier than that.
*  But some major reviews occurred in the early parts of this century.
*  It's one quote that I just love is we used to think that astrocytes were just the handmaidens of neurons.
*  We now know that they tell the neurons what to do.
*  So all of this stuff is known and it's known well enough that you'll even find little hints of it in introductory textbooks, but nothing more than hints because people don't have any alternative models for thinking about how the brain functions.
*  They know that it functions in terms of this stuff at the biochemical level, but they don't know how to try to understand that in terms of the cognitive or representational or emotional or mental level of any sort.
*  And so computationalism still reigns supreme.
*  You'll still pick up a book on physiological psychology and you'll either see one chapter or multiple chapters split out on sensory encoding, visual sensory encoding, auditory sensory encoding, etc, etc, etc.
*  And they haven't even caught up with Gibson in that respect.
*  So the interactivist framework and the way that you conceive of minds and brains really integrates all of the parts, all of the temporal and spatial scales, and it incorporates them as necessary components of a functioning whole.
*  What does this say about experiments in neuroscience?
*  Because generally all the experiments I've done, you know, is just recording spiking neurons while an animal is performing a task, right?
*  And that, you know, you talk about the silent neurons being an issue as well in their role.
*  You know, so I'm not recording any of the silent neurons, obviously.
*  But do experiments need to address across temporal, across spatial scales more than they do to actually make viable progress in answering cognitive questions?
*  Because they seem we seem to always be at one scale at one spatial and time resolution.
*  No, I think they do. I mean, I think you can test some hypotheses at a single scale, but you can't test overall hypotheses at a single scale.
*  So, I mean, you can discover stuff, although sometimes you misinterpret what you think you've discovered.
*  But you can discover stuff at single. I mean, you know, we've learned about volume transmitters and we've learned about sites and so on and so on and so on.
*  We just don't know what to do with it.
*  Right. Well, that's what I mean is like to integrate it in as a whole story, a whole picture.
*  Exactly right. One of the points I make is that this is enormously complicated interrelated multiscale dynamics.
*  Yeah. Which makes it very difficult to model.
*  Yeah. But evolution didn't produce it for the purpose of being modeled.
*  Evolution produced it for the purpose of it being functional for us.
*  And the complexities and the nonlinearities and so on are functional.
*  It means we've got a much bigger range of possibilities that we can tune to use one term.
*  We can tune our dynamic processes into then would otherwise be there.
*  I think using and therefore tuning or self organizing into these sorts of characteristic modes of functioning is what it has all evolves for.
*  It's not evolved to make it simple for us to model.
*  Going back to so in your literature and we're not going to get into specific details, but you have accounts for how how this relates to specific cognitive functions, memory, episodic memory, learning language, you know, and like you said, up to social dynamics.
*  I want to ask maybe we can just focus on learning for one second because you talk about learning as a variation and selection constructivism constructivism.
*  And I wanted to ask because part of the basis of what representation is anticipating, you know, potential actions, potential interactions with the world.
*  And I don't know if you've written about this, but I'm wondering if the variation in those anticipatory potentialities.
*  Is there a correlation there with what we would consider intelligence?
*  Right. Because you need the better set of anticipatory possibilities you have, perhaps the better actions that you can take.
*  Right. So is there a relation between the varieties of anticipatory possibilities and what we would think of as intelligent?
*  I think there's a relation.
*  I don't know that they're quite identical because I think there may be more to what we call intelligence.
*  I doubt that intelligence is a single unitary kind of phenomena.
*  But here would be a trace through one possible interrelation.
*  Even if you go back to the classical synapse, it's not steady state.
*  It's not a soldered wire.
*  And in multiple senses, it's not.
*  I mean, even if you go back to C. elegans, there's volume transmitters all over the place, even in C. elegans.
*  But more simply put, the strength of a synapse in terms of how much transmitter substances released is not fixed.
*  It will vary.
*  Now, so there we got variation.
*  OK, now suppose that if things work out, that whatever the variation value was when the transmission occurred will tend to stick around and stabilize.
*  But if things didn't work out, it will tend to destabilize and perhaps have an even greater range of variation the next day.
*  There is a variation in selection process.
*  It's very primitive.
*  You know, you can get Hebbian out of it in terms of modifying weights.
*  But it's so primitive, it's not going to give you much cognitive.
*  But it is an example.
*  So where do the variations occur and what sorts of dynamics are involved in the variations?
*  The variation and selection principle is a fundamental epistemological or but it can be implemented in multiple different ways.
*  So the variation and selection principle in the cortex, I would argue, is in this multiscale, larger scale, imposing parameters on faster scale stuff.
*  And similarly, if it succeeds, if the anticipations that are involved in that succeed, it will tend to stabilize.
*  And if they don't, it will tend to destabilize.
*  Now, exactly what the biochemical dynamics are of stabilizing and destabilizing, I don't know.
*  But the best evidence so far is they can vary just as much as from a single synapse to an astrocyte.
*  The key is that you've got a variation of selection process and that variation of selection process can be implemented in multiple different kinds of biochemical processes.
*  Don Campbell, who was here at Lehigh, as a matter of fact, he created the position that I have at Lehigh.
*  He invented terms like downward causation and was a, you know, evolution.
*  He coined the term evolutionary epistemology and so on.
*  And one of his slogans was that I that I happen to like.
*  You cannot knowledgeably go beyond whatever knowledge you currently have.
*  But that doesn't mean you can't go beyond it.
*  It just means you cannot knowledgeably go beyond it.
*  And that just forces some kind of variation and selection process.
*  Yeah, nice.
*  So intelligence is going to be at some limit variation of selection.
*  It's not going to be logical deductive process.
*  Logical deductive processes can occur, but they have to be constructed by a more basic and more encompassing variation of selection processes.
*  When I'm when I'm laying down at night and I'm thinking about, you know, what I'm going to do the next day and simulating potential things that I'm going to do next or the next day, are those simulations?
*  Do they map on to the various anticipatory possibilities or are those two different things?
*  No, I think they do.
*  I mean, I think that involves reflection.
*  So it involves the prefrontal basal ganglia thalamus loop back to prefrontal and that interacting with stuff going on in the court, rest of the cortex and so on and so on and so on.
*  And in effect, what it's doing is exploring the distinction that I didn't name earlier.
*  I talked about situation knowledge as this organization of what we know about what we could do and what we could do if we did this first and so on.
*  That doesn't remain constant.
*  It has to get updated.
*  It has to get maintained.
*  And the dynamic processes by which we do that I call world knowledge.
*  And the reason I call it world knowledge is because it's our knowledge of how the world could be.
*  So it modifies our knowledge of how the world currently is on the basis of how it could change and what could happen and so on and so on.
*  So the kind of reflections you're talking about at night, I think of as reflections making use of the world knowledge.
*  The world knowledge is what allows us to consider.
*  Well, what if I did this?
*  It allows for counterfactual future oriented explorations.
*  Mark, this is great stuff.
*  I want to I just want to make sure that we get in some artificial intelligence conversation before we wrap up.
*  Yeah, well, of course, it depends on what we call artificial intelligence.
*  But if we equate artificial intelligence with processing of inputs, then, you know, it can be enormously powerful.
*  It can be enormously dangerous as well as for good things.
*  But we're never going to get anything mental out of it.
*  It has to be interactive.
*  It has to be future oriented.
*  So I have an early 80s publication in which I point out artificial intelligence isn't going to do it.
*  But what's considered to be a branch of our artificial intelligence sort of encounters these problems, even though it's not considered to be science
*  or theory, it's considered to be engineering.
*  And that's robotics.
*  So I have I have I quoted myself in that.
*  I think that's why I got this job, because I in my application letter, I quoted myself.
*  What what what year did what do you did you get the job?
*  Well, I moved here in 1980.
*  OK, OK.
*  So the title of my position is cognitive robotics and the philosophy of knowledge.
*  Donald Campbell also coined the term cognitive robotics.
*  OK, so here I am anticipating in the early 80s that robotics is going to be cognitive.
*  And I think I was right, although, you know, it needed a lot of further development.
*  So along about late 80s and into the 90s, robotics, dynamic systems, autonomous agents, all this stuff became a big deal.
*  And I think it's all in the right direction.
*  Interaction is required.
*  It still doesn't account for normativity.
*  So you're still not going to get truth value and therefore cognition out of it.
*  You need more. You need the normativity.
*  So you need the thermodynamics.
*  But it gets more and more powerful.
*  I like a lot of Rod Brooks stuff.
*  We gave he gave a talk and then I gave a talk.
*  And then a commentator got up and started his talk, which was supposed to comment on the two of us.
*  He said, well, in spite of the differences between Brooks and Bickert and Brooks leans over to me and says, I thought we were saying the same thing.
*  Right.
*  And, you know, up to a point we are.
*  But he doesn't he doesn't value representation.
*  No, he's strongly anti-representation.
*  But his I mean, I have his lab report for the paper, Intelligence Without Representation, and it's just excoriates representation.
*  His published paper, Intelligence Without Representation, is much more conscious.
*  He says, my robots don't have any representations in them, or at least nothing that looks like standard conceptions of representation.
*  Right.
*  And so he sort of recognized, you know, maybe there's more to it than that.
*  So, I mean, there are lots of anti-representationalists, Brooks being one.
*  A lot of the inactivists are anti-representationists.
*  The Bayesians are not, but their model of representation, in my judgment, doesn't work.
*  The anti-representationalists like Cameroon, like Milkowski, or well, not Milkowski, but De Jager, De Paolo, and so on and so on.
*  They make a fundamental mistake in my judgment.
*  They criticize correspondence models or information semantics models.
*  It goes by different names.
*  There are criticisms I generally agree with, and I've added to them.
*  I've made those crit- and added to those criticisms.
*  Although historically some of them go back 2,000 years.
*  But then they conclude representation doesn't exist.
*  And they never take into account a non-correspondence, non-encoding kind of model of representing.
*  And so their reasoning, I think, is bad reasoning.
*  They eliminate X and then assume they've eliminate everything that X falls within.
*  It's an argument by elimination.
*  So if representation by correspondence and no representation are the only two possibilities, then eliminating representation by correspondence does give you no representation.
*  But there are three possibilities, not just two.
*  The third possibility is representation not by correspondence.
*  And they never even seem to recognize that.
*  So that would be my comment on a lot of these anti-representational people.
*  Brooks was not a philosopher.
*  So, you know, I'll give him credit for not really looking into this much.
*  He did seem to like my work to the extent that he knew about it.
*  He knew something about it because we gave talks together various times.
*  I can't claim he ever fully understood it or endorsed it.
*  I don't think he looked at it that much.
*  So he was an anti-representationalist who maybe sort of made these mistakes, but not fully because he didn't really look into it that deeply.
*  What's your take on the modern?
*  So you have these convolutional neural networks in the whole deep learning world.
*  And we don't have to go in depth on deep learning in general.
*  But, you know, the fact that there are similarities between the activations in the deep learning nodes and neurons found in sensory systems.
*  Well, I'll just leave it at that.
*  What is your take on that modern deep on deep learning in general?
*  And also the fact that there are some similarities between what we see in the brain and what we see in connection as to deep learning convolutional neural network type of.
*  Yeah. Well, OK.
*  Similarities first. I mean, the processes are concurrent.
*  Everything in the brain is concurrent.
*  So there's that. I mean, the neural network people, the PDP people way back in the 80s were making those kinds of claims and arguments.
*  And that's correct. Yep.
*  They are overall, some of them autonomously active, but the nodes are not.
*  The nodes are passive. Right.
*  They are not autonomously active.
*  There's a big difference there.
*  And in general, what they're doing is settling on various kinds of statistical patterns.
*  And that can be very powerful.
*  I mean, what gets called deep learning actually has multiple different flavors.
*  But every one of those flavors, as far as I can tell, is ultimately passive in the sense that it is settling upon statistical patterns in the input flow.
*  They don't interact with the world.
*  Now, actually, you know, in early connectionist models, some of them did get set up to interact with the world.
*  In the 80s, I remember one where a connectionist net was set up to control a ping pong paddle.
*  Yeah. And the overall system learned to bounce the ping pong ball ball off the wall.
*  But that was just considered to be engineering that had nothing to do with the mind or cognition.
*  So anyway, at least two big differences.
*  The elements are not active.
*  You don't get timing out of it.
*  I mean, they're not interactive.
*  So it doesn't really make any difference that you don't get timing out of it.
*  And they're picking up statistical patterns, which can be powerful and useful, but it's not cognition.
*  So at heart, you see.
*  Well, I suppose you gave some light to robotics and that robotics is moving in the right direction.
*  But you'd say we're not going to get to whatever artificial general intelligence, autonomously intelligent systems pursuing just deep learning.
*  You would say that robotics and interaction is necessary.
*  So in that sense, I suppose A.I. is doing just fine because robotics is marching on.
*  Yeah. But I mean, it's doing fine in the same sense in which neuroscience is doing fine.
*  It keeps making progress, but it keeps making progress with this background assumption.
*  The encoding is an assumption.
*  Yes, exactly.
*  Do you think the A.I. needs to incorporate more spatial and temporal scaling, knowing that the brain does that?
*  Well, in part, I mean, something I consider to be ironic, you know, I argue against computational models all over the place.
*  But there is one thing that goes on in computers that I think does translate with some modifications.
*  So a computer program with data and programs stored in store and so on and so on, that can be extremely misleading.
*  But if you look at a single register in a computer at a given cycle, maybe it does an integer addition.
*  Next cycle, maybe it does a floating point multiplication.
*  Next cycle, maybe it does a Boolean exclusive or so each cycle.
*  It does something different.
*  There's all kinds of microcircuitry around the register that has to get set up differently in time, in real time.
*  So that it will do the different things.
*  That is microgenesis.
*  And also that separates it from Turing computation, which has no need for time.
*  Yes and no.
*  I mean, it still doesn't have normativity.
*  So you could put this into Turing.
*  I mean, if you think of abstract machine theory and you think about a transition from one state to another, we tend to visualize that.
*  So the whole system is sitting on one state and it moves to another state.
*  But each state is actually a functional summary of the entire system.
*  So to move from one state to another is actually a set up process.
*  It's just that we don't tend to think of it that way.
*  So it is in a certain sense consistent with Turing.
*  In the register example that you just gave also timing wise, you could just set the clock differently.
*  And is that the difference with an endogenously active autonomous neuron cell, glial cell, whatever you life cell, which sets its own constraints, sets its own oscillatory timing relative to the timing of components that are at different spatial and temporal levels?
*  And so in a computer, it's imposed from the outside, whereas in a brain it is manifested endogenously.
*  Is that a key difference?
*  I agree that one of the senses in which Turing machine won't work for us is you can't get timing.
*  You can get sequence, but not timing.
*  Right. So the first step can take a year.
*  The next step, a second and so on and so on.
*  Nothing about Turing machine theory changes.
*  Your computer has timing, so it's more than a Turing machine.
*  But as you say, the timing comes from a clock with all kinds of complicated timing circuitry that cycles the other functional elements, the other transistors.
*  Well, you can get timing that way, but it's a very complicated way of getting timing.
*  And from an evolutionary perspective, there's a much simpler way of doing it.
*  Now, actually, I was giving a talk at MIT one time and one of the students, you know, these brash, arrogant MIT students got about to this point and he says, well, that's wrong.
*  You know, there's asynchronous timing, you know, different timing on every and so on and so on.
*  And I said, permit me one more slide.
*  And so I go beyond this asynchronous timing.
*  I said, make everything a clock.
*  That's all there is is clocks.
*  But clocks are quote, just unquote, oscillators.
*  And clocks oscillators can interrelate with each other by modulating each other, each other's oscillatory processes.
*  Now we don't need timing circuitry.
*  We get timing for free.
*  And it's at least as powerful as a Turing machine.
*  Because the limit case of a modulating B where A and B are both oscillatory processes is for A to switch B on and off.
*  And you can construct Turing machines out of switches.
*  So now we've got something that in the limit can be a Turing machine, but it's got intrinsic timing.
*  Mark, do you my last question, and thanks for staying so long with me here.
*  Do you consider yourself a philosopher?
*  Because you're a lot of things.
*  Well, I have zero training in philosophy.
*  OK, it's all right.
*  You're a philosopher.
*  It's all in psychology.
*  But I made this mistake of continuing to ask all of these fundamental questions.
*  Right. And psychology doesn't even address them.
*  Well, here's that's OK.
*  So that's why I got driven into philosophy.
*  So my primary location now is in the philosophy department.
*  Once upon a time, Don Campbell was retiring for the fourth or fifth time.
*  And at a retirement party, people were giving some talks about Don.
*  And the then chair of the philosophy department gave a talk about Don.
*  And his talk was built around the question of is Don Campbell a philosopher?
*  OK.
*  And he pointed out, he said, well, from a philosophical perspective,
*  that would depend on what philosophy is.
*  But what philosophy is, is itself a philosophical question.
*  Oh, boy.
*  So we can't hope for an answer as to whether Don Campbell is a philosopher from that perspective.
*  So let's ask the question from Don Campbell's psychologist have an empirical answer.
*  And he considered a couple.
*  And he ended up with, does Don Campbell have a mailbox in the philosophy department?
*  And he said, yes, he does.
*  So therefore, he is a philosopher.
*  He's a philosopher.
*  Yeah.
*  That's your mailbox now.
*  Ever since then, I have used that criterion.
*  So I claim to be a philosopher.
*  Well, as a philosopher then with your mailbox that confirms that you're a philosopher,
*  do you feel that the AI world and or the neuroscience, cognitive science world pays enough attention to these sort of fundamental ideas?
*  Do you feel neglected?
*  Do your ideas feel neglected within those worlds that sort of just march on in the encoding-ism framework, et cetera?
*  Or do you feel like you have some some push and pull there?
*  Well, this stuff has never hit the big time, quote unquote, whether it ever will or not, I don't know.
*  But it does have its influences and the influences are growing.
*  It would be real nice if it had, you know, an exponential growth.
*  Yeah.
*  But that hasn't happened yet.
*  So, yeah, it gets ignored, but it gets ignored like lots of other stuff.
*  I mean, things like Bayesian brain will come along and have a big splash and activism has a big splash.
*  Mm hmm.
*  Classical AI had a big splash.
*  But then, you know, it gave up on the original or a lot of the people gave up on the original aspirations of AI and started doing applied stuff.
*  You ever you ever think about just walking into your manuscript and writing the end on it?
*  And then that will be the that will be your book.
*  When is that?
*  When you're going to finish that thing?
*  Well, like I say, I mean, you know, I've turned in the last year and a half or so, five hundred pages of notes into maybe two hundred pages of text.
*  That's good editing.
*  Yes. So I'm making real progress.
*  If it weren't for this discussion group that I mentioned, I could make a whole lot of progress.
*  But they keep coming up with stuff that I really need to figure out and address somehow or another.
*  Well, I'm guessing year and a half to two years, I hope.
*  Well, you'll have to come back when you do finish it, because then we talked about it.
*  We covered a lot of ground here.
*  And yet there's a lot more ground to cover, obviously.
*  We're only we're not even halfway through the book.
*  Oh, yeah. Oh, good. OK. Well, there's I mean, yeah. OK, good.
*  Well, they'll be having gotten to social realities or language or any of that.
*  That's the language is not the same in this model as it is in standard models,
*  because language is also a correspondence phenomena in most ways of thinking about language.
*  Yeah. Yeah. Well, thanks, Mark.
*  This has been fun and I look forward to doing it again sometime. Thank you.
*  And get access to the full versions of all the episodes,
*  plus bonus episodes that focus more on the cultural side, but still have science.
*  Go to brandinspired.co and find the red Patreon button there.
*  To get in touch with me, email Paul at brandinspired.co.
*  The music you hear is by The New Year.
*  Find them at thenewyear.net.
*  Thank you for your support. See you next time.
*  Thank you.
