---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 5886s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 3964
Video Rating: None
---

# BI 111 Kevin Mitchell and Erik Hoel: Agency, Emergence, Consciousness
**Brain Inspired:** [July 27, 2021](https://www.youtube.com/watch?v=vEA6TvgaOtI)
*  My own feeling is that if we want to get to something that we would say has a kind of
*  autonomous intelligence, then we do need to give it agency really, and we need to make
*  it a living autonomous thing that has some sort of causal insulation from the rest of
*  the world.
*  Just if you look at the macrostate descriptions of a very simple system, they can be completely
*  deterministic and therefore kind of constrain the past and the future to a greater degree
*  than any of their underlying microstate.
*  The way that I think we're going to get to a principled understanding of consciousness
*  might be...
*  The reason why I say that the goal is consciousness rather than behavior is that...
*  This is Brain Inspired.
*  Hi, my name's Paul.
*  In this episode, we have a discussion with Kevin Mitchell and Eric Hoel.
*  So Kevin is a professor of genetics at Trinity College Dublin, and his recent book is called
*  Innate, How the Wiring of Our Brains Shapes Who We Are.
*  And in that book, he describes the massive complexity of both our genes but also our
*  development and how our DNA and our developmental processes interact and both give rise to how
*  we turn out to be.
*  And Eric is at Tufts University in Boston.
*  Eric has worked on integrated information theory, which is a modern popular mathematical
*  theory of consciousness from Giulio Tononi, whom Eric has helped develop that theory,
*  and continues to work on using information theory to account for emergence and emergent
*  properties.
*  He's also a novelist, and his recent novel, The Revelations, is a story about some neuroscientists
*  who are trying to come up with a good theory of consciousness.
*  So our discussion is really wide-ranging.
*  We start off talking about Eric's novel, The Revelations, and Kevin's book Innate, and
*  we talk about the process of writing and how their writing, exercise, and practice
*  interacts with their science.
*  We talk about consciousness and whether we have brains for consciousness or for movement.
*  We also discuss emergence, the concept of agency and autonomy, and whether those are
*  important for building AI that we would consider true quote unquote AI.
*  And there are a lot of other topics in there.
*  There's really something for almost everyone.
*  Show notes are at braininspired.co slash podcast slash 111.
*  I want to say thanks to my Patreon supporters.
*  If you are listening and you get value out of this podcast, consider returning some of
*  that value in the form of a couple bucks a month through Patreon.
*  Go to the website at braininspired.co to learn more about that.
*  So this is a super fun conversation, and I hope you enjoy hearing it as much as I enjoyed
*  hosting it.
*  Take care.
*  Eric, a fresh congratulations to you and Kevin, a stale, I suppose, if two years to three
*  years to Innate was written in 2018, right?
*  Or published.
*  I don't know when it was written.
*  And Eric, a fresh congratulations to you.
*  Although I know that the revelations your book has been a long time coming and has,
*  you know, this is your first novel, correct?
*  It's my first novel.
*  Yeah, about 10 years is probably the is probably the lower end of the estimate.
*  Although, of course, the bulk of the writing was done in graduate school.
*  Which is crazy.
*  This is not 10 years.
*  Well, I know people and there's nothing wrong with that.
*  Nothing wrong with 10 years in graduate school, everybody.
*  But so this is the this is the first on the podcast, I believe, where we're going to talk
*  a little bit about a fiction book.
*  And so we'll spend some time talking about the revelations.
*  I want to talk about Innate a little bit, Kevin, and then we'll come together and you
*  guys will really butt heads about some of your some fundamental core concepts and ideas
*  that you hold dearly.
*  So so I've been listening to more of Kevin's like talks and so on.
*  And my suspicion is actually that we agree on basically everything.
*  So I think so, too.
*  So it may it may be more of a kind of more of a head shake.
*  Yes, exactly. Yeah, we'll see.
*  So this is to me, this is the conversations I aim for.
*  I actually find debates mostly utterly unuseful.
*  But but anyway, we don't need to get into my thoughts on on debates.
*  So, Eric, among other things in the revelations, it's just really impressive.
*  The scope of the philosophy and the science that you cover throughout the novel.
*  And it's a it's a long novel.
*  So you do have some time and space to do that.
*  But it's also just filled with these really vivid descriptions of the science.
*  And so this is maybe I should back up and say that the novel revolves around characters
*  pursuing a theory of consciousness.
*  And then things happen in the background.
*  Like there's a murder mystery involved as well.
*  But like I said, there's lots of vivid descriptions of the science,
*  but also the characters, what they're going through emotionally and their thoughts
*  and the scenes and the writing is generally just fantastic.
*  And so congratulations on writing.
*  Thank you so much. That's awesome to hear.
*  On the other hand, I'll say I felt almost like an old curmudgeon,
*  partly because I am these days.
*  But I kept wondering why these these immature, you know, children
*  and the novel that are the characters were so pretentious,
*  you know, and self-absorbed in their quest to to understand.
*  And I found myself grateful that I didn't know many people who
*  who held that held their own,
*  held their own ideas in such high regard throughout my own academic work.
*  So so I am. Yeah, go ahead.
*  I think that that's a very viable take. Right.
*  From a curmudgeon, especially the youth, the energy.
*  Well, yeah, so a lot of the novel is about,
*  you know, when there are dominant kind of modes of thought,
*  particularly within academia, oftentimes there are people who really,
*  you know, chafe, chafe against that.
*  And in some sense, it's kind of necessary.
*  It's very similar to the fact that, you know, no one who is a billionaire
*  didn't think when they were a kid, I'm going to be a billionaire.
*  But there are a lot of people who you don't hear about
*  who thought that the same thing and they're not billionaires. Right.
*  And so every billionaire has this, you know, self-reinforcing narrative of like,
*  well, I just believed it from when I was very young and look, it all worked out.
*  And the same is probably true for scientific theories,
*  particularly sort of grand sweeping scientific theories.
*  You know, one of the main characters or the main character Kirk
*  is looking for a scientific theory of consciousness,
*  which he thinks there needs to be a scientific theory of.
*  Even that is in itself debatable.
*  Some people disagree. But he thinks this.
*  And he, you know, is kind of monomaniacally
*  throwing himself against the problem.
*  And, you know, I wanted to draw similarities
*  between the sort of anxiety that drives, I think,
*  probably a lot of those discoveries and things like, you know, creative endeavors,
*  like writing a novel or becoming a painter or, you know,
*  any of these other things that we think of as involving,
*  you know, almost an artistic, romantic level of obsession.
*  And I do think that probably.
*  You know, at the upper levels of science,
*  there is a lot more ego and humanness going on
*  than it would be apparent from the outside.
*  And my goal wasn't to say that the character Kirk,
*  who is very strident in his opinions, so much so that he can sometimes be off putting,
*  is correct about everything.
*  But I'm also not.
*  Of the opinion that that he is kind of irredeemable
*  or that this is, you know, actually a very bad thing.
*  I think in some cases it can be a very good thing to be like that.
*  Yeah. I mean, the other striking thing, reading the novel.
*  And of course, I'm coming at it from a neuroscientist perspective.
*  And I also knew your background or at least some some therein,
*  just looking through your publications.
*  And so there's a lot of overlap.
*  And I found myself.
*  So I actually thought I learned through another interview that you gave that
*  that Kirk K.
*  I E R K is Kirk as in Kierkegaard.
*  But I thought early on, I thought, oh, that's an anagram of Eric with an extra letter.
*  And because there are these parallels, a lot of overlap between the nonfiction
*  of your life and the fiction of what happens in the story.
*  And so I'm kind of wondering, because there are such great descriptions,
*  I think I even tweeted early on when I was reading the book.
*  It's like you like captured the world of nonhuman primate
*  research like so well, you couldn't have done that had you not experienced those things.
*  And and a lot of like the social aspects and stuff.
*  So it makes me wonder where the fiction ends and where the nonfiction ends
*  and where the fiction begins in the novel.
*  Well, it's it's a good question.
*  And I'm not even sure that as an author, I have a definitive answer
*  that can partition out that boundary appropriately.
*  I think all authors draw a lot from their own experience and lives.
*  Mine just kind of happens to be in this,
*  you know, world of like high performance science, where there is a lot of,
*  you know, stress and there's also a lot of really interesting things going on.
*  I mean, all those descriptions, you know, in the novel,
*  they these young scientists are are coming to New York to study consciousness
*  at New York University.
*  They're in a building which is called the Center for Neuroscience or CNS,
*  which is very maze like.
*  So they're always getting lost in the CNS.
*  And, you know, there are primate labs in the building.
*  And even the dynamics between, you know, young people meeting each other
*  for the first time can often be primate esque.
*  So there's kind of a mirror between the monkeys, you know, and the people
*  and how they interact.
*  And, you know, that's all based off of there is a real primate
*  research facility at the CNS at, you know, New York University.
*  And it is a realistic depiction of the sort of animal research.
*  And I didn't want to spare, you know, some people have have,
*  you know, said some some reviewers have said this is a really dark.
*  Well, very interesting, very dark descriptions of what's actually going on.
*  And I didn't want to spare that because I do think that science alone
*  is thematically interesting enough
*  and dark enough to to get the sort of literary treatment.
*  I mean, it is an absolutely insane thing to drill open
*  a monkey's brain, lower in a gigantic microscope
*  into it, having, you know, possibly reprogram the cells in the brain
*  to respond to light and then flash light, you know, over the dark cortex
*  and cause various, you know, effects.
*  And that is a that kind of mechanism.
*  And work is so thematically dense to me
*  that I felt I could only capture it
*  if I drew from real life and real experiences.
*  You know, I I do think that there's there's no way to cleanly separate it.
*  But I would also say just to quickly beg off like the the quick Kirk
*  to Eric comparison that, you know, a lot of other characters also have
*  a lot of me in them.
*  So like Carmen, for example, yes, Kirk and I went to the same graduate school.
*  So one might say, well, isn't it kind of obvious then?
*  But like Carmen went to Columbia University and I worked at Columbia for years.
*  So, you know, her experiences at Columbia are, you know,
*  me observing things that go on at Columbia. Right.
*  So, you know, a lot of, you know, a part of me ends up in all the characters.
*  And I and I and I wouldn't say that there's some sort of like
*  immensely direct or obvious mapping.
*  I want to bring Kevin in a little bit because I have a bunch of questions
*  about just the process of writing him and what jumped into my head.
*  Well, you're talking about I didn't think about this before,
*  but I'm curious, Eric, about writing the
*  how how the process of writing the more nonfiction, like the descriptions
*  of monkey facilities and things of that nature that you're
*  have a lot of experience with.
*  If was that faster, was that harder or easier or faster or slower
*  than the parts that you were more you had to generate in your head?
*  Yeah, I would say probably somewhat similar.
*  I mean, you know, in terms of speed, the speed aspect, I mean,
*  I'm sure Kevin can speak to this in the sense that I do think that
*  nonfiction feels a very particular way.
*  And when you're writing fiction, you know, the
*  the the goal is is almost to somehow like
*  transcend the subject in a particular way.
*  Like in the end, the literary eye has to have a final say
*  when you're talking about fiction, like art is like the laughter,
*  like after everything is done, right?
*  Like the universe gets run out.
*  It's just after heat death and it's cold and it's dark.
*  But art kind of gets this last like chuckle like at the end.
*  And I think that that's true.
*  Like in general, like when you're trying to describe anything that art
*  kind of has to maintain superiority.
*  But it's very dangerous to go into nonfiction thinking about
*  that sort of like romantic, poetic angle.
*  And you kind of have to go in very dry and very,
*  very skeptical and like non romantic at all.
*  So really, it's much more about turning on and off like the more romantic
*  parts of my brain when I write either or.
*  But but you still have to go in, you know,
*  trying to write a readable book in nonfiction.
*  And I realize, too, you know, there's different types of nonfiction
*  because writing a book about the history of dog shows, for instance,
*  you're not really writing about the unknown and much of the nonfiction
*  that you guys both write in, Kevin, in innate, for instance, is all about.
*  It's partly about what is known,
*  but it's vastly about what is unknown and how we might be able to start
*  knowing what is unknown and making connections.
*  And so innate is a lot of people will have already read it, I'm sure.
*  But it's kind of about the connection between genetics and development
*  and and psychology.
*  So from like the really low level code, DNA code to our psychological traits.
*  And so in a sense, that's hard to pull off writing a readable nonfiction.
*  Yeah. Yeah.
*  I mean, and the goal, I guess, I mean, I think of, you know,
*  fiction writing as as very evocative, you know, and really making
*  making the words dance and making making images, you know,
*  appear in people's minds and in a in a sort of a dialogue
*  where the the author is not necessarily,
*  you know, directing everything, but but more sort of inspiring
*  a response in the reader, whereas certainly what I was doing,
*  it's it's not really evocative in that sense.
*  It's really, I guess, not making the words dance, but maybe making the march,
*  you know, trying to be clear enough that there's a sort of
*  it's almost a kind of I feel like like it's a kind of mind control almost.
*  You know, you really have to have this sort of constant empathy for the reader
*  to say, OK, well, what do they know?
*  What are they thinking?
*  If I say this, how are they going to take it?
*  Never mind what the words I've said, how are they going to take it?
*  And then do I need to explain something else?
*  Do I need to give them, you know, a metaphor or something familiar
*  that they can take as a scaffold for an idea,
*  you know, that I'm trying to build up here?
*  And so, yeah, I mean, I find actually writing the book,
*  writing that kind of nonfiction for non specialists really fun.
*  But it's a different challenge to writing, you know, academic papers
*  for very specialist audiences where you can rely on the crutch
*  of shared knowledge and shared perspective and shared assumptions.
*  And sometimes the goal in writing the interdisciplinary stuff
*  is to question those assumptions from any from any individual field.
*  And I guess try to recast
*  things so that the relations between,
*  like you said, genes and brains and minds
*  can be seen in a in a particular perspective.
*  And the perspective I was taking in innate is a developmental one.
*  The argument was that the only way to make sense of that relationship
*  is through it, through the prism of development.
*  And the take home, first of all, two things, one, the take home
*  is that everything is messy. Yes. And development.
*  So that's one of the take home take homes in the book is just you have genes,
*  you have psychological traits.
*  They're not a one to one mapping. Everything is super, super messy.
*  And we have forgotten about development as a process that
*  gives rise to just tons of variation in itself.
*  Yeah, exactly. The the idea that there's some genetic variation
*  in our psychological traits is nothing new.
*  But what I think was, you know, the message I was trying to get across
*  is that that variation is realized through the processes of development.
*  And like you said, there's not there's no one to one mapping between,
*  you know, a gene for this and a gene for that cognitive traits.
*  It's really complex, polygenic
*  and very indirect and sort of emergent relationships between those.
*  And yes, the processes of development themselves are noisy
*  in molecular terms, so you can start with the exact same genome
*  and you won't get the exact same outcome every time you run that program, basically.
*  So that's why, you know, identical twins don't look exactly the same
*  and their brains are not exactly the same as each other
*  and their minds are certainly not exactly the same.
*  So, yeah, I think development is that third source of variation
*  in our individual natures that's often overlooked and
*  and in a sense, a really important one, because it it defies any predictability.
*  It will never be predicted.
*  It's just inherently stochastic, which it's a really down.
*  It's a real downer. You know that?
*  Well, in a sense, but, you know, it puts a limit.
*  It's interesting because it puts a limit on
*  on genetic predictability, for example.
*  So the the claims that, you know, you'll be able to sequence someone's genome
*  or sequence the genome of embryos and and and really predict
*  with some accuracy what their psychological traits is going to be like.
*  You just won't ever.
*  And it's not just that we don't know.
*  Designer babies.
*  Yeah, designer. Yes, designer babies.
*  Sorry, it's not just that we don't know enough now, it's that we never will.
*  There's a firm limit in principle on how much we could ever predict from that.
*  Kevin, do you do you find that it's harder to attract attention
*  arguing like a nonfiction perspective, wherein you're arguing from
*  like a more skeptical perspective, like like what you just said, right,
*  is a lot easier.
*  It's a lot easier to sell the opposite.
*  Yeah, I I do think, yeah, I do think that a more sensationalist point
*  of view probably would sell more books than a than a more the the nuance
*  kind of picture that I'm trying to show, which is complex and it is messy.
*  And at some point you just have to you just have to accept that.
*  But it doesn't you know, there aren't
*  the strong headlines like, you know, a strong headline is DNA is your future.
*  That's a great that's a great newspaper headline.
*  And people are going to want to read that.
*  Whereas, you know, the headline, well, I think it's a great headline.
*  Well, it's complicated.
*  That that doesn't doesn't necessarily jump off the page in the same way.
*  Yeah, right.
*  Yeah, it's something I've been struggling with, you know, myself.
*  I mean, I think that the defining
*  your feature of like good literature is its agnosticism.
*  You know, you're kind of agnostic about about almost everything
*  when you're writing, like, you know, whether or not this person is a good or bad person.
*  You have to be agnostic about that.
*  And and and whether or not, you know, in in the revelations,
*  you know, it's it's very much not that one particular hypothesis
*  about how consciousness works is advanced, right?
*  All the characters have a different take on that.
*  And then when I go to write nonfiction, it's very much not agnostic.
*  Right. Like you have to put that aside and take some sort of strong, you know,
*  you're either a hardcore atheist or you're like a fundamentalist Christian
*  or what have you. Right.
*  And that then you kind of argue firmly for for this belief.
*  And the agnosticism kind of is is left aside.
*  I don't know if you ever have.
*  Yeah. I mean, in the sense,
*  I guess what I was doing was was taking a strong position
*  against extreme positions.
*  So I was arguing against genetic determinism,
*  but also against naive empiricism where everything is learned.
*  So so in a sense, there's an argument, you know, innate is argumentative.
*  In that sense, it's advancing a set of ideas.
*  It's just that they're they're ideas in the middle.
*  They're not they're not ideas at one or other extreme.
*  So, for instance, Eric, I know that you consider yourself a writer first
*  and an author first, perhaps, and a scientist.
*  I don't want to say second, but because you're you're, you know,
*  fully engaged in science also.
*  But I know from an early age, you have always wanted to be a writer.
*  So in some sense, you consider yourself a writer first.
*  The reason why I'm bringing this up is because I have this weird
*  what I really want to know is the right cyclical
*  pattern for me and for anyone to like work on something
*  and then walk away, but not just walk away, work on something else.
*  Right. And then coming and then when is the right time to come back
*  to the thing that you were originally working on?
*  And you have three or four different things you're working on.
*  What is the right pattern?
*  Because when you do that, when you go work on something else,
*  whether, you know, sometimes it's just taking a walk,
*  but often it's also diving deep into another subject.
*  And that's when the real insight comes relative to your first
*  for the thing that you're mainly working on.
*  And there must be some
*  some right answer for people, you know, in particular for each individual
*  for how long and what depth to work on something before moving on
*  to another thing and coming back and revisiting and cycling through.
*  And I'm wondering what your experience is if you found the right rhythm
*  with with your writing.
*  And, Kevin, this applies to you, too, because writing nonfiction
*  is a different beast and how much that informs your science and vice versa.
*  Yeah, the description of the cyclical nature of that is key.
*  You know, the reason I've described myself as a as a writer
*  first is one that, of course, I want people to take the book seriously.
*  I mean, I think that there's the standard take is something like,
*  oh, look at this Dilettante, you know,
*  but, you know, who somehow found the time and like was incredibly lucky
*  to get it published.
*  And it's like, no, you know, if you look historically,
*  I grew up in an independent bookstore that my mother owned
*  and I worked there as a teenager.
*  And so I always loved books and was surrounded by books
*  and wanted to be an author first and foremost.
*  But all my favorite writers wrote about
*  really drew from their background and experience, you know,
*  somebody like Herman Melville going off and writing type
*  E after he gets stranded amid the cannibals, you know, or Joan Didion
*  finding the counterculture. Right.
*  And it's like, well, I I didn't know where the counterculture was,
*  you know, when I was 17.
*  But I did find the nonfiction section of the store.
*  And I realized that I could actually be pretty good at this
*  and that the world of science was itself incredibly interesting and rich
*  and really had been understudied from like a literary
*  slash humanities perspective.
*  You know, you can go back and read like C.P.
*  Snow's The Two Cultures,
*  you know, a famous lecture where he's just bemoaning the
*  the lack of communication between the humanities and the sciences.
*  And I think that that's still true today.
*  And, you know, I did, you know, have this idea for the book,
*  even in college.
*  And I ended up pursuing my PhD in neuroscience, at least partly
*  in order to kind of I knew that I would need to have that background.
*  As you said, so much of the book, you know, draws from reality
*  and has that ring of hopefully has that ring of truth to it.
*  And that's from, you know, getting literally going and getting my PhD.
*  With all that said, just to answer your question about how to,
*  you know, balance those things,
*  I think that it's it is very, very helpful to work in cycles.
*  I don't think that there is any way that someone can
*  completely appropriately balance two very, very different fields.
*  And I'm sure this even applies within Kevin's own scientific research,
*  which draws from various interdisciplinary aspects
*  because just doing deep dives into something and then coming up
*  is always going to be better than doing something shallow.
*  So there have been periods of time, you know, even like a year
*  where I just have not written a word of fiction.
*  And then I'll start writing again and, you know, it'll all just kind of pour out.
*  So I'm I'm very, very much in the cyclical nature.
*  I wish I could systematize it and tell people some sort of good,
*  you know, system to do it.
*  But I think it's it's it's it's it's almost
*  it's almost always by the seat of my pants. Yeah. Yeah.
*  I mean, I I would, yeah, say something similar.
*  I think the the cyclical nature for me is somehow
*  enforced by reaching a point where I'm just not making progress,
*  you know, where I'm just trying to write something and I just can't.
*  It's just not flowing.
*  And I just need to go away and do something else.
*  It's often when I've written myself into a corner
*  and actually I need to pull I need to pull back from that. And
*  yeah, like, you know, going for a walk or something like that,
*  or even just not looking at it for a week or so and coming back fresh.
*  But also, I think before I start writing,
*  there's a long, long period where I'm just kind of ruminating on stuff
*  and I'm reading loads and loads of different things,
*  kind of thinking about them. I may be making notes and stuff.
*  I might not even ever go back to the notes,
*  but there's a sort of an active process there of saying, yeah,
*  here's an idea I can use. And and
*  I mean, the ones I really get excited about, I guess, are where
*  I'm trying to explain one thing and there's an idea that comes from another field.
*  But actually, it's very much the same process.
*  And so it's a, you know, some kind of insight that I can use
*  there that is a kind of a cross fertilization of ideas.
*  That's for me, that's the really intellectually satisfying,
*  stimulating part of doing the research for these kinds of books that are
*  trying to make a synthesis of of different fields.
*  But then at some point, I get to the stage where I'm like, yeah, OK,
*  I think I think I can start writing.
*  I'm just going to start and then, yeah, just carry on until I hit a wall again.
*  Guys, are you ready for the the big showdown, the big debate?
*  I think we're going to vigorously agree.
*  Fine, I'll disagree. What is it?
*  So you guys, apparently, at least on the surface,
*  differ in the answer to the following questions, to the following question.
*  What are brains for?
*  And in this corner, we have Kevin, who says brains are for action.
*  And in that corner, we have Eric, who says brains are for consciousness.
*  And I don't I don't know. This was just it happens.
*  This was a for some reason.
*  I, to be honest, I don't know why I ever go on Twitter,
*  but I saw that there is an exchange between you two on Twitter.
*  And it was this exchange.
*  So I don't know what the backstory is and what how tongue in cheek it is.
*  Yeah, I can't remember.
*  I can't remember either.
*  I do. I do remember disagreeing about Marvel movies.
*  But the yeah, the consciousness versus action thing, I don't think that's
*  I don't think it's a real versus there.
*  I think it's well, for me, I think if you look in an evolutionary sense
*  and you say what are brains or more basically what are nervous systems for,
*  I think they're for homeostasis, actually.
*  Therefore, keeping helping the organism keep itself going, right?
*  To keep its it's all of its systems in the optimal operating range.
*  And one way the organism can do that, of course,
*  is sort of regulating its internal physiology.
*  So reconfiguring its biochemistry, say.
*  But another way it can do it is
*  if the you know, if it can't locally adapt to its environment is to move.
*  So but but the goal of it moving is to restore itself to homeostasis.
*  So, for example, it might be hungry.
*  That's a signal that its internal physiology is is a skew
*  out of the range it wants to be in.
*  And then it can move in order to find food.
*  So a goal directed, reinforced kind of behavior.
*  And of course, you know, simple organisms,
*  single cell creatures like bacteria and amoeba do that.
*  But nervous systems in in multicellular creatures are really good for,
*  you know, coordinating action across the across the whole organism.
*  And and of course, they have built up this this power of information processing.
*  So rather than just having a single trigger that, you know, you go towards
*  just doing chemotaxis, you can assess multiple things in the environment
*  and you can integrate that information and build up a picture of what's out
*  in the world and even predict things about what's in the world
*  and take action that anticipates things and so on.
*  So you can get this sort of elaboration over time that nervous systems allow,
*  especially when they have a kind of a hierarchy that gets processes
*  more and more abstract things about the environment.
*  And ultimately, I would say that ends with consciousness, where
*  what it's processing is the goals and beliefs and desires that are being,
*  you know, represented or enacted within another part of the nervous system.
*  So for me, consciousness is the ultimate means of, in a sense, controlling action.
*  And it's still in favor of the or in the service of this ultimate goal
*  of keeping the organism persisting.
*  Yeah, I think I think just to follow up on this and maybe provide,
*  maybe I'll try to say something radical.
*  So Kevin and I actually have something to disagree about, you know, to be like
*  as as radical as possible, you know, a big concern of mine.
*  And this is, of course, married in, you know, some of the characters
*  in the revelations is this idea of a scientific theory of consciousness.
*  And the way that I would maybe phrase this is that, you know,
*  the way that I would maybe phrase this is that right now, neuroscience
*  has very good correlational measures.
*  So we can do a pretty good job in neuroimaging of correlating someone's
*  experience to some particular brain state.
*  But we have one would say no lawful measures.
*  So we have no lawful way to or relations.
*  We have no lawful way to relate, you know, some ongoing neural activity
*  to a particular conscious experience, like, you know, classically,
*  the redness of red or the feeling of pain or so on.
*  And if we don't have a and my suspicion is that if we had a lawful way
*  to do this, it would become very apparent that most of the brain's
*  kind of architecture and design is in instantiating is based around
*  instantiating this, you know, basically stream of consciousness,
*  which is kind of this dominant information flow within the brain
*  and that everything is kind of subservient to it in that it's feeding it
*  or manipulating off of it or so on.
*  And that this would be very
*  this would probably be a big paradigm shift just in the sense
*  that a lot of previous results would maybe look pretty incommensurate.
*  And the reason why I say that the goal is consciousness rather than behavior
*  is that, you know, certainly I think that you need behavior
*  to develop consciousness, you know, and all these things.
*  But I do think that it is true that most of the time for conscious experience,
*  a lot of the world just does not actually filter as directly into behavior.
*  In other words, it takes an immensely convoluted route.
*  You know, in the end, we're all Darwinian.
*  And, you know, the reason that, you know, organisms survive
*  is because of the way that they behave. Right.
*  Like that, that is incontrovertible.
*  But I think that there's a very
*  a view that I don't agree with, which is that consciousness is very minimalistic
*  or almost epiphenomenal, or you're only conscious of a tiny, tiny
*  top of the iceberg and everything else is going on.
*  I think that that's wrong.
*  I think probably, you know, even organisms that we think of
*  as having not very complex behaviors are
*  might have a very definite consciousness and that that is the thing
*  that much like for ourselves, that feels like it's kind of in control and so on.
*  And so, you know, this this view
*  is is, you know, in my opinion, not quite
*  as popular as it should be.
*  And I would say that as a bit of an understatement, because if it's true
*  and I'm not, you know, one could argue against it.
*  But let's just assume for a moment that it is true.
*  Then the question of lawful
*  the question of lawful relationships between, you know, neural
*  you know, neural states and experiences, it becomes incredibly powerful
*  and probably would in my and probably sweep away a lot of contemporary,
*  you know, neuroimaging or the way that neuroscience is done or so on.
*  So that's why I stress this consciousness as primary approach,
*  because it just is a change and it's just so different
*  or at least somewhat different than how, you know, this maybe the standard
*  and maybe the average neuroscientist, although that's very hard to figure out.
*  Right. Like what the average neuroscientist view is.
*  So I would agree in one sense that, first of all, that we don't have any good,
*  good theoretical grounding of of consciousness, really.
*  Or there's hardly, you know, much good theoretical grounding
*  in neuroscience generally. It's it's kind of theory free.
*  No, I disagree. Hang on. I disagree.
*  It might be good theory free, but there's a lot of theories.
*  Well, there's a lot of theorizing.
*  OK, we don't really have a there's not a, you know.
*  And this goes for biology overall, actually.
*  We have one good theory, which is the theory of evolution by natural selection.
*  That's our bedrock.
*  And everything else around, you know, beyond that is.
*  Yeah, there's loads of theorizing, but I don't think we have a solid framework.
*  We don't have a standard model.
*  But I'm not I don't I don't mean to be dismissive of the work
*  of theoretical neuroscience. It just hasn't gotten there yet.
*  I actually think it's really important to be work to be doing.
*  But I would say so the way that I think we're going to get to
*  a principled understanding of consciousness
*  might be in in in following an evolutionary trajectory
*  to say, OK, well, if we think of nervous systems as, you know,
*  there to as control systems, basically.
*  Then what does consciousness get you in that context?
*  You know, how how does it better allow an organism to control itself
*  by having that kind of a subjective experience of something going on?
*  And when we get to humans, I think the idea that we've got
*  what effectively is metacognition, you know, so that we can.
*  It's not just that we're having a conscious experience.
*  It's that we can introspect about our goals and beliefs and desires
*  in a way that gives us actually some control over them.
*  I think that's a powerful sort of maybe addition to
*  to the arsenal that an organism can bring to bear in terms of maximizing
*  its agency and autonomy over time.
*  But, you know, when you're thinking about, say, a fruit fly
*  and and I agree that a fruit fly probably has some kind of fruit fly
*  consciousness, then, you know, the question is, what is it?
*  What does that feel like?
*  But also, what does it get the fly above and beyond the control
*  systems that are already built into its nervous system?
*  Why does experiencing something help there?
*  And I don't I don't know what the answer to that is.
*  Well, it's so funny is that if you ask a person,
*  if you ask like an average person on the street, you ask them, like,
*  what's the point of consciousness, right?
*  They'll give you a very functional definition based off of things like,
*  well, you know, if something hurts, you'll move away from it.
*  Right. And if something feels good, you'll do more of it.
*  Right. And things like that.
*  And, you know, to be honest, I'm not entirely convinced.
*  We've even been able to supplement that in, you know, the sort of artificial
*  brains that we make with things like deep learning.
*  Right. Like we're kind of cheating where we're
*  kind of we're basically just doing calculus about the input and output
*  and figuring out, you know, what what what inputs you need to get
*  to the output that you want.
*  That's obviously not how biology is doing is doing this.
*  It's doing it off of somehow conscious experiences like don't don't ask me how.
*  Or at least that's what it appears to be.
*  And so kind of there is this very naive functionalist approach,
*  which is just that, you know, you organisms have experiences,
*  they have some sort of spectrum of, you know, affect along those experiences.
*  And then everything they're doing is kind of trying to, you know,
*  maximize or minimize their their affect along them.
*  And that is, I think, a viable read and might at some point
*  reassert itself as a very viable read if you got a good,
*  you know, lawful relationship theory.
*  I think the only problem with that, Eric, is that the, you know,
*  you can build a lot of those sort of control systems into into robots, for example.
*  You know, you can make a robot withdraw from things that are damaging
*  and you can make a robot go towards things that are rewarding.
*  You can build reward and punishment into into the circuits.
*  And of course, in, you know, when we look in animals, you know,
*  we can do these these experiments now in in mice or monkeys or other things
*  where we're tweaking those circuits and we're literally changing, not just,
*  you know, not just controlling what the animal is doing,
*  but controlling its cognitive states, controlling what it's what it's thinking, basically.
*  But it's all, you know, the counter argument would be to say,
*  well, OK, all that machinery is there, right?
*  You're we're going to send a reward signal.
*  We're going to send a punishment signal.
*  The circuits are going to interpret it this way or that way.
*  And the question is, why does it why does it help for that to feel like something?
*  As like if you build it in a robot, is the robot going to experience that?
*  Is that the you know, where's the where's the magic sauce coming from
*  that that converts the neural processing into a conscious experience?
*  And why does it help?
*  You know, is it just that it's broadcasting the signal to the whole nervous system?
*  And that's just what that feels like.
*  Is it does it inevitably feel like something or does it add something functional to the to the mix?
*  Yeah, let me maybe push back a bit on that initial assumption
*  that we do have very good models for how it for how it works.
*  So one is, I would say.
*  You know, maybe for some very, you know, maybe for like a pleasure,
*  you know, or something like that, we have very good neural models.
*  The moment you get into something like mice, I honestly do become
*  somewhat skeptical of, you know, a lot of kind of the contemporary approaches.
*  And now I know that that sounds like me just like throwing out the whole thing.
*  But let me just give a give an example of I don't quite think that if I when I have like a Roomba.
*  Right. Yeah, my Roomba is doing various things that look like it's trying to avoid or go back home,
*  you know, or so on.
*  And I think that it could very easily be that we're kind of fooled by this, where we think,
*  where we think, well, this is a very reasonable explanation for like an animal's behavior,
*  where it has some sort of almost like pre-programmed algorithmic, you know,
*  very simple thing inside of it that's going to be governing it basically, you know, in the same way.
*  You could say, well, maybe that's almost like a bit of an illusion, which is, you know,
*  and that actually what's going on inside an organism is like vastly more complicated
*  and somehow rooted or grounded in the actual experiences it's having.
*  And a Roomba just kind of apes that.
*  And, you know, while we can open up the Roomba and do experiments and we can open up a mouse and do experiments,
*  maybe they're just actually kind of a fundamentally different natural kind.
*  And you could have a whole behavioristic science of Roombas.
*  And our current techniques would work very well.
*  But if you did it for mice, maybe the current techniques would only kind of seem to kind of work well enough
*  that you can get publications and, you know, do various other stuff,
*  but they're not actually super effective as like a view of it.
*  And again, this is I'm not saying that this is 100 percent true.
*  I'm saying that I don't find this view represented enough.
*  Yeah, just a really kind of like hardcore consciousness first view of things.
*  Well, I mean, I think so I wouldn't necessarily I guess I'm very sympathetic to the idea that the
*  approach I just described there of, you know, digging into the neural circuitry of animals and tweaking this way and that way and showing that you can control the behavior.
*  I don't think that that gives us understanding necessarily.
*  We can get control without understanding of what the organism is doing.
*  And I think the reductionist sort of approach, really mechanistic, is just fundamentally wrong.
*  I think these are, you know, we have to think of these as organisms in concert with their environment as ongoing processes, really,
*  that have a kind of causation that's not just instantaneous and mechanistic.
*  And that sort of view is not really very, very popular.
*  And I see in a really vague sense how consciousness will somehow fit into that kind of model better than a mechanistic one.
*  But I mean, I don't see exactly how obviously, if I did, we'd have a much better understanding of what consciousness is and what it's for than we than we currently do.
*  I'll bite on Eric's radical statement.
*  I think that you like loaded up the crazy train and headed out by by going with the I'll just say something radical, too, by by going with a consciousness first approach.
*  I mean, because there's so little evidence that, well, there's so much evidence.
*  So here's my here's here's my pushback, I suppose, that I think there's more evidence that consciousness is the tip of the iceberg,
*  whereas you're saying that there's more of the iceberg in consciousness than than we appreciate in academia.
*  I have that right. Right. Yes.
*  And but the but the evidence I would suggest is would be in my favor, I guess,
*  or what you're saying is like the rest of academic academia's favor that the vast majority of our processing is unconscious.
*  And we have for me, I'm at home at ease with the fact that I have a very low dimensional, very minor connection to the rest of my processing.
*  And, you know, that sliver of free will that I don't really have, but I think I have is just I just barely I'm barely conscious, essentially.
*  I'm barely aware of what I'm doing and not in control at all, which is not a great feeling.
*  But I've become at home with it. So but but I think that the vast majority of research would support that notion that it is just the tip of the iceberg.
*  Yes. So I disagree. I think that that is a complete Freudian holdover and that Freud's I mean,
*  it is very difficult to overstate Freud's immense impact on ways of thinking from about 1930 to 1970.
*  I mean, his complete and utter domination of the intellectual scene and this idea that that humans are driven by, you know, mainly on sub sub or unconscious processes.
*  And, you know, Freud's theories, specific theories have now been, you know, pretty much round, you know, roundly refuted.
*  But his his his focus on the unconscious and the minimization of consciousness is, I think, still incredibly predominant.
*  I don't agree that there's any good evidence. I mean, as far as we know, the only complex agential behavior that biological systems demonstrate occurs when they are conscious.
*  You know, there is very, very few or rare cases of somehow loss of consciousness and complex behavior.
*  And they're very questionable. It's it's completely you have to separate between whether or not you are conscious of all the information flowing in your brain,
*  which is not at all a position that's even worth kind of discussing and whether or not in terms of a consciousness first approach,
*  whether or not the stream of consciousness is completely necessary for the complex behavior that the organism is demonstrating.
*  So and these are these are two different things. Right.
*  And this is something like, you know, your computer would be kind of nonfunctional without this sort of very nice top level user interface kind of baked into it.
*  So even if it's the case and now the computer metaphor isn't perfect because, you know, so let's take it as it is.
*  But like, even if it were the case that you could claim that consciousness is relatively high level within the brains, whatever term you want, representation, information processing,
*  either like poorly defined terms that neuroscientists throw around, you know, whether or not the brain is very high level, it doesn't really matter.
*  Because what matters is if you take away the high level, does the whole thing just collapse?
*  And I would say both from a from a naive perspective of like just people's understanding of other people's psychology and their own psychology.
*  This is true. And also there has been no good disproof.
*  And most of this stuff are things like working memory papers that I think are kind of poorly, poorly generalized and things like that.
*  So so I actually do disagree about the predominance of evidence.
*  Yeah, so that's interesting, because I would be more along Paul's line here.
*  But I think there's a there's a question, I guess, about Eric, when you're talking about consciousness, whether you know, because it means so many different things.
*  Right. And if it sounds like what you're talking about is that it's it's just the organism is online, basically, that it's been booted up and it's active.
*  Right. And as opposed to the question of whether it has to be having subjective, self, you know, self aware experience and be aware of itself experiencing things.
*  And to me, I'm happy to buy the idea that the whole system has to be working for the organism to behave as it normally does.
*  Although I think that would look and feel very different for organisms of different level of complexity.
*  Yeah, I certainly agree about the the the looking and feeling to some degree.
*  The only thing I mean by conscious experience is a is is is the James Ian sense of a stream of experiences which are qualitative.
*  So the what it is likeness.
*  And so and you know, if you're if you're if you're giving explanations about people's behavior,
*  what you'll find is that you talk entirely in terms of their conscious experiences.
*  Now, sometimes you might say something like, well, they unconsciously wrote a letter or so on.
*  And now the standard, by the way, just to just to say this, you know, I think the standard reply that I've heard from this is that eventually gets down to people saying something like,
*  you know, when you add up numbers in your head, do you really do the addition or you kind of handed the solution?
*  Right. And I think that that's actually a reasonable take.
*  But it doesn't mean that you could actually do, say, many of the things that you require consciousness to do unconsciously.
*  But this is the false step.
*  Yeah. OK. But if we maybe frame it in a different way and ask about, you know, decision making and action selection,
*  then I think all the evidence is really clear that most of the decisions, most of the actions we take,
*  we're not consciously deliberating about them necessarily, you know, because it just takes too long.
*  We're on autopilot for most of the things that we do most of the time because we have these constraints built in to our habits,
*  to our heuristics, to the policies, you know, decisions that we've made before about what we will do in the future,
*  which is all good and important because otherwise we take so long deciding everything that we'd be we'd have been dead long ago.
*  So, you know, in terms of sorry, go ahead.
*  I was just going to just for that very specific example, I would say, I think that, again, some of this stuff is just linguistic.
*  So, you know, your point is absolutely correct.
*  Right. If we if we cognitively kind of made high level decisions of what we think of as consciousness.
*  But the trick is that I think that that's a very different use of the word consciousness.
*  A simple example might be like, let's say I reach for a glass, you know, a reach for a glass of water.
*  Now, you might say, well, did you really deliberate consciously about whether or not you would reach for the glass of water, you know, before you reached.
*  Right. And of course, everyone would say probably not most of the time.
*  Right. And then, you know, I don't think that one can at that point claim victory at all because we can say is, listen, I kind of felt like this urge,
*  like this whole this whole thing played out within the activity of my stream of consciousness.
*  I saw the water. I had an urge.
*  I wouldn't have really analyzed it or described it.
*  I wouldn't have spent much time on it. And then I consciously reached out, grabbed it.
*  Everything is again operating in the theater of my consciousness.
*  And then I took a drink and I experienced the sweet cold liquid.
*  And that is what I mean.
*  Yeah, but there's lots of other situations that are even less than I give an example because I burned the hell out of myself two days ago with coffee.
*  So I have this is going to sound highfalutin, but I, you know, I put butter in my coffee or whatever and you got to mix it up.
*  So I have like this aerator thing. Oh, stop grimacing, Kevin.
*  It's OK. It's it's intermittent fasting anyway.
*  So you stick this little wand in and it spins really fast.
*  And I had and kind of like aerates the coffee mixes up the butter and stuff.
*  It's unsalted butter. And I had heated the coffee hot enough so that when I put the butter in, it wouldn't you wouldn't get cold.
*  And right when I started aerating and I press the button and it goes and for some reason it kind of blew up.
*  I don't know. It was a butter reaction or something with the coffee.
*  And in that. So my experience was nil.
*  But what happened was I managed to take the aerator out.
*  I did actually accidentally throw it across the room, but nothing was broken.
*  And and at the end of that experience, I was thankful that my body took over and performed these complex actions without me being aware of it.
*  And you sort of like come to and realize, oh, I just did all I made, you know, a lot of degrees of freedom movements.
*  And yes, the the little wand is OK, but I did have to pick it up, you know, because my body did kind of what I'm trying to do is take it away from reflex and say it was more than reflex because I was making a complicated movement.
*  But it was all unconscious, all my body. So just to throw that example as I don't know if Kevin, you're going to.
*  Yeah, look, I mean, I think again, there's lots of things that we do on complete autopilot where we're not even necessarily conscious of what we're doing at all.
*  You can be driving along and just, you know, drive to the wrong place because you're not thinking about it at all.
*  You're just really not devoting much cognitive resources to that task at all, except a kind of a surveillance for danger and traffic signals and stuff like that.
*  So I guess I mean, it's sort of appealing to the system one system to, you know, dichotomy or or a spectrum, maybe of Daniel Kahneman.
*  But in terms of decision making, you know, I think the the things that we do consciously and deliberatively, at least, are a small subset of everything else.
*  But, you know, maybe it's maybe it's maybe it's semantic.
*  Yeah, I find it incredibly telling that the clearest example you have is basically a reflex arc.
*  That's what I was saying is is beyond before that I agree with.
*  Right. So so it's very telling that right, we immediately go to something that we actually do all agree would be a kind of classic unconscious activity, right?
*  Which would like putting your hand on a hot stove.
*  And let me just say that even that even that right, like even particularly in your example.
*  Right. Now, if you didn't already have like the theater of consciousness set up such that you knew that it's kind of broadly available information about where your body is, where this thing is all these things.
*  And then, yes, maybe you do have something that happens so quickly in kind of neural time scales that you're only going to experience it once it's once it's over.
*  But it's still making use of all that information that you already had.
*  So even in that case, I wouldn't be willing to say that your conscious, your stream of consciousness had no kind of significant causal impact on on what you did.
*  And if even in that case, I feel like one can kind of possibly defend it, then I think that when we get to more complex cases, it becomes more and more obvious.
*  And again, I think that some of this stuff, as you say, Kevin, it is semantic, right?
*  Where one has to say precisely what one means.
*  But I think by focusing on this notion of a stream of consciousness and the degree to which that information is used, right, and necessary, then one gets, I think, closer to kind of both interestingly enough, closer to the naive perspective.
*  Which is actually which is that human beings are experiencing these things and they're just basically reacting based off of what they're what they're conscious of.
*  And they have their various hedonic pleasures and pains and so on.
*  When you get closer to when you take this view of brain function, you also get a lot closer to the naive view.
*  And I find that is probably a good thing and good evidence for it.
*  So can I can I push back, Eric, just on the well, I want to roll back in time, as it were, evolutionarily.
*  So if we imagine just an amoeba, say, and it's schmooing around the place and it's getting some signals from the outside about where, say, some bacteria are that it could eat or where other amoeba are to form a fruiting body or something like that.
*  So it's got it's got information in that there are, you know, it's got receptors on the surface.
*  They're sending a signal internally when they bind some chemical.
*  There's a therefore there's a pattern inside the organism that has relative information, right.
*  It's physically correlated with something out in the world.
*  And it's configured in such a way that it responds to that by, say, approach or avoidance.
*  My question is, I guess, where is it experiencing any of that?
*  Is an amoeba experiencing any of that?
*  And if it is, then then fine.
*  You would say that's a kind of a proto consciousness, then that's fine.
*  I'm happy with that.
*  But if you think that it isn't, then at some point in evolution, consciousness arose where it wasn't there before.
*  And then and then literally its behavior first, consciousness second as an as an add on in evolutionary terms.
*  But I'm wondering what you think about the amoeba if it's having amoeba experience.
*  Yeah, I would say, you know, that's dependent on the final theory.
*  Right. So this is the boring answer. Right.
*  Like the boring answer I can give is that, you know, when consciousness arises is basically just a function of whatever this law, this lawful relationship is.
*  And I don't know what the lawful relationship is.
*  Unfortunately, I wish I did.
*  I can give some some guesses and we could talk about, like, you know, maybe a well, at least one of the bigger theories, which is like integrated information theory,
*  which is, I think, you know, maybe it's not well accepted, but it's kind of well known and well discussed.
*  And there are empirical studies that do support it. Like one should be clear about that.
*  There are there are some good studies, although I don't think it's correct.
*  Slipped it in. But yeah, I think reasonable to say just because I worked on it.
*  So, you know, we should have my my personal opinion is probably that it's not the final theory, but it's a good theory.
*  It looks kind of like what a theory should look like.
*  And so, you know, so to that, I can't quite answer it, but maybe I could just say that, you know,
*  the the gap here is probably a bit bigger than people think in that depending on what the sort of lawful relations you end up with,
*  it could be very much that consciousness is totally epiphenomenal and only looks to be, you know, it just so happens, right,
*  that we experience something very unpleasant right when we are supposed to be acting like we experience something very unpleasant,
*  you know, or it could be maybe very directly, causally impactful.
*  And I think for those sorts of questions, you know, we need theories of causation.
*  You need theories. I know, Kevin, you're interested in like theories of emergence and and theories of consciousness.
*  And I think that those things need to be resolved like my own personal preference, to be completely honest,
*  is that I think that emergence is very solvable scientifically.
*  No, I don't think that there's anything in there, even in the most even taking very seriously everything that philosophers talk about,
*  like classic analytic philosophy about emergence, even taking all that stuff.
*  Let's just take it very seriously.
*  Even then, I think it's completely solvable.
*  And that feels very different to me than my consciousness, where, you know, I have some ideas.
*  But to be honest, I don't have any of the same certainty that anyone's going to crack it, you know, in the next dozen years.
*  I mean, maybe this is an opportunity to talk about emergence and some of the stuff maybe we do.
*  Definitely. Let's let's because I want to make sure we have enough time to go down that road.
*  So, I mean, Kevin, one of the reasons why you're here right now is because you've been working on the evolution of agency and and the emergence, essentially, of agency.
*  And, Eric, you have a host of recent publications talking, examining how you can use information theory concepts to show that you can get more.
*  There's there's more in the macro level than in the micro level.
*  You can show that mathematically in these certain systems that you use as examples.
*  So, yeah, I mean, I just kind of introduce those topics because I just want us to go down that road of, you know, so maybe I'll start with here.
*  Here, Kevin, I'll quote you in a recent talk here.
*  He say patterns of neural activity have causal power solely by virtue of their meaning.
*  OK, so where does meaning come from? Let's go down this road.
*  Well, yeah, great. Good.
*  OK, so, yeah, I mean, that's really a pushback to the reductive view that, in fact, you know, as we learn more and more about how neural mechanisms work and seemingly underpin things like desires and beliefs and goals and so on,
*  the less work there seems to be for the desires and beliefs and goals themselves to be doing anything.
*  The mental content doesn't seem to have any efficacy there.
*  It's just like, well, look, the neural circuits are firing that way and they're configured like this.
*  And this is what's going to happen.
*  So what's all this other stuff is just epiphenomena.
*  And I think there's a there's a strain, at least in modern neuroscience, that's that's quite reductive in that sense.
*  And I think it's absolutely backwards.
*  I think that those patterns of neural activity only have any causal power in the system because they mean something.
*  So the system is configured in such a way that the patterns refer to something, represent something, reflect something either out in the world or or internally that is tied through either evolutionary wiring that sort of packs this program for configuring
*  the nervous system a certain way into the genome or through the individual learning of of the organism through experience such that the the outcome is appropriate for the organism in light of the goals that it has at any moment.
*  So, you know, that's a long winded way, I guess, to say that the organism is behaving as an agent because it has purpose built into it by natural selection and the simplest things, you know, single celled organisms, their purpose is just to persist.
*  But that's how natural selection works.
*  Things that persist. Persist and things that don't don't.
*  So we see the ones that do.
*  So that tendency is just wired in there, you know, starting with biochemical circuits that that maintain themselves going and then moving to behavior when animals can sense things in the world that it is adaptive for them to approach or avoid.
*  And then that behavior gets reinforced over time.
*  So in that sense, the meaning is, first of all, a pattern of information that's correlated with something.
*  That's just there's nothing controversial about that.
*  Lots of things are just physically correlated with each other.
*  But secondly, that it has some relevance for the organism in terms of its goals.
*  So in terms of the purpose that it has, so it has some some salience and some and some importance.
*  And it's linked consequentially to some kind of action.
*  Yeah, Kevin, maybe you could say something about like this, the very first thing you said, right, which is kind of framing this, which is the reductionist drive within neuroscience.
*  Yeah.
*  Do you find it like almost overwhelmingly common?
*  Kind of, yes, I think it's it's not always explicit.
*  It's often just sort of implicitly there.
*  The idea that we can first of all go, you know, we can break down behavior to the circuits, the components that are driving it, and we can control them with these amazing experiments.
*  And that sort of reinforces the idea of a mechanism at play that we can intervene on and and drive and manipulate.
*  But then, you know, below that, there's a there's an even deeper sort of idea that actually, you know, the circuits, that's all illusory.
*  It's actually just atoms and molecules.
*  And it's the laws of physics.
*  You know, it's a really deterministic view from physics.
*  And this comes up in debates about free will, where people say, well, look, it's all determined by the laws of physics.
*  You're just made of atoms.
*  The atoms are going to do what they're going to do.
*  What does you having a thought have to do with any of that?
*  Nothing. It couldn't possibly have any causal power in the system.
*  And I think that's I think that's completely wrong.
*  It comes from a really impoverished view of causation, which is all basically bottom up.
*  And it ignores the causal potential of organization, which is a trivial commonplace sort of thing.
*  Like, we know that organization has, you know, has some causal influence on the way that things happen.
*  But people bizarrely seem to just reject that idea.
*  And I can't really understand why it seems to be so controversial.
*  It's actually quite funny because most of the time, the people who are the most reductionist are often not always, but often,
*  you know, all their science in their particular science, its elements occupy some
*  some very high up place in the spatial temporal hierarchy of physical objects.
*  Right. This is something that I've talked about a lot and have been trying to bring back as like a really big issue.
*  If you say science is about reduction, you have to explain the fact that there are very there is a huge diversity of scientific fields,
*  which all take various high level components as units of function and causation.
*  And I'm not the by any means the first person to say this, probably, I think one of the best statements of this comes from the 1970s by a philosopher, Jerry Fodor,
*  who wrote who wrote something called like the the unity of the special sciences as a working hypothesis.
*  But his his whole the whole paper and I think Jerry Fodor was probably one of the better
*  and like philosophers of the 20th century is basically just saying, listen, you can't be a universal reductionist and still believe in science because
*  science contains all sorts of things where people just sort of stop at some particular level of description and then they like don't want to reduce any further.
*  And then his his question is like, why don't you want to reduce any further?
*  And he doesn't provide an answer to that. But he does point out that it's a it's a really big problem.
*  You basically have to dismiss your own field and just say, well, if we could, we would.
*  And that's what I very much have been trying to show is incorrect and try to prove is incorrect using simple, clear models.
*  Because, you know, the moment you start talking even about physics in general, you're talking about very complex systems that are difficult.
*  But if you can show it in, say, cellular automata, then you can be reasonably sure that it's true in the real physical world.
*  So, you know, all my research has basically been looking at things like cellular automata or like small, simple Markov chains and simple systems like that.
*  And then asking questions about, say, causation when you move through different different levels or scales and you find some very surprising and concrete effects,
*  which is that two macro states by which I just mean some dimension reduction of micro states can have a stronger dependency than their underlying micro states.
*  I mean, it's almost like so trivially true that it sounds absurd.
*  But as a very simple example, imagine I have 10 micro states and those 10 micro states all transition to one another depending on what state you're in.
*  So it's just a Markov chain, just 10 states.
*  And let's say the first, you know, three states, two of the states all are equally likely to go to each other.
*  So A and B, if you're in A, you could go to A, you could go to B equally likely 50-50 chance.
*  Right. If you are in any of the other eight states, you are equally likely to go to one of those eight states.
*  So you just bounce around, right?
*  It's like this. It's like if you're in if you're one of these eight states, you just bounce around between these two states.
*  Right. If you're in these two states, you just bounce.
*  OK, well, let's think about some of the conditional dependencies, which is the traditional way to talk about causation in that system.
*  And what you will quickly find is that the macro states of that system, if you just say these eight latter eight states are macro state, you know, gamma and the first two are macro state alpha or whatever,
*  then you'll quickly find that macro state alpha has a deterministic transition to itself.
*  And the other macro state also has a deterministic transition to itself, even though the micro states are essentially choosing at almost random.
*  So there's almost no like causal.
*  The causal relationships of the micro states are immensely noisy.
*  But the macro state relationships, while there are fewer macro states, they are deterministic.
*  They're not only deterministic, they're that you can retro deck, too.
*  So now I have perfect prediction and perfect retro diction, which in my research, this is called determinism and degeneracy.
*  So you have you have perfect determinism and zero degeneracy.
*  And you had a lot of indeterminism in your micro state model.
*  And my argument is that, you know, if you're if you're if you want to choose between your models of the system, both are equally valid descriptions of the system.
*  But one of those actually contains two strong dependencies and the other one contains just a bunch of totally weak, noisy dependencies.
*  And according to various metrics of causation, they can be higher at this macro scale.
*  And I think that a lot of the time, you know, it's not just that what you want to what you want to show to argue against like the universal reductionist position is not that somehow you can't do this reduction.
*  Of course, you can, because what philosophers call supervenience holds.
*  But if you do do the reduction, you lose something.
*  Yeah.
*  And quantifying that loss is what I've been been after.
*  And we've I've kind of proposed various measures, you know, by which one could do this.
*  I happen to think that the latest one, which is just using the mutual information, which no one can argue with the mutual information, which is why I love it.
*  You can't get out.
*  There's no escape from the mutual information.
*  If you show something in the mutual information, you have to believe it.
*  So, you know, just even showing in the mutual information that you can lose, you can break down the mutual information to three different types and you can lose different types of information when you go down in scale.
*  You can transfer from synergistic to redundant information by reduction.
*  And so what this shows is that it's not just about compression, right?
*  It's not just that, yes, everything should be all our models of the world should just be physical models, but of micro physics.
*  But we just don't have a big enough supercomputer.
*  Like, we're not Laplace's demon, so we can't do it.
*  It's like, no, Laplace's demon has a provably bad low information model of the world because he doesn't have good dependencies.
*  The world that he sees is just completely indeterministic.
*  And it's just there's no boundaries.
*  And the causal relationships are poor and uninformative.
*  And all the information is redundant.
*  It's not synergistic or unique.
*  And when you think about it like that, I think that you can have a strong argument that you that higher level scales, you can talk about it philosophically, that they're ontologically real.
*  But certainly, I think just talking about in terms of method and when or when one should or should not reduce is probably the best way to talk about it.
*  Yeah, yeah.
*  I mean, I agree.
*  And I really appreciate your work on this because it I think really clearly shows that it's not the case that like someone like Sean Carroll, for example, the physicist talks about, you know, these other levels of description, higher levels of description as kind of convenient ways of talking about things.
*  But the real truth is all down at the low level.
*  And if we had the full picture of the low level, then we would have all the information that's there.
*  And the higher levels would emerge from in a very simplistic kind of sense would be completely determined by all that what's happening at the lower levels.
*  And, of course, in an instant, they're instantiated in the low level organization.
*  But that's not where the explanation lies for how the system evolves.
*  And we have to have the right level at which to to interrogate that and to understand it.
*  And I think actually neuroscience these days is catching up with the idea that in any field of cells, for example, you'll have some pattern of activity.
*  But it's got tons and tons of different possible microstates.
*  And it actually is a trajectory through a sort of a low dimensional manifold.
*  And depending on what the trajectory is, that's what the meaning of that state is.
*  And then what happens in the system is based on the configuration of the filter, the set of synaptic connections, for example, that that manifold goes through.
*  And so it can be configured in such a way that if it's manifold A, this happens.
*  And if it's manifold B, that happens.
*  And all of the low level information is just lost.
*  It's too noisy to begin with, but it's actually actively filtered out by by the nervous system.
*  So that's what I mean, Paul, what I'm saying, the nervous system is running on meaning there.
*  It's meaning it's meaning that drives the mechanism and the meaning is inherent in the configuration of of the circuitry.
*  And it's been put there, it's been packed in there by evolution.
*  So we have to think of it in and by experience.
*  So we have to think of causation not as this purely instantaneous sort of thing that just doesn't capture why the system is the way it is.
*  There can be some instantaneous trigger, but the structure of the system has causality packed into it that is just often kind of ignored or seen as non non scientific.
*  It was almost banished by Francis Bacon, who was just saying, well, look, we've got just the efficient cause and the material cause.
*  And we're not going to talk about formal causes and final causes in Aristotle's framing.
*  And I think we're still suffering from that really narrow, reductive, both in space and level and time, view of causation.
*  That's really interesting, Kevin.
*  So, you know, in terms of like this notion of meaning, you know, I'd be very interested in seeing some sort of connection between, you know, because meaning is kind of you can think about it as like this very, very high level phenomenon.
*  Right. So it's kind of like almost like what happens if you dimensionally reduce enough.
*  Right. Of course, you know, in a sense, we are saying something a bit different.
*  Right. So, you know, you're you're focused on this notion of of meaning and the different sort of notions of, you know, causation, you know, like the classic Aristotelian.
*  And I do think that that's a really interesting way to talk about these issues.
*  And but I want to be clear, I don't I'm not I don't I don't know to what degree it will kind of fully like I have not actually studied it.
*  Right. So so I can't speak to like the truth or falsity of it.
*  But I think it's a very interesting approach because I do agree that people take causation as this obvious primitive.
*  Like and it's not right. You have to specify what you mean.
*  Right. And what you're saying is like, well, OK, let's be very serious about what you mean.
*  In your in the example you gave of like the someone like Sean Carroll.
*  Right. I mean, I think it's when somebody says something like all the information is at the bottom.
*  Right. So that is directly provably wrong.
*  So and but one has to be subtle.
*  One has to be very subtle. So it's it's provably wrong because the type of information that one is probably talking that someone's probably talking about when they say that is something like the like the comagro of complexity or something.
*  But they're like, yeah, like, listen, like the, you know, if you were to run a Turing machine that was running the world and you ran it at the level of microphysics, it would, you know, the program that you need would be way longer than if you ran it at some higher level of scale.
*  Right. And that's like obviously true and totally irrelevant to any discussion about the causal powers of higher level scales.
*  But instead you have to look at is, you know, like a measure of causation or a measure of information and you have to specify what measure you're talking about.
*  And, you know, like, for example, in the in the latest research that we did, we were using the mutual information, which you can break down into redundant, unique or synergistic components.
*  And what we showed is that, yes, you can you can have the same mutual information at the lowest level scale and at a higher level scale.
*  But at a higher level scale, that mutual information, all those bits are synergistic and at the lowest level scale, all those bits are redundant.
*  OK, so choose between your two models, right?
*  You can have a model where everything is just redundant bits or you can have a model where all the interactions are synergistic and that synergistic effect disappears when you reduce it.
*  So I want to be clear that synergistic information disappears when you do that.
*  So when you say, you know, if somebody says all the information is at the bottom, it's like, no, it's literally not.
*  Yeah. And so I just think that this has been basically a massive confusion of people who weren't like sitting around with simple models and just like specifying what they meant.
*  And then we and also a confusion of reduction with like universal reduction versus like taking things apart helps you understand what they do.
*  Well, that is very, very obvious.
*  Right. But also not completely true, because we obviously always stop at a certain point and declare kind of victory or declare that we have a good subfield of science here with these kind of primitive atoms of function and so on.
*  So I really think that I hate to talk about free will because I do think that consciousness comes in and is the wild card in this discussion.
*  But certainly, I think one could even just say just talking about neurons versus atoms, that there is there is way stronger claim that your actions are caused by the macro states of your neurons, then by the underlying micro states of the atoms that make them up.
*  Yeah.
*  Which I think is totally true.
*  Yeah.
*  And I think a parallel way to argue that is, first of all, that that I think physical indeterminacy is just not the case that there is real indeterminacy in the universe.
*  So that's a whole, whole other discussion.
*  And it physics hasn't, you know, agreed on it.
*  But I think it's it's right to say that the low level details of any neural state or the state of all the atoms inside a single cell by themselves don't fully determine the next state.
*  And and so you've got some neural state, it doesn't determine the next state.
*  And you also have this multiple realizability and that many, many different micro states can mean the same thing at a macro, at a macro level, which is where that causation comes in.
*  So if the if the low level details don't determine the next outcome of the whole brain, then you can ask, well, what does settle the outcome?
*  And what I would argue, and many others, is that it's it's the meaning in the macro states that is what drives the system.
*  And that's where and that's where I think agency and ultimately what we refer to in humans as free will can be found because there's some causal slack in the system.
*  It's not just reductive.
*  The high level things drive it.
*  And that's basically what we mean when we say we're deciding things is that we're doing them for our reasons.
*  I was going to ask a naive question, and this is about from from both perspectives, I think, from both of your work.
*  What role so so, Eric, in your work and again, this is naive, but when you make a macro state out of micro, you're making a move.
*  But mathematically, there's no cost to making that move.
*  You just state it and it happens.
*  But in a physical world, in the real world, to to create a macro state, there might be physical thermodynamic all penalty cost to actually instantiating that in a physical world.
*  And this gets back to and I don't know if we need to talk about this more, but the idea of constraints and boundaries and just environment and the impact that the whatever system.
*  There is the interaction with the environment and how that relates to to the information and that you can glean from the micro and macro states and the emergence, whether emergence necessarily needs to take in considerations from from its environment.
*  Yeah, so just to clear up a confusion, there's definitely no cost to like, creating a macro state.
*  Like, as a very simple example, you know, when we talk about colors, right?
*  Obviously, if I say, you know, my wall is a certain color, what I'm saying is basically that there's some sort of macro state wherein if you kind of average together all like the colors of my wall, it'll end up being this.
*  I don't really mean that every single, you know, like like the finer and finer you zoom in that color is just completely consistently maintained.
*  Right. That would be the description of the micro states of all the colors.
*  And then you could go even further and further right of all the states.
*  So it's just describing something at a particular level.
*  And just to differentiate, maybe just to try to differentiate Kevin and my position a little bit, because it sounds like we agree on so much would be, you know, on this this notion of, you know, for me, the notion of meaning does not yet have to come into play for many of these
*  phenomenons. Now, maybe it does come into play with something like a nervous system.
*  As I said, I'm like open to this kind of interesting notion of like macro states somehow gaining meaning.
*  But just if you look at like the macro state descriptions of a very simple system, they can be completely deterministic and therefore kind of constrain the past and the future to a greater degree than any of their underlying micro state.
*  And it's not a contradiction.
*  So this is this is a completely non contradictory thing to say.
*  And I'll give you a very simple example, which is let's assume that the macro state we're talking about is your behavior.
*  But again, this could be a very simple macro state.
*  I'm just using this as an example.
*  You know, I can predict what physiological macro state you're going to be in in about 12 hours.
*  Right. You're going to be asleep.
*  So my guess off of your current macro state, which is like, you know, you're awake and it's this time and you're feeling like this.
*  My current guess is that I'm going to predict with like, let's say, a 90 percent probability that you're going to be asleep.
*  And that's going to be the macro state that you're going to be in.
*  Now, my now you compare that to like Laplace's demon.
*  Right. And you say, OK, Laplace, Laplace's demon.
*  Why don't you make your prediction now about what their future state's going to be?
*  But here's the thing. I'm going to restrict you to talking about it in the language of micro physics, because that's what's supposed to be so special about you, Laplace's demon.
*  So you got to make this bet in terms of micro physics.
*  And Laplace's demon takes in your entire micro physical state.
*  Right. And then I say, OK, which micro physical state are they going to be in in 12 hours?
*  Right. And Laplace's demon says, well, listen, I'm going to give you a really big list of possible micro physical states, all with vanishingly small transition probabilities.
*  So I'm going to say, listen, you've got a one in a billion chance to be in this micro state, one in a billion chance to be in this micro state and so on.
*  Why? Because you're getting hit by solar flare, you fly solar rays and like you're an open system.
*  It's just impossible. So Laplace's demon makes this big list.
*  And you say, well, listen, Laplace's demon, like you the dependencies between the current state and this huge list of possible state.
*  The dependency here is vanishingly small.
*  Right. You're just saying like you're basically not barely.
*  You're only you're not even probabilistically sufficient and you're definitely not necessary for any of these states and so on.
*  But my macro scale description, suddenly I was able to get a really nice deterministic causal relationship.
*  And as Kevin said, the world, particularly at the micro physical level for open systems, even forgetting if physics is itself deterministic, if you take the full state of the universe.
*  But we're all open systems and you're incredibly noisy.
*  So, you know, you really are gaining something by talking about it in terms of macro states.
*  And I think that that's probably something that scientists are implicitly queuing in on when they find a nice field of study, because it's like, oh, look, I can intervene on things here and I get nice kind of deterministic responses.
*  And, you know, my my theory is basically that what you want to do is you want to maximize the determinacy while also maximizing this the size of the model that you have.
*  So you want to find that sweet spot where you're as deterministic, you're like your interventions to effects or the conditional dependencies are as deterministic as they can.
*  And you haven't dimensionally reduced too much, you know, because you could just dimensionally reduce everything into one big macro state and declare victory.
*  Right.
*  And the.
*  So anyway.
*  Yeah, the interesting thing, I think, is that that's what the nervous system is doing.
*  And it has to, because all those components are really noisy and neurons are just not great information processors in isolation.
*  And, of course, you go from analog signals to digital and back to analog and you're filtering all kinds of information and doing it and doing it really actively.
*  You know, every time you go from one synapse to the next, that that neuron's doing something.
*  You know, you're performing some operations on that on that information, either at a single synapse or collectively from one area to the next.
*  So, I mean, in a sense, there's a cost to that in that that's the activity, the work that the nervous system is doing.
*  But on the other hand, it's far less work to do that than to try to transmit all the individual bits of information.
*  In fact, it's pointless to just keep transmitting the same information along a chain without without operating on it or extracting any, as I would say, meaning from it.
*  I was worried this was going to happen.
*  I have about 400 more questions to ask you guys, but I guess my questions are micro states and we'll have to we'll have to let me let me ask one more question here.
*  And I don't know if you guys will will differ on this and then we can wrap up.
*  So the question is, do we need to understand life to build intelligence and in other words, is building artificial life essentially a precursor to building artificial, a necessary precursor to building artificial intelligence?
*  And my gut tells me, Kevin, your work with understanding agency, trying to understand how agency evolved would suggest that you do think that intelligence presupposes essentially life processes, homeostatic processes.
*  And, Eric, I don't know where you land, but maybe who knows if you guys will disagree or agree, but that's that's the question.
*  OK, well, maybe I'll jump in there.
*  So it's really, really interesting.
*  And I think in a sense, it depends on what you mean by intelligence.
*  And there's been a tendency, especially in AI, to think of intelligence in terms of things like playing chess and sort of logical, really cerebral operations when, you know, for most things on the planet, intelligence means behaving in a way that keeps you alive.
*  You know, I think intelligent behavior is things that keep the organism alive.
*  So if you think of it in that sense, you know, it's goal directed behavior.
*  And of course, you can do information processing and cognition that underpins it.
*  But my own feeling is that if we want to get to something that we would say has a kind of autonomous intelligence, then we do need to give it agency, really.
*  And we need to we need to make it a living autonomous thing that has some sort of causal insulation from the rest of the world and.
*  And I think that intelligence isn't just being, you know, it's not just a stimulus response kind of machine or something that's doing information processing in isolation from any from any real world goals.
*  I think we need to give it a reason to care.
*  And the easiest way to do that is to make it care about itself, because that's what life does.
*  What do you think, Eric?
*  Yes, I mean, again, hinging greatly on the definition of intelligence.
*  Right. So I think to get the sort of a gentle behavior that the average person would say, oh, this this AI is intelligent or something like that.
*  Most people wouldn't even say that about Siri.
*  Right. Like, like, why wouldn't they write Siri actually seems to know quite a bit.
*  Well, Siri is no like animus, like Siri just sits there and gets queries and spits back answers, you know, and it's really not what we think of when we when we think about intelligence.
*  But I would say I'm also a little bit maybe just to finally bring this all in full circle.
*  You know, the sort of techniques that people use to build these artificial intelligences and so on look to me a lot more like like cheats than the way that biology does it.
*  You know, just like you're what you're literally doing is you're just rewiring the system until you get the answer that you want.
*  Right. And then you do that over and over and over and over again.
*  And that's what backpropagation is.
*  And, you know, it would be like if if you were taking a test and, you know, you got you got a certain number of answers wrong.
*  And then your teacher rewired your brain such that you would have gotten those answers correctly on this multiple choice question.
*  And then they give you another test and you're performing better on it.
*  But what did you learn?
*  You didn't learn anything.
*  They just rewired your brain.
*  You didn't have the experience of learning.
*  You didn't you don't even feel like you've learned.
*  Right. Like you're just getting better at these questions.
*  So I wonder if sometimes we are if we might have just discovered like very different ways to do things and that the concerns of biology, which might include things like metabolic efficiency and so on, just completely ignored all these sorts of solutions because they're like they're not practical.
*  If you don't have good training and testing data and they're not practical, if you can't do post hoc regularization and they're not practical, if you can't do blah, blah, blah.
*  Right. So I wonder if, you know, again, maybe what you really want for intelligence is something that's just conscious.
*  And once it's conscious, it'll kind of look and act like us and or not look like us, obviously, but it'll act like us.
*  And, you know, it just requires a total reframing.
*  But we'll see.
*  I think actually, just to just to pick up one thing there on the the energy efficiency thing, I think if anything is going to drive a move in AI towards a more biologically inspired framing, I think it's that it's power consumption is going to be the limit of deep learning and those kinds of those kinds of methods.
*  And there's going to have to be a rethink of however the hell it is that brains managed to do this on, you know, whatever, it's 20 watts or whatever, you know, something like that.
*  So I do think that there may be a radical rethink, which brings us closer to biological intelligence by virtue of having to be inspired by that biological design.
*  I certainly hope so, because, you know, the fact that something like GPT-3 can spit out a poem and I don't think that it has consciousness or mind.
*  I wouldn't say it has any of those things is a horror to me.
*  So like as a writer, I literally think it's a horror.
*  And if you think about it enough, I think it becomes a horror.
*  And so, you know, I'd love for it to actually be conscious because then at least, you know, I'm competing against, you know, an actual agent rather than just this like weird statistical summation game that is totally mindless and yet can like, you know, put out good Shakespearean poetry.
*  So, Eric, I mean, that's a good note to end on because I don't think GPT-3 actually has your vocabulary reading the revelations, like the descriptions.
*  I mean, a lot of it is borderline poetry, the way that you narrate and describe what's happening.
*  I mean, it's really like just a pleasure to read so much of what you wrote in the book.
*  So congratulations again on the novel.
*  Kevin, I can't say that you write poetically in an eight.
*  Maybe you're going to include some poetry.
*  Is the new book about agency?
*  The new book is about agency and I can't wait.
*  Ultimately, free will.
*  And I don't think there's going to be too much poetry in it.
*  Not from me anyway.
*  But anyway, it's very enjoyable on my normal reading level, which is the nonfiction.
*  And so I greatly just enjoy both your works and research.
*  Keep it up, guys.
*  I really appreciate you being with me.
*  Thanks.
*  Thanks very much.
*  Thank you so much, Paul.
*  It's been awesome catching up in somewhat in-person, Kevin.
*  Yeah, likewise, Eric.
*  Thanks a lot.
*  Patreon button there to get in touch with me.
*  Email Paul at brand inspired.co.
*  The music you hear is by the new year.
*  Find them at the new year.net.
*  Thank you for your support.
*  See you next time.
