---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 4641s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 6051
Video Rating: None
---

# BI 132 Ila Fiete: A Grid Scaffold for Memory
**Brain Inspired:** [April 03, 2022](https://www.youtube.com/watch?v=jL_tka90wKY)
*  I practically fell out of my chair. It was just such elegant periodic grid-like responses of cells.
*  It was just a physicist's dream.
*  So you've got like a very large library, so a large clothesline if you will,
*  and then you've kind of got as you move through the world, you're kind of moving along the clothesline,
*  and you're also getting sensory data, and then hippocampus is like the clip.
*  Hippocampus just clips the clothesline to the sensory data and clips it together.
*  Now there's one difference, I think it's fundamentally,
*  I tell my students that biology is fundamentally different from physics in one way.
*  Hello everyone, it's Paul. That was the voice of Ila Fiet, who runs the Fiet lab at MIT,
*  where they study the dynamics and coding principles that underlie computation in the brain.
*  That's actually what her website says.
*  So the hippocampus and the hippocampal complex is one of the most widely studied brain regions,
*  especially these days after the discovery of place cells in the hippocampus and grid cells
*  in the interrinal cortex, which is a major gateway to the hippocampus.
*  And we've discussed place cells and grid cells and a host of other spatially oriented cells
*  multiple times on the podcast, which together are thought to encode what's often called a cognitive map.
*  And cognitive maps are what help us navigate the world.
*  And recent work has shown that cognitive maps seem to help us navigate our own thoughts
*  among the abstract concepts we hold in memory and manipulate to do cognitive things.
*  But the story of how place cells and grid cells get formed isn't finished.
*  And part of what we discussed today is Ila's work supporting the idea that grid cells
*  are providing place cells with a kind of pre-built scaffolding,
*  which the place cells can sort of latch onto in different ways, in different contexts.
*  That's the very short version of the story, which Ila elaborates.
*  We also discuss her background in physics and how that shapes her neuroscience approach.
*  And we touch a little on a recent review she co-authored,
*  which is all about the dynamical systems approach of analyzing the attractor landscapes
*  of low-dimensional structures among populations of neurons in the brain.
*  And in the review, she goes into more detail about all of the brain regions
*  in which that approach continues to be successfully applied.
*  Show notes are at braininspired.co slash podcast slash 132.
*  On the website, you can also find out how to support the show on Patreon.
*  Thank you so much to all my Patreon supporters, as always.
*  And lastly, I've had a few people ask me when the Brain Inspired Neuro AI course will be available again.
*  That is happening very soon. It will be available from April 10th through 13th.
*  Then it won't reopen for a while.
*  So if you want to learn more about that, go to braininspired.co
*  and click the Neuro AI course menu button,
*  where you can also sign up to be notified when it becomes available.
*  And for this round, I'll have a few free videos about some of the open questions
*  and what's missing in AI and in neuroscience.
*  So check that out if it's of interest to you.
*  Thanks for listening and enjoy, Hila.
*  Hila, you have a physics background.
*  Do you consider yourself a physicist first now or a neuroscientist?
*  What do you consider yourself these days?
*  That's a great question. I guess a neurophysicist, if there was such a thing.
*  Oh my gosh. Did you just point that?
*  No, no. I've heard other people use it.
*  I think that what that means is I think of physicists as people who have a certain perspective and a certain outlook,
*  more than a certain set of problems that they work on.
*  So I feel like anything that you try to understand in natural world from a perspective of,
*  you know, reducing things down to the simplest possible models, simpler, in that sense, right?
*  Those kinds of things, those kinds of approaches, I guess, as the physics of the natural world.
*  And so in that sense, I guess the brain, as much as it's this crazy complicated biological object,
*  but it's a physical object in the natural world.
*  So I think that, you know, it's still physics, but I'm very much a neuroscientist.
*  I think all the problems that I'm interested in are very much tied to neuroscience or related to neuroscience in some way.
*  Well, I know that one of the things that you're interested in is memory.
*  And I was just trying to recall, I believe it was about 20 years ago, I went to, I believe, one of my first SFNs.
*  And I cannot recall as you human memory is a little imperfect and mine is extremely imperfect.
*  But the presidential.
*  We study what our pathologies are, right?
*  So, yeah, that's true.
*  Yeah, very true.
*  Anyway, the speaker was a neuroscientist, not a physicist.
*  And he and this is like the big beginning talk at SFN, Scottish fellow.
*  I can't remember his name.
*  But he was saying that we've come to the limits of our abilities as biologists in the neurosciences and neurobiology.
*  And we need to hand it over to the physicists.
*  And this was like, you know, 20 years ago.
*  And I guess since then, there's been more and more physicists coming over.
*  I mean, neuroscience is an agglomeration of many, many different disciplines.
*  So anyone can really come in.
*  Do you find yourself surrounded by more and more physicists these days or physics,
*  physics minded people, as you would put it, I suppose?
*  Yeah, that's interesting.
*  That's a very interesting question.
*  There's definitely been a lot of the computational and theoretical side that a lot of physicists who come into the field.
*  But they've also been a lot of a lot of the technology development, you know, calcium imaging, two four time microscopy, a lot of those tools and techniques that even MRI, right?
*  Those are developed in physics.
*  MRI was developed by Norman Ramsey in physics.
*  And so I think a lot of the tools that we're using that are not on the genetic and sort of molecular biology, biological engineering side, are come from physics.
*  And so I think there's definitely an important role of physicists in biology, I guess, even Seymour Benzer and various others, you know, had like a physics background, physics influence.
*  I don't know if I'd call it like being surrounded by physicists.
*  But as you said, I think it's more like a lot of physics minded people who are thinking about systems level problems.
*  I think that one difference between biology and physics is that physicists are maybe because of the history of studying mechanics are really acutely aware of this problem of emergence.
*  Right. The fact that you can have a lot of entities that are relatively simpler working together in large numbers.
*  And you can suddenly get behaviors out of it that you couldn't predict and you couldn't tell stories about, you know, from a smaller aggregation of those things.
*  Right. So just like many molecules of water can make this thing which is fluid and wet and lower the temperature, it freezes.
*  I guess. Right. Those are things I think about as emergence.
*  But if I but if I tried to freeze you, you would resist because you're autonomous.
*  Right. And you need to survive.
*  So that's not a different flavor of problem.
*  A lot of the traditional physics problems, even with, you know, emergent properties have to do with inanimate objects, essentially.
*  Yeah, no, that's that is true.
*  I guess that is fundamentally the question of agency and this feeling that I am the master of my fate and the master of my ship.
*  And the feeling I'm going to have an opinion about what happens to me.
*  I guess those are definitely things that feel almost beyond physics.
*  And it's I mean, it's fascinating. I don't know.
*  I mean, I guess these are things that philosophers have asked about along, you know, for a long time.
*  Right. Like, is you know, should we think about, you know, the cells and the ego and the soul?
*  All of these things are these different from the material, you know, that makes up our brains?
*  And I don't know. I guess as a physicist, I have to believe and as a scientist, a natural scientist,
*  I have to believe that somewhere there are, you know, physical substrates of all of those feelings and sense of agency.
*  So you don't have free will then?
*  I definitely do not have free will. I do not believe in free will.
*  It's not possible. Just to get that totally clear, since we're settling big philosophical questions.
*  I wonder if we mean the same thing about free will. We're not going to we're not going to go down that road, though.
*  We're not going to go. Yeah, I guess physics tells you that it's either, you know, that either things are stochastic or they're or they're, you know,
*  you can it's all dynamical system and maybe the stochastic stuff, but then you can't predict what's going to happen.
*  So there's certainly randomness in behavior.
*  So you can't predict it, but that doesn't necessarily mean it's free will.
*  On your website, it states that your group seeks to understand high level cognitive function from the bottom up.
*  And that's in bold. So this is a little bit related to physics.
*  I don't know if you would call physics a bottom up because it's, you know, traditionally reductionist, but that's kind of a bottom up approach as well.
*  What does bottom up mean to you from the point of view of how you study cognition?
*  Yeah, again, I think that so so there's many different approaches to studying the brain.
*  I think that's totally complementary. Right.
*  So, you know, on the one hand, people study molecular things like genetic influences in the brain, all that stuff.
*  And that's definitely bottom up. I guess to me, bottom up maybe means something a little bit less bottom up,
*  maybe something at the neural level and how neural activity gives rise to circuit level outputs and circuits, you know, contribute to behavior.
*  So that's what I mean by bottom up. But I think there's a fundamental and then, of course, the people who study top down questions,
*  they start from the top and in machine learning and what's the top behavior?
*  The top would be like you start with a problem and maybe you formulate from an engineering in an engineering sense models of how,
*  you know, what could be a good solution to this question? Right.
*  What would be a good way to accomplish this function and then build models and then maybe then search.
*  Right. For, you know, once you have your model, you search for is there a counterpart to that, you know, to that solution in the brain?
*  And I would say that that's top down. And I think that without all of those, it has to be in all of the above strategy.
*  One thing is I've learned about biology is that, you know, it's never one or the other.
*  And it's, you know, if you ask a question about biology, it's never this or that.
*  It's usually both. And I think that also for spending the brain, it's going to be both.
*  How can it not be? It has to be. Right. It has to be. Right.
*  Because if you're if you're in the forest and looking at molecules, if you don't ask how they then ultimately affect behavior,
*  then I mean, ultimately, why are we doing neuroscience?
*  I think every neuroscientist will agree that ultimately they want to explain behavior.
*  So in a sense, you always have to make that link.
*  And the question is, are you linking it by going from the bottom up or are you linking it going from the top down?
*  And, you know, I think, you know, why should you only do it one way?
*  You should really come at it from both directions and then link wherever you can make those links.
*  It's important to do that. Now, there's one difference.
*  I think it's fundamentally I tell my students that biology is fundamentally different from physics in one way.
*  Right. And this maybe gets to your question about, you know, agency and other things.
*  In physics, we know how to make a hierarchy.
*  So we know that, you know, there's sort of like light scales and there's energy scales.
*  So at the smallest scale and the highest energies, you know, the particles matter, subatomic particles matter.
*  And then but then we can say, well, if we are not concerned with those energy scales or those length scales,
*  then we can replace, you know, we can sort of have a, you know, a phenomenological description,
*  some kind of a, you know, coarse grained description of what's going on at the length scale that we're interested in and then work on that length scale.
*  Basically, we don't have to worry about the smaller length scales.
*  And what we're finding on the larger length scales are not going to go back and feed back into the smaller length scales.
*  Right. Particles, of course, give rise to atoms and then atoms give rise to molecules and the molecules give rise to stuff.
*  And then, you know, stuff gives rise to galaxies and all that stuff.
*  Right. So but there's no way in which as far as we understand physics, that galaxies then go back and like feed back on which particles exist.
*  But I think that fundamentally biology, you know, genes can give rise to, you know, cells and circuits and behavior.
*  But then the behavior ultimately leads to revolution and selection, natural selection feeds back into which genes are then replicated and how they then affect the behavior downstream.
*  So I think that it's just this fundamentally like the highest, the longest scales, the biggest scales feed back into the smallest scales in biology.
*  So I just don't think that in biology we have any principled way to discard scale.
*  We just don't have the luxury to say that at this scale, these smaller details don't matter.
*  And I think that our role in neuroscience is to try to figure out, right?
*  Like, when do the small scales affect scales of behavior?
*  And at what temporal scale? I mean, there's spatial and temporal scales.
*  And temporal scale. Yeah, that's right. That's right.
*  Where do you I'm going to ask you a little bit later, unless we want to talk about it now about dynamical systems and attractor landscapes.
*  Where is that bottom up or top down? Because that's a huge concern field right now, right?
*  Yes, it is. I think of that as bottom up, I guess, because it's, you know, I mean, you've got neurons and we are trying to understand how neurons can give rise to, you know, circuit level, some states and how those states evolve over time.
*  And it's not necessarily with a function in mind, right?
*  So this sort of if you have a circuit and you've got connectivity and you've got feedback, how does that affect the states of the circuit?
*  And at least that's how I think about it. And then I think, OK, given these dynamical sort of behaviors that the circuit can now exhibit, how do we map those properties or behaviors onto tasks or computations?
*  We know the brain performs so that, you know, maybe useful for the brain in generating its output.
*  So I guess I definitely think of it as bottom up.
*  But now that we have theories and models and some insight into the brain actually using these kinds of dynamics and fixed points and attractors, then maybe we can also approach it in the top down, which is we could say, now, given this new problem that the brain is solving or this new question I'm asking about.
*  What the brain does and how does it do this certain cognitive computation or form this representation?
*  Maybe now I can invoke an attractor from a top down perspective and say, well, this is the computation that requires a certain type of dynamics.
*  So maybe let's go look for if there's an attractor in the brain.
*  Do you so, you know, having your theoretical background and your theoretical bent, I'd say, do you do you think about brain processes first or do you think about your toolbox, your theoretical toolbox first and then look for brain processes to apply those tools to?
*  Or do you do you see, oh, hippocampus, what could that be doing?
*  And then what is available to apply to it?
*  Yeah, I'm very much a questions person.
*  I'm not. So I get interested in in questions about, you know, how is the brain doing something?
*  What is it doing? And then I try to find whatever tool I need to solve those solve those problems and answer this question.
*  So I guess, yes.
*  So, you know, and again, I think that, you know, people, people choose problems in so many different ways.
*  There are tools people, as you as you know, like they build, develop some really powerful tools.
*  And then, you know, they look for, you know, what problems can they crack using these powerful tools?
*  And of course, that's been a very powerful approach in our field.
*  And and so I would put them in the tool developer category, people who are primarily developing shiny, new, really amazing technologies that allow us to do the kinds of things that we can do and ask.
*  And then I'm the person asking the questions and looking for what tools might help me solve those.
*  And so I'm kind of a tool scavenger.
*  A tool scavenger.
*  Yeah, I scavenge whatever tools I can find to answer the questions.
*  And, you know, and the hope is the brain's got like a lot of things up its sleeve, right?
*  Like, it forces you to maybe invent some tools when you ask a question.
*  Maybe I mean, one question is, do we have all the math that we need to be able to describe what's going on in the brain?
*  I don't know the answer to that.
*  There's always more math needed.
*  That's that's a problem, right?
*  For people going through, you know, learning neuroscience, why don't you just learn all math?
*  Because that'll all be handy at some point, right?
*  But you have to pick and choose.
*  And I know that you don't think that there's one right way to go through your your study, your path right to where you get.
*  But, you know, math is important, especially these days.
*  Maybe maybe we'll come maybe we'll come back to what the exact right way to go through is, because I know that you don't think that there is an exact right path.
*  Let's start talking about cognitive maps.
*  When did you get interested in the hippocampus?
*  Yeah, the first time I got interested in hippocampus was I was a postdoc at the company Institute of Theoretical Physics.
*  And I was there.
*  My husband is a theoretical physicist.
*  I he had just completed his PhD in physics at Harvard, and I had gotten my PhD in physics at Harvard, working in neuroscience all week at that point.
*  Very cute.
*  And yeah, so then we were looking for, you know, postdoc where we could be in the same place.
*  And the Theoretical Physics Institute had these independent positions.
*  So we both went there.
*  Greg, my husband, had, you know, a bunch of collaborators to work with, mentors.
*  And I had the incredible luck to have a position there and be a free agent and do my own thing, but also meant that I didn't have somebody to work with.
*  And it was it was a difficult time.
*  I was, you know, kind of isolated and, you know, casting around looking for something to do, finishing up some old work and by serendipity.
*  And I'm not a big reader.
*  I'm not a huge reader of the scientific literature.
*  I don't know if that's good or bad.
*  I mean, there are pros and cons to reading, I guess.
*  You know, you know what's going on if you read.
*  But if you read too much, maybe you know, maybe you're too much caught up.
*  And you can't create your own thoughts then.
*  And yeah, yeah, it becomes difficult.
*  I mean, there is like it's interesting.
*  That's an interesting trade off that students often ask about how much should I read anyway, for better or worse.
*  I didn't read too much, but I sporadically read and I happened to be reading some, you know, spending the morning reading papers and catching up.
*  And I saw this paper that appeared in nature by Torek O'Hafte and Edward Moser.
*  It was their first report of grid cells.
*  And I, you know, it was just, it just, and it was just happened to be within the week of their publishing the paper.
*  And I practically fell out of my chair.
*  It was just such elegant, you know, periodic grid like responses of cells as a function of position.
*  This variable that's not periodic.
*  It's local and you've got this periodic grid like response of cells.
*  It was just a physicist's dream, right?
*  Like how on earth is a crystalline response arising from this, you know, really what we think of as a messy biological squishy organ.
*  Yeah, so it was, that was it.
*  I mean, I think I remember that same day I just wrote down three questions about what I read on grid cells.
*  And that became my research agenda in a sense for the next.
*  You just close your eyes, throw a dart, open it up and it's, it's Moser, the nature paper.
*  That's right.
*  Grid cells.
*  Yeah, that's right.
*  I mean, I had some time there to think about what I might want to do and I wasn't sure.
*  And then it was the grid cells.
*  That's right.
*  It was clear.
*  And so then you've been really focused ever since then, it seems, on grid cells, hippocampus and.
*  So the reason, the reason also I was interested in grid cells was, so one was the unique phenomenon of, of their, you know,
*  periodic responses.
*  So appealing to physicists, the physicists in me.
*  But then it was also the fact that, you know, these spatial navigation circuits, I think are like a microcosm of cognition more broadly written.
*  So, you know, cognition involves memory.
*  It involves like, you know, representing, you know, extracting like some, you know, latent information from complicated sensory data about the world.
*  Right.
*  Like, for example, theory of mind is I'm extracting, I'm looking at all your actions and stuff.
*  And I'm extracting like your mental state.
*  Right.
*  So similarly in navigation, you're looking at all of this like scene data and then extracting some abstract variable, like your position in the world.
*  Right.
*  So it's sort of, you know, extracting some, you know, latent variable from, you know, a bunch of latent variables, really, from complex observations, you know, in time, maintaining a memory and then building long term memories, which are like maps mapping the world.
*  So there were all these elements of, you know, my interest even in song learning was sort of like how do we acquire this memory of a tutor song?
*  How do we then build a memory of our own song as we learn to generate it?
*  Right.
*  So memory is always been a big part of my interest.
*  And that's kind of sort of the high level question.
*  I see.
*  Well, then we should talk about Hopfield networks.
*  So Hopfield networks are kind of classically thought of as a good starting point, at least for a model of memory, because they settle into these attractor low energy states.
*  But your work and of course, others as well, has shown that there are some less attractive aspects of Hopfield networks as a model for our own memory for our well, I'll just let you explain why are Hopfield networks not enough to explain the
*  how our own memory works.
*  Yeah, so Hopfield models.
*  So maybe I can very briefly describe the models.
*  Right.
*  So models are, you know, models where you've got neurons modeled as simple units, which, you know, some of their input from all the other neurons in the network with some weight and then apply some threshold and then decide to respond or not respond.
*  Depending on whether it was something that's our overall threshold.
*  And the beauty of Hopfield networks is just the elegance of the theory.
*  They were the first sort of formalization of how a neural circuit can do two types of memory.
*  Really, it's like kind of have a long term memory, which is learning on the way and then also have a short term memory, which is maintenance of activity states that can be stable, you know, maintain.
*  And so the way that the Hopfield network works is that the idea is that if you drive the neurons in the network with a pattern, like some pattern of activation, zeros and ones or minus ones and ones, and then you the rule, the learning rule is really simple.
*  The rule is just strengthen the weights between a pair of neurons if they're coactive and then and then and then make the weights negative between the pair of pair of neurons.
*  If those those neurons are like opposite, right? So one is off and the other is on.
*  These are symmetric weights, though. So it's one weight, but shared between each unit, essentially.
*  That's right. That's right. These networks have symmetric weights. And so if the neurons are anti correlated, then you should have negative weights between them.
*  And if they're correlated, then they should have positive weights.
*  And that's basically the learning rule. I see you've got to have positive weights between the two.
*  And then change the weights based on the correlation of neurons in that activity pattern.
*  And then you can apply the second activity pattern and then change the weight some more and then apply a third pattern and so on.
*  And what's beautiful is then those patterns now become fixed points of the of the dynamics.
*  So it means that now in the future, if you now present the network with one of those patterns as an input, the network will be able to do the same thing.
*  And so that was the beauty. So these networks are called content addressable memories because you you re-enable the network.
*  And then you can apply the same pattern to the network.
*  And so that's the beauty of the network.
*  And then you can apply the same pattern to the network.
*  And then you can apply the same pattern to the network.
*  So these networks are called content addressable memories because you you reinstantiate or recall the memory by just giving a fragment of the memory as the input.
*  So the memory itself or some fragment of the memory is the label for the memory.
*  So you can pull it up with the content.
*  So the content addressable and auto associative, these recurrent connections.
*  So, yeah, I think they're just really they've been beautiful.
*  They've been super important in how we think about how circuits can maintain states like persistent activity for short term memory and stuff like that.
*  And, you know, there have been extensions like so hopfield networks with very sweet sets of memories.
*  Like these are like discrete patterns.
*  And then there are these extensions or generalizations of those where, you know, if you have like the ways to then build a continuous set of fixed points.
*  Which are all stable activity patterns that then can be used to represent the continuous variables.
*  So, say you want to represent a variable like the orientation of a bar and the visual scene or the orientation of your head compass heading direction is moving around.
*  Then, you know, it's very analogous to these discrete hopfield networks.
*  There are ways to construct ways that make the networks be able to store and retain, you know, persistently express the analog variable and all of its values over time.
*  So the hopfield networks have been really powerful, but they're also a little bit maybe at least the discrete hopfield networks seem to have some pathologies.
*  So if you look at if you take off the network and you do what I was saying, which is you give a pattern and then you look at the correlations and then change the weights and keep doing this.
*  Then if you have about N neurons in the network, you can do this with about N patterns.
*  Same number of patterns with the number of neurons in the network.
*  So you can pack in, you know, more and more patterns and just keep incrementing the weights.
*  But then once you go past N patterns, when you add in one more pattern, single more pattern, the whole network, all the previously memorized patterns just go.
*  So the whole network catastrophically sort of failed.
*  So if we were going to analogize that to the human brain, that would mean that we would need lots and lots of neurons to store what we the number of memories that we actually can store.
*  It's not not a feasible number. If we actually used a hopfield network as our memory bank, it wouldn't be feasible that some of us, maybe the host not included, might be able to store many, many memories.
*  Yeah, I mean, I guess the issue. Yeah. So certainly if you look at so what was the area in the brain that was maybe hypothesized as a hopfield network?
*  So the classical area in the brain hypothesized to be a hopfield network was CA3 and hippocampus.
*  So this hippocampal subfield that has recurrent excitation and is known to be involved in memory.
*  So in and of course, this is the famous patient HM, you know, HM had a hippocampal lesion.
*  I'm sure you've covered this in various of your other podcasts.
*  But basically when he had a I don't probably you probably have.
*  Right. So when HM got a damaged hippocampus, he was unable to form new memories.
*  And so the idea was that, you know, hippocampus, CA3 specifically is involved in creating these associated memories.
*  And and maybe the hopfield model is a good model of CA2.
*  So now if you look at like the rodent hippocampus where people have spent lots of time studying hippocampus in rodents,
*  because rodents have for all the various reasons that they're practical to study in the laboratory.
*  Plus they have, you know, I mean, they're they're they're great at spatially moving around, running around, making memories.
*  So it turns out that hippocampus is generally involved in memories, but it's also specifically involved in spatial representation and spatial memory.
*  So that's another connection that means is general memory and spatial representations and spatial memory.
*  So hippocampus is involved in spatial memory and hippocampus CA3 cells.
*  It turns out that when you place these animals, mammals in a spatial environment and let them walk around,
*  then these cells in the hippocampus end up firing at specific locations in the environment.
*  And so then so then this was a discovery by John O'Keefe.
*  And so he called them place cells because, you know, you could kind of look at the firing of these cells in a small room.
*  And then if cell A was firing, then you know, you were at that one location corresponding to the neighborhood of places where that cell A fires.
*  And so it turns out that all the principal cells, the primal cells in hippocampus CA3 were all place cells.
*  They all had like if you put the animal in enough environments, then, you know,
*  every cell that you record principal cell from CA3 look like a principal cell.
*  And so, OK, so now this is interesting because this is like fundamentally a memory area,
*  but it's got this it's very much spatial because every cell expresses spatial tuning.
*  And so now we can ask the question about capacity, which, you know, we were just discussing how that works.
*  And so it turns out that, you know, a good bound on the number of cells in hippocampus and the rodents is like 10 to the 6 physical neurons in hippocampus.
*  And so if you have something like 10 to the 6 cells, some million cells, then then we can ask the question of suppose these cells were tiling the world, right?
*  Like they were tiling the space as you went around.
*  So, you know, these place cells are called place cells because each cell has one field in a sufficiently small space.
*  So it's like a unimodal grandmother cell like representation for place.
*  So it fires for one place, one place only, not other places.
*  So then you can use the computer.
*  So they remap in different locations. Sorry.
*  They do. Yeah. So that's a very interesting complexity, which we can get to next.
*  But basically, like if you just consider that, you know, it's just like the simple code where, you know, one cell represents one location and we just tile all the world with this simple code,
*  then it turns out that you've got like 10 to the 3 neurons per linear dimension, right?
*  Like if you're tiling duty space, you've got a thousand by thousand neurons.
*  And now each neuron has, you know, a field with, right, some resolution with which it's coding the space of like 10 centimeters, then you can do like 10,000 centimeters per linear dimension.
*  And so that works out to not very much total mapping space or map space in the world.
*  And so this clearly suggests that, you know, if we're thinking about the brain as or the hippocampus, seems to be as like a HOPZone network, you're very quickly out of capacity.
*  Certainly, you know, you can represent at most, you know, if there are n neurons to a million neurons, you can represent like a million locations with this resolution, which ends up being not very large at all.
*  So something's got to get right. And so that can't that doesn't seem to work.
*  So what's the solution? And so you mentioned remapping.
*  So, yeah, so it turns out that if you now record neurons in multiple locations, like in multiple different environments, then the same place cell can actually have fields, you know, one field in one environment and then a different field in another environment.
*  And if you look at the cell-cell relationships between place cells, so two place fields may be overlapping in environment one.
*  And then if you bring the animal to environment two, it could be that one of the cells has a field and the other just doesn't have a field.
*  Or it could be that now they have two fields that are far apart.
*  Right. So in other words, even though they were overlapping before, they're no longer overlapping in the second environment.
*  So the cell-cell relationships are, you know, are scrambled.
*  And this happens, you know, in the population at large.
*  So it looks like you just kind of have a random shuffle of all the cells and then you reallocate the cells to fire in different locations, completely unrelated to what they did in the first one.
*  So this suggests like it's really complicated, right?
*  It's not so simple and it's not low dimensional representation of campus.
*  And then there was these beautiful experiments from Albert Lee, who, you know, have the idea to put animals in these very long tracks and record the statistics of place cells in long tracks and see what happens.
*  And I should also mention Andre Sentin did beautiful experiments in two dimensional larger spaces.
*  And he showed that once you go from these small environments to much bigger environments, then suddenly the cells that seem to have the simple place coding, right, like one place per cell,
*  even in the single two dimensional large environment, now they pop, they have multiple fields that popped up, but kind of irregularly spaced.
*  But now there were multiple fields.
*  So now we've gone from like thinking, you know, these place cells that we call place fields because it looked like they were coding for a place are now suddenly doing something much more common tutorial.
*  So in Albert Lee's long track experiments, you found that there are cells that had, you know, over a 40 meter track had something like, you know, 20 fields.
*  And the fields look like they were kind of randomly organized.
*  So now we're talking about some kind of common tutorial coding where each place cell has some random, you know, constellation of fields.
*  Are those the studies that also showed, you know, one place cell might have a lot of fields, whereas another place cell might have very few.
*  And the distribution among those seems random. Is that?
*  That's right. Exactly. So that's right. It was the same study.
*  So he showed that exactly. So it seems like they were not able to discern a structure in the firing of the distribution of fields per cell.
*  But the one structure, the one piece of structure that was that was preserved across environments and, you know, from the first half of this long track and the second half of long track was the average, you know, tendency of a place cell to put down a field.
*  So some cells had a higher average tendency to put down fields and other cells had a lower average tendency to put down fields.
*  And that itself was like a long tail distribution. And so, you know, there really were, you know, many, many cells that had, you know, almost no fields.
*  And then, you know, some cells that had very many fields and then, you know, this distribution.
*  So, yeah, exactly. So for all the world, place cells are now looking like these things that are just doing kind of very random combinatorial coding into the building maps.
*  And so maybe, you know, so the question is, is the word place cell a misnomer for what these cells are doing?
*  Every every created name is a misnomer, it turns out. Right. But then we're stuck with them.
*  And they are evocative, you know, so they have a role. But yeah, exactly.
*  And but, you know, and I guess, you know, you know, I should, of course, point to Howard Eichenbaum and, you know, others who argued that, of course, because we know that humans have a campus is essential for just general memory and general learning and not just the spatial domain.
*  There's no sense in which they can only be firing as a function of space. So it was just that, you know, if you were studying them through the lens of a spatial task of animals physically moving around in the world, doing very little else other than just randomly running around in the world.
*  And so by definition, almost, we were just studying their spatial correlates without regard to what else they might be encoding. And now when people record place cells on more complex tasks that involve contingencies or some like operant type behaviors where the animal has to make a decision and make a choice and get a reward.
*  Now they find that place cells really there's almost nothing that these place cells aren't sensitive to. So it's almost any task relevant variable or even task irrelevant variable. There are place cells that have, you know, coding or tuning to those variables as well.
*  So if you were if you were going to be in charge of renaming the place cell, what first of all, let me just guess and then I'll ask you what you would rename it. Would you rename it the internal scaffolding cell?
*  Ah, good question. So I would name I would give that name to grid cells as the internal scaffolding cells and I would call place cells the scaffold associated cells.
*  Okay, okay.
*  Or they would be like part of the scaffold. Yeah, I'd call them part of the scaffold network. That's right. I call them scaffold network cells.
*  I'll let you think about this longer. We can come back to this scaffold networks. Okay. All right.
*  Scaffold networks. That's it.
*  Actually, a colleague of mine who works in engineering had a very nice description actually was talking about something else, but it really applies here. I think the scaffold network is like a clothesline, you know, and then it's got pins, right?
*  The clips, you know, and a clothesline where you lay the clothes back to dry. And then everything that we experience in the world is clipped onto those clips.
*  Okay, and that's how I think about the scaffold network. So it's the clothing.
*  I thought you were so did you come to think about are we skipping? Are we skipping ahead too far to talk about the role of grid cells?
*  You know, do we need to describe more about place cells because the way you've described it now. Now it's making me think that you have come at this from trying to solve the mystery of place cells.
*  And then you originally got interested in grid cells. So how did you come into this? And maybe we can just get to the story of what you've discovered and why you would rename it the scaffold networks.
*  Yeah, absolutely. You know, so we first started by working on grid cells. And I feel like even the grid cells have, you know, this complex looking geometry of their response.
*  And it looks complex, because there are these multiple fields, and there are you know, on the lattice, and on the lattice. I would say that that immense structure almost in the end lends real simplicity to grid cells.
*  And that's what it seems to be. It seems to be the case that the structure lends simplicity to our ability to understand them.
*  And so then we felt like we have made enough progress, at least enough to satisfy my level of curiosity that I felt comfortable then asking the really hard question of what are place cells doing?
*  Because they seem very, very, very complex because of this remapping phenomenon that you mentioned. And so, okay, let me make one or two more points about place cells.
*  So where are we? So where we are is we're saying that, you know, the thought was that if there's an instance of hopfield networks in the brain, C8-3 and hippocampus would be a really good candidate for hopfield networks.
*  And now we said, well, look, spatial learning is a form of learning. It's a form of memory. And so we can then compute the capacity of these networks by looking at their spatial responses.
*  And we're saying, we're really falling short, right? And hopfield networks have this property where, of course, once you go past their capacity, it's all over.
*  Like there are these palimpsest, they're like this blank slate. You start with a blank slate and you start drawing on the blank slate. And by the time you cover the blank slate once over, and if you want to start writing, have you seen those old letters from the 1800s where paper was really expensive?
*  And so they used to write their letters horizontally across. And then when they filled the page, they would rotate it perpendicular and then they'd write across.
*  Oh, wow, that's cool.
*  Yeah, yeah, yeah. You should see those. It was a thing. It was a widespread thing to do. But anyway, so hippocampus is like you start with this blank slate, you write on it, and then once it's full, it's full. In fact, it's full and you cannot go back and retrieve.
*  Once you've filled it, it basically magically erases.
*  Because there are no minima at that point, right?
*  That's right. That's right. Or it's like a proliferation of minima, if you will.
*  Too many minima.
*  Too many minima. It just becomes a spin glass. There are just exponentially many minima and you can't control any of them. That's what happens. So it's basically like the whole board goes white instead of going blank and black for you to write again.
*  So yeah, that's great.
*  Okay, so totally bizarre and it seems like we just don't have enough cells. But at the same time, you're telling me, well, place cells are remapping. So, you know, I mean, they're somehow like forming one map and then they're forming a different map.
*  But that can't be right with Hopfield networks. Because again, like, you know, I mean, having that whole set of maps is like a whole bunch of memories too. So there was a nice work by McNaughton and Skagg showing how you could, you know, fit like multiple maps into like the same kind of network.
*  But again, when they compute the capacity of those multiple maps, that's even worse. Like it's a real problem. So if you wanted to fit, you know, a number of maps, the scaling is very bad again. And so, you know, something's going on, right?
*  So, you know, that was kind of a puzzle with hippocampal cells and kind of I understood that this is a problem and Hopfield networks aren't quite doing it. But I didn't know what to make of it. And then we backed off and then we were thinking about grid cells, continue to think about grid cells. So it turns out that grid cells have beautiful properties. And should I get into grid cells?
*  Well, in their simplicity, they're beautiful? Or is it more complicated than?
*  Both. It turns out that in their mechanisms, they're very simple. But it turns out that in terms of their abilities, there's a lot of richness. And the richness has some beautiful mathematics that's kind of like very elegant from a mathematical perspective, but also from the brain's perspective, it has some real use. And then the grid cells set out the scaffold that maybe I'll say is like an alternative to Hopfield model. So what is a grid cell? So these, yeah.
*  Go ahead. No, refresh the listener's memory because, you know, things need to be repeated. We've actually talked about cognitive maps quite a bit. But I think it's worth repeating, like, because you did such a good job with describing place cells. Let's talk about grid cells then and then we can get into your model and the explanation.
*  Yeah. So grid cells are these cells that like place cells, they like to fire at specific locations, you know, people are moving around a room, if mice are moving around a room, rats are moving around a room, even bats, if they're crawling around in a room, it turns out that in their brain, not in the hippocampus, but in the entorhinal cortex, a part of cortex, it's a special older part of cortex, it's not the neocortex, which, you know, is all of the visual processing, hierarchical, and the
*  it's actually, you know, part, it's the same kind of cortex called allocortex. It's related to the piriform cortex, which is a factory cortex. And then there's entorhinal cortex. So entorhinal cortex is really privileged because it is the gateway of all the cortical information that goes into the hippocampus. So all of it gets routed through the entorhinal cortex. So it is a sort of special path into this memory system. So what does entorhinal cortex do? Well, I mean, it does a lot of things, but there's a lot of things that we can do to get into the hippocampus. So what is entorhinal cortex? So what is entorhinal cortex? So what is entorhinal cortex? So what is entorhinal cortex? So what is entorhinal cortex? So what is entorhinal cortex? So what is entorhinal cortex? So what is entorhinal cortex? So what is ent
*  r鑑se is one subset of cells that the moesers discovered in the mid 2000s. And they have this remarkable property where when, as I said, if we're walking around, then they fire at these specific locations, but not just individual specific, single
*  places in a room like placed cells do, but they fire at multiple different locations. And amazingly, those locations are located on the vertices of a regular triangular lattice, that
*  And if the room size is twice as big, then you just get the same period, like the same
*  lattice, but it just has many more cycles, right?
*  So it just kind of, it towns that space.
*  Different spatial scale.
*  Yeah.
*  By the way, I just want to interrupt because since it's an audio-only podcast, the listeners
*  can't see how giddy you look talking about grid cells.
*  So big smile on Ila's face while she talks about, and play cells.
*  So I don't want to leave them out, but it's just a pleasure to see.
*  Sorry to interrupt.
*  Yeah, they're amazing.
*  I mean, it's just, yeah, I feel like a kid whenever I think about the existence of these
*  cells.
*  So yeah, so if you look at a cell, it has this periodic firing, even though the ground
*  or there's no cues in the environment that are indicating that this is some period that
*  have a periodic arrangement of landmarks.
*  There's nothing.
*  It's just an internally generated periodic representation of the world.
*  And what I just want to point out how remarkable it is because let me just describe the experiments
*  that people do when they record these grid cells.
*  So they take a rat and they put it in this drum, this space that has just a flat bottom,
*  maybe a meter across in diameter.
*  It's a circular enclosure with some walls and the walls aren't terribly high.
*  So the animal can look over the walls and see the bigger room and see that there's some
*  orienting cues, maybe there's a door and a window in the room.
*  And so that gives them some general orientation.
*  But within the space locally, there aren't really any space.
*  There's no spatial cues.
*  It's just a featureless circular environment.
*  And the animals are just kind of running around and usually chasing things like chocolate
*  chips or something with cookie crumbles or Cheerios that are scattered in the environment.
*  So they're just kind of running around freely foraging for the food.
*  And then they're doing things like they pause, they might stop, they might scratch themselves,
*  they might, you know, scrap, you know, they might like kind of put their paws up along
*  the side of the wall and look up.
*  And then they'll run around at different speeds in a different direction.
*  But every time the animal comes to one of those vertices that doesn't actually exist
*  in the real world, but it arrives at the neighborhood of that vertex, that cell that
*  fired previously at that vertex fires again at that vertex, even though the animal may
*  this time be running in the opposite direction.
*  It may be running at a different speed.
*  And if it's running in the opposite direction, it has a completely different visual input
*  than it did when it was running the other way.
*  So somehow it has, you know, this internal, this cell has access to a good estimate of
*  where the animal is with enough detail that it, you know, with fidelity lays down spikes
*  repeatedly over 20 minutes, 30 minutes of random running around these things, you know,
*  at that same vertex and at each vertex of the triangle.
*  I actually don't know the answer to this and I'm sure that you do.
*  Does this happen?
*  Does the map, do the spikes happen immediately or is it a gradual couple minute process?
*  I feel very ignorant to not know the answer to this question.
*  Yeah, no, that is an excellent question.
*  And I think the answer is that those spikes that, you know, fall on the vertices of this
*  lattice, you know, appear on the very first, you know, trajectory, like the first part
*  of the trajectory.
*  As soon as they start running.
*  Okay.
*  Yeah.
*  I mean, there's some scatter, right?
*  So they're not, you know, I mean, the question is what is the precision of these fields?
*  And so, you know, the fields have a, you know, a size, the blobs, you know, the neighborhood
*  in which they fire is like probably about 20-70 years wide.
*  And so, you know, plus or minus, they have a good estimate of their position plus or
*  minus.
*  But it's like pretty damn quick.
*  It's like set right when they start.
*  It's pretty much set when they start.
*  Yeah.
*  That's right.
*  That's right.
*  It kind of exists right from the get go.
*  And yeah, exactly.
*  And you can put them in a novel environment and there they go.
*  Like off they run and they're, you know, firing spikes on these like triangle lattice
*  patterns in a brand new model.
*  So it's pretty incredible.
*  So then the question is, okay, so, okay, so that's one cell.
*  Just one cell has this triangle lattice response.
*  And then you can ask, well, what are, you know, are there other cells like that?
*  And it turns out, you know, if you look nearby to that cell, there are other cells that have
*  the same lattice response, the same periodicity, the same angle or orientation, right, of the
*  lattice.
*  But they only are different by, you know, shifts.
*  Like you can just just rigidly take that pattern and just translate it.
*  And that's what maybe the response would be.
*  And so, so it's all translations of this one.
*  So if you had, if you could, you know, record all of those cells with that same period,
*  the different shifts, you would know exactly where the animal was in the room up to like the
*  periodicity of the animal, because it's completely degenerate.
*  Because once you've moved by one period, once the animal has moved by one period, it's back to,
*  you know, the same firing field that, you know, that cell was on and all the cells have shifted by
*  that one period.
*  So they're all back to the original.
*  So it's basically like, it's like, it's literally like a sideway, right?
*  It's this periodic thing that is, you know, basically not giving you information about the
*  animal's position other than as like this phase with this.
*  Okay.
*  So then, I mean, then there are mechanistic questions that, you know, arose like why, how on
*  earth, like how do you set up a circuit that does that?
*  And then there's like the questions of like, why, right?
*  It's like kind of like, okay, so then it turns out that if you go further in the entorhinal
*  cortex and not look at the immediate neighboring cells, but there's kind of this long, so hippocampus
*  is like a banana and the entorhinal cortex has this long axis that kind of aligns with that banana.
*  So if you go along a long axis, then you'll find other cells that are also good cells that have a
*  different period.
*  So these are different spatial scales along the, is it a dorsal lateral?
*  It doesn't matter, along the banana of the hippocampus.
*  Along this long axis, yeah, this lengthwise along the banana.
*  Yeah, you go from one end to the other and they come in clusters.
*  So these discrete clusters of cells that have, you know, a few discrete distinct spacings or scales
*  or periodicities relative to each other.
*  So it's kind of like, like from a coding perspective, it's like saying, you know, I walk into a room
*  and I want to know the time and, you know, instead of a single wall clock on the wall, that's like a
*  24, like a 12 hour wall clock.
*  Instead, what I've got is, oh, by the way, I should mention, what are those periods, right?
*  Like, so what is that scale?
*  So it turns out that the smallest scale is about 30 centimeters and the biggest scale is about a
*  meter and a half, maybe at most two meters.
*  This is in rodents or across all?
*  This is in rodents.
*  Okay.
*  Rodents, yeah.
*  But you can see that the smallest to largest, like it's only a factor of two or three, right?
*  It's not, and you know, rodents are prodigious explorers.
*  Over one day, they'll go a kilometer or two looking for food, like in each of the interventions.
*  So they cover a lot of ground.
*  So this is nothing close, right?
*  To like, this is not close enough to even the largest scale at two meters is nowhere close enough to
*  this ambiguity position in the world.
*  So it's like coming into this room and seeing a wall full of clocks and each clock now has like, you
*  know, one clock has like 11 minute period.
*  Another clock has like a 12 minute period, right?
*  It's kind of just minutes and it goes around every 12 minutes and the next one goes around maybe
*  every 17 minutes and so on.
*  I mean, we kind of have that because of the second hand, minute hand and hour hand.
*  However, you're talking about a lot more hands.
*  A lot more hands, exactly.
*  And moreover, you know, seconds, minutes and hours hands are like factors of 10 or more from, you know,
*  it's like a hierarchy, right?
*  So each one is kind of like a finer resolution of the other.
*  Here, it's kind of like having a bunch of clocks that have very similar, right?
*  It's like instead of like one second and 60 seconds and then 360 seconds or 3600 seconds, I'm sorry,
*  you instead have clocks that are like, you know, I don't know, you know, like 10 minutes, 11 minutes,
*  12 minutes, right?
*  Like they're almost all the same, but they're distinct.
*  And the question is what?
*  And how?
*  Like can you decode, you know, a time in the 12 hour day with those clocks?
*  And why on earth would you represent time in that way, right?
*  Right. So backing up to play cells, is it, I don't know if traditional is the right word,
*  but the recently traditional story is that the play cells themselves are encoding the grid cells,
*  the patterns in the grid cells.
*  And correct me if I'm wrong.
*  And what your recent modeling work and theoretical work has shown is that you guys make the strong case
*  that it's in fact the grid cells that's encoding the play cells.
*  So maybe I don't know if this is the right time to bring that home.
*  Yeah, absolutely.
*  Yeah, that's probably a reasonable time.
*  And we can talk about it more when we talk about like the dynamics of these grid cells.
*  But yeah, so there's this sort of these.
*  So ultimately the anatomy of this area, so I mentioned that entorhinal cortex where the grid cells reside,
*  is this gateway into hippocampus, right?
*  So all of the external sensory evidence, all of that sense data is coming into the hippocampus via the entorhinal cortex.
*  But it doesn't just, if anatomically the flow were just entorhinal cortex to hippocampus,
*  then obviously grid cells would drive play cells and there would be no debate.
*  But it turns out that this is a very famous loop pathway.
*  So entorhinal cortex projects into hippocampus and then it forms this thing called the trisynaptic loop
*  where hippocampus outputs also through the interus.
*  So in fact, hippocampus outputs to the deep layers of entorhinal cortex
*  and then project back to the superficial layers of entorhinal cortex with these grid cells are found.
*  So the whole thing is one big loop.
*  And so the question becomes, you know, in this big loop, who's giving rise to whom?
*  And, you know, or is there even such a thing that can be even answered?
*  That's a big emerging thing.
*  And so as you pointed out, there's a couple of models.
*  There's one model, which is that, you know, you can think of grid cells as arising from play cells
*  as like a pattern forming process on top, you know, on top of play cells.
*  And then there's the opposite school of thought, which is that, you know, you can think about play cells as generated from
*  if you combine grid cells of multiple different scales, right,
*  then you can set up interference patterns where, you know, if you align grids of different periods
*  so that, you know, they all have a peak, say, at one, I'd say zero phase, right.
*  And but then they all have different, you know, they're all have different peaks at different frequencies.
*  Then there's interference, right, at all, you know, because they have different frequencies.
*  These periodic waves are interfering destructively everywhere,
*  but only constructively interfering where you line them up at zero.
*  And so then, you know, if you sum all of those up, you would get one big peak at zero and nothing everywhere else.
*  So this was like this is the general idea behind how you can get these, you know, you can construct these periodic representations
*  and then sum them up at different scales and get play cells.
*  So that's like the opposite direction of models, right.
*  And the question is, yeah, which one actually obtains.
*  And also, you should really be asking yourself at this point, is that really what the brain is doing?
*  Is it in the business of like representing stuff and then re-representing stuff?
*  I would say no, right.
*  Like, clearly, you know, there has to be processing, right.
*  It's not just the brain wouldn't just construct a representation and then just re-represent the information.
*  It doesn't make any sense.
*  So, right.
*  So we have to think about, like, you know, what is the relative role of those two of those two areas?
*  OK, so that's a question.
*  And I think that, you know, if you think about OK, so I guess I can I can sort of give you my view on this.
*  And my view on this is I think that grid cells are the primitives in this in this dynamics.
*  They're the primitives of this process.
*  And there's many reasons to think so from from the dynamical responses of grid cells, from the fact that they're present in sleep
*  and they maintain their structure in sleep.
*  And this was shown from studies by my group and other groups in 2013 and onwards and then most recently
*  sort of directly demonstrated from multi-unit recordings in the Mosel lab and showing directly that the structure of those states
*  of the grid cell, you know, a single group of grid cells of the same period, you know, lies in this very low dimensional surface
*  in the shape. And that's the prediction of these models for the dynamical models of the grid cells.
*  And it looks like the grid cells have those responses, not just when the animals awake and doing its periodic spatial representation
*  business, but even when it's moving and even when it's running in one D different distorted shapes.
*  Nevertheless, the grid cells stay the same.
*  But the place cells are, you know, as we observed already across different environments, they map in sleeping.
*  They don't maintain the cell-cell relationships.
*  So that suggests that if there's a group of cells that are maintaining a highly structured relationship across all of these conditions,
*  right, they're just invariant and just present all the time with immutable responses and relationships.
*  But this other area has responses that change dramatically from one environment to the next.
*  And across waking and sleep, like different behavioral states, it suggests that the primitive here is the grid cells.
*  And I'll leave it to the listener to look at all of the details in multiple papers, but I have one in particular in mind.
*  But, you know, you have a model which shows and accounts for how grid cells essentially put the generate the scaffolding for the place cells,
*  which are the what you call the scaffold network.
*  And then you have external data coming in through the cortex, also coming in to the place cells in the hippocampus.
*  And so it's kind of like a three modular network, neural network that accounts for these things.
*  So it's a really nice mapping of the different kinds of models onto the different brain areas that I described that.
*  You described it beautifully. That's right.
*  And the idea here is that like so why do you need a scaffold?
*  I mean, I guess maybe is a relevant question, right?
*  Because you need your clothes to dry.
*  You do need your clothes to dry. You need that clothesline.
*  It's just that the grid cells generate a very long clothesline.
*  So this gets back to this. It's like it gets back to this question of the hopfield networks and their capacity.
*  So if the place cells had to do like this, you know, if they had to do their recurrent weights, according to this hopfield prescription, maintain, you know, patterns in memory.
*  Then we talked about how few patterns they can store in memory, how you run out quickly of capacity and how when you run out of capacity, you have this memory cliff where the whole board goes white.
*  Right. That was the problem with the hopfield networks.
*  And so we were still left with this puzzle of how do place cells have all of these distinct maps for all of these open environments?
*  If the hopfield model doesn't explain it, how do you explain it?
*  So I tried to say that each of these grid cell networks, like each set of cells that have the same period, is itself like you could think about that as a hopfield network, but like in that continuous sense, where it's representing this position, right, as the animal moves around space.
*  So in a continuous sense, it's kind of representing a set of discrete, a set of continuous fixed points, right?
*  So stable states that can, you know, if the animal stops moving at a point, the grid cells continue to fire that correspond to that position.
*  So, right. So if the animal even if it closes its eyes or you turn off the lights, those cells will just continue to fire, you know, in other words, representing a memory of where the animal estimated its position.
*  Right. So, so each of the grid networks is like its own hopfield network.
*  That's how we can think about it. But then there's all these discrete modules of different scales.
*  Right. And so each of them, like if each of them has N neurons, and each of them has N states, but each of them can, you know, be in some state independently of each of the other modules, so it's uncoupled modules.
*  So now you're talking about something like if there are, you know, M modules, now you've got like, you know, N times N times N times N, you know, distinct states.
*  High capacity.
*  It's high capacity. Exactly. You've got a capacity that's exponential in M. So you've got N to the M state. And so now it's exponential. These are all like stable states, right?
*  I mean, each of the in each module, the states are stable. And then and then and then okay, so that's that's that's the idea.
*  So you've got like a very large library, so a large clothesline, if you will.
*  And then now I'm thinking that that long clothesline now what's going on is you're kind of providing this long clothesline and then you kind of got as you move through the world, you know, space, then you're kind of moving along the clothesline.
*  And you're also getting sensory data. And and so you've kind of got these like states in the clothesline and then you've got the sensory data coming in.
*  And then hippocampus is like the clip hippocampus clips those, you know, the clothesline to the sensory data and clips it together in place.
*  And so it's kind of the states are stabilized by these, you know, large library of stable grid cell state.
*  And then the last piece, which is a bit technical, but I guess it's just to say that now if you close the loop and you have grid cells go back to place cells, then we can show that as a whole circuit together, those are all now fixed points like stable fixed points of the dynamics.
*  And so the whole thing can be in, you know, a memory system, it can do like pattern completion, and so on. So that's the idea of a scaffold network.
*  Nice. So I want to I know that our time is coming to a near near coming to a close here, but I was actually going to ask you about your abuse.
*  Aki's inside out approach to the brain. I'm not sure if you're familiar with that. When I was asking you about your bottom up approach and how those two relate.
*  But I'm going to bring him up in a different context here because, you know, he has this idea that basically we have the, you know, pre existing networks that are just waiting to get filled with this story.
*  Do you agree with that viewpoint?
*  Yes, it completely resonates with that viewpoint. And again, this is a beautiful example of, you know, like we said, biologists have these amazingly sophisticated internal models of, you know, the mental word models of how the brain works.
*  And I think that's just such an example. Like I think Yuri just he's continuously he's a fountain of such ideas. And I think that, you know, from the formal side, I think what we're seeing is very much in line that, you know, his his idea of like internal states that are, you know, for example, these are just the grid states.
*  So they're literally internal states that exist independent, like endogenously generated states, independent of what the outside world is saying. And they're just there to be associated with or clipped onto, you know, like inputs from the external world.
*  When it's relevant and needed. Yeah.
*  Exactly. Exactly.
*  Okay, so that's wonderful. Another thing so I actually didn't realize that you had written this review that's I guess resubmitted to nature reviews neuroscience, all about the power of and recent trend of using the dynamical systems approach including including a tractor and landscapes like you know, we were just talking about with hot field networks and such.
*  It's a really nice review, by the way, and I hope it gets accepted soon. But it's available I think on is it bio archive or archive. It's available in my archive. So are we going to talk about every brain process as an attractor landscape in the next in the coming years, it feels that way in my biased myopic vision.
*  The latest example I've heard about that is, have you heard David Anderson talk about fly copulation behavior and the lead up to fly copulation is the male fly enters into some kind of a cracker state, along with it evolves, just before copulation.
*  That's just a punchline waiting to happen.
*  Exactly.
*  It really is.
*  So you're telling me the attraction happens right before.
*  Yeah, sorry, I had to.
*  I'm sure the joke's already been made.
*  I'm sure the joke's already been made.
*  But I mean, is that the way you view it, that everything is just going to be so a lot like I've had David Barack, for example on the show well many people, john crack our you know they wrote a review on this and I guess there are multiple of these but john, in particular,
*  like these attractor landscapes these manifolds are real entities that are a nice in between stage between describing something at the mechanistic single neuron or population level, and the behavior or the cognition that we're interested in.
*  I mean, do you agree with that view and or how do you how would you describe your view of that.
*  I do, I do agree with that view.
*  I think that's exactly right. It's like an abstraction, where we can link from both ends right and you had asked earlier like top down bottom up, and it seems like a tractor dynamics or something right in the middle, where we know how to connect on both ends.
*  And I think that to the question of you know, is everything going to be understood in terms of attractors.
*  Oh, not clear. I think the jury's out. I think that the place where attractors have to be involved is whenever you want persistent activity.
*  It's got to be attractors on the level of either single neurons or circuits, right, it you know to persist, you've got to have any by default almost, it's almost logical to say so but you know you need a state that is stately maintained, and the way we understand the emergence of stability in the circuit is the fixed point that is, you know, fixed point dynamics and that is an attractor.
*  So I think that every time we're looking at persistent activity, you're going to see attractors. It might also be that even when we're talking about like weight changes, right.
*  So, you know, the question about LTP, the fundamental question of how learning and memory is localized in synapse, you know, change and remodeling.
*  Even for a synapse to persist requires, you know, some kind of, you know, stabilization of its state because how does the synapse know what size it should maintain over time as proteins are degraded and so on.
*  So, you know, so I think even there, there may be some, you know, attractor dynamics ultimately on the level of, so anytime you're talking about persistence over time, I think there has to be some, you know, attractor dynamics.
*  Let me ask you about, so the way that these landscapes are calculated these days is using spiking rates from neurons.
*  And you actually talk about in the paper how this is one scale, one temporal and spatial scale to view this, but how it may be it's enough, but you know that there are other processes, neuromodulator processes, etc. glia, etc.
*  And I've been in conversations recently with a few people who are excited about astrocytes and cognition and they do these calcium signaling.
*  But then it's, you know, so then you wonder about are there attractor landscapes among the glia and how would you cross levels with neural activity and glial activity and slow neuromodulators?
*  Like, is there a way to form dynamical landscapes across levels like that or do you think that we're going to be always contained in one, you know, one level?
*  I think there's got to be interaction between levels. I think that most of our mathematical models, you know, typically have, you know, they usually assume that this one biophysical time scale and then to extend it, you get these circuits that have positive feedback and then you have to have a
*  And prolong, you know, and cancel out decay and prolong the state by, you know, by recurrence and reverberation and headsworn.
*  I think that, but I don't see, you know, why they may not, you know, I mean, seems like there could be major benefits of having some interaction with, you know, different scales in time.
*  One of the problems with the attractor networks is that they're, you know, they tend not to be very fast responding, right? If you're creating this long scale, time scale, they're also sluggish.
*  Like you have to give a huge input and you have to like, you know, give, you know, yeah, you have to hit them hard to change their state.
*  And, you know, I think it's a bit of an open question how much like if you have multiple time scales and multiple processes, whether you could, you know, have a bit of both like some rapid responses as well as, you know, slows and stability.
*  And so, yeah, I think there's so much to do on the mathematical side. We haven't touched on the questions of like, you know, how, I mean, I think you made the point that you can think about attractors as maybe this middle level of description thinking about function cognition.
*  And so I think I just want to mention for sure that there's this beautiful line of work from, you know, that Buffalo, David Tank, Tim Barron's colleagues showing that some of these same representations for, you know, for space.
*  So we talked about how the hippocampus is involved in like general memory, but then it's also involved in spatial memory.
*  And then now we're going back the other way, which is that they're showing that the same spatial circuits actually modulate the firing in the same ways that they do with animals navigating real space.
*  But now when the animals are actually navigating in some conceptual task space.
*  Yeah, I had Tim on and we talked about stretching birds and.
*  Oh, stretching birds. Fantastic. Yeah, that's it.
*  That was his earlier one. Yeah.
*  That's right. So, so that's another one.
*  Are the here's what I want to ask you is, do you think that the that this approach the dynamical systems approach will give us insights into our subject subjective experience?
*  And I want to pair that with the question, whether the manifolds are always going to be low dimensional enough or, you know, enough in air quotes for us to, you know, understand them right or will it be will there will there be cognitive processes that are too high dimensional?
*  For the dynamical systems approach to be useful, if that makes sense.
*  Yeah, no, I mean, brilliant. Yeah.
*  Well, on the first one, I think that, yes, I think we can, you know, even understand like pretty high level cognitive processing in terms of some of these, you know, I cracked the landscapes and attracted dynamics, I think already, you know, things like attention, you know, we can think about attention as being a winner.
*  Kick all dynamics between, you know, multiple different potential targets of our attention and focus on one.
*  You know, there's like, you know, a lot of perceptual effects like conscious perception of binocular rivalry, where you have to stimuli and your retinas in both of them, but you only consciously able to see one.
*  Right. So I think that, you know, even low level by stability can manifest very quickly at the high, you know, consciousness, you know, kind of the core perceptual report levels.
*  So I definitely think so.
*  And I think those examples are all around us. Like, I think that, I think that, right. I think that.
*  Or maybe like, you know, I guess the essay, the reasonable effectiveness of mathematics says that, you know, we've got only one language to describe the natural world, which is mathematics.
*  So maybe shouldn't be a surprise that, you know, we translate everything in terms of mathematics that we know.
*  So I don't know, but I feel like philosophically, yes, the dynamical existence attractor perspective really does fit in a lot of pretty high level conscious percepts.
*  I don't know the answer to the second one, whether the manifolds that exist in our brain are sufficiently low dimensional for us to understand them.
*  I mean, I think that like, mathematically, we don't have ways to understand higher dimensional manifolds.
*  Like, once again, it's a six, seven dimension, eight dimensions.
*  You know, we can do things like topological data analysis.
*  We can characterize things like how many cycles and how many rings and how many loops and how many, you know, voids of higher dimension are in this manifold.
*  But putting it all together to construct the whole manifold, it's more like it's like we would be doing like the piecewise characterization, like of an elephant.
*  We've got it's got four legs and it's got a tail and it's got a head.
*  But how do we put all of those together?
*  Do we put them together in the right order to understand that it's an elephant or is it more like a Picasso, you know, cubist perspective on an elephant, which we just joined together?
*  And what are our prospects if the brain could take higher dimensional manifolds of the fundamental units of representation?
*  New math.
*  Open question. New math. Yeah, always new math.
*  Always new math.
*  Thanks. Thanks. Thanks for doing this.
*  I know that you have to go, but we didn't even talk about, you know, how you guys mentioned that this same approach is going to is already being used more and more in AI to understand neural networks, artificial neural networks, et cetera.
*  So we'll have to leave that for next time and the host of other questions I wanted to ask you.
*  But I very much appreciate your time.
*  Thanks.
*  It was a pleasure.
*  Thank you for having me on.
*  Brain Inspired is a production of me and you.
*  I don't do advertisements.
*  You can support the show through Patreon for a trifling amount and get access to the full versions of all the episodes.
*  Plus bonus episodes that focus more on the cultural side but still have science.
*  Go to braininspired.co and find the red Patreon button there.
*  To get in touch with me, email Paul at braininspired.co.
*  The music you hear is by The New Year.
*  Find them at thenewyear.net.
*  Thank you for your support.
*  See you next time.
*  Let me into the snow.
*  The covers of the paths.
*  They take me where I go.
*  You
