---
Date Generated: April 21, 2024
Transcription Model: whisper medium 20231117
Length: 2496s
Video Keywords: ['Science & Medicine', 'Technology', 'episodes']
Video Views: 2914
Video Rating: None
---

# BI 014 Konrad Kording: Regulators, Mount Up!
**Brain Inspired:** [October 18, 2018](https://www.youtube.com/watch?v=qS3tlaUVVBg)
*  I was just thinking, what am I going to name this podcast?
*  Watch Out?
*  Kurtis going to F you up?
*  No, I think if you're faking your data, they will find you.
*  It might not be me who's finding you.
*  I don't think I believe in the big breakthrough.
*  And in a way that's fine.
*  The brain is the ultimate frontier.
*  There could be nothing bigger for mankind than understand how we think, how our brains
*  work.
*  This is Brain Inspired.
*  Welcome.
*  This is Paul Middlebrooks.
*  Today I talk with Conrad Kurding, whom, as you'll hear, has been lingering in the background
*  of the show for many episodes now.
*  Conrad is a professor at the University of Pennsylvania, and he was hired into a position
*  specifically created for someone who brings together multiple disciplines and multiple
*  research groups from those disciplines.
*  He's made a career out of massive collaboration, and it's worked wonders for him and for science.
*  I will leave it up to you to explore his website to see for yourself the breadth and the depth
*  of his work.
*  And that will be linked in the show notes.
*  It's at braininspired.co.uk.
*  I think you might find this episode to be one of the more fun episodes for a few reasons.
*  One, it's short.
*  Conrad had a tight schedule, so you're welcome to many of you who prefer a shorter episode.
*  Number two, Conrad likes to have fun, and that comes across readily.
*  And three, we discuss his recent paper with Daniel Acuna about work that they did to automatically
*  detect fraudulent images in scientific papers.
*  So, if you're shaking in your shoes right now, that is not a good sign for you, my friend.
*  They will find you.
*  I also get Conrad's passionate take on consciousness and more general questions.
*  Okay, if you have a question for me or that you would like me to ask a guest, send an
*  email to paul at braininspired.co.
*  Send me the question either as written text or preferably as an audio file of you speaking.
*  As always, you can connect with me on Twitter, I am at pgmid.
*  And here is Conrad Kurding.
*  Conrad Kurding, your fingerprints have been all over this podcast so far.
*  So thanks and welcome, and it's nice to finally have you on the show.
*  It's great to be here.
*  So you are currently the PIN integrates knowledge professor at University of Pennsylvania.
*  I will have introduced you more in the introduction, but can you just talk a little bit about what
*  that means?
*  Yes, so this is a program that our president put up.
*  It's meant to hire people who will bring people and departments together.
*  So for someone like me, this is perfect because the job description is basically to do what
*  I do, which is bring a lot of different people and departments together into joint ideas.
*  I'm going to ask you about that in just a second.
*  But just to enumerate how binding you are within the episodes of my show.
*  So in episode eight, you had done the work with Josh Glazer about how to use machine
*  learning tools and neuroscience and which decoders work best to predict movement velocities,
*  etc.
*  In episode nine with Blake Richards, he mentioned your name.
*  You do have the most mentioned name in the show.
*  So we talked about how back propagation might work in the brain.
*  And again, you have a 2001 paper suggesting almost the same thing that Blake Richards
*  has been working on.
*  In episode 10, you co-authored a paper with Adam Marblestone, and you've worked with him
*  in multiple papers, but we talked about toward an integration of deep learning and neuroscience.
*  So it wasn't intentional to have that little run where you're all over it, but here we
*  are.
*  So...
*  Yeah, I feel bad about that.
*  What can I say?
*  Oh, yeah, you're too famous.
*  So my first question is kind of a big one here.
*  So is it a skateboard or a longboard that you ride to work?
*  Well, it is a long skateboard.
*  I call it a longboard.
*  Long skateboards are called longboards.
*  And the reason why I need that is the streets are really bad in Philadelphia, and I commute
*  to work with the skateboard almost every day.
*  So I need a good long skateboard.
*  Oh, I see.
*  I thought maybe you just didn't like being honked at on a bicycle or something.
*  No, I really like the feeling.
*  You see, I love snowboarding as well and surfing.
*  Longboards feel very similar.
*  Oh, we just got our first good snow here in Durango, Colorado.
*  So I'm looking forward to the snowboarding too.
*  Okay, that's not fair.
*  Yeah, because there's no snow showing up here anytime soon.
*  You know, I lived in Tennessee, so I don't feel very, very feel free.
*  So Conrad, one of your signatures, as you mentioned, one of the things that you're known
*  for is that you collaborate with so many people in so many different labs.
*  Before we get into talking about what we're going to talk about today, can you talk about
*  the importance of collaborating and how it's helped your work?
*  Yeah, I think the world is changing.
*  It used to be that a single person could do most big things in the world.
*  But I think, you see, we start producing really big data sets.
*  It starts to be that the experiments that people run are like really, really complicated.
*  It starts to be the conceptual work of just like, what does it mean that we're getting?
*  It's really baffling us.
*  So in a way, the whole world is drifting towards a collaborative mode of working.
*  And I think the reason why you see my lab in a lot of projects in neuroscience is just
*  we totally embrace that idea.
*  The world is basically, if you want to solve big problems, you have to work with a lot
*  of good people and you have to specialize.
*  It's a difficulty for a lot of people.
*  The original model in neuroscience is you're a big established guy and you hire everyone.
*  Everything is around that one person, the leader who runs it.
*  And I think we see the end of that.
*  In the past, that person would almost always be an experimentalist and they might hire
*  someone who analyzes the data.
*  But in reality, if you have a lab that is run by an experimentalist, they can't really
*  supervise a computational person.
*  So I think everything is getting better in a way by moving towards a collaborative way
*  of operating.
*  Yeah, I know.
*  Even when I went into graduate school, one of the things that was touted in a lot of
*  the places that I applied was how collaborative all their labs are.
*  And I think some people are more naturally suited for that kind of work.
*  For example, Carl Olson, who's a computational neuroscience researcher at University of
*  Pittsburgh, he told a story about how he really begrudgingly started collaborating with people
*  because he was so used to working by himself and enjoyed it so much, but how it was the
*  best thing to do in the long run.
*  So I think that you're really onto something there.
*  Yeah, it's also more fun.
*  Besides, I really love coffee and all the collaborations give me an excuse to drink
*  copious amounts of coffee.
*  Good.
*  I'm having mine right now as well.
*  So Conrad, I've been doing everything in my power to prevent you from being on the podcast,
*  like I said.
*  But one day I was sitting in my little podcast studio here, minding my own business, avoiding
*  my family, of course, thinking, hmm, who can I pester next about neuroscience and AI?
*  And all of a sudden, the brain chip in my head alerts me to a new email from one Conrad
*  Kurding.
*  And all the email says is, we need to talk.
*  And there's this paper attached to the email.
*  The paper was called Bioscience Scale Automated Detection of Figure Element Reuse.
*  Conrad, just give it to me straight.
*  What is it you found in my prolific, illustrious, unparalleled record of high impact, jaw dropping,
*  potential mating partner swimming body of research publication?
*  What did you find, sir?
*  So look, I don't like people who fake their papers.
*  And it dawned upon us that we could capture those guys.
*  And that's how that project started.
*  And I just thought that if I'm to be on a podcast, that would be the most fun thing
*  we could possibly talk about.
*  It is fun.
*  I was just thinking, what am I going to name this podcast?
*  Watch out, Kurding's going to F you up.
*  No, I think if you're faking your data, they will find you.
*  It might not be me who's finding you.
*  But whoever's out there currently faking your data, you will be in a world of heart.
*  So OK, so this paper is all about figure reuse.
*  But for people who don't even know, because this was actually new to me because I'm so
*  innocent.
*  So what is the inappropriate reuse of figure elements?
*  And what are some examples of why someone might do it?
*  OK, so let's say you're a biologist.
*  And the reviewers make you do a control where they say, well, we think this paper might
*  be all wrong because your antibodies might not be working or something.
*  They make you do an extra experiment.
*  And now there are people who aren't entirely honest under those circumstances.
*  And if a biologist fakes data, a good proportion of cases, they will not really fake data,
*  but they're going to use a photo they already have on their computer and pretend it shows
*  something else.
*  So let's say you have a photo of cells growing nicely and you have a photo of cells dying.
*  You have a video, you have a paper that you publish which shows if I do this thing, I
*  prevent the cells from dying.
*  That's great.
*  But then people might say, well, maybe it was the time of the day that prevented the cells
*  from dying.
*  Can you redo the experiment?
*  And now maybe you haven't done that experiment.
*  Maybe you don't want to do it.
*  But you have another photo on your hard disk that also shows cells not dying, that nice
*  happily live.
*  You might just use that other photograph to not have to do that extra work.
*  And so in general, lots of biologists that are faking their data have been caught by
*  them basically doing what's image fraud, where you see the same image in two papers.
*  In one case, it shows one thing.
*  In the other paper, it shows another thing.
*  So you were just talking about within the same paper, because a reviewer might ask you
*  to do a new experiment.
*  But now you're talking about a cross paper.
*  So just to give an overview of what you guys did here, you looked at over 2 million figures
*  over tons and tons of papers.
*  And just to keep it from combinatorially exploding, you restricted the analysis to papers that
*  shared an author within one paper or across papers that shared an author.
*  Is that right?
*  That's right.
*  OK.
*  Yeah, let me highlight what the procedure would be.
*  I suspect you, Paul, to be a malicious fraudster.
*  Damn you, Conrad.
*  OK.
*  Sorry about that.
*  Imagine I would.
*  I would never do such a thing.
*  But imagine I would.
*  Then what I would do is I would download all your papers.
*  And then I would take all the figures out of all your papers.
*  And then I want to check, do you see the same figure appear multiple times?
*  And I might find like, oh, in that one paper, you say that's the control condition.
*  And in another paper, you say that's the treated condition.
*  And then I could say, oh, this is like really fraud.
*  Like it can't be both at the same time.
*  Now how does an algorithm do that?
*  The problem is if people do that, they aren't stupid.
*  Not like what people may do.
*  They might flip the image upside down with the hope that a human can't see it anymore.
*  And in fact, it's hard to see it.
*  In fact, they might rotate the image a little bit and recrop it and change the contrast
*  and do all these changes to make it hard to spot them.
*  They just do it in a fraud.
*  There are humans that do this at journals.
*  Is that right?
*  That's right.
*  A lot of people have been found out to be frauds by someone just doing it by eye.
*  Now like in the past, what I would have done is I would have like printed out all your
*  paper, put them all on my desk and looked, do I see anything that looks suspicious?
*  Instead of doing that by hand, we can do algorithmically.
*  Okay.
*  So this is a case where it's AI assisted work because it's not fully automated.
*  So you guys, you had an original algorithm, an algorithm that originally went through
*  all the figures and then, well, maybe you can just tell me the process.
*  Right.
*  So it's a three stage process.
*  The first thing is for fraudulent image we use, well, you need to reuse an image.
*  So for that we have an algorithm that can basically mine through all the paper and find
*  every image region that has been reused.
*  And that even it doesn't mind if you rotate it or change contrast, change color, it will
*  still find all those.
*  So that's the first stage.
*  We find basically that images are reused.
*  The problem is you will find lots of really boring things.
*  You will find, let's say, lots of X axis that all have time on it.
*  And in fact, like my own work might have all kinds of X axis that have time, open bracket,
*  seconds, close bracket to it.
*  So that is reuse of an image region.
*  It's just like really boring reuse.
*  So we have the outputs of the first stage, which finds reused image regions, then goes
*  to a second stage, which looks for interesting reuse.
*  And the interesting reuse then basically means that this is something that doesn't look like
*  it's random.
*  It doesn't look like it's just like an axis of something.
*  The way that works is we give the computer a big database where we said, well, this is
*  boring reuse, this boring reuse.
*  And it learns how the boring things look like.
*  It basically learns that axis and standard brain images and a whole bunch of things that
*  the fields use don't mean anything by themselves.
*  So for example, you might find a map of America and all kinds of papers where maybe something
*  is highlighted.
*  That doesn't mean that they're all fraudulent papers.
*  It just means that they're all looking at the same map of America.
*  So we don't want those things.
*  And that's why we have that second stage.
*  And then by that time, we will have gotten rid of most of the bad things, of the uninteresting
*  things.
*  And then we'll have the humans focus on the cases where there's quite possibly something
*  wrong.
*  And of that last stage, the third stage as we call it, a good proportion of the papers
*  we have prongs.
*  Yeah.
*  Do you want to just spit out some numbers of what percentage that you found?
*  And you didn't name any researchers or papers or anything like that.
*  So this is just a sort of a proof of principle, right?
*  Yeah.
*  We haven't solved our ethical problems yet.
*  So let's first name some numbers.
*  If I remember that right, and I've done hundreds of them, about every 10 papers that I see
*  that have reused, that basically passed the first two stages, there's really something
*  wrong with it.
*  So now that produces an ethical problem, which is some of the image misuse will be
*  stupidity.
*  Let's say I'm a microscopist.
*  I have 10,000 images on my heartbeats, and I accidentally use the wrong image.
*  That doesn't make me a fraudster.
*  That just makes me careless.
*  There are probably a lot more careless people in the world than there are fraudsters in
*  the world.
*  I hope.
*  I am pretty positive about that.
*  So suddenly I could see myself sometimes being careless because, well, there's all kinds
*  of things in life.
*  We basically now sit on a big database of papers where we can be sure that something
*  is wrong.
*  We know that these two images cannot at the same time show what the two papers say.
*  But we can't be sure, is that stupidity or is this fraud?
*  And that leads to a big ethical problem for us that we haven't yet solved.
*  What should we do with it?
*  We could put it all on some webpage, but people would bring out the pitchforks, and it wouldn't
*  be nice in that sense.
*  So at the same time, letting the fraudsters, undoubtedly there's a good number of fraudsters
*  in the list that we have, letting the fraudsters run free is also not the right thing.
*  So we are trying to work towards a solution where we can make this be a standard part
*  of doing science for say every new paper in the world according to us should be scanned
*  for if there are signs of image mistakes.
*  I wonder if there should be a system like you've tried to log in three times, we're
*  setting your password, that sort of thing, three red flags or something like that.
*  Maybe.
*  I don't know.
*  I haven't thought about it.
*  But it seems harder to me to, so coding, there's a lot of room for stupidity and carelessness.
*  But making images, it seems more difficult to make errors via stupidity using images.
*  I don't know.
*  In lots of biology papers, there might be 30 microscopy images.
*  It might be like this is the 10-micromolar calcium paper, this is the 30-micromolar calcium
*  condition and so forth.
*  For all of them, you have a microscopy image.
*  Can it happen that you mislabel them on your computer?
*  Yes, I think there's honest mistakes that people could make.
*  Yeah, that's true.
*  So you don't release the code.
*  You can't find the code or the algorithm on GitHub.
*  Why is that?
*  We should make it.
*  It's for exactly that same reason.
*  Given what we have, it would be very, very easy for someone to just rerun our code and
*  get that list of a large number of probably fraudulent papers.
*  So we feel that we need to solve it before we make that code openly available.
*  Yeah, that's a good project.
*  Can I just make one guess?
*  You don't have to answer, but are convolutional neural networks involved?
*  They're not.
*  Oh, man, I missed.
*  Okay.
*  That's good.
*  That's kind of interesting.
*  Let's highlight why.
*  The problem that we have here isn't so much a problem that we want to recognize something.
*  The problem that we have here is that we are basically drowning in data.
*  Keep in mind that we have 2 million images.
*  Now, each image can arguably you want to be able to detect the reuse of small regions.
*  So each image might legitimately contain 100 different subregions or something.
*  So all of a sudden you're in this like crazy large space where you want to check if there's
*  reuse.
*  Once you give me that there's a hint of where we use, it gets to be a relatively easy problem.
*  The problem is how can we compare a very large number of papers without running out of runtime?
*  Not like a million papers, that is 10 to the 12 pairs of images.
*  So whereas there's this old framework that is more like it's called SIFT features, it
*  an image finds interesting points and describes a neighborhood of those.
*  That is a much better match for what we want to do in this domain.
*  So our algorithm is relatively similar to that.
*  Like you said, the three stages and then the third stage is reviewing by eye.
*  There are three authors on the paper and all three of you reviewed a lot.
*  I see that you didn't review the most by eye, but one author stood out as the clear laggard.
*  Was that author just lazy?
*  I think that author was lazy and that author might have been me.
*  No, you were second.
*  You were second place.
*  There was pretty large discrepancy.
*  But it was over, if I remember correctly, almost 3,000 images that you guys looked at.
*  But I'm pretty sure I was the laggard.
*  I'm sorry.
*  I caught you.
*  I wanted to catch you with something.
*  I'm really positive about it.
*  I'm the lazy guy.
*  Just busy.
*  Let's say busy.
*  Sounds much better.
*  How many man hours did it take you to...
*  That's something you didn't report.
*  It's just how long it took you each to go through your sets of figures.
*  How fast is it to go through one and look at it and be able to tell?
*  I'm sure we have statistics for that.
*  Let me highlight how the process looks like.
*  Basically, you're on this webpage.
*  You see 10 papers at a time.
*  Each of those papers, in fact, 10 pairs of papers.
*  You basically see two figures.
*  You see some red markings that say, here's this suspiciously similar region.
*  And then you basically have links with what you can get to the papers.
*  Now, I would say maybe two thoughts of papers.
*  You look at it and you're immediately clear that this is not inappropriate.
*  That includes maybe there's a sketch of methods that people use in two papers.
*  That's not fraud that might be inappropriately not cited,
*  but that's not something that makes me worried.
*  I will not spend time on these examples.
*  You see that within seconds.
*  For two thoughts of them, you can be really quite sure.
*  Then you find the ones...
*  For the remaining thought, you've got to click on the papers.
*  It basically takes 10 seconds for the two papers to open.
*  In maybe half of them, I might be somewhat off at the ratios, but roughly,
*  in maybe half of them, you go there and it will say in the later of the two papers,
*  it will say, replotted from X.
*  Then it's clear, okay, that's good, that's fine.
*  Then there are the obvious fraud cases.
*  Obviously, there's something wrong with cases where you also don't need to click on anything.
*  You might see that in the same figure, you have what seems like a mistake.
*  It might be a titration and number three might be the same as number seven,
*  but otherwise the main effect is there and you might not want to call it a fraud.
*  It's like a clear image mistake.
*  Then there are the cases where it seems that it just fits the narrative of the paper beautifully
*  without making sense that it's that paper.
*  In some cases, it obviously can't be.
*  This is one figure and it shows a completely different cell line or something like that.
*  Then there are the real hardcore fraudsters, which is also fun.
*  There are some people who take the same image and rotate it by 30 degrees and recrop it a little bit.
*  It's like, wow, you guys have been creative at this.
*  You find the same figure, like flip it like it's a little more orange than the previous one.
*  Then you really get the impression that here's the real master at fraud.
*  Did you ever find one with a middle finger translucent embedded in the air?
*  That would be hilarious.
*  I wonder what's going on psychologically.
*  What would you be thinking if you'd be doing such a thing?
*  It's crazy. It's a crazy thing to do.
*  Maybe people are worried about their life as a scientist, maybe about tenure,
*  maybe the system puts too much pressure on people.
*  I guess, but you're throwing up your whole career for and be ousted anyway.
*  People who do that don't think they can get caught.
*  That's why it happens often.
*  They believe that that's safe.
*  They don't know that.
*  That's why we made sure that despite the fact that we didn't yet solve our ethical problem,
*  that we put it out as a pre-prenuptial as early as possible
*  and that we also talk nature into doing a little article about it
*  because we want people to know that they can't do that.
*  Two things.
*  One, I'm wondering if other journals are showing interest in the work.
*  Two, by putting the paper out, there must be a name for this phenomenon,
*  but you might be lowering the future rate of fraudulent reuse of images
*  just by showing that this resource could be used.
*  What do you think?
*  That is the idea.
*  That's why we made sure to at least get the word about the existence of this approach out fast.
*  We hope that it will help fix things.
*  I'm reasonably hopeful about that.
*  The thing is that forensic data analysis is really coming very quickly at us.
*  You're now expected to publish the data of everything you're doing for most modern journals.
*  You will be expected to upload all your microscopy images.
*  Once people are forced to put in good images, it will be so easy to detect any kind of fraud.
*  If you Photoshop an image, there is a signature of Photoshopping that's still in there.
*  Band splicing was a big thing.
*  When they do these western blots, they just take a line of one western blot,
*  put it into another, and things like that.
*  That thing is also getting fully observable.
*  I think anyone who still fakes data is in for a rude awakening.
*  Well, it's good work here, Conrad.
*  Thanks for talking with me about it.
*  I know that you're pretty short on time.
*  I'm going to plan on having you back on the show, if you'll come back on at a later time,
*  to talk about causality.
*  What is something that you're working on now that you're excited about in the lab?
*  Causality is at the moment what I'm most excited about.
*  In neuroscience, we want to find out how things work.
*  In a way, how things work is a causal question.
*  I'm very broadly interested in things.
*  I'm interested in what it would mean to understand the brain.
*  I'm interested in how an understanding of the brain should look like.
*  I'm interested in what we can learn from deep learning.
*  You covered that area extensively.
*  I think it's the most promising way of thinking about the brain that we have at the moment.
*  I was going to ask if you think that deep learning is overblown or underblown,
*  or if it's just right blown.
*  I think it's a very natural progression.
*  Let me give you a very high reason for the existence and usefulness of deep learning.
*  A long time ago, when we did computer science, we as humans coded the solution to the problem.
*  That's what we call good old-fashioned AI.
*  We basically built the solutions to it.
*  Then we figured that that wasn't tenable, and we switched to optimization.
*  For a long while then, computer science was, we take a problem, we write it as an optimization problem.
*  We as humans give it the function, and the computer finds what the parameters are that are most useful for that.
*  That includes how we fly fighter pilots all the way to how we solve all kinds of estimation problems.
*  We've done a lot of Bayesian statistics over time, and that's all based on that idea.
*  We built in how we believe the world works.
*  If a human writes down the function with parameters that characterize how uncertain we are,
*  we don't know what the influence of that on that is, but we know what its parametric form is.
*  Humans put in the model, and the computers put in the parameters.
*  Deep learning is, in a way, the obvious next step for that.
*  Why is it better to learn the parameters than having humans set it?
*  Humans just don't know what the right parameters are.
*  If we have humans put in the functional form of it, humans don't know the functional form.
*  You can say what deep learning is.
*  It basically says, instead of me specifying this is how the output depends on the input,
*  I say all I know is that the output will smoothly depend on the input, or sparsely, or hierarchical.
*  Instead of putting in the full knowledge of what I know about the world,
*  which I usually don't because we don't understand the world we're in,
*  we instead build in very soft things, where we say,
*  yeah, things are smooth, and the world is translation in there,
*  and we build in knowledge of that kind.
*  In that sense, deep learning is the natural progression of computer science,
*  where we went from, we built the solution to, we built the function,
*  and the computer finds the parameters,
*  to now the computer finds the parameters and also the function.
*  It seems like there's a trend recently of building back in some assumptions into the deep learning models,
*  like, for instance, building dendritic compartments within the units,
*  and making one unit not one unit, but it's a unit with multiple subunits, or things like that.
*  I'm wondering how far that's going to go.
*  There's two sides. Let me separate it into two questions.
*  The first one is how the brain does it, or does the brain do it like that?
*  The other one is as a technical system.
*  As a technical system, there's no doubt that it helps,
*  but yes, it also helps to build in at least cognitive things.
*  Today's deep learning systems often do have attention.
*  They do have routing circuits. They have memory.
*  They start having a lot of the things that we as cognitive scientists discover for people.
*  But then the other question is how the brain operates also somewhat like deep learning.
*  And that's an area that from my perspective is a hugely promising approach to neuroscience,
*  because we don't, if we are honest, we don't have meaningful models for the brain at the moment.
*  Deep learning is in a way promising there, because deep learning in lots of ways looks like brain,
*  shares a lot of properties with the brain,
*  and you can make an evolutionary argument that it should be a bit like the brain.
*  It's really refreshing to hear someone talk about how little we know about the brain
*  and how few models and theories there are.
*  Do you think that the big breakthrough,
*  people talk about how there hasn't been an Einstein type breakthrough, right,
*  for understanding our brains and minds.
*  Do you think that that's going to come from AI or neuroscience or this collaboration or somewhere else?
*  You have a physics background. Maybe it's coming from physics, you know.
*  I don't think I believe in the big breakthrough.
*  And in a way that's fine.
*  The brain is the ultimate frontier.
*  There could be nothing bigger for mankind than understand how we think,
*  how our brains work.
*  So I don't think that we should be waiting for like a big breakthrough.
*  We will be making progress in lots of areas.
*  And among others, I think what we need to do is figure out what it means for us to make progress.
*  Yeah.
*  And I think the problem is at the moment,
*  we are probably trying to reach something that is fundamentally logically not reachable.
*  You know, I have lots of people ask me questions about what we know about the brain.
*  And it's often frustrating because I want to say almost nothing.
*  And that's frustrating to them.
*  So I could talk about numbers and what we found.
*  But to ask what we really know about the brain, 60 minutes is wrong.
*  We don't know anything about the brain.
*  So let's see, like we know lots of correlational things, no?
*  We know that there's a lot of cells in the back of my head that correlate with the contrast in the results.
*  We know a lot of those things.
*  We know a lot of things about anatomy.
*  But how the neurons get correlated to that?
*  We don't know that very much.
*  Now, like the problem is what our question is in neuroscience.
*  The question that we all ask if you probe us on this is it cause a question.
*  We want to mechanize.
*  We want like, how does the light go to the eye makes activity there,
*  makes activity there, makes me talk in a funny way with you.
*  And that chain of causal influences, we don't have tools in neuroscience to really ask how that chain works.
*  I'm glad that you're working on causality.
*  That's wonderful.
*  Conrad, so pretend like you're at a cocktail party and you've had a couple cocktails here.
*  Oh, so that's good.
*  I get drunk extremely easily.
*  OK, well, let's go ahead.
*  Three, too many.
*  Let's say you've had too many.
*  Nice.
*  Easy.
*  These won't be hard.
*  So but I want you to give me a number here.
*  When do you think we'll know what we're talking about when we say consciousness?
*  Never.
*  OK.
*  OK, that's good.
*  So Blake Richards mentioned that it'll just kind of be explained away over time and it won't.
*  We won't think of it as a thing.
*  It'll be explained away as functions.
*  But look, this is bullshit.
*  Like consciousness relates to a way how we feel about ourselves and about the world.
*  What gives neuroscience the right to say anything in that space?
*  Like there are many levels of description.
*  Why is reductionism the right way of answering that?
*  You can say things like maybe anger or consciousness.
*  They don't necessarily.
*  The link to the substrate might be very hard and it might in fact be like basically so complex that it's useless.
*  Whereas saying, well, consciousness, it's not the argument, the evolutionary argument for consciousness or anger is like very easy.
*  You can make a very clean argument.
*  Why having something like a record of the things you've done in the past or what your objectives and goals are, why that is useful from an evolutionary perspective.
*  Once you go into that hardcore reductionist thing that is like, sure, like the brain's made out of physics.
*  So you can say neuroscience isn't necessary.
*  It's all just like physics all the way down.
*  But no, that's not the right words for that.
*  So the idea that it will just be explained away, that doesn't even make sense.
*  So, man, I'm going to have Blake and you on and this will be fun.
*  I didn't know you're an angry drunk.
*  This is awesome.
*  By the way, Blake is super awesome.
*  Hey, I forgot something when we talked earlier, which is I didn't mention that paper.
*  I didn't mention that that paper about detecting fraud in science is it was beautiful work by my former postdoc, Daniel Acuna, who is now professor at Syracuse.
*  And I'm super proud of him.
*  And I just wanted to say that he's great.
*  And it's important to mention the good things he's done here.
*  It was a very complicated project just because of the scale of things.
*  Yeah, I bet.
*  OK, so we just have just a couple more minutes.
*  I have just a couple more questions.
*  OK, go for it.
*  All right.
*  So what is something?
*  Take a sip.
*  What is something that you believe about neuroscience and or artificial intelligence that that might be a little out there?
*  That might be a little unconventional.
*  Well, I believe that the answers we are seeking are all answers for which there may not exist answers.
*  I think I think we are looking for we're trying to answer the wrong questions in your.
*  Yes, thank you.
*  OK, so I love that answer.
*  So I but I even before I was in graduate school, I was a tech in a research neuroscience research lab and I was auditing this class and it happened to my advisor was teaching it.
*  And what was that?
*  I don't remember what the question is, but I raised my hand and I said, you know, maybe we're not asking the right questions.
*  And he said, well, what are the right questions?
*  And I said, I don't know.
*  So just a text.
*  Yeah, yeah.
*  I think this is the right way of thinking about it.
*  OK, Conrad, what is your advice for people who want to accomplish as much as you aside from collaboration?
*  I think having fun.
*  I think playing is really the basis of good scientific inquiry.
*  I think we have probably learned an awful lot about the world, but just trying to blow things up and making things fail and and playing.
*  And playing with things and playing with ideas is entirely underrated.
*  Very good.
*  Last question.
*  What is something that you wish was on your CV that's not?
*  I wish there was an explicit mention of dinosaurs in my CV.
*  So subject zero is the mascot of the lab.
*  And I just love dinosaurs and everyone in the lab loves dinosaurs.
*  And yet, if you look at my CV, there's not one mention of dinosaurs.
*  So I would like to find an excuse to have a chapter on dinosaurs on my CV or at least a paper that has dinosaur in the title.
*  OK, people, you heard Conrad.
*  He loves dinosaurs.
*  He loves to collaborate.
*  So get on it.
*  Contact me.
*  Contact him.
*  You're at courting lab on Twitter.
*  That's right.
*  Exactly.
*  And people should probably go there and I'll link to your your lab site.
*  Is that another place you recommend people learn more about you?
*  Yeah, that sounds great.
*  OK, very good.
*  Well, thank you, Conrad.
*  I appreciate your time.
*  I know you have to go.
*  I'm going to if I don't get caught for fraud, then I will have you back on the show.
*  We'll talk about that.
*  That would be great fun.
*  I had great fun talking with you.
*  OK, thank you.
*  Great.
*  See you.
*  See, I told you that would be fun.
*  If you like the show, please leave a review on iTunes and or tell your grandma and her
*  friends about it.
*  See you next time.
