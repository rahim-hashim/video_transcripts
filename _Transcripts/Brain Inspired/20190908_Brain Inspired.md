---
Date Generated: April 21, 2024
Transcription Model: whisper medium 20231117
Length: 5833s
Video Keywords: ['Science', 'Technology', 'Education']
Video Views: 1701
Video Rating: None
---

# BI 046 David Poeppel: From Sounds to Meanings
**Brain Inspired:** [September 08, 2019](https://www.youtube.com/watch?v=xfkLg5awx8M)
*  Hey guys, quick announcement before we start here.
*  I will be in Berlin at the Cognitive Computational Neuroscience Conference from September 12
*  through the 16th.
*  If you're there and you want to meet up for a coffee or a beer, contact me on Twitter,
*  I'm at pgmid, or email paul at braininspired.co.
*  I would love to meet you, hear your feedback or suggestions for the show, and otherwise
*  just chat about all this stuff.
*  Because that's always fun.
*  With or without a microphone present.
*  So I hope to connect with some of you.
*  I'm really looking forward to the conference.
*  Should be a fun time.
*  Okay, on to the episode.
*  I mean, how are you going to actually articulate a notion of concepts that's sufficiently
*  rich, interesting and bizarre, because thought is bizarre.
*  And language is bizarre.
*  You know, the mind is a weird place and has very idiosyncratic properties.
*  How do you get to that?
*  Right?
*  Language is one of the best ways to get to it.
*  And even that falls short.
*  How do you keep friends, sir?
*  I don't have friends.
*  I just try to do, I just try to be nice to my family.
*  That's hard enough.
*  That's hard.
*  That's already a lot of work.
*  This is Brain Inspired.
*  How do the words that I'm saying mean anything to you?
*  These words that are coming through your headphones, traveling through the air into your ear, vibrating
*  your eardrum and getting passed along to your cochlea.
*  How do they get processed in your brain over the course of a few tens of milliseconds until
*  they end up connecting with the language circuits of your brain and manifesting some meaning
*  in your mind?
*  Hopefully close to the meaning I intend when I speak them.
*  David Popple is much closer than the rest of us to answering this question, though he
*  may be loathe to say so.
*  Hello, experts, speech processing systems.
*  I'm Paul Middlebrooks.
*  Welcome to the show.
*  David runs his lab at NYU where he studies what I just described, plus lots of other
*  things related to speech and hearing, language and music.
*  And he uses various tools that measure electromagnetic signatures of populations of neurons, things
*  like EEG, MEG, electrocorticography, plus fMRI.
*  Basically anything that we can use to experiment with humans.
*  You may remember episode 25 with John Krakauer when John and I talked about the idea that
*  carefully crafted behavioral experiments aren't as prevalent in neuroscience as they should
*  be if we want confident answers to how brains are responsible for what we do.
*  David was a co-author on that paper and thinks hard about what makes worthwhile science.
*  When you read almost any of David's papers, you can't escape without understanding his
*  philosophy and approach to science.
*  And that comes out plenty during our discussion, which is peppered with philosophical and otherwise
*  tangents.
*  I have split the episodes into parts one and two because it was a long chat that covered
*  lots of territory.
*  In this first part, we talk about how fast we produce and can comprehend speech, how
*  language and thinking interact, the difference between language processing and speech production
*  and perception, the impact on David that David Maher and Tomaso Pagio's levels of analysis
*  kind of thinking has had.
*  And then we end up talking about his work on how brain oscillations might underlie how
*  we get from sounds that hit our ears to meanings in our minds.
*  So in part two, which I'll release in a few days, we continue along this path and talk
*  more about the state of natural language processing and deep learning with respect to speech and
*  language and how it relates to neuroscience.
*  And we barely touch on one of his major contributions, which is the notion of a dual stream model
*  of speech processing in our brains and the cortex that has become the standard model
*  after it was mocked and ridiculed.
*  And we go on to talk about a lot more.
*  So check that out in a few days.
*  It is the first time on the show that I've been told I was deeply wrong about something.
*  And I consider that a great success, landmark achievement.
*  To learn more about David and get links to what we talk about, go to brandinspired.co
*  slash podcast slash 46.
*  Okay, happy speech processing and lingual understanding during this episode.
*  Welcome, David, to the show.
*  I hope you don't mind if I speak this way during our conversation.
*  I really want to break your four to five-hertz syllable rule.
*  But thank you for being on the show.
*  Nice try.
*  You only got to six hertz.
*  Damn it.
*  I hate on a podcast to slow way down.
*  So if you go too slow, it's painful.
*  If you go too fast, it's annoying.
*  So you got to have our individual wave vibe that we surf on.
*  Just before we even start here.
*  So that rule is that all languages seem to follow this four to five hertz syllables frequency.
*  Does that apply to the clicks languages, the African clicking languages?
*  I can't remember the name.
*  Yeah, that's a good question.
*  Absolutely.
*  So far, there have been no exceptions to this.
*  It has to do with the physical structure of speech signals.
*  So the way we're talking to each other, signals are going back and forth.
*  These are waveforms of some kind of broadband.
*  And if you look at the rate of the amplitude modulation of the speech waveform, so it's
*  going up and down, that turns out to be between four and five hertz for any language.
*  That means roughly you open and close your mouth or you increase and decrease the amplitude
*  of your speech signal.
*  And now obviously there's variability and sometimes within a sentence or within a word,
*  we speak more quickly and more slowly.
*  But the range is remarkably restricted.
*  It's between about two and nine hertz.
*  And if you go outside of that, it's no longer comprehensible.
*  So there is really cross linguistically a mean rate of speech.
*  And that's although one might not like it and not believe it, that's a fact you can
*  take to the bank.
*  That's now our interpretation is we are all entitled to our own interpretations, but not
*  to our own facts.
*  So we can then debate what is the origin of this?
*  Is this a property of the biomechanics of articulators or cortical computation?
*  But a fact of the matter is that speech across languages has a modulation rate of four to
*  five hertz, which is cool.
*  It is cool.
*  You know, there's maybe a limit on the speed at which you can listen to audio books and
*  podcasts for that same reason, huh?
*  That's exactly right.
*  And there are a few exceptions.
*  So one can train oneself.
*  That's actually a topic under investigation.
*  There's a few people.
*  So some people in my lab and some people in a lab in Germany as well that are doing exactly
*  these experiments as there are purported to be listeners, particularly blind listeners,
*  who can teach themselves or who listen to the audio versions of things, a factor of
*  at least four more.
*  And that's around, let's say, 20 hertz.
*  And that's for the typical listener.
*  That's completely unintelligible.
*  Right.
*  So you can't parse or segment the information stream anymore.
*  So you don't know what kind of representation you're building perceptually.
*  But there are apparently it's trainable, which is kind of interesting.
*  So you can train your.
*  So all of us can do a factor of two.
*  Right.
*  So for instance, I listened to one of your podcasts last night.
*  I first listened to normal speed and after a while I was like, look, I still have important
*  Netflix to watch.
*  I'm going to go back here.
*  And our intelligibility doesn't suffer.
*  We're fine.
*  That's well documented.
*  If you go to speed up by a factor of three, your intelligibility sharply drops off.
*  You're significantly worse.
*  You're missing a lot.
*  And by a factor of four, you're screwed.
*  So now it does seem to be trainable.
*  And it raises an interesting question, which is if you are, you know, if some kind of cortical
*  mechanisms underlie comprehension, which seems pretty likely unless you're a dualist, I guess,
*  then are you how malleable are these systems or are you in fact capitalizing on other systems?
*  Are you kind of driving another regime of cells or something that is not not known yet?
*  Right.
*  Yeah, I actually often because I listen to podcasts and audiobooks as fast as I can to
*  still retain it.
*  And I wonder, given sometimes the depth of the technical depth that we talk about on
*  the show, if that's still a viable way to do it for people, you know, I'm wondering
*  what what speed people are listening to this show on.
*  Well, I mean, look, the so there's a difference.
*  So the question is, does this reflect the speed of speech or the speed of thought?
*  Yeah, right.
*  So these things are not unrelated in the sense that, I mean, you know, we can have a very
*  quick conversation about highfalutin things, but it's not just about intelligible speech.
*  That is, you can identify individual words, but it's actually getting your head around
*  the topic itself.
*  And so maybe the limiting factor isn't the speed of the sensory motor systems, the input
*  in the output. It maybe has to do with compressing things into mental representations that can
*  actually be recognized, concatenated with others written down into memory.
*  Is that the fast memory system or is it statistical learning?
*  You know, there is always so suddenly you're connected to all these parts of neuroscience
*  that are complicated and we just don't know.
*  This is a new area. We just don't know enough about it.
*  OK, maybe I'll give you a little introduction.
*  I have the apparently very naive David Purple on the show today.
*  You study speech and language in your lab at NYU.
*  And in your case, I'm stealing this directly from your website.
*  You work on how we go from vibrations in the ear, our sounds, to abstractions in the
*  head being words.
*  So it's good to have you on finally.
*  I actually I had your friend John Krakauer on many episodes ago now, and he and I were
*  actually sitting in a bar outside of Santa Fe, New Mexico.
*  And we talked. You and he co-authored this paper with other authors about needing to
*  understand behavior better in neuroscience.
*  And so we were talking about that and he was telling me a little bit more about you.
*  And I said, oh, good, I'm going to have I'll have David on the show, hopefully.
*  And, you know, I'm like two beers in.
*  He's probably half a beer in because, you know, a little more moderate than he just
*  grabs me, grabs me right by the shirt, pulls me in.
*  He said, you listen here.
*  David has no idea what he's talking about.
*  You should never have him on your show.
*  And I said, oh, OK.
*  So I backed off. But anyway, I'm glad to have you on today.
*  So tell John go screw up.
*  So we worked together on five of us actually and worked together on this on this paper
*  project where just reflecting on some of our frustrations of the direction neuroscience
*  is taking. And so we because we kind of see eye to eye on that.
*  The paper itself had a kind of difficult birth, as you can imagine, because some of the
*  recommendations or the kind of ruminations we have were not uniformly popular or well
*  received. Yeah.
*  Well, I've heard you discuss that maybe it's not the content, but the tone of the paper.
*  And so, you know, maybe we'll touch on some of those things and revisit them.
*  Have you ever seen the movie Hoosiers?
*  Is that the one with Rudy Rüdiger?
*  I don't know who that is. It has Gene Hackman as a basketball coach.
*  Oh, no, no, no. I mean, Rudy Rüdiger is the one about the Notre Dame football team.
*  Different. Yeah, slightly, slightly different game.
*  No, I don't think I've seen Hoosiers.
*  Anyway, in Hoosiers, it's this basketball team and they're Gene Hackman is the coach and
*  they're in like the final game and it's close.
*  You know, it's getting toward the end.
*  And there's a classic scene where the coach gathers the team around, you know, and he's the coach is
*  the guy who makes the plays, you know, but he gathers the team around and he looks at everyone.
*  He says, what do you want to do?
*  And, you know, he just takes takes their information.
*  So I feel a little bit like Gene Hackman right now in this episode, because there's so many things that
*  we could talk about.
*  You know, we may spend as much or more time talking about just your approach to research as your
*  actual research, because I think that that is so valuable.
*  So here's my tentative plan.
*  We'll start off with a sort of a big picture and then we'll kind of focus in on some of your more
*  particular research, past and present, and hopefully end up again at a big picture.
*  Sounds good. Great.
*  So to start off with, I want to discuss.
*  I'll try not to speak like John.
*  OK, you can't be serious.
*  Just know anything at all.
*  Oh, yeah. Oh, man.
*  That's pretty good.
*  You've spent some time together.
*  We've had a few. You should do a double episode with us.
*  That could be entertaining.
*  That would be fun.
*  I'm hopefully having some double episodes coming up.
*  So. OK, so.
*  So I want to start off with a few questions about language and speech in general and how it
*  interacts with our thoughts, which you've already touched on talking before.
*  So and I have a few quotes to frame this here.
*  So we walk around all day with thoughts like coursing through our heads.
*  And sometimes language is associated with those thoughts.
*  Sometimes we think in language, sometimes not.
*  And different people seem to think more and or less in language than others.
*  In fact, you've recently divided the world into people who who sync up with other people's
*  rhythms, you know, in language.
*  And maybe we can talk about that later.
*  People who do and don't do that.
*  So so many people have exalted writing as a way to clarify their own thoughts.
*  So the idea that formulating your thoughts into language is a valuable process.
*  So there's the well-known quote, which apparently is actually a paraphrase from Ian
*  Forrester. How do I know what I think until I see what I say?
*  But, you know, it's tough to create anything, including language.
*  So here's a second quote as the poet Stanley Kunitz has put it.
*  The poem in the head is always perfect.
*  Resistance begins when you try to convert it into language.
*  OK. But as we know, language is not a one way street.
*  And this is kind of what I want to ask you about here.
*  So translating our thoughts into language actually seems to change our thoughts as well.
*  And so so here's a quote, a third quote that is more closely related to my own
*  frustrating experience. How curious that I'm unable to say who I am.
*  The moment I try to speak, not only do I fail to express what I feel,
*  but what I feel slowly transforms itself into what I am saying.
*  So that's from Clarice Lispector from a novel Near to the Wild Heart.
*  So it's this this notion that we don't just use language to rather poorly express
*  our thoughts, but that the act of expressing it in language, of observing our own
*  expression in language actually changes those thoughts.
*  You know, I find, especially when I'm trying to describe what I do to someone that I
*  meet in the wild, for instance, you know, beyond the simplest notions, language
*  quickly fails and falls way short for a way of communicating, you know, what I'm
*  actually intending to communicating.
*  So, you know, especially it's never fun to talk about something like consciousness,
*  for instance. Right. So I just kind of want to open it up to you and ask you what
*  your thoughts are in language and how it interacts with with other types of
*  thoughts. I mean, that's look, I mean, that's a I mean, it's a good and extremely
*  deep and complicated question.
*  It's been discussed for as long as we've thought about thought, say, three
*  thousand years is the relationship between thought and language.
*  And I think the and it's a complicated, subtle relationship.
*  So I think one thing we're going to you know, so I think that the poem you
*  said very beautifully captures some of that, which is you.
*  There's no one to one mapping of thought to language as you try to put it down,
*  you know, the spoken words are writing it down and making explicit to yourself the
*  thought you suddenly realize that you're by by compressing it into the code of,
*  let's say, the words you have, the vocabulary you have to make it available.
*  Parts of the conceptual stuff that's in your head remains ineffable.
*  I mean, there's part of conceptual experience which is just not mappable to
*  the vocabulary you have and possibly to any vocabulary.
*  Vocabulary has a certain format.
*  We don't know what it is.
*  Microsoft brain. I don't care what it is.
*  Right. So we don't know yet.
*  That's a very complicated question.
*  And we have reason to believe that the conceptual information that you carry
*  around with you is not that easily mappable to a list of, you know, a list
*  of lexical items like that.
*  So there's so there must be something about the conceptual worlds which
*  comprises you that is ineffable.
*  And so something about aspects about concepts is compressible into the format
*  that lends itself to becoming a word, but not everything.
*  And as you write it, but as the poem beautifully captures, once you do that,
*  once you take that particular concept and you articulate it as a linguistic item,
*  as a lexeme, as a word, and you speak it or you write it down, it may have actually
*  only captured the fraction of what it was that was in your head that you really
*  felt you wanted to express.
*  And that's, I think, deeply interesting and fascinating.
*  It highlights very well how, you know, how tenuous the relationship is between
*  language and thought.
*  And of course, then, you know, that cycle goes around.
*  Suddenly you realize this is the word I use, but it doesn't really, you know,
*  remotely capture what I had in my mind.
*  But there's no other way to do it.
*  So it can, it's sort of a filter, right?
*  I mean, it's a filter function of concepts.
*  And it may be dramatically, for all I know, underestimate the richness of thought.
*  And there's lots of things we can't talk about.
*  But I'm sort of attached to the idea that part of conceptual structure and
*  conceptual information is simply ineffable.
*  As it can't be translated into the format of representation that we use for storage
*  as words and then able to be articulated or heard.
*  It's a part of the sensory motor interfaces.
*  Yeah.
*  And that's kind of a bummer because we don't know how do you then get to
*  thought at all?
*  I mean, language is a great problem.
*  It's a wonderful thing to work on and it's kind of mystifyingly difficult.
*  But thought is even better.
*  So how do you get this, you know, how do you get into your head?
*  I mean, it's something that's very difficult to study, let's say, with an
*  animal prep.
*  I mean, how are you going to actually articulate a notion of concepts that's
*  sufficiently rich, interesting and bizarre?
*  Because thought is bizarre.
*  And language is, you know, the mind is a weird place and has very idiosyncratic
*  properties.
*  How do you get to that?
*  And so language is one of the best ways to get to it.
*  And even that falls short.
*  Well, so that's what I was going to ask is, you know, so we think of ourselves as
*  at the tip of evolution's arrow, right?
*  And we have language and that's what separates us from the rest of the
*  animal kingdom and stuff.
*  But then another way to approach it is, well, we just barely have the cognitive
*  capacity to communicate with each other using language, let's say, which we see
*  as a brilliant, beautiful way to communicate.
*  But really, it could just be a very impoverished and poor way to convey our
*  thoughts.
*  It's one of the ways we have available.
*  It turns out to be pretty efficient, but there's no reason.
*  So, so I mean, I think it's important to keep in mind that it's true that we use
*  language for communication.
*  They use many other things for communication, too.
*  Right.
*  And just because we use so this is this gets into, you know, sort of subtleties of
*  evolutionary argumentation and people feel very strongly about this.
*  But I'm not sort of I don't enjoy these arguments a lot.
*  So the the fact that we use a system like this for communication, it doesn't
*  license the conclusion that it was designed for communication.
*  Yeah.
*  That's just a different kind of conclusion.
*  That may or may not be true.
*  And it's sort of an obvious conjecture.
*  But just because we can use a series of words and we to exchange them, it doesn't,
*  you know, some aspects of that lie under evolutionary force.
*  But that doesn't mean it's designed that way, right?
*  It could be it's just so, for instance, an alternative is designed for thought as
*  we're just, you know, it's a way to take a kind of mental representation, let's call
*  it for lack of better terms, thoughts and compress them or compile them into a kind
*  of representation that allows things to be put together and then maybe connect to the
*  sensory motor interfaces.
*  We just don't know.
*  And we just try to do the best we can to study the properties of this thing and try
*  to figure out how it works.
*  And it's really damn complicated because the models are very coarse that we have
*  because we can't do certain things experimentally.
*  We're left to very gingerly approach these issues of the relationship between
*  language and thought. But I mean, I think here's a very trivial example, but one just
*  to make it very explicit to the putative listener, should there be any to who wants
*  to listen to the two of us.
*  And the take almost all words have some kind of multiple meanings.
*  Right. So take the word spring.
*  Right. So spring has multiple meanings.
*  The fact that a single string of items has multiple meanings already shows you that the
*  mapping is more complicated, that there's multiple ideas, concepts, thoughts associated
*  with just a string of sounds.
*  So it can't just direct mapping.
*  So it has to be so that there's probably multiple entries and what are they mapped
*  to. So we want to be very conservative and careful about that relationship.
*  And people have super strong feelings about this.
*  You know, the famous famous line is the limits of your language or the limits of your
*  thoughts. Yeah.
*  Wittgenstein. Yeah.
*  And then there's theories most well known as the Wharfian hypothesis.
*  And Benjamin Lee Wharf was a linguist anthropologist that basically articulating
*  that same view. That is, what you have available as a linguistic system in your head is
*  basically a fundamental constraint on the thoughts you have and can generate.
*  And that's I don't think that's right, but that's a subtle issue in the sense, you know,
*  what we were talking about earlier.
*  So, you know, if you can only express certain things, but the word feeds back on the ideas,
*  how does that shape your things?
*  I think it's complicated, but I think in its course form clearly wrong.
*  I mean, would you say that to aphasic patient who has tremendous problems generating
*  anything, but can still solve all kinds of reasoning tasks, navigation tasks, you name
*  it. They're not thoughtless because they don't have speech and language.
*  So this reminds me of something I really want to get off my chest.
*  Oh, go for it. It's a big picture thing.
*  And I think it's really important.
*  And I think it's it's a trivial point, but I guess maybe trivial points are the ones
*  that the ones that get forgotten too often.
*  And that is we want to be really pedantic about speaking separately about speech
*  perception and production and language.
*  Sure. Yeah, I already conflated the two essentially.
*  So that's a very important distinction in the sense that, you know, the the language
*  system in your head can be accessed by sound and the modal case.
*  Right. So you say stuff and you hear stuff that, of course, it can be accessed by vision,
*  for instance, sign language or reading, and it can be accessed by touch.
*  So Braille. So that means that the central system, you know, that's has a kind of the
*  way its representations and computations are organized or its data structures, that
*  they have access to different modalities seamlessly.
*  Yeah. So speech perception is just one of the subroutines of speech perception is taking
*  an acoustic input and transforming it into the kind of representation that makes contact
*  with the linguistic system.
*  So speech perception is a little bit more akin to reading or seeing sign that when we
*  study language comprehension, we want to be very careful to talk about which contribution
*  is from the auditory part and which contribution is from the let's call it for lack of a
*  better term, the central part.
*  Right. So the computational system that doesn't particularly care about the interfaces.
*  And I guess you've kind of studied both of those processes, but I suppose mostly you've
*  gone down the speech processing recognition and.
*  Yeah, I mean, I think they're hard to separate.
*  It's just I think it's important.
*  I mean, we often know the reason this can become a problem in not just sort of
*  terminological confusion, but the confusion can lead to weird to weird research programs or
*  conclusions. So let's say you find out something extremely useful about the speech
*  production system.
*  That's a conclusion about the speech production system.
*  And it's not yet a conclusion about how language is organized.
*  Right. And we do that.
*  And the reason I think it's important to we often do that when we're talking about the
*  animal work. Right. So there's lots of interesting animal models that are studied for all
*  kinds of functions, be it birdsong or communication calls.
*  We want to be, especially in those cases, crystal clear about what is the system that
*  we're actually studying. So are we studying something about the sensory or motor
*  interfaces that generate the kind of intermediate representations?
*  Or are we saying something about the ability like the atoms of language or the Lego blocks that
*  comprise words or something like that?
*  And I think that has led to some confusion that's unnecessary.
*  I see. Because there's really clearly these are these are different kinds of questions.
*  Well, I know.
*  One of the things that annoys me.
*  So I had to get it off my chest because it's my pet peeve and it bums me out.
*  It's been since my dissertation.
*  I keep writing the same stupid, boring paper, but nobody nobody doesn't listen to me.
*  Yeah, that's your only pet peeve.
*  I'm sure. Right.
*  Yeah. So when I was studying, when I got into neuroscience, trying to kind of figure out
*  what I wanted to study, there were two things that really.
*  Oh, frightened me, let's say, or repelled me in a way.
*  And one was language and, you know, not so much speech because I wasn't thinking in those
*  terms, but but sort of the study of the neuroscience of language and the other was development
*  because they just seemed untenable to me.
*  And so one also, because I mean, development is everywhere, but but speech and language.
*  And and you just made this distinction because you can study some things in dolphins.
*  You can't study the other thing in dolphins, for instance.
*  And I'm wondering if that experimentally is frustrating to you that you're sort of
*  restricted as you're with your animal model to humans in many ways.
*  Or is that in some sense liberating because then you can go more theory approach it from
*  a theory perspective?
*  I mean, yeah, it's a hard look.
*  I mean, the answer is yes.
*  So on the one hand, obviously, as experimentalists for us, it's it's immensely frustrating
*  because there's a stuff we would love to be able to do.
*  And who wouldn't want to do just to be politically incorrect?
*  But no, I don't know.
*  I want to do a little bit of crisper and optogenetics on a newborn language.
*  So we obviously have frustration because we can't do what, say, you can do in the visual
*  system. Right. So the reason I mean, macaque neurophysiology is immensely has been
*  immensely influential, partly because it's a quite elegant model for human vision.
*  For the speech case and certainly for the language case, I would say the other way around,
*  if anything, human language is a great model to study bird songs.
*  Interesting. You think of it the other way.
*  So we have severe limitations technically.
*  But that's just the fact of the matter. And you live with it.
*  And so it also has some kind of liberating features.
*  And what can we do? Well, we can do a lot more pretty well motivated and subtle
*  behavioral experimentation. Right.
*  So there's tons of theories coming from psychology, from linguistics, from computer
*  science, and that allow us to formulate pretty well developed
*  hypotheses. We can develop alternatives.
*  And we can. So we have a just a, you know, well, to put it bluntly, a shit ton of
*  experiments we can do and that are, you know, careful psychophysicals or behavioral
*  characterizations of the system.
*  So the phenotype can be really well characterized, which is much easier than for
*  the animal prep. Right. Right.
*  So we don't have to train a monkey for six months to make a saccade to the right.
*  Screw you. Yeah.
*  Go human research.
*  And so that's a that's a big advantage.
*  Right. So we take we can develop an experiment very quickly tested on so-called
*  normals, right. Undergraduates.
*  But then the limitations arise.
*  So we have to actualize the experiments we can do very delicately to the methods
*  that are available. And as you know, the methods we have available for human
*  neuroscience are are coarse, to say the least.
*  Right. So there's no neurodust for us.
*  And the question is, how do we deal with that frustration?
*  Can we ultimately that's sort of a big picture question for the next 20 years or
*  50 years? So can we arrive at the kind of model circuit mechanistic account of
*  attributes of language processing in light of the fact that we can do the work?
*  And that's so it has to be guided by theory, by engineering, by very clever
*  psychophysical experiments that will take characterize the inputs and outputs of the
*  system. But what you're used to doing, let's say you want to study some circuit
*  that is part of a decision making perception, something like this, just
*  that's a non-starter.
*  I mean, we do in the last couple of years, ECOG is all the rage.
*  So everyone and their brother wants to do ECOG in my lab, too.
*  It's all ECOG all the time.
*  But look, that, too, is extremely limited.
*  You have a grid here or you have now the big thing is, oh, I have a thousand
*  electrodes. I'm like, yeah, that's nice.
*  Yeah. Yeah. Yeah. Good for you.
*  So, yes, we're making exciting progress by using these new technologies because
*  there's cool analytic approaches and you get a little closer to the signal.
*  It's just a little closer. Let's face it.
*  There's still some fundamental hurdles to overcome.
*  Some serious, serious hurdles.
*  And so we have to live with that somehow and say, you know, if we're committed to
*  trying to understand the system, we simply have to make do with the toolboxes
*  we have and use and take advantage of other things.
*  You know, we have to think in terms of like a forward model, like if it were like
*  this, what would be the predictions at this at this distal case that we can
*  measure? You have to have a robust sense of humor to enter this line of research.
*  I think you have to have a robust sense of humor to just to be an experimentalist.
*  You have to be a little nutty anyway.
*  Yeah, that's euphemism.
*  Nutty. Yeah.
*  Madina, Shradha, Jim, Hannah, you guys are the best.
*  I'm working on making some videos for a little online course about the
*  intersection of neuroscience and AI, and I will be sending them your way and to
*  the rest of my Patreon supporters to get your feedback and as a way to say thank
*  you to support the show for next to nothing.
*  And join me in this effort.
*  Go to braininspired.com.
*  So, David, you frame much of your work in terms of levels of understanding and
*  often referring in talks and papers to to the levels that David Maher and Tomaso
*  Poggio proposed.
*  Yes.
*  And the importance of proposing linking high-level research to the
*  intersection of AI and AI.
*  And I think that's a really important point.
*  And I think that's a really important point.
*  And I think that's a really important point.
*  And the importance of proposing linking hypotheses that can tie these levels
*  together, that tie together what we understand at the different levels.
*  And and you guys touched on this with your paper with John Krakauer and others
*  and and lots of other of your papers basically lamenting that neuroscience
*  doesn't focus enough on full understanding.
*  So it seems like language sort of naturally leads one to think in terms of
*  different levels, just like we were just talking about.
*  You know, you have to approach it from sort of a different perspective.
*  You know, understanding different computations that are necessary for
*  syllables and words and sentences and different algorithms required for different
*  representational elements and so on.
*  So but you know, so I want to talk about this, but did your research on speech and
*  language early on lead you to thinking about levels of understanding or or did
*  levels of understanding come first and always inform your research?
*  How did you get on this?
*  Yeah, you know, probably.
*  I was very influenced by reading this kind of stuff as a student.
*  How did you come across?
*  Like, because I think this is important stuff in classes.
*  Right. So as an undergraduate and certainly as a graduate student, I
*  was in, you know, I was surrounded by people doing vision, you know, who isn't.
*  Yes.
*  What department doesn't do all vision all the time?
*  And so very early on, I don't remember precisely when I was exposed to the kind
*  of Mar framework of thinking of things.
*  And since I'm sort of slightly philosophically inclined, it spoke to me a lot of
*  because at least here was someone trying to make explicit the nature of the problem
*  that is trying to say, look, you know, it's all good that you're trying to, let's say,
*  characterize, you know, the firing rates of V4 cells and their contribution to, you
*  know, chrominance detection or something like that.
*  But I was you know, but I was moved by the distinction that if you study that and you
*  have a very beautiful description of that level of analysis, it doesn't follow the
*  any good understanding of how color vision works.
*  Right. And so there's only various color vision turns out to be one of the few cases
*  where you do have good linking hypotheses.
*  So I was certainly influenced by that.
*  And, you know, since I started taking a bunch of linguistics courses, I was struck by how
*  successful that research program is to understand different languages.
*  Right. So when you start looking at so when you when you think about language when you're
*  in high school, you think, oh, someone who studies language knows a lot of languages.
*  Right. That's not what I mean.
*  I do happen to know some languages, but that that's it's about thinking of the problem
*  of language as a sign as a problem that's not different than looking at the visual
*  system and say, what is it that what does it mean to have that system in your head?
*  And so and what would a natural science approach to this mean?
*  So you want to know what actually is the knowledge of having knowledge of language?
*  So if you're a speaker of English or, you know, how some or, you know, worldry, what
*  does it mean as a speaker and listener of that language to have that knowledge in your
*  head? That means you have to have a theory of the vocabulary is what is it that you know,
*  what are the primitive elements or the atoms basically?
*  And how do these things interact to generate sentences, discourse?
*  And so how do you acquire that information?
*  How is it processed online and how is it implemented in the brain?
*  So very quickly, it became obvious that in the language case, these different levels,
*  they sort of graph themselves onto the sort of Mar and level of distinction, the sense
*  to say what linguistics proper gives you a sort of a characterization of the computational
*  system, a la Mar. Right.
*  So what is the stuff for?
*  What is the what is the nature of the knowledge that you have and what
*  psycholinguistics or computational linguistics give you is sort of the algorithmic level
*  of analysis. So the sort of what are what are the representations and computations that
*  underlie the set of phenomena?
*  And then obviously, neurobiology or cognitive neuroscience gives you the
*  implementational level.
*  So it was from the get go clear that if you're going to go down this path of research,
*  at least for me, you have to take this on board because you have to make clear to yourself
*  in this particular project or question, what am I actually studying here?
*  Am I studying how this is acquired or how this is broken or what is the likely
*  computation allowing me this subprocess or which brain region?
*  And so you have to be you have to be a pedant.
*  You have to be a conceptual pedant.
*  Otherwise, it's serious trouble in a hurry.
*  And the thing that is, you know, let's say what's my biggest turnoff,
*  I'd say is correlation.
*  So if everything just becomes correlational, it's just like, yeah, that's great.
*  But I mean, then I'd rather like, you know, do something else.
*  If you run an explanatory account, I have a my yearning or I think our
*  yearning is a field should be higher.
*  It shouldn't be like, yeah, I correlated four things.
*  Yeah, good for good for you.
*  I mean, I think we want to know more than, yeah, some brain regions of this
*  and then some other thing happened over here.
*  Yeah, that's good.
*  That's I meant to start.
*  That's not to denigrate the wonderful correlations of you all report
*  in our papers all the time, all the time.
*  But is that our yearning?
*  Is that to me, that just should be the beginning of the research project.
*  But it takes years, man, years, years and years and years and years.
*  And then but it is, you know,
*  that that should be.
*  I take that for granted that you start that way and say, OK,
*  so now we know that there's something let's peel this onion now.
*  Let's figure out what this is really about.
*  And that's just that.
*  And you're quite right.
*  That does take years because sometimes we don't know how to ask the question.
*  Yeah, because we're lame, because people are dumb.
*  We are. We're so dumb.
*  Forgive the question. Speaking of dumb, dumb questions.
*  I mean, you know, you just mentioned that we want something higher.
*  We want something more out of it.
*  Why is it important to understand something or to be able to explain it?
*  I think it's an intrinsic.
*  It has intrinsic value.
*  So I'm not satisfied.
*  I mean, look, take all the stuff we're all sort of seduced by right now.
*  So my feeling about that is, you know, I'm optimistic about that as everyone is,
*  although it has clear limitations.
*  But looking at a slight from the outside,
*  does it mean that we've replaced
*  science that has been practiced with regression?
*  You know, is is regression the new science?
*  Or have scientists been supplanted by engineers?
*  And I mean, I think because our
*  let's say epistemological stance has changed to the extent that we say,
*  you know, it really what I count as success is prediction and model fitting.
*  Right. Right. And that I think is I think is extremely interesting.
*  Well, that's an engineering sort of metric of success, I suppose.
*  It's a clear engineering metric of success.
*  And it's doing great. Right. Can't be denied.
*  Stuff is amazing.
*  That being said, is that the notion of understanding
*  that we seek in the sciences?
*  And I think if you look at the history of science, I mean, I think it's not.
*  And so the question is, are we going down this interesting, different path
*  without a value judgment? I don't know.
*  I'm not. I'm neither a philosopher nor a historian of science.
*  But as an observer and practitioner, I do notice that we're going down
*  a different direction.
*  What are metrics of success are we going down an engineering arm?
*  That's fine, because, you know, the proof is in the pudding.
*  And there are a lot of successes.
*  But it does seem like at least in our area of research, we might be departing
*  from the epistemic foundations of the sciences that we embraced
*  for the last couple of hundred years, let's say, since the Enlightenment.
*  And that's maybe that's good.
*  Maybe that's bad.
*  But I think it's an observation worth reflecting on.
*  Well, I often when I'm reflecting, I often think that my desire
*  to understand something is purely selfish, because like you're saying,
*  all these metrics like solving the problem, that's very useful.
*  But it leaves something out to me, right?
*  Because I don't understand it.
*  But I think, you know, when I die, the goal for me is to have understood
*  something, and then that's just gone.
*  What use was that?
*  That wasn't very useful to understand something.
*  And I guess we all maybe have our own notion of what understanding is,
*  what explanation is.
*  And so for me, a key concept here is that of explanation and theory.
*  And I assume, again, naively, pre theoretically, that having a
*  having explanation requires a theoretical understanding of the domain,
*  whatever that domain is, whether it's, you know, quantum chromodynamics or,
*  you know, understanding a word.
*  And you have to make your own commitment to what you think
*  understanding is and what satisfies you.
*  And maybe and look, I have friends, colleagues who say I'm absolutely
*  satisfied by a model fitting.
*  That is the that's the work I want to be in and others that say, look,
*  that's not even that's not even wrong.
*  Right.
*  And the famous words of Polly.
*  I mean, it's just totally unsatisfactory.
*  And you're why aren't you thinking about the notion of explanation
*  or mechanism or account in the way, for instance.
*  So, you know, in addition to Mar, I have to say I'm quite taken by
*  the ethologist work of the 1950s and 60s, like Tim Bergen and Lawrence,
*  who they had none of the tools we have now.
*  But what they did have is, you know, they had their thinking cap on
*  and they were very, very careful observationalists and theoreticians
*  that they proposed hypothetical mechanisms for things.
*  And the things that were ecologically well motivated.
*  Right. So they weren't making up some weird ass task and saying,
*  well, what does this creature do in its naturalistic context?
*  Let me be super, super careful about trying to figure it out,
*  looking at all its parts and variables and then try to understand or
*  pause it in a theory, in a theory driven way.
*  What could be a mechanism? Right.
*  And they came up with all kinds of stuff that's, you know, some of it is super weird,
*  but it's cool. And it's an attempt at an account.
*  Right. And what the account means for them and what I would consider
*  a cool explanation is it posits a parts list.
*  It has a set of primitives,
*  which is a big deal and very complicated.
*  And that's the biggest, you know, what are your ontological commitments?
*  What do you think are the elements of the domain?
*  Then how do they interact to generate the phenomena that you're trying to explain?
*  And that's what we're trying to do.
*  I just think that's extremely bold and inspiring.
*  And I see what we're trying to do is a kind of not as successful version of that.
*  That is what I would like to know.
*  You know, let's say, you know, the fact that you can recognize a word is kind of amazing.
*  I'm sitting in New York and you're sitting in Colorado and we're talking over weird computers
*  and I'm saying the word, you know, concept.
*  And it goes right through and gets into your ear and goes to the right part in your head.
*  And the fact that that works is really amazing.
*  And the question is, what is its parts list?
*  So for that to work, what are the constituent elements that have to be in place for that tiny transaction?
*  You know, tiny sensory motor transaction that takes no more than 250 milliseconds to work.
*  So there's a lot of little parts in that and we don't.
*  And what are those and how do they interact?
*  And that would for me be a successful account.
*  And, you know, the question is, do we have it for any domain of cognition or experience?
*  And I think, you know, as I've written about a lot, there is very, very few that I find convincing.
*  Yeah.
*  Well, so that brings up just a ton of things here.
*  I just going back to the notion of understanding briefly.
*  So the satisfaction that one feels at their whatever they so the word understanding, right, that you use.
*  And it goes through the computer and into my ears and it lands in a particular part of my brain.
*  But it means something different for me than it means to you, even though we can talk about it.
*  And the target, even individually, the target of understanding changes as we learn.
*  Right.
*  You know, what it means to understand something actually changes as we study it.
*  So these are all moving parts, right?
*  So they're moving parts in the sense that, for instance, the sequence of sounds of the word understanding can arrive in your head.
*  But of course, its contextual contingencies are different in your head than in my head, because, you know, you've been thinking about understanding for the whole morning and I haven't understood it.
*  We have all kinds of statistical contingencies, theoretical contingencies, biographical contingencies.
*  So not only does the correct item have to arrive, it has to arrive and then be contextualized in its thing, which means whatever its format of representation is, it has to integrate into all the other junk in our heads.
*  What you had for breakfast and what you what your favorite theory of understanding is and which philosopher you think sucks.
*  And all of that happens on the fly.
*  Yeah.
*  That's unbelievably efficient.
*  Yeah.
*  It really is.
*  So in researching you and preparing for the show, I've been thinking about levels from the Marr perspective.
*  And we don't have to stick with Marr, but it's just it's the one that most people know.
*  It's a very, I mean, well, it's a useful way to sort of summarize the issue effectively.
*  I think other people have thought about this and written about it in a similar way.
*  But I think Marr sort of captured it in a simple and easily graspable manner.
*  Yeah.
*  So, I mean, the major thing that was contributed is that the computational level.
*  Right.
*  And you were talking about Timber and these behavioral studies where you come at it from a theoretical perspective.
*  What is the behavior for?
*  And then that's how you go about figuring out the parts list.
*  Right.
*  And so it seems to me that our confidence in our own correctness should decrease as we go up the levels.
*  Right.
*  So we feel.
*  Why is that?
*  Why?
*  Because.
*  So I'll get to that in a second.
*  I'll get to it.
*  Because you're a sensory imperialist.
*  Because you think the clearer you are to the sensory surface, the more confident you are in the encoding.
*  Well, I think that you can.
*  So in the case of like a behavior, like let's say bats flying in the night through the forest or something.
*  Right.
*  When you start to ask the why question, why do they do that?
*  Or they do that in order to find the mosquito or whatever.
*  Well, why?
*  So that they can fill themselves and then be more likely to mate.
*  Why?
*  And you can keep asking why.
*  Right.
*  But then I think the more you ask why, the more they become just so stories that that we're really conjecturing.
*  Whereas in a, at the implementation level, we can actually measure did the spike happen, for instance.
*  And I'm not saying that that makes implementation level better.
*  I'm just saying that I think that the level of care I'm asking.
*  If you think that the level of care needed to approach these things needs to increase in our confidence needs to be a little lower in our stories and what we tell ourselves why these behaviors happen and what we're actually studying.
*  What the.
*  Yeah, I think you're deeply wrong there.
*  Good.
*  I think the sense that there's a presupposition that there's a different amount of care or that the standards of evidence are different in terms of higher level versus putatively lower level things.
*  So that's a kind of, well, it's almost a dirty word in my world, but it's a kind of reductionist thinking.
*  We can't.
*  So, of course, it's true that directly measurable things like spikes give you some confidence that a measurement was made.
*  But how is that actually better or deeper or more convincing evidence than an observation of some further some other?
*  So my point is this.
*  I see.
*  Evidence is just evidence in support of some position.
*  And it can for some kinds of approaches, you need spike based evidence.
*  And for others, you need observational or whatever it may be for the behavior.
*  And there is no hierarchy of evidence.
*  There is no sense in one kind of evidence is better.
*  I mean, it is or it is not consistent with or points to something.
*  And so I so assuming that one takes the same amount of like just rigorous and quantitatively well motivated approach to different levels of stuff, there's no reason to believe that the implementation level is in some sense a better foundation than another level.
*  Right.
*  So let's say to be specific in my own research on auditory perception or speech perception, we measure people all day long using different neural techniques, the ones we have available, warts and all, right?
*  Your limitations.
*  But there's clearly no sense in which that evidence, which we collect, you know, which is expensive and hard to get and requires a lot of analytic toolboxes is better evidence for a position than carefully done psychophysical characterizations of the process.
*  So quite frankly, take the case of word recognition, we understand a lot more about word recognition from a few decades of really beautifully done behavioral work than from the last 10 years of neural work.
*  That's been sort of consistent with this or that position.
*  But the real kind of nuts and bolts about that system, what we know of it has been beautifully characterized by just very clever studies by a bunch of people for the last 30 years or so.
*  We're like, wow, what a cool and clever idea to study that.
*  And so that's really characterized the elements of the process, you know, whatever the putative parts and the putative algorithms.
*  And that allows us to probe the neural system.
*  So in the case of the paper that John and Asif and Malcolm and that we wrote together, part of our point was simply to say, don't forget that you have the luxury of these amazing data to guide the process.
*  The systems neuroscience of the cognitive neuroscience, you have it as data that are as valuable.
*  And if you have a really beautiful and let's say, quantitatively well characterized description of some process, why not capitalize on it as you're designing your single unit study, your ECoG study or God knows what it would be.
*  You're missing out by thinking about it the other way around.
*  Let me assume that the process reduces to my neuro measurements.
*  Who's to say?
*  Who's to say, by the way, that the single neuron is the, you know, the arbiter of all things or the spine or whatever?
*  Maybe it'll turn out in 50 years that it's some weird, you know, a seven some of cells.
*  Right. So people have talked about, you know, a canonical cortical microcircuits or motifs.
*  Those are interesting ideas, but we just don't know.
*  It could turn out to be some other thing we simply haven't thought of.
*  It might be, you know, this this agglomerate, you know, this these five spines plus those four cells in this particular arrangement are the elemental units.
*  Right.
*  Yeah.
*  Say, I'm surprisingly happy to be deeply wrong.
*  I think we're actually talking about different things because when I, you know, for instance, if I study the synaptic mechanisms, right, like a pre synaptic mechanism for it at its own for its own sake, not in terms of how it contributes to bad behavior.
*  Okay.
*  Then then I feel highly confident that I'm measured when I'm measuring is an accurate reflection if I do it 12 times and take the average of the voltage across the membrane and how.
*  So for so I mean, so for a pure characterization of a particular, let's say, implementation mechanism, like a.
*  Yeah.
*  Synaptic mechanism.
*  Yes.
*  Yeah.
*  But then if I go up and I and then I it's it's it's harder to think and I think this is why you're talking about these amazing, careful studies.
*  It's harder to think about the ethylogical validity and needs and what things are for right.
*  The teleological almost.
*  And that's in my head.
*  That's why I think, oh gosh, we're more I'm more likely to be wrong when I try to conjure reasons for things happening, the reasons for the behavior at that level.
*  But I mean, I think I understand your your your your but the maybe I think it's because we're talking about the question from the perspective of why.
*  Yeah, right.
*  And I don't ask that question that way.
*  Yeah, because that that teleological position gets you into trouble in a hurry.
*  And so you don't I mean, so we can speculate on why.
*  But I mean, we're trying to figure out just how does it work?
*  Right.
*  How was the right question?
*  So for me, so for instance, in terms of let's say, you know, let's stick with a simple example of spoken word recognition, because it's easy to get your head around what you're trying to do.
*  I mean, I assume there are good reasons why you recognize words, but we don't even have to ask the question with that sort of teleological tinge.
*  We can simply say, look, you have to do this set of transformations.
*  It comes in one data format.
*  A bunch of stuff happens in the brain.
*  It gets translated into some data format that actually has the following consequences.
*  Namely, it can be written into memory.
*  It can connect with other representations.
*  It can enter a sentence and God knows what.
*  So you're accountable to those operations.
*  Those are the things you have to figure out.
*  And so it's hard enough to figure out how even parts of that might work that we can punt on the why question.
*  Yeah, I'll leave that for my colleagues in evolutionary psychology or evolutionary speculation.
*  Oh, man, you're conjuring up some Terrence Deacon here.
*  I can feel I actually I remember this is I distinctly remember learning the word teleology from my father.
*  And since I think we were talking about eyelashes or something and he said, what do you know, what are they for something?
*  And I said, oh, they keep the rain out of your eyes.
*  You know, I was young and he's like, son, that's a teleological statement.
*  And then he taught me what teleology was.
*  And since then, it's been a really dirty word in my mind.
*  You know, it's filthy.
*  Well, so but I said Terrence Deacon because he uses that he uses the concept of teleology and other people have to and sort of have tried to taken the sharp edges off of it and equated it more with function rather than the why.
*  Yeah, there's a kind of soft core teleology, which is, you know, let's say topless teleology.
*  That's not that that loses its sort of logical bite.
*  And the thing is, the you know, these guys are like Terry and colleagues that they're super educated evolutionary biologists and they know more about all the potential nuances and mechanisms than I do.
*  But I just I wonder whether it's ever necessary to invoke it when we're talking about biologic.
*  I mean, we're all evolving all the time.
*  You know, we're we're one current endpoint of a whole bunch of organisms that are currently around.
*  There's a bunch of we're there.
*  There's no ladder, but there's a kind of coral tree.
*  Right. And so we went down this interesting path.
*  So and teleological explanations seem to me largely unnecessary at the moment.
*  I mean, we can wait for that again.
*  I'll wait for the movie.
*  I mean, we have a lot of heavy lifting to do just giving an accounting of how the stuff works.
*  It's a complicated place to have.
*  Right. I mean, forget the language stuff.
*  I mean, we're trying to figure out things for which we have wonderful animal models like, you know, how come you were?
*  Well, actually, let's let's take the example that's sort of parallel in the vision case, which is object recognition.
*  Yeah. So there we have animal models, we have computational theories and we have all kinds of stuff.
*  But there, too, we have problems and tricky bits about figuring out visual object recognition.
*  And spoken word recognition is not that different, except we don't have the luxury of the animal model.
*  So we don't have, you know, 30 to 50 areas in the visual system.
*  Yeah, right.
*  It has to do with what we have.
*  But the end point is not that dissimilar as we try to create a representation that's amenable to being stored, combined with other things retrieved, also that has invariant properties,
*  because you can recognize it from different viewpoints and different contexts, different illumination conditions and so on and so forth.
*  So that's very similar to the language problem as well.
*  The problem of invariance, which is nontrivial, to say the least.
*  And so, you know, are we better off?
*  I mean, I don't know.
*  I mean, the language, the spoken word recognition case and the object recognition case are not that different.
*  We're kind of struggling in both.
*  I mean, we have one.
*  So let's take the current, let's say the orgy of AI models.
*  Great classification performance.
*  But that is not a, you know, equivalent to what we have as a mental mind slash brain representation of an object that we can insert into inference, not just classification.
*  No, I'm more than just cat.
*  Yeah.
*  You know, it's just more going on.
*  And so we come up against clear limits.
*  And the spoken word case is just the same.
*  There's amazing systems now for automatic speech recognition.
*  They're really their performance is awesome.
*  Compared to, let's say, 10 years ago, it's cool.
*  But that's not the same.
*  Having solved that engineering challenge is not the theory of the mind and brain.
*  That's just not the same ballpark at all.
*  So, I mean, while I'm totally impressed, I still, you know, we still have our work cut out for us in terms of the theory of psychology in neuroscience.
*  Yeah, it makes me want to jump straight to that topic.
*  Let me I'll try to hold off, though, because I have a question.
*  I still want to get through a little bit of terms of levels if you're with me.
*  Yeah, because there's a lot of stuff to talk about.
*  There's a lot of stuff to talk about in general.
*  So I appreciate your time.
*  The level thing is a really I think it's a deeply interesting and serious problem.
*  And so it's in some sense.
*  Look, so people who come to my lab, students or postdocs, I always, you know, invariably there, they get sick of me within a week because I carry on about bar like a like some kind of weird, you know.
*  And I think it's important, you know, and then you're welcome to disagree about these things.
*  But I think it's really important to get your head around the nature of the problem.
*  And I think it's disingenuous not to be very to point that out right away that, you know, regardless of whether you're here to do a neuro, you know, you want to do some fMRI or some MAG studies on this.
*  You have to tell me how it is that this relates in some systematic principled way to the problems that we're trying to actually grapple with, which are at a different granularity.
*  And it's just not I'm just not game.
*  You say, look, I recorded this cool, you know, evoke response or oscillation or God knows what, unless you tell me how it relates in some principled way.
*  Yeah, the punitive representation in your head, which is also well motivated.
*  So I'm just not willing to play until, you know, obviously we then proceed.
*  But you at least have to have a sort of self awareness that different levels are different and finding good links.
*  And that doesn't mean reductions, by the way.
*  That means sort of unifications between levels is extremely challenging.
*  It's just not a gimme.
*  So linking the levels is a case where two outcomes are interesting.
*  Both outcomes are interesting.
*  It would also be interesting and maybe more satisfying in some senses to find a linkage.
*  What do you would be more interesting and what do you secretly hope the answer is?
*  And so I think which let's say for language.
*  I'm totally vanilla on that part.
*  I think it would be blown away if we had a story where we can identify some cellular property or circuits that implements a particular computation that in turn leads to things.
*  So I have a very specific example that animates me that I've written about occasionally, which I've always had great admiration for.
*  And that's the case of sound localization of the barn owl.
*  So that is not like word recognition.
*  It's to some extent a slightly simpler problem, but it exemplifies, I think, the Marr levels quite beautifully.
*  And this is, of course, work famously done by Catherine Carr, Mark Konishi and colleagues.
*  And the reason that's an interesting problem, well, it's just a cool problem.
*  So barn owls have to do sound localization in the dark, as do their prey.
*  So let's say you're some mouse running in the barn and it all happens in the dark.
*  And the way sound localization works in these critters is by basically temporal cues in the auditory system.
*  So you can, let's say, do as the move the localization around some angle because of time differences.
*  So there's a lot of ways to solve this problem from a mathematical or engineering point of view.
*  So how do you point the cannon somewhere?
*  And what I found so elegant about this is that behavior is well characterized by ethologists and by people just watching what's going on here.
*  And then there was a very particular algorithm advanced a long time ago to solve this problem, which is a so-called Jeffress algorithm by somebody named Jeffress in the 50s and 60s who said,
*  look, there's a very clear circuit that does this for you in a straightforward way, which takes delay lines from the two ears as a set of delay lines, and they converge on a set of coincidence detectors.
*  And that's all it takes.
*  So you have a delay line set up and they converge.
*  Then depending on which coincidence detector cell fires, you've now translated interaural time differences into a spatial code.
*  And when that cell fires, it tells you to go three degrees to the left or right.
*  So super simple.
*  I mean, the math is simple.
*  The wiring diagram is simple.
*  But why is this such a...
*  So that's kind of the computational level of analysis.
*  So your goal is point yourself to whatever, lunch.
*  Point yourself to lunch.
*  Or dinner.
*  Whatever your meal is as a barn owl.
*  Oh, yeah. Midnight. Yeah, midnight meal.
*  Point yourself.
*  So the problem is very well defined and it's computationally well defined.
*  And there's, of course, other algorithms to do this.
*  But that was one.
*  And the beautiful work that was then done by Kahn and Konishi over many years is they said, okay, so if this is true, I should be able to find a circuit in the barn owl auditory system that reflects exactly that.
*  After years of extremely clever biology and physiology, they identified precisely that circuit.
*  So they found in the avian brain the set of delay lines and coincidence detectors that are wired up exactly to give you that.
*  This is the calyx of held, right?
*  Maybe the coolest name of any brain structure.
*  Yeah, no, actually the superior olive.
*  Superior olive. Not nearly as cool.
*  Best brain structure is the superior olive, obviously.
*  So but then what's nice is that that particular circuit is in some sense a direct reflection of that thing.
*  So now you have an accounting at the computational level of behavior, in particular algorithm was suggested, and that algorithm is actually implemented in the specific circuitry that's observed.
*  Yeah.
*  So that's a really beautiful account.
*  And then you can spritz that stuff on the thing and you can manipulate it backwards and forwards.
*  That's real understanding in this sort of mechanistic sense.
*  Now here comes the thing that is really the pièce de résistance of this research.
*  So in a very beautiful review by Benedict Grote on sound localization, he then summarizes this literature and raises the other point, makes the story even more beautiful and gives you the sort of mar par excellence thing.
*  Now compare the circuitry of the mammalian brain that solves the same problem.
*  They're also from the prey's ear view.
*  So you're trying to not get eaten.
*  You have to sound localize the bar now.
*  Solves the same problem.
*  Right?
*  So sound localization, let's reduce it just to the azimuthal plane for now.
*  Gets the temporal information in two ears.
*  What's the circuit there?
*  It's a different one.
*  Because it's a different algorithm.
*  And then, of course, being able to trace all that.
*  So now you have.
*  So why is this so cool?
*  You have at the computational level, and I'm going to go back to that.
*  So this is a very interesting discovery for you.
*  You have at the computational level of analysis of these two creatures the same problem, right?
*  So they have to do sound localization with the same kind of cue on the same time scale,
*  same ethological contexts.
*  There's different ways to do this problem from an engineering or math point of view,
*  and you go in and you do the implementation and you find precisely different circuits implemented.
*  Yeah. So you have a particular set of a particular arrangement of anatomy and physiology
*  that is a direct implementation of an algorithm, which itself forms the basis for the behavior.
*  I mean, that's about as good as you're gonna get. Yeah. Yeah. And so my...
*  What would really work for me is if I could find some example of that in this Petro language.
*  Go literally from soup to nuts from the signal to the intermediate representation to the algorithm that generates the right representation at the end.
*  That would be golden, right? I mean, that'd be cool.
*  That's, you know, I won't hold my breath, but you know, I'm...
*  I'm optimistic. I'm crazy enough to think it can be done.
*  Do you think that we will ever know how it feels like anything at all to be alive?
*  I have a solution about that.
*  You do? What is it?
*  Your brain is like
*  thinking about stuff.
*  And then there's like a zap, like your body moves.
*  And then there's like a zap of light.
*  A zap of something.
*  What do you think? So you've written a lot about how like the different levels could relate and interact and inform each other.
*  And I like, well, you've written about multiple ways of doing this, but one of the ideas is that the implementation level almost serves as just a constraint for the computational and representational level.
*  I kind of want to see what you think about that idea, you know, or just wax poetic about the idea of...
*  So the computational level of being eaten or eating something, right?
*  And then we have the neural architecture and the structures and the neurons.
*  And that is just sort of a constraint on the way the computations can occur.
*  Does that resonate?
*  Yeah, no, I think that's right.
*  I mean, you have the neural infrastructure you have.
*  For now. For now.
*  For now. Yeah. I'm augmenting daily.
*  There you go.
*  A new chip.
*  Well, let me discuss that from a slightly different angle, which is because there, I mean, this is, you know, a little bit more of a current issue, but it's in the same flavor of sort of linking across levels of analysis.
*  That's the issue of oscillations and oscillations, which is a kind of topic that simultaneously sort of elicits excitement and disgust and depends on who you're talking to.
*  So then it's a topic that has split the field a lot, right?
*  So there's a lot of people who are really fundamentally excited about it on board and sort of exploring it in different ways, literally from intracellular recordings to, you know, high level systems.
*  And then there's a substantial contingent about colleagues who are deeply skeptical about that.
*  I mean, my favorite line is it's the exhaust fumes of cortical computation, it's epiphenomenal and so on.
*  And I think, you know, my own view at the moment is that really the evidence in favor of a kind of interesting role outweighs the evidence against.
*  And so I'm sort of on the probe.
*  I'm interested in exploring more about what oscillations might mean for perception and cognition.
*  So what is that?
*  So why, you know, why, how does it fit into the discussion?
*  Well, in the sense, so I assume that where does this stuff come from?
*  So the stuff is really old from an evolutionary or phylogenetic perspective.
*  It's not like we invented, you know, excitability cycles in physiology.
*  That's something that's so that's something that comes from biophysics.
*  Right. So there's, you know, there you can, I don't know, people like Nancy Coppell does, you know, mathematical modeling of these things is extremely elegant treatment of these things.
*  Or, I don't know, my colleague, Yuri Buzhaki, has worked on this at every possible level.
*  So these are old physiological observations.
*  And so there's just something.
*  So the question is, is there something to account for or is it just some kind of weird matter?
*  And, you know, the does it matter whether you're intracellular or whether you're an LFP or an EEG recording?
*  I've gotten it right. So now in your case, MEG, right?
*  In our case, it's primarily.
*  So when we do this kind of work, yeah, we're really focusing on MEG or EEG or sometimes ECoC because those are the things we have available for us in the human case.
*  And so my assumption about this is that nothing is invented here for the case of speech perception or cognition.
*  These are these are just physiological properties that are there as a property of the biophysics.
*  And so those are the kind of off the shelf mechanisms that are excited, physiological excitability cycles that are, you know, and they're really I just, you know, borrow from someone like Nancy Coppela.
*  But what are the biophysical principles of this that gets pretty hairy in terms of, you know, what exactly is going on?
*  Yeah.
*  And now suppose it's there.
*  Would you, if you're a perceptual system, build on that or not?
*  Well, if it's a big signal, then it would be very odd not to.
*  So the question is, do you if you do, then what could it provide?
*  What at the very most what it could provide is some kind of, let's say, for instance, in this case, a temporal constraint.
*  You could say, look, if I have excitability cycles of a certain mean frequency, whatever, let's say five hertz or something, then it's interesting.
*  No, that would mean that you have some kind of set of processes that you want to basically be done then.
*  Now, it doesn't matter what it is for now, but it says if, you know, if that's your excitability cycle physiologically, then you want to have and then that's basically like a chunking rate or integration constant or whatever you want to call it at that rate.
*  So it doesn't tell you what the computation is, but it gives you a very clear temporal constraint.
*  In this case, maybe also spatial if it's, you know, across populations.
*  That's right.
*  It says, look, it is what it is.
*  This is these are the Lego blocks you have.
*  And whatever you're doing, it better fit into this because this is what I'm turning off because this is when my, you know, amp I shut down or my, you know, my ion channels are open or whatever.
*  So, I mean, the so instead of being sort of purely epiphenomenal, if it's a physiological signal that's been there and it has been there, you know, it's there across all creatures and so on right across, then it seems very weird not to use it since it's a very big signal.
*  And so we've exploited what it might be used for.
*  And so in this case, what a study of the implementation level alone, right.
*  So this is just looking at physiology, waxing and waning says, well, what kind of what kind of sort of formal constraints am I providing for an algorithmic or computational analysis?
*  And so there my conjecture is what I'm providing is a time constant, a time constant that's it's not periodic, but it's sort of within a distribution that says, you know, if I'm happening within this distribution, I'm somehow unit.
*  So it's like a sampling rate or it's, you know, whatever you want to call it.
*  And there's different metaphors we can use.
*  But so the suggestion is that a very methodical analysis and characterization of the implementation level here provides you kind of guideposts in which way to look for what kind of algorithms might be the right thing, what kind of units of representation, what kind of time courses and so on.
*  So I think that's not crazy, honestly, and I don't think it actually conflicts with the importance of impulse responses of non oscillatory phenomena.
*  I don't see that every time you mention the word oscillation to people, this is like a red flag, the gal go crazy.
*  So one of my friends here I was actually meeting with before we started talking, Tony motion, who's in my, you know, just goes ballistic on this.
*  We already had like practically came to blows already this morning on this.
*  So I just don't see any any it's not like teleology.
*  It's not a dirty word.
*  It's just a description of a phenomenon and it's incumbent on us to figure out what is this about and does it have causal force and does it matter for perception and cognition?
*  And my answer for the moment is yes, it's half of course.
*  And so that's it.
*  Well, let's tie it together because this is sort of a main.
*  I mean, we might as well just talk about about your work on linking these different levels right with in the world of oscillations.
*  So, I mean, you know, I started the podcast off trying to beat your four to five hertz limit.
*  And, you know, maybe I'll.
*  So well, so I'll just say like the linking hypothesis is that you have these neural oscillations.
*  And what you have found is that as waveforms come and hit our eardrum, the the neural oscillations link up well with the waveforms that are hitting our eardrum.
*  Yeah. And not only that, that then you can take it a step further.
*  So that's at the syllabic level, the syllabic scale, the scale.
*  But then you can join these things together in slower oscillations, right, because you have to link multiple things together and that these eventually lead up into meaning in our mind at oscillations and that's all great.
*  Yeah. Yeah. So you want to just talk about that?
*  You know, that's sort of the grand picture, I suppose.
*  Yeah, I mean, that's what well, that's one of the ones where we're trying to be explicit about, you know, how do you go from, you know, the parts at one level to the parts at another level?
*  And so I think we have a pretty good story for the input level.
*  So as you know, we're having this conversation.
*  If I take that signal and I analyze the signal of our conversation or actually any conversation, because we've done that already, as have many other labs, by the way, and we just then this is a well-known observation.
*  The modulation of speech is so the physics of the speech signal is remarkably regular.
*  So it's between four and five hertz and it's peak is the peak in the module, what's called the modulation spectrum.
*  Right. OK, so that's just fact one.
*  Now, suppose I take a brain signal like that and I squish it into the brain, which is what we're doing right now, and then I record your brain activity.
*  As it turns out, an experiment that has been going on for about the last, by now, actually a dozen years across a large number of labs, it's now been quite well established that cortical activity actually ends up in the brain.
*  And then it then trains to that signal.
*  That is, the underlying activity very faithfully tracks the up and down or the modulation of the signal.
*  So now first, you know, you have to be want to be a little bit Catholic here.
*  It doesn't or Catholic.
*  It doesn't follow from that. So if you track a signal, it doesn't follow from that, that it's either an oscillation or an evoked response.
*  There's many different mechanisms to track a signal.
*  And so that doesn't fall. So that's its own research program.
*  So one research program, which people in my lab here have been working on, too, is is is that really is this kind of tracking mechanism.
*  And that's, by the way, ubiquitous. You can we've done it with ECOG, EEG, MEG, you name it.
*  With music and you can see it in a single trial.
*  So this is not like, you know, this is nothing particularly fancy in them.
*  So the question is really what's a good account of it physiologically?
*  They were open. And in fact, we've had big debates in my own lab about this.
*  I have some postdocs who are strong evoked as everything people.
*  Most of us are strong oscillation people.
*  So we have a we have a muscular lab meetings.
*  And the we're just good fun.
*  At the moment, the data suggests actually that you that a pure evoked model alone is insufficient.
*  And so you must have at least a rich component of oscillation.
*  So that's that's one line of research.
*  Now, suppose, OK, so suppose we have a regular signal and you turns out you have oscillatory activity of the same rate, which turns out to be called the theta band conventionally in physiology.
*  That's interesting. So now you have a brain signal that's at that rate, a speech signal at that rate.
*  But who gives a shit? Does anyone care?
*  Well, it turns out and this is why I want you to care that that is the mean duration of syllables across all languages.
*  So that the plot thickens, it's kind of cooler.
*  What does it mean? Well, what does entrainment do for you?
*  Entrainment basically is a chunk.
*  So if you if you entrain to something, it gives you basically the chunk rate of the item.
*  And if the chunk turns out to be related to something that's actually behaviorally perceptive, cognitively meaningful, then you're in business because now you've extracted from the input waveform is some physical signal, some intermediate unit, which you can doubt.
*  Now you have to do some other complicated. You have to decode it.
*  Maybe through a predictive mechanism, you have to turn it into something useful.
*  But at least you've solved the intermediate step of what size chunk you need and what size chunk are you looking for from a computational point of view.
*  And that's pretty neat. So I can at least go from sound to the right kind of chunk size, which is syllable, which is a meaningful unit for us.
*  That's the smallest Lego piece.
*  Smallest Lego. Well, they're smaller Lego pieces, but that's the one we have a really good story for.
*  Now it turns out, of course, we're not interesting in understanding syllables.
*  You don't go, Bob, Bob, Bob.
*  But we put these together to create words.
*  So now we have, of course, a whole way of thinking about, well, what about if we put these things together?
*  So are there now intrinsic rates of brain activity that sort of allow you to to glue stuff together and tend to glue stuff together at higher orders?
*  And those are more, you know, slightly more finicky experiments.
*  But they suggest for the moment that the same kind of activity you can use to sort of create longer units to bind things together.
*  Now, there's a lot of that's pretty hand-waving because you need a lot of intermediate steps because to put words together, you need to find the word.
*  You need to find, can you connect to some other word?
*  Find it.
*  Then you need to connect them. Then you figure out what's the higher order thing. Can I connect to something else?
*  I mean, it gets when you try to actually write down for yourself step by step what's going on is kind of a lot.
*  It's not different from vision. You have to do a lot of stuff.
*  It's daunting. Yeah.
*  It's just a ton of intermediate steps before you get to the end game.
*  And it's it's just lame not to be concerned of those.
*  Yeah. And then you recognize this thing.
*  I'm like, then you recognize it. That's like 20 steps away, man.
*  Yeah. You recognize the thing.
*  So people are pretty cavalier about this, right?
*  When you're like, actually not so easy to do.
*  Like my favorite now is, well, it's just predictive.
*  Yeah, I tend to. Yeah.
*  I mean, that's it. It's an attractive.
*  It's an attractive. It's an attractive cop out.
*  I know I use it to cop out.
*  There you go. That's that's the phrase.
*  Predictive coding is like, you know, it's like everyone's answer to everything.
*  I mean, what everyone is interested in prediction, as you know, of course, because it's a very interesting thing.
*  But come on, it can't be the answer for everything.
*  I'm now I'm now in the I'm now after I'm I'm over prediction.
*  I'm now into post addiction. Oh, is that right?
*  What? Yeah. I mean, I think the predictive coding stuff is I mean, of course, there's anticipation, prediction, expectation.
*  I mean, that's sort of trivially true.
*  But you then have to fill it with with kind of representational meat.
*  I mean, what the expectation gives you is some kind of forwards predicted scaffolding.
*  But what do you put on there? Is it is the Cape Cod house?
*  Is it a castle? Is it I mean, the nitty gritty turns out to matter when you then use it in subsequent computational stuff.
*  I suppose in language, the predictive processing ideas are really getting thrown out.
*  You know, it's you know, we can talk about music and lyrics and music.
*  Right. Like, I don't know why why I continue to like Bob Dylan, because what what he's singing means absolutely nothing.
*  He doesn't believe it. He sounds like he believes it.
*  But I'm sort of like predicting my own story and then whatever he is singing maps onto whatever I have in my head.
*  Right. That's right. So there's this prediction mechanism going on there.
*  So there's a cop out, you know, but I mean, look, I mean, I don't want to belittle prediction and predictive.
*  Of course, it's an extremely interesting and important thing that, you know, a bunch of us are looking at.
*  It's just it gets a little tiresome when it's like prodded out for everything.
*  It's you know, it's as if when you go to a talk, if you don't say base and prediction, you're not even there.
*  Yeah, I'm like, I can play them. That's like, you know, I can do that.
*  That's I think we kind of cut your cut the story short on just your research and building it up to the level of meaning with the story.
*  Yes. I mean, so yeah.
*  So we have I think we have good evidence at the level of, let's say, perceptual encoding.
*  And I think there's so.
*  And incidentally, what it suggests, not just for for auditory perception, but I think it's true, you know, roughly for visual perception, that there's a sort of perceptual grain size for representations you entertain.
*  That's on the order of, you know, about 200 milliseconds or whatever, you know, 100 to 300.
*  And I think that's that's sort of the from a temporal point of view, the size of temporal representation that becomes the basis for whatever step you do next.
*  I mean, I think it's quite interesting, by the way.
*  So as I said, there's a linking hypothesis between speech signals, syllabicity that's extracted from that and neural oscillations in the state of that.
*  And I think that's cool. And I think it's a really good hypothesis.
*  It's quite interesting to me that that's also the rate the mean rate of eye movements in naturalistic settings.
*  Right. So I've talked a lot to, for instance, Beth Buffalo about this was a nice quantification of that in Macaque.
*  That's also the mean rate of just making psychotic eye movements when you're looking at a naturalistic scene.
*  So is that an accident that you make, you know, three to five eye movements per second?
*  Probably not. It would be a cool accident.
*  But the fact that you basically create temporal Lego blocks of a certain size that that are, let's say, easy to align might be something pretty deep, you know, because you have to solve the sort of multisensory alignment problem.
*  And if they come in the same grain size, that's way easier than if you have, you know, units coming from one dimension that are all a second long and others that are all 30 seconds long.
*  You're kind of screwed at the periphery. You might have very different time scales because there's different transduction mechanisms.
*  But cortically, in terms of the interpretation of the signal and creating, let's say, experiential primitives, you got to have a grain size that can align with each other.
*  And I think for that, this sort of rhythmicity is really well suited, whereas so things even very low, even very slow things.
*  So to go to the slow things, in the end, my job is to take a bunch of syllables become words and you stick them together.
*  Then, of course, the fun begins because you have to look it up in your mental dictionary.
*  You have to grab into the bag of words, yank the right one out.
*  How do you know it was the right one, by the way? Pretty complicated matching mechanism, which we don't understand.
*  It's predictive processing. Go ahead, though.
*  It's all pretty. It was trivially true. I predicted the correct.
*  Which is true, of course. So there is a lot of prediction about that because you have contextual cues.
*  This is the famous, you know, I drink my coffee with cream and and you nobody says feet or socks.
*  You say sugar and it's pre activated.
*  As you know, I have a we've written a couple of reasonably well known papers about what that means.
*  You know, these responses to be facilitated because you pre activate the relevant representation.
*  But you then have to assemble things and assembling things has to be at a time scale.
*  Obviously, that's slower than accessing them to begin with.
*  So there must be underlying time constants that form the basis of putting your Lego blocks together.
*  Right. So now I want to put two blue blocks together and two red blocks and two blue blocks are, let's say, a noun phrase like whatever.
*  Angry birds and the two red blocks are a verb like, you know, plays easily.
*  And so my job is to put the Angry Birds together and plays easily together.
*  And now I have to put the four some together.
*  So to put stuff together into an entire phrase that gets interpreted, not just at the individual word level, I have to assemble all of it.
*  So that time constant has to be even slower.
*  The question is, do you have some form of underlying time scale mechanism?
*  Maybe it's oscillatory. Maybe it's not. We don't know.
*  That actually provides constraints on what those time scales are.
*  So if you're within a chunk rate, you will be grouped together, structured, read out, decoded.
*  If you break that or you violate that, you might do something different.
*  That's an interesting research. That's currently an active research program.
*  People disagree wildly about it.
*  But it's a natural consequence of the stuff that we at this point pretty much agree on on the periphery.
*  So the peripheral mechanisms are pretty well suited.
*  And now, of course, this is an interesting case of a cross levels debate because we're now saying, well, the at the implementation level,
*  maybe we should look at other mechanisms that extend.
*  So maybe let's say Delta activity, cyclicity at the Delta level is a similar mechanism.
*  Then we have to show that. How does it link to things that are higher order?
*  Now the higher order is the physical signal like a syllable, but it's a kind of meaning signal, which you have to construct.
*  And so things get complicated in a hurry.
*  I mean, at some point you've got to get out of brain oscillations, especially when you're reading someone like Terence Deacon,
*  who writes these long run on sentences that are impossible to follow.
*  So what is the unit that you can?
*  So the unit is the one you make of it.
*  So the interesting thing about unitization, just like in vision, is you superimpose it based on your perceptual apparatus.
*  So the stuff comes at you and you say, look, you naturally draw boundaries.
*  I mean, in some sense, so take the case of, you know, in speaking one natural class of boundaries, the breathing rate.
*  I mean, by the way, an interesting and open question to what extent it correlates well with sort of mental units.
*  Because sometimes you're in your middle of your run on sentence, you go, and then you breathe in and you say the next thing.
*  It's not obvious that you do it. I mean, you do it at some kind of phrase boundary, but it's not obvious, actually.
*  So you take a breath and then a bunch of stuff comes out.
*  When you're done, you're done. And you have to.
*  So that is a break. But is that break actually congruent with the break of your mental unit and of the listener's mental unit?
*  It's a simple low hanging fruit study to do. I'm just too bored to do it.
*  Yeah, sure.
*  So, you know, if such mechanisms are, you know, are just part of the human brain, although it's part of all kinds of brains.
*  Do you use them by force because they're there? So are they unavoidable?
*  In other words, so again, you know, do they have causal force?
*  I mean, if they're there, I mean, there's a legitimate argument to be made that these are just an epiphenomenal or exhaust fumes.
*  But I think by and that's again the same is true for higher order things.
*  I do think that the. So, well, actually, let's be a little bit more careful here.
*  You know, as a neuroscientist there, I think the debates at the different levels of time scale have been about different things.
*  So a lot of debate about oscillations in their pro and con was well, it sort of has gone up and down over the decades.
*  But a lot of it about the gamma range is sort of, you know, the rate, let's say between 20 to 40 milliseconds or so, right, has been was fueled by the very influential hypothesis by by Wolf Singer on using synchrony, synchronous firing and neurons, single neurons for binding the visual system.
*  So the series of papers in the 80s and 90s by Singer and his lab and Gray Singer Singer and Gray Singer and Gray is probably the original.
*  I think I made that paper showing that synchronous firing across regions or even actually how many fields that was reflective of, let's say, properties of a receptive field.
*  And maybe the synchronicity was saying, OK, I'm binding whatever left visual field with, you know, verticality in my line or something.
*  Very influential, very interesting hypothesis with lots of interesting problems to I mean, who reads out the synchronicity of the cells and so on.
*  But I think that got people off on a very muscular debate on the role of that kind of oscillation.
*  Is it an oscillation? Is it there at all? Is it really the mechanism for perceptual binding?
*  And so I think.
*  You know, that debate has sort of gone away a little bit because the theory has a lot of problems.
*  It's been very I think I should mention that what I like about a theory like that is it may or may not be wrong, but it generated a lot of interesting research and debate.
*  Yeah.
*  It was one of those big idea thing where a ton of people said, I'm going to totally show it's wrong.
*  I'm going to totally try to find support.
*  Very, very.
*  A lot of physiological mechanisms were elucidated and cool experiments.
*  So, you know, and I think Singer himself said, you know, it turns out to be not really the right way to think about it.
*  But it was a very exciting and important research program that he that he was happy to be part of.
*  The so that was a debate on the sort of gamma band high frequency stuff in the.
*  Slightly different stuff happens in sort of intermediate range of the state of band activity, which we were talking about in the context of parsing speech.
*  And there I think there's considerably less debate about its kind of phenomenological realization, because partly it's just because there's so much evidence from actually stuff like hippocampal physiology.
*  That it's not something epiphenomenal in terms of the neural tissue.
*  It's just an observation about, you know, whether you court single cells or LFPs or whatever you're working on, you see excitability cycles and turns out extremely interesting theories about how that may or may not support hippocampal physiology.
*  And people have interesting debates, but there was no debate about the phenomenology.
*  And that's also true for cortex.
*  As people started measuring more carefully and saw this and that you know, then there were endless debates about how you measure it.
*  And is it just artifacts?
*  And I think people are a little smarter in terms of signal processing than that.
*  I found that a little insulting, but there are other legitimate.
*  You can, of course, we can all make mistakes in measurement analysis.
*  But I think by now it's established as a physiological phenomenon.
*  There are all sorts of biophysical models.
*  So now it's a question of interpretation.
*  So it's not a debate about whether you see period quasi periodic or quasi rhythmic fluctuations.
*  The question is, do they do anything?
*  So and that's where we talked about, you know, successful case in the speech case.
*  So I think that the gamma band is a little different than the theta band.
*  That in turn is different than very low frequency oscillations, which again is now we're back to the question, well, are they even there?
*  And if they're there, are they doing anything or are they just kind of the, you know, the leftover stuff?
*  I think that's actually currently an interesting area where people just don't know.
*  It's very difficult to measure in the human case.
*  These ultra low frequency, like let's say between point five and three hertz.
*  It's a shitty part of the signal.
*  You know, there's a lot of power there.
*  It's noisy as all hell.
*  The effect you predict a small effect size to begin with.
*  You're not predicting some enormous thing.
*  You're predicting fractional effect sizes in the case where the noise is huge.
*  So like you have to really be a clever experimentalist and an awesome signal processor.
*  Might as well be measuring fMRI at that point.
*  Yeah, that's ugly, but true.
*  Yeah, nasty truth.
*  Yeah, might as well go.
*  I mean, I think I'm sort of attached.
*  I think I like electrophysiology just because I like to think in terms of kind of the dynamics of stuff in time is excites me the most.
*  But it's there turn out to be real measurement problems there for the human case.
*  And that's a frustration too, because we have I think they're very clearly worked out hypotheses, models, theories, what have you.
*  But it turns out to be really a pain to do the best possible quantitative work and capture the stuff well just because we're not good at it.
*  We don't have a good we just have to be really, really do experiments a bunch of times, a bunch of different ways, replicate each other.
*  Do it across labs.
*  And my hunch is, you know, maybe another five or 10 years, we'll have a better maybe it's just that's that's a non thing.
*  It's possible.
*  Or we find some really compelling effects.
*  I mean, I have one paper now coming out that I think is a pretty strong argument in favor.
*  But, you know, I'll wait till it gets rejected.
*  Okay, good.
*  Brain inspired is a production of me and you.
*  You can support the show through Patreon for a microscopic two or four dollars per month.
*  Go to brain inspired dot co and find the red Patreon button there.
*  Your contribution will help sustain and improve the show and prohibit any annoying advertisements like you hear on other shows.
*  To get in touch with me, email Paul at brain inspired dot co.
*  The music you hear is by the New Year.
*  Find them at the New Year dot net.
*  Thanks for your support. See you next time.
*  You trust the sky.
*  You must like your lies from blue eyes.
