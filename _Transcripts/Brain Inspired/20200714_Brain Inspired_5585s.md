---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 5585s
Video Keywords: ['Science', 'Technology', 'Education']
Video Views: 3612
Video Rating: None
---

# BI 077 David and John Krakauer: Part 1
**Brain Inspired:** [July 14, 2020](https://www.youtube.com/watch?v=cy7PAo4kCaY)
*  I care that we are honest about what we don't understand and the limits of our methods and the limits of our frameworks. That to me is what's important.
*  I've come to the conclusion that there are two things that you cannot avoid if you are thinking about science.
*  One is you have to think philosophically and the other one is you're going to have to deal with complexity and its broadest conception.
*  I don't think you can escape either of those ways of thinking that go along with the more traditional notions of what a scientist does.
*  I just want to say I don't think mind emerges from brain. Mind emergently is engineered by an environment.
*  And that's the thing that I've always found missing in the mind-brain is the third part, which is I think it's pointless to talk about mind without talking about environment.
*  There seems to be a trade-off between collecting data versus actually slowing down and having a think.
*  This is Brain Inspired.
*  Hey everyone, I'm Paul Middlebrooks and those were the voices of two brothers, David and John Krakauer.
*  I've had John on before. He runs his Brain Learning Animation and Movement Lab, his BLAMM Lab at Johns Hopkins,
*  where their work circles around motor learning and memory, learning motor skills and recovering motor skills after brain injuries.
*  And David is the president of the Santa Fe Institute, SFI, where they use complexity science to study all sorts of things.
*  David himself has a wide range of interests that maybe all spring from a central interest in the evolutionary history of intelligence and information processing
*  at various biological levels from molecules to cells to collective groups to societies and beyond.
*  And you can hear David often on SFI's podcast, which is called simply Complexity.
*  So this is one of those episodes where I let it run a bit wild and take its own course, although there are a few main themes as we talk.
*  Those main themes are complexity science itself and its role in neuroscience, how to think about emergence,
*  and what are the right levels of explanation, especially in hierarchical systems like the kind we're interested in regarding intelligence and cognitive phenomena.
*  Cognitive phenomena from the simpler, like reflexes or making eye movement decisions, up to the highest order,
*  like awareness, consciousness, projecting your astral body, things of that nature.
*  We talk about understanding, and this is really just scratching the surface.
*  It's fruitless for me to list everything that we talked about, but maybe the best way to characterize the conversation is that it's about how to think about whatever you're working on.
*  We spoke for a long time, so I split the episode in two.
*  This first half is pretty broad and lays the groundwork.
*  The second half, which I'll publish in a few days, really heats up, and we talk more specifically about brains and minds
*  and what role complexity science thinking can serve moving forward.
*  I link to David and John's information in the show notes, as well as a few of the resources mentioned throughout, at braininspired.co.uk, slash podcast, slash 77.
*  If you value this podcast and you want to support it and hear the full versions of all the episodes and occasional separate bonus episodes,
*  you can do that for next to nothing through Patreon.
*  Go to braininspired.co and click the red Patreon button there.
*  This was especially fun for me.
*  I have an older brother, and John is David's older brother,
*  but my brother and I usually co-cogitate about things like the sounds and smells of our respective children, you know,
*  the latest embarrassing mistake either of us has made, and there's never a shortage there, and things of that nature.
*  So it was fun to witness David and John go back and forth on these topics of intellectual exploration.
*  And in many ways, as I expected, I sort of just pressed go on the crack hour machine and just tried to keep up.
*  Anyway, I hope that you enjoy it and it makes your world better as it did mine.
*  David, I've heard you talk about your conception of intelligence and stupidity.
*  And I don't know if you want to briefly talk about what those are, but you also talk a lot about entropy.
*  But when I hear you talk about intelligence and stupidity,
*  it maps directly on to what I've heard you say about increasing and decreasing entropy.
*  Is there a direct mapping between those two?
*  There's a relationship in the sense that methods of information theory that deal with concepts like entropy are useful in understanding intelligence and brains and so forth.
*  So I don't use it in the sense that, say, my colleague John Carroll would write in terms of the they might be related, but in terms of the entropy in the universe,
*  I use it quite operationally in terms of the reduction of uncertainty between a signaler and a receiver.
*  And so that's the common sense, I think.
*  But from what I understand, an intelligent process for you does decrease entropy, whereas a stupid process inherently by your definition of it seems to increase entropy.
*  Do I have that mapping?
*  Yeah, I mean, to the extent that when someone is teaching you something, you come to an efficient means of arriving at the right answer, right?
*  As opposed to a whole bunch of spurious answers.
*  And at that scale, you could say the entropy is reduced.
*  So very operationally.
*  But I don't I wouldn't overstate there's much more to intelligence and stupidity than just a very simple information theoretic measure like entropy.
*  It's just a part of it.
*  It's just a bit of arithmetic that you use to get at the questions.
*  Very good.
*  And by the way, welcome, David and John to the podcast.
*  John, welcome back.
*  And David, thank you.
*  The brothers crack our being here together.
*  This is a what a day.
*  What a what an episode already.
*  It's a horror.
*  It's a horror movie.
*  It's a horror podcast.
*  I'll have the background music going the soundtrack.
*  So, guys, let's talk about complexity first.
*  I just actually had Olaf Sporns on the show and he is a network neuroscientist.
*  And he has done a lot for introducing, well, complexity into neuroscience via networks.
*  And I think that neuroscientists can be hesitant about embracing complexity in their research because you're already dealing with, you know, a difficult and challenging area of study.
*  And then you think, oh, yes, complexity.
*  And then you sort of approach it and you think, oh, shit.
*  And then because you end up studying complexity itself, it seems like no matter what.
*  And then and then you're out of the realm of actually studying brains or you could end up that way.
*  There are a few different ways to think about complexity.
*  And I've David, I've heard you mention, you know, kind of slice it in multiple different ways.
*  One is that complexity is networked adaptive systems.
*  And so there are two words there.
*  Network is one of them.
*  And I had Olaf on and we talked all about that.
*  And adaptive is another one.
*  So it strikes me that all complex systems are both networks and adaptive by this definition here.
*  And it strikes me there are networks that are not complex because they're not adaptive.
*  So, for instance, a spider web or something.
*  I don't know if you'd call that adaptive, but you could consider every cross a node, for instance.
*  And that's not adaptive.
*  Are there adaptive systems that are not complex, though?
*  Are there adaptive systems that aren't networked?
*  You wouldn't consider a network.
*  And by the way, both of you just jump in because these are all questions for both of you.
*  Yeah. So possibly, I mean, you could someone might claim a thermostat was adaptive, but I don't think we treat it as a complex system.
*  I mean, there's a way of making this really simple.
*  And that is that many of us have felt dissatisfaction with the methods and the frameworks that people have been using to deal with a certain class of phenomena in the universe.
*  And that class of phenomena we call living.
*  I mean, we don't get into a big discussion about what life is.
*  And complexity science basically says that across many of these different living domains, and by the way, we would include the economy in that.
*  That's what makes us maybe a little different.
*  There are common principles and there are useful methods that can be applied to all of them.
*  So I think that's just a straightforward way of talking about it.
*  That's not mystical.
*  And it is very unfair, I think, when people who are disciplinary say, what's complexity?
*  Because if you ask a physicist, by the way, what's physics?
*  And you should try this because I have I always do this.
*  I don't want to do that.
*  Well, you know, because you don't want to do it because they can't.
*  And the best answer you get is we do back of the envelope calculations, which tells you absolutely nothing.
*  If you ask a biologist, what is biology?
*  They'll say, well, that's the study of living systems.
*  And then you ask them what life is, and then it goes horribly wrong.
*  So all fields have this problem of having an essential quality.
*  They're defined in terms broadly of the domains that they study and the methods that they use.
*  So do people really do you think that people have the notion that there's something mystical about complexity?
*  Is that the general response you get is well, it's worth getting at the history.
*  I think part of the problem is that very broadly speaking, there are two schools.
*  One of them is interested in determinism and deduction and pattern.
*  And it really goes back to Alan Turing in the 1930s.
*  OK, and that has its chronology through von Neumann and Stan Ulam and all the way up to John Conway, who just passed away.
*  And most recently, of course, people like Stephen Wolfram.
*  And they're interested in patterns and simple rules that produce them.
*  And that's one school. It doesn't have much to do with the adaptive world.
*  It's not really natural science.
*  It's a kind of logic that uses computation and mathematics.
*  There's another school, which is very much what the Center for Institute is.
*  And it's interested in randomness, empiricism, more interested in induction, and universality.
*  And for that reason, we were interested in economies and history and brains and genomes right from the beginning.
*  And those three elements are critical, in particular, how laws, natural laws or contingent laws, evolved regularities, exploit randomness to create function.
*  That's why information theory is important. And that's what we do.
*  We're looking for these constraints, if you like, or physical principles through which noise is filtered to produce things which have regularities that might be universal, meaning that we'll find patterns in the brain that resemble patterns in culture.
*  And that's our style of complexity science.
*  And in the end, it's only as good as the work that's done.
*  In other words, that's a very high level specification.
*  And we'll get into it, of course, today.
*  But I think you mentioned Olaf is a very good example.
*  Olaf is in more of the applied side, of course, uses network theory to study the brain is extremely useful and insightful.
*  And no one calls that mystical.
*  I mean, weird if they did.
*  So it comes down in the end to where the rubber hits the road.
*  And that, I think, would demonstrate that there's no mysticism involved.
*  I mean, that was an interesting thing, because I hadn't thought of the mysticism aspect of people sort of being wary of it.
*  It sounds like people are wary of it if they come in thinking it's mystical.
*  And maybe it's because it is.
*  It's still new.
*  It's complexity science is even is newer than neuroscience, which I thought was interesting.
*  The word, at least.
*  Yeah. Well, I mean, again, in that second tradition of randomness in induction and universality,
*  you have people like Claude Shannon in the 40s and Vena and others and Murray, of course, and Phil Anderson and our community,
*  Manfred Eigen, who were not considered mystical because many of them won Nobel prizes.
*  So I'm not quite sure where that comes from.
*  But I think what makes it in the eyes of many people suspect is, first of all, most people hate ideas, philosophy and theory.
*  They're just if it's not factual in the most mind numbingly obvious way, they're suspicious of it.
*  And the other is that they think it's a theory of everything.
*  And there have been people in my community who have made that mistake, actually.
*  And I think, to be honest, it's more of a crime in the first school, the sort of deterministic deductive school that looks for metaphorical correspondences in patterns.
*  You know, this looks like that. Therefore, I've explained it as opposed to this more inductive school.
*  I kind of get the sense when I, you know, watch you give a talk or read some of your works.
*  And I'm probably way off base. Is there a sense at the Sanitha Institute of almost pride in being an underdog?
*  Probably. We're all a bit childish.
*  So maybe I suspect that if you don't have pride in being an underdog, then you shouldn't be a scientist.
*  But what happens when you when complexity science comes to dominate and gain the respect of all of the sciences that it should have already gained the respect of and it already has.
*  Yes, fair enough. I don't think it's complexity science per se.
*  That's another issue, which is and John should jump in here.
*  There are personality traits that are correlated with new science.
*  I mean, Mavericks is one entire section of one of the recent books of a collection of SFI people that you put together.
*  You're absolutely right. You're right.
*  And I think that I do believe it's true that there are personality types that are drawn to novel frameworks.
*  They're not made uncomfortable by them.
*  There are many other people who are equally good scientists who are satisfied by recapitulating what has gone before and perhaps come up with discoveries that have huge depth.
*  I think that there is a personality aspect to science. There's no point denying it.
*  People were obsessed with Albert Einstein's hairstyle.
*  They were obsessed with Richard Feynman's brushing his teeth with his own urine.
*  We shouldn't deny it. It just shouldn't be confused with the quality of the work.
*  John, I don't remember if this is I don't know if you told me this last time you were on or if this was offline.
*  But I think that you mentioned that David finally sort of pulled you in and convinced you that that what you do is complexity science or you.
*  I don't know if he drew you in further and convinced you that what you do is complexity science or convinced you that you should come more toward the complexity science side of things.
*  Maybe you can untangle that.
*  Yeah, I mean, I definitely think there are moments where I find myself in my own work rediscovering for myself things that I could have just gotten a quick update about if I'd spoken to David in the first place.
*  In other words, I think he sort of kindly allows me to think that I'm thinking new thoughts when in fact all that's happened is that I'm beginning to see the light that has always shone from the top of that hill in Santa Fe.
*  And also, I think David, I'm trying to remember now when he talked about what complexity is, it's really.
*  It's really about hierarchical systems, levels of explanation, coarse graining.
*  In other words, it's not just about defining complexity, it's about recognizing that there are multiple disciplines and that there's something about the structure of knowledge and the ontology of knowledge that has to be subject to a way of thinking about it.
*  And complexity science covers in a way, Hasok Chang, who I spoke to about before in the philosophy of science, where he talks about going after those things that scientists in their everyday work or conceptual schemas pass by.
*  Yeah, and I think complexity science, I think, is the equivalent of that in so much that it addresses things that people have an inkling about.
*  They give it a side glance, but don't really want to have to tackle directly.
*  And I think if you become thoughtful about your subject as a scientist, I think I've come to the conclusion that there are two things that you cannot avoid if you are thinking about science.
*  One is you have to think philosophically.
*  And the other one is you're going to have to deal with complexity and its broadest conception.
*  I don't think you can escape either of those ways of thinking that go along with the more traditional notions of what a scientist does.
*  Does that make sense?
*  Yes, I think, again, I mean, it's really important and Paul asked that question about entropy at the beginning.
*  I'm quite serious when I say that complexity is as broad a church as physics, right?
*  In other words, it shouldn't be confounded with a method.
*  And I think John's absolutely right.
*  It's if we think about adaptive systems carefully.
*  Right from genetics up to economies, which we do.
*  That is what we do.
*  Then there are common principles.
*  And moreover, you have to be able to defend and explain why it's defensible to be an economist.
*  Right. In other words.
*  And this will get to it when we discuss emergence.
*  In other words, we think it's not only acceptable, but correct to have multiple levels of description and explanation and understanding.
*  They might not align, by the way, with the current disciplines.
*  And that's a very interesting fact.
*  I mean, we might have to reconfigure that space.
*  It might be that there's only two things or there are 10 things.
*  But John's right.
*  It's an approach to understand this domain of matter that exhibits purpose at multiple scales and an exploration of the kinds of ideas that work best at each of those scales.
*  And so it's a very broad church.
*  I think that's very important.
*  And it's it's not well, it's basically agnostic with respect to methods.
*  Correct.
*  Well, yes and no.
*  It's interesting.
*  I just didn't have the interview on this.
*  And yes and no.
*  I mean, where we get a little upset.
*  I mean, look, we're having this conversation now in a period of huge trauma in this country.
*  And many of my colleagues are involved in writing down mathematical models for epidemics.
*  And I did an interview yesterday where we were talking about what's missing from those models.
*  And those models, by the way, are crap if you're trying to explain what's happening to African Americans and Native Americans.
*  So it does matter what methods you use.
*  And I think a lot of these mathematical formalisms have been so beholden to the fantasy of parsimony that have been inherited from physics that they failed to address the complexity that we all with our eyes open see.
*  So we're not agnostic about methods.
*  We think it matters which ones you pick and that they are true to the phenomena under investigation.
*  When you get a well-rounded knowledge base in complex systems, because I think it takes a broad spectrum of knowledge to really I mean, I certainly don't have a good grasp of the entirety of what complexity is because it touches so many different realms.
*  And it does cover many different methods.
*  If it's not agnostic to methods, it at least has a broad swath of methods that it can employ.
*  It's agnostic regarding which is the correct whether there is a single correct method.
*  Its purpose is to correct pick the correct method given the problem, for instance, perhaps.
*  I'm just putting words in your mouth.
*  But when you get this well-rounded knowledge that is necessary in complex systems, does it make you know, does it sort of transfer?
*  Does it make can you can you hop around between complex systems and understand them using the same approach more easily once you have a broad base in that knowledge?
*  Does that make sense?
*  It does. Again, I want to say something quite subversive.
*  I mean, I believe I have the sort of same attitude towards complexity as I do to dentistry, right?
*  That I wish that teeth were all healthy enough that dentists could go away.
*  And I and I wish that we thought thoughtfully enough about the living world that complexity science.
*  I don't care about an area of science in the slightest.
*  I care that we are honest about what we don't understand and the limits of our methods and the limits of our frameworks.
*  That to me is what's important, much more than anything else.
*  Yeah, there's too much emphasis, I think, on this sort of what the last thing I would like to see happen is complexity become disciplinary.
*  I think that the Institute itself, for example, to the extent that it represents that world, has to be constantly mutating into some hopeful monster that can address difficult problems of the future.
*  I'm much more comfortable with the X-Men model of science.
*  I mean, there are common principles to complex systems.
*  And I'm wondering if so we're going to talk about its relation to neuroscience and the brain and the mind in just a moment.
*  And I found myself wondering if there are known principles from the study of various complex systems that have transferred from one complex system to another, such that you realize in the new complex system that you're beginning to study, you see where the actual holes are and where some principles from this previous complex system that you are that is already well studied.
*  Where some of those principles are supposed to fill in in these holes and be able to then predict what you might empirically find in the new discipline you're trying to study.
*  That was a big bag of words, so I apologize.
*  John, do you want to try that one first and then I can jump in?
*  Oh, I don't think I can be authoritative enough about another area outside of neuroscience to know whether it will lead to some savings in the way we apply it to neuroscience because we've learned it in others.
*  I have to believe that when it comes to physics, whether it's condensed metaphysics, solid state physics and what's been learned about hierarchical systems and emergence in physics, I must believe that the physicists could be of huge value to us when it comes to thinking about these things.
*  So Phil Anderson, who just died and the way he thought about the disciplines and the way he used examples from physics and superconductance, I find it extremely informative.
*  In other words, effective theories in physics and how they can be hived off to some degree from their hierarchical position.
*  Those are all hugely valuable ideas that I think neuroscience would benefit from, but I certainly have.
*  So all of that emergence, what is it called?
*  This disciplinary fragmentation that is ontological that Anderson talks about psychology and economics and biology and he believes those are real disciplines.
*  He has it in his paper.
*  Right. So we must learn from the physicists, I would say.
*  But maybe I don't know if David has to say about that, but I certainly do.
*  Well, I mean, I wouldn't give the physicists too much credit.
*  So I feel that...
*  Okay, they'll just take it.
*  No, I know. Well, look, I mean, I'm something a mutant. I'm surrounded by this.
*  I feel that there's another way of thinking about it, right?
*  That nonlinear dynamics, right?
*  You can't really do any modern science without doing some nonlinear dynamics.
*  You can't really do modern science without doing information theory.
*  And nowadays it seems that you can't really do neuroscience without talking about circuits or networks and et cetera.
*  And it goes on and on and on.
*  And of course, we've been working on dynamics on networks, you know, nonlinear dynamics since the beginning.
*  And so in a way, there's this natural diffusion of more advanced, I'd say, methods that hardly are restricted to the Institute, quite the opposite.
*  And you just look at the history of neuroscience.
*  There is a history that, and John, of course, knows it much better than I do and you do too, Paul.
*  But certainly if you think about McCullough and Pitts and von Neumann and John Hopfield and Bill Birleck and most recently people like David Munford and Carl Friston,
*  there's this obvious foment in new techniques and methods that they actually describe as complexity themselves, quite interestingly.
*  So it's hard to imagine any field evolving if it were not to be open to new formalisms.
*  And I actually think, I mean, that we haven't even started.
*  And we might get there.
*  And I think the emergence point that John raised is very important.
*  I don't think we have a clue how really to theorize about things like the brain.
*  And we're still in the descriptive phases.
*  But that's great.
*  Lots of opportunities.
*  Where do you think we are in complexity?
*  But again, you know, I think that it's a brand new area.
*  I mean, think about things like the use of maximum entropy approaches that Jane's first pioneered in statistical physics,
*  that people like Bill Birleck have used so effectively in looking at spiking,
*  that people like John Hart have used so effectively to look at ecology,
*  look at scaling theory that's been so effective in looking at allometry and so on.
*  This is, you know, a couple of decades.
*  And so you're right.
*  We're embryonic.
*  It still does.
*  It still does seem like it is a it is diffusing over that example just gave from from physics into other disciplines.
*  Absolutely.
*  But also mathematics and logic.
*  But yes, you know, I asked about it about certain principles transferring to new domains so that when you're exploring a new domain,
*  you might know what to look for.
*  You know, and you just mentioned scaling laws and, you know, you can think of something like scale free distributions
*  and how they are common among all sorts of complex network adaptive systems.
*  And, you know, indeed, you find them in the brain.
*  And I'm wondering, like, how many of the how many of these different principles are there that we get, you know, from a table,
*  go look and think scale free.
*  I should find that at this level when I look at the, you know, mechanical level or something at the spiking neurons.
*  I should find a scale free distribution.
*  And I do.
*  And, you know, how many of those types of things do transfer across complex systems?
*  I mean, I know it's very I'm not I'm not a lover of that kind of work, to be honest.
*  I view it as very descriptive and phenomenological.
*  In other words, it's true that it's intriguing.
*  Of course, there was a huge brouhaha when some of our faculty actually got very involved in small world networks.
*  It was then small world.
*  And now, of course, it's it's it's fat tailed and it'll be something else in a few years.
*  And I. Yeah, right.
*  But I have nothing against that because it's but it's really just shining a flashlight in an area that we have to think about much more
*  carefully, empirically and with much more fine grained models.
*  And so I don't like papers that pretend to report an insight just by doing fancy statistics, which is all you're talking about, by the way.
*  So, I mean, when people like Pebak and others got interested in, you know, parallel distributions around self-organized criticality,
*  they provided a model, the Sanpam model.
*  Now, it turns out that Sanpam model is wrong.
*  But nevertheless, it wasn't enough just to describe it.
*  So I think that some of that work tends to give complexity a bad name because it's a bit superficial.
*  It's where you begin and then you go and do some real experiments and generate some real theory.
*  I mean, somewhat is somewhat analogous.
*  You know, you talked about Olaf and, you know, Danny Bassett, who, you know, there are a lot of these metrics that can be applied to brain data.
*  But sort of to what David said, they tend to be very a theoretical.
*  In other words, you get a lot of descriptors of the connectivity.
*  But unless you have a question to ask, why should it be this versus this?
*  It's a beginning.
*  And, you know, Danny herself is sort of admitted.
*  How does one go beyond increasingly sophisticated descriptive statistics of networks to something that begins to sound like an explanation of something?
*  But you have to open the bag and see what's in the bag before you can theorize.
*  Yes. Yes.
*  But I just want to make that point.
*  You know, Danny is like John is one of our professors.
*  And so and I spent a lot of I know her very well.
*  But I would say that Danny's a great example of someone who did precisely that.
*  I mean, she said, look, there's some tantalizing statistical evidence.
*  Now let's go in there and and do control theory and do some experiments and do good science.
*  I mean, there's nothing surprising about that.
*  I think if you stop at the level of phenomenology, it's worst.
*  It's numerology. It's just finding patterns that are meaningless because they fall out of some very simple central limit theorem.
*  So, you know, oh, wow, I found all these Gaussians.
*  Well, of course you have because we know what happens when you add up random variables.
*  And I think that the we have to go further.
*  And I think a large part of what's happening in complexity science, that is that community of researchers interested in these adaptive networks have been doing just that.
*  I mean, there is just there's been a siren call for more theory in neuroscience now for I don't know, a decade.
*  I don't know when the I don't know when it really started to gain volume.
*  But the pushback to that would be, yes, of course, we need more theory, but we also, you know, we're just seeing data.
*  So you could think it's jumping the gun and expecting too much.
*  But we do need more. You know, any anytime I ask anyone that question, it's always yes, we need more.
*  Everything is is the how about we need more thinking.
*  OK, well, let's start thinking. So but I mean, what do you mean by that?
*  Because thinking to me means theory.
*  Not necessarily not at all. In fact, no, I don't feel that way.
*  Look, I mean, we've all been to talks, right, where we are sort of doused in vast quantities of visual data and you're sort of left drowning on the one hand in all of this information.
*  But with no question being asked, no lucidity in the way that the problem's been framed.
*  And one of Murray Gilman, who one of the founders of this institute, was extraordinarily critical of talks that did either of one two things.
*  A just presented data as if that was somehow science and B just did math.
*  That's not science either.
*  And I do think that there is a kind of complexity to the scientific enterprise that you have to be prepared to spend time to think deeply about difficult problems
*  and not look at the data for a bit and, you know, have data and theorize.
*  It's sort of laziness, I think.
*  And it goes into this whole sort of machine based science that you just take the human out of the loop.
*  And I think just thinking carefully and collaboratively for a long time without a paper in mind is a very good idea.
*  There is a trade off. There is a trade off.
*  In other words, you know, there's a wonderful book called James Bridal called You Dark Age, where he gives a very bleak description of the world that we're currently in.
*  But he gives beautiful examples of how utterly useless surveillance is.
*  Right. So now that all these cameras and all this data.
*  Right. And it doesn't work.
*  It doesn't prevent anything.
*  Right. So in other words, there seems to be a trade off between collecting data.
*  Versus actually slowing down and having a think.
*  Right. And so, yes, you can say, look, send out all your hounds have pluralism in the way that you do science.
*  OK. But don't say that when really it's an excuse to never really give a critical subversive talk ever.
*  And I think I remember I try to remember it was at a Gordon conference, right.
*  The last one. And I gave a talk.
*  I think it was. I can't remember someone said to me, you know, John, that's a very different kind of talk to what I'm used to hearing.
*  It's actually very interesting because I don't think that way anymore because I feel well, that's the way I give talks.
*  And I think that's the way they should be given.
*  But it's extremely interesting. He said, you know, usually people show their data.
*  Right. And it showed data. But he says that's but he wasn't saying I didn't show data, but he said, that's it.
*  And it's very difficult to grasp the context. What's at stake?
*  Why does this matter? How does it relate more broadly?
*  It's as though none of that matters. Now, of course, you can always say that they could if they wanted to.
*  They could give all that context.
*  But actually, I'm not so sure. Right.
*  Because synthesis is not something that is in any way taught or promoted.
*  And so, of course, you can get into sort of discussions about what counts as thinking, but you kind of know it when you see it and you detect more often than not that it seems to be absent.
*  Not everyone has the skill to synthesize.
*  I think that it is a master skill that, yes, is underdeveloped in at least in me and across the entire population broadly.
*  But I think that it is one of the more important and maybe underappreciated is maybe what you're saying skills because it's hard.
*  It's also about, you know, I was reading Oliver Sachs's essay on Darwin when he came back and his botanical experiments on orchids.
*  Right. It's an incredible essay. And what that essay exudes is the insatiable curiosity machine that Darwin was.
*  Right. And it's just like he was a scientist out of every pore.
*  Right. He just getting down onto the lawn to sort of look at the orchids.
*  And I mean, it's just this kind of question asking curiosity and experiment in one's head as well as literally.
*  And just that essay by Sachs on Darwin had more science in it than I've experienced at most talks.
*  Now, I don't know what that thing is necessarily, but you want that back.
*  But so there's a disciplined patience that comes along with with that, at least with Darwin and perhaps Sachs.
*  I mean, is that part of the special mix?
*  Yeah, it's an interesting question. I don't want to keep us away from some of these deeper scientific questions.
*  Sure. But I don't think we can avoid recognizing that the industrialization of science,
*  that sort of the penetration of thought by economic considerations and the obsession with citations and H indices,
*  you can't imagine that that doesn't compromise the quality of the enterprise.
*  Of course. Right. And I think that what John has described, I don't think Oliver Sachs gave a shit about a citation.
*  I don't think he would even know the word. He probably thought it was an aircraft or something.
*  So I think that the and I think that's important for everyone to bear in mind that it's a complexity problem.
*  Right. Culture, the economy bears on how we reason and the way in which we produce science.
*  And it would be nice and perhaps a bit idealistic if we could return to communities that were slightly less obsessed with the weight of paper and more interested in the quality of the concepts.
*  Well, that's what SFI is fundamentally as well.
*  It wants to be. I mean, it fails very often, but it wants to be.
*  And certainly from my point of view, supporting an institute like this, I'm absolutely committed to that.
*  And we go to the cross for that. But on the other hand, we live in this world that has these perverted values.
*  We had a meeting at SFI where these two worlds collided, Paul, last year,
*  where I very much felt like it was like the fable of the stork and the fox where they invite each other over and then it's impossible to eat the other's food because it's the wrong utensil.
*  Right. And I felt that was a meeting held last year on the brain, actually, at SFI, where these two kind of ways of trying to talk about a subject went up against each other.
*  And I'm not I'm not actually trying to be, you know, sort of bitchy for the sake of it.
*  It was it was really quite stark to see the discomfort in two very different ways of talking about the same subject, you know, wanting to be more broad, more abstract, maybe a little bit more formal, trying to sort of look across different areas versus let's stick to the data.
*  Let's know what we know. I mean, it was very stark.
*  Now, again, one shouldn't say that there's one type of science only, but neuroscience, I think, would benefit greatly from relaxing a bit and going for a walk and thinking things through across disciplines rather than this mad rush towards publication and data collection and substituting whatever science is, which is another hard thing to define with all its ancillary subjects, whether it's statistics or do you see it's it's.
*  In fact, we're trying to do everything other than the science itself.
*  I mean, that's an institutional problem. There's a lot of pressure on people to publish. Do you guys know your H index?
*  People remind me and it's disgracefully bad. I think mine people who are being mean to me tell me mine.
*  Yeah, yeah.
*  No, no, I do not want to know and I don't want to talk about this.
*  Yeah, it's not to celebrate naivete, but I don't think I didn't know what an H index was until I was I think I was a postdoc maybe.
*  And then it's appalling when someone tells you. Yeah, it turns out it's just the logarithm of your citation factor. So it's kind of a it's it's hilarious.
*  So a lot of fast over nothing, but I've had colleagues just sort of stay on the H index page.
*  Is my H index up today? Yeah, so, you know, what do you mean?
*  It's it's it's a career as well. You know, it is a career.
*  So well, we can put these let's put these aside and talk about brains and minds.
*  How about I do I do want to talk about and I guess it will be in in relation to brains.
*  This issue of emergence, I think it's very important. Let's let's just start off with it then.
*  So you guys you guys have mentioned emergence a few times now.
*  And so this is pressing on your mind. What is it about emergence that is so let me talk about it.
*  Generally, more formally, perhaps, and then John will explain why for him, perhaps for me to why it's important in brain and mind.
*  Emergence is another one of those words that generates a huge amount of confusion needlessly.
*  And so let's just make it very clear for everybody. So here it is.
*  And that I accept that there are many definitions. I'm not going to define it.
*  I'm going to talk about its operational value in relation to what we're going to talk about.
*  And that is that there are coarse grained theories that are statistically and dynamically sufficient.
*  And I'll explain what that means. It means that there are aggregations of variables which are principled, typically averages of some kind,
*  which are better predictors of their future selves or as good.
*  I should say that really qualified as good as any additional microscopic information would be.
*  In statistics, that's called sufficiency and dynamical systems, dynamical sufficiency.
*  So in other words, you don't get any additional predictive benefit at all by including more microscopic data.
*  And the question then is, when is that true and when is it false? And I just want to give a very simple example.
*  Water. If you want to understand the laminar flow of water.
*  You don't need to go to the microscopic constituents.
*  You just have Newton's second law, F equals MA applied to a fluid.
*  It's called the Navier-Stokes equation, and it deals with macroscopic observations and measurements, density, pressure, viscosity.
*  OK, if you want to understand the boiling point of water, that theory is useless.
*  And then you have to do the theory of phase transition, so-called Landau theory.
*  And that's all expressed in terms of microscopic Hamiltonians, energies of microscopic interactions.
*  So according to what you care about, you use either the effective theory, the average theory, Navier-Stokes, that is not improved at all by including the microscopic.
*  Or you need the microscopic to explain the property of boiling of water.
*  And the reason it really matters is because the macroscopic theory has huge advantages.
*  First of all, it's computable. So it's completely positivistic, this remark.
*  You can't do it with any computer the size of the universe if you want to include all the microscopic detail.
*  So that's just practical. Learnability when it comes to the brain, right?
*  In other words, there are so many free parameters in the microscopic description that you'd never learn them.
*  So there's a learnability constraint, which is analogous to the computability constraint.
*  And the most interesting one is the observability point, which is you wouldn't know what macroscopic property you need a microscopic description to describe.
*  In other words, unless you had it first. And so that's a much more difficult one.
*  So they top down concept that you can't get to the macroscopic from the microscopic.
*  You have to have an observable prior. So those are very practical reasons why it matters above and beyond the concepts of sufficiency.
*  So I just want you to put that in the background.
*  Is this all fundamentally due to the fact that you don't have if you did have a computer, you would need a computer the size of the universe?
*  Because otherwise you have to simulate things at the microscopic level to eventually actually understand them.
*  And you physically, practically cannot do that.
*  Yeah, you practically are too. It would be absurd. I mean, just the example I like to give is mathematics. Right.
*  So mathematicians proof, proof theorems.
*  Just go to a math journal. Look at the great mathematicians. Pick punk array, you know, Grotendieck.
*  You know, you pick your favorite. Nowhere will you find any reference to psychological states of mind.
*  Firing patterns of neurons.
*  Dopamine receptors, electrons, neutrons or quarks.
*  It's not considered important. And it's not right because at the level of a mathematical proof.
*  Mathematics is sufficient. Furthermore, right.
*  It would be incompatible and non-computable from the point of view of the atomic structure.
*  You wouldn't know what to observe and it would be not fundamentally non-learnable as a discipline.
*  So it's it's it's moot to me.
*  And the question then is whether you're dealing with the laminar flow of water or the boiling point of water.
*  And I think that's really the interesting question when you do have to go down a level.
*  And and for many of the systems that we study, I'm not sure we know.
*  Right. Exactly. I think what people get confused about is what you were sort of hinting at, Paul, is when is it just a sort of epistemological limitation?
*  Or when is it ontologically true?
*  Now, I would say and David can correct me if I'm wrong is mathematics and proofs in mathematics are ontologically independent of those other things about the world.
*  Knowing. About atomic structure is simply not relevant to mathematical proofs.
*  It's not that they if you had the computer or the time that they would add in any way, they don't.
*  OK. So and I think the question is when you talk again about Phil Anderson's disciplines, are they ontologically true?
*  In other words, does the explanatory structure of the universe fall into ontological classes?
*  Or are these just our cultural and epistemological failings that could splay out the way they do?
*  But there are only a few true ontological objects, presumably down the level of physics.
*  Right. And everything else is just derived.
*  And if we have a computer the size of the universe, we could do away with all the disciplines.
*  OK. Now, in a way, I don't even care if one has to decide when it's ontologically true or epistemologically true, because you want to actually get some work done.
*  And so, you know, I think there's a philosopher, Strevens, who gives this great discussion using evolution to talk about the independence when he talks about, if I remember correctly, a wonderful description of the shape of the marsupial mole and the golden mole.
*  And these are two moles with completely different evolutionary histories.
*  And yet they have. They're blind, they have snouts, they have thick fur and they have claws.
*  They've converged evolutionarily on the same solution to digging through the earth.
*  OK. And that's the explanation for their body shape.
*  It's adaptive to the environment they live in.
*  Now, it would be very odd if you were to say, I need to explain these two moles by going into their developmental history or not.
*  Or how did where did they come from? In fact, you'd be detracting from the actual explanation, going into details which will be different because they have completely different stories evolutionarily.
*  Doesn't that depend on what it what satisfies you as an explanation?
*  You want to know why they have the shape that they have.
*  And the question you're asking is that contrastive question, right?
*  It would be very odd to say that that explanation of that level of contrast, why do they have the same body shape?
*  You see, and I think that's the I think to go down lower, it wouldn't add very much other than that, unless you want to say why can't they both have a worrying rotor instead?
*  OK. But that's a different question.
*  Why can't they have a worrying screw?
*  Yeah, that's about constraints and what's available.
*  That actually sounds a little bit like the boiling point of water.
*  Why couldn't they have some other structure to drill through the earth with?
*  But if you want to know why they share that body shape, given biological constraints, that's enough.
*  It's adaptive to going through the earth.
*  Well, you know, it's I do think it's interesting.
*  Every question is susceptible to both forms of inquiry.
*  And if John were to look at those moles, he'd find that under the surface, they both had pentadactyl limbs, as do dolphins and whales.
*  Right. And so if that was the thing you cared about, this surprising homology that isn't explained by selection, it's explained by common descent.
*  And so I think it's always going back and forth.
*  I think I suspect I don't know, John, if my criticism is that there is this belief, and I'm not sure quite where it comes from, that the most fundamental, the truest description is the most microscopic, the most reductionist.
*  I mean, the other example that's given a lot by philosophers, I think I don't know if we spoke about this before, Paul, is about, you know, causal contrast, which is there is that what you know, the one that's given, I think Carl Kraver gave it first is, you know, why did Socrates die?
*  Right. And, you know, somebody might say, well, Socrates died because he was condemned to death by the Athenian authorities for corrupting youth.
*  Okay. Somebody else will say he died because he chose to drink the hemlock rather than to go into exile.
*  Right.
*  Well, I thought I thought it was a Caesar analogy. He died by metal spike in his chest versus the Senate.
*  Anyway, then you can say, well, it's because, you know, he dragged hemlock rather than English breakfast tea.
*  And then you can say, well, hemlock operates on a certain part of your body.
*  Now, the point is, is that all ontologically equal in terms of their efficacy as explanations?
*  But neuroscientists to the point that David make will think that if you can work out the mechanism by which the hemlock makes you stop breathing, that that's the best explanation for the death of Socrates.
*  And it just isn't right.
*  And I think that's the point is that there's this strange belief in neuroscience that there's a foundational privileged causal contrast and that everything else will ultimately devolve to that causal contrast.
*  And that's the odd thing. Whereas physicists are absolutely fine having Navier-Stokes equation for fluid dynamics versus having phase transitions.
*  And say that those are just different regimes of explanation.
*  Isn't ontology fundamentally out of our reach, though?
*  I don't think so. I don't think so.
*  You can be Keppensian. I know where you're going. But here's the nice thing, right?
*  Which is that it has to do with degeneracy that whilst it's true that our representation of the world might not be identical.
*  I mean, I should explain what that means, by the way.
*  So I just have to formalize these things because John and I argue about these all the time.
*  I want to make sure I'm being clear.
*  Say it's some structure X.
*  We would call Y a representation of X if Y is the image of X under some structure preserving map.
*  And so think about retinotopic maps or motor sensory homunculi.
*  They're all Ys, right? And they lose information in X.
*  But they preserve some structural feature of X, some geometric, some topological.
*  Now, if that were not true, Paul, selection would be ruthless to us and remove us from the world.
*  So it doesn't mean that we are identical. Y and X are not identical by any means.
*  But Y has to maintain something which is absolutely true about X.
*  That's a sense in which I do believe it's possible for ontological unity.
*  Not disciplinary unity, I'm with John.
*  But I don't like this idea that somehow because we can't know exactly the world other than mediated through our senses and our instruments,
*  that means that we know nothing about the world. That's just false.
*  That's a very important point that there must be some similarity transform that is possible.
*  Because if there weren't, I mean, that's what's so nice, I think, about Streven's mole example, is it's what evolution is working on.
*  It's almost an example that evolution has given to us, right?
*  That it's actually converged on this body shape to burrow through the earth.
*  It's sort of demonstrating to us that there is something ontological that it's operating on because otherwise there would be no survival.
*  So in other words, we have to believe that a mapping is that what David, I think, is saying is there has to be some mapping.
*  Right? Of course. There has to be.
*  So this kind of comes around and we're going way off course, which is totally fine with me.
*  But this kind of comes around to David Deutsch's, to me, it kind of comes around to David Deutsch's conception of what explanation is.
*  I don't know if you guys are familiar, but it's along the lines that explanation is just the latest thing that's hardest to remove.
*  And a better explanation is harder to remove as the explanation.
*  And between the epistemology and the ontology that we're talking about, David, you're saying that there's some must there must be some truth if there's a mapping that does it here.
*  Over time between X and Y.
*  But and I might be misunderstanding what ontology is.
*  But then I would say that we only have epistemic access to that and not ontological access.
*  No, I understand. But again, this is the critical point about this sort of structure preserving some mathematicians call these homomorphisms and think that the critical point is it's much more optimistic in some sense.
*  Because whilst it's true what you say, by definition, we are instruments that make measurements.
*  It's epistemology. Everything is right.
*  But as John pointed out, the behavior that ensues from those measurements has implications in that same real world, which doesn't particularly care about our epistemology, but it does care whether we can fly or swim.
*  And so that maintains an ontological through line.
*  And it doesn't matter to me whether or not we achieve identity.
*  It's just that we achieve some kind of structural correspondence.
*  And that's it. Well, you see, it's very important.
*  It's deeper than that, Paul. Is it you have to decide?
*  I think you had a really wonderful person on your show.
*  Difficult to pronounce her name.
*  As Rita Chirimutha. Yeah, Masri to turn.
*  She was very interesting on this point where she said, Do not confuse the goals of science of trying to seek the truth versus trying to seek understanding.
*  They're not the same. OK.
*  Right. So I think she, you know, she was right about that.
*  It gets a little bit, which we'll get to later about a piece that David wrote recently is that there's probably a sort of veracity understanding trade off.
*  And wouldn't it be interesting if getting models that are sort of difficult to understand, but they fit the world better is a different discipline to science, which does have to have understanding in it.
*  In my view, to be called science.
*  But there may be another discipline that may be closer, be a better fit to the world, but will be opaque to us.
*  And so if science is going to have anything to do with what the people we've been discussing so far, then I think understanding must feature in it.
*  Otherwise, I think I'll just give it another name.
*  Well, this is an issue is I think that so.
*  So the philosophy of science or understanding in the philosophy of science has sort of exploded recently.
*  And actually, John, you turned me on to Hassock Chang's work, who turned me on to direct.
*  Actually, I turned you on to Hank direct as well, actually.
*  That's fine. I'm very glad.
*  Yes, he was mentioned in that podcast, too.
*  Yeah. Yeah. So she so there's like four other, you know, recent books on the different natures of understanding and our conception of them.
*  And you guys couldn't have heard this, but I just had Jim DiCarlo on the show, who has sort of headed up this modeling the eventual visual stream in feed forward deep networks and now recurrent deep networks as this hierarchical system.
*  And it models on the brains really well and predicts brain activity very well.
*  And now he's controlling brain activity, using the models to generate images to control neural activity in the brain by presenting the stimulus to the subject and his conception of control, which was fun because he's very excited about this.
*  He sees control and prediction as the same thing, which is understanding.
*  I mean, I know Jim and he's fantastic.
*  And that's a complete and utter cop out.
*  I mean, he's basically decided that if you can do control and prediction, that would be the new understanding to a new kind.
*  Sure. I mean, if you want to give this new name, but it's much more interesting to me about what direct and others say, and, you know, in line with what Feynman and many others have said is that you need to have an intelligible theory to build explanatory models of the phenomenon.
*  And then you should be able to do intuitive work with that intelligible theory to generate explanatory models to explain the physical phenomena.
*  And if you don't do that right and you know, it's the Dirac idea that we discussed last time I was on, which you should be able to see the implications of the equations without having to go through the full derivation.
*  You can do intuitive work.
*  Okay. And science is this ability and maybe it's your own way of developing an effective theory that you can work with to generalize, to do new experiments to that science, right?
*  If you don't have that, then I don't know how it proceeds other than saying, well, let's just stop doing that kind of science and let's just do deep neural nets and be model free.
*  Right. But let's not deny that we're losing one thing over the other and that there's a trade off because there is a trade off.
*  Yeah, I don't I mean, I have a lot to say about this pool.
*  Sure. Take your time. Well, I agree with John, of course.
*  I mean, whatever that other chap said was just ridiculous.
*  And if he wants to just make those two words have the same definition, the dictionary, he can.
*  But I rather have a dictionary with more than one word in it. So let's just look at prediction.
*  So let's just make again, make it simple. I find these things useful.
*  So prediction is very simple. It's just getting an input output relation correct out of sample.
*  That's a prediction. So if the input is time and space, you tell me temperature.
*  That's called weather prediction. And, you know, doesn't matter. That's what prediction is.
*  It's an I.O. relation that works. Now, knowledge, of course, the facts that go into making the I.O. work.
*  But knowledge also goes into understanding. And I want to talk about understanding.
*  And I know John is interested in this. I cite some work by John actually on this.
*  So for me, understanding is the communication of why the I.O. works or the construction of the I.O.
*  in the first place. So communication and construction.
*  And let's just make this quick because everyone who's listening to this knows this already.
*  If you are taking an exam and you copy someone else's answer, who you know always gets A's, right,
*  that predicts success for you. You understood nothing. You used a simple rule and it worked.
*  OK. What most good teachers ask is once you've produced a result, whether it's right or wrong,
*  they'll say, how did you get there exactly? Why did that work?
*  Why does summing up rectangles in a limit give you integration?
*  Anyone can use an integration formula, but not everyone can explain why they work.
*  That's the difference in a good mathematician and a crappy mathematician, quite frankly,
*  or a good scientist and a crappy scientist, a good teacher and a crappy teacher, a good student and a crappy student.
*  We know that. So there is much more than prediction, right?
*  There's much more than knowledge and understanding is tricky.
*  And philosophers have commented on this. And of course, John Searle most famously in his thought experiment
*  of the Chinese dictionaries in the room. And that's been of great interest to me.
*  And there's a lot to be said about this. I think John Searle gets a lot wrong.
*  And I do want to mention something John has done and my thinking on this topic.
*  So, again, understanding goes beyond the I.O. map.
*  It goes to the explanation for why it works or how you construct what it is.
*  And just one thing on that before David, you know, I think it's not to knock, obviously, people like Jim Decarlo
*  and all the people who who who build these impenetrable, you know, I.O. networks.
*  Right. And their understanding finds other places to land.
*  You know, how how do you build the cost function?
*  How do you play with the architecture? You know, what is the learning rule?
*  There are other places where people show great understanding.
*  But the thing itself. Can I explain the performance of this system?
*  They admit that they can't. Now, that's fine.
*  But don't buy because that's true.
*  Say I'm no longer going to consider that a problem that I can't understand that piece.
*  OK, you just just live with it.
*  Now, we'll get we'll get on a little bit longer to what I think is a solution to that problem,
*  because I'm not completely satisfied that you should just go when it comes to deep neural nets.
*  It's overparameterized. We'll never understand why it's this way versus that way in terms of the connection strengths.
*  And therefore, let's just fall back on having known what the cost function is, having known what the learning rule is,
*  and just accept that at asymptote it learns it.
*  Well, so that what you just said was put forward as the beginnings.
*  We won't we don't can't understand things yet.
*  So let's start with learning algorithms and objective.
*  But we have to be careful that that's not what I don't know your previous speaker.
*  But that's not what you communicated.
*  He said that, you know, so that is prediction is understanding, which is apparently false.
*  I do want to give a bit of a history, though, because we've not we've been here before.
*  Right. And we were here at the origins of science.
*  And the example I like to give of this is Francis Bacon in the Novo Morgana.
*  And he makes this beautiful remark.
*  He says it's very difficult for humans to draw straight lines or circles.
*  So we use rulers and we use compasses.
*  OK, so we use tools and in some sense, they subvert our abilities.
*  And deep learning is just, you know, compass prime.
*  OK, now, interestingly, the tool that Newton developed with Leibniz was the calculus.
*  Well, they didn't really actually.
*  That's a kind of falsity. But the fundamental theory of calculus, the relationship between differentiation and integration and the application to orbits.
*  And it's quite interesting if you read the Principia, which I have not read reviews of it or summaries of it.
*  It's quite interesting that the method of fluxions, which was Newton's name for the first derivative of space with respect to time, right, velocity was not in it.
*  He actually when he wrote it, it was too arcane and he was too paranoid to actually disclose his discoveries.
*  He actually presents his results geometrically because they were better understood than his new methods.
*  So Newton felt that just predicting using his methods was not sufficient.
*  He wanted people to understand why his theory of gravity could reproduce Kepler's three laws.
*  And he did it geometrically. Now, when he went on to discuss the inverse square law, Huygens hated it because it was non mechanistic.
*  It wasn't understandable. It posited action at a distance.
*  And then Newton turned around and said, hypothesis non-fingo, you know, it's good enough.
*  It predicts really well. Why should I have to do that, too?
*  Descartes hated it and came up with his theory of vortices, which was much more mechanistic, which didn't work.
*  So right there in the early days of the revolution was a theory that was predictive.
*  The author chose to present a method presented in terms of a method that people could understand geometrically.
*  More familiar with that, but was criticized for being sufficiently mechanistic and only too predictive by Huygens.
*  And then there was a suggested alternative.
*  So that then continued into its limit with quantum mechanics and what we now know as the Copenhagen School,
*  where people like Bohr and Pauli and Heisenberg disavowed any intuitive understanding of the physical world.
*  They hated it and replaced purely predictive mathematics.
*  And the famous expression of that position was from David Mermin when he said, shut up and calculate.
*  Don't even bother. Now, so physics has this tradition.
*  It's no different from what's going on now in neuroscience and machine learning.
*  And it generated endless discussion back and forth.
*  And now, as of today, there's a return to fundamentals of quantum mechanics where people are trying to provide,
*  as John said, an understanding for why these methods work.
*  Murray Gell-Mann, my colleague here, Jim Hartle at Santa Barbara, couldn't stand this.
*  They wanted to provide a comprehensible theory, as Einstein had and as Schrödinger had.
*  So this seems to be a quite universal feature of the scientific enterprise,
*  that there are those who tend to favor predictive efficacy, even if it forfeits intuition,
*  and those who don't like that and feel that the humanistic aspect of science,
*  the creative aspect of science requires understanding.
*  Are they both necessary for progress?
*  I think they are. I think they are.
*  And I think what, if anything, John might be saying, and certainly I would be saying,
*  is that the extraordinary power of predictive frameworks in the face of complex phenomena
*  that have very high dimension, you could talk about that, makes this much more complicated to argue.
*  In other words, there's something about a complex phenomena that is so much easier to predict than understand
*  that that side of the equation, if you like, gets differentially weighted.
*  And that's a bit of a problem.
*  But only via simulation, though, right?
*  No, in other words, the nice thing about fundamental physics is that you could have your cake and eat it.
*  So you could say, I'm going to predict with this theory to a hundred decimal places,
*  and I can write down on one page the equations which generate that solution, which human brains can pass.
*  But when it comes to predicting market trading or the spiking of that particular neuron,
*  unfortunately, it looks as if the representation of the structure, this Y thing, is a very, very high rank.
*  And that has lent itself in the short term to the utilitarian school,
*  which says either prediction is understanding, which is kind of silly,
*  or we don't care about understanding because you could never accomplish it.
*  Yeah, I mean, I think that's absolutely true.
*  I mean, it goes back to the question before, you know, this is exactly, you know,
*  I was looking into this quite a lot and direct actually has a whole chapter in Chapter 7 of his book
*  on exactly what David's talking about with quantum mechanics, you know,
*  the sort of Schrodinger equations and the wave function being something that people could do intuitive work
*  and picture with versus Heisenberg's matrix mechanics being just churning out the numbers.
*  Right. So it's absolutely true that we've been here before.
*  And again, it speaks to the parochialism of neuroscientists
*  that they just don't sort of look out their own discipline for the most part.
*  But I do think it's true that one criticism that has occurred is some people have said,
*  well, the reason why we've had understandable neuroscience for quite a while is that we made such simple experiments
*  that it was the simplicity of our experiments that sort of reigned in the multidimensionality
*  that David's talking about.
*  And as soon as you started going into the real world and with more naturalistic experiments,
*  it got hopelessly complicated. Right. It wasn't just one bar in a dark room.
*  It was complex images, movies, things like that.
*  OK. And, you know, you know, you had Yuri Hassan on, right, who very much made the point that it's just not right to consider
*  the human brain trying to overtly model the world.
*  It just has so many neurons. It has so many parameters.
*  It can just do direct fit. OK.
*  And that where it's again, it gets to the epistemological era of doing simple experiments
*  that require representations that lead to understanding.
*  In fact, you have this ability to fit the world and you fit so much in the course of your life that everything is interpolation.
*  OK. You only really need what David was saying, sort of out of sample.
*  If your training set was so small that the probability of you having discovered what you're going to discover in the rest of your life
*  is not present in the original training set. OK.
*  So there is a sense not just that there's a there's an option, but maybe it's true that for the most part,
*  because there's no overt representation, we shouldn't come up with an intuitive understanding and just accept that you're fitting.
*  And I think he gave the example of evolution, right, that it locally optimizes.
*  But it's not going to predict what the next species is going to look like. Right.
*  It's not like you're going to predict what the next creatures morphology will be within constraints.
*  So let's just do interpolation with vast sampling and loads of parameters. OK.
*  And but interestingly enough, he he he fell short of cognition. Right.
*  He admits that cognition isn't understood that way. And you know, and it's very interesting that.
*  You mean how how that maps onto mind?
*  Doesn't work for mind. He admits that. That's right.
*  And Jeffrey Hinton actually says that the last thing the last thing that will yield when it comes to A.I.
*  is cognition. OK. So you've got this interesting thing that the evolution of neural networks.
*  And if you believe in, you know, cognition getting more complex as you move towards primate of a kind,
*  both of them don't yield to what's happened so far in neuroscience or in A.I.
*  And the reason I bring this up is in the meantime, we may need intuitive explanations of these phenomena to work with,
*  even if those things are true. Right. So one of the biggest things that I would love to prove is David,
*  you know, when it comes to all these things, hierarchy, emergence, complexity, aggregation is I've always wondered
*  whether there will always be some intuitive, understandable form of the question at some level of course graining,
*  even though at some level it's at the predictive level of the system, you won't understand it.
*  So in other words, you just accept. But there will be another way to talk about the phenomenon that will yield to more intuitive explanations.
*  OK. So you can have your matrix mechanics, but there'll always be a wave mechanics way of talking about it as well.
*  And maybe that's just hopeful thinking on my part.
*  Or maybe it's kind of true that hierarchical complex systems that omit details as you go up have two secrets about them.
*  One is that predictable and hard to understand. And there's another form that can be intuitively talked about.
*  And is there some principle there that you can have two flavors in any complex system?
*  Yeah. And I yes, I want to get back to Sarah in a second because I realize I didn't complete that or a Boris.
*  But to John's point, I mean, I've always felt that there are two paradigms that are emerging now. Right.
*  There's the fine grained paradigms of prediction that have these very high dimensional phenomena that are somewhat incompressible.
*  And so they don't lend themselves to these intuitive frameworks.
*  Then there are the coarse grained paradigms of understanding. Right.
*  And a good example of that, just to bring it to neural networks, I think John mentioned this is, look, we know how reinforcement learning works.
*  AlphaGo Zero has a very, very simple learning rule. Right.
*  And that's the level at which understanding tends to operate in that case, which is we have as a community and DeepMind and their colleagues come to understand that there's a very simple kind of learning rule that can train these very large elaborate structures.
*  And however, the elaborate structure once consolidated is opaque.
*  And I think it's true. I think that understanding of complex systems might be a little bit like the learning bit.
*  And the prediction is done by the structure that's learnt.
*  I mean, that's very much the Lily, Krap and Kurding position. Right.
*  They said, look, you can write on, you know, on half a page, the reinforcement learning rule. Right.
*  And the objective function. Right.
*  And maybe that's I actually think I don't actually fully agree with that is I actually think there are psychological terms that can be used to explain phenomena that neurally are too complicated.
*  Yeah, I agree with that, too. So I just wanted to make a point.
*  So I think that's right. I think the theory of scale that my colleagues here have been developing Jeff Jeffrey West and others are a good example of these coarse grained frameworks that also do extraordinary prediction, coarse grained prediction.
*  And what John is suggesting, I think, is I think is correct and demonstrably correct in some domains is that not only is this there is this kind of theory like the learning theory,
*  which is a theory that can be understood to train a network, but there might even be a coarse grained theory of how the network works.
*  And that that that's interesting. And there's been a lot of it, as you know, I mean, people.
*  And I believe that. I mean, I think that's what I think.
*  I think that cognitive neuroscience and psychology psychology is, you know, the way, you know, William James wrote his entire book, right.
*  To find all the disciplines, it gets back to what we discussed at the beginning.
*  These are these disciplines, ontological or the epistemological.
*  And I'm just saying that wouldn't it be interesting if psychological terms just happened to be the correct course graining to discuss the performance of systems that at the neural level are opaque?
*  Would that be more interesting than if they weren't?
*  I'm saying that it doesn't surprise me that there are, as David said, you know, averaged out objects that you can think with.
*  And I'll give an example just to be very neuroscience.
*  You know, when you look at what Mark Churchlin and Krishna Shanoi have done, where they, you know, looked at motor planning and motor execution as a trajectory through a state space.
*  Right. So they're basically it's very interesting.
*  You know, David talked about the fact that neural networks and dynamical systems, you know, that they have an intimate relationship to each other.
*  There are dynamical neural networks. Right.
*  But it's interesting that when you look at the work that's now very in sort of in fashion right now in science where you take millions of neurons and you do dimensionality reduction.
*  And then you look at a trajectory through a subspace, the dynamical systems approach.
*  But what's interesting, but it's very much about what the Schrodinger Heisenberg thing is that Feynman diagrams, right?
*  What Feynman diagrams were another visual visualization tool that allowed people to have intuitions.
*  So if you talk to Mark Churchlin, I remember him saying to me as an aside, you know, I've started to look at so many of these trajectories through these, you know, state spaces.
*  He can see them. He can see that he actually thinks with them.
*  And so it's very interesting that these are derived objects from neural data, thousands if not millions of neurons.
*  But if you ask him, do I need to know the connectivity of each of these neurons?
*  Of course not. And in fact, it has to be not the case because in any given animal you're going to see very similar trajectories, but they don't have one to one correspondence of your of their neurons.
*  So the invariance happens at a level above those details.
*  And you can think in that at the level of that invariance.
*  Yeah, I'll give you a good I'll give you a good example of that, actually, from a totally parallel domain.
*  And that's computer programming.
*  And the great genius of computer programming is Donald Knuth, who wrote about computer programming languages and many, many other things and makes the point that computer programming languages are the interface between the machine and human understanding, human reason.
*  They're not a tool for programming.
*  You can use machine code for that.
*  Right. You could write an assembler.
*  No one writes in assembler.
*  Everyone writes in Fortran or C++ or Python or whatever, or Go or whatever your favorite language is.
*  And there's no debate in the computer science community about the value of using high level programming languages.
*  No one there's no kind of machine code zealot who says that the only way to really understand is to write in ones and zeros, you'd be a lunatic.
*  And so I think it's the same thing.
*  I'm sure well, there probably is.
*  But I think that's the same thing is that, you know, our high level, psychological, cognitive, literary, mythological abstractions stand in relation to reality as high level programming languages stand in relation to circuits.
*  They allow us to not only understand them better, but program them better to control them better.
*  It's it's I don't see why that's even controversial.
*  I mean, just to that point, I think sometimes this is the heart of the matter is it's not that there's hierarchical organization of a computer or nervous system just so that we can understand it better or program it better.
*  It's actually for itself to control itself better.
*  In other words, the nervous system has its hierarchical structure.
*  Because that's the way you have to organize.
*  A complex system.
*  In other words, you know, the nature of the commands that go out of motor cortex versus pre motor cortex are very different in terms of their details.
*  The type of detail required at the level of the spinal cord in terms of, you know, temporal and spatial dynamics isn't present.
*  Higher up the hierarchy, you omit details so that control, as David said, is easier.
*  Yeah, we called this system self observation.
*  And so it's absolutely right, because any adaptive system, that's what makes them interesting, by the way, is theorizing about themselves.
*  Right. And so if if you write software that's interoperable with other software, so I'm you know, I do everything in EMAX and I'm constantly adding in max extensions and you know, they're written in in Lisp, you know, and they can control this.
*  You know, OS text editor hybrid.
*  That's the right level at which to operate.
*  And so John's absolutely right.
*  That's that's the great ingenuity of hierarchy, right?
*  That once you operate at that level, you can control at that level.
*  So bringing us back to we can bring it back to any level, but I'm thinking specifically of the thinking in dynamical state space trajectories like John, you mentioned, you know, March Churchlin, Mark Churchlin told you he does.
*  Is that understanding?
*  Yeah, I mean, so so there's this question, you know, can you use your way when you're using a tool like neural networks, like, you know, dynamical systems theory, can you use your way to understanding without just by practice, you know, and and making it implicit in your
*  Yeah, so as you know, direct and others have may much talked about that if you are going to be able to do intuition like Dirac and Feynman did, they look at the equations and know their implications about going through the derivation.
*  That's because they're skilled at it.
*  Okay, so that direct makes a big point that in order to be able to do that intuitive work with this level of coarse graining, you have to become skilled and practice that it is that what Mark was saying in a sense is that he's become skilled at thinking with trajectories, just like people can look at Feynman diagrams.
*  Okay.
*  And so that so that is but that is understanding me it's very important just to get to your first part of your question.
*  If understanding is having intelligible theories to build explanatory models to map onto real phenomena.
*  So let me give you an example when any if you ever talk about the stretch reflex and somebody asked you what's the reflex you will think of the muscle spindle the one a afferent the synapse with the motor neuron back onto the muscle.
*  Okay, and then you'll think of an inhibitory into neuron going to the antagonist. Okay, so reflex when you think about it intuitively has neural objects in it, you're thinking about axons and neurons.
*  Okay, now when you get to what Mark church and is doing in motor cortex of Sheraton had lived you could have seen what happens when you take that approach up.
*  He would have realized that people aren't worrying about how neuron a connects to neuron B connects to neuron C connects to neuron D in all that detail and motor cortex.
*  It's abstracted up to course grained measures they are nearly derived but now they're trajectory through a state based so you're on work and working on this paper I think I told you it's almost done called the two views of the cognitive brain with a fantastic neuroscientist philosopher at Columbia called David Barack.
*  Where we're talking about this and it's possible to have a functional explanation of high level behaviors where you can have the psychological terms and add to them.
*  A neural piece just like the axons in the in the reflex but the neural piece is a trajectory in a state space.
*  It's a dynamical object.
*  It's quite interesting John there's a I'll give you another example of this and again in another domain and I was in 2018 mathematician called Peter Schultz won the Fields Medal for creating something called perfectoid spaces.
*  Which have to do with galois representations and so on and one of the things that he pointed out is that when he is trying to solve a problem.
*  The first thing that he really has to do is come up with almost a linguistic definition of the mathematical problem.
*  If he doesn't have that he can't do the math sure okay now he's not.
*  This is a Fields Medalist and he's saying that I need to move between levels exactly what John just described it's not that he can he doesn't operate at the machine code of mathematics right he moves up and down and I think.
*  One of the really interesting questions I would have you and John and so forth is could we come to an understanding of how many levels we should have for a given observable.
*  And what would be the theory that would tell us how to sort of optimally allocate our attention across these different levels I mean that's something I think which would be very much a complexity problem feels very meta.
*  But I imagine the nervous system has to do it too.
*  Yes exactly and I just exactly the nervous system has to do it and it would be against all the other things that I've learned sort of through the center of the institute and David and other complexity scientists which is it would seem very odd to me.
*  Is as behavior gets more complex and the neuronal aggregates in court cortex get larger that the explanatory object is going to remain a sharing Tony and style description of a circuit.
*  The idea that your level of explanation will never change no matter how more complex your behavior becomes what a bizarre thing that would be right so in other words one thing I can be sure of is I don't think that circuits.
*  Circuits.
*  In insects and in the spinal cord on the machine code and the idea that once you get into cognition and cortex that you're going to be able to revert to that level of description flies in the face of what other hierarchical systems and complex phenomena do it is that you have to come up with new objects that are more abstract.
*  And maybe and it's actually you know another point you're talking about Olaf Spawns and Danny Bassett versus what Mark Churton I find trajectories and state spaces.
*  Give me a feeling of understanding that connectivity metrics utterly fail to.
*  That's right they just don't do it for me and it's very interesting and you know I have huge respect for Danny she's super bright but she's when she's written most recently about the kind of understanding and hypotheses you can test with connectivity they themselves are couched in connectivity language.
*  Is this area autonomous or very connected to this area it's just connectivity language again.
*  Right where's I find dynamical systems and trajectories seem to be something that adds to the psychological terms.
*  It's interesting Paul this gets to your opening remark about that sort of plurality of frameworks that we need to understand something complex right and I think.
*  Obviously in my position I'm very open minded I feel as if.
*  They're all great right as all of the illuminator phenomenon and I think the problem is always the reduction to one this belief there's only one best way of doing things and I think you're right I think for many people.
*  Dynamical systems work for other you know these combinatorial algebraic structures work and we as brains by virtual histories presumably work differently and I think.
*  If anything complexities a kind of liberalism says that's allow for the possibility of a multiplicity.
*  I've approaches and not assume one is why wouldn't be that you know it's interesting I don't know Paul of youth read the new history of neuroscience Matthew Cobb's book the idea of the brain.
*  No but isn't it just a list of metaphors I've not read it so yeah but it's easy well no I think actually at the scaffold for thinking and it's very good I love the history part and the early present.
*  I think once it gets into current neuroscience and prediction of the future it gets more impoverished but I don't know that's Matthew Cobb or whether the field itself is sort of accurate.
*  But it is a good book I really do recommend it it's got lots of delicious rich stuff and he's done a good job it's not easy to synthesize all that material but I tell you what's fascinating about it is that he has a section at the end of the book.
*  Where he talks about the future.
*  It's very interesting that he begins by talking about emergence.
*  Then drop it like a bad smell right it's like.
*  Well I think you said something like emergence is that.
*  I'm satisfactory so explanation before we get to the real explanation right and then he moves on to where he feels like the real progress we made.
*  Is this get back down to the circuits in the neurons themselves let's study cognition in a fly where we have the serotonin connectivity map.
*  And then we'll do some sort of extrapolation to cognition in humans in other words you see this tension in the field.
*  Between not really wanting to talk about course graining and psychological terms and.
*  The right measures and saying surely we can avoid that awful fate foul field.
*  I going into a fly or a worm where we can have the same level of connectivity detail and intuition as we did for the stretch reflex.
*  But now we can apply that understanding to something that we call cognition.
*  And then somehow extrapolate from that higher up in your access in other words you see that there's this tension.
*  That it just won't go away.
*  Okay that's it for part one part two will pick up right where we left off here with just a little bit of overlap to remind you about the latest bits that we were talking about.
*  See that.
*  Brain inspired is a production of me and you I don't do advertisements you can support the show through Patreon for a trifling amount and get access to the full versions of all the episodes.
*  Plus bonus episodes that focus more on the cultural side but still have science go to brand inspired.co and find the red Patreon button there to get in touch with me email Paul at brand inspired.co music you hear is by the new year find them at the new year.net.
*  Thank you for your support see you next time.
