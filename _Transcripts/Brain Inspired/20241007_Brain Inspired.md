---
Date Generated: October 13, 2024
Transcription Model: whisper medium 20231117
Length: 4625s
Video Keywords: []
Video Views: 185
Video Rating: None
Video Description: This is the first of two less usual episodes, recorded during a recent NeuroAI workshop in Norway. Gaute Einevoll and I have discussions with neuroscientists Ken Harris, Andreas Tolias, and Mikkel Lepperød about how artificial intelligence has shaped their neuroscience research, thoughts, and productivity.

Show notes: 
https://braininspired.co/podcast/195/

Patreon for full episodes and Discord community: 
https://www.patreon.com/braininspired

The Transmitter is an online publication that aims to deliver useful information, insights and tools to build bridges across neuroscience and advance research. Visit thetransmitter.org to explore the latest neuroscience news and perspectives, written by journalists and scientists. 

Read more about our partnership: https://www.thetransmitter.org/partners/

Sign up for the “Brain Inspired” email alerts to be notified every time a new “Brain Inspired” episode is released: https://www.thetransmitter.org/newsletters/ 

To explore more neuroscience news and perspectives, visit thetransmitter.org.

Apple podcasts: 
https://itunes.apple.com/us/podcast/brain-inspired/id1428880766?mt=2
Spotify: 
https://open.spotify.com/show/2UZj8c8Ap5oc2gh2rJxLLe
---

# BI 195 Ken Harris and Andreas Tolias with Gaute Einevoll and Mikkel Lepperød
**Brain Inspired:** [October 07, 2024](https://www.youtube.com/watch?v=xudJqtuAfkk)
*  This is Brain Inspired, powered by the transmitter.
*  Hey everyone, it's Paul.
*  This is the first of two less usual episodes.
*  I was recently in Norway at a neuro-AI workshop called Validating Models, How Would Success
*  in Neuro-AI Look Like?
*  And what follows are a few recordings I made with my friend Gauta Einvall.
*  Gauta has been on this podcast before, but more importantly, he started his own podcast
*  a while back called Theoretical Neuroscience, which you should definitely check out.
*  So Gauta and I will introduce these conversations we had with a few of the invited speakers
*  at the workshop and one of the main organizers.
*  I link to everyone's information in the show notes at braininspired.co slash podcast slash
*  195.
*  So I hope you enjoy these conversations that we had on a rather large boat you'll hear
*  about in a second.
*  Enjoy.
*  Two podcasters on a boat in Norway.
*  How can that go wrong?
*  Hi Gauta.
*  Hi Paul.
*  Why are we doing this together?
*  What's happening?
*  Yeah, this is, I mean, you have been making Brain Inspired for how many years?
*  I think five, maybe six.
*  Five, six years, exactly.
*  So I've been podcasting for five, six years, but this new Theoretical Neuroscience podcast
*  is sort of that started in October.
*  So I remember I talked to Konrad Koiding and well, this Brain Inspired was an inspiration
*  for me to make this what I call academic podcast.
*  It's not really about, it's actually for people in the community.
*  science podcast really, which are of course really important too, but it's a different
*  thing.
*  So in some sense, when I talked to Konrad Koiding about this, he said, oh, so your
*  podcast is Brain Inspired inspired.
*  That is actually true.
*  That's actually true.
*  So anyway, so we are a little bit, in some sense, like sister podcast, wouldn't you say?
*  We are sort of both sort of like, I mean, yours are like Neuro AI and mine is a little
*  bit more sort of like into the like more other aspects of Theoretical Neuroscience, maybe
*  like more like starting with the like the physics tradition, because that's sort of
*  where I come from.
*  But anyway, when we both were going to this very nice workshop on Neuro AI up on the coast
*  of Norway.
*  So then of course, we have met before you visited me in Oslo once.
*  So then we decided why don't we pool the resources and make a joint podcast.
*  Yeah.
*  So what came out of is just a couple, a few discussions that we had with some of the invited
*  speakers and then also with one of the organizers, Mikkel, to sort of frame the workshop.
*  So you'll hear from Mikkel a little bit about how this workshop came about.
*  And then in closing, so this will be two episodes.
*  And then at the end of the second episode, which will be our second discussion, Mikkel
*  kind of summarizes and wraps up as well.
*  So anyway, so the workshop just to introduce that a little bit more.
*  So that was then on like Neuro AI.
*  It was sort of Mikkel Leprø in Oslo and I think Konrad Kording, who is sort of like
*  in working out the program.
*  And there are also like other organizers who I think sort of supported the well, security
*  funding, like people in Oslo, Anders Malte Sørensen, Marianne Fyn and Tone Skramstad.
*  I like to give credit to people.
*  Of course, they did an awesome job.
*  It was an awesome workshop.
*  It was an awesome workshop.
*  So this was quite, quite unique.
*  I mean, I never taken, it wasn't a coast liner along the most beautiful part, beautiful
*  coast of Norway from Tromsø down to Trondheim.
*  It took like three days or two and a half days or something.
*  And it was a good weather and it was really, really excellent in all ways.
*  As you mentioned, the first clip we present here is with Mikkel, main organizer, where
*  we actually discussed with him why he made that podcast and what he wanted to get out
*  of it.
*  It was done in the...
*  You said podcast, you mean workshop.
*  Workshop, exactly.
*  Like a Goli Freudian slip is not something.
*  Yeah.
*  So I meant workshop.
*  So and this was done at the, actually at the last day of the workshop in a luggage room
*  of a quite fancy hotel in Trondheim, the Britannia hotel, which is sort of, I used to study in
*  So this was sort of like the places you don't go when you are on the student budget, to
*  be sure.
*  But anyway, yeah, it's very fancy.
*  So we're in the luggage room.
*  So the sound is actually better, but they also had people walking, coming into the luggage
*  room, like our friend John Krakauer, for example, who attended the workshop.
*  Yep.
*  He makes a boisterous entrance, but it's brief.
*  He was the main interrupter or whatever.
*  So we say hi to him and you'll hear other things in the background and other people
*  kind of coming in and out.
*  Yeah.
*  And we link to the homepage or the workshop.
*  So this is divided into two episodes.
*  So in the episode that's going to come out in just a couple of days, you'll hear Christina
*  Savin or Savin, I'm not sure how to pronounce her last name, and Tim Vogels.
*  And we'll talk a little bit more about them in the next episode.
*  But on this first conversation that we had, we have Andreas Toglias and Ken Harris.
*  Gautik, do you want to talk about Andreas?
*  Yeah.
*  So Andreas Toglias, he has just moved to Stanford, by the way.
*  And he's sort of at least he's done many things.
*  And he obviously is doing monkey physiology and mouse physiology.
*  Some of the work that I'm particularly interested in is these foundation models he has made
*  for the visual cortex of mice, where he has sort of trained these deep networks to essentially
*  sort of predict sort of calcium responses when the mouse is shown different kind of
*  visual stimuli.
*  And I think in terms of predictability, this is sort of like really the state of the art
*  when it comes to making these kind of models that predict things.
*  And of course, in terms of interpretability, which we also discussed a little bit in the
*  podcast, it's a bit different than it's harder to interpret.
*  And then there were Ken Harris.
*  Yeah.
*  So Ken, among other things, I mean, he's interested in how large populations of neurons sense
*  the world and convert that sensation into action.
*  But one of the things he's been known for in the past few years is just the immense
*  recording capacity.
*  So in the past few years, our data has skyrocketed, the computational power has skyrocketed.
*  And he was, speaking of cutting edge, he was one of the first to use a super high density
*  recording electrode to record thousands of neurons at the same time.
*  And that has not been done before.
*  So we're still grappling with what to do with all these neurons.
*  But we don't actually talk so much about their research in these conversations.
*  Because he actually at the workshop, exactly, not the podcast, at the workshop, he actually
*  talked about, he had been challenged to talk about sort of actually what it means to understand
*  something more on the philosophy of science.
*  That's right.
*  Yeah.
*  Okay.
*  So I think that's a fair enough introduction.
*  And all right.
*  So enjoy our discussion and see you in a few days.
*  Mika, so you had this idea to put this workshop together that we're now at the end of.
*  But we're going to go back to the beginning and ask you how this workshop came about and
*  what was it supposed to be about?
*  Yeah.
*  So I mean, I come from, I had the training in both kind of computational and experimental
*  neuroscience.
*  I've been working the past, I don't know, four years on Neuro-Ion models.
*  It's okay.
*  It's okay.
*  It's just John Crack, I believe.
*  He said, the number 15 on my podcast.
*  It's the 15th time you're here on the podcast.
*  It has a characteristic laughter, which we have enjoyed all through the workshop.
*  I hope you mean it.
*  No, I do.
*  Hey, are you leaving?
*  Are you out?
*  I'm going to check in.
*  Okay, cool.
*  I'll get the dinner.
*  Sorry.
*  No worries.
*  No, you're good.
*  So you've been studying computational neuroscience and yeah.
*  I mean, I got really excited when I learned that we could, I mean, when I did my work in
*  my PhD and training, I was working on grid cells and spatial representations in rat brains
*  foraging.
*  It's a very Norwegian thing to do.
*  It is a very Norwegian thing to do, I guess.
*  But I've always been interested in kind of the why question.
*  Why do we have these representations?
*  What are these cells used for?
*  My training from mathematics always drove me into kind of comparing experiments with
*  That is kind of how I envisioned science would be for me.
*  And I tried to do that in some of the experimental work I did.
*  I tried to perturb neurons with the optogenetics, I perturbed the medial septum area while recording
*  medial and thoracic cortex and trying to see if I could say something about validating
*  models back then, like the classic computational models of grid cells.
*  So I think this kind of notion of validating models has always been kind of a core part
*  of my vision of how science should be done.
*  Well, how did the neuro AI thing come in?
*  I mean, I started working on neuro AI models of grid cells, if you will, or navigation
*  when there was a model coming out from DeepMind and also in parallel there's a paper from
*  Quava Way that did a parallel kind of discovery that if you train recurrent neural networks
*  on path integration tests, you give them velocity input and you train them to output like a
*  position based on that.
*  Then in some models you can see a similar pattern that you see in real brains.
*  So this seems to be very, and I think it still is, it's a very interesting way of modeling
*  these phenomena because you don't put that many assumptions in.
*  So in the classical mechanistic models you kind of build in what you're seeing and so
*  it's a slightly different approach.
*  So my hope with these models was that you could kind of, without putting in too many
*  assumptions about what the system does, you could have these patterns emerge or become
*  part of the computation that the RNN is doing and then you could probe it afterwards and
*  ask why questions?
*  So what are these cells doing?
*  How are they interacting and so on and so forth because that's something you can do
*  in experiments very easy.
*  But working on these models I realized it's not that easy.
*  So you can train a model and you can get a lot of different results and there was a
*  big discussion whether or not this grid pattern would occur kind of consistently and it doesn't.
*  You mean over different training regimes and different architectures and stuff?
*  Exactly, yeah.
*  Or even just the initialization, at least in the early models.
*  Looking at that I started worrying about how I'm supposed to relate these models back to
*  neuroscience.
*  I mean that was my motivation at least and I think it's the motivation for many that
*  you can use these models to say something about how the brain works.
*  So for the workshop did you think, oh I need to make some new friends here?
*  One thing is that this work kind of sparked the notion in me that we really need to do
*  this in the right way in order to say something that has a scientific rigor and we can't just
*  generate lots of models and say that every model that has sufficiently gritty or whatever
*  pattern you're looking for is a good model.
*  So that's kind of sparked the scientific question and in terms of the workshop I think many
*  of these problems would occur in many other systems as well.
*  And looking at other types of new AI models that are being used that are somewhat similar
*  where you train a vision model to recognize images and you can compare their linear probing,
*  you can compare their activations with real neurons or just do this similarity analysis.
*  Yeah, lots of different ways to compare the models with the neural activity.
*  Exactly.
*  So I think in many of those cases similar problems can occur where you can generate
*  lots of different models and even though they look similar to what you study in the brain
*  and they even look similar to between the models but that doesn't necessarily mean that
*  they're doing the same thing.
*  Well even if the output is the same, the way that they're doing it might not be the same.
*  Exactly, yeah.
*  So it's kind of this algorithmic level question of whether or not they're implementing the
*  same thing.
*  You gathered together a wide variety of people from different fields using different types
*  of models to study different brain systems but also using AI as a tool to analyze their
*  data.
*  There's even a philosopher here, one philosopher.
*  That's enough for any conference, right?
*  Yeah, so it was a nice group of people.
*  There's a fantastic venue you chose.
*  Oh my God.
*  Yeah.
*  I like this coastline that shows the coolest thing of Norway from a nature point of view
*  are the fjords.
*  So even in the American, the hitchhiking guy to the galaxy, this guy got the planetary
*  engineer who got an award for the fjords of Norway.
*  So I think that was a well-deserved award.
*  So now with this trip going from the north to the middle of Norway or Trondheim on the
*  boat was really showing off the best of the nature and I guess that also was, that was
*  probably intentional.
*  I also heard multiple times this is like the coolest conference slash workshop that I've
*  ever been to.
*  I'm sure you did too, multiple times.
*  I think most of the people I talked to, they really enjoyed themselves.
*  It's just made the bar very high to go to other workshops, right?
*  So I mean now, again, this is going to be at the start of the podcast and now we're
*  going to have, I would say like the main material with like two, well first this, first
*  one, well in this episode we're going to have one pair of participants and then in the next
*  episode we're going to have the other pair of participants and then, so after that we
*  sort of want to come back to you and then at the end of the second episode to sort of
*  to maybe think a little bit ahead.
*  Yeah, so through the magic of podcasting, let's get to the first episode and then we'll
*  revisit Nico.
*  Yeah, exactly.
*  So we're on a boat in Norway and Gauta and I have stolen you away to answer a few very
*  broad unfair questions maybe, Gauta?
*  Really cool question.
*  No, not, yeah.
*  No, unfair.
*  I don't think they're unfair.
*  Okay.
*  But that maybe you haven't sort of thought so much.
*  I don't know.
*  I think if I had to answer to these questions without having thought so much about it, I
*  don't, well anyway, but you are better than I am so, so that's why.
*  Yeah, so I mean these are kind of broad questions.
*  So one of the questions that we had for you both was how in parentheses has, you know,
*  whether neuro AI and we can talk about what neuro AI is, how has it changed the way that
*  you ask questions or approach your scientific questions?
*  Yeah, well that's a really good question but let's try and maybe first define.
*  So this is Andrea speaking.
*  Yeah, exactly.
*  So you hear this slightly, a slight Greek accent and it's Andrea's.
*  Yeah, so for me, neuro AI is sort of defined in two ways.
*  One is using the modern version of AI, which is deep learning with large data and large
*  compute to build models of the brain.
*  And the way that I think it's impacting the research that we do, one way that is impacting
*  it is essentially has changed, it has changed our thinking of embracing high entropy data
*  and then using the tools that have been developed to feed models.
*  What is high entropy data?
*  Well, meaning like, you know, you sample, let's say, natural images without being very
*  hypothesis driven.
*  You just say I'm just going to, or you do naturalistic behaviors and you record, you
*  know, without like trying to like control the behavior a lot.
*  And basically, you know, and they build a lot of tools, a lot of them are engineering
*  tools like GPUs, libraries, you know, different pipe torches and stuff like that, that enables
*  us to feed this large scale data and basically use them as statistical ways to extract statistical
*  structure from the data.
*  So that's one way that it has been impacting us.
*  The second way is that this field has been developing tools.
*  Because you have a neural network that predicts something, you know, they are trying to develop
*  tools to try and understand, get some interpretability, the whole field called mechanistic interpretability
*  and how it works.
*  And we're incorporating their tools.
*  So these are the sort of more going from AI to neural.
*  On the other hand, of course, as neuroscientists, we're always interested to build intelligent
*  systems.
*  That's a much harder thing, but it also has helped us think about what are the type of
*  tasks that may be important and, you know, what is the advantages of brains versus AI,
*  for example, this stuff about generalization, robustness, adversarial robustness.
*  So I think it has been a fruitful interaction between AI and neuroscience.
*  But how can you contrast that with the way that you used to do science?
*  Yeah, it's very different because the way we used to do science, you know, we were always
*  limited by data, both in terms of, you know, if you wanted to record from neurons in the
*  brain, even if you could record from neurons, you had, let's say, an hour, two hours to
*  do an experiment and you were developing some hypothesis that you were testing.
*  Whereas now it allows us to like control, you know, do more like non-hypothesis, more
*  data driven science.
*  So it has changed from, I would say, hypothesis driven science to data driven science.
*  Yeah.
*  Well, maybe, Kim, let's just ask you the same question if you have, because you have a different
*  perspective on this.
*  Yeah.
*  So I'm a bit more old school, perhaps.
*  So we certainly use AI technology, for example, to do video processing, the deep lab cut software
*  and other things like that.
*  As a tool.
*  Yeah.
*  To let you do science by doing video processing that wouldn't have been possible a few years
*  ago and that sort of thing, certainly.
*  In terms of AI for informing scientific questions and conclusions, for me, I'm less up on the
*  more, we certainly read stuff like what Andreas publishes using the most recent techniques.
*  For me, the really valuable concepts at the moment are still those from a few years ago,
*  such as kernel machines and variational Bayesian inference and things like these we just use
*  very fundamentally in the way we think about things.
*  So why do you stick with them because you understand them better?
*  Exactly.
*  Because these are the things that you can understand.
*  Because a kernel machine, you know exactly what it's doing.
*  You know how it works.
*  A deep network, it's found a solution, but I don't really understand how it works.
*  Maybe the point is that's the same with the brain.
*  Maybe we're never going to understand how the brain works in the same way that we don't
*  understand how a deep network works.
*  By the way, you guys interrupt each other and argue.
*  I agree that there's pros and cons here.
*  Right now we're basically putting a lot of emphasis on building a very accurate model
*  of the brain in silico that's differentiable and stuff like that, that then we hope we
*  can then analyze it to understand it.
*  But kinesync, which is another approach, and of course it has other advantages, is like
*  You start with a model that is already like building interpretability.
*  So then you feed the data, then the understanding falls out of it.
*  Whereas the deep learning approach that is more data driven, you basically emphasize
*  the predictability first, and then you hope that by looking inside the...
*  The other thing is very good to compare the two.
*  Because if, for example, you use an interpretable model that only explains half of what the
*  deep learning model does, it also says that there's really a lot that we don't understand.
*  Because I remember I read some of your papers in terms of how you train these deep networks
*  to predict like this two-photon calcium responses to all this visual stimuli in mouse.
*  And when you compare with the previous approaches with like Cabor filters and whatever, I mean
*  in terms of predictability, nothing compares to the predictability of these trained models.
*  But that sort of maybe comes at the expense of being not quite sure how it works.
*  And maybe with the interpretability...
*  So what's the interpretability of your models, Ken?
*  And these kernels?
*  Well, okay.
*  So the kernel is just a measure of similarity between how similarly a population of neurons
*  responds to any pair of stimuli.
*  So it's just a number for every pair of stimuli.
*  It tells you how similar the population response is to those two stimuli.
*  And there's a whole field of machine learning theory that went out of fashion about a decade
*  ago that did a lot of very useful work in understanding what sort of representations
*  those give you.
*  And you can use all of that to understand what's going on in the neural code of the
*  brain.
*  So you made the point earlier on, very early, that it's changed your science in terms of
*  making it more data driven.
*  I hear a lot that what we need is more theory with big compute, with big models as tools,
*  with big data.
*  So how do you think of that?
*  We're kind of in this weird space, right?
*  Where you have to explore to then generate theory, maybe.
*  I don't know how you think about that.
*  It is something that I think a lot of it bothers me in a way.
*  But also, it's like we are at this stage where the way we are doing science and engineering
*  with deep learning, it's a little bit non-classical scientific in that we figure a way, a hacky
*  way to basically build models that can drive cars around.
*  But we don't really understand them in a classical scientific way how they do it.
*  We understand to some extent, we understand the loss function, we understand something
*  about the architecture of the network.
*  But we don't have that algorithmic understanding in a more classical way.
*  And that is an issue.
*  That's a problem.
*  Now, the question that I hope, and it's a hope, is that by building very highly predictive
*  models and that can generalize very well, and internalization is key here, then the
*  fact that they are differentiable, the fact that you have a model that you can do any
*  experiment you want that is actually a neural network, which is sort of like the brain,
*  even if it's not implemented in the same way, but it still has synapses and optic waves,
*  activities, then we just have to develop tools.
*  And the AI community is already doing that because they care about that too.
*  And this is one of the issues about safety and robustness and generalization.
*  These are key things in AI.
*  That then we can leverage what they're doing, what we develop to try and gain some more
*  understanding.
*  I think once we have that understanding, then it may be possible to then think about more
*  interpretable models that are going to be simpler, that then we'll fit the data and
*  then we'll get to sort of bring it back to what Ken is talking about.
*  Do you believe that, Ken?
*  So, well, I don't know.
*  I mean, if you look in the history of science, there's some cases which are a lot of cause
*  for optimism.
*  So, for example, if you were an astronomer in the days of Tycho, but before Kepler, you
*  might have thought there's no way all of this data is ever going to end up being simpler.
*  A few years later, a few hundred years later, you have Newton's laws.
*  You've got one equation that can explain everything.
*  Same if you're a chemist.
*  Before the periodic table, you would never have guessed it was going to be that simple.
*  On the other hand, if you're a biologist before the genome, you were then confronted with
*  the fact that there's 20,000 genes and they're all different and you're never going to know
*  what they all are.
*  So we don't know for neuroscience whether...
*  But there's a difference.
*  Those weren't complex systems, right?
*  The DNA code readout is not a complex system.
*  Whereas with brains, we're dealing with a complex system.
*  Does that difference make a difference, do you think?
*  Well, the solar system is a pretty complex system.
*  It's complicated, but it's not a complex system.
*  Well, I guess three-body problem.
*  What's the difference?
*  Well, complicated just means hard, lots of parts.
*  Complex means interacting parts where there's emergent properties.
*  It's sort of the stable.
*  You can predict the planet orbit of Venus 500.
*  Oh, you mean chaotic.
*  Yeah, chaotic.
*  I think complex systems are often chaotic, right?
*  Or not always.
*  That's true.
*  We are not chaotic.
*  Often properties of complex systems.
*  That's right.
*  Anyway, yeah.
*  Also, maybe that's...
*  But your point was things have looked impossible for over and over in the history of science
*  and maybe this is one of those things.
*  Things have looked impossible over and over.
*  Sometimes they weren't.
*  Sometimes so far they still appear to be.
*  And we're in that regime.
*  Well, we don't know.
*  I think if I can come back to what you said, Andreas, that now you're doing this training,
*  these deep networks, difficult to understand and you hope to get...
*  That is our form of basis for more interpretability.
*  And then, of course, we have better tools for understanding how the brain works.
*  But at the moment, given what you sort of have at the present stage, has it sort of
*  anything new about the brain or cognition that...
*  Yeah.
*  I think that's a really good...
*  I think it's still early to know if this is going to be...
*  If the way to the future is like this is going to be like the standard.
*  But there are cases where, for example, this starting contextual modulation in the visual
*  cortex.
*  People have been studying it with the gradings and they found a specific relationship between
*  centers around interactions.
*  And then when we followed these image synthesis using these deep learning methods, we got
*  something that was different.
*  And the nice thing here is that then you can verify it back in the brain.
*  You can run this closed loop experiment.
*  That's right.
*  Inception loops, right?
*  Inception loops, yeah.
*  Yeah.
*  So that's one example where it's not a circuit level mechanistic model, but the description
*  of how the centers around interact, we gained some new understanding that...
*  The other thing is once we do that, then you can design experiments in a more classical
*  way because now you develop the hypothesis, then to test it and then do exactly what Ken
*  has been talking about.
*  And in fact, we did build a model like that.
*  We built a more Bayesian model that can try and explain centers around interactions based
*  on natural image statistics and priors.
*  In the primary visual cortex.
*  Yeah, in the primary visual cortex.
*  So I think that's one example where you start with a data-driven model that there's no interpretability.
*  It's just sort of an engineering task.
*  Then you analyze it, then you derive a principle or some understanding.
*  You test it back empirically to see if it's correct.
*  And then you build a simpler model that is more based on more classical stuff like in
*  this case was hierarchical Bayesian inference and see can a model of hierarchical Bayesian
*  inference train on natural images, predict at least qualitatively the same type of effect?
*  So I think that's an example.
*  You started your talk today with the clip of 60 Minutes of Hubel and Wiesel serendipitously
*  discovering the edge that...
*  So they were moving a piece of paper, they were trying to test the visual neural response
*  to dots and they happened to move the transparency or whatever it was off the screen and part
*  of that transparency, there was an edge where that transparency ended.
*  And that's how they discovered edge cells.
*  And that's a data-driven approach or an exploratory approach, but it was also serendipitous.
*  And it made me think right when you were showing that, are we past that stage where we're going
*  to...
*  How does serendipity play a role these days?
*  Ken, you're shaking your head.
*  Well, over time, almost everything we do is serendipity.
*  You get your data.
*  Normally you have a hypothesis in mind and when you get your data, you realize, oh, actually,
*  wait, that was never going to work anyway.
*  But then you notice something a bit odd in the data and it's probably a bug, but you
*  chase it up and, well, it doesn't seem to be a bug.
*  And then you follow it up a bit more and then there's something you don't understand and
*  you don't understand why you would see this.
*  And then you try and figure out why you're seeing it.
*  So it's the analog of, oh, what's the famous quote when science progresses by saying,
*  huh, that's funny.
*  Exactly.
*  Does anyone remember who said that?
*  I'll have to look it up later.
*  So is there any way that AI has set neuroscience back?
*  Or put some or many or all neuroscientists on the wrong track?
*  It's probably led to some blind alleys, but the problem is we don't know which ones they
*  are yet.
*  We will in the future.
*  Do you think, so I worry that it can, in a lot of, especially young researchers' minds
*  might confuse the map with the territory and that people, in terms of people thinking of
*  the brain as a transformer, you know, and sort of substituting the model for the real
*  thing and then that conceptual framework then frames their research questions.
*  And I wonder if that has had a deleterious effect at all.
*  Yeah, I mean, it's early.
*  It's still early to know where this thing is going to progress right now.
*  But because there's also this kind of two-way interaction, some people are working, you
*  know, it's like using tools from AI or as a model of the brain.
*  I do think that there is some danger here of like, basically just doing like, using
*  it as an engineering tool that is sort of the end game versus it's just the beginning
*  of the end.
*  So I do think it's important to like just see it as a tool right now and not take it
*  as just sort of like, OK, if I just take a model and I build it and it works great, I'm
*  done, I should move on to something else.
*  I think there's a little bit of that.
*  It's a lower threshold for starting doing it, right?
*  I mean, if you have tools like whatever, PyTorch, TensorFlow, you can sort of quite easily train
*  networks to do something.
*  So maybe it's sort of you don't, I mean, if you do like traditional statistical analysis
*  is, it takes more effort to get into it, maybe.
*  And certainly compared to like the physics type modeling, which is like the threshold
*  for getting into it is more like a basic tool.
*  So this is, but I guess low threshold is both good and bad, right?
*  I mean, it means that it's easier to test, but it's also easy maybe to do things which
*  are not that high quality.
*  Is there a danger that it introduces less critical thinking from the beginning?
*  There is definitely that danger from AI in general, right?
*  Like, I mean, it's sort of one of the, you know, like, you know, there are people that
*  trying to build, let's say, autonomous AI scientists to analyze the data for you, right?
*  I mean, I don't think it's going to happen around the corner, but there is...
*  It might replace me.
*  It probably won't.
*  No, no, I mean, but this is an issue, right?
*  Like it's easier to, you know, but on the other hand, you know, that's what I mean,
*  I think historically people were worried about when calculators came around, people were
*  not.
*  So I don't know.
*  I think it's important to just use it as a tool, but make sure that people are educated
*  and they're doing the critical thinking.
*  Every new technology introduces new ways of doing things well.
*  And you don't think this is different at all in that respect?
*  No, not really.
*  More is different, you know?
*  Well, it could get...
*  It's easier to fool yourself when the thing trying to fool you can speak English.
*  Fluently.
*  Right.
*  That's true.
*  By the way, just as an aside, I have to commend you because you worked on a talk, and I think
*  against your will, the talk that you gave, you like really put thought into it and tried
*  to address...
*  So the talk was on...
*  What was the talk on?
*  The talk was on what would it mean to say that a system such as a deep network is a
*  good model for the brain.
*  And did that drive you crazy creating that talk?
*  Well, I thought at first I was going to say it's impossible and ended up after thinking
*  about it thinking that it could be possible.
*  I don't think it's been done yet, but it's not actually impossible.
*  What it would need is an interventional experiment where you have a mapping between the artificial
*  system and the brain that not only shows they have a similar representation of information,
*  but also if you perturb them, you perturb the network that causes a change in the rest
*  of the activity in the network in a way that maps onto the way a perturbation of brain
*  activity would.
*  Then you can say there is a mechanistic similarity in how they're computing information, not
*  just a similar representation.
*  But you also said that a model is something that shows what is not possible.
*  Yeah.
*  Yeah.
*  How does that fit in?
*  Oh, I think that's just what science is.
*  I mean, that's falsifiability.
*  Falsifiability, exactly.
*  I was trained as a physicist and there it was looked a little bit down upon by active
*  physicists to talk about philosophy.
*  It was all like this idea, shut up and calculate.
*  Yeah, they did it instinctively.
*  Are we talking too little about these kind of questions?
*  I mean, what does it mean to believe in explanation?
*  This is, in some sense, our job for the last decades to do science, which is about this.
*  And still, we don't really formulate it often to ourselves.
*  Yeah, well, that's why I was asking Andreas, too, if we're in a weird space because you
*  have to explore with all these new tools.
*  I think we are in a, I mean, to me, we're in a more weird space than I've ever experienced.
*  And I think it feels like different, something qualitatively different than before.
*  Why do you say that?
*  Because I think the reason is because we are capable of building systems and models that
*  seem quite intelligent, very intelligent, are capable, have capabilities.
*  You know, I bought a Tesla and I drive it and I'm really impressed by it.
*  I mean, you can drive for hours in a very complex environment and it's really impressive.
*  But then at the same time, you know, it's a neural network that nobody really understands
*  in a classical scientific way.
*  And I think that and I do think it's a technological advancement of these two things.
*  We have data, you know, we are in, I'm talking not just in neuroscience, but
*  generally in biology, in medicine, in, you know, the way you have cameras everywhere,
*  collect data, the internet, right?
*  Basically, we've created a society where it's made it easy to collect a lot of data.
*  And then we have computers that became very fast and we put these things together with neural
*  networks and we build all these very complex systems that are capable of complicated things.
*  But again, we don't understand them.
*  So I do think that, you know, there's some danger here, right?
*  So you're not talking about science specifically, you're talking about the state of the world.
*  I'm just talking about the state of, yeah, basically the whole, you know, if you look
*  at, let's say, AI in general, I mean, and neuro AI is just neuroscience using AI.
*  You can think of, let's say, the people who predict the storm market using AI,
*  people that are trying to build autonomous driving.
*  I mean, they were doing it before.
*  Yeah, all these areas, even in physics, they're using AI.
*  Yeah, because that's, I mean, the Feynman and other physicists said that if I can't
*  build it, I don't understand it.
*  Or if I understand it, I can build it.
*  It didn't mean like physically build it, but meaning make a physical model, physics type
*  model that essentially kind of, and now we're just over finished because now we put in these
*  learning models and so we build things we don't understand.
*  Yes, exactly.
*  Which is sort of a new thing, right?
*  Which is very fascinating.
*  So now we have made this fantastic large language model just thinking about what it can achieve.
*  And we don't understand, it's like a research project.
*  We just do research on it just like we do on a test animal, right?
*  Which is really fascinating.
*  We build something, it's manmade, but we don't understand it.
*  Yeah.
*  And my impression is we went through that before, somewhat during the industrial revolution.
*  People, the first steam engines were built without really understanding the dynamics.
*  And in fact, they were not safe.
*  They used to blow up all the time.
*  And it only became after people started doing measurements, especially after discovering
*  low thermodynamics and pressure, things became so.
*  So maybe we're going through that phase.
*  Well, at least we know that AI is safe and doesn't affect society.
*  Exactly.
*  Nobody worries about that.
*  That's really interesting because the electromagnetism,
*  there the revolution came after the Faraday and Maxwell and like these people.
*  So that's sort of, but it's true.
*  The thermodynamics sort of came after the steam engine.
*  They made things like entropy, this type of electron and energy conservation and stuff.
*  So if we are in a weird space right now, just scientifically then,
*  one of the questions that we were going to ask you was how long are we going to be in this
*  space?
*  Like what role will AI still have a role in 50 years or will we have used it to solve
*  lots of brain problems?
*  I'm not going to say solve the brain or solve intelligence, but will it have been a key factor
*  or is it a fad, will it go away?
*  I'll tell you what I mean.
*  I think about this a lot.
*  I don't think I've never been in a situation in my life that I'm really curious what's going
*  to happen in five or 10 years.
*  Are we going to really have AI that's going to basically solve not just very difficult
*  questions for the brain and neuroscience, but let's say health, I don't know, climate change,
*  or is it going to be like the iPhone?
*  When the first iPhone came, it was amazing.
*  Now we have, I don't know, what is it, model 13.
*  It kind of looks similar, right?
*  It is better apps, but it's large language, most of all this thing is just the fad, as
*  you said, and in 10 years we're going to be like, yeah, you know.
*  In fact, in the last two years, I wouldn't say it's like
*  impressively amazingly getting much better.
*  If you look at 3.5 versus 4.0, yeah, it's a little bit better.
*  It does some things better or is new applications.
*  It can do video now, but it's not like, you know, a collectively new type of thing.
*  We're getting incremental changes.
*  Now that doesn't mean it will remain like that, but I think it's sort of very interesting
*  because it's like, you know, in some days I wake up and I feel like, oh my God, this is it.
*  And others are like, yeah, you know, not much is going to change.
*  One thing is that these stuff relied a lot on the scaling laws.
*  And I do believe that there's a big problem that these big companies are facing now.
*  They're just running out of data to train their models.
*  Scaling in terms of like computers or data?
*  Both.
*  Both.
*  The scaling law is both larger computers, I mean, basically more energy and more data,
*  but data, you know, they're synthesizing data, but it's a niche.
*  Little bit incestuous.
*  Yeah, exactly.
*  A lot of the stuff they're doing now is like data selection because there's a lot of,
*  you know, they've shown that if you select the type of data you train,
*  let's say large language model or a video, it may make a big difference, but it,
*  it does feel like to me that there could be things like in robotics with VR, people wearing
*  cameras and collecting their body movements and imitation learning, but it's possible that
*  we are sort of going to have incremental improvements or maybe there will be a new
*  revolution. I don't know. And I think that's going to impact us too.
*  Sure.
*  You know.
*  So I think you're right. Even if there isn't another step change though, just the one we've
*  already had.
*  We don't even know how to deal with it yet.
*  Yes. It is creating a lot of changes to societies in ways that are going to be unpredictable,
*  like the industrial revolution. So for example, a friend of mine, it works in classical music.
*  She has a lot of friends who are composers who used to write for film schools and now
*  they're at work because that's something that AI can do pretty well is write classical music
*  for film scores. And you know, who would have predicted that, you know, and society's going
*  to change in a lot of ways. There was, what was it called? There was something that had an AI
*  girlfriend app. I think that's gone away.
*  Japanese thing. I think that's popular.
*  Yeah. But there's all sorts of ways that society may really change that we just can't predict,
*  even if there isn't another revolution.
*  So if, I mean, they go back to the science because I'm sort of doing sort of like physics
*  type modeling, sort of like extensive Hodgkin-Huxley and like multi-compartment models and
*  networks and so on. And it seems now that like computation neuroscience has always been like a
*  small subfield of neuroscience. And now I also feel that maybe computation neuroscience is
*  because you have all this AI. I mean, if you want to go into computation neuroscience, maybe many
*  people go into this using this AI tools so that sometimes it is physics going to be a
*  traditional computational neuroscience. I have this hope and maybe there's an idea
*  when you push this sort of learning roots and stuff at some point to understand more,
*  we have to get back to the biophysics of neurons and stuff.
*  It'll be important in the end. Yeah, sure.
*  It's an important point. What physical brain neurons do is so much more complicated than
*  unit threshold ReLU units. And that's surely important.
*  For what though? Maybe not to explain cognition. Maybe it's important for
*  what question is it important?
*  Okay, if you took your brain and you replace every neuron with a ReLU unit,
*  I would predict your cognition would be severely impacted.
*  Do I still get plasticity though?
*  Yeah, you just don't get any iron gate voltage, get your iron channels, no intrinsic oscillations.
*  My brain again might not be that different, but maybe years from now.
*  Yeah. So yeah, I think that's an important point that the physical brain for whatever reason
*  it has all these different cell types, the cells are very complicated. Maybe it didn't need to be
*  like that to have an intelligent system, we don't know. But it is like that. And neuroscience,
*  which is whose goal is to understand our brains rather than just to come up with an
*  intelligent system, that stuff is going to matter. But then don't you, I mean, isn't there a limit to
*  the biophysical detail that you would need to implement? And can't you just figure out if there
*  are a thousand different types of neurons in the brain, give them a thousand different activation
*  functions and other algorithmic profiles, for example?
*  So you're saying you don't need to simulate every single channel.
*  What's the bottom, where is the bottom layer that matters?
*  I agree. I mean, I think that is a very interesting question, right? And I don't know the answer,
*  but one possibility is the following, right? To really understand cognition and behavior,
*  you really don't need to go down to the iron channels and the non-linearities and the dendrites
*  at that level, because it's just a bridge too far, it's too complicated. Just understanding
*  it at the representational level and manipulating it may be, as you said, can't at that representational
*  level. So you have an AI system that represents information and you have the brain and you study
*  that this representational level and you manipulate them at this representational level and you try
*  to understand them, it's enough to build, to understand the science of intelligence or the
*  loss of intelligence and build systems that are intelligent. And maybe they are computational
*  neuroscience in a traditional way, maybe in trouble, but there is another way that is very
*  important, which is diseases. In order to intervene, and maybe that's what Ken was saying,
*  like in our brains, let's say psychiatric diseases, neurological diseases, they're not
*  railroads. I mean, they have ion channels, they have molecular pathways, they have dendrites,
*  you know, if you look at autism, the spines are different. And there is where maybe people
*  that are doing more, let's call it physics based or more classical biophysics, computational
*  neuroscience should maybe pivot in that direction and that field probably needs people like
*  computational and also that's where probably like, you know, most of, if you look at it even
*  from a practical point of view, where the funding is and what let's say NIH cares about is to cure
*  diseases more than to really understand the algorithm of perception, right? So I do think
*  there is an opportunity. I'm going to quote you in my next application. Yeah. Like the great Dr.
*  Tullius. But even those details, like I think that's a good point about diseases and how that those
*  lower level reductive small molecules, dendritic shapes and spine sizes, et cetera, matter at that
*  scale. But then just like an artificial unit, if you can abstract what's important about how
*  that affects communication, that might just solve it. Yeah. You won't need to know every single
*  potassium channel, but I think there will be, to make an accurate model of how the human brain
*  works. You will need to incorporate things like dendritic nonlinearities and oscillations
*  in some simplified form. That's what I would. But also, I mean, we are sort of, I mean, if you think
*  still we haven't really figured out what sort of mind or whatever conscious, I mean, this feeling
*  of mind, which is different that we are not only sort of looking at statistical relationships when
*  we sort of infer things, right? We have this first person perspective and so it's more to our
*  intelligence that just sort of the things that are picked up by AI, I would think. So that's
*  saying that maybe this is where, maybe you need these kinds of things to- Well, it's funny. I
*  asked a large language model the same question that said the same thing. Really? Did it say that
*  they had a mind or that they didn't have a mind and we need to look at, we need a better brain
*  model or something? No, I'm just saying that the fact that you just said all of that,
*  any agent could say that. Yeah, but you believe that I'm conscious, not you? I mean- I don't know
*  what that word means. Really? But I- Oh no, let's not do it. Let's not do it. Okay, one sentence on
*  the topic of consciousness. The moment you actually define the word, it becomes quite a boring question.
*  But I think it feels like something to be Ken. I think it feels like something to be me and
*  Andreas and Paul. I'm not quite sure if it feels like something to be a large language model.
*  I don't think it feels like anything to be Ken. Just kidding. No, that's correct.
*  Oh, gosh. Anyway, we went off to the consciousness. Yeah, and so we're at like 35 minutes.
*  Yeah, but what's switched to what? Why don't I just want to take up everyone's time and everything?
*  Oh, they have plenty of time. They are on the boat. Where should they go?
*  Okay, go for it. Okay. No, I mean, sort of, yeah, we have one question. I just read this book
*  on called Slow Productivity. I think it's one of these. It's almost like the kind of book that you
*  pick up at an airport, but it was sort of interesting in the sense that what does it need to be an
*  efficient knowledge worker, which is different from being an efficient farmer or an efficient
*  because then you measure the output. And then sort of what does it mean? So I thought what does it
*  really mean? So the book claimed that then since it's not easy to define knowledge, productivity
*  and knowledge workers, you make these proxies to sort of to look busy, sort of. You're in a
*  you work for a company and they sort of just look busy when the boss is coming, right? And
*  are we and maybe some of these things when you sort of look at sort of how we
*  survive in science is like having many papers and is this so this has sort of become a proxy
*  for productivity, not only numbers, but also the quality and just add also like especially in the
*  neuro AI space. One way to look really productive is just to throw a neural network at whatever
*  problem that you have without considering the theoretical framework or questions or
*  hypotheses, right? So I just wanted to. Yeah, I just want to. So I was thinking,
*  what does it really mean? I haven't thought of didn't think too much about it, but what does it
*  mean to be productive in science? Besides paper advice? I mean, it's like this mundane things of
*  surviving and funding grants and getting a job. Yeah, I think it's a problem. I mean, you know,
*  there is I mean, this is the way science is, right? It's like it's not, you know, the way that I like
*  to be justified is that we humans didn't really evolve to science. We evolved to the other stuff.
*  And science is something that we started doing in the last few hundred years. Right. And it's kind
*  of remarkable how much we've advanced science is humanity. So whatever we've been doing, even if
*  it's like at any given point in time and one of us, it looks like it's very incremental and we're
*  not doing much, you know, as a species, we've done tremendous advancement. Right. So some ways why,
*  you know, now doesn't need improvement. I think it does. Right. Like, you know, and one of what
*  you are saying is maybe the way our reward system is of the classical academic system may need to be
*  reformatted to some extent, like some of these questions may require more teams working on it.
*  We are credit is, you know, it's not about just publishing the next paper, but it's more about
*  like working on a project longer, maybe, you know, allowing people to work as a team on the project
*  longer and having a way to like reward them, you know, maybe allow some more risk. But do you mean,
*  personally productive? Yeah, I know. Just because I mean, I understand people who don't have permanent
*  jobs and want a permanent job. That's like a different thing, right? Or, but I'm sort of like,
*  like, like a professor with a permanent job. So I can in principle do anything I want, but that's
*  still you sort of as a professor, when you sort of easily get involved in too many projects,
*  because you don't sort of want to be that it feels good. Sometimes if I'm, if I'm doing this as well,
*  you get brought into podcast conversations. Exactly. But I mean, it's sort of this thing,
*  there's a bit of a danger. Yeah, I think it's just something that my own sort of the psychology of
*  people makes it makes us be very stressed sometimes. And often, you end up, we can this
*  breathing here, right? And often when you have several PhD students, and you have, and you have
*  some responsibility, feeling of responsibility, you, you have maybe have to spend most time on
*  the project, which is working the least. So you have to sort of to try to salvage it, right? So
*  sometimes I think I would much rather work on the thing that this person is doing, because that's
*  the whole great thing. So it's just something about something about psychology of how we make
*  choices. The best thing for my productivity was when I formed a team lab with Matteo Carandini.
*  And there's just something about that, that, you know, when you got two people, I might have
*  an idea, I think it's great. But then he says, wait, but did you think x? Oh, you know, and then
*  you save so much time. Just by that. I mean, you have a lot of collaborations as well. And
*  similar similar thing. But do you also feel the responsibility to be productive for the other
*  person? I mean, do you feel up? Does that just having a collaboration make you more likely to
*  do the work you need to do the work? Yeah. Okay. But you feel like there's someone to remind you,
*  you know, you didn't you say you were gonna? Oh, yeah. So put yourself worth in someone else's
*  head. But that doesn't mean that you sort of sometimes are just getting stressed and not able
*  to think. Yeah. When was life not like that? No, it's not. That's all that there's the
*  Dodds-Yerkes curve. But I heard for example, and then Francis Crick, obviously, he was
*  after he sort of like after I sorted out the DNA and also like this, whatever the
*  other proteins and I called it exactly. Then he sort of after it, and they he wanted to stay under
*  busy. So the thing that I think he just wanted to have so few projects that that he gets always
*  jump on something which was really exciting. Right? Of course, then he's sort of in a position
*  where you can sort of like you don't have any social constraints or practical constraints. But
*  it's this thing that Yeah, no, I don't know. I've been thinking about that lately, sort of what is
*  what is sort of external pressure? And what is just internalized? Do we make silly choices because
*  we are just internalized some kind of behavior? We surely do. But the moment you try and come up
*  with how to change the system, I mean, the things you're saying about these changes in centers,
*  it's all good. But these are minor. This is all fairly minor changes, right? The system
*  isn't perfectly efficient. But when you try and think how to make it better,
*  it's quite hard to come up with anything radically different. Absolutely. So this is not what I'm
*  more thinking that even people who are but people should maybe like when people have like a noble
*  Christ, they can sort of, for example, and I try to be under that I said that to you. Yeah, I said,
*  well, here's like for the quick example, he's already famous, he can do that. Sure. But I mean,
*  I can do I'm not. But I can do what I want. Also, I think that many people at some stage in the
*  career, Maxwell, the physicist, James Clark, spent something like 20 years trying to find a
*  particulate explanation of electromagnetism. Yeah, right. Yeah. You know, there's so many cases,
*  but you know, you don't know what's the blind alley. What would happen if you sort of decided to
*  now go to solve some kind of just focus on one particular mathematical problem related to
*  neuroscience analysis would would you we wouldn't be fired, right? Would you or I don't
*  I'd need to have a conversation with my boss. Yeah, she'd kind of okay, you know,
*  you used to get a lot of grants. Exactly. But you are just you have actually changed your just moved
*  to Stanford. So you're trying to try to make a good impression. You know, we can do whatever we
*  want. But you know, if you keep I mean, especially in the US, the system is very competitive. I mean,
*  it's true everywhere. But I'm saying it is a little bit like running a little startup in the
*  media, you know, especially in medical school. So you have to bring in resources. And then,
*  but I do also think, you know, what you said about Creek is interesting, right? Because,
*  you know, I think we're still at the stage where, you know, I mean, obviously, the most important
*  thing is to choose the right question. But it's not clear like this, like, this is the question,
*  right? There's always like a lot of possibilities. So we try and sort of, we have to remain focused,
*  but also remain open minded enough to see what new things may be happening.
*  Here's a different way to ask the question. What makes you feel unproductive?
*  Web surfing. Web surfing. Okay, I don't mean yeah, I mean, in science, you know, not like
*  And you cannot answer this conversation. Yeah.
*  No, I think, you know, sometimes, you know, like, you can be unproductive, you know,
*  it's hard to know like, like sometimes you feel you're unproductive, because you're like,
*  sort of your daydreaming or you're like, a year goes by and you feel either it was a productive
*  or an unproductive year. What do you think made it productive or unproductive?
*  I think it's more, it's complicated, right? Like, there could be years where, you know,
*  we may not be publishing as much, but you know, you feel you're very productive because you're
*  doing experiments, you have new results. You're laying the groundwork.
*  Yeah. So I wouldn't say like, there is a metric, you know.
*  I've spent a lot of time over the last few years on statistical methods that a few of them have,
*  I've written preprints, not one of them has been, I've even submitted a peer reviewed paper.
*  But I do think it was worth it. And maybe I'm at that stage now, I can do what I want. So I've
*  spent a lot of time on these questions of like statistical analysis.
*  Then it seems like you actually educated yourself also.
*  Oh, yeah, absolutely.
*  So that I think, because I think for me, like an unproductive project would be something I just
*  join, you know, I'm not particularly interested, not particularly challenging, but it has some
*  reward in terms of maybe getting on a publication. So you spend your mental resources on the...
*  Things you don't really find interesting.
*  If you do, and it's not really building up to anything. I don't really need like
*  a new AI for tax laws or whatever.
*  Maybe we could...
*  This is an actual project.
*  Yeah, okay. I don't know. No, no, this is not an actual project. But I was thinking if...
*  It's an example.
*  An example of something which is important, but not really...
*  Okay, Paul.
*  Let's just move on then and ask perhaps the closing question. By the way, the quote was,
*  it's from Isaac Asimov. And I did use chat GPT to look this up. So hopefully it's correct.
*  The most exciting phrase to hear in science, the one that Harold's new discoveries is not Eureka,
*  but that's funny. That's the quote. Isaac Asimov.
*  I'm glad I didn't say Einstein because everything is attributed to Einstein.
*  We had this discussion, this question, this one we sort of prepared yesterday.
*  And this question of sort of... I've been thinking of this question of if, I mean,
*  that if for some reason there was a moratorium, it was almost like the pandemic where you couldn't
*  experiment for a year so that everybody had to sort of work on existing data.
*  And would that be a good thing? Because now I have a feeling that it's all these things that
*  you've measured and you don't really understand it. So, oh, let's put in another mouse.
*  Can I go beyond that and say that you weren't even allowed to analyze existing data? All you
*  could do is read the literature.
*  Yeah, you got shut down. I mean, that's why everyone, like 90% of neuroscientists,
*  wrote their first books during the pandemic. There's a bunch of books.
*  Okay, so exactly. So would it be a good thing? I mean, I don't want to live in a society where
*  this is happening.
*  If all I could do was read papers, I'd be very happy.
*  For how long though?
*  Oh, a year. I mean, yeah, I don't need to write anything.
*  Don't you want to do the science? You just want to read and learn?
*  I think, so you talked about Francis Crick. That's basically what he did in neuroscience.
*  He just read papers and he tried to figure things out and then he wrote...
*  He wrote a book, he wrote review articles, but that's all he did. It was very valuable.
*  Yes, no, it's true. I think different people... I mean, I think we need to do more experiments.
*  Yeah, I'm more thinking about the moratorium to think about what we have and then...
*  Yeah, I think thinking, stopping and thinking about things, I think is very, very important.
*  Yeah, none of us do it really.
*  But it's easier. It's so much easier to do the next experiment than to think. Exactly.
*  Yeah. Well, it's also when I do simulations and I change parameters and it doesn't really work.
*  And then I, oh, let's try another parameter set because it makes me feel like I'm doing something.
*  Well, actually, I'm just sort of avoiding to... trying to avoid to think.
*  So we shouldn't have another COVID? Is that the take home? Or we should?
*  I don't think we should.
*  No.
*  For several reasons.
*  To think. I think there's a lot of pressure to keep, you know, stay in the rat race, but I think
*  figuring out ways to get outside the rat race and think, it's always important.
*  Yeah.
*  I have maybe a quick question before our last question, if you guys have a few more minutes.
*  How do you know when you have a good idea, scientifically?
*  Like, how do you... when you kind of feel like, all right, this is a good idea without much vetting of the idea.
*  Before you ask your experimental collaborative.
*  No, you just know.
*  Is it just an intuition?
*  But don't you have those intuitions that turn out to be bad ideas?
*  Oh, yeah. Lots of times.
*  Then how do you know? How do you decipher if you...
*  Well, you know, you wake up, you know, they normally come in the middle of the night.
*  Right. Or in the shower or...
*  Yeah. And then if you still think so that afternoon, that's a pretty good sign.
*  Okay.
*  I agree. Something, you know, sometimes you think you have a great idea and then you think more about it.
*  Isn't that the best feeling in the world though? Like when that thing hits you and you're like, oh.
*  But I had this great business idea in the middle of the night, and which was,
*  we woke up and I had to write this down because I looked at the morning. It was just...
*  Well, that's good.
*  That's good.
*  Completely ridiculous. I felt so in the middle at four o'clock, four a.m.
*  But that's good because you could falsify it. Because I fail to write mine down all the time.
*  Exactly.
*  And then it goes off and I think, well, I still come up with good ideas, but who knows?
*  Exactly.
*  Because I've forgotten them.
*  So mine was not very good.
*  Yeah.
*  So intuition.
*  That's...
*  Intuition is key, yeah.
*  Okay.
*  Yeah, so the last one. So this is like the advice to young researchers.
*  This is Gauta's question because I've stopped asking this on my podcast.
*  Okay. So then it's...
*  I'll include it for sure. I like the question.
*  Yeah. No, I mean, you are sort of very established researchers.
*  And so what would you sort of... What is the advice to...
*  My advice is, especially I think this is generally true,
*  is to young researchers is spend a lot of time thinking about what is the question that you
*  really want to address and talk to a lot of people. Don't just like do it just because
*  you want to get some training. Just sort of focus on the question more. And it's okay to kind of
*  explore stuff and be thirsty sort of for a good question. And I often find like
*  people are being too practical and jumping into a project and then you're going to get training.
*  I'm going to do this. But I think it's very important because one thing that I didn't...
*  My experience, but also this is true in the history of science,
*  it doesn't matter how motivated you are or how much hard work you put. Of course, these are important.
*  But often like, I mean, Francis Crick is a perfect example with the double helix, right?
*  It wasn't in their project, but it was a good question. The work done, he did an amazing
*  discovery. So I do think that we kind of maybe don't spend enough time. And this is something
*  we don't get trained as undergraduates or in high school. We don't think, okay, what's a good
*  question? We just thought facts. And then suddenly when you start doing research,
*  now you have to start thinking about questions. And it's a hard thing to do. And I would say
*  for young people, spend more time thinking about what is really the question that I want to do.
*  So this is one thing. Unless you nearly have something that you're very excited about,
*  you're very curious about, that's the best thing of a scientist. If there's something that you're
*  like, if there's something that you're very curious about, just follow your curiosity and what
*  really excites you. But if you're trying to choose, you say you want to become a scientist
*  and you're trying to say, okay, what should I work on? I'm excited about a lot of stuff or I
*  can get excited about a lot of stuff. Spend a lot of time thinking about the question.
*  Would you, just linking that back to that productivity question, would you consider that
*  productive? Yeah, I would think of that as very productive, even if it looks like you're not
*  doing anything for a month or a year or a couple of years. I think because it's like a big boat,
*  right? Once it takes off and goes into a direction, it's harder to steer it. So at least it's
*  important. Unless you have something that is like, okay, I'm very curious, I don't know about
*  a problem in physics. People are just curious about something. They can't sleep, they stay up
*  at night thinking about it, then go for that. But if it's like you're trying to get a PhD and
*  you're interested in neuroscience or molecular biology or genetics, there's so many stuff,
*  there's so many labs, just put effort thinking about what is the question and educate yourself
*  more broadly. Don't just go very narrow. You're going to have to go narrow and focus for sure.
*  But start broad, like what is the impact of what I'm trying to do? Where is this field going?
*  I think it's important. Yeah, so what I'd say is you have to enjoy it and if you're not
*  enjoying it, switch to doing something else that you do enjoy. Do you have to enjoy 24-7?
*  No, but on balance it has to seem worth it. And if you ever think, why am I doing this?
*  Then think, how can I change it so I actually want to do it? And if you can't change it so you want
*  to do it, then do something else. Because there are other options and if you're not at the point
*  of science, you're supposed to enjoy it. So if you're not enjoying it and you can't figure out
*  how to enjoy it, then do something else. But I guess also there is some, I mean,
*  obviously you are sort of successful, you're sort of like a survivor bias because you actually,
*  well, at least you made it to get there. So far, so far. So far, exactly. But I guess people,
*  like young people listening to this, they think, oh, I mean, I enjoy it, but what's the,
*  and if I want to, I enjoy being like doing research, maybe get a position in academia
*  or at the research institution doing basic research. But what are my chances for actually
*  making it? I mean, this is always that thing also, right? I mean, investing many, many years.
*  It's not like you can't do something else. I mean, so, you know, for me, I very nearly
*  stopped. Tell us more about your story. You have a quite unusual story. So my,
*  yeah, very unusual. So my, my PhD, well, I started doing physics, switched during my PhD,
*  which funded me to do anything I wanted anywhere in the world. So I thought about all sorts of
*  things. And that's a nice goal. I know it was great. It was the fine print. Lots of American
*  citizens have this. They just don't know they have it. Okay. And so I ended up doing kind of
*  neuro robotics in London. And, you know, it wasn't that much of a success, my PhD, really,
*  but because, but your bachelor was in mathematics, it was in math. And, but because the lab I was in
*  didn't have any continuation of funding, I had to fund myself. So I got a job building a very early
*  internet gambling website. And very easily could have stayed doing that. It's only a few years
*  ago, actually, that I finally earned more money than I was in that job. So yeah, I mean, there's
*  always other options. You know, pretty much everyone doing this job can code. You know,
*  you have other options. I could have been a stay on bad. That would be great. Yeah.
*  Because I think I like at least when I when I have my students ask me about this, I say, well,
*  taking a PhD on user learning how to come up like scientific programming, coding and stuff.
*  That's, that's, that's always going to be good. That's I wouldn't worry about that. It's more
*  maybe if you decide to go on postdocs, then you are sort of that is that's more of a bifurcation.
*  Cut you off. Do you think it cuts you off? I don't think so. I don't really know. I've had
*  postdocs go and work in data science have done great. Yeah. And they even got good jobs. Yeah,
*  excellent. Yeah. Maybe I'm too too pessimistic. Maybe. Thank you, guys. Thank you. Anything else?
*  Yeah. By the way, Christina, are you first of all, you're cheating by being in this room.
*  Secondly, oh, she said you're not you're not waiting for us, right? No. Okay, I just I just
*  realized. Oh, because Tom is out. Tim is out talking. Yeah, yes. I just I thought now you
*  know what we said you can see the rest. Okay. Anyway, thank you guys. Thank you. Great.
*  Thanks.
*  Brain inspired is powered by the transmitter, an online publication that aims to deliver
*  useful information, insights and tools to build bridges across neuroscience and advanced research.
*  Visit the transmitter.org to explore the latest neuroscience news and perspectives
*  written by journalists and scientists. If you value brain inspired, support it through Patreon
*  to access full length episodes, join our discord community, and even influence why invite to the
*  podcast. Go to brain inspired.co to learn more. The music you're hearing is Little Wing
*  performed by Kyle Donovan. Thank you for your support. See you next time.
