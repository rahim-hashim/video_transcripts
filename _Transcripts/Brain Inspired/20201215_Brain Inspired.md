---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 6133s
Video Keywords: ['Science', 'Technology', 'Education']
Video Views: 11018
Video Rating: None
---

# BI 092 Russ Poldrack: Cognitive Ontologies
**Brain Inspired:** [December 15, 2020](https://www.youtube.com/watch?v=BSa7HWLH5bI)
*  A cognitive ontology basically says, what are all the parts of the mind?
*  You know, what are all the things that we think minds do?
*  A lot of the ways that we kind of chop the mind up are almost certainly wrong, where
*  by wrong I mean they don't reflect the computational organization of the brain.
*  What's the secret?
*  Why do you maintain such a healthy balance while still being productive?
*  You're assuming that I actually maintain a healthy balance.
*  This is Brain Inspired.
*  Hey everyone, it's Paul.
*  When I entered graduate school, I wanted to study consciousness, how our brains give
*  rise to awareness.
*  It didn't take long to realize just how little consensus there was about what consciousness
*  is, let alone how to study it.
*  Depending on who you talk to, very little or some appreciable amount of progress has
*  happened in that regard.
*  But even beyond that often contentious question, it may be surprising to realize even the mental
*  functions that we take for granted maybe aren't on as sound a footing as we thought
*  or as I thought.
*  So if I want to study the neural basis of some mental function like working memory for
*  instance, do I even know what working memory is?
*  What other component functions it may involve or depend on or overlap with or relate to?
*  So a while ago I had David Popol and Yuri Buzhaki on to discuss whether neuroscience
*  or psychology provides a better path forward for understanding our mental lives.
*  Today Russ Poldrack joins me and we focus more on cognitive ontology, the parts that
*  make up our mental processes and the relations between those parts.
*  Russell's scientific research over the years has focused on the neural basis of things
*  like decision making, executive functioning, learning and memory.
*  But over his career he's turned a big chunk of his focus onto finding solutions to the
*  many meta-science problems that his own research field has faced.
*  So a few years ago he co-founded and runs the Stanford Center for Reproducible Neuroscience
*  where they focus on how to ensure that we're essentially doing reliable science that will
*  stand the test of time.
*  Things like establishing standards and making tools for sharing data, sharing analysis tools
*  and so on.
*  He also wrote the book The New Mindreaders, What Neuroimaging Can and Cannot Reveal About
*  Our Thoughts, which is a great overview about the history and the present and the future
*  of fMRI, which also touches on many of the meta-science problems and solutions.
*  So we also talk a little bit about those kinds of meta-science issues and the field broadly.
*  Show notes at brandinspired.co.
*  Alright, so we're going to start a little bit in left field here, Russ.
*  So I was thinking about cognitive ontologies and I happen to be in kind of a back and forth
*  conversation with my friends about musical genres.
*  And you're a punk fan, right?
*  Yes.
*  What's a punk band that you like from the early days?
*  When I was in high school in the early 80s, I was really into the Dead Kennedys, really
*  into all the Southern California, like SST bands, like Black Flag, Circle Jerks, that
*  kind of stuff.
*  Yes, I knew you were going to say Black Flag.
*  What musical genre, sub-genre is Black Flag?
*  That's a good question.
*  I would just call it hardcore punk.
*  Okay, so you're going to get in trouble with my friends because I wouldn't even go so
*  far as hardcore.
*  I would just probably call it, I might say early punk, but it probably has a technical
*  name.
*  Anyway, I was thinking about cognitive ontologies and thinking about these sub-genre musical
*  labels, pre-punk, post-punk, postmodernism, whatever punk, you know.
*  And I was thinking about how these genres are kind of imposed from the outside, from
*  the critics, while the artists themselves, probably many of them resist being labeled.
*  So I made this terrible analogy between a cognitive ontology, like mental functions
*  that are proposed by psychologists and from anyone who's just thinking about these things,
*  these folk psychological terms and concepts, versus the actual cognitive functions that
*  are resistant to, they don't want to be labeled.
*  Right.
*  But it's interesting, I assume that if you look at the fans of the different artists,
*  they're probably going to cluster around those labels, right?
*  In some ways, that's where the labels probably come from.
*  It's an interesting question, yeah, still like where the right place is to decide that
*  the ontology is useful or not and what data should go into it.
*  I agree that it is kind of funny that those are very top-down and very much like what
*  psychologists do.
*  Yeah.
*  I should say, I mean, this is audio only, but in the background Russ has his guitars,
*  at least three of them I see back there.
*  You have a little collection going.
*  Yeah, trying not to get any more.
*  Very good.
*  So maybe we can apply your cognitive ontology approach eventually to the musical genre spectrum
*  as well.
*  But Russ, welcome to the show.
*  Thank you for being on the podcast.
*  Yeah, thanks for having me.
*  So you've been a major influence in multiple meta-science issues that have become big over
*  the past, I don't know, decade or so, things like the reproducibility crisis, just how
*  to do better science in general.
*  You're an advocate for open science.
*  You introduced the problem of reverse inference, which you've talked about at length and will
*  likely come up while we're talking here.
*  I'm wondering though, how much of your thinking and your career is devoted now to these meta-science
*  kind of issues relative to earlier?
*  How much did you predict you'd be working on these sorts of things when you were earlier
*  in your career?
*  Yeah, no, I certainly did not predict that I was going to be spending this kind of time
*  on kind of meta-scientific issues.
*  I mean, I'd say at least half, if not two thirds of my effort these days goes to thinking
*  about, writing about, talking about these kind of meta-scientific issues.
*  Really in the last five years, it's kind of exploded.
*  So when I'm, I guess six years, I moved to Stanford six years ago and was lucky enough
*  to get funding from the Arnold Foundation to start a new center.
*  This was when Chris Gorgolewski was part of my group as well before he moved to Google.
*  We started a center together.
*  We called the Center for Reproducible Neuroscience.
*  In part, the decision to kind of buy into spending that much time on meta-scientific
*  issues really came from this kind of growing, gnawing feeling that I had that I just couldn't
*  believe a lot of the work that I was seeing published.
*  Because I, it's like I knew all the tricks they were playing.
*  I didn't want to be part of a field when I couldn't believe, or I couldn't know what
*  to believe.
*  I'm sure a lot of it is reproducible.
*  A good part of it isn't, but it's like I couldn't, when the base rates are as low
*  as I thought they were, it was hard to tell.
*  That's really what inspired me to move in that direction with this intuition that if
*  we can't believe the work that is being published, then I don't want to be a part of a field where
*  I can't believe the work that's being published.
*  It seems unethical to take a bunch of money from the public and use it to do science when
*  we know that the methods that we're using are broken.
*  The other issue is that science is a, well, ideally a super slowly, but slow correcting,
*  self-correcting system.
*  If these problems don't get fixed a century from now, our era is going to be a real laughing
*  stock.
*  I guess that's to be avoided.
*  That's exactly right.
*  I really want to be someone who's doing everything I can to try to figure out how to fix it.
*  It is the most important, well, I don't know how to rank importance, but it is a super
*  important problem.
*  Thank you for working on these things.
*  I'm curious, you run the Center for Reproducible Neuroscience.
*  You just said that you know all the tricks and how these things happen in papers and
*  whether you should believe it.
*  I'm wondering if earlier in your career, because you started at the center when you were an
*  experienced researcher and at the top of your career perhaps thus far, I'm wondering if
*  that makes a difference with respect to, okay, looking back now I can study these things
*  now that I've gotten to this level or if people should be focusing on that earlier in their
*  careers as well.
*  Yeah, that's a really good question.
*  Yeah, it almost certainly is the case that a junior person trying to get tenured in a
*  psychology or neuroscience department doing meta-science is going to be very challenging.
*  It was only because people knew me as a neuroscientist and a psychologist who has done
*  some things that I think are at least somewhat impactful in those worlds that I could make this
*  move.
*  And so I certainly counsel all of the trainees in my lab that you need to have a, fundamentally
*  you need to be asking scientific questions and doing interesting science.
*  And then you want to do it obviously in the best possible way.
*  And if doing some meta-science along the way is something you want to do, then you should do that.
*  But ultimately you're going to be judged for hiring a tenure promotion on the scientific
*  impact that you make.
*  Yeah, so I guess that's an evolving question on how to proceed at different stages of your
*  career. You've stated in the past that you think of the reproducibility crisis while solving it as
*  a design problem. First of all, are you familiar with the Designing Your Life book that was written
*  by the Stanford design team?
*  I'm familiar with it. I haven't read it.
*  Okay. It's one of the books that really is part of five or six of my go-tos back,
*  just as a life, the self-help genre that everyone's really interested in, and how to apply
*  principles from design into your life and career. But I'm wondering, so what do you mean when you
*  think of the reproducibility crisis solution as a design problem?
*  I think about it in terms of choice architecture, this idea from behavioral economics,
*  that whenever we go into a situation, there are features of the situation that were designed
*  either explicitly or implicitly to drive people towards particular choices.
*  The default settings in a software package are the most obvious ones. People are very likely
*  to use whatever default statistical threshold is built in if it's there.
*  And so using what we know from behavioral economics about how do you modify choice
*  architecture, Thaler and Sunstein talk about nudges, the idea that we can push people to
*  do the things that we think are the right things to do without limiting their freedom.
*  You can always choose another threshold, but to the degree that we know that there's something
*  that's a good thing to do, we should make sure that the situation drives people to do that thing.
*  Incentives.
*  Well, it's incentives plus affordances. It's not so much that you're incentivized
*  to use the default except for the fact that it's easy.
*  Gotcha. I want to ask you one more thing just based on larger, broader questions before we
*  get into more nittier, grittier stuff. I've heard you give the advice to learn as much technical
*  skills as possible as early on in your career as you can. When I went into graduate school,
*  all of us, and this relates to open science as well and collaborating, when I went into
*  graduate school, I had to learn MATLAB and so did my associates. And we were all learning MATLAB,
*  our own versions of MATLAB, making our own idiosyncratic mistakes and awful, awful code,
*  which as you know, every year you think now I'm a good coder. And then you look back the next day
*  and you think, oh, that's terrible. But now I'm good. Now I'm good. But everyone had their
*  own style and everything. And specifically just for coding, I'm not even sure if this has changed
*  toward this favor, but why is coding not a required class or skill in going into graduate
*  school, for instance, in a science like neuroscience? Yeah, I think it should be.
*  De facto, certainly for my lab it is. I have a blog post where I wrote about graduate study in
*  my lab, what I expect. And I used to accept graduate students into my lab who didn't know
*  how to code, the idea that they could learn how to code. And I've now realized that they basically
*  end up spending the first two years of their life just learning how to code. And so now I basically
*  say, if you're going to come into my lab, you need to know how to code. But I think that beyond that,
*  just quote unquote knowing how to code, doesn't mean that much in terms of these issues about
*  quality and rigor of the coding. In the last year, I've become really interested in
*  software engineering and its role in science and thinking about what we can bring to bear to try
*  to improve the quality of scientific software. We recently had an interesting thing that happened
*  in my lab where we had posted a preprint and with it posted all of the code. And it was for analyses
*  of this open data set, the ABCD data set. And the team that had developed that data set,
*  we were our preprint criticized some of the choices they had made in their design. They dug
*  into our code and found an error. And so what- They were probably looking pretty hard for that
*  error. Exactly. Yeah. Yeah. And it was basically because the person who wrote the code had written
*  it in a really obfuscated way with a bunch of nested Boolean operations. And so we sat down in
*  the lab and did- We wrote a blog post about this on our reproducibility blog. We basically tried
*  to dig in and say, why did this happen? What did we do wrong? Why did this happen? Patterning it
*  after- There's this thing that happens in the medical world at academic medical centers called
*  the Morbidity and Mortality Conference where it's basically like a blame-free zone for talking about
*  medical errors or possible problems. So we basically did that. We said, look, everybody makes mistakes.
*  Let's figure out why this happened so that it doesn't happen again. Yeah. I mean, even
*  after I learned to code, when I was a postdoc, every year we would have at the beginning of
*  the semester, we'd have a big lab meeting about how we needed to all be able to combine our code
*  and trade code and work seamlessly. And at the end of the lab meeting, we all felt like, all right.
*  And then we all went back to our offices and continued just as we were only to convene again
*  the next year or semester with the same issues. I mean, this is an ongoing problem as well because
*  there are so many meta skills to learn coding, how to do science, how to think about things.
*  It seems like there's hardly any time for science. Do you think that this is a big issue or is this
*  something that we just need to get better at building into the system?
*  No, I think it is a big issue, particularly for people in a field like cognitive neuroscience where
*  there's so much to have to know. You have to understand statistics. You have to understand
*  image processing. You have to understand how to code. You have to understand how an MRI scanner
*  works. You have to understand neuroscience. You have to understand psychology. There's just
*  supposed to understand all those things anyway.
*  Exactly. Right. Yeah. It's sort of an inhuman amount of stuff to expect anyone to know. So
*  the question is, how do you deal with that? I mean, one strategy that people have started proposing,
*  if it can be done, is great, is this idea of having research software engineers who are basically,
*  right now, most universities have statistical consultants who you can go to and for free,
*  they'll help you solve your stats problems. And those are often grad students in the statistics
*  department. The idea would be sort of similar to that, having software engineers who one can go to
*  and get help with software problems, to do a code review or to whatever the issue is that one has
*  with one's code. Obviously, that's something that's going to work well at a well-resourced
*  place like Stanford. A lot of places aren't going to have the resources to hire people like that.
*  So then the question becomes, how can one try to do a better job at software engineering?
*  So I've been reading a lot of software engineering books lately and reading a lot
*  of that literature. And it's really interesting. It's not just impacted the way I think about
*  coding. I think it has made me a much better coach in terms of helping people in the lab with code
*  review, but it's also given me some thoughts about meta-scientific issues as well. But we
*  in my lab, we now regularly, probably once every month or so, do a code review session in our lab
*  meeting where one of the trainees in the lab has a piece of code they want to go through. And we
*  just kind of walk through it and tear it apart and try to rebuild it. That's a great exercise
*  for everyone, I think. Yep. Okay. Well, all right. So these are ongoing issues and I'm glad that
*  people like you are working on them. I've been having some guest questions and we're just going
*  to start off with a guest question from Kendrick Kay. And I'm just going to play the question and
*  then you can have at it. My question to Russ, given that he has a nice broad view of many different
*  types of thinking out there, different fields from psychology to fMRI, of course, and computational
*  work. So the question is, I mean, we all have limited resources, so you have to dedicate your
*  resources somewhere. And of course, our decisions are reflected in our actions. But I guess from
*  your perspective, Russ, if you had limited time to spend on either, and these are loaded terms,
*  of course, theories, so better theory, better modeling, better analysis and software, or better
*  data, where would you put your resources? Okay. So the key here is you can't say all of them,
*  of course. I think that's a great question. And in part, I mean, so I can answer it the way,
*  in a personal way. I think that each individual is probably going to fall in a different place.
*  And in part, it depends on thinking about what your strengths are. I would love to think that
*  I'm a strong theorist or a modeler, but I'm not sure that that's where my strengths lie.
*  I think historically, my strengths have lied in finding interesting new problems and doing
*  a few experiments on them and then moving on to some other problem rather than building compelling
*  theories or models in those areas. So for me, I think it would be more about spending time on
*  analysis and on data. And that's cashed out in the way that I've been spending my life.
*  I don't actually think those are the most important things for the field. I think that
*  right now, especially in psychology, and well, in neuroscience as well, I think that
*  theory is really the thing that we need more of and that we need to focus more on.
*  Because I think that in the time of the brain initiative, there's been this idea that, well,
*  we just need to record more neurons faster and better, and then we'll just understand the brain.
*  That understanding will just emerge from the data. And it's become pretty clear that that's just
*  an incorrect way of thinking about how science progresses, that we really need
*  theories to help us understand the data. And so I think actually that theoretical
*  neuroscience is probably the most important area right now, and theoretical psychology as well,
*  even if that's not the area that I have the greatest strengths in. So that wouldn't be
*  the way I would focus. But if I was telling somebody else where to focus, and in part,
*  this is like, where do I think that there's the most fruit to be picked? That would be
*  theory. Gosh, but it's, well, two things. One, he guessed that you would say analysis and or
*  software for yourself as opposed to theory or modeling or data, although you did say data.
*  But then the question is, how do we change the field to, because we don't just need theory,
*  we need good theory. So how do we influence the scientific community to promote more of good
*  theory and less bad theory and less data for data sake sorts of approaches?
*  That's a really interesting question. I mean, I think in part, you have to hope that
*  if you have more theory, period, then ultimately, good theory will outweigh bad theory. That's
*  an article of faith rather than a data-driven belief. But-
*  You need a theory ontology.
*  Right, exactly. Yeah, so I think that just getting more people to do theory is the first step.
*  Okay, so before we get into cognitive ontology, I want just your broad assessment
*  where we are and where we're headed in neuroscience and in AI. I'm wondering if you think that we're
*  on the verge of a paradigm shift, a la Kuhn's paradigm shift, because as the voices like yours
*  rise about, hey, we may be doing it wrong, we need to reorient and rethink how we're going about even
*  doing it and the questions that we're asking and reformulate the questions and so on. So I'm just
*  wondering where you think we are in the current time and where we might be in the near future.
*  Obviously, it's a really exciting time to be doing neuroscience. A lot more exciting for people
*  working in animal models than in human models, though even in human models, the imaging techniques
*  have become pretty amazing. As I've already said, I think that we're in a relative glut of theory.
*  The big hole that I see is one that I think has been characterized well in a couple of recent
*  papers. One was by John Krakauer and his colleagues and then Yael Niv just had a pre-print recently
*  on the primacy of behavioral research for understanding the brain. Rolling my eyes, but okay.
*  Okay.
*  So I think that if you interact, if you're a psychologist or a cognitive neuroscientist
*  and you interact much with people who do cellular, molecular, or neuroscience,
*  they don't even hide rolling their eyes often when you talk about psychological theory or imaging
*  results. And there are certainly reasonable questions one can ask about psychological
*  theory, imaging results. But I think that there's an idea, there's this very deep-seated reduction
*  in a lot of cellular, molecular neuroscientists that, well, once we understand the circuits and the
*  ion channels and all these things at the cellular, molecular level, we don't need to care about all
*  that goofy psychology stuff. Here's an example of a place where I think this is a problem.
*  If you look at the pages of Cell, I think the journal with the highest impact factor,
*  you regularly see papers with titles like, depression involves a disruption in circuit X,
*  where that circuit is defined in these amazingly precise terms of specific sets of neurons in
*  particular regions with particular types of connections. But what they don't tell you is,
*  they say depression involves a disruption, but it's really a rodent model of depression that
*  has tenuous validity for the human depression phenotype. So we have these amazingly precise
*  biological models built around really imprecise and often invalid models of the psychological
*  phenomenon. What would be a better way to word that? Well, I think saying,
*  anedonia in a mouse model of depression involves a disruption in circuit X, but that doesn't sound
*  as fancy. Right. A little bit lower impact, I suppose.
*  John Krakauer rails against the exact thing that you just described. I don't know. It's so strange
*  to me. I just have a hard time believing that that's still the case, that maybe within the
*  cell and molecular neurobiology world, I just think of it all as being everybody's multi-level
*  in thinking about all these things and all the different levels are interacting. But am I just
*  naive in thinking that or just is it because I came from a monkey neurophysiology lab where we
*  attempted to tie spiking rates to higher cognitive functions and so on?
*  I think it is that you're naive and it is also because you came from a
*  systems neuroscience lab that I think takes cognition seriously. Certainly people in systems
*  neuroscience I think are much more, in general, much more open to taking seriously
*  the psychological side. But the papers in cell are not being done by them. They're being done by
*  circuit busters who really care about doing optogenetics on these very particular circuits.
*  There's a deeper problem, I think, that actually the issue that I have with the way that John and
*  Yael and others have framed this critique is I think it actually goes deeper than this idea
*  that behavior is the ballad. So they frame it in terms of we have to understand behavior.
*  In part, this speaks to where I came from. When I was starting graduate school in cognitive psychology,
*  the memory of the cognitive revolution was still fresh in the faculty's minds.
*  And so my training instilled in me this deep sentiment that you can't understand behavior
*  without understanding the mental representations and the processes that underlie it.
*  Obviously, understanding behavior is really important and characterizing behavior well.
*  There's a lot of cool work that's being done and building, especially in rodent models,
*  building models of the behavioral repertoire of animals. But I think that's not going to get us
*  to where we want to be. Unfortunately, Yael points out some examples of this in her paper.
*  Work focused at that cognitive level is increasingly shunned by the funding agencies.
*  It's as if NOAA was focused on understanding weather, but they were to say one of our missions
*  is to understand coastal flooding. But since water is made of quarks, we're only going to
*  fund research that uses high energy physics techniques. I think there's this
*  naive and implicit, kind of eliminated reductionism amongst a lot of neuroscientists,
*  who really think that once we understand the neurons, then everything else is just going to
*  fall into place. And not recognizing as legitimate these higher levels of emerging organization like
*  the cognitive level. Highlight of the podcast thus far,
*  Russell Poldrack called me naive. I must be naive because, yeah, maybe I'm just looking at all through
*  rose-colored glasses. It's just hard for me to believe that people do have that notion that it
*  will all just work out if we figure out the structure, what's connected to what, and the
*  implementation level stuff. Yeah. The C. elegans example shows that that strategy is not going to
*  get you to where you want to be even in terms of understanding behavior.
*  There's certainly good evidence that it doesn't work.
*  Yeah. Well, we could spend all day talking about just this, but let's move on and get closer to
*  cognitive ontology. You've been thinking about this kind of stuff for a long time.
*  There's this old phrenology approach that you've highlighted in blog posts and such,
*  that areas of the brain do mental things. You can map on mental functions to areas of the brain.
*  And you talk about that in your book, The New Mind Readers. You talk about what we have known,
*  the history of fMRI, what we can know and what we can't know based on fMRI. And you detail the
*  reverse inference problem in that book, which I really recommend. It's a great overview of fMRI,
*  but it also starts to touch on some of these cognitive ontology issues. I'm wondering how
*  your thoughts about fMRI in general as a tool for understanding minds has changed over time.
*  I know that you didn't initially think you were going to be
*  doing fMRI work when you started your career, but you were sucked into it.
*  That's right. Yeah. In fact, it's funny in graduate school,
*  so I got my PhD in 1995. fMRI was invented in 1992. So in the early 90s, a lot of people were
*  still doing pet research. There was some new fMRI work coming out. It was all pretty low hanging
*  fruit kind of work like, hey, we show people words and this part of the brain lights up.
*  And if you show them scrambled words, it doesn't. So it was easy to ridicule. And so when I went to
*  do my postdoc, I wasn't really interested in doing imaging. I wanted to do patient work
*  looking at basal ganglia and skill learning. And for various reasons, I ended up getting
*  sucked into doing imaging in part because I'm a geek and I like messing around with computers and
*  data. And that's something you do a lot of in fMRI. So am I more or less enthusiastic about
*  the ability of fMRI to inform our understanding of the mind? I think that I'm fairly optimistic
*  in, at least in one particular way. I think that there's ways that people have started to use
*  imaging fMRI in the last decade that I think do have a much better ability to actually tell
*  us something interesting theoretically. So in the early days, you would do some subtraction.
*  Let's say I show people high frequency words and low frequency words and look at the difference
*  in brain activity between those and then try to find the regions that are differentially active
*  and say something about their function. That's not that useful, I think, for psychological theory,
*  because if I have a theory about word frequency, it's a psychological theory that probably doesn't
*  say much about where in the brain that lives. Now, you can imagine if we know the computations
*  that different brain areas are doing, we could use that to help understand what that activation
*  might tell us. I think that's a strategy that has been at least a little bit successful.
*  But I think that the more useful strategy for telling us about cognitive theory is, even though
*  it's not clear to me that it's really been cashed out fully yet, is this pattern similarity idea.
*  The idea being that when we do pattern similarity analysis in fMRI, what we're doing is basically
*  instead of saying what regions are more active than others, what we do is we say across a bunch
*  of stimuli or task conditions or whatever it might be, what's the similarity structure of
*  patterns of activity across the whole brain or in particular regions? Then we can use that.
*  So for example, most psychological theories, even if they don't say anything about
*  kind of where in the brain things live, they almost certainly say something about the degree
*  to which different stimuli should be processed in a more similar or different way. So now using
*  pattern similarity analysis, you have a way to start actually testing predictions about theories
*  or either theories as a whole or the other thing you can start doing is saying, well, I think often
*  in the history of psychology, we've had this kind of pathological binarization of hypotheses.
*  We've had all these debates, is it serial or parallel processing? Is it analog or propositional
*  information? Almost every time when we have those debates, people end up realizing that the debate
*  was pretty much kind of off base and kind of a little bit of both of them are right.
*  The one thing you can imagine is that we can now start saying, well, it may well... So let's take,
*  for example, in categorization, some people think that categorization relies on memory
*  for exemplars. Other people think categorization relies on some kind of prototype. It may well be
*  that only one of those theories is right, but it may also be that different brain systems implement
*  different of those processes. So now you can use pattern similarity to say, well, this one system
*  looks more like an exemplar system. This other system looks more like a prototype system.
*  And I think that starts to let you much more closely tie psychological theory to brain function.
*  Oh, it's never simpler than you conceive of it. It's always more complicated than...
*  Exactly.
*  It's never an either or. Yeah. I mean, has that sort of the development in fMRI and the way that
*  you've thought about that, has that also altered over time your conception of our minds?
*  It's an interesting question. I mean...
*  It's impossible to isolate that specific. How has the fMRI specifically changed? But maybe even
*  more broadly, has your conception of mind changed over time? And if so, can you articulate how?
*  I think the main way that it's changed has become more computational. I started out
*  from a tradition... I did my PhD working in a lab that focused on memory and memory disorders. And
*  that's a very kind of box and arrow model type of field, at least it was back in the 1990s.
*  And obviously people have been doing computational modeling of various sorts across psychology
*  for a long time. So in some ways, I'm just kind of catching up with where the field has been going.
*  But one of the things I've been really struggling with lately is how to think about...
*  What does a cognitive ontology look like when it's framed in terms of computation rather than in
*  terms of what you might call folk psychological concepts. So I did an analysis, I wrote a blog
*  about it a few years ago, where I took all the terms from the cognitive atlas, which basically
*  just tries to describe all the different parts of the mind that we think we know about as psychologists.
*  I took all those terms and used the Google Books database to ask,
*  what proportion of these terms were in the literature, in the English literature, starting
*  back, going all the way back to 1800. And basically what I found was the cognitive atlas terms, I think
*  for the single words that are in the cognitive atlas, 80% of them were in the English language as of
*  1800. And for the phrases, the majority of them were in the English language, certainly by
*  the early 1900s. Whereas if you take the gene ontology, which is probably the best known
*  biomedical ontology that describes the parts of cells and molecular functions and biological
*  processes, very little of those terms were in the literature until well after 1900. So it says that
*  we're using this set of terms. Also, if you look at William James's 1890
*  principles of psychology, the chapter headings there are, other than the way they're worded,
*  are things that people are studying today. And so the way that we chop up the mind certainly has not
*  changed in more than a hundred years. I think that the computational turn is a really big
*  change in the way that we think about this. So one of the things that I've been trying to think
*  about is how do we rethink describing the organization as a whole, and how do we
*  rethink describing the organization of the brain in computational terms?
*  And an intuition pump for this has really been the work over the last few years that's been using
*  deep neural networks to try to understand the visual system. So the work that I know best is
*  the work from Dan Yeamans and Jim DiCarlo, where they basically take a deep neural network
*  or really take a class of hierarchical convolutional neural networks and train them
*  to recognize objects without telling them anything about the brain. And then also,
*  simultaneously, or in parallel, record from non-human primates in the visual system,
*  basically recognizing those same objects across the ventral visual stream.
*  And then what they see is that you can well predict the activity of neurons from the activity
*  in different layers of that hierarchical neural network. And so the question is,
*  what have we learned when we do that? So let's say that area V4 is best predicted,
*  its activity is best predicted by convolutional layer five in this particular deep neural network.
*  What have I learned about what V4 does by knowing that? And one answer might be, well,
*  it does the thing that convolutional layer five does, and that you can't really say anything
*  more than that. And I think that's the way that my colleague Dan Yeamans kind of views it, is that
*  trying to put verbal labels, functional verbal labels on these things, it doesn't really make
*  sense. Because ultimately, it's described in terms of the computations, the particular
*  transformations of information that are being performed by those layers in the network. But I,
*  as a psychologist, I have this, I think, deep-seated need to give a kind of a low-dimensional verbal
*  description to what that particular circuit or system or region or network is doing.
*  **Matt Stauffer** So do you think that then in that case, and we may come back to this,
*  we'll back up in just a second. But in that case, right, so we have this intuition that a given
*  area of the brain needs to do something, right, and needs to have a function. And in this particular
*  case, let's say V4, we need to be able to look at what it's doing and give a name to it. But the
*  low-dimensional description that we give to that kind of processing is that it is a fairly higher
*  step in the ventral visual stream on the way to object categorization or object identification.
*  And is that where it ends? Is that how we describe? Is that where our ability to put words
*  and phrases to this in a low-dimensional space ends? Then we describe the actual trajectory of
*  the layers versus what each layer is doing at each given step. Or because in V1, it might be a little
*  bit easier, right? Contrast enhancement, line detection, things like that. And it may just get
*  more and more abstract. Or maybe we need to invent new terms. Or maybe we need to use equations,
*  computational equations. Is that what you're getting at?
*  **Matt Stauffer** Yeah. Yeah. I mean, obviously there's lots of strategies that people have used.
*  So for example, you can try to ask, you can take the neural network and kind of do in silico
*  electrophysiology and ask, what are the stimuli that best activate these particular units in the
*  network? And then kind of look at those and say, ah, that kind of looks like a high level feature
*  that's like an object, or it looks like a lower level feature and has a smaller receptive field
*  or a bigger receptive field. There's various tricks you can play, but ultimately it's not clear what
*  those buy you. What kind of predictions you can make or what kind of understanding you get about
*  the system that's sort of useful beyond kind of what the network-
*  **Matt Stauffer** Being a step in a process or something.
*  **Matt Stauffer** Right. Right.
*  **Matt Stauffer** Yeah. All right. Maybe we'll revisit this,
*  but all right, let's talk ontology and cognitive ontology. So the word ontology in philosophy,
*  as you have pointed out in your papers, has to do with what's real, what things exist in the universe
*  that really exist, no matter what we call them, what are the real things that exist.
*  But a cognitive ontology is slightly different than that. So what is a cognitive ontology?
*  And then why do we need one? **Matt Stauffer**
*  Yeah. So a cognitive ontology or what is called often a biomedical ontology or a formal ontology
*  rather than being a description of what really exists in a kind of a metaphysical way,
*  it's really a description of what we think exists. It's basically a formalization of our
*  conceptualization of the world. So the gene ontology says, what are all the parts of a cell?
*  What are all the processes that a biological system does? So a cognitive ontology basically says,
*  what are all the parts of the mind? What are all the things that we think minds do?
*  And so those could be things like memory, those could be things like task set shifting,
*  they could be high level, they could be low level. And then in a biomedical ontology,
*  they're generally described in terms of a specific set of formal relationships, things like X is a
*  kind of Y or A is a part of B. And so that's the way that we think about a cognitive ontology.
*  Now, why do you need it? Well, let's ask a question a different way. Why did I start
*  spending time working on this? And I started thinking about this more than 10 years ago,
*  back when I was at UCLA, sort of inspired by my colleague, Bob Bilder, who was thinking a lot
*  about gene ontologies and how we might bring to bear those sort of ideas on psychology.
*  I was inspired to think about what are the things that we're mapping onto the brain?
*  So one of the terms that's sometimes used to describe the enterprise of cognitive neuroscience
*  is, quote unquote, brain mapping. So the question is, if you're going to map things, you need to
*  know what the things are that you're mapping onto the places. And so the question is, what are the
*  things? And in part, I sometimes like to say that there was sort of a subversive agenda around the
*  cognitive atlas, which is, I went into this being pretty sure that a lot of the ways that we kind
*  of chop the mind up, these ways that we inherited from William James et al., are almost certainly
*  wrong, where by wrong, I mean they don't reflect the computational organization of the brain.
*  But if we want to figure out how we're wrong, we need to kind of figure out exactly what it is
*  that we believe to start with. So in some ways, it was like, let's write everything down as precisely
*  as we can so we can figure out how to break it. Can you just describe what the cognitive atlas is?
*  This is kind of where you store the cognitive ontology, I suppose, is one way to say it.
*  Yeah. So the cognitive atlas is a website that was sort of inspired by Wikipedia. It's meant to be
*  kind of a community project, so anybody can come on and sort of contribute knowledge. And basically,
*  it describes two separate, at least two separate sets of things. The main two sets of things are
*  what we call cognitive concepts or mental concepts. These are the latent things that we can't see,
*  but that we think exist in the head, things like-
*  Working memory.
*  Working memory, exactly.
*  Yeah, okay.
*  And then we have a separate kind of description of what we call mental tasks. These are the things
*  that we measure the mind with. And one of the really problematic moves that people in psychology
*  and neuroscience often make is basically equating tasks with functions. They'll call something a
*  working memory task. That's a theory of what is involved in performing that task. And the task
*  almost certainly involves lots of other things. Coming from the memory world, we always had this
*  saying that no task is what we call process pure. And this is basically just trying to highlight
*  that fact that tasks and processes are not isomorphic. And so we try to describe the
*  relationships. What are all the parts of the mind? What are all the relationships between them?
*  So is working memory a kind of memory? Is visual selective attention a kind of visual attention,
*  and so on? And then we try to describe how those things are measured by particular
*  contrasts or comparisons on particular tasks.
*  Then the goal is to define formal relationships between the tasks and the concepts and the
*  activations in the brain related to those tasks and concepts, correct?
*  That's right. Yeah. The neuroscience part is the next step. The idea is that we start with these
*  formal relationships between particular tasks and particular measures on task and particular
*  cognitive functions. And then the idea is like, well, now what we can do is get data on those
*  tasks and ask various questions. So for example, my student, John Walters right now is doing a
*  project where he basically takes people doing... There's a data set that Jern Diedricksen,
*  Rich Ivory, Maeve King collected that I was involved in helping them analyze. We published
*  in Nature Neuroscience last year. It's this multitask data set where people do
*  40 something different task conditions. And so what John has been doing is basically
*  taking all those tasks and a group of us sat down and basically annotated each of the tasks to say,
*  for each particular comparison of task conditions, what psychological functions do we think are tapped
*  by or required to perform this task? And that's not always clear. And sometimes we can spend an
*  hour or two talking about one task, but we've done that for that set of tasks. And now he's building
*  models to basically say, okay, so can we train... So actually models that are inspired by work that
*  people have been doing in the visual neuroscience literature for a while, most prominently the work
*  of Jack Allen and colleagues using encoding models, the idea being like, you build a model that
*  relates cognitive functions to brain activity. And then you test the model by predicting patterns
*  of brain activity for tasks that the model, specific combinations of cognitive processes
*  that the model has never seen. And we're actually finding we can, surprisingly to me,
*  given that I thought our cognitive ontology was pretty bad, we can actually do pretty well at
*  predicting brain activity patterns on tasks that we've never seen before based on an annotation of
*  what cognitive functions we think are involved in those tasks.
*  I mean, this is a set of... Well, we were going to get into this later, but anyway, this is a set of
*  multiple tasks and multiple... I mean, the whole idea is to do this in mass. And then you can really
*  figure out where the lines are and the joints are. And that's how the modeling works so well,
*  I suppose. That's right. Yeah. And even 40 something task is spanning a very small part of the
*  psychological space. And then this in part was my motivation for about a decade ago, getting into
*  the data sharing business. Obviously, there's a reproducibility angle for the data sharing
*  idea, but there's also the idea that my lab is never going to be able to collect data on all the
*  tasks that we would like to collect data on in order to do this kind of mapping. And so if I can
*  get a lot of other people to share their data, then that allows us to be able to expand the set
*  of things that we can try to model. Now, the problem there has turned out to be this annotation
*  issue, right? That to do this right, each of the task comparisons needs to be annotated using
*  something like a cognitive atlas to say, what functions do we think are engaged in this particular
*  comparison? And that's just a time consuming enterprise. And so doing that on hundreds of
*  thousands of tasks is just really challenging. People don't do this in their papers in general.
*  It's interesting, back in the 90s, you would regularly see papers that would have a little
*  chart showing, what do I think all the subtractions in my analysis, what psychological
*  functions are they tapping into? And this was particularly common back when people were doing
*  PET imaging. And you just don't see that anymore. I think people don't think as deeply about
*  the implications of subtraction as isolating particular cognitive functions.
*  This is, I think, a good point to play the second question here that I have from you.
*  And then I want to go back and talk about what you've been describing so far as kind of a top
*  down approach. And you also do a bottom up approach to developing a cognitive ontology.
*  But before we get too deep into it, so I had David Popol and Yuri Buzaki on the show talking
*  about whether we should go from top down, which should have epistemological primacy, psychology,
*  and naming these mental functions. And then we confirm it with neural data. Or Yuri, his
*  preferred approach, which I'll ask you about in a little bit, is to look at neural data and try to
*  infer maybe not mental functions, but at least properties of the neural data that will help us
*  better maybe build a cognitive ontology, for instance, of mental functions. But all right,
*  so here's David's question. Hi Russ, it's David. I hope all is well and good,
*  and that you're having fun talking to Paul. So I'm very sympathetic to the problem you're
*  grappling with here. And I like the framing of defining ontologies. I wonder how you
*  handle the tension between ontologies that come from different ways of approaching the problem.
*  Let's just say the ontologies we derive from psychological investigation or text mining,
*  or the cognitive sciences, are of one form. And the ontologies we might derive from biology
*  straight up are quite different. And so we end up with ontologies that are not necessarily well
*  aligned or even linkable. And I wonder if you think you have an approach to deal with this problem,
*  or if you think one or the other ontological type actually has, let's say, a kind of epistemic
*  priority. In any case, I think it's a really important problem, and I'm excited about pursuing
*  it further, and I'm glad you're working on it. Okay, thank you, David. Great question. Yeah. So
*  I do not believe that any of these individual levels has an epistemic priority, and I'll look
*  forward to discussing that in a bit more when we talk about Yuri's ideas. I guess I take some
*  degree of inspiration from the gene ontology, which talks about things that are in principle
*  very different. It talks about parts of cells, endoplasmic reticula and lysosomes and all those
*  sorts of things, which are very different from molecular functions, phosphorylation,
*  or biological processes like citric acid cycles. You might think that those are very different
*  things, but they're obviously related in the sense that particular molecular functions are
*  required in order to achieve particular biological processes and particular parts of cells
*  implement particular biological processes or molecular functions.
*  Even though they're different, they're ontologically very different types of things.
*  The parallel with minds is really interesting, because some of them, obviously parts of brains
*  are observable things. We can see neurons in CA1. We know that they're physically present things.
*  We can't see memories. We might be able to see the traces that memories are associated
*  with in physical brains, but we can't see a memory because a memory is an abstract latent thing.
*  Similarly, we can't see the TCA cycle. We can see the evidence of particular molecular functions in
*  particular parts of cells, but the TCA cycle is also an abstract thing. I think that we can
*  actually hope to relate these things if we, going back to the comments earlier about this
*  limited reductionism, if we buy the idea that there really are a set of hierarchically organized
*  levels of organization, none of which is primal in a sense. Obviously, the higher level ones depend
*  on the lower level ones, but it's not as if they can be reduced to the lower level ones. There's a
*  level of organization that emerges that can't simply be described in terms of the lower level.
*  He had a follow-up related, wondering whether what you're after are these irreducible
*  primitives or rather if they're parameters, he says, with respect to a theoretical level of
*  abstraction. This almost gets back to the metaphysics of it. Are they irreducible
*  primitives like particle physics or whatever the basis is of all matter or something?
*  I like the idea that there are parameters in a theoretical framework in part because
*  I don't think we can ever get out from behind our theories, be they implicit or explicit.
*  This relates to this idea of learning everything from the bottom up.
*  I agree that a good way to think about this is we have some basic assumptions about how minds
*  should be chopped up. Then what we're doing here is basically saying, now let's go in and
*  given that strategy for chopping things up, let's name the parts that we have chopped up.
*  Okay. Before we move on and describe a little bit more the actual approaches that you've taken to
*  this, just broadly, I'm wondering how much progress actually depends on getting the ontology
*  right? Of course, embedded in that is like, how do we know how right it is, for instance?
*  It's an interesting question. I think it does simply because in other sciences, we think that
*  moving towards a more accurate ontology has been associated with more effective outcomes in those
*  sciences. In this case, if our goal is to come up with mechanistic models of how brains give rise
*  to mental life and to action, it seems that if we're not chopping up mental life or behavior
*  in a way that is truly reflective of the mechanisms that generate it, then we're going to be
*  fundamentally limited in how well we can do. I use this thought experiment sometimes,
*  what would have happened if the phrenologists had gotten their hands on fMRI?
*  They did.
*  The answer is the faculty psychology phrenologist, GALL. If they had asked, can we now use fMRI to
*  map our quote unquote mental organs like phylo progenitiveness and suavity onto the brain?
*  You have to know that it's not like they would have found nothing. They would have found something.
*  That doesn't mean that their way of chopping up the brain is correct. In fact, they probably
*  would have found something similar to what we find, which is that there's a ton of different
*  supposedly distinct psychological functions that all give rise to very similar patterns of activity
*  in the brain. The anterior cingulate is activated in something like a quarter of all psychological,
*  a quarter of all neuroimaging studies. Clearly, we have not learned much, I think, about what
*  that area does in terms of its ultimate function, at least from the larger body of that work.
*  There's a trap question. I just want to make sure that there was a good reason for us to
*  go ahead with a cognitive ontology. Like I was mentioning before, you've taken multiple approaches
*  to this. Broadly, you've taken a top-down approach and a bottom-up approach, but even within the
*  top-down approach, by top-down, I mean you've started with our theories of mental functions
*  and our names of those mental functions, started with psychology, I suppose you could say,
*  and used that method to break down the ontology. In parallel, maybe you can discuss whether it's
*  in parallel or more recent, but there's this bottom-up approach where you start with observations
*  and you correlate observations in tasks and in surveys. You correlate your way to developing a
*  new, to generating an ontology. I'm just going to ask you to take us, because you already talked a
*  little bit about the top-down approach, but I'm just going to ask you to maybe describe a little
*  bit more both of those approaches and what you've found regarding our current ontology,
*  which you've already said surprised you. Yeah. As I mentioned, the work that we've been doing,
*  based on the top-down ontology models to look at how well can we predict brain activity based on
*  those models, we're far away from being able to predict all the brain activity, but we certainly
*  do much better than I would have expected, suggesting to me that at least in part,
*  there's something right about those models. Then now the question is going to be, where does it
*  break down? Yeah, the work on data-driven ontologies is really more recent. It started with
*  a student in my lab several years ago, Ian Eisenberg. I had been walking around with ideas
*  about trying to do data-driven ontology development for a while, but none of my students would ever
*  get very interested in it. In part, I thought it was too dangerous of a project to give to
*  a grad student, but Ian jumped on it and really wanted to do this project. It was in concert with
*  a set of ideas that we were just developing with some collaborators around and driven by
*  interest from NIH in developing an ontology of self-regulation. Self-regulation is a term that's
*  used in many different ways in many parts of psychology. People in my part of psychology
*  might talk about response inhibition or delay discounting being an aspect of self-regulation.
*  People in social psychology might think about self-control or people in health psychology might
*  think about impulsivity. There's lots of different ways that this gets cashed out. Sometimes in
*  cognitive tasks that measure reaction time and accuracy, sometimes in self-report where I answer
*  questions like, do I make impulse buys at the grocery store? We obtained some funding from NIH
*  to go after this question specifically in the context of self-regulation. What we did was
*  generated a battery. We looked across psychology and said, as broadly as we can, can we pick a
*  bunch of different measures that are all thought to index different aspects of self-regulation from
*  different standpoints? Basically, it was like a 10-hour battery. We got a little over 500 people
*  to complete this 10-hour battery all online. We had data from them doing lots of different tasks.
*  Then we basically just took this very standard approach from psychology for a long time of using
*  multivariate analysis like factor analysis to look at the structure in the data. It was like an
*  unsupervised approach to looking at the structure of the data. There's a lot of structure in the
*  data. For example, we had several different measures of how much a person discounts future
*  rewards. Those are all highly correlated with one another. We also had several measures of how well
*  you can inhibit a motor response, which are also correlated with one another and not really
*  correlated at all with the measures of delayed discounting. In that analysis, don't you have to
*  tell the algorithm how many clusters to create? Yes. This turns out to be the trickiest part of
*  this. Well, because then you're defining how many mental categories there are, right?
*  Yes. In part, this is why I think I've become a lot less enthusiastic about
*  the idea that we can just use data to infer the joints in the system.
*  In some ways, this is very similar to the clustering problem in machine learning. There's a paper
*  by Ulrika of Unlooks where we're colleagues from a few years ago called Clustering Science or Art.
*  They basically outline this idea that there's no way of defining a quote-unquote correct clustering
*  solution for any data set. The decision about which clustering solution is best has to depend
*  on the end goals of the researcher. For example, in our work, we use Bayesian information criteria,
*  NBIC, to determine the quote-unquote optimal number of factors in our factor analysis.
*  Using that particular criterion makes particular assumptions about how much we want to penalize
*  parameters versus sample size. We could have used AIC, we could have used cross-validation,
*  and those all give us different answers about the optimal number. Now, fortunately,
*  the story that one might tell is not that different. If I get a cluster solution with, say,
*  or a factor analysis where I say there's 20 factors as opposed to five, if you look at the 20,
*  you can usually see that, well, they all emerge from the five. It's not like they're telling you
*  something completely different. They're giving you a more detailed view of what you would have
*  kind of the lower dimensional view you would have gotten with fewer.
*  Nonetheless, it tells me that this idea that you can just kind of look at the data and have
*  the structure emerge without any sort of pre-existing theoretical framework is just
*  an untenable idea. Well, it also makes one hesitate to, speaking of ontology, and I know
*  this isn't about the metaphysically real things in the universe, but then if you can tell the same
*  story with a cluster of five versus a cluster of seven, what you want to be able to say,
*  and even moving forward, relating brain to mind, let's say, they do equally well, the five cluster
*  model versus the seven cluster model, you'd still feel kind of hesitant to believe in the mental
*  function that you're purporting in those clusters, right? I don't know. I mean, I think clearly
*  there's an argument that the data, the structure in the data to some degree has to come from the
*  mechanisms that are generating the behavior, right? The question is to what degree do you attribute
*  the structure in the data to the kind of fundamental joints versus, for example,
*  the particular choices of tasks. For example, one of the big distinctions that we see in our data is
*  that behavior on self-report questionnaires is pretty much uncorrelated with behavior on cognitive
*  tasks measuring reaction time and accuracy. That might be that they're reflecting fundamentally
*  different types of psychological functions. It might also be what people in psychometrics call
*  methods variance, right? That it's really something about the way that you're measuring the things
*  that's causing those correlations. For example, people differ in the degree to which they want to
*  present a positive view of themselves or not, right? That's going to cause all the self-report
*  things to covariate with one another, right? And not with the reaction time tasks. There's
*  lots of stories like that one could come up with. Yeah. I interrupted you, I think, talking about
*  what you actually found with this bottom-up approach.
*  Right. What we found was that we certainly see that there's interesting structure in the
*  cognitive tasks and in the self-report. Then we wanted to ask basically how well do those relate
*  to the things out in the world that we think are associated with self-control, things like
*  smoking or overeating or success in life in some sense, like household income and education level
*  and things like that. Basically, what we saw was that we could, using a cross validated out of
*  sample predictive model, we could predict pretty well those various measures of real world outcomes
*  using the self-report measures. We could hardly predict anything using the cognitive task measures.
*  That's crazy.
*  That's probably the most important finding, I think, from that work, which throws a bit of water on
*  when I and many of my colleagues in cognitive neuroscience write grants, we say, hey, we're
*  going to study response inhibition because it's so important for addiction, right? These data
*  suggest that if it is, it's really weakly important. It's actually more important to
*  listen what a person believes about themselves. Where does this leave us? What's the current state
*  in your current thinking about the cognitive ontology?
*  I think that regardless of the bottom up stuff, I think that there's still insights to be gotten
*  from the top down analysis. I think in part, it points to our need to be much more precise in
*  defining exactly what it is that our cognitive tasks are measuring. On the one hand, I'm
*  optimistic that we can still make progress there. On the other hand, I think that I've become
*  convinced that ultimately, an ontology that's written down in words is probably never going
*  to be a particularly powerful ontology compared to one that's written down in some kind of
*  computational language. Then the question becomes, what does that computational language even look
*  like? Well, that's a good question. I just immediately, a graph network, of course, popped
*  into my head. Do you have an idea? I can't say that. It's a problem I've been struggling with
*  a lot in the last year. I gave a talk, I guess, a couple of years ago now at this ontology conference,
*  this philosophy conference, where I first started thinking about this particular issue. I can't say
*  I've made great progress. Clearly, the insights that we're getting from artificial neural networks
*  has provided at least food for thought, if not a fundamental language. I still feel like there
*  has to be some kind of way to talk about this that accurately describes in a low-dimensional way
*  what's, going back to that earlier discussion, what is it that this particular,
*  what is it that the computation is that's being done by a particular circuit or area or network?
*  I just haven't been able to pin down exactly what that is yet.
*  You have a vision then of having a, I'm going to say computational language, even though it's not
*  language, but a computational ontology, let's say, a formal computational ontology that,
*  when it's used, will eventually be able to apply, whether it's new terms or existing terms used
*  in reference to the particular ontology, that low-dimensional description we will have,
*  even though the actual ontology will be beyond our description.
*  Yeah, I think that's right. Well, I guess, I don't know if beyond our description is the
*  right way to put it. I think that it'll be at a level that's necessarily imprecise
*  because it's a generalization. It's a low-dimensional approximation of the
*  higher-dimensional model, which is a low-dimensional approximation of the actual
*  thing. There's all these, there's just layer cake of approximations. But the question is,
*  is there utility in having this very high-level approximation? Maybe there is, maybe there isn't.
*  Sort of like statistical mechanics. It's a low-dimensional description of all kinds of
*  crazy stuff going on, but it's still useful for answering some kinds of questions.
*  Yeah, I've started thinking more and more about these types of things as
*  attractor states in dynamical systems theory and even concepts, mental functions.
*  Let's say a mental experience like pain, for instance. When you ask Jim what his pain is,
*  and you ask Sally what her pain is, it's not like they have the same thing, the same actual thing
*  going on. But we use the term pain, but it's almost like you could, pain is like this attractor
*  state that can vary in its actual location, but within a realm. And I wonder, going back to the
*  mental functions and the clustering aspect of it, is if it's good enough to just have an attractor
*  surface, right? That all these, whether you divide it into 12 mental functions or three,
*  whether it's sufficient to say that it's within this attractor state, is that way off base?
*  No, I think that the whole question of how we bring ideas from dynamical systems
*  into our understanding of cognition is really important. Historically, there's been this,
*  again, I think problematic dichotomy between the people who do dynamical systems modeling
*  and cognition in psychology, who've basically tried to say, oh, there's no representations
*  in the brain, right? That we just need to do this dynamical system description. And then the people
*  who want to build mechanistic models who say, oh, the dynamical systems theory doesn't tell
*  us anything about mechanism. So actually, there's a grad student in my lab right now, Grace Huckins,
*  who's working between myself and a couple of philosophers, who's become really interested
*  in this question of how do we, can we talk about the idea of dynamics as being explanatory, right?
*  Can we learn anything about a system from these kind of dynamical systems analyses beyond
*  just something that's a description? So I think that there's a lot of, she doesn't have any
*  results to show for that yet, but she's working on it. Yeah. So over the next few years, I think
*  we'll see something emerge from that. Until a few years ago, I never really thought about
*  dynamical system stuff. And then had a postdoc in the lab, Max Shine, who's now faculty in Australia,
*  who started reading and thinking a lot about this sort of stuff,
*  and kind of dragged me kicking and screaming into it. And I think that there really is something
*  there. I think that one of the real challenges is trying to figure out how do we bring together
*  these ideas from dynamical systems and from network neuroscience more broadly,
*  and ideas from computational neuroscience that in order to come up with a unified framework for
*  thinking about how we describe the function of brains.
*  Maybe I'll have Mac on because at some point, because I wanted to, there's too much to talk
*  about. So there's this paper from last year in Nature Neuroscience, human cognition involved
*  the dynamic integration of neural activity and neuromodulatory systems, which looks like great
*  work, which you're the last author on. But maybe I'll have him on soon to talk about that stuff.
*  Okay. So obligatory question here. We think about mental functions and dividing them up.
*  I got into neuroscience in graduate school with the high aspirations of understanding
*  consciousness. And now I roll my eyes when I say it. Are we anywhere near, given the background
*  of your work on cognitive ontology, do you see any promise getting closer to approaching what
*  consciousness is and how it would even fit into a cognitive ontology?
*  I'm sorry. I'm still rolling my eyes. Let me stop that. I think if somebody could come into the
*  cognitive ontology and write down what the hell consciousness means, then that would be a great
*  first start. How many clusters is consciousness? That's a good question. Right. Okay. Well,
*  so what is your take? So I mentioned Buzaki's, what he calls his inside out approach. And this
*  is taking not without, it's not strictly bottom up or data driven. I mean, because as he admits,
*  you always are working under a theory. So there's always that sort of top down influence. But,
*  his idea is that neuroscience, unlike many other fields, has not developed its own vocabulary, its
*  own, not even necessarily new words, but its own conceptual framework, like other mature sciences
*  have. And his idea is to take what we have found at, let's say the implementation level, like
*  oscillations and different patterns of oscillations and on and on, and use this inside out approach
*  to develop concepts to maybe influence and change some psychological concepts, to change the ontology
*  almost. So I'm wondering about your thoughts on that. And I'm not sure I described it well enough
*  for you to even comment on it. Yeah. No, I read parts of his book and there's a lot to like about
*  the book, I think. Obviously, he's done amazing work on understanding dynamics of neural systems
*  and their role in behavior. And I really like the focus of the book on action, on situating. I think
*  many of us still have this kind of idea that kind of stuff comes into the eyes and then goes forward
*  and action is like the thing in the end and really framing us as being embedded in these
*  action perception cycles. And there's arguments in the book about the primacy of action. I'm not sure
*  I buy, but certainly the importance of action and of our embeddedness in the world, I think,
*  is a really important one. You see the brain as an information processor, not as a behavior producer,
*  primarily. I see it as both of those things, I guess. I think there are different views on
*  the same thing. I think it processes information in service of generating behavior and part of that
*  generation of behavior is about generating the appropriate perceptual signals so that we can
*  assess our predictive abilities and so on. It's very inclusive of you. Okay, very good.
*  Sorry, I interrupted you. I grew up Lutheran, so try to be very ecumenical.
*  First, I would say that I agree with the commentary by David Popple and Adolfi that
*  Buzaki's philosophy of science is kind of broken. I mean, he basically says, I think, that we need
*  to free ourselves from prior assumptions. And if we basically can look at the data and somehow this
*  new taxonomy of mind will emerge. It's never clear to me from the book exactly how that happens
*  because all the things he's talking about are kind of things that certainly memory and spatial
*  navigation, these are all things that people were talking about well before anyone ever measured a
*  brain. Well, he does the same thing in his talks as you did in your blog post and as you've mentioned
*  in multiple of your talks is using William James's table of contents, for instance,
*  to talk about how old these concepts are. And his take is that we both have the, we need to revisit
*  these concepts take on it, but from different philosophical vantage points.
*  Yeah. And I agree with him on that, right? That we need to, I think his strategy seems to be,
*  basically, let's throw it all out and then try to kind of build up from neural data,
*  some new functional description, quote unquote, without, free of prior assumptions,
*  which I think is just, that's a broken philosophy of science. You just can't do that. So if you
*  think you're working without philosophical assumptions, then you're basically, you just have
*  implicit philosophical assumptions that you haven't examined.
*  In fairness to him, he's not here to defend himself, so I'll defend him. He was at pains
*  when we talked before to, I don't know if backtrack, to explain that that is not his actual,
*  that he does have theoretical assumptions and that we all work from those and he does
*  acknowledge those. So it's somewhere in between, it's being able to acknowledge them and throw
*  them out eventually, but not go just from the ground up, I suppose. But yeah, I won't defend
*  that. That's fair. I'm glad to hear that. I mean, I think fundamentally the issue that I have is
*  that I don't see, if somebody could show me an example of how this stuff works for something
*  beyond these relatively, something beyond stuff that rats do, like behaving in the world on
*  relatively simple types of tasks, spatial navigation, spatial memory, that sort of stuff.
*  I'm interested to see how this could work for understanding, say, self-control or economic
*  decision-making or very much higher level types of cognitive functions that I think are going to be
*  very challenging to have emerge, especially if you can't, even if you could study humans with all the
*  tools you can use to study rodents, I don't think they would emerge, but we can't. And so that makes
*  it even harder. With him, this is a framework that needs to be tested, and that's what we're
*  going about trying to do. Yeah. I mean, this is the big goal. It's the big dream, and this is what
*  the cognitive ontology is all about. And this is what everyone wants, right, to bridge the brain
*  and mind. Okay. Well, switching gears here. So a self-driving car probably doesn't need to fit
*  into any cognitive ontology, or does it? I mean, does a cognitive ontology matter for building AI?
*  And I know that this is loaded because it depends on what AI you want to build, of course. But how
*  do you see, and we've already talked about the deep learning aspect of AI, how do you see a
*  cognitive ontology and understanding the linkage between our brains and minds? Does that matter
*  for AI? So I'll speak to kind of artificial general intelligence, right, kind of the most
*  expansive type of AI. And I think, obviously, just because evolution built our mind in a particular
*  way doesn't mean that that's the best way or that's the only way to build a system to solve the
*  problems that we solve in the world, right? So I don't know that necessarily that you have to know
*  anything about the ontology of the human mind in order to effectively build an AGI system.
*  I think that the place where it probably becomes really useful is thinking about what are the
*  cognitive abilities or the cognitive tasks that humans can solve, right? Because if you're going
*  to build a self-driving car, you need to basically know what are all of the things one has to be able
*  to do, what are all the functions that a system needs in order to effectively engage in that
*  repertoire of behaviors out in the world, right? And so there, I think, we're kind of thinking
*  through what are all the things that one needs. So obviously, working memory is going to be
*  important because you're going to need to probably keep track of where all the things are around you,
*  right? Episodic memory might be important because you need to remember, hey, last time I drove
*  through here, some kids ran out in front of me, so that might happen again. So I think that one can
*  certainly get clues from cognitive ontology, but I think it's more kind of like the task ontology than
*  the function ontology that's probably more important for the people doing the building.
*  Yeah. Do you think that building in the task ontology, then the mental function ontology would
*  naturally occur? Or would that depend on the underlying architecture of the system,
*  for example? Yeah, it's an interesting question. In part because we rely on people being able to
*  talk about things to get at some of these underlying functions. So I think that one
*  could probably infer, it sort of gets back to our discussion earlier, like, let's take a really
*  complex, take like AlphaGo or something, a complex deep reinforcement learning system.
*  You can almost certainly put labels on parts of that system that are functional labels, right?
*  I don't know the model well enough to know what those would be, but you almost certainly could
*  chop it up and say, these are going to be, this is the retina, if you will. This is the thing that's
*  computing the prediction error or doing the exploration or whatever those things might be.
*  And that might or might not be useful for the person building that system. But I mean,
*  it is interesting that at least some of the recent work in reinforcement learning has been taking
*  basically episodic memory and building it into these deep reinforcement learning systems.
*  So you might think that that's, I mean, I don't know where those intuitions came from,
*  but I think they in part came from knowledge of how human brains work or how mammalian brains work.
*  So thinking about the ontology and how different cognitive tasks and the related mental functions,
*  there's this huge overlap, right? And you might have one cognitive task that employs four different
*  mental functions, and you might have one mental function that applies to 12 different cognitive
*  tasks. And then there's that, I'll use the word emerges, you have these higher functions that,
*  whatever the function is, we give it a name, emerges through the interaction of these different
*  systems, right? These different lower finer grained mental functions, let's say.
*  Might it be necessary then for an AGI system, let's say, to be put together in such a way that
*  these lower level, more fine grained mental functions are interacting in such a way as to
*  dynamically give where a higher mental function, quote unquote, would be an emergent property of
*  these lower level interacting functions? Yeah, I think it's reasonable to think that that could
*  be the case and that something could be learned from computational neuroscience and psychology
*  that would help build those things. I'm not deep in the deep learning world, so I don't know
*  to what degree those insights have actually come to pass. It's a reasonable strategy.
*  So in the new mind readers, I'm going to read a quote from you. You say,
*  I was in graduate school, and you already mentioned this a little bit earlier.
*  I was in graduate school in the early 1990s and had heard lots of hype about fMRI,
*  but it wasn't available at the University of Illinois where I was a student. When I moved
*  to Stanford as a postdoctoral fellow in 1995, I had not initially planned to do fMRI research,
*  but I got pulled in by the excitement of this new technique. Just as a
*  career type question, what do you take from that regarding being pulled in by a new exciting
*  technique? I'm thinking about deep learning in particular and deep reinforcement learning
*  and all the hype, the revolution, and I'm using air quotes, of AI that has recently happened.
*  Would you be pulled in? It's an interesting question. I think I'm cynical enough in general
*  that if I were to be pulled in, I'd probably end up being one of those internal critics,
*  kind of like I've been in the fMRI world. That actually wouldn't surprise me. I think actually
*  some of the really cool work that's going on right now, even though I understand it at best
*  it's kind of like a storytelling way, is a lot of the theoretical neuroscience work that's trying
*  to understand why is it that neural networks work well or don't for particular problems from a
*  fundamental theory standpoint. I could see getting pulled into asking those kinds of questions.
*  Okay. Yeah, I like that getting pulled in and just to be a nuisance.
*  Exactly.
*  To use the techniques and be a nuisance. Russ, have we missed anything about cognitive ontology
*  that you wanted to touch on? Because I have other sort of general and career type questions for you.
*  Yeah, no, let's move on.
*  Okay. So you're productive. In fact, you've written on your blog post multiple times about
*  your productivity stack and people are impressed that you somehow maintain a career fixing
*  neuroscience and psychology plus doing neuroscience and psychology. What's the secret? How do you
*  maintain such a healthy balance in your approach and your productivity while still being very
*  productive?
*  You're assuming that I actually maintain a healthy balance.
*  Well, no, actually I think I do.
*  I know you eat a lot of brisket and I know that's not healthy.
*  Right. Oh, it's very healthy actually. So yeah, I think the short answer is just that I really love
*  a lot of what I do and so I don't really consider it work. I wake up in the morning and I'm like,
*  I really want to go do that analysis or go read that paper. And so I do work a ton but I think
*  the thing that helps me maintain the balance is having pretty strict rules about not letting my
*  academic pursuits negatively affect the other parts of my life. So for example, I refuse to
*  let work keep me from sleeping. If there's something that has to be done and the only way
*  it's going to get done is if I stay up all night, then it's just not going to get done.
*  And also I refuse to let work get in the way of exercise or time with my wife or practicing
*  guitar. I feel like there are things that one has to do to remain reasonably balanced in one's life.
*  I certainly occasionally I'll spend, especially these days where everything's happening on Zoom,
*  I'll end up spending eight hours in a day in my chair and I just feel trashed afterwards.
*  And so that's about as, I try not to even let myself do that. Obviously sometimes one can't
*  help it. Got to go on podcasts and stuff. Exactly. How important is it that you have this innate
*  drive? I don't remember the term that you used, how you described yourself earlier, if it was nerd or
*  just computational intrigued person, but you have this sort of innate drive toward the analytical
*  side of things and the computational side of things. And there's almost a antithesis between
*  that and just pondering the higher questions and what is mental function in general.
*  So I don't know, you seem to have this really nice balance. Do you think that that is really
*  important to have this passion for the analytics of things with being able to ask the higher
*  questions? For me, it certainly has been. It's interesting. I minored in philosophy as an
*  undergrad and actually spent in grad school, even though I was in grad school for cognitive
*  psychology, I actually spent a lot of time reading philosophy of mind, philosophy of science
*  sort of work. And I think that it's probably obvious that I've done that,
*  because I think it's kind of infected the way that I think and write. So for me, I think that
*  there's a lot to be said for having a mixture of those different ways of thinking about things.
*  I think that in general, I think that people who think... Obviously, there's room for lots of
*  different types of people in science. We need the people who are going to really be very hard-nosed,
*  focused on a particular question, digging in as deeply as they can, building really detailed
*  theories. And then I think I just constitutionally couldn't do that. I think we also need people
*  more like me who really kind of look very broadly, try to kind of bring together ideas
*  from lots of different sources. And it's been successful and fun for me.
*  Pete Yeah. Whatever you're doing, it seems like it's fun and rewarding.
*  John Indeed.
*  Pete So you have been impressively productive. And I assume everything has gone just perfectly
*  for you throughout your career. But if it hasn't, okay, good. I mean, have you ever felt
*  disillusioned or have you ever had a major failure for whatever reason? And if so,
*  I'd love to hear about it and how you overcame it.
*  John Well, yeah, I felt disillusioned at a lot of points. I mean, in some ways, I think because
*  I'm a cynic, I'm kind of continually disillusioned.
*  Pete That's your base state.
*  John Exactly. Or maybe I just look for, I'm like searching for disillusionment. But I guess,
*  for example, the last few years, I've been really deeply disillusioned about the way that everyone
*  else have done it from my studies since I started doing it back in the 90s, both because of all the
*  methodological issues, the analytic flexibility that basically allows pretty much any study to
*  find a positive result. But more importantly, because I think that even if we did the methods
*  right, I think the strategy that we've been using wouldn't be able to actually answer the
*  questions we want to answer. So what I've done is turn that into trying to figure out how I can
*  actually do some work that tries to address the problem. So on the analytic flexibility side,
*  I've talked for a while about the fact that there's so many different ways to analyze an
*  fMRI dataset and we've known for a long time that these can lead to different results,
*  but we didn't really know to what degree that actually has impact in the real world. So we
*  did a study last year that came out earlier this year, we call it the NARP study, where basically
*  we had 70 different groups analyze a real fMRI dataset, test a set of hypotheses, and tell us
*  what they found. And we found really a disconcerting amount of disagreement in what they found.
*  And we dug in a lot to try to figure that out. But that was a step to... That was really inspired
*  by my disillusionment. And then the work that I did for that project... So I wrote most of the
*  analysis code for the project last summer before this last one. And it was really that experience
*  that spurred me to become much more interested in software engineering practices that I've
*  continued with. So I think I try to overcome disillusionment through action.
*  Had you not written code in a while and that's why it was a bad experience?
*  No. I mean, I've... In some ways, the thing I like most about this job is the fact that I still get
*  to write code pretty regularly. So I started coding when I was in high school, back when you
*  saved your program to a cassette tape. Oh, not even a floppy? It was like...
*  No, no, no. I had a TI-994A and I programmed in BASIC on it. So I've been programming for
*  a long time and really enjoy it, but had never really... I'm totally self-taught. I've taken
*  one CS course in my life. And so there's been a lot of learning to do around that. But it was
*  really just trying to... What happened was this is a project in reproducibility and I was like,
*  well, we need to make this as reproducible as possible. And so I spent a lot of time
*  trying to think about what is the best... When talking to people, trying to figure out what is
*  the best way to make this thing as reproducible as possible. I still need to write something about
*  exactly what we did. It's there implicitly in the methods section, but I haven't written anything
*  about it. Well, what about other... Have you been disillusioned in your career? So what you're
*  talking about is almost a... It's like a scientific disillusionment, right? But have you ever thought,
*  oh, I shouldn't go on because the field is so rife with difficulties or didn't think that
*  you had the chops or something like that? I doubt that's the case.
*  I always feel like I don't have the chops. I think...
*  Yeah. The way you approach things, it seems like is the way that the ideal hypothesis
*  approach to science is that you seek to fail. That's the way that you seem to approach science.
*  Yeah. It's not exactly the most psychologically healthy way of dealing with life, but I think
*  it's actually pretty effective for science. Seems to be. How would you... Lastly, Russ,
*  if you were going to begin again, do you have an idea of how you would start over if you were
*  starting over right now, let's say thinking about going into graduate school or early in graduate
*  school? I think the main thing I would do is wear earplugs at rock shows so that I wouldn't need a
*  hearing aid in my 50s. You have a hearing aid? Yeah. Oh, man. Yeah. I have pretty substantial
*  hearing loss. I think both from going to way too many rock shows, playing in bands in high school
*  and then also... I grew up in Texas. We shot a lot of guns as kids and I don't remember wearing
*  any hearing protection when we were shooting guns. I think all those things have blown my hearing.
*  I'm from Texas. Where did you grow up in Texas? Outside of Houston, Rosenberg.
*  Okay. Yeah. I'm from the Dallas area. Wonderful areas. Okay. So back to your question.
*  Besides wearing the ear protection, which I think is a great idea. I have a friend with tinnitus
*  because of the same reasons. Yeah. So I guess the question is, am I starting again now or am I
*  starting in back in the day? Young Russ. Young Russ. I'm not sure what I would do differently
*  other than maybe being more disciplined about learning, particularly computational skills
*  because I've been really kind of haphazard in how I've learned them. I think so much of success is
*  just luck and capitalizing on luck. I was really lucky to end up at Mass General Hospital in the
*  late 90s. I was really lucky to end up at Stanford at a time when FMRY was taking off. I've been
*  really lucky to end up around various colleagues at the various places I've been. I don't know
*  that I'd want to change any of that. I went to undergraduate at the University of Texas at Austin.
*  What do you miss about Austin? Anything? Barbecue.
*  Are you making brisket these days? Occasionally. I don't smoke brisket very often just because it's
*  such an ordeal. Although I've started, usually you would do it low and slow and then you're
*  smoking for 16 hours. But I've tried the hot and fast method and it's actually pretty good. You
*  can get it done in a day, so that's not too bad. But I'll usually smoke either beef ribs or pork
*  ribs or pork shoulder or things like that. See, I'm not sure I'm a true Texan because I think
*  brisket is overrated. But I have had really good brisket. I've had really good brisket,
*  but most brisket I've had is not good brisket. I think you can have bad ribs and they're still
*  pretty good. If you have bad brisket, it's not good. I would agree with that.
*  Russ, this has been very fun, very enlightening. I really appreciate it. Continue the great work
*  that you're doing. Thanks very much. It's been great to chat with you.
