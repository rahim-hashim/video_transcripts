---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 5969s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 9861
Video Rating: None
---

# BI 124 Peter Robin Hiesinger: The Self-Assembling Brain
**Brain Inspired:** [January 05, 2022](https://www.youtube.com/watch?v=rkD0A0HPK3s)
*  There is only one way to do it.
*  You need to let it grow.
*  You need to let an amount of information unfold that you then need if you wanted to describe
*  that endpoint bit by bit would be quite a lot.
*  But if you would only want to describe the information needed to grow it would be very
*  little.
*  But you can't predict from the little information what the endpoint would look like without
*  actually growing it.
*  And the genome is always just there.
*  It's like a book that's always there and you always just need to decide what to read in
*  that book.
*  And to access that book is just enormously complicated.
*  You can't just open page 255.
*  You literally need a very strange combination of say 30 different proteins that are super
*  unlikely to ever exist at the same time in the cell.
*  But if they do...
*  This is Brain Inspired.
*  That was the voice of Peter Robin Heesinger who recently authored the book The Self-Assembling
*  Brain How Neural Networks Grow Smarter.
*  Hi everyone, I'm Paul.
*  And today I talk with Robin about a handful of topics in the book.
*  Robin is a neurobiologist or a neurogeneticist more specifically at Free University of Berlin
*  studying among other things how DNA and the developmental process encodes the wiring of
*  brains in the fruit fly Drosophila.
*  The central theme of his book is that current artificial intelligence and perhaps current
*  Neuroscience theories are leaving out an essential part of what makes us intelligent and that's
*  the growth and development of our brains neural networks.
*  And in the case of deep learning, an artificial neural network.
*  Robin suggests we don't yet appreciate how information, which begins at a relatively
*  low level encoded in our DNA, unfolds and increases with time and energy as our networks
*  are formed, something Robin calls algorithmic growth.
*  And his claim is that it's essential to include a growth and an evolutionary selection
*  process to get anywhere close to building something with human like intelligence, if
*  that's even what we want.
*  So we talk about that central theme and many of the issues that arise out of it.
*  And as you'll hear, the book is also a history lesson about the parallel yet independent
*  paths of AI and developmental neurobiology.
*  Show notes are at brain inspired.co slash podcast slash 124.
*  Thanks to all my Patreon supporters.
*  If you like this sort of thing and you want access to all the full episodes and to join
*  our brand inspired discord group, you can do that on the website also at brand inspired
*  co.
*  All right, enjoy Robin.
*  Robin, I enjoyed the book immensely.
*  So we're going to talk all about it.
*  One of the things that I was surprised about when I read it, given that I'd seen one of
*  your lectures was the amount.
*  So of course, you dive into the history of AI, because the book is all about how AI might
*  be missing something, right?
*  But what I was surprised about and thoroughly enjoyed as well was the history of developmental
*  neurobiology and how you weaved that history into the history with of AI and how they happened
*  in parallel.
*  And of course, you know, hadn't really spoken to each other for many years.
*  And you did it in a format that was sort of a storytelling format.
*  So it's very easy to digest.
*  So congratulations and thanks for writing the book.
*  Thank you so much for having so much good things to say about it.
*  Yeah, it is a unusual angle.
*  And it's because I'm coming from kind of left field, if you will.
*  Right.
*  I'm a neurobiologist.
*  I, you know, I dabbled a bit in informatics and I dabbled a bit in philosophy as a student.
*  But I'm running a research lab on teaching undergraduate and graduate students.
*  And we're publishing papers on how genes encode the information to wire a brain.
*  And so the origin of this somewhat unusual approach and of the parallel storytelling
*  of a field of neurobiology and artificial intelligence really kind of originates with
*  me being, I guess, somewhat unhappy with my own field in biology, because, you know,
*  we started many years ago in the very successful molecular revolution to publish more and more
*  papers on individual genes, their products and their roles in how the brain develops
*  and how it functions.
*  And it's led to a data explosion.
*  A very good friend and colleague, Bassem Hassam, always says, you know, we're increasing the
*  amount of knowledge at an unbelievable pace, but our increase of understanding is not keeping
*  up.
*  And so I was wondering whether we're missing something.
*  I was wondering whether we need some kind of theory, whether we need some kind of information
*  theoretical background.
*  What does it even mean that the genes encode the brain?
*  I mean, that's obviously a very loaded, strange question.
*  And then, of course, you can't avoid in this day and age being bombarded by the news about
*  some kind of allegedly superintelligent systems, you know, seemingly overtaking us next week.
*  So what do they know that I didn't?
*  That's when I started to feel like, okay, maybe these people know something that I don't.
*  And I realized, and that's where the historical part comes in, that the history of AI is unbelievably
*  fascinating.
*  My goodness, these people have been at each other from very different fields for so many
*  decades.
*  And for most of those decades, they really wanted to have nothing to do with the brain
*  or neurobiology at all.
*  And all the successful approaches that we hear about today, this like unbelievable,
*  you know, success of AI that we have right now is actually all based on what is called
*  artificial neural networks.
*  And they're closer to the brain than any approach in AI has ever been in history.
*  So that got to be interesting, right?
*  I mean, if they suddenly take an idea that we have been studying as biologists for so
*  many years, and they can do with it things that we can't do, and then we feel we can
*  also do some things that they can't do, maybe we should talk to each other.
*  So this is how it started.
*  So I was imagining that as a neurobiologist, you saw the deep learning revolution, the
*  neural networks, and essentially, you said, Whoa, whoa, they have a lot to learn from
*  me.
*  But in fact, it was kind of the other way around when you first poked your nose into
*  it, thinking, what do they know that that I don't know?
*  Absolutely.
*  I mean, the idea that, you know, they should be listening to us is dangerously close to
*  ignorance in any kind of approach, right?
*  Because you need to first understand what the other field is doing.
*  And it's a very rich field.
*  And so this is exactly why I had to go into the history.
*  I mean, when I started, I just wanted to know, okay, what are they doing right now?
*  What is interesting about this?
*  And I found like, okay, deep learning is really cool.
*  The recent approaches in reinforcement learning make perfect sense to me.
*  It even has an evolutionary angle.
*  This is even more biological than anything, right?
*  clearly learn with some kind of reinforcement learning.
*  So that makes some sense.
*  So that was all very good.
*  But then you start to wonder, why are they doing certain things?
*  Not at all.
*  That you know, I'm actually spending my life studying.
*  And the thing that came to the forefront at that moment in my thinking, of course, was,
*  wait, I'm a neurogeneticist.
*  I'm studying how genes encode a growth process to make a neural network.
*  And that thing is actually pretty smart before you start learning anything.
*  I mean, we can talk about examples later on from the insect world to, you know, when a
*  baby is born, it's not born with the network that starts to learn.
*  Actually, exactly what all pretty much all deep learning approaches do today.
*  There's no genome, there's no growth process that turned on to learn.
*  That made me then wonder, okay, why is it that they're doing one thing that we know
*  from biology, but not the other?
*  Why is it that they initially didn't even want to use neural networks to start with?
*  And when I started to understand their history, I had like so many moments of, yeah, you know,
*  these kinds of problems I've seen before.
*  We had that in biology.
*  We had a time when people felt like the human brain is so amazing in our thinking and learning.
*  You know, it got it, you know, the genome, you know, beginning, it was, of course, even
*  not known what the genome looks like.
*  It had to be learned, right?
*  And so this debate on learning, not nature versus nurture, on how much can actually get
*  into a network via a growth process and to what extent you would even need it has been
*  there in the neurosciences as well, some time ago, but in one form or other, it's still
*  there.
*  And so this is very interesting, right?
*  So to see then the parallels between those fields, to see how, from my perspective, to
*  some extent, the AI community is actually retracing some steps that historically neuroscientists
*  made me wonder that, you know, there's something, again, that we need to talk about, we should.
*  And I wondered how much we are, and it turns out there's very little crosstalk.
*  And so this is how the book originated.
*  So I want to talk just for a moment more about the book itself before we get into the ideas
*  that are in the book, because I'm curious, for one thing, that was a very rich in detailed
*  history that you told of the developmental process.
*  Was that a lot of work or was that easy to piece together?
*  Because I know the AI history or I knew the AI history quite well, because it's been told
*  a few times, and I even learned more about it through your writing.
*  But what I didn't know about was that rich history in developmental neurobiology.
*  Did you just know all that or was that a lot of research that you had to do to write that?
*  It's both.
*  I mean, it came first, of course, right?
*  I mean, it is my field, but you're actually touching quite an exposed nerve.
*  I mean, if we go into, if you open textbooks, there is a lot of knowledge that is being
*  communicated without communicating the field's history.
*  And there are some debates that just appear ludicrous today, right?
*  I mean, the whole debate, this is how the whole problem, how many of my lectures and
*  the book start, is that people couldn't even agree whether a neuron is a physiological
*  unit because nobody could understand how you could have so many of those things wiring
*  together, right?
*  And so this seems, of course, it's a completely settled debate.
*  Of course, we know that the brain is made up of neurons and their physiological units
*  and somehow they need to connect up to make something that works and appears smart to
*  us.
*  But this you can only understand if you actually have the historical context.
*  And of course, I knew some historical context, but probably not more than any other somewhat
*  trained developmental biologist.
*  And when I started worrying about my own field, this actually happened before any deep diving
*  into AI history.
*  And where are we at right now?
*  Why are we just collecting gene after gene and molecular function after molecular function
*  and publishing more papers every year than ever in the history of developmental neurobiology
*  before?
*  And are we actually getting closer to understanding how that thing is put together?
*  So when I started worrying about this and wondering about this, that's of course when
*  I initially went back in the history of where this came from.
*  And there's a very cool story to be told that's of course in the book of an interesting
*  breakpoint in history where a very famous neuroscientist, Roger Sperry, went ahead and
*  said, you know what?
*  embryonic development will make a brain out of individual neurons live with it.
*  And there got to be molecular interactions that ultimately define the development and
*  the growth of that network.
*  And that was at a time in the 30s, 40s and 50s predominantly, when most scientists, including
*  the famous, even more famous supervisors of this gentleman were on the other side of the
*  spectrum and said, you know, it got to be all somehow induced by some kind of plastic
*  form of learning.
*  And, you know, it was a field of psychology.
*  Brain wiring was at that time the subject of psychology and not the subject of, you
*  know, today like molecular geneticists.
*  They didn't exist really at that time.
*  So this is where it all started.
*  And it's been good and bad.
*  Of course, we know that, you know, there are a lot, some say an infinite number of instances
*  of individual molecular functions in different contexts and specific cells and specific animals
*  at specific developmental stages.
*  I mean, you know, there's no limit to the depth of this that you can study and publish
*  papers on.
*  But how the genome actually does that?
*  You know, famously, the genome contains one gigabyte of data.
*  And there are people in the AI field like Schmidt, Huber and others who actually use
*  that as an argument and saying, look, you know, one gigabyte of data that can't encode
*  anything.
*  So, you know, we don't even need to look there.
*  Clearly, we only need learning.
*  We don't need the genome.
*  But then again, of course, what we're all doing, maybe not looking at the whole forest
*  at a time, but always like looking at some individual leaf or needle of just one tree
*  inside that forest is looking at how the thing unfolds.
*  And we do know that an apple seed will grow an apple tree.
*  This is the job of developmental biology.
*  And the development of the brain is no different.
*  And so this is basically where we're coming from.
*  And this is where the history became so important and has a huge impact on what we do today.
*  So, I will read from a quote from your book, I guess, to start us off here because just
*  dovetailing off of what you were just mentioning.
*  This, then, is the core question of our workshop.
*  What difference does it make for the intelligence of a neural network, whether connectivity
*  is grown in an algorithmic process that is programmed by evolution versus only learned
*  based on a designed network with initially random connectivity?
*  So, you were just talking about people like Schmidt Huber, and not to single him out because
*  it's the entire AI community, essentially.
*  After reading your book, it's just a curiosity that we all, I'll include myself, right?
*  Because at first pass, it's like you have this brain, you have the network, and then
*  all you need to do is learn from there.
*  And that's what intelligence is about.
*  But your book makes the argument or asks the question that maybe the growth process itself
*  from the genetic code is an important part of that process.
*  And of course, there are debates in the deep learning field how important inductive biases
*  are and the architectures that you use and whether that matters.
*  But I would guess that you'd say that that's not enough.
*  Yeah, exactly.
*  That's exactly what I would say.
*  But I would also say it's a step in the right direction.
*  There's like convolutional neural networks that are basically mimicking a little bit
*  of the wiring of a visual cortex in mammals.
*  Or the new proposal that just made somewhat of a splash by Jeff Hawkins in his Thousands
*  Brains is of course that we've got to design these things like the cortex.
*  And then you have like all these cortical columns, and then they can compete and vote
*  and all these things, right?
*  And these are all very good ideas.
*  But they're basically coming like tiny, tiny steps back from like the purely random network.
*  And of course, they're still designed.
*  So in biology, how you got to the cortical columns in the first place was of course through
*  a growth process.
*  And the fact that there are cortical columns contains information.
*  It's not just a randomly connected network that we have in our brain.
*  Otherwise, most of my neuroscience colleagues would be out of a job very quickly.
*  They're studying circuitry.
*  They're studying how the neurons are exactly put together.
*  And it's fabulous.
*  I mean, you can study things like motion detection.
*  So it's a beautiful example by understanding how exactly different types of neurons with
*  certain delays and certain conduction velocities and synaptic strengths and then some state
*  dependencies where you have some neuromodulators that whole populations of neurons suddenly
*  have a lower threshold, all kinds of stuff.
*  And when you see how all of this is put together, suddenly you understand you can even build
*  a computational model based on that.
*  And it tells you, yeah, you know, this network can see motion.
*  But this is very different from teaching a completely random connected network motion
*  detection, right?
*  So to teach the randomly connected network will not lead you to all the both cellular
*  connectivity that is very specific that I just try to just, you know, like outlines
*  describe or the molecular aspects, which are things like I even mentioned something like
*  a neuromodulator.
*  These are molecules that are diffusing in whole areas of the brain and changing synaptic
*  weights.
*  And this is simply not included in the modeling of synaptic weight changes in an artificial
*  neural network.
*  So evolution has found solutions to problems that the brain can solve like motion detection,
*  like you name anything up to cognitive abilities in the human brain or down in insects.
*  You know, my favorite example is the monarch butterfly that flies these 3000 miles.
*  Yeah, you seem you're crazy about butterflies.
*  Yeah, I really love those.
*  They do so much.
*  They're like half a gram and they can do so many things.
*  If you wanted to train a neural network that is randomly connected to do all the things
*  a butterfly can do to achieve butterfly intelligence, I can tell you we're far away from that.
*  But you know, without strength, this is the this is the this is the idea, right?
*  So clearly, learning from biology has become more accepted than ever in the history of
*  AI before.
*  Jeff Hawkins famously was unhappy early on as a as a young person before becoming a billionaire
*  that he wanted to learn from the brain.
*  And you know, there's a whole history and this is why I tell that history right in the
*  book in AI research saying, you know, we don't need all this messy wet stuff.
*  And you know, it's all these idiosyncratic solutions that evolution may have found a
*  way we can design something from scratch.
*  It's better.
*  And now we're at a time where we're kind of, you know, dipping in.
*  I mean, when I say we actually talk about the AI community deep dipping into ideas from
*  the brain, like, you know, maybe we need cortical columns.
*  But it's really just the tip of an iceberg because the brain is not just simply cortical
*  columns.
*  It is all the molecular beauty that defines how individual neurons communicate with each
*  other.
*  And there is so much information, not just in the connectivity of a specifically wired
*  network, but also in the molecular composition that you cannot, if you want to simulate the
*  way the human brain works or butterfly brain works, just reduce to synaptic weight changes.
*  And so this is where I'm coming from.
*  Well, I don't know how much I agree with you that it's more acceptable now to include
*  biological detail because there's and you document this in the book as well.
*  There is a constant drive in the community to abstract out as much as possible.
*  Right.
*  So the idea that they that you would need to include growth, and we'll talk more about
*  the details there in a moment, the idea that you would need to include growth from the
*  gene must be horrendously unattractive to someone in the AI community who's just trying
*  to get their neural network to learn something.
*  Right.
*  Yes, it's very unattractive.
*  We did the experiment together with colleagues just how unattractive it is.
*  If you just want to learn a specific task.
*  And this brings us to a very interesting topic, right?
*  I mean, artificial neural networks based on reinforcement learning have been at this point
*  more successful in almost any individual task a human could do that I could imagine.
*  I mean, obviously, they can play better chess, they can do better visual image recognition,
*  they can do better solutions to the cocktail party problem, auditory present, whatever.
*  So individual things, you can train these things to become better.
*  If you now want to train the same network something else, you quickly have the problem
*  of catastrophic forgetting.
*  And the AI community is trying to address that with deep learning approaches.
*  And there are some good proposals.
*  Now, the bottleneck in teaching a network any of these things is still the training,
*  obviously, because the design is largely random, right?
*  I mean, you may have some pre-connectivity like in a convolutional or recurrent neural
*  network, but really, the key bottleneck is learning.
*  So reinforcement learning takes a lot of time and energy to get that thing to be really
*  good.
*  Once it has learned it, you can just deploy it.
*  Then it can decide whether it still should learn anything or not.
*  But once it has learned something, it just can do, right?
*  It can recognize images, it can make predictions about who should be your spouse or your next
*  soap.
*  Now, if you want to do this same job for a specific task with a neural network that is
*  not trained by learning, but that is trained by a genome that produces the network.
*  And then once you grow that network, you have it evolutionary selection for one that works
*  back to the genome and iterations of this process.
*  Then you will soon find out that the time and energy that takes is even enormously bigger.
*  So maybe it's really worth saying one more word about this.
*  The AI that we know today, everything in any of these big Silicon Valley companies, they
*  were all familiar with all the stuff that we're scared of or impressed by.
*  It's all trained networks that have been trained in one or the other form, big data or reinforcement
*  learning, deep learning stuff, right?
*  But there is an AI community that actually does a very different type of learning of
*  artificial neural networks.
*  And it works like this.
*  You take a genome, the genome defines, in the easiest case, directly synaptic weights.
*  It's not how biology works, but that's the easiest approach you can take.
*  You can say, I have one gene per synapse, if you will, right?
*  And then you can basically fill the synaptic weights of a matrix of a recurrent neural
*  network.
*  And then you can have that thing do something.
*  For example, let a little agent find a path through a maze or do image recognition, anything
*  you want.
*  And then if it did it well, then you take more of the genome that was at the base of
*  this.
*  And if it didn't do it well, you just mutate more of the genome at the base of this.
*  And then you do it again, and then you do it again, and then you do it again.
*  Just like backpropagation is an iterative process where you train and train and train
*  classic deep learning.
*  And reinforcement learning is actually very similar to the process I just told you, right?
*  Because you only learn from the end state of the system.
*  So can you actually train a network not by learning, but by keeping on randomly mutating
*  that genome that feeds the synaptic weight matrix?
*  But that's still without a developmental process.
*  And if you now add a developmental process, this thing gets very quickly, even for the
*  biggest computers on earth, out of hand.
*  You'd have a genome that's a few hundred genes.
*  It's not even been done, maybe a few dozens.
*  And then you basically feed that into some gene regulatory network.
*  That may have to go through a few hundred iterations of a developmental process.
*  That leads to the numbers that you fill in the weight matrix for the recurrent neural
*  network.
*  Then you finally have a network that can do a task, perform something, see whether it's
*  good.
*  And if it's good, it's good.
*  You keep more of the genome.
*  And if it was bad, you mutate more of it.
*  This iterative process.
*  So it's a huge computational effort.
*  It's orders of magnitude, more computational power needed to even simulate a laughingly
*  simple version of a genome and developmental process in an iterative evolutionary selection
*  process.
*  And the outcome is at this point in time, never better than the deep learning stuff.
*  So therefore, nobody's doing it.
*  That's not quite true.
*  There are some academic scientists doing it.
*  But then the question becomes, where are we in this?
*  Artificial neural networks based on deep learning, I mean, before there was deep learning, before
*  we had this humongous amount of data, and faster computers also were not successful.
*  That's when simple processing logic had its heyday in AI.
*  So maybe today we're at a time when computers are still not fast enough.
*  Maybe we need quantum computers or something to actually simulate the evolution of the
*  growth process and neural networks.
*  So not deep learning, but neuro evo devo learning, if you will, of artificial neural networks.
*  And then they suddenly will become powerful.
*  That's one thought.
*  And just the last thought, and then you need to stop me because otherwise I keep on talking.
*  It's also a big question of what we're trying to achieve.
*  Arguably, to achieve a single task, I don't see why this enormous effort that I'm talking
*  about here right now would be better.
*  If you just need face recognition, deep learning is amazing.
*  And I don't see how this orders of magnitude, more computational effort, evolution of the
*  neural network would do that one task better.
*  But this, of course, brings us to the question of artificial general intelligence and where
*  we're really going with this.
*  Maybe you need that more, much more effort process if you want to go beyond single task
*  artificial intelligence.
*  That was a lot that you just talked about.
*  Maybe where we could start is the concept of unfolding information and algorithmic growth.
*  So you had mentioned that there's not enough, well, you alluded to that there's not enough
*  information contained in the DNA, in our DNA, to encode all the synaptic connections in
*  our brain.
*  It's orders of magnitude less than you would need to encode the entire structure of our
*  brain.
*  But that through the process of genes becoming proteins and transcription factors and through
*  the developmental process, through which you call algorithmic growth, that information
*  unfolds and that essentially encodes the program that results in our connected brain.
*  So could you talk about the concept of unfolding information and algorithmic growth?
*  So the words are the best I could find, unfolding information and algorithmic growth, but they're
*  just putting a label on something that we clearly observe.
*  We know that if we look at an apple seed, we can get all the information out that's
*  in there.
*  It's in the sequence of the DNA.
*  Maybe some lipids around it are important.
*  We need to know some physical laws.
*  And you know, based on experience that you've seen it before, that if you put that seed
*  in the ground, there will be an apple tree one day.
*  You know what it will look like.
*  So in the apple seed, there is no way to read that it will be an apple tree.
*  The only reason why we know that this is what happens is because we've seen it happen before.
*  If you would not know, then I say the apple seed will not reveal the secret.
*  You can only compare it to other sequences you have and what they did in the past, but
*  that's the same sleigh of hand, right?
*  That's the same cheating based on previous outcomes.
*  Even if you could read all the DNA and know everything about the contents of the apple
*  seed.
*  Yeah.
*  So this is what I'm saying.
*  And this is controversial.
*  Right.
*  Clearly, there are more optimistic molecular geneticists than me that feel like one day,
*  if we just know enough, you know, we just will understand just how this happens.
*  And so this is what brought me to try to find out whether there is any more solid way, any
*  mathematical way.
*  There's something in science that tells us whether or not something like this can be
*  unpredictable, that you have a simple code, right?
*  Let's just call that one gigabyte of genetic information.
*  Simple.
*  I mean, it's not, but you know, it's amazing.
*  But just for, you know, in relation to describe, let's put it like this, describing the DNA
*  sequence in our genome or in an apple seed compared to describing every single neural
*  connection in your brain, or even the branching pattern of an apple tree is like, you know,
*  it's like comparing almost nothing to an enormous amount of information.
*  Right?
*  So clearly something happens.
*  See it's clearly during growth, you know, there's more in your brain than you can read
*  in a sperm and an egg.
*  And so I try to find examples.
*  So I talked to mathematicians and I looked in other fields again.
*  And so I came across something that actually been, you know, I've known for a long time,
*  but it's not been obvious to me where the connection lies.
*  And I guess it's a connection that still requires some explaining.
*  There are examples of very simple rule sets, very simple codes that can lead to a lot of
*  what we like to call complexity.
*  And the example that I use then in the book are cellular automata, right?
*  Stephen Wolfram made them quite famous with his book, A New Kind of Science.
*  And he showed that there are types of one-dimensional cellular automata.
*  I'm not going to go into details.
*  There are super simple rules.
*  You can do it on math paper.
*  It's like, you know, they're deterministic.
*  They always produce the same thing.
*  They're boring in many ways.
*  But he would actually show that with a super simple rule set that I can write down in one
*  line, you know, if this, then this, if this, then this, if this, then this, done.
*  And it's just black and white squares.
*  If you keep on applying the same rule again and again and again, you'll grow a pattern
*  that never repeats and that will literally grow with infinite time to infinite complexity.
*  And for one of those rules, there is actually a mathematical proof by a co-worker of Stephen
*  Wolfram from the 90s already that shows that it is undecidable, which is math speak for
*  unpredictable.
*  So, this is actually what is funny, you know, not funny, but this is what is called the
*  universal Turing machine.
*  If it can contain in its pattern, every single computation that you could possibly do math.
*  And this proof shows that it shows that a very, very simple rule set can produce infinite
*  complexity.
*  It's the, it's the smallest known, the simplest known universal Turing machine in science
*  today.
*  This is rule 110, right?
*  This is rule 110, the cellular automaton.
*  Which by the way, I think would be a pretty good band name.
*  I guess so.
*  Yeah, 110 is a number, you know, that's the emergency number in Germany also.
*  Oh, sorry.
*  That would be a good German band name.
*  All right.
*  So, and it is, you know, it produces infinite complexity and we know that you can't predict
*  what comes out of it.
*  So, what that means, you know, this was, I think I'm making it too complicated here.
*  It's very simple.
*  You can literally do this on paper and everybody, you know, in grade one, you could already
*  do this, like draw a line after line after line and you will find that the pattern never
*  repeats and it's beautiful.
*  And you may ask, well, could I have predicted, is there any kind of math that would allow
*  me from just knowing the code, what the beautiful pattern in the end would look like?
*  And now you see the analogy, right?
*  This is what biologists and we all would like to know.
*  Is there any math that would allow us from an apple seed or a human sperm and an egg
*  to predict without any previous knowledge of outcomes, what comes out of it?
*  What brain wiring you would have?
*  And so for this super simple mathematical concept, for this rule 110, several automaton,
*  we know there cannot be any way, any analytical math to calculate what say row number 1000
*  looks like.
*  There's only one way to do it.
*  You need to let it grow.
*  You need to let an amount of information unfold that you then need if you wanted to
*  describe that endpoint bit by bit would be quite a lot.
*  But if you would only want to describe the information needed to grow it would be very
*  little.
*  But you can't predict from the little information what the endpoint would look like without
*  actually growing it.
*  So this is why I talk about unfolding information and this is why I call it algorithmic growth,
*  which is just a simple description of what we're seeing here.
*  It's algorithmic because you use a rule set again and again and you grow something and
*  there's no shortcut to that.
*  So in the example of the cellular automata, this is a very simple system.
*  And the idea in your book is that DNA doesn't encode the endpoint, but it encodes the algorithm
*  to grow things.
*  And DNA and the developmental process are way more complex than cellular automata.
*  And one of the daunting things is that, let's say, we could go a lot of different directions
*  here, but one of the daunting things is, let's say, your DNA encodes a protein.
*  That protein has a, what we search for is the function of that protein.
*  But through the time and energy in the algorithmic growth process, the quote unquote function
*  of that protein varies depending on different contexts and different stages of development.
*  And of course, then you have all of these things interacting.
*  So somehow the algorithm is encoded in the DNA and development takes care of the rest.
*  Yeah. Isn't it beautiful?
*  It's a problem.
*  It's just so supremely non-intuitive, right?
*  We know it happens.
*  I mean, there's no magic.
*  We know that you have a seed, you have an egg and sperm, and we know that given enough
*  time and nurture, something beautiful will develop.
*  And developmental biologists have just been studying how that happens, right?
*  Instances of this, snapshots of this.
*  But in principle, one cannot look at the DNA code and infer the algorithm, right?
*  Yeah. So we actually don't know that, right?
*  So the reason why I like this simple rule 110, and you're right, it's of course much
*  simpler.
*  It was ridiculously much simpler to the extent that it really is not a good model for brain
*  development at all.
*  It's just an example that shows that a tiny amount of information, even deterministically,
*  and the same rule applied again and again.
*  I mean, the simplest possible thing, if you put in enough time and energy, can produce
*  something of literally infinite complexity that contains everything, any possible computation.
*  So my argument is kind of, if that simple thing already can produce infinite complexity,
*  then we should definitely at least not be surprised that something that's so much more
*  complicated like a genome with a so much more complicated and prolonged and protracted developmental
*  process like what happens for nine months in the womb and then for many years thereafter
*  can lead to quite remarkable, what we like to call, complexity in brain wiring.
*  So what's so supremely non-intuitive about this is where does the information come from?
*  If the stuff in the genome is so little and what I need, the information I need to describe
*  the network connectivity is so much, where does it come from?
*  This is really the core of understanding the algorithmic growth process and the time and
*  energy it takes.
*  So there's a lot of beautiful discussions we could have now and the physicists who are
*  listening to this will know of course a lot about this, right?
*  I mean, the fact that you can describe entropy in many different ways and find it.
*  You can describe the information content of heat exchange between my room and the outside
*  and so forth.
*  The time and energy you put in puts in information.
*  So, this is not easy to explain but this is of course will be no happens, right?
*  So it's not like I'm saying something outrageous.
*  We know that there's a seed, there's an apple tree.
*  All you need in the meantime is time, energy, water and sunshine.
*  So just information theoretically what that means for brain wiring and how much information
*  there is in a actual wetware biological neural network I think should not be underappreciated.
*  The amount of information that has grown into that thing while you were nine months in the
*  womb and while you were growing up as a toddler and later teenager with all the characteristics
*  that you have at these developmental stages that we immediately recognize.
*  Nobody mistakes a teenager for a toddler behaviorally.
*  It should not be underappreciated and neither should be learning but this is basically the
*  trying to find the sources of information and then coming back to your original question
*  of or statement about pragmatic approaches in AI that of course must try to shortcut
*  this.
*  If you want to just make a deep learning neural network that recognizes, that helps your business
*  grow, you want it to work.
*  And so you're not going to go through all these processes and you don't need to.
*  But then the question is can that thing ever be what our brains are?
*  That's where I think there's no shortcut.
*  So you mentioned learning there and connectivity.
*  So I'll ask about learning first.
*  You consider, so the modern AI begins with learning essentially.
*  Like you said, there's some dealings with architecture and how many units to use, etc.
*  But then the almost sole focus in deep learning is the learning process.
*  But do I have this right that you see learning as a continuum of the algorithmic growth process
*  or do you see it as, is it separable?
*  It's not like, so what I'm guessing is that you see our continued learning throughout
*  life and as we develop, these are not separable processes from the algorithmic growth process.
*  It's all one big process.
*  That's a question, sorry.
*  Yeah, it's a wonderful question and it's a big distinction between what we know about
*  biological brains and artificial neural networks.
*  Artificial neural networks, however close you want to make the design to the brain,
*  they still have an on switch.
*  And then there is this break to talk about and then learning starts.
*  So there's a design period and then there's a learning period.
*  Biological brains do not really have that.
*  There is of course a period when you do not yet have learning.
*  That's when the neurons are in a state where they're not yet excitable cells.
*  They're not yet connected.
*  Early in embryonic development, you have like all kinds of other developmental processes
*  that have to even start making that network.
*  So you could say there is a break in the sense that there can't be learning yet while the
*  connectivity develops.
*  However, the moment the neurons start making connections, things start happening.
*  Part of the developmental process of every neuron is that it becomes an excitable cell.
*  They will start to spontaneously excite each other.
*  We now know that a large part of very early brain development are activity waves that
*  sweep through parts of a brain, both in an insect as well as in a human brain.
*  And these activity waves are the brain learning from itself already prior to even input.
*  So part of the purely genetic program, no learning added, no environmental information
*  added, part of the purely genetic program is already that a neural network starts talking
*  to itself and that's part of what changes its connectivity even before you're born
*  and even before there's any input.
*  The moment there is input, you're still inside the genetic program in the sense that the
*  way evolution selected for the genome that encodes the developmental program is that
*  there is a time when for development to conclude properly, certain input is absolutely needed.
*  I mean, there are horrific experiments I don't even want to tell you about to deprive a human
*  of a certain input afterwards.
*  And then certain things will never develop.
*  And there are critical periods, as they're called in biology, that if then the input
*  doesn't happen as part of the algorithmic genetically encoded growth process at that
*  right time, if you're not talked to, if you don't get visual input, or if you don't get
*  auditory or factory input, certain things can never even be made recovered.
*  And they become part of the growth process.
*  So the genetically encoded growth process continuously partakes and accompanies the
*  learning process the moment the network is a connected entity.
*  This includes activity before there's any environmental input, before learning from
*  any environmental outside information, before any nurture, if you will.
*  But it also includes that nurture has to be right then and right there as environmental
*  input as part of that period of the growth process.
*  And that continues our entire life in one way or the other.
*  It seems like such a delicate process that there needs to be certain things happening
*  at certain times within or else the algorithm doesn't function properly.
*  And yet we also seem to be quite robust organisms.
*  How do we reconcile those two things?
*  Because at first pass, doesn't it seem like, well, anything goes wrong at the wrong time,
*  in the wrong place, in the wrong environment, it could go haywire.
*  And yet we are surviving thriving organisms.
*  Yeah, it can actually.
*  I mean, you know, the of course, only see the winners walking the earth.
*  Right. I mean, all those experiments that evolution continuously makes that don't make
*  it just simply not there.
*  The question of robustness is a beautiful question that that neuro biologists both
*  as well as functional neuroscientists are struggling with.
*  And there are certain features that we have learned that are key to the robustness of
*  this whole program.
*  And I think the most important feature is the idea of autonomous agents, the idea that
*  an individual neuron actually knows nothing about the brain.
*  An individual neuron has its own algorithmic growth process.
*  It kind of, you know, it grows an axon like the big cable that needs to connect somewhere
*  else.
*  And, you know, just when it needs a partner to make synaptic connections with that, the
*  partner happens to be exactly there.
*  Right.
*  This is how the beautiful ballet of development unfolds.
*  But if the partner were not there, the neuron would still run its program.
*  And you know, for example, in this particular example, by and large, a neuron would just
*  make actually a synaptic contact with somebody else.
*  So it would not be quite right, but it would probably be much better than nothing.
*  And you can early in embryonic development, you can do crazy experiments.
*  I mean, so we work with flies in the lab, right?
*  I mean, so flies, when you develop part of the visual system, you can early in development,
*  easy go in and just kill half the cells.
*  And then when you look at the final outcome, everything is perfectly fine again.
*  So it just turns out that all the remaining cells during the growth process, they kind
*  of just did what they normally do.
*  But because there were no others that they would normally have had to compete with, which
*  would have led to some of them dying and some of them surviving, they kind of all survive
*  and they just fill the space.
*  So this is very robust.
*  And it's robust because it is not a blueprint directed maker with some factory and robots
*  that assembles it.
*  But it is a self assembly process of lots of individual autonomous entities.
*  And each individual neuron, like every other cell in your body, has the capacity to encounter
*  different environments, to encounter surprises when things go wrong during development and
*  when things happen during normal function.
*  That is of course unpredictable in an unpredictable environment and deal with it.
*  And that's one of the key ideas that we know is important for robustness.
*  And it's a very interesting concept because self-organization is therefore absolute key
*  to the wetware neural network function of any brain as it is for its development.
*  But self-organization is kind of, you know, meh, kind of implicit in artificial neural
*  network research, but slightly avoided.
*  So you could argue that gradient descent and parts of how back propagation work and how
*  neurons communicate has features of self-organization and I think it does.
*  But it's not a major topic in the design and training of neural networks when you look
*  into the literature of the field.
*  I want to back up here.
*  A lot of the book is dedicated, you mentioned the axon growth process, a lot of the book
*  is dedicated to describing both the history and the current science and the controversies
*  of how axons reach out and make the quote unquote correct connections, although you
*  were just mentioning that there isn't necessarily a correct connection from the start because
*  these are autonomous agents essentially and they self-organize and end up and do okay.
*  Before we talk about that process, thinking about the code of the DNA.
*  So the book is all about the eventual connectivity of the brain, right, brain wiring.
*  But a lot of what is in the DNA must also be dedicated to metabolism, right, because
*  we have to survive in a far from thermodynamic equilibrium state.
*  Do you see is metabolism and the metabolic products, right, that are coexisting with
*  the connectivity products in that algorithm, is the metabolic code separable from the connectivity
*  code within the algorithm?
*  I'm asking you to speculate unless you have a definitive answer.
*  I dare say I have a definite answer.
*  I'd say it's not separable.
*  And it's not separable.
*  This is a big discussion also in the larger now a life community rather than AI community
*  about embodiment, right?
*  The idea of, you know, is the simulation enough and how much do you need to simulate?
*  Do I need to simulate the metabolic things happening at individual synapses or is it
*  enough to just have a value for a synaptic weight?
*  This kind of thing.
*  And if you talk about cells acting as autonomous agents, they start to have, of course, their
*  own drives and they need their own, you know, at least minimally simulated metabolism.
*  But yeah, you know, this is at the heart of self-organizing versus a designed entity.
*  But you're asking about genes.
*  And so we look at genes, of course, people have been trying to find like individual genes
*  that just tell us something about brainwiring, right?
*  Is there like a gene for this one synaptic connection?
*  That's of course nonsense because, you know, we have, depending on how you want to count,
*  let's just say 20,000 genes and humans and like some, you know, ridiculous number of
*  synapses in the brain.
*  So how does this work?
*  And so then people were trying to find, is there like, you know, maybe it's like surface
*  proteins that sit on one cell or another and then they recognize each other and these proteins
*  exist.
*  But then you find that the same surface proteins, you know, they're also functioning in the
*  liver or, you know, somewhere where like, you know, blood vessels grow and need to branch
*  and do things.
*  And you try to find, you know, okay, this metabolic stuff, is this just, you know, is
*  metabolism only like kidney, heart and liver or how about the brain?
*  And then you find like, yeah, of course, you know, most metabolic enzymes are actually
*  expressed as particularly high levels in the brain.
*  It's the organ that requires and uses most energy.
*  And so basically the bottom line is that, yeah, you know, there are a few heart-specific
*  genes and there are a few brain-specific genes.
*  But by and large, this whole question is not very good.
*  The idea of hoping to find, you know, a gene that specifically tells me how the brain wires.
*  There are very few genes in the human genome that will not be turned on and off, that will
*  not be read out in one way or another in one cell or the other during brain development.
*  And it's all part of the algorithmic growth process.
*  Evolution didn't care about our intuition of say two molecules that recognize each other
*  and could be a key and lock for synaptic connectivity.
*  Even though, you know, we would love to write, we love to write papers like this as developmental
*  neuroscientists.
*  Look, I found another cell surface protein that's exactly on that cell and the lock to
*  that is another protein on the other cell and, you know, both are genes in the genome
*  and this is how this one synaptic connectivity is wired.
*  But evolution, I dare say, really tried out any kind of mutation in regulatory sequences
*  and coding sequences of any kind of gene.
*  And as the growth process unfolds, you will find that the mutation in some ubiquitous,
*  let's, you know, biology speak for expressed everywhere, expressed metabolic enzyme, the
*  mutation in that thing that let's say changes just, you know, it increases 5% of the function.
*  That'll turn out to be completely irrelevant for your heart and your kidney where that
*  enzyme is set up.
*  But during brain development, there may be just this one neuron that if you increase
*  this particular metabolic enzyme 5%, at the exact time when it is making a synaptic connection,
*  it changes the speed, say, because of the increased metabolic rate of the time window.
*  So it shortens, say, the time window of when it can make a certain connection and it will
*  lead to less connection of one type and more connections of another.
*  And that was a mild change to a metabolic enzyme that's everywhere in your body and
*  the only change it may cause in the outcome, completely unpredictable, but, you know, evolution
*  tries these things out, was a slightly different wired brain.
*  So this is why you need all of it.
*  You need, you know, you can't just take a synaptic weight as a number, but the information
*  encoded ultimately in all the synaptic connections and the way to get there required evolutionary
*  process, selection of something that worked, that was not predictable, like rule 110, but
*  that, you know, if you had enough millions of years to try out evolution on earth and
*  evolution of brains, you can figure out adaptations and changes based on mutations in many different
*  genes and there need be nothing intuitive about it for what scientists would like to
*  see.
*  So modern deep learning, right?
*  It begins with a network of connected artificial units and, you know, like we've been talking
*  about, through a long process, the synaptic weights become, get adjusted through learning,
*  but it starts as a neural network and a large part of what you describe in the book is the
*  developmental process that leads to a network, which is a bunch of neurons connected.
*  And you give multiple examples throughout the book of different connection patterns
*  that can happen depending, you know, on the sequence of the development that happens.
*  But, and yet, the focus is still on sort of the end connectivity of the brain, that you
*  end up with a network of neurons with connections between them.
*  Are neurons the end all though?
*  Do we need to consider things beyond neurons like astrocytes and glia?
*  Is that part of the whole algorithmic growth process that may eventually be important for
*  building better AI and understanding how this all works or do we really just need to focus
*  on the network of neurons?
*  So, again, we need to come back to what we want.
*  What is it that we're trying to achieve?
*  To make an algorithm to predict what to buy, I don't see why you would need astrocytes.
*  If you want to have any kind of resemblance to what you may want to call a human AI,
*  I'm hesitating because I'm almost, I'm trying to use the word general artificial, you know,
*  there are so many terms, they're all undefined, right?
*  I mean, artificial general intelligence, nobody knows what the hell that's supposed to be.
*  And that has a lot to do with there being no definition for intelligence.
*  And, you know, the idea then that you want to have a human intelligence is very different
*  to me from human level.
*  I don't even know what level is supposed to mean, right?
*  I can measure level of playing chess, but I cannot measure level on being, you know,
*  Paul.
*  You know, how Paulish is my intelligence.
*  I think many different people will be more similar or less similar to your individual
*  type of intelligence.
*  And that requires the entire brain.
*  One of the seemingly important features of brains is the feedback loops that occur within
*  the, if we can just stick with neural networks.
*  The brain is a highly, highly, highly recurrent neural network.
*  And AI is taking this on, deep learning is taking this on and, you know, people are using
*  recurrence.
*  My question is, thinking back to the algorithmic growth process and a self-organizing system,
*  and actually in the book you talk a lot about levels.
*  So going to the DNA level then, it is interesting, and I'm going to ask you if there's a deeper
*  principle involved here.
*  It's interesting that an enormous amount of DNA is devoted to feedback in the form of
*  regulatory proteins that feedback onto the DNA and regulate what's being encoded by the
*  DNA, transcribed, I should say, harking back to my own molecular biology days, trying to
*  remember the words.
*  And then through the developmental process, it seems to be that these feedback mechanisms
*  are also, you know, like a majority of the processes.
*  So is this a deeper principle that, within algorithmic growth, to have a robust system,
*  that feedback is the main thing?
*  I think so.
*  It is a very important thing.
*  I mean, this has been recognized.
*  You know, we can go back to the old cybernetics days, right?
*  This is Norbert Wiener and others who first formulated and quantitatively worked on ideas
*  of feedback and how they determine self-organizing systems.
*  Very specifically to the example you give, going back to everybody's biology 101, right?
*  The genome doesn't change by and large from, you know, once the sperm has met the egg,
*  you're kind of done.
*  I mean, that's your genome and every single cell in your body has it.
*  And it's the same genome in every single one of your cells.
*  And of course, you know, what makes the cell in your eye different from one in your heart
*  is that different parts of the genome have been read out during a developmental process.
*  And that process, as we already discussed a little bit earlier, never stops.
*  We know in the brain when it comes to learning that to form long-term memory requires the
*  feedback going back all the way to the genome, new transcription of the mediator of what
*  will become proteins, the famous RNA, and then making new proteins.
*  And then those proteins get incorporated into whatever molecular function you need to change
*  the physiology of the cell.
*  Many of the proteins that get this way read out from the genome are proteins that themselves
*  have this funky property of binding back to the genome, which then leads to yet another
*  type of protein being expressed.
*  And you know, maybe it's not one, maybe it's a different thousand again.
*  And then one of those thousand is again one that binds back to the DNA and changes it.
*  So both the internal program that keeps on running changes the cell continuously in a
*  feedback process.
*  And that's part and parcel of any developmental growth process.
*  But also the environmental input once you have the neural network will feed back to
*  that genome.
*  And the genome is always just there.
*  It's like a book that's always there and you always just need to decide what to read in
*  that book.
*  And to access that book is just enormously complicated.
*  You can't just open page 255.
*  You literally need a very strange combination of say 30 different proteins that are super
*  unlikely to ever exist at the same time in the cell.
*  But if they do, then in particular gene combination, you know, these 231 genes or something will
*  be transcribed and you will have a new state of the cell.
*  And this is, of course, what happens all the time.
*  And none of this, I mean, very few cells, there are few cells that actually are very
*  silent in our bodies, but most cells in our bodies never ever stop that feedback process.
*  If you have an injury in your skin, it goes all the way back to changing what will be
*  transcribed cells in your heart and of course cells in your brain.
*  So the idea of a feedback to the genetic information and what will unfold as a next step, this
*  is basically what all of biology and all of biomedical research is about.
*  We're continuously studying when and how, what kind of genes get expressed.
*  And this is such an enormous field, you know, even with this only laughable one gigabyte
*  of base pairs in the genome.
*  That's not much information if you want to write it down.
*  Easy one gigabyte.
*  But the information that can just in one or two iterations of any of the 20,000 genes
*  that are being expressed change what will be expressed next is just a combinatorial
*  explosion that gets out of hand like almost immediately and kind of ensures that researchers
*  will never be out of having something new to study.
*  I mean, it makes sense that AI researchers would want to avoid all of that mess.
*  Yes.
*  Which is why you can't design it.
*  So the only way you can deal with that mess is you have to give up control over the design.
*  You have to program it literally by making random mutations and hope for the best.
*  And if they're not good, then what comes out of it will be just not as good in the outcome.
*  And evolution didn't know, but evolution will just select against it.
*  And if what comes out of it is better, then you know, you keep some of these new randomly
*  tried out mutations and you program something better because remember rule 110, you know,
*  if there's a proposal, but we'll just take it for what it's worth now as a hint that
*  it may just be just as unpredictable how the genome encodes what comes out of a given
*  genome without having prior outcome information.
*  There's no other way to program this.
*  And you know, if you do this, then it would be nice to at least keep it, you know, not
*  hyper multi-dimensional, right, to at least have only a few genes and a few interactions.
*  And you know, then it's still a lot of computational effort to simulate that to basically do this
*  experiment and for every single slightest random change to see what comes out of it,
*  to do this entire effort of, you know, nine months in the womb and then, you know, all
*  those crazy teenage years where you just don't know what you want.
*  And then finally sitting here in a podcast, that's not what you would like to do if you
*  have a pragmatic job to do in programming a neural network.
*  In the book, I guess, I guess you get a little philosophical about generality and specificity
*  talking about the growth and development process and how different proteins are used in different
*  contexts at different times in different environments.
*  And what we want to do as humans to understand what's happening is we want to have a very
*  general principle, right?
*  But then it's really difficult to say, well, you know what, I'll just read what you write
*  in the book.
*  This is a bit of a conundrum.
*  We can choose between fewer general mechanisms that explain more, instances less, or many
*  less general mechanisms that explain fewer instances better.
*  Where we draw the line for generality is anybody's guess.
*  And this is a recurring theme of, you know, you also talk about levels and what's the
*  right level to explain a given system and so on.
*  I don't know, could you just comment on that balance between generality and specificity
*  and that conundrum?
*  So in our field of developmental neurobiology, you know, it's funny how papers are written,
*  right?
*  I mean, of course, everybody is studying like a super specific system.
*  I mean, you know, we study flies and some other people study mouse in a specific neuron
*  at a specific developmental stage where it makes a certain choice and you want to understand
*  how molecularly it does that.
*  So of course, every single one of these scientific publications about a process like this then
*  has to say, you know, we are looking at this super specific thing.
*  But then the hope is, of course, always, yeah, you know, we're looking at the super specific
*  thing, but really, it's very general, right?
*  I think we found something in our specific instance of the problem that tells us something
*  how this generally works.
*  And so, you know, everybody does that.
*  Everybody then writes like, you know, this gives rise to a potentially general principle
*  of brainwiring.
*  And the classic ones are, of course, the attractive or repulsive molecular interactions.
*  And they're clearly part of how neurons interact and how brains are wired.
*  You know, these are words that scientists use.
*  But of course, generality is, as you know, the sentence you just read, I hope, kind of,
*  suggests they're not black and white.
*  I mean, what does it mean?
*  Like, you know, this is a super general principle.
*  I mean, I can give you the super general principle that everything that happens is read from
*  DNA into an RNA and then into a protein and then the proteins interact and zoom, you got
*  a brain.
*  That's a really general principle.
*  And everybody will agree.
*  I mean, you know, this is what happens.
*  The feedback stuff that we've been talking about, this general principle, this general
*  principle that you have continuous feedback of the proteins, which are the products of
*  the genome, onto the genome itself to change what next will be read out from the genome,
*  general principle.
*  But of course, if I phrase it as general as that, it tells me very little about how this
*  one neuron made a synoptic contact with another neuron.
*  So there I need to become a bit more specific.
*  And then the question is, you know, how specific do I have to be about every single molecule
*  that is there right then and, you know, at the right place and at the right time to put
*  this thing together to understand this instance of the problem.
*  And then still I want to say, yeah, but this is now a general principle.
*  So it's just, you know, I'm not sure it's very philosophical.
*  It's just an observation that we have when we're trying to understand any system.
*  Right.
*  And you can always make a very general statement that's almost certainly true, but really
*  then not very helpful anymore.
*  Or you can make a very, very specific statement that's really helpful to understand that specific
*  thing.
*  But then of course, it's not going to apply anymore to every other, you know, things that
*  every neuron has, every development of a synoptic connection has in common.
*  And then there are things that must be different.
*  In the end, the idea that you need all of it, that you do need every single one of those
*  molecules that have to interact, that unfold specifically at some point differently at
*  every single synapse in the brain, such that every single one is in some way different
*  from any other, is irreducible if you want to have that thing in the end, the brain.
*  And so the selling point of, yeah, but we're looking only at generalities, is helpful to
*  a certain extent.
*  But at some point, we just have to appreciate that it's really an arbitrary choice how deep
*  we look at any given synapse and at any given neuron.
*  Well, toward the end of the book, you argue that, so you talk about whole brain emulation,
*  you also talk about the brain AI interface that is oncoming with current companies trying to do
*  this, like Neuralink, etc.
*  But you argue that to emulate a whole brain, you actually need to do it from start from the
*  molecular level.
*  You need all of those details, right?
*  How strongly do you believe this?
*  And have you received a ton of backlash on this?
*  How strongly do I believe?
*  I mean, the data just shows.
*  I mean, this is, I try to avoid to believe, I try to believe anything really.
*  But I'm very happy to be proven wrong.
*  The biological systems that we study are just that, like that, right?
*  If you take out any component at any point, you have surprising implications.
*  And as we discussed earlier, this is exactly how evolution programs the brain.
*  So if you take any component out, if you simplify it in any way, you can still get something
*  that's amazing, but it's not going to be that thing anymore.
*  So if you want human intelligence, the argument is you need every single one of those molecules.
*  You can't take any of that away.
*  That doesn't mean that you can't produce something more intelligent than a human in many other
*  ways.
*  That's just not going to be a human intelligence.
*  So in terms of backlash, the idea is, of course, not very well received by the more pragmatic
*  camp of deep neural network developers.
*  But they don't mind really all that much because they know that what they're doing is amazing.
*  They know that what they're doing is successful in what they're trying to do.
*  And it becomes a little bit philosophical again, then, to talk about where the whole
*  journey is going.
*  So I'm not actually clashing with any of these amazing people who are developing neural networks.
*  I think we're all equally impressed with those.
*  Where I am genuinely clashing is with the prediction of where, therefore, inevitably,
*  current technology of neural networks has to go.
*  The notion that clearly the next thing that happens is an even more intelligent thing.
*  And the more intelligent thing will have this enigmatic property of being able to produce
*  a yet more intelligent entity.
*  And therefore, then we have super intelligence and runaway intelligence and we have the famous
*  omega point and we have singularity and then they're all going to take over.
*  So, yeah, you know, I disagree.
*  We are we're not just far from this.
*  We're just not even anywhere near the right path to anything like that.
*  And the argument has a lot to do with what we understand about what it means to make
*  an intelligent system.
*  The key argument I would make against this whole singularity debate, if this is where
*  our journey is going right now, which I'm not an expert at all, right.
*  But I mean, I'm coming from another side.
*  And so I'm just I'm just raising a voice, a critical voice here.
*  And is that there's no example anywhere in the known universe of an intelligent system
*  producing the system that is more intelligent than it.
*  Our entire discussion that we just had circled around the idea that evolution is the only
*  thing that can program a thing like our brain precisely because of the unpredictability
*  of rule 110 and what the outcome is.
*  And therefore, you need the entire unfolding thing.
*  So the notion that just because something is even more intelligent than us, it will
*  automatically inevitably have that enigmatic ability to produce a yet more intelligent
*  thing. I don't see why at all.
*  I mean, why are we not able to make something more intelligent than us then?
*  And we're not.
*  There is no example of that in history.
*  That's the first major criticism and the second major criticism.
*  If you read a book like Superintelligence.
*  I don't know. I don't know that I recommend reading that book.
*  It was a rough one.
*  Yeah, interesting.
*  I agree with you.
*  I mean, but you know, it has some it tickles.
*  The the senses and the excitement about the future, as it has always done right.
*  I mean, there is an entirely absolutely unproductive branches of so-called science that
*  have been dealing with this ever since Verner Vinge and this whole, you know, Superintelligence
*  thing came up many decades ago.
*  They haven't produced anything.
*  They've just been talking a lot and making a lot of money.
*  But, you know, one of the things that, for example, Bostrom desperately needs and just
*  glances over in like three sentences in order to copy your brain is just the brain scanner.
*  Right. You just scan your brain and you get the information out and then you can take
*  that information and make another one.
*  Well, we have just been discussing you and me the entire time that we don't even know
*  what information we need to what molecular level in order to have a brain that actually
*  functions. So what is it that you are supposedly scanning in theory, at least, which is
*  practically absolute pipe dream.
*  But in theory, at least, you could do like a molecular scanner that takes every single
*  molecule and makes a copy of that.
*  And then you have that other brain.
*  But that's, of course, not what they mean.
*  They all mean that, yeah, clearly it will be it's got to be enough to have something
*  like, say, you know, states of synapses and some digital representation thereof.
*  That's a pipe dream.
*  So I'm taking it. You're not a fan of the idea that one could slowly, let's say let's
*  let's go with neurons, right, replace our neurons with mechanical neurons very slowly.
*  And then we would have a functioning brain that is half or, you know, what, however many
*  however much neurons make up our brain.
*  Right. That that wouldn't be functioning well.
*  We're not anywhere near the sophisticated level that it would take to create an artificial
*  neuron that would that would be able to function holistically.
*  Well, I don't want to be as critical as that.
*  Quite. I'm actually very optimistic and very impressed with current machine brain
*  interfaces. As you know, we can now do extracellular, like, you know, little electrodes
*  and thousands of them into, say, somatosensory cortex.
*  And that'll allow somebody who has lost the ability to move an arm or a leg to to move
*  a prosthetic device.
*  And this kind of technology is super.
*  I mean, it's fantastic and it's going to improve and it's going to get better.
*  And it makes perfect sense for companies like, you know, there's the BrainGate initiative,
*  there's Neuralink that, of course, you know, because Elon Musk made more headlines, but
*  it's not really all that new even.
*  No, it's not. You didn't roll your eyes there.
*  I was expecting an eye roll.
*  I often. No, no, no, no, no.
*  I mean, I'm actually trying to be positive here.
*  Right. I really I love these approaches.
*  I think it's awesome that they're doing this.
*  And of course, what it's what it's designed for, right, is if we just leave the the the
*  science fiction out is at the moment, tetraplegia, like patients who really can't move
*  their arms or legs and, you know, the locked in syndrome patients and so forth.
*  If you can have any bionic device that communicates with the brain that helps these
*  patients bring it on.
*  Yeah. And if you're blind and you can put a little camera in front of your eye and
*  connected to the visual cortex and you can, you know, you're not going to see as you and I are,
*  but you see at least something again.
*  It's fantastic. And there is no reason to not assume that this is going to become, you
*  know, exponentially better in the next years.
*  I'm sure it will. It's going to be wonderful.
*  And it's going to come with its own challenges.
*  And there's going to be some critiques.
*  And, you know, will other borgs now finally coming?
*  And there's going to be some concerns and there's going to be some failures and there's
*  going to be some successes and, you know, how any technological advance goes.
*  And it's all good. It's all it's all part of it.
*  So this is going to happen and it's going to be great.
*  But this is not what we had been discussing.
*  And this is not what Bostrom talks about when he has a brain scanner to take and make a
*  copy of your brain. We're talking about, you know, this is can you get do you even know
*  what kind of information you would want to get out of a brain to make that brain or to
*  make any brain?
*  You know, what makes Paul Paul?
*  You know, can you just copy that?
*  And then another person can be Paul.
*  This is a whole other level.
*  Amount of information we're talking about here is something that we really just don't
*  even understand.
*  And if you just want to bring it on a very technical basis, right?
*  I mean, we're talking about a few thousand electrodes and all these things do it's super
*  impressive.
*  But, you know, these are extra cellular electrodes somewhere in the brain region where no one
*  knows what the hell these neurons are doing individually, where individual neurons can
*  die and everything is fine.
*  And you just get field potentials as it's called from like these areas of the brain.
*  This is not the same thing as neurons that are intricately wired via all the molecular
*  glory of synaptic connectivity inside an actual brain.
*  They're valiant approaches and efforts and they're there to be applauded and they're
*  going to be big successes, but they're not a path to making a human brain.
*  So, Robin, there are a ton of other topics that we could go into from the book.
*  I'm aware of the time, though.
*  One of the cases that you make in the book is a case for the utility of cognitive bias.
*  Right.
*  So I'm not going to ask you about that.
*  But what I'm going to ask you about thinking about cognitive bias is during the process
*  of writing the book and thinking about these things.
*  And, you know, in the beginning, we were talking about what led you down this path.
*  Has your view of intelligence changed through this process or is your cognitive bias stuck
*  where you had the same view of what intelligence is and what it means, et cetera, from since
*  the before you were writing the book?
*  You know, the embarrassingly safest answer is that I can't possibly know because I'm
*  sure I'm somewhere stuck.
*  Right.
*  And I'm, you know, caught in my own brain and my own biases and my own growth history.
*  Right.
*  So I come to the topic of biases through the growth history, right, which is, which is
*  serendipitous and idiosyncratically individual and makes you, you and me, me.
*  And of course, new information coming into a brain is not compared on an even footing
*  with the information that is already there.
*  I mean, we know this and that has a lot to do with what, you know, how you have used
*  your brain in the past.
*  And let's just not go into all the examples that leap to mind right now about, about,
*  you know, data unbiased beliefs that people have right now.
*  This is how the brain works.
*  So, you know, this is a dangerous area to be in.
*  You know, they actually, I mean, this is not my field, but they're, they're, they're, they're
*  amazing experiments of psychology out there that actually show that people who are trying
*  to not think about these things and people who are not trying to worry too much about
*  themselves are actually more successful.
*  You know, to be ignorant to your own, you know, you can look up these things like the
*  embarrassing questionnaires.
*  So it's a very difficult and dangerous area to go in, right.
*  You can go and spiral down in self doubt very easily.
*  If you question data based every single part of your growth history based on a brain that
*  happens to function based on that growth history.
*  So has my view of intelligence or any other aspect of the book changed?
*  Yeah, well, not so the way that I asked the question, it sounds like I'm asking what was
*  your view before and what is your view now?
*  That's not actually what I'm asking, because, you know, like you've already said, we don't
*  really know what intelligence is.
*  What I'm more asking is, do you feel like your approach to understanding intelligence
*  has changed throughout the process?
*  So you can answer.
*  I thought this before and now I think this, but that might be an impossible question, of
*  course.
*  I think I think I've become more humble.
*  I mean, if I if I dig into my idiosyncratic past, I remember being a young 20 something
*  year old scientist who thought he knows everything.
*  But that's what got you to where you are.
*  I've never been more insecure than ever in my life than I am now.
*  You know, maybe that's a good thing.
*  I'm yeah, it got me to where I am.
*  Exactly.
*  I'm humbled.
*  The process of writing that book and making the connections that I try to make is a
*  humbling experience.
*  Because you have these moments when you realize parallels in history, you see that all
*  these things have happened before and you find these references in people who have
*  thought these thoughts before.
*  There's so much out there.
*  There's so much beauty and so much knowledge in the literature.
*  People who have been out.
*  If you just go into what people thought, I could have gotten completely lost just in
*  the cybernetics years, between the 40s to 60s and all the thoughts that people had
*  back then had like Ross Ashby and so many others.
*  And it's humbling, right?
*  Because then here you are and you're writing this book based on, you know, there
*  got to be something that we need to talk about because we should learn from each other
*  in the AI and neuroscience communities based on the idea that, you know, we have a
*  genome and you don't.
*  And then you dig into this and it's of course a bottomless pit.
*  And so many thoughts have been thought have been thought before.
*  And I'm with every minute that I'm spending on a project like this, changing my brain
*  in a certain direction and not another.
*  And time is so scarce.
*  Yeah, I'm running out of time every day.
*  It's like as we are right now in our conversation.
*  You know, if I want to investigate something, I need to write this chapter, you know, the
*  temptation to just get lost and dive into this infinite depth of almost infinite depth
*  of knowledge that is out there is very humbling.
*  And so then you, you know, you kind of I find myself then disciplining myself and saying,
*  OK, I have one week for this thing and I have one week to interview people and to learn
*  about this and this is how far I go.
*  And and of course, if you do it well, you must be after this one week at a state where
*  you realize, oh my God, there's so much more than I initially even thought that could be
*  known that it must necessarily be humbling.
*  So one of the things that you did allow yourself to dive into in the book is Roger Sperry and
*  his work and also Mike Gaze.
*  And you talk about their differing ideas in the book and go into some depth about it.
*  Maybe the last thing that I'll ask you, you talk about how there are differences in
*  scientists, right?
*  Some are more vocal and some are quieter.
*  Mike Gaze was a a quieter scientist who didn't self promote as much and not necessarily that
*  Roger Sperry self promoted, but he was more opinionated and willing to vocalize those
*  opinions.
*  Both great scientists, right?
*  I think it's fair to say, yeah.
*  Yeah.
*  The question is, how self promotional as a scientist should one be?
*  So now, you know, I'm asking someone who's written a book and needs to promote it as
*  well, right?
*  Or, you know, hopefully we'll we'll sell some copies, right?
*  But is it better to be wrong and popular or well known or is it better to be right but
*  unknown?
*  Some career advice for those.
*  Oh, my God, this is so difficult.
*  I can tell you from the bottom of my heart that I did not write this book with the intent
*  to, you know, make it a New York Times bestseller.
*  I would like it to become and I'm actually delighted to see that it is being picked up
*  more than I initially could have even hoped.
*  So it's been doing very well and I'm very, very happy about that.
*  But, you know, writing the book is one way of being vocal.
*  But the example of scientists you give right now is also about just how you present data.
*  There is no way in science to present data without interpretation.
*  The way you present it, the claims you make, bringing us back to the discussion we had
*  before about generality, but also the manner in which you do this, has an enormous influence
*  on how it is perceived.
*  And I'm afraid that there are many examples in the history of science where a really good
*  idea and a person who actually got something right has not been corrected to this day.
*  We always say that science self-corrects in the end and I believe to the extent that I'm
*  capable of believing anything that that, you know, is likely true in the limit of infinite
*  time.
*  But it's scary how many processes, many ideas, that are not correct in the end, are not
*  correct.
*  It's scary how many processes, many ideas have not been corrected and people actually
*  got forgotten although they said the right thing for that reason.
*  So this is very tricky.
*  I can tell you that I basically did everything wrong.
*  I did write the book, so maybe that's, you know, in itself something right.
*  But because I always felt that science should be something that is promoted by the value
*  of the science itself, which happens through scientific publications and peer review and
*  then reviews about that work and discussions within the scientific community based on scientific
*  publications themselves, I until I think two days ago or so didn't even have a Twitter
*  account.
*  Oh, you're on Twitter now.
*  I'm not really.
*  So we made an account for my lab.
*  So we just published a beautiful paper, 21st of December.
*  And so I decided, you know, the Heesinger Lab has now a Twitter account so that we can
*  at least tell our colleagues we published this paper.
*  But this is literally, you know, I've sent one tweet in my entire life.
*  That's a really bad idea in this day and age.
*  If you want to write a book and promote it and if you want it to sell well, you better
*  have a good following.
*  You better have a Facebook presence.
*  You better have a LinkedIn account.
*  You better have an Instagram following.
*  And I literally have none of these things.
*  It's great.
*  Not even LinkedIn.
*  You've caved in now.
*  Well, so we see this is the question.
*  Yeah, you know how morally, you know, I don't want to be morally superior, right?
*  I mean, I don't want to.
*  It's just choices we make.
*  And so, yeah, there are ways how you can try to sell whatever you want to sell more.
*  And clearly, I have not tried.
*  I mean, you know, there's no advertisement.
*  There is no tweet.
*  There's no tweet.
*  There's no advertisement.
*  There is no Facebook.
*  There is no Instagram.
*  There is nothing about this book other than that, you know, here it is.
*  This is what I wanted to tell you.
*  I did this bit of work.
*  I put all my heart and a lot of work in it over three years researching the history and
*  the current state of how developmental neurobiology and artificial intelligence see the information
*  problem, the question of how does information get into a neural network?
*  How does a neural network grow smart?
*  And this is what I wanted to do.
*  And I wanted to contribute this and I'm proud of it.
*  And now, you know, live with it.
*  And if somebody wants to read it and it develops its own life, you contacted me and you're
*  asking me questions that be like, you know, deep knowledge even of many of the ideas in
*  this book.
*  And so that makes me super happy.
*  Maybe that's better than a short tweet, you know.
*  Well, Robin, you should be proud of the book.
*  I didn't mention the way it's laid out is a series of 10 seminars.
*  And before each seminar, you have these different characters like neuroscientists and a robotics
*  engineer and, you know, various personalities dialogue with each other.
*  So in Gödel Escher Bach, Hofstadter uses this kind of form, but it really doesn't
*  work.
*  Like it was with the tortoise in the hair, I believe.
*  Oh, really?
*  Not for me.
*  I thought it.
*  You liked it.
*  Interesting.
*  To me, it's just actually dragged on.
*  Honestly, I have to tell you, it's been 20 years ago.
*  It's been 20 years since I read it.
*  So maybe I should look at it again.
*  It's a bit different.
*  So what Hofstadter did in Gödel Escher Bach is that he does this really fancy, funky thing
*  they actually talk like in the like a canon of Bach or so, right?
*  So it's very symmetric and it kind of and, you know, it also just probably serves a little
*  like relaxation, right?
*  That, you know, between like heavily loaded chapters, it's nice to relax a bit.
*  In the self-assembling brain, the dialogues are different.
*  They have a different origin and a different idea.
*  The reason why they're in there, they were not in my original book proposal and they
*  were not in my original draft.
*  The reason why they're in there is because this is what my notes look like.
*  So when I got dissatisfied with my own field as we started this discussion, right?
*  And I felt like it can't be that we're just studying molecule by molecule, building a
*  parts list and we don't even know what the end point is.
*  I'm not sure what we're missing there, but I wanted to know what could be out there.
*  So I just started to go to other conferences.
*  I just went to an artificial life conference and just, you know, let's see what these
*  people are saying, right?
*  And it was eye-opening, it was beautiful and I met amazing colleagues that I'm working
*  together with right now and I had discussions with them.
*  And so then whenever and of course then when you already have the idea of the book in your
*  mind and you go to this conference and you just, you know, I chatted up people.
*  So I entirely went, I come to you and then I just, you know, start to have a discussion.
*  And of course I asked them certain questions and then, you know, some people just are amazing
*  and you just get into this.
*  Then I would always run back to my hotel room and just write down the conversation.
*  And you know, so as to not to lose the arguments, as to not to lose, you know, I asked him this
*  and then he said that and I asked her that and then she actually said, that's not even
*  a good question. You need to do this, this, this or that.
*  And so it was very clear that, you know, people are always talking based on their own growth
*  history in their own worlds, right?
*  I mean, in the beginning, these discussions are very tricky, right?
*  Because I'm asking one thing, but I'm getting a completely different answer and vocabulary
*  that I'm not necessarily understanding.
*  And then I did this in my own field and, you know, I could ask the same questions.
*  And so I basically started to have, so I had a lot of notes from discussions and all these
*  characters were there. There's the robotics engineer, there's the developmental geneticist,
*  there's the neuroscientist.
*  Was that more fun to write, easier to write, harder to write than the rest of the text?
*  So this is where I'm just getting it, right?
*  So initially I didn't write it, because I tried to get the essence from my notes and
*  I tried to write like a normal book.
*  And it was very difficult because what you lose is the way they talk coming from, you
*  know, a different place, right?
*  If I say something as a developmental neurologist and try to describe something and a deep learning
*  expert tries to talk about it, we talk differently.
*  And the way we talk is just loaded with our own history and our own way of talking.
*  The way we even then try to communicate becomes quite interesting and it takes time for us
*  to find each other.
*  And so this is what happened, right?
*  So I had these notes, I had this discussion, I tried to distill it.
*  But just to circumscribe basically where people are coming from is so much harder and cumbersome
*  and it didn't read well.
*  That in the end, I just felt like, you know, just let these people speak.
*  And so I just started to write the discussions between those people and it was much easier.
*  Because then of course, you know, the developmental geneticist can say these outrageous things
*  that I wouldn't even as an author dare to write in a book because I think this is like,
*  you know, hardcore is too much, you know, it's not that deterministic and so forth.
*  But as a character, I can have a developmental geneticist say all these crazy things because
*  that's what people are saying.
*  And then I can have a robotics engineer, of course, come in and say, you know what, we
*  don't need all your wet wear and that's all nonsense and we can do this all much better.
*  You know, I can, I don't need a bird with all this stuff.
*  I can make an airplane that flies much faster.
*  But these things, to say these things is best said if you have characters who are themselves
*  and have their own growth history, if you will.
*  And then of course, that became a beautiful challenge over 10 dialogues to have them find
*  each other, right?
*  So in the first dialogue between them, they are, you know, they're all talking cross purposes,
*  right?
*  They're all just nobody understands each other and they don't even appreciate each other.
*  And so of course, what I hope happens to them is that in the end, they understood each other
*  a bit better.
*  Well, Robin, thanks for writing the book.
*  Thanks for unfolding information with me here today and spending your time and sharing it
*  with the podcast listeners.
*  You'll be getting a tweet from me soon about the book.
*  And you know what I'm going to do?
*  I'm going to retweet that.
*  Okay, yeah, that's my just be that might just be the second tweet that I will ever have
*  said.
*  You are on top of your game, sir.
*  So thanks Robin.
*  It's been fun.
*  It's been awesome.
*  Thank you very, very much.
*  See you next time.
