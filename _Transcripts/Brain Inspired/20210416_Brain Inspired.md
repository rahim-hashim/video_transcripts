---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 5542s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 10304
Video Rating: None
---

# BI 102 Mark Humphries: What Is It Like To Be A Spike?
**Brain Inspired:** [April 16, 2021](https://www.youtube.com/watch?v=ZGcFnsE5lxc)
*  The brain itself is one massive dynamical system, so much of what we record in the brain
*  is generated internally by nothing outside in the world.
*  So we need to understand the separation between what's evoked by the world and what isn't
*  to be able to peel apart the two and go, no, this is what's happening inside and that's
*  what it means, that's what's happening outside.
*  When I spin my brain forward a hundred years into the future and go, what will the explanations
*  of neuroscience look like?
*  Almost everything that we would understand at that point would just be from massive simulations.
*  We have great theories for about, what does that leave us with, 3% of neurons?
*  I think so we've got.
*  Great theories for what they're doing.
*  You only use 3% of your brain.
*  I think that's the new, yeah.
*  This is Brain Inspired.
*  Hello everyone, it's Paul.
*  Today I have Mark Humphries back on.
*  Mark runs his lab at University of Nottingham in the UK, which he describes as a neural
*  data lab.
*  That means they're more of a theoretical lab that uses computational models to analyze
*  neural population data that's been recorded from other labs' experiments.
*  So back on episode four when Mark first appeared on the podcast, we talked about some of his
*  work analyzing how the population of rat prefrontal cortex neurons relates to learning new rules
*  in a behavioral task.
*  He's written a book now, which is the main thing that we discuss today.
*  The book is called The Spike, An Epic Journey Through the Brain in 2.1 Seconds.
*  Just like the title says, it chronicles a couple seconds of brain activity of someone.
*  And that someone happens to be in a meeting at work and they see a cookie on the conference
*  room table and they think about reaching for it and they finally reach for and get the
*  cookie.
*  The premise of the book is the story of what it would be like to travel along with the
*  action potentials happening in the brain during those couple seconds of cognition.
*  And along the way you learn where things get processed and how they get processed.
*  You learn a lot about what we do know, some of the important principles discovered over
*  the past 30 years or so.
*  You learn a lot about what we don't know, so some of the big mysteries left to solve,
*  and what we think we may know, so theories about solving some of those mysteries.
*  And we talk about just a few examples from each of those categories, but mainly focus
*  on some of the bigger discoveries and questions that he writes about.
*  Like we discussed, the book is aimed at a smart audience that can pick up concepts,
*  but it doesn't assume that you know much or anything about brains to follow along.
*  So you don't need to be a brain expert.
*  It can be used as an introduction to a lot of these things.
*  But if you are a brain expert, it still takes you to the modern challenges of neuroscience
*  and puts those challenges in the context of historical knowledge and current knowledge.
*  So show notes are at braininspired.co.uk slash podcast slash 102102.
*  Thanks for listening.
*  Happy reading, I hope.
*  And here's Mark.
*  So Mark, last time you were here, I just checked it was episode four.
*  So welcome back.
*  So we actually just chatted a couple of weeks ago because you were included in this little
*  hundredth episode special series that I did.
*  And one of the things that you mentioned that has benefited your well-being and career in
*  the past five years has been this idea of writing down just one thing, the most important
*  thing to get done in a given day.
*  And then the rest of the day you can use to, you know, get all the other scraps done.
*  What was that one thing today?
*  Well, precisely it was prepared for this interview to be.
*  Well, but okay.
*  Sure.
*  I scratched my head.
*  But it was preparing in a particular sense because I finished the book about a year ago.
*  So I had to go and reread quite a bit chunk of it to refresh my memory of exactly how
*  I'd structured some parts of exactly what it said in various parts because the slow
*  lead time in academic publishing in the publishing world compared to even journal publishing
*  means that I haven't looked at some of this text for a year and a half.
*  So it was great to go back and take a look at it with very fresh eyes and go, okay,
*  that's not bad.
*  It actually does make sense.
*  Yeah, that's always nice.
*  How does that compare when you to like publishing a paper where, you know, once it's finally
*  out in print or online these days, I suppose it's old news by that time.
*  But there's even a longer lag time for a book.
*  Yeah, there is a long, long time for the back.
*  So it's been as I said, I handed in the final version back in March, early March 2020, just
*  as a sort of we went into lockdown, the pandemic broke big as when I was writing the last,
*  all the redraft of the last chapter.
*  So that was that was challenging, but it was got done.
*  So it's the reverse of a paper.
*  So as you say, with the academic paper, it kind of just peters out, you have all this
*  huge energy build up to the first submission of that paper, and then the revisions of that
*  paper and resubmission of that, blah, blah, blah.
*  And particularly now when we do it, we pre print all our papers.
*  Most of the sort of the big oomph is gone because it's there now and you're just trying
*  to push it through the door, a journal somewhere.
*  And the book is completely opposite.
*  So it was written a year ago, it's been sat.
*  And as it come up to release day on March 9th, it's just been the amount of things to
*  do with the book has been escalating.
*  So it's becoming it's a clearly an event in a way that a paper release isn't.
*  There's also a bit more of a permanence to because, you know, to a book because you publish
*  a paper and then it's kind of on to the next thing.
*  But the book is more of a statue, right, where people can revisit and revisit a lot and sort
*  of its own thing.
*  Does that make sense?
*  Yeah, indeed.
*  So it's not least because it's kind of monolithic, but people aren't going to add much to it.
*  It's a standalone thing.
*  It's also a bit like a message in a bottle to it's just been thrown out there to float
*  around the world.
*  So hopefully people pick it up and read it.
*  And they can read it as many times as they like this.
*  But it's not a, it hasn't got the ephemeral nature of a paper.
*  Some books obviously have designed to be ephemeral too, right?
*  So we have a sudden, you know, bookshelves for the books about COVID-19 that in about
*  five years time will be of purely academic interest of what do people think at the time,
*  I sure as hell hope so.
*  Exactly.
*  Yeah.
*  Yeah.
*  The other thing is that I wanted to ask about is, you know, blog writing because, you know,
*  you write the spike.
*  And in a sense, I mean, it's, it's, there's almost like this model these days, and I don't
*  know how writers used to do it.
*  There's almost, it seems like a model these days where someone, you know, you write a
*  blog and then you kind of write a book from that, you know, like use like your blog posts
*  sort of as inspiration.
*  I mean, some people just put their blog posts in a collection and call it a book, which
*  is that's a different thing.
*  But you know, a lot of people in science, it seems, are doing this kind of model where
*  you write these blog posts and then the ideas kind of coalesce.
*  And then you realize that it can be a book maybe.
*  I don't know.
*  Is that, that's a question actually.
*  I'm wondering if that's the case, like how the blog writing interacted with the book
*  writing.
*  To be fair, we initially when we're discussing projects with my, with my agent, I was just
*  you flow with the idea of do we do some kind of collection thing?
*  And it's a no, no.
*  Yes.
*  It needs to be a book.
*  It needs to be a first book needs to be a thing that's really, you know, it really makes
*  a statement about what your position on the world as much of anything.
*  It's a bit sort of, you know, so essay, books of essays and stuff are further down the line
*  and established, you know, mature authors type of thing where people will be interested
*  in reading what you, your thoughts.
*  So for me, as it turned out, the idea I had for the book, I had more or less before I
*  started writing the blog.
*  So clearly as it turned out, the blog was a place where I ended up rehearsing a number
*  of the ideas ended up in the book.
*  But the idea of the book and the structure was something I'd had a year or two before
*  I started the blog.
*  Just this idea of this notion of what's it like to be a spike?
*  If I look at the spikes perspective on the world, coming from neuron to neuron, what
*  do I see?
*  And that's where that came from.
*  This is very you talk in the book in the beginning, maybe the preface about having
*  written since you were a kid or started a thousand manuscripts or a thousand stories.
*  And that comes across in the book.
*  It's very story like.
*  And the point of view of the of the spike reminded me of this.
*  I'm sure you haven't seen this.
*  It's an American film. It's called Inner Space.
*  It's from the late 80s.
*  Oh, Dennis Quaid. Oh, my gosh.
*  You know it. Yeah.
*  So in this movie, he's a pilot.
*  Dennis Quaid is and he gets shrunken down and accidentally injected into Martin Short.
*  And then all sorts of hilarity ensues.
*  But I mean, it's him like from the perspective of a very miniature person going through
*  Martin Short's body and interacting with his body.
*  And this kind of made me think of that.
*  Your book, thinking of traversing the brain as a spike, you know, writing on a spike,
*  kind of made me think of that.
*  So that's interesting that you actually know that movie.
*  Yeah, you know, it's yes.
*  Riffed on a lot of British TV shows, actually, even the kids cartoon called Danger Mail.
*  I didn't realize it was a classic.
*  Apparently, apparently, all the creatives in television grew up watching watching that film.
*  Oh, interesting. That's a great point.
*  That is kind of exactly that's good, because that's exactly what I was aiming for.
*  Right. To get the read of the feel of they were with essentially with me as well.
*  Both of us were with the following the spike through its very first journey through the
*  through the brain.
*  So that, yes, so the book was structured as a journey.
*  So that unfolded as we follow this spike from the eyeball through all the various
*  complex processing centers of the brain to the part where it controls the arm to move
*  the hand to the thing it's doing.
*  And so that journey allowed me to both then slowly unpack as we travel the various
*  aspects of what it means to be a spike, how you create one, why we have them.
*  So the basic understanding in the first at the start and then the journey as we go
*  through the brain also opens up into more and more complex ideas of of how spikes
*  work, how the brain works, using them and how it's used in decision making and memory
*  and all kinds of things.
*  So it was meant to be a journey in two senses of through the brain and also as every
*  chapter is a new set of more ideas that build on the last and it gets bigger and bigger.
*  And it's all with the the premise of someone in a like a meeting and an office and
*  looking considering whether to reach and grab a delicious cookie.
*  And throughout you come back to what's going on in the office with Barbara or Pam or
*  someone moving to the left and stuff and then relating it back to what's going on in the
*  brain. So it's it's a fun read in that sense as well.
*  And the language that you use, you can tell like you have it sounds like you're having a
*  good time when you're writing it anyway and coming up with the many metaphors that you
*  use in the book. And it is interesting because it my question that I'm
*  about to ask is who the book is for, because it starts fairly basic, I would say,
*  you know, like how spikes kind of are generated and some of the nuts and bolts of
*  just a spike and what it does and how it moves through the brain.
*  And then as you go on and on in the book, like you just mentioned, the story becomes
*  more complex and you start to bring all of the gory details and the things surrounding
*  what's happening, decision making, predictive coding, things like higher level concepts.
*  Right. So there's a real trajectory in the book, I feel like.
*  So I'm wondering who might benefit the most, you think, from from reading the book.
*  So I was ambitious and I aimed at a lot of people.
*  So I took the approach, the sort of sort of the classic advice of writing a popular science
*  book of assume your audience is intelligent but doesn't know the information.
*  I decided to, yeah, so as you say, build from the ground up.
*  So once you grasp that the spike is this voltage signal that is sent by a neuron to
*  another neuron, whenever it gets enough inputs, it's a signal that says, OK, something
*  important has happened now. I'm going to send bit information.
*  And from knowing that, having really embedded that, spending a whole chapter really making
*  sure that that is embedded in the reader's head and you can use that as a platform to
*  slowly build out on out on out.
*  So it's for a very general audience, but I had particular audiences in mind, so I
*  wanted to write it so that it was of interest for our AI and neural network audience.
*  We want to understand more about what we know about brains to see if anything useful was
*  going to be in there. So, you know, I throughout the book, I touch back on ideas from from
*  AI and neural networks, occasionally contrast the bit we're talking about the brain, about
*  how neural networks work to the extent that I understand they work.
*  And in particular, there is, you know, because this is all about spikes, it's the domain
*  of systems neuroscience.
*  So the bits of neuroscience where people recall from lots of neurons at the same time.
*  And of course, this whole areas of research fields where people are interested in this
*  kind of stuff, but have no way of getting into literature itself.
*  So also, it's in one respect, it's for an enormous audience of clinicians and of medical
*  people and people who work on molecular stuff and people who work on, you know, anything
*  that ever touches on brains who won't have a chance to actually delve into literature.
*  This is like a one stop shop saying this is all the cool stuff we know about how brains
*  use spikes to do stuff.
*  Nice. And I was also interested, so I've had, I actually gave it to Ashley Driver-Nette
*  to have a read. She's a associate professor at UCSD who specialises in teaching neuroscience
*  because I'm interested in how it would work. As you know, Eve gave out this to an
*  undergraduate course where they, you know, be able to run with it as a supplement to
*  like looking at the technical details and really understanding how it fits together
*  because they can do it as a framework.
*  So I was also keen to, you know, as people as a gateway into neuroscience, this would
*  also work as a book.
*  So, yeah, so I had ambitions for a number of audiences.
*  I can definitely see how people could go back to it.
*  And every time they go back to it, depending on their level of interest and expertise, I
*  mean, you can get kind of what you want out of the different levels from it.
*  So that's an interesting, that's an interesting take.
*  I also just I find that I and I don't know if you're the same way, I don't mind reading
*  about the stuff that I know about.
*  It's always from a slightly different angle and it always, depending on how it's written,
*  and what else is incorporated, it makes you think of new things, what your book does.
*  And you saying that you sent it to UCSD to an American audience, because I, I was
*  amused by the the British lingo that you used in there that that made me stop and
*  think, wow, you really are going for like a lot of the assuming that we'll all be
*  along with the British lingo.
*  Anyway, one thing that struck me also is the book is, so you talk a little bit about
*  behavior and decision making, but it's really brain centric in that you're really
*  describing the brain as an interesting thing in itself.
*  And it made me wonder about your particular interests.
*  And this is kind of outside the book, I suppose, just just asking you out of my curiosity,
*  because the brain is interesting in itself.
*  You know, if you had to describe your main interests and what your main interests are,
*  and what you're most interested in explaining and learning about, is it the brain in
*  itself and its workings?
*  Or is it the relation between brain and mind?
*  Or where would you put yourself in that camp?
*  Yeah, I guess I put myself in that.
*  So I actually draw more towards trying to understand the brain's internal dynamics.
*  Obviously, to make sense of them, we always have to link them to the outside world.
*  So all our papers are on this talk about behavior in some way, whether it's literally
*  just movement, movement of a sea slug or movement of an arm, or whether it's decision
*  making behavior.
*  But the core is about understanding how essentially how groups of neurons do what they
*  do together.
*  So once you get beyond the sort of the single neuron fires, because this thing happens in
*  the world framework, when we look at populations of neurons, that's where we're
*  interested in both the terms of what they're, what we can read out from there, what
*  they're coding and the sort of the dynamics that they create.
*  This is probably due to the types of hooligans that I digitally hang out with these
*  days. But it feels like there's a, you know, a backlash against studying these types of
*  things for their own sake, right?
*  So like population dynamics in neurons without considering behavior as an overall
*  overarching top down, I won't say constraint, but inspiration for how to think about
*  neural activity as being explanatory.
*  Right. Do you feel that?
*  Do you feel that at all?
*  Because, you know, obviously no one no one says that there's anything wrong with studying
*  the brain for itself, just because it's a, you know, fascinating, super, super complex
*  entity. Right. So just understanding like how it goes about doing anything is is an
*  interesting topic in itself.
*  But do you feel the pressure of this needs to be related to behavior as a fundamental
*  thing?
*  I think you're right. At the moment, there is in particularly in terms of the areas of
*  neuroscience that record neurons activity, there is a big push at the moment from various
*  people to push this emphasis of going always think about the behavior and on now further
*  on, you know, more ecologically valid types of behavior, making sure that the animal is
*  doing something that's vaguely relevant to what it's supposed to be doing.
*  Right. But as a neuroscience, like all sciences is cyclical, right?
*  It has fashions to come and go. So the last time this was a big push was, I mean, in the
*  mid 80s, there was this huge outcry about neuroscience needing behavior.
*  You can pull out a number of review papers and opinion pieces, which says, yes, we're
*  getting too far from this sort of behavior perspective because we followed human and
*  visa. We've stuck an electrode into our into our neuron and we've watched it fire when
*  we've shown it something and then we've gone a neuron up and we've gone a neuron up and
*  gone a neuron up. We're just recording lots of neurons now.
*  We've got lots of spikes. That's great.
*  But we're not doing anything with them.
*  So you have this push to go back to behavior.
*  So and then we get to the behavior section and then sort of in the sort of late 90s, the
*  push in source theory, at least, was to go for a lot was a split between people looking
*  science to understand this population coding idea and people who are really interested
*  in the details of a single neuron.
*  So building these incredibly detailed models, the compound mental models of individual
*  neurons, each dendrites model by a whole bunch of different sections stuck together.
*  So you need a computer just to run one neuron.
*  And that took over for a while and that phase, and I've no doubt that will come back again in
*  10 years time as a next push.
*  So it's true that at the moment there's a little bit of there's a little bit more emphasis
*  on the need for behavior.
*  But as you say, the brain itself is one massive dynamical system.
*  So much of what we record in the brain is generated internally by nothing outside in the
*  world. So we need to understand the separation between what's evoked by the world, what isn't
*  and to understand what isn't.
*  We need to understand what is how the circuits of the brain are doing, generating all this
*  activity and what forms it can take to be able to peel apart the two and go, no, this is
*  this is what's happening inside.
*  And that's what it means. That's what's happening outside.
*  So before we jump into some of the topics in the book and how they may or may not be
*  related to A.I. as well, given how complex the brain is itself and how complex
*  behavior is.
*  And we'll, you know, I don't know how to talk about how complex mind is.
*  We'll just call it very complex as well.
*  Do you think that an eventual satisfying explanation of the brain and mind linkage of
*  how the brain is related to mind and the characteristics between them, do you think that
*  that's going to feel intuitively right?
*  Or do you think that we're going to have to eventually accept, you know, that we can't
*  quite quite grasp, can't quite grasp it in an abstract sense?
*  You know, like these days.
*  So like like you were just talking about from the single neuron perspective, you can build
*  these computational models. You kind of feel like you have some idea of the canonical
*  computation, right, that some single neuron might be contributing to.
*  And now we're getting to these larger populations.
*  We're having to talk about dynamical systems and state spaces and the terms are becoming
*  more and more abstract. Do you think that we're going to maintain an intuitive
*  grasp of the explanation of how bright brain and mind are connected?
*  Sadly, no. So and you're comfortable with that.
*  It sounds like you're comfortable with that.
*  Well, I think I'm comfortable.
*  That's what I'm looking for. I'm I know I'm resolved to that.
*  Resolved, yes.
*  Yeah, it's so because one hand, so our explanations of mind are all psychology, where
*  we talk about memory of various forms about of, you know, of perception.
*  But those, of course, are kind of too philosophical.
*  There's got to be semantic labels that we give to our own internal experience.
*  There's no need that anything in the brain actually maps directly onto the things that
*  we call, you know, short term memory, working memory, episodic memory.
*  Sadness.
*  Yeah, that these are labels we give.
*  So the mapping from mind to brain is going to be quite, quite awkward in places, I think.
*  I think that's a good word. Awkward.
*  It means that then when we have a we have a we ever end up with an explanation of the
*  brain beyond some kind of general principles, which we all agree are in play, then it's
*  going to be fairly unintuitive. Yes, I think it's that's inevitable.
*  I mean, secretly, not secretly, I'm about to tell you the the for me, when I spin my
*  brain forward, 100 years into the future and go, what will the explanations in neuroscience
*  look like? Mostly, I'm left with looking at the fact that almost everything that we will
*  understand at that point will just be from massive simulations.
*  Because we have we just look at other fields that deal with with systems of comparable
*  complexity. So look at the weather and climate modelling, let them even try to understand
*  their thing in an intuitive sense, they have a toy model in your head, or what might happen
*  if this happens in a short space of time, but on a longer time scale, you have to run a
*  simulation. And those simulations are all probabilistic, right? So you start different
*  conditions, and you get a range of outcomes. So if we want to understand how some treatment
*  for Parkinson's will affect the brain, maybe trying to try and target a particular set
*  of neurons, they're in, we're going to end up with some kind of in silico platform where
*  we do that, run it, run it from various configurations and get a range of outcomes that will
*  that will be predicted. Not satisfying, but science doesn't is under no constraint to
*  give us any satisfying answers.
*  Yeah, I mean, the complexity and weather prediction makes me I should have a climatologist
*  on or a what's the weatherman called? Yeah. Yeah, I should have a meteorologist on and
*  ask them how satisfied they are with, you know, having to run the simulations and how
*  intuitive it all feels. Because eventually, these things that makes no sense kind of, well, I
*  think you use the word resolve. And I think that's I think that's right. You kind of give up and
*  you get so used to it that it starts to feel intuitive, even though when you actually examine
*  it, it makes no sense at all for it to feel intuitive. And maybe that's what's going to
*  happen.
*  So I think we're gonna as I said, so I think we're gonna have a end up with a lot of agreed upon
*  principles that we know the brain works by. And we're going to understand some of the
*  algorithms that it uses to get from A to B, right, particularly algorithms for learning for
*  creating memories, what things it prioritizes, and so on. But those are going to be elements of a
*  complete picture. So we stick them all together, we're going to need some kind of, no, no doubt
*  some kind of simulation in the same way that for weather forecasting and for climate modeling,
*  they know the physics extremely well, but the physics is extraordinarily well known how the
*  equations the problem is that you can't put them all together into into your brain, you have to
*  stick them on a supercomputer and run them to find out exactly how they interact.
*  When I spend my brain forward, though, I am sorry, I'm this is a you know, kind of a long
*  tangent. But when I spend spend my brain forward, I have this kind of wager in my head or it seems
*  likely to me that there's still a long way to go with the neuroscience with characterizing how to
*  understand neural activity, populations of activity, the dynamics between areas and how they
*  communicate and the different motifs right of computation and processing. I feel like there's a
*  lot more of that to discover that will that will be useful. Getting toward that final place where
*  we're resolved to, you know, there's a gap, and we're and it's fine, because there's a loose
*  mapping. It's not, it will never be like isomorphic, it will never be one to one. But you
*  know, the principles, I think, I feel like the neuroscience has a lot farther to go to contribute
*  to the principles that will eventually be our explanatory resolution, you know, as opposed to
*  coming from the other side from the psychology side.
*  All right. So yeah, I agree that we have much to discover in neuroscience about what the
*  particular principles in the in the vertebra brain, we have a lot of things to resolve of.
*  Because we only we only really spent the last what 20 years routinely recording from one neuron
*  at once. So we have we're basically at the beginning of uncharted territory. And we have a
*  well, basically a first paper in nature, a few weeks ago from Matteo Carandini's lab, where
*  they finally imaged 100 or so inputs to a single neuron. So that kind of little detail is this
*  kind of thing where we need to understand properly how neurons talk to each other because we need to
*  look at what the inputs to each neuron are. So yeah, so there's going to be this, this, this, a
*  lot more you say a lot more of these principles to come up. A lot of these principles are going to
*  be about the back end of it with dynamics, I think about principles of wiring, of how particular
*  neurons connect to others to create different forms of dynamics. And so we're going to need to know
*  a lot about the sort of canonical circuitry of the brain. But we're not going to know a lot about
*  particularly how that maps back up into these higher cognitive, cognitive processes.
*  These higher cognitive sort of ideas, not least because we have to do all our experiments in
*  animals, which we can't get them to internally tell us that I had a memory of this, we have to
*  infer from, you know, sustained activity prefrontal cortex, that that is a memory. Because if you
*  perturb it, then memory seems to go away. But that it's, but it's us labeling it a memory rather
*  than whatever the brain is using as
*  lots and lots of levels. That's, it's just, this is why I do what I do. It's just fun. It's fun to
*  think about and talk about. So, all right, let's talk about the book. And I'm the questions that I
*  have for you come from, generally from kind of later, mid to later in the book. And I'm skipping
*  over like the bunch of the introductory stuff that talks about, you know, the generations of spikes
*  and, you know, the role of, you know, non spiking activity in the retina. I mean, it literally goes
*  from, you know, photons, the book goes from photons in the environment hitting the retina, how
*  that's processed and, and then traverses through the entire mostly visual areas of the brain to a
*  motor action, as you've already said here. But the first thing maybe I want to ask you about is, and
*  I picked out a few things just specifically so that we could kind of compare them like you do in
*  the book to what we know, and what is being used in AI. And the first of those are just the
*  randomness of spiking. So it's well established now that spiking is a random process. And you
*  asked in the book, how that can be the case. And one of the things that you point out is the
*  excitation inhibition balance coming into a spike, as all the voltages are getting added up from the
*  excitation and inhibition, and to eventually produce a spike. So maybe you could just say a
*  few words about the importance and the role of excite excitation and inhibition, and maybe how
*  it differs, obviously from AI.
*  Yeah, sure. So, so as I also outlined in the book, this is one of the lovely sort of clear detective
*  stories in neuroscience of how people uncover this idea of excitation in a minute in mission
*  balance, as you say, and long been observed that the spikes coming out of individual cortical
*  neurons appear to be essentially random, that the gaps between them were, gap following a single
*  spike was either short or long, and it seemed to have no relationship to the previously whether
*  it was short or long. So essentially, it appears to be a random series of spikes in time. And that
*  when you've got a models of neurons, that seems to be impossible, because when you give a model
*  neuron lots of inputs, its outputs are really regular, no matter how random its inputs. And I
*  explain why in the book is a nice diagram, which shows this much more intuitively than I can say
*  in words. Right. So the solution one of the solutions that so there are many solutions to
*  this problem of how you get irregular outputs from a single neuron. And one of the key ones that
*  were hit on early, I think, there was a review paper by Mike Shadlin and Newsom who floated the
*  idea in words, and it was put into models to test it was that if you have a neuron whose excitation
*  inputs and inputs, inhibitory inputs were basically cancelling each other on average, then
*  the voltage of the neuron itself as those inputs kept bombarding it, they would be all random, but
*  the total amount of inhibition excitation would be roughly the same. So then it would be
*  fluctuating back and forth as it up when it got excitation and down as they got some inhibition.
*  And eventually, there'll be by at random, a tiny little burst of excitation would suddenly
*  overcome all the inhibition and a spike would appear because the neuron voltage would reach its
*  threshold for making a spike. And that creates this, this irregular output spike train. So it's nice
*  and easy to show that that would happen in a single model neuron. And the real breakthrough
*  was showing that if you put neurons in a network, and you basically balanced out the number and
*  strength or the excitation inhibition connections within the network, so on average, it was balanced
*  across the network, then the network was self generate irregular spike trains. And it would do
*  that because essentially, it was it was, it's on a massive feedback system for itself. So we had too
*  much in excitation coming out of the of the excitatory neurons, then that means they would
*  drive the inhibitory neurons to create too much inhibition, which would drive them down. And so
*  the excitation inhibition would count would balance itself out. So that means that in the so in the
*  brain, we have this this apparent particular cortex, we have this beautiful balancing act going on,
*  which means that the if it's unseen, then that the outputs of each individual neuron are not
*  heavily driven by a particular set of inputs that they are driven instead by this ongoing
*  barrage coming into them from both excitatory and inhibitory sources. So they don't necessarily
*  reflect, obviously, something that a clear labeled line which says this input means, you know, a line
*  of 90, 180 degrees or a particular tone right now, because the timing of that spike isn't under the
*  only under control of the whatever the external stimulus is.
*  A couple important things also to note, I mean, it's not like there's a positive there's an
*  electron or an anti electron or something, you know, it's not like excite excitatory input and
*  inhibitory input are of the same ilk, right? So they're very different, because you have these,
*  you have a lot more excitatory input numbers, right of axons impinging on the dendrites, but and
*  fewer inhibitory inputs, but those inhibitory inputs are firing higher for one thing. So that's
*  one way that they balance it. And also they're they're the strength of their effectivity.
*  They're you could call it their synaptic effectiveness, efficacy is higher than the
*  excitatory input. So this gives rise to this ability to have a lot of these voltage fluctuations
*  within that balance overall average balanced scheme, correct?
*  Right. So looking at a sort of site and network level, yes, that network level, you have many
*  more excitatory neurons and you have inhibitory neurons. So in cortex, the balance in the mouse
*  cortex balances roughly sort of 80 85% excitatory neurons, 15% inhibitory neurons. But as you say,
*  then they are, those inhibitory neurons are giving out many more connections. So they connect to many
*  more sort of many, many more neurons, which means that individual neurons receive quite a
*  number of inhibitory inputs. And even though they then may be fewer in number, the excitatory ones,
*  they are stronger. And then they also inhibitory inputs, struggling with this phrase inhibitory
*  inputs tend to tend to arrive at the neurons body, where the excitatory inputs tend to arrive in the
*  up in the dendrites. So which means that they are able to have a more powerful effects on directly
*  on the neurons voltage than are the many thousands of excitatory inputs out in the dendrites. But
*  that also means that locally inside the dendrites then that so for example, there is a particular
*  interneuron in cortex, which projects its axon just up into the far top of the dendrites of the
*  pyramidal cells in cortex. And that appears to be specifically to be able to regulate the excitatory
*  inputs in particular parts of the dendrite, so that you have this that tug of war between emission
*  excitation happening in local little parts of the dendrite as well as globally controlling the
*  output of the neuron. And one reason you might want to do that is because we know that when up in
*  these far regions of the dendrites, when you get these big clusters excitatory inputs firing
*  together, you get this kind of spike like thing happening in dendrites, big nonlinear jump up in
*  the dendrite, which then flows rapidly down to the body and can itself cause a spike to be sent down
*  the axon. So you want inhibition up there to be controlling this process to which it appears to
*  be doing. Then that means that obviously played out then across all the very big dendritic
*  branches of one of the pyramidal cells, you have these lots of little different regions,
*  which are essentially acting independently with this independent excitation inhibition balance
*  going on in each of them, potentially to the sending spikes down to the down to the neurons
*  body. So you end up with this really complex computational device inside this individual
*  neuron, of which the readout spike is just the readout of this very complicated interaction
*  within the dendrites between excitation inhibition. I think we talked about this the first time you're
*  on the show that that in that sense, every neuron is like a little neural network in itself.
*  Yeah, so there is actually so there is some lovely modeling work showing that yeah, when you build a
*  single model neuron, that then has little compartments, we discussed before we choose
*  compartment gets a little inhibition excitation to it is formally equivalent in many respects to a
*  two layer neural network. And indeed, we can show if you've got any of these kind of nonlinearities,
*  this kind of spike that appears in the in the dendrites with many excitatory inputs, as long as
*  you have one bit of dendrite that has that and other linear bits of dendrite, you open up this
*  whole class of computable functions that was impossible if you have purely sort of an add up
*  and some device happening. And also, yes, and then we have to do that in a really compact space. So
*  that single neuron is a very tiny thing. So being able to do all this computation locally means you
*  don't have to have all have this competition spread out amongst 1000s of neurons and hidden
*  layers in a neural network. So then then like zooming out even on the interneuron level between
*  neurons and among populations at the neuron level, this excitation and inhibition property in mass
*  gives rise to and because of the different types of excitation and inhibition, the different
*  properties of those inputs gives rise magically, oh, I said magically, emergently, let's say,
*  let's take the magic away to self organization and ongoing dynamics within a population. So it's this
*  nice property that these lower level characteristics give rise to. Yeah, right. So as we sort of
*  touched on then, because this this is, yeah, so this is a single neuron, property of this
*  excitation inhibition balance explains the irregularity of a single neuron. And then we
*  take these excitatory neurons and inhibitor neurons and wire them together in a network.
*  Because then they are they provide each other's excitation inhibition, they are then self
*  balancing. So you require a robust range of ways of wiring up these networks, you will always get
*  this irregular spiking, you know, always get this ability to for inhibition to a balanced excitation.
*  One thing though, touchpoint is sort of your question of what we we lack a good knowledge of
*  in neuroscience is how this complex dendritic computation actually contributes to the network
*  level dynamics, there's almost no one looking at that level, partly because building the models
*  that are that complex for individual neurons, and then wiring them into a network is incredibly
*  computationally expensive, you have to have access to some kind of, you know, IBM, blue gene scale
*  supercomputers to run them properly. So people have built models of cortex on this scale, of
*  course, you've got the you know, the blue brain projects. And similarly, there's a team in Sweden,
*  who also have a blue gene supercomputer that building cortical models. But as of yet,
*  no one's really done a good exploration of what dendritic computation adds to the network dynamics,
*  these two things still fairly treated fairly separately.
*  And what's your what's your sense? Is it a subtle context sort of information that it adds? What
*  if you had to guess? It's good question.
*  We got to be speculative sometimes on the show.
*  I'm not sure actually, I'm really not sure what it adds. So we've done we've done a bunch of work on
*  what the individual neuron computations would be with these nonlinear dendrites. And then when you
*  scale it up, essentially, it means that you, I think one of the things going to let you to do is
*  allow us to access by putting together relative so relatively simple neurons that be able to do
*  something nonlinear, that you can open up this whole class of functions you can compute that you
*  would otherwise need extremely complex dense neural network to to like multiplexing sort of
*  Yeah, either that. Yeah, either that you're allowing it to instantiate many functions at once
*  in the same network, all that in a simple, obviously, because most of your brain networks
*  are recurrent in some way that what you're letting it do is, is, is allowing some kind of
*  the current computations, but it's passing back through these functions over and over again,
*  historical context, you know,
*  yeah, to build very complex, instead of just a simple, you know, way equals f of x function,
*  something that's really deeply recursive, is being built by being passed constantly through
*  these dendrites and spat back out as a spike.
*  Yeah, I mean, there's just so much complexity and so much fine detail. And it's hard to know,
*  you know, what's important, you know, as you move up in scale in size, right, and in computation,
*  does any of this matter for for AI, for instance, or, or all these types of things,
*  and we're going to talk about plenty more things that we can just abstract away. I mean,
*  there are people like Blake Richards and many others who are working on using the
*  variation in dendritic compartments and, you know, different electrical properties of the
*  different types of dendrites, for instance, to be able to compute things like feedback,
*  information, predictive information, and, and actually trying to use these models that you say,
*  you know, are super, super compute heavy to make anything large. But it, you know,
*  whereas like when you think of like a neural network, you think it's just a dumb little
*  node that adds, puts a little sigmoidal function and spits something out. And it's just, there's
*  such a vast difference functionally between that and the complexity of neurons. And when you get
*  down to that sub neuron level with the location of the dendrite, when an input's coming in,
*  how close it is to other inputs, whether it's excitation, inhibition, and all that variety
*  that can happen, I mean, it's mind boggling, does it matter for, you know, for building it
*  for building intelligence systems? That's a key question, isn't it? So, so, so one point of view
*  is that, is that maybe doesn't, right? So one point of view of why deep neural networks are so
*  successful is because they essentially they replicate, they replicate by just adding many,
*  many, many, many layers. The process that's happening in a handful of neurons, right? So
*  we only need, you know, for our object recognition system only needs essentially four layers of
*  neurons, well, maybe five, depending on which object you're recognizing, but a deep neural
*  network, you know, 15, 20, however many layers you're putting on that convolutional
*  network at the start. One, one, one point of view would be that simply that really deep network is
*  just replicating the many stages of processing that in the brain are collapsing to a handful of
*  neurons, each neuron is doing a job of multiple layers in that network. But as you say, the neural
*  network is a pretty static device, right? You, it's, it's, you just add up its inputs, you split
*  it out of a sigmoid, you can pass it to the next layer, you pass it to the next layer,
*  which lacks any sense of timing. So much what we know about how the brain computes
*  clever ways is about timing. So a lot of dendritic computation stuff is about how dendrite,
*  dendritic computation can be used to get really specific timing effects. So for example,
*  give an example in the book of coincidence detection of the sound coming from the two ears,
*  the spikes arriving at a particular neuron somewhere in the midbrain will happen to arrive
*  at the same time because they're delayed with each other. They arrive at the same time the
*  dendrite they cause that neuron to spike. And that spike means that there is something that's a 20
*  degrees in front of you in the world, because that that neuron a particular neuron stands for when
*  those two spikes arrive from the left and right ear together. That means that thing is at the 20
*  is at 20 degrees and now those sounds will arrive slightly far apart in the two ears.
*  So that and sort of the more general ideas of coincidence detection in cortex of just this,
*  when we want to know the sequence of events of bind things together that when spikes arrive in
*  the dendrites, when they arrive one after the other immediately or arrive together, that gives
*  different information. So obviously a lot of the computations in the dendrites, and particularly
*  in the synapses as well with things like short term plasticity, where it matters what all of the
*  spikes come in as whether you get an increase or a decrease in the strength of the synapse.
*  This seems to be about timing effects and they're all completely missing from from AI.
*  I think that's going to be a recurring problem in AI, just guessing just timing at all levels.
*  You can imagine, I mean, just zooming out as far as you can, you can imagine a, you know,
*  if you're interacting with a person or an AI or something, and they move, you know, a thousand
*  times slower than that, you wouldn't call that intelligent behavior. So there's some threshold,
*  right, where timing is important for us even to consider something, an intelligent process.
*  I mean, if you zoom way out, you could look at the earth itself as an intelligent process,
*  but it's going way too damn slow for us to consider it what we would consider an intelligent process.
*  Right. Right. And like you said, I mean, time just gets completely ignored in the vast, vast majority
*  of AI, because it is a static thing where it's just a functional thing, input, function, output,
*  and it does the thing, it categorizes the thing, but it doesn't matter how fast it does it.
*  It doesn't matter the timing that it does anything with respect to anything else. You know,
*  if you want to talk about, you know, the generalizability, you would need all these
*  processes working together in harmony dynamically. I don't know, now I'm just off the deep end here,
*  but this goes also back to another thing that you write about in your book that seems at odds
*  with our intuition is that spiking is a relatively rare phenomenon. Right. So you have,
*  you talk about in the book how, you know, you have like 10 to the fourth inputs on average to
*  every neuron. Right. Or yeah. And given all that input, you would imagine the neuron would just
*  be going wild all the time. But in fact, spikes are rare. And, you know, it's not that that
*  signals aren't being delivered to the neuron. It's just that those signals are being averaged out
*  and, or for whatever reason, don't add up to a spike. It takes a lot to add up to a spike
*  in a neuron. And you call that spike failure in the book. And you talk about why that might be
*  good. You give a few reasons. Would you mind just talking about some of the reasons why it might be
*  good for a spike to fail? Yeah, sure. That was the chapter I had most fun writing. I'd say. Oh,
*  yeah. I've long been fascinated by spike failure because it's such a paradoxical idea. So particular
*  this synaptic failure problem where most synapses in cortex and hippocampus and midterms and so on,
*  there was a failure rate of about an average 75%. So every spike that turns up with those synapses,
*  about 75% of them will not cause a response on the other side. They'll simply not release
*  the VC call. The bank transmitter won't go across the other side. They won't lock in the other side.
*  No voltage will be transmitted at all. Some of those estimates you talk about get up to 90%
*  failure rate. Yeah. So there are reports of, yeah, in hippocampus reports, they're up to 90%. So
*  only 10% of spikes are doing anything. What a waste. Exactly. And as you say, it appears to be
*  nonsense because spikes are metabolically extremely expensive to produce. They use
*  sort of estimates of how much energy they use on your moment to moment energy basis. It's about,
*  in your brain, it's about 46% of all the energy that your neurons are using. It's just to produce
*  the spikes. So why would you use all that energy and have them fail is kind of bizarre.
*  These kind of paradoxes fascinate theorists, right? Why is the brain doing this to itself?
*  There must be a fabulously good reason for it. Yeah, I'll give you a couple of examples. There's
*  a reason why it's good for an individual neuron to have its inputs fail. So Livin Baxter had this
*  idea that what each neuron is trying to do is it's trying to actually make the most efficient use of
*  its own energy when it's producing its spikes. So its output along its axon has a maximum rate
*  it can send information. So typically what we call an active cortical neuron, when we used to
*  just lower a single electrode in blind into cortex and find a neuron, that'll be firing at 10 spikes
*  per second. Yeah, exactly. And that's considered the really active neuron. But of course, that's
*  still a fairly low rate of information that's being transmitted by that single neuron. If all
*  of its inputs were active, all of those 10 to the 4 inputs were active, then the input rate on the
*  information rate on the inputs would be three or four orders of magnitude bigger than it could
*  output. So all this information coming in is just wasted. So their idea is that synthetic failure is
*  there specifically so that it matches the output information rate to the input information rate.
*  So the input is throttled back to the point where it can make absolute maximum use of its output
*  without wasting all this energy on having all these voltage go up and down because these inputs
*  that it has no way of making use of. So that's one really neat sort of way of thinking about
*  synthetic failure that ties together what a neuron is trying to achieve, which is to maximize its own
*  output while making sure it optimizes its energy usage at the same time. And then there's
*  then I also speculate on a few reasons that haven't been as well sort of researched yet
*  about why it might be good for the brain as a whole for synthetic failure to be in play. So one
*  of those might be, as we touched on briefly about methods of generalizing. So we know that
*  when we are learning stuff or when we're learning, like when neural networks are learning an image
*  classification task, shown in many, many, many images, and any problem with learning from many
*  examples is overfitting. So we're going to just learn about some kind of detail in the thing that
*  we're looking at, which isn't relevant to the actual what we're supposed to be looking at.
*  Like horses are always in fields and we might categorize it as a horse if there's a field in
*  the background or something. Exactly. Yeah. Yeah. So of course, there are various solutions to that
*  in the neural network field, one of which is Drop Connect, which is basically the idea of course that
*  every time you show a batch of images, you have dropped out a set of the connections in that
*  network. So every batch, you essentially the batch being shown to a different subset of the network
*  you started with, as though it was being trained on different network. And then when you test it,
*  of course, you show it a new picture, you've put all those connections back in and it hasn't
*  over learned because you haven't had the same connections learning over and over and over again
*  that, you know, as you say, is always a field. So it's going to pick up more, hopefully more the
*  idea of horse. And Drop Connect basically just is synaptic failure. So the brain, it is a fairly
*  logical idea then that the brain, one reason for the brain having synaptic failure then is that it
*  enables it to learn without, to be able to generalize well without overfitting to particular details.
*  Obviously, every time you images are flowing in, you're not having, it means that the connections
*  between particular neurons, because of the failure, are not rock solid. They're not always being the
*  same ones firing a spike down from this neuron to this neuron to this neuron to this neuron.
*  They're constantly dropping out at random while the world is going past you. So it would seem
*  a logical idea to pursue that one of the reasons the brain has the synaptic failure is so that
*  it's better at generalizing than if it was this fixed series of connections that always fired
*  every time you gave an input. And that's one way in that, and we'll get on in a little bit
*  to the topic of noise in the brain and variability. But I mean, that is essentially variability
*  playing a positive role then if this intrinsic variability of sometimes allowing spikes to pass
*  through and sometimes not. I mean, it doesn't work out. It doesn't work just like drop out in
*  real brains. You call it Drop Connect. And I don't think I'd ever heard that. It's the same
*  as drop out, right? So there's two versions. So drop out is literally dropping the nodes.
*  But Drop Connect is dropping out individual weights instead. So you're leaving all the nodes,
*  all the nodes units intact, but they're dropping out the weights. So all the nodes, all the neurons
*  are still on, but you're just removing the connections between some subset of them.
*  Yeah. So basically you put a mask over the weight matrix basically, and you just
*  randomize the mask every sort of batch. And this is those being trained on a different
*  network each time. But of course it's actually the same one. They're connected together
*  ultimately underneath. So you take the mask off and it has learnt the image classification
*  you've given it, but not, hopefully not overgeneralized to the features that are
*  specific that are not the thing you're supposed to be learning. Yeah. So it's one of the many
*  ways that in AI, the term is called regularization where these different various strategies to not
*  overfit, to not categorize something as a horse just because there's a field in the background.
*  So that was a few reasons why spiking is rare. Is there anything to add? I mean,
*  did we miss anything about the rarity of spiking and spike failure being a good thing there?
*  So the rarity of spiking, well, it ties into the whole dark neuron section. I'll talk about
*  it. Yeah, let's talk about dark neurons, which is one of the, to me, like one of the more exciting
*  things that you write about in the book. Yeah. So what are dark neurons and why do brains have them?
*  Yep. So dark neurons are the fact that in any given moment in time, most neurons in your brain
*  won't be firing a spike. So although we can say that in a primate brain, the neurons in your cortex
*  on average fire one spike per second, actually most of the spikes are fired by a handful of neurons.
*  So when we do some detailed recordings, we can see that about half all spikes that are fired
*  are fired by 10% of the neurons. That's hang on. Let's just pause there because that's crazy.
*  Right. So I just want to pause just to just to make sure that sinks in because, you know, as someone
*  who recorded neurons in the brain from an awake behaving primate, right. And you talk about this
*  in your book too, you know, as you drive an electrode down and you're listening and you're
*  hear some neurons, you hear lots of neurons, but the vast majority of things around that electrode
*  aren't making any noise because they're not spiking. And just say that number again,
*  10 to 10% number just to reiterate. Okay. Well, study is showing. Yeah. So we got
*  50% of all spikes are sent by 10% of the neurons. Yeah, it's astounding.
*  It is. And as I know, in the book, it's kind of been hiding in plain sight for a while. So the whole
*  reason that that sort of single electrode recording in your primate works is literally
*  because the neurons are silent. If they weren't silent, you wouldn't be able to see anything.
*  It would be a company. Yeah.
*  Yeah, exactly. But just be the electrical signals would be so overwhelming, you wouldn't see the
*  individual spike shape. You would just see this massive waveform, which would be the
*  superstition of all these of the actual potentials from hundreds of neurons.
*  There would be nothing there to be able to say, okay, this spike is being caused by
*  that stimulus in the world. It's memory or it's seeing a picture or grating or whatever.
*  So yeah, I mean, they've worked out by the late 70s that the recording radius of a
*  single sharp electrode should encompass about 200 neurons, and yet you were picking up what, two?
*  So something weird is going on. And then fast forward to the point where we finally got
*  calcium imaging working properly in vertebrates. And you could video, literally video the neurons
*  and just you sustain them for the, so you know they're there, you're looking at them,
*  and they're not fluctuating. The dye isn't going up and down when you're shining light on it.
*  They're not active at all. So you could just then go and account the fact that there was all these
*  hundreds of neurons there and only handful of them were clearly flashing in your video suggesting
*  they were active. So yeah, so it's become apparent that they are very common. These neurons are doing
*  almost nothing. So when I say almost nothing, I mean that they're firing less than one spike
*  every 10 seconds. It's very hard to get a handle on how much nothing they're doing. Because as I say,
*  because most of the way we can find them is by looking at the calcium signals the neurons
*  produce. But of course, calcium is not really directly related to, it's an indirect readout
*  spiking. So it's hard to get a handle on quite how quiet the neurons are. Because if you fire
*  one spike every few minutes, you're probably not going to pick it up.
*  Yeah. So the calcium signaling doesn't, you don't get individual spikes. I mean,
*  it's in these like windows where you can tell that there's been some activity from the neuron,
*  but you can't tell precisely at the millisecond time scale when a spike happened and how many
*  happened, et cetera. Yes. You can be pretty confident when it hasn't been particularly
*  active and send a handful of spikes. But as you say, you can't get this resolution.
*  So what I want to worry about this in the book is I don't, so I feel that neuroscience as a whole,
*  particularly theoretical neuroscience hasn't grappled with this problem at all. Because we
*  have all these, for example, in the in the we have these beautiful models of what happens in the in
*  area v1 or the first part of the vision system, we have all these beautiful models of how the
*  inputs coming from the retina via the thalamus go into v1 and their process through this sort of
*  linear process. And they took to be the spikes that come out are reflective of this property
*  and this property and this property. But of course, they only correspond to them,
*  the handful of neurons that actually have that activity, which is literally a handful of neurons.
*  This is kind of an old problem, too. I mean, this is like all house and classic papers, like what
*  what is v1 doing, right? Because we have such a small sample of, of the actual neurons in v1
*  that are doing what we want them to be doing. And we can that we can talk about what they're doing.
*  Right. Exactly. So he was so yeah, that old house and paper on what is the other 85% of
*  v1 doing? Yeah, yeah. Yes. So I touched on that a little bit. Because he was at this this point
*  where it still wasn't quite clear. So he was running from a slightly different angle where
*  it wasn't quite clear that there's so many silent neurons. He was pointing out that when we record
*  in recording v1, then many of the neurons that you record from you hear this tick tick tick,
*  as you say over the speaker, you hear on the oscilloscope, when you play them the stimulus,
*  they don't respond to that stimulus, they're active, but they're not looking at it.
*  Apparently, even though they're in v1. Yeah. And those are the neurons that don't go into the
*  paper that you publish, because they're not doing the interesting thing that you're looking for.
*  Yeah, exactly. So in the book, I call them the type two dark neuron. So you have these
*  dark neurons, which are literally neurons that don't fire at all. And all this this set of neurons
*  are the set of neurons that are active, but are dark to the outside world, they don't seem to care
*  about anything that's happening in the outside world, they don't care respond to the inputs,
*  they respond to the outputs, they're just, so they take up another of that 10% of neurons that
*  are firing half spikes, we're not quite sure how many of that 10% belong to this category of
*  neurons that are they don't care about the outside world. There, as you say that the old house and
*  paper suggests actually, it's most of the neurons don't care about the outside world, even when
*  they're active. That's the problem here is pointing out. So it's a stacked problem. So we have for
*  these, all these neurons are barely fire at all. And all the neurons that do fire, most of them
*  don't seem to be responding to the stuff that we're interested in showing the animal, or making
*  the animal do. So we have great theories for about what does that leave us with 3% of neurons.
*  Great theories of what they're doing. You only use 3% of your brain. I think that's the new.
*  Yeah, great. Yeah, exactly. So yeah, there's, as I said, one of the reasons I want to write about
*  this in the book was to really point out that there's this terrific whole area to explore
*  that we don't yet. And there are good reasons to think, you know, why, I mean, there are sort of
*  prosaic reasons why there are dark, these all these dark neurons, one is just simply energy,
*  as I said, the creating spikes is really expensive, as it's processing them. Also, as we know,
*  the brain is a really metabolically expensive organ, right? So the classic numbers are about
*  20% of your resting metabolic rate is just your brain, which is pretty massive, or something
*  only weighs a handful of kilograms. Mine's only about 5%. But that's what people tell me. I don't
*  know. It's exceptionally efficient, right? But so one of the reasons they may simply exist is because
*  is one of the reasons that we may be have this dark neuron problem is not that they are always
*  really inactive is that just that we never give them anything interesting to do. So this is this
*  simplest argument is this dull world argument there. And when we put animals in the lab,
*  we ask them to look at really, you know, so the best we do in visual experiments is we show them
*  what we consider a video of natural, some sort of natural image of video, which often turns out to
*  be a film, the matrix often as a choice. So that's an yeah, we used we used the Hobbit movies, the
*  Tolkien movies. Yeah, well, it's that's got trees and leaves and mountains and stuff.
*  It's got lots. Yeah, yeah, they loved it. The monkeys loved it. Yeah, that's actually nature.
*  Yeah, I mean, so yeah, like the Schneidman and Bialik papers where they record the
*  retina for the salamander and showing in Matrix movies, as though that was a thing the salamander
*  would ever see. They should have showed inner space. Yeah, yeah, but I mean, that that harkens
*  back, I mean, because you're talking about there's this big push right now for ecologically,
*  ethologically valid tasks. And that speaks to one potential role of the dark neurons that they just
*  don't care about what we're asking them to do. Right. So there's a real possibility that we're
*  going to now people have this big push for recording a lot of spontaneous behavior in particular.
*  And I know some people are working hard on sort of fairly naturalistic vision experiments. So I have
*  a colleague Ricardo Storky in Manchester, who's working hard on setting up recordings from retina
*  and the thalamus from freely moving mice in a really rich environment to try and see how
*  what vision processing like looks like when they're actually controlling their own vision
*  for once. And wondering if that's going to be radically different from I mean,
*  but the slight caveat, of course, is vision in mice, so they don't use their eyes much but
*  mice are the animal de jour.
*  Yeah, that's true. Just to throw another little fact in there. I mean, there's a push these days
*  as well. So going back to my graduate school days in non-human primates, I mean, the other thing is
*  that they're sitting in a dark room, they're looking at a screen showing them pictures or
*  just dots on a screen, right and having them make decisions. But they're also only moving their eyes.
*  You actually, you know, the classically you fix their head in place so that you can control for
*  head movements. So even that even even their own behavior is unnatural in that respect and
*  because they can't freely move their head from side to side. So I mean, there's all sorts of,
*  you know, caveats to, you know, reducing as much and controlling for as much as possible in the lab
*  and relating it to brain function. I glossed over something about the dark neurons. So what we didn't
*  talk about was when you include the dark neurons in your like in a population decoding scheme,
*  when you're trying to decode what information is out in the world just by recording the neurons,
*  if you record from only the neurons that you can hear with your electrode going down, you can decode
*  you know fairly well. But if you include the dark neurons, all of a sudden that the decoding becomes
*  much more accurate. The point that you make in the book is the is pointing toward the importance of
*  the population coding scheme relative to like the single neuron or a tiny ensemble of neurons.
*  And it's really the population is where the important information is. Yeah, indeed. So that's
*  but yeah, that's been a that's been a bit of our research work too has been looking at this.
*  And we talked about this last time as well, you know, with the rats want wandering back to in the
*  maze wandering back to start the maze over. That's right. Yeah, yeah. Yeah. Yes, you're right.
*  This is a general idea that we can extract from a population of neurons, not just far more information
*  than there is an individual neurons, but we can extract from neurons that don't appear to be
*  individually responding to the outside world, we can perfectly well extract actually the sort of
*  what's happening in the world. So an example, we're just talking about of the rats walking back in
*  the maze, we could extract from the activity and prefrontal cortex, whether that rats had just been
*  rewarded, whether it had just chosen to go left or right in the maze, and whether at the end of the
*  arm, it was at visited whether the light was on or off. So it's having all this this activity prefrontal
*  cortex is remembering these things. And even in when we record look at the populations in which
*  individual neurons had no apparent response to any of these properties, you can still decode these
*  things perfectly well. In fact, some cases 100% accurately. And you see this this play out in
*  various other areas of the brain, two people started looking at this this question of what
*  can we extract from groups of neurons who individually seem to show no tuning whatsoever
*  for the outside world. And they're finding indeed we can decode quite quite rich properties of the
*  world from them. Yes, it gets really suggesting that it is the the level of information representation
*  interested in the brain is really is the population neurons. And then sort of extreme
*  view of this then that this single neuron tuning is a pure epiphenomenon. It just so happens that
*  we you have the brain has so many neurons that you're going to find some neurons that have
*  perfect tuning to things that you show it. But they aren't actually the neurons that are
*  specifically used for this task. It is they just happen to have the tuning that is you're looking
*  for. One of the things that you again are looking back to this special 100th episode thing,
*  I think it was your answer to the question. What's holding us back in neuroscience and AI. And your
*  answer was looking at averaging, you know, as opposed to like sort of single trial neural
*  activity, that averaging tends to mask things. And this kind of is related to this population idea
*  as well. So you like these cognitive functions, they're emergent phenomenon emergent properties
*  of this myriad, you know, connections and activity. And there's these multiplexing, there's all this
*  noise that's hopelessly complex, you know, and like you said, there's all these dark neurons,
*  and really super low firing and spontaneous neural activity. And one interpretation of that is that
*  single units then are meaningless, as far as looking at them to extract any information about
*  what's going on. And maybe they're epiphenomenal, as you just said. But on the other hand, the other
*  way to look at it is, isn't it insane that we can that we can actually see any modulation at the
*  single neuron level. And often that modulation is striking. And so I, you know, my background is,
*  I did a lot of work in frontal eye field where you had these single neurons that right before
*  the eye moves in a certain direction into its response field, you can hear it, and it just
*  zips up to a threshold. And this is a single neuron pretty reliably that does this trial in
*  and trial out. And, you know, there is variation. And you do average to tell a story and to compare
*  between trial conditions. But in that case, and there are exceptions to this as well,
*  I mean, you're averaging pretty similar ramp ups like each time. And it is striking then,
*  that's just another way to look at it, I think, is just to be impressed with how much information
*  you actually can sometimes get just from single neurons. Yeah, you're making a good point that,
*  because a lot of what we particularly talk about, but coding, we often think about
*  the information coming in. So we're talking about senses, of course. But if we take a view,
*  and as I work on motor systems too, I've done a lot of work, much of my career working on
*  base of ganglia, I looked at working on building a brain stem control of the spine. So when you
*  work backwards from the motor neurons in the spine, obviously, the motor neurons are sort of your
*  classic, these are the neurons that fire spikes, then you move a muscle. So that neuron fires,
*  that muscle is going to contract. Let's record those. Yeah, it's a really,
*  really beautifully simple one. Indeed, it was spinal motor neurons that gave us the
*  sigmoid in the first place for the AI networks. It's them who have the sigmoidal discharge curve
*  and cortical neurons don't. They have a more like a nonlinear power loss thing. And as you say,
*  you can work backwards from the spinal motor neurons or indeed from the neurons in the brain
*  stem controlling the eye muscles that are going to move the eyes. And those neurons, of course,
*  are going to be burst firing, that's going to make that muscle contract here to move the eye to one
*  side. And you work backwards from them to where they're getting their inputs from. So somewhere
*  else, in this case, in the brain stem, in the eye movement, especially from the superior colliculus,
*  and you can work backwards and up to the frontal layer fields. And you can see, okay, I can hold
*  this whole chain where I can just get spikes here, spikes here, spikes here, and it moves.
*  Yeah. Yes, it's a beautiful causal chain. So moving, you can see this beautiful causal chain,
*  but at the other end, you see this just mess. Well, that causal chain does get messier and
*  messier as you- Exactly, yes. So more and more things are controlling the eye movement eventually.
*  Because there is obviously some work on population coding in spinal cord. So
*  Runeberg in particular is doing a bunch of work in turtles recording hundreds of neurons
*  simultaneously in the spinal cord of turtles to show that there really is quite a bit of population
*  coding going on in spinal cord too. The dynamics are quite complex that you've got balanced activity
*  in the spinal cord. You've got these long tail distributions of activity, just as you see in
*  cortex, because you have these recurrent circuits with the interneurons and the motor neurons.
*  Right. So there may be, as it will turn out, motor neurons may be the only one that you can go,
*  when that fires, that means something, and backwards from there, it all gets a bit messy.
*  That would be unfortunate, but- It would. I mean, there's all that work in motor cortex,
*  right, about using dynamical state spaces to infer when a movement is actually being coded.
*  So it's not a ramp up, it's taking the whole population, looking at the reduction of the
*  variance toward, as you get closer and closer to a movement, and then the variance is eventually
*  just quashed and you make a movement or whatever. So interesting, different ways to look at it.
*  Yep. So maybe we could get onto, I don't know how much you want to talk about sort of
*  what I consider like the big idea in the brain that you talk about related to spontaneity
*  and evoked from sensory stimulation, neural activity versus this intrinsic spontaneous activity,
*  and the role it could play in predictive coding. Do you want to wax poetic about that for a moment?
*  Yeah, sure. We'll touch on that for a little bit. Yes. So in the books, so we get to the end of the
*  journey through the brain, and then I asked the reader to reflect back on the journey we just took.
*  It's important though that your character gets the cookie, right? So-
*  Yeah, that's exactly it. So you win. So your brain realizes how much energy it needs to carry on. So
*  obviously it's going to take the cookie to give it that, keep up with that 20% burn rate in the meeting.
*  So you got the cookie, sit back, satisfied as the star of the book and reader simultaneously.
*  I then invite you to then think back through the book and think that most of the times when we
*  sort of landed on a neuron on a spike, that neuron was already spiking. I'd already just sent a spike
*  down or we'd seen spikes come back past us the way we just come. And in fact, it appears that most
*  of the spikes in the brain are actually spontaneously created rather than created by the outside world,
*  either because there are particular classes of neurons that are able to generate their own
*  spikes from their input whatsoever, these kind of pacemaking neurons, which exist mostly in sort of
*  the midbrain and the brainstem. And then in cortex, you have these massive recurrent networks, which
*  is full of feedback loops. So you give it enough input and that activity will be sustained forever
*  as it reverberates around and around and around in these feedback loops. So it appears that most of
*  the spikes that we come across are not created by, in this case, the world, the scene in the office
*  in front of us, seeing this cookie in a box on a desk in front of you. That's kind of the feedforward
*  evoke stuff that's appearing and that's having an effect, but it's not clear what effect that is.
*  So the idea floated in the book is really that what most of the spontaneous spikes are doing
*  is they're solving the problem that spikes for all their wonderfulness are kind of a slow way
*  of processing information. And actually, we need to make decisions fast because making decisions
*  slowly, particularly in the most niches that animals live in, is a way of getting eaten or
*  failing to survive long enough to reproduce. So what I'm arguing in the book is that what
*  the spontaneous activity is there for is to solve this speed limit problem by essentially
*  is predicting what the incoming spike should already be. So there also exists sort of predictive
*  processing accounts of the brain, which are fairly sort of high level ideas of what the brain should
*  be doing, sort of normative models of in an ideal world, the brain should be doing this. When we look
*  going in down into the details of the spikes, we can see that there's this rich, dynamical brain
*  waiting there to act as this predictive machine. So that these spontaneous spikes then reverberating
*  around our so they give your easy example is always always his vision, are then they're
*  predicting what should be coming from the from the retina. So the spikes the retina is sending up into
*  the brain are standing for various edges and corners and parts of the visual world, elementary
*  elements of the world we can see before us. So in the in the book example is edges of the box,
*  the top of the cookie, all those edges of the desk, that kind of thing. But of course, your
*  your eye has already swept past this scene. So your brain already has a really good idea of what it is
*  you're looking at. So it's about to predict that there's an object on there, which is a cookie
*  shape of box shape. And that information is being fed backwards from the object areas in spikes
*  towards the early visual system bits to meet up with the spikes coming from the retina to essentially
*  see whether they agree or disagree. And all you need to know information is to come forward then
*  just like in predictive processing counts is whether there is something is wrong with that view to
*  change that view. And then that fits that sort of account conceptually fits beautifully with the
*  ideas. We take this sort of dynamical view of the brain, the every spontaneous activity is all this
*  these ongoing dynamics, then all the incoming spikes can do is change those ongoing dynamics,
*  they can just prod those into a different shape, it can't really drive them forward into a complete
*  entrain them to it to this itself, it's not like a feed forward network, all it can do is take this
*  ongoing activity swallowing around the brain and gently move into a different trajectory.
*  So from that point of view, it makes sense then that the information coming in from from your
*  various senses all it's doing is probably ongoing to with you into a different state,
*  saying is this is wrong or this is right, if it's wrong prod it up to something which is a bit
*  bit closer to what's going on in the world. And it's the difference that makes a difference.
*  Yes, yeah. It struck me that or it strikes me just now, I mean there so there are ways to
*  you know go into sensory deprivation so that you're not getting
*  incoming light, incoming visual signals, I mean you still get sort of proprioceptive signals from
*  your body I suppose but what is the way to cut off the predictive aspect? I mean,
*  you know the the top down aspect, there aren't experimental conditions where you can only
*  evoke sensory activity, I mean that's essentially turning off your brain if the predictive
*  processing account is right and there just wouldn't be a condition in which you could do that I suppose.
*  Yeah, I think you're right, yes. As you say, there are a number of experimental paradigms
*  which try and replicate that sort of sensory deprivation experience, right, there's trying
*  try and make normal humans hallucinate stuff so there's like auditory hallucination paradigms
*  where you play a tone that's barely the perception of the hearing, you also regulate it so the tone
*  is at an at volume that they can barely hear, flash a light at the same time as that tone,
*  and then keep flashing the lights, occasionally you don't actually play the tone and ask them to
*  report when the tone is being played and obviously normal people will happily report hearing the tone
*  a whole bunch of times that it was never there, so that they're able to, you can induce auditory
*  hallucinations because they're happily predicting that the tone is there when it is not, so that
*  you know something in their brain has said yeah there was a sound and clearly there has been no
*  feed-forward input whatsoever, but you're right, it would be somewhat more complicated to shut off
*  the the backward flowing information, although one would say given the rate that
*  systems neuroscience in invertebrates is going at the moment, one wouldn't say it's never going to
*  be impossible, one could imagine that if we end up roughly agreeing on this view of
*  if we're doing object recognition from top down for predictive processing count and we grab a
*  fairly good idea of where in the temporal lobe particular object types are represented
*  with a sufficiently powerful optogenetic approach, you could in theory shut that off that top level
*  and see whether that's going to affect the perception of and particularly generalization
*  of those kind of objects I guess, because obviously the idea being that you're feeding back
*  whether it's exactly that object you're looking at, you think you're looking at, so say you were
*  I mean maybe it's something like, say you keep getting exposed to simple squares right
*  and so that you're expecting that part of the brain to be able to and predicting squares,
*  you shut off that bit and but show it something which is like a rectangle or some smoothed square,
*  something which is your brain would say top down is not what the thing you've been looking at, but
*  top up has many properties of the square right, so maybe your decision there would be there,
*  that's definitely a square, when the actual response is supposed to be it's not a square
*  because it's morphed from the shape that you've been shown over and over again, so maybe yeah,
*  maybe there will be a way of that require a lot of obviously of predicting where you know where
*  the brain is storing this information, but approaches like Jim DiCarlo's where he's
*  training neural networks, deep neural networks to do sort of image recognition, finding the
*  sort of responses, response units on the top layer of that deep neural network and then finding those
*  back in V4 and the temporal lobe, then if you could then go into the you know, go in and turn
*  those off specifically, then you would have a really powerful way of testing the backwards
*  flow of information in the actual brain. Mark, this is so this is like wrapping up
*  our discussion about the book, hopefully this has given people a lot of different flavors of what
*  you talk about in the book, you know obviously there's a ton more in the book, but it's really
*  enjoyable, the joy of your writing also is just very apparent and it makes for a really fun read,
*  so nice job again on the book and I hope people check it out. Cool, thank you very much Paul.
*  All right, I have just three questions, three simple questions to end up on here. One, and the
*  background here is that you're really a theorist I suppose, although you work with plenty of
*  experimental data, but you do it in the guise of in the stead of theory and that's kind of maybe
*  that's irrelevant to the question, but the question is what's one of the best scientific
*  moments that you've had? Can you think about, you know, is there something that stands out in your mind?
*  Yeah, there's been a few, let me think, so one that's good to explain. So actually one, yeah, so I
*  now tell the world that what we do is kind of a neural data science, right, so we are
*  much of, we do is heavily theory informed and we're interested then in testing theories
*  using computational methods on data. The byline of your lab, on your lab website, I think is
*  we're a neural data lab, is that what? Yeah, that's right, yes, yeah, yeah, yeah, okay.
*  So in that context, so we had one of my sort of favorite moments, so obviously working quite a lot
*  on the C-slug-Aplissia with Bill Frost in Chicago and his grad student Angela Bruno,
*  and they have this fantastic setup where they're doing this voltage-sensitive die
*  imaging of the Aplissia's motor system, so they can record about 10% of the neurons in the motor
*  system simultaneously and get it at spike resolution. So it has, it marries the advantages
*  of calcium imaging where you can see each individual neurons, you know where they are,
*  but it's voltage imaging and it's at extremely high rates, so you can see all the individual spikes.
*  You actually touch on this in the book a little bit, the idea of the voltage,
*  the future of spike recordings, yeah. Yes, because having spent,
*  sort of now I am all blind, it's now what, seven, eight years working on this system with them,
*  the voltage imaging is obviously, it's just fantastic. I understand all the technical
*  limitations why it can't work so well in vertebrates, but in the last two years there's
*  been this dramatic improvement in the sort of both the genetically encoded and voltage
*  sensors and the dyes that are used in vertebrates to the extent there's been a raft of nature in
*  science papers in the last year and a half showing that this is really is coming of age now,
*  you can really record for a decent amount of time, individual neurons, voltage imaging them
*  in hippocampus and cortex in mice and see the individual spikes and with fingers crossed and a
*  good squinting at it, you can just about see occasionally the sort of potentials of the inputs
*  coming in to the soma. So to me that's going to be the big part of the future. Having worked on this
*  data in an invertebrate where the neurons are enormous so that it really works beautifully,
*  you know, if it really pans out on the trajectory then we're going to be seeing voltage imaging
*  everywhere I think. So yeah. So what was the moment? Yeah, it was, I mean not just,
*  once more moment just seeing this data for the first time because it's just glorious going.
*  So I have all these spikes and all these neurons and we know this most of the motor systems,
*  instead of seeing, you know, recording from prefrontal cortex and the rodent which is just
*  going to be 0.001% of the neurons just in that region of prefrontal cortex. It's like this is
*  almost everything. I think the big moment for me was just, I really just, so I really deep
*  interested in dynamic systems. So we had this, I did this piece of work whilst trying to figure out
*  how do I show, particularly to the satisfaction of, you know, just my collaborators who are
*  experimentalists, they're not, you know, computational people, how do I show to their
*  satisfaction? This is an attractor. The system they're looking at is an attractor, making
*  meaningful for them. So they go, instead of just going, oh yeah, that's a buzzword.
*  That this actually is a useful thing to know and a useful thing to be able to understand about
*  the system. So the whole piece of work where yesterday is recording these multiple recordings
*  from recordings were from three separate recordings from each animal of this system being evoked to
*  run away, to escape. I was able to show them that these population dynamics fitted all the
*  criteria of an attractor, particularly a spiral attractor. So an attractor where the dynamics
*  starts always from the same spontaneous activity when it's evoked, it goes up and falls nicely
*  onto the same trajectory each time and that trajectory is a spiral. So it's amplitude is
*  cycling around, but the amplitude is getting smaller and smaller and smaller as it goes on,
*  kind of coming back towards the starting state, but never quite gets there. And that was true
*  in every recording. So no matter how noisy, particularly, I was beautiful, but it was no
*  matter how noisy the recording was, how much like they went, you don't want this, it's a really bad
*  one. I said, no, no, give it to me. And I'll show you that it's there. So I can show them that even
*  these recordings were almost none of the neurons were firing this beautiful periodic burst, you
*  can still see underneath there was this spiral thing happening in the population. It was just
*  obviously really noisy. Got the preparation was, you know, whatever had gone wrong with it.
*  And then what was particularly lovely then is because they had three recordings from the same
*  animal, you could show that they each, the three ended up on the same trajectory each time they
*  converged, they were genuinely attracting. And by some beautiful accident, because this motor
*  system has in it various gaborotic interneurons, particularly one massive one occasionally fires
*  randomly in this preparation, there are pauses in the ongoing activities, you can see sort of all
*  these neurons are firing away. And there's this pause where some other neurons start firing and
*  it restarts again. So you get to over and over get to see the same trajectories. Yes, so you
*  get to see some trajectories, but also of course when this neuron fires, it means that it perturbs
*  the activity away from what it has been doing. And I could show every time it perturbs it,
*  it came right back to where it was supposed to be. So it had, it met all the criteria of what you
*  want an attractor to be. And so it happened, you know, a spiral in five or six dimensions instead
*  of this 110, 200 neurons, whatever it wants. And so, yeah, so one, it was showing that, yes,
*  I have shown to even my satisfaction, which is quite hard, that this thing is genuinely a spiral
*  attractor. This is a useful description of this system. That means that we understand how it works
*  because you poke it and it jumps into this state and that state is literally just driving the
*  crawling. Every loop around this spiral is one full loop of the crawl where the animal puts his
*  head forward and pulls itself back behind. And then each, and the parameters of the spiral,
*  so essentially how wide each of the spiral is, how fast it goes around it, how quickly it goes back
*  to the start, are properties of the crawl. So you could say, easily say, these three parameters
*  should probably control three separate parts of the crawling. Which would be predictions to go and
*  do in further experiments. So how were they affected by this? You finally got this across
*  to them, like that was important. And did it sink in? Is that what the... Yeah, I think, yes,
*  I think it sunk into it. They finally saw the value of the dynamical, of the attractor as a
*  tool of explanation. Yes, that is this low dimensional thing that we can describe it
*  in quantitative detail. So now that means that when we manipulate the system, we can describe
*  those manipulations in terms of that attractor and make predictions about what direction it should
*  move. So for example, when we put neuromodulators in the system, we already know what those
*  neuromodulators do to the behavior. So they must do a particular thing to the dynamics of the spiral
*  attractor. That's awesome. Sorry to bring you up and then I'm going to take you down. What about
*  sometime that some failure that you've had or some disillusionment that you've felt in your career
*  and then how you got through it? This is supposed to be for people struggling in their graduate
*  school days or this is supposed to let them feel like, oh, this happens to everybody. So
*  that's why I'm asking you the question, not to bring you down.
*  Okay. That was a fair question. Obviously, there have been a few. So particularly I'll talk about
*  the PhD one because that's the one I'm obviously most relevant and it's the one I talk about most
*  when I talk to early career researchers to talk about this one. So my PhD was on building
*  computational models of the Bayes of Ganglia and inside that circuit, there is a feedback loop
*  between two structures, one called the subclimate nucleus, one called the Globus pallidus and it's
*  a negative feedback loop. So you have a one positive connection, one negative connection.
*  So you have this beautiful negative feedback loop, which is self-sustabilizing because as soon as one,
*  if you drive the excitation up, then you get more inhibition to it. It turns down excitation,
*  you drive the inhibition up, you move the excitation, the inhibition goes down. So it's
*  this nice, something that engineers love to see in a system is this beautiful negative feedback loop.
*  So I obviously built a bunch of different models with this thing in and it was after my
*  funding had run out on the PhD, it's a UK PhD, so it's three years of funding.
*  And I'd gone, I was supposed to be handing in, so I was writing up some results and checking the
*  code of one of the main models I was using. And I had discovered that in my code, I had hard
*  coded the connection sign and I had put them as both positive. So my model had this blowing up
*  feedback, excitation feedback looping, so there's negative feedback loop. So all the results of,
*  I think, two chapters had to go in the bin of the five chapter thesis after my funding had finished.
*  Simple coding error.
*  Yeah, so a simple coding error that has now formed the basis of how I approach coding.
*  Oh, I bet. How did you get over it? I mean, did you just move on? And well, I guess that's,
*  I mean, obviously lesson learned, but it must have been pretty devastating.
*  Yeah, so it was really hard for a week of being quite miserable about this, but realizing that,
*  okay, because I was thinking about how much time I had spent in building these models and how long
*  it had taken. But I was realizing, well, I think that's when I really realized about that,
*  when most of the time when you're doing science, all the time it's taken up when you don't know
*  what you're doing. So you spend all this time, you don't know what you want to do next, how you're
*  going to measure this thing, how you're going to make this thing work, how you're going to do this,
*  how you're going to do this. And then all I had to do now was do it the second time. I knew how
*  everything worked. I'd done all the code. All I had to do was I'd done all the graphs even. All
*  I had to do was reproduce. You know, redo the simulations with the right thing, check all the
*  results. I had all the analysis all set up. All I really needed to know was did it make a big
*  difference to the results? So that really helped me sort of focus then so I could obviously have a
*  nice very structured to do list of fix that and run this, this, this, this, this, this, over and
*  over again, the list of things to do and then just grind through it. So that's, that's what I did.
*  So you fixed the code, rewritten it all, checked everything, rewrote two chapters of the thesis.
*  Then as it turned out that actually that momentum meant I finished the thesis writing really fast
*  because I'd written, worked so hard to fix this problem that I then I finished the wrote the next
*  two chapters and wrote the discussion and it was done. So it was, it was a, as well as a coding
*  lesson, it was also a lesson in thinking, realizing that much of what you think is a time
*  sync, time sync in science is often about, yeah, when you just finding your way. But if you know
*  what you're doing moment to moment, then you can get through it much faster.
*  Does that happen? Does that continue to happen throughout your career? Like the, for me in my
*  kind of short career, that continued to happen where I realized the entirety of the past three
*  years, I had no idea what I was doing and was building up to get to the point where I'm right
*  now. And then a couple of years down the road, I realized I didn't have any idea what I was doing,
*  but was very valuable to getting to the point where I know right now what I'm doing, you know,
*  and that that recurred over and over. Does that keep going?
*  To an extent? Yeah. Yeah. You keep reevaluating, you know, particularly reevaluating your sort of
*  priorities and the way you're approaching certain projects and keep refreshing the
*  month must be a better way of doing this and spending like six months hacking about a couple
*  of graphs. So nothing is really sunken cost in that respect or a lot most of what you're actually
*  doing that may feel like sunken cost, I suppose isn't as valuable in retrospect.
*  Yeah, it often is. Yeah. Lastly, Mark, what would you do differently if you had to,
*  or maybe not even necessarily what would you do differently, but if you had to start your career
*  over, not back then, but now if you were starting as a, you know, thinking about going
*  going to graduate school or early in your graduate school career, what would you do,
*  you know, differently, if anything, or how would you proceed?
*  Very practical answer to that question, which is I would take some,
*  some serious courses in linear algebra. Oh, I've gotten that answer too. Yeah, that's,
*  I think that as well. Yeah, because I so yeah, so I'm a, I'm a computational neuroscientist who
*  feels a bit of an imposter because my math is terrible. So I mean, my undergraduate degree was
*  in cognitive science. So we did some we did discrete maths, we did a lot of graph theory and
*  logic and stuff. And I did, I took some, some, you know, undergrad classes in calculus when I
*  started my PhD, but didn't touch linear algebra. So I haven't done anything with vectors. I did it,
*  I finished, you know, did last at school. So not being able to pry open the box of the whole
*  matrix algebra toolkit, even the linear bit, as proven challenging, taking well,
*  obviously doing a lot of data analysis and working endlessly now with with dimension reduction
*  techniques that are beautifully simple written out as linear algebra, trying to explain them
*  any other way is a nightmare. Just go no, just the matrix decomposed like this. Oh, okay, I see that.
*  Yeah. So yes, so proactively, yeah, linear algebra.
*  I think the earlier you get that the better too, especially just because it's,
*  it's really counter, not counterintuitive. It's hard to intuitively grasp, I think it really takes
*  a lot of time swimming in that world to feel comfortable with it in my experience anyway.
*  And I'm not not I'm not even saying that I'm comfortable, just I'm to the point where I can
*  see, okay, that could become comfortable. Yeah. Well, thanks, Mark. So I, you know, good luck
*  with the book. Congratulations on I know it's now it's late, because it's like a year,
*  delayed congratulations, but you're going to be hearing this a lot, I suppose. And if this so
*  this episode should air, the book will be out. So everyone should should run and grab it and
*  grab hold of the spike with Mark on your back whispering sweet nothings about brains in your
*  ear as you as you travel through the brain. So thanks for spending the time with me,
*  Mark and continued success, man. Thank you. Thank you very much.
*  Brain inspired is a production of me and you. I don't do advertisements, you can support the
*  show through Patreon for a trifling amount and get access to the full versions of all the episodes,
*  plus bonus episodes that focus more on the cultural side but still have science. Go to
*  brain inspired.co and find the red Patreon button there. To get in touch with me, email
*  paul at brain inspired.co. The music you hear is by the New Year. Find them at the new year.net.
*  Thank you for your support. See you next time.
*  Bye.
