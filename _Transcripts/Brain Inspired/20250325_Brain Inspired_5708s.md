---
Date Generated: March 26, 2025
Transcription Model: whisper medium 20231117
Length: 5708s
Video Keywords: []
Video Views: 140
Video Rating: None
Video Description: Gabriele Scheler discusses her theoretical neuroscience work, understanding the link between cognition and verbal thought, and making a new type of neuron model to improve artificial intelligence.

Show notes:  https://braininspired.co/podcast/208/

Patreon (full episodes and Discord community:  https://www.patreon.com/braininspired

Apple podcasts:  https://itunes.apple.com/us/podcast/brain-inspired/id1428880766?mt=2
Spotify:  https://open.spotify.com/show/2UZj8c8Ap5oc2gh2rJxLLe

The Transmitter is an online publication that aims to deliver useful information, insights and tools to build bridges across neuroscience and advance research. Visit thetransmitter.org to explore the latest neuroscience news and perspectives, written by journalists and scientists. 

Read more about our partnership: https://www.thetransmitter.org/partners/

Sign up for the “Brain Inspired” email alerts to be notified every time a new “Brain Inspired” episode is released: https://www.thetransmitter.org/newsletters/

To explore more neuroscience news and perspectives, visit thetransmitter.org.

Gabriele Scheler co-founded the Carl Correns Foundation for Mathematical Biology. In fact, Carl Correns was her great grandfather, one of the early pioneers in genetics. Gabriele is a computational neuroscientist, whose goal is to build models of cellular computation, and much of her focus is on neurons.
We discuss her theoretical work building a new kind of single neuron model. She, like Dmitri Chklovskii a few episodes ago, believes we've been stuck with essentially the same family of models for a neuron for a long time, despite minor variations on those models. The model Gabriele is working on, for example, respects the computations going on not only externally, via spiking, which has been the only game in town forever, but also the computations going on within the cell itself. Gabriele is in line with previous guests like Randy Gallistel, David Glanzman, and Hessam Akhlaghpour, who argue that we need to pay attention to how neurons are computing various things internally and how that affects our cognition. Gabriele also believes the new neuron model she's developing will improve AI, drastically simplifying the models by providing them with smarter neurons, essentially.

We also discuss the importance of neuromodulation, her interest in wanting to understand how we think via our internal verbal monologue, her lifelong interest in language in general, what she thinks about LLMs, why she decided to start her own foundation to fund her science, what that experience has been like so far. Gabriele has been working on these topics for many years, and as you'll hear in a moment, she was there when computational neuroscience was just starting to pop up in a few places, when it was a nascent field, unlike its current ubiquity in neuroscience.

0:00 - Intro
4:41 - Gabriele's early interests in verbal thinking
14:14 - What is thinking?
24:04 - Starting one's own foundation
58:18 - Building a new single neuron model
1:19:25 - The right level of abstraction
1:25:00 - How a new neuron would change AI
---

# BI 208 Gabriele Scheler: From Verbal Thought to Neuron Computation
**Brain Inspired:** [March 25, 2025](https://www.youtube.com/watch?v=MMirmqzjAWk)
*  I mean, there is this still unexplained in current neuroscience enormous increase of [[00:00:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=0.0s)]
*  cortical capacity in humans and the obvious explanation would be a language. [[00:00:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=10.16s)]
*  We don't even understand how the neurons work together to create grammatical sentences [[00:00:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=19.44s)]
*  and so on. [[00:00:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=26.6s)]
*  And this is something that we can find out and this is important, but that doesn't mean [[00:00:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=28.0s)]
*  that we now can build an automaton which does exactly the same thing and that this automaton [[00:00:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=32.72s)]
*  is then the same as us, so to speak. [[00:00:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=40.0s)]
*  If you have the building blocks from the brain, if you can build it like a brain, then we [[00:00:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=47.52s)]
*  should at least be able to get away from these absolutely huge and wasteful essentially dumb [[00:00:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=52.44s)]
*  huge models. [[00:01:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=61.4s)]
*  This is Brain Inspired, powered by the transmitter. [[00:01:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=70.75999999999999s)]
*  Hi everyone, it's Paul. [[00:01:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=74.03999999999999s)]
*  Welcome to Brain Inspired. [[00:01:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=75.75999999999999s)]
*  Gabrielle Scheller co-founded the Carl Correns Foundation for Mathematical Biology. [[00:01:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=77.6s)]
*  In fact, Carl Correns was her great-grandfather, great-great-great, I can't remember, you'll [[00:01:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=84.47999999999999s)]
*  hear from her, and he was one of the early pioneers in genetics. [[00:01:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=90.96s)]
*  Gabrielle is a computational neuroscientist whose goal is to build models of cellular [[00:01:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=95.28s)]
*  computation, and much of her focus is on neurons. [[00:01:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=100.52s)]
*  When we discuss her theoretical work, building a new kind of single neuron model, so she, [[00:01:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=105.04s)]
*  like Dmitri Shiklovsky a few episodes ago, believes that we've been stuck with essentially [[00:01:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=112.28s)]
*  the same family of models for a neuron for a long time, despite minor variations on those [[00:01:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=117.36s)]
*  models. [[00:02:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=123.36s)]
*  The model Gabrielle is working on, for example, respects the computations going on not only [[00:02:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=124.88s)]
*  externally via spiking, which is the traditional way models are built, and the only game in [[00:02:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=130.88s)]
*  town forever, but she also wants to respect the computations going on within the cell [[00:02:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=136.07999999999998s)]
*  itself, within the cell membrane, and then even down within the nucleus. [[00:02:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=141.6s)]
*  So this is in line with previous guests on Brain Inspired, like Randy Gallistol, David [[00:02:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=147.35999999999999s)]
*  Glansman, and Hesam Akhlaqpour, who argue that we need to pay attention to how neurons [[00:02:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=152.04s)]
*  are computing various things internally and how that affects our cognition. [[00:02:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=157.12s)]
*  Gabrielle also believes the new neuron model she's developing will improve AI, drastically [[00:02:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=162.76s)]
*  simplifying the models by providing them with smarter neurons, essentially. [[00:02:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=168.36s)]
*  So we eventually get to talking about that work on the single neuron, but we also discuss [[00:02:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=173.3s)]
*  things like the importance of neuromodulation, her interest in wanting to understand how [[00:02:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=179.64s)]
*  we think via our internal verbal monologue. [[00:03:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=185.04000000000002s)]
*  So connecting the language that we hear, essentially, in our minds with the process of thinking. [[00:03:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=189.56s)]
*  We talk about her lifelong interest in language in general, what she thinks about large language [[00:03:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=196.04000000000002s)]
*  models, why she decided to start her own foundation to fund her science, and what that experience [[00:03:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=200.92000000000002s)]
*  has been like so far. [[00:03:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=207.84s)]
*  So Gabrielle has been working on these topics for many years, and as you'll hear in a moment, [[00:03:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=209.60000000000002s)]
*  she was there when computational neuroscience was just starting to pop up in a few places, [[00:03:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=214.2s)]
*  when it was a nascent field, unlike its current ubiquity in neuroscience. [[00:03:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=220.17999999999998s)]
*  So you can find the links to Gabrielle's work in the show notes at braininspired.co slash [[00:03:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=224.7s)]
*  podcast slash 208. [[00:03:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=229.35999999999999s)]
*  By the way, you may be listening to this in Montreal right now. [[00:03:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=234.04s)]
*  If you're at Cosine, I wish I was there with you. [[00:03:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=238.28s)]
*  However, my name is on a poster there, so you should swing by and say hi to Aidan and [[00:04:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=241.92s)]
*  Eric, my colleagues in crime, and check out our research. [[00:04:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=247.44s)]
*  And I hope you're having a good time at Cosine. [[00:04:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=251.92s)]
*  I hope that you are well, and I hope you enjoy my discussion with Gabrielle. [[00:04:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=254.07999999999998s)]
*  So I vaguely remember when I became interested in the neurosciences, the cognitive sciences. [[00:04:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=261.08s)]
*  Like many people, I wanted to understand consciousness, subjective experience. [[00:04:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=269.12s)]
*  But you have a slightly different interest that drove you into it. [[00:04:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=275.08s)]
*  You wanted to understand how we think and how we speak. [[00:04:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=278.88s)]
*  Is that correct? [[00:04:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=282.78000000000003s)]
*  That's right. [[00:04:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=283.78000000000003s)]
*  I mean, I wanted to understand how we think and the sense of this verbal thought in a [[00:04:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=284.78000000000003s)]
*  monologue or so that some people produce more or less of. [[00:04:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=289.2s)]
*  I produced a lot of it. [[00:04:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=294.12s)]
*  I was very introspective, and I wondered what is going on in my brain that I have these [[00:04:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=296.28s)]
*  sort of conversations with myself. [[00:05:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=302.88s)]
*  So you don't equate thinking with that internal monologue. [[00:05:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=305.2s)]
*  That's just the facet of thinking that you're interested in? [[00:05:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=311.03999999999996s)]
*  Exactly. [[00:05:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=313.91999999999996s)]
*  I wouldn't say there's no other way of thinking. [[00:05:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=314.91999999999996s)]
*  There's certainly pre-verbal thought. [[00:05:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=316.64s)]
*  It's very important. [[00:05:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=318.96s)]
*  And some people suggest that they actually think very explicitly in visual images. [[00:05:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=320.36s)]
*  It plays a role, but so there are differences. [[00:05:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=327.16s)]
*  But there's no doubt that all of us at times use internal speech or in a monologue. [[00:05:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=330.52000000000004s)]
*  And certainly also when we speak, we all speak and explain something that is going on in [[00:05:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=337.36s)]
*  our head. [[00:05:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=343.64s)]
*  So I don't want to just get into sex differences right off the bat, but is it true? [[00:05:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=346.0s)]
*  I mean, are there more proportionately males who think visually and females who think in [[00:05:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=352.32s)]
*  language? [[00:05:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=359.96s)]
*  Am I off base there? [[00:06:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=360.96s)]
*  Okay, yeah. [[00:06:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=363.36s)]
*  But you have a high rate of internal thinking. [[00:06:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=364.84s)]
*  You used pre-verbal to categorize other thought. [[00:06:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=367.36s)]
*  Is there post-verbal? [[00:06:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=371.64s)]
*  No, I think it is more that when we speak or when we require the ability for inner monologues [[00:06:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=373.28s)]
*  at some point in our lives, often only around the age of six or so, even though we can usually [[00:06:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=383.71999999999997s)]
*  speak by the age of three, so that is also a process where we start to internalize it. [[00:06:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=391.08s)]
*  But we use it for thinking. [[00:06:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=397.32s)]
*  We use it in trying to solve a problem. [[00:06:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=399.56s)]
*  We begin to speak and say, oh, I should probably do this or something. [[00:06:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=403.15999999999997s)]
*  There is some, I think verbal thought is really very important and very central for our experience [[00:06:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=410.84s)]
*  as humans. [[00:06:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=417.8s)]
*  It is not some additional extra that you can leave out. [[00:06:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=419.92s)]
*  I had a small conversation with Jan De Kern about it because he thought cats are fine [[00:07:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=425.56s)]
*  as a model. [[00:07:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=431.52s)]
*  If artificial intelligence, as I would define it, is an attempt at modeling human intelligence, [[00:07:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=434.28s)]
*  then no way, because it is really the case that children who in the past who could not [[00:07:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=440.8s)]
*  hear, when you don't stimulate them sufficiently early about language, they really have a deficiency [[00:07:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=453.11999999999995s)]
*  in their intellect in some way and that's why people have learned to do this very early. [[00:07:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=464.32s)]
*  It is important, I think, for our internal organization of our thoughts, the ability [[00:07:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=471.15999999999997s)]
*  to resort to symbols and then do symbol manipulation, which is why I think there is also, I think [[00:07:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=477.65999999999997s)]
*  Piaget and Zygotsky and people like that have found that you need object manipulation skills [[00:08:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=487.9s)]
*  in order to learn grammatical sentences because that is what you are doing. [[00:08:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=495.85999999999996s)]
*  You are manipulating symbols, attaching them together, doing them apart, building an actual [[00:08:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=503.94s)]
*  sentence like you would build something out of stones. [[00:08:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=512.8199999999999s)]
*  So all these abilities come together there and I don't think it's so mysterious anymore. [[00:08:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=517.98s)]
*  You asked me about this upfront, whether I think that we could understand human language [[00:08:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=524.02s)]
*  and from my perspective, yes, I would say we can, we are close, we can understand it [[00:08:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=530.66s)]
*  pretty well. [[00:08:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=535.38s)]
*  It's not much more difficult than odor recognition. [[00:08:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=536.38s)]
*  For instance, flies can do, they get all these odor runs and then we understand in their [[00:09:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=540.06s)]
*  brain how it goes through the different neural areas, like antenna lobe and the mushroom [[00:09:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=546.54s)]
*  bodies where you have these sparse coding. [[00:09:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=556.3s)]
*  And so we can understand how out of this odor environment they build sort of their own world [[00:09:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=562.42s)]
*  of odor, so to speak, which then influences their behavior. [[00:09:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=572.82s)]
*  Of course, language is more complicated, but it has this mechanical aspect. [[00:09:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=577.22s)]
*  Do you ever have this experience though? [[00:09:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=584.02s)]
*  I have this experience over and over where I will be thinking about something and a sentence [[00:09:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=585.42s)]
*  about that thing will pop into my head and I will think, that is so stupid that I'm using [[00:09:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=592.2199999999999s)]
*  language to think about this. [[00:09:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=599.0999999999999s)]
*  It doesn't buy me anything. [[00:10:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=600.9399999999999s)]
*  And in fact, sometimes it gets in the way. [[00:10:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=602.26s)]
*  I'm restricted by it. [[00:10:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=605.42s)]
*  Yeah. [[00:10:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=606.42s)]
*  Do you ever have that experience? [[00:10:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=607.42s)]
*  Well, actually, interesting for me, language is actually has been very, I've used it differently. [[00:10:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=608.42s)]
*  It's more empowering, I would say. [[00:10:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=615.9399999999999s)]
*  It leads me sometimes from one thought to the next or a certain thought pops up, which [[00:10:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=618.18s)]
*  I cannot name, but as I think about it, I can begin to put it into words for myself. [[00:10:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=625.4599999999999s)]
*  Plus, the good idea is once I have articulated it in words, I don't even know how many people [[00:10:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=631.78s)]
*  have this, I can better remember it. [[00:10:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=638.62s)]
*  Oh yeah, sure. [[00:10:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=642.02s)]
*  Yeah. [[00:10:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=643.54s)]
*  It's almost like collapsing the wave function, right? [[00:10:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=644.9s)]
*  It's like not a real thought until you put it into words. [[00:10:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=647.26s)]
*  And then because of that symbolic abstract nature of it, then you can kind of from afar [[00:10:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=649.98s)]
*  look at it anew in a new light. [[00:10:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=655.2199999999999s)]
*  I guess that's why when people say writing things down helps them think about it because [[00:10:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=657.4599999999999s)]
*  it concretizes some idea that you had that was vague. [[00:11:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=663.6999999999999s)]
*  And then that can, I think, even change your own thinking. [[00:11:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=667.26s)]
*  Yes, it helps with your memory. [[00:11:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=669.8199999999999s)]
*  It helps with the memory. [[00:11:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=671.8199999999999s)]
*  Also internal memory. [[00:11:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=672.8199999999999s)]
*  That was the point I was making that I believe as humans we have organized our brains, especially [[00:11:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=674.1s)]
*  our cortex, very much according to language and symbolic principles. [[00:11:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=683.62s)]
*  And that is probably very different. [[00:11:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=689.0600000000001s)]
*  I mean, there is this still unexplained in current neuroscience enormous increase of [[00:11:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=690.58s)]
*  cortical capacity in humans. [[00:11:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=697.3000000000001s)]
*  And the obvious explanation would be language. [[00:11:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=699.86s)]
*  Because that's what we develop. [[00:11:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=704.62s)]
*  And as we develop language, our cortices are bigger and bigger and bigger as if we suddenly [[00:11:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=706.1800000000001s)]
*  can use all that memory, which you can't use. [[00:11:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=712.0200000000001s)]
*  You have to access it. [[00:11:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=716.7s)]
*  And in order to access it, it's probably structured and audited, I think, with help of symbols. [[00:11:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=718.5s)]
*  And it's like a hash table or so into your memory. [[00:12:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=724.5s)]
*  Yeah. [[00:12:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=731.6600000000001s)]
*  And that's, of course, since you had the topic, current AI doesn't do that. [[00:12:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=732.66s)]
*  What do you mean? [[00:12:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=739.14s)]
*  Elaborate on that. [[00:12:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=740.14s)]
*  Current AI does not build a structure, build of symbols which references into complex theories [[00:12:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=741.14s)]
*  or forms. [[00:12:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=752.42s)]
*  Okay. [[00:12:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=753.42s)]
*  Maybe we'll, yeah. [[00:12:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=754.42s)]
*  So we'll come back to the AI because, yeah. [[00:12:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=755.42s)]
*  So we'll come back to the AI and large language models, which I know you're interested in. [[00:12:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=759.5s)]
*  One more random thought about language. [[00:12:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=765.0600000000001s)]
*  I was asking, so my son is 10, my daughter's 12, and we were driving around. [[00:12:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=768.1s)]
*  And I'm frequently bothered when I see advertisements, for example. [[00:12:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=774.14s)]
*  What is the name of this phenomenon where you cannot not read something when you see [[00:12:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=779.26s)]
*  it? [[00:13:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=784.34s)]
*  It's like language capture. [[00:13:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=785.34s)]
*  What is the name of that? [[00:13:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=786.34s)]
*  Oh, yeah. [[00:13:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=787.34s)]
*  I don't know the word either. [[00:13:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=788.34s)]
*  I only know that it's interesting for bilingual like me. [[00:13:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=789.34s)]
*  I cannot shut this off in German, but I can shut it off in English. [[00:13:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=793.1s)]
*  Oh. [[00:13:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=797.34s)]
*  What do you mean? [[00:13:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=798.34s)]
*  I can actually watch an English movie and decide not to listen, not to understand the [[00:13:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=799.34s)]
*  words, just listen to the sounds. [[00:13:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=804.58s)]
*  Oh, that's verbal. [[00:13:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=806.7800000000001s)]
*  I was thinking visual, but you're saying it happens verbally, too. [[00:13:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=808.14s)]
*  I can decide just let them speak and not listening into what they are saying. [[00:13:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=812.34s)]
*  That's like the entirety of my listening experience in any language. [[00:13:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=820.4200000000001s)]
*  Come on. [[00:13:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=823.4200000000001s)]
*  Yeah. [[00:13:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=824.4200000000001s)]
*  I can choose to understand or simply listen to the sounds, but I cannot do this in German. [[00:13:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=825.4200000000001s)]
*  It's probably too deeply in brain problem. [[00:13:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=830.58s)]
*  Okay. [[00:13:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=833.5400000000001s)]
*  So you had that early interest in understanding how we think specifically in our language capacity, [[00:13:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=834.5400000000001s)]
*  but have you kept the same sort of worldview? [[00:14:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=842.14s)]
*  What I wanted to ask you is, what is thinking? [[00:14:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=845.66s)]
*  Because my conception of thinking has changed over time. [[00:14:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=847.98s)]
*  Have you kept that the same sort of conception about how to go about thinking about thinking? [[00:14:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=851.46s)]
*  Yeah. [[00:14:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=856.5s)]
*  Well, yeah, that's actually no. [[00:14:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=857.5s)]
*  My original idea was simply I want to understand it from a scientific point of view. [[00:14:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=859.34s)]
*  To me, that is mechanical and mathematical. [[00:14:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=865.78s)]
*  What has changed a bit is after a couple of years with my 30s or so, I became, I wondered [[00:14:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=870.78s)]
*  about the spiritual side of human experience. [[00:14:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=880.4599999999999s)]
*  And that was already the time when the machine translation was on the horizon. [[00:14:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=883.9s)]
*  And of course, you could use a synthesizer to create a violin and all these things, all [[00:14:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=890.26s)]
*  this artificial was already in the air. [[00:14:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=896.74s)]
*  And so people asked themselves, me too. [[00:15:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=901.46s)]
*  And I came to the conclusion that even though we can rebuild all these experiences and we [[00:15:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=903.46s)]
*  can mechanically analyze it, and that is also very useful for us in many ways, especially [[00:15:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=912.3s)]
*  in medicine, we do not capture sort of the essence of what is going on, something else. [[00:15:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=918.9s)]
*  And I said you can link it to subatomic physics or whatever it is. [[00:15:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=926.66s)]
*  It certainly is against, I mean, the mechanical account from the physical point of view, that's [[00:15:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=932.5799999999999s)]
*  Newtonian. [[00:15:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=939.2199999999999s)]
*  So that is really a 70th century. [[00:15:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=940.26s)]
*  But in terms of, as I said, in language and the thought, we don't even have that. [[00:15:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=944.18s)]
*  You don't even have a mechanical Newtonian account for it. [[00:15:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=949.3399999999999s)]
*  Now, I think it's two different things. [[00:15:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=954.4200000000001s)]
*  And if we have that, that's fine. [[00:15:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=956.82s)]
*  That is a scientific point of view. [[00:15:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=959.7s)]
*  And if somebody has an illness, if something is broken, if somebody has an aphasia or a [[00:16:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=962.1s)]
*  dementia or whatever, that is important. [[00:16:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=967.78s)]
*  But it is not the essence of who we are, how we communicate. [[00:16:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=970.5s)]
*  All these spiritual sort of extra is, I think, not, that is not all, so to speak. [[00:16:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=977.86s)]
*  When I was young, I wasn't even thinking about whether there could be a dichotomy between [[00:16:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=986.66s)]
*  this. [[00:16:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=990.58s)]
*  But once you've explained it in a scientific way, that's what it is. [[00:16:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=991.46s)]
*  There's nothing else. [[00:16:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=994.66s)]
*  So but that has not really changed your approach necessarily, just how you think about it. [[00:16:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=996.1s)]
*  Exactly. [[00:16:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1001.22s)]
*  For the science, I think it makes no difference. [[00:16:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1002.5s)]
*  It makes no difference, as I said, because we are so, so far behind. [[00:16:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1005.38s)]
*  We don't even understand how the new ones work together to create grammatical sentences [[00:16:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1013.2199999999999s)]
*  and so on. [[00:17:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1020.5s)]
*  And this is something that we can find out. [[00:17:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1021.86s)]
*  And this is important. [[00:17:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1023.9399999999999s)]
*  But that doesn't mean that we now can build an automaton which does exactly the same thing. [[00:17:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1024.98s)]
*  And that this automaton is then the same as us, so to speak. [[00:17:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1031.94s)]
*  It will remain an automaton which is mimicking certain aspects of our thought process. [[00:17:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1039.3s)]
*  That is the difference. [[00:17:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1046.02s)]
*  You see, that's the difference. [[00:17:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1048.3400000000001s)]
*  And as I said, this is in contrast to people like that who seem to think once they have [[00:17:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1050.5800000000002s)]
*  an automaton, once they have a mechanical device, which produces pretty much what a [[00:17:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1055.94s)]
*  human produces, then the human is not different from this device. [[00:17:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1060.74s)]
*  And yeah, I even I came across Hinton the other day saying that it's already conscious. [[00:17:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1065.3s)]
*  And yeah, come on, guy. [[00:17:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1071.78s)]
*  Yeah, but I mean, it's what is understandable to me is when you go very deeply into it, [[00:17:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1075.14s)]
*  I already had said Trump, deep person is a deep personalization effect. [[00:18:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1080.66s)]
*  I think it's called in psychology. [[00:18:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1086.34s)]
*  When you suddenly have the idea that you're that all everybody around you is some kind [[00:18:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1088.42s)]
*  of automaton. [[00:18:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1093.8600000000001s)]
*  So yeah, yeah. [[00:18:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1094.9s)]
*  And I think it must have that problem that what yeah, well, if you can explain everything, [[00:18:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1096.66s)]
*  then you don't understand that other people are actually still people and not, [[00:18:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1102.98s)]
*  let's say, in the aisle. [[00:18:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1108.5s)]
*  So so I think it is a psychological problem if you mix these things up. [[00:18:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1109.8600000000001s)]
*  Yeah. [[00:18:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1115.0600000000002s)]
*  So I mean, I like that you maintain that distinction because we live, our modern [[00:18:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1115.38s)]
*  scientific world is very mechanistic. [[00:18:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1121.7s)]
*  It is like the machine metaphor. [[00:18:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1124.2600000000002s)]
*  So as soon as we've explained it in those mechanistic scientific terms, that's all there [[00:18:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1125.6200000000001s)]
*  is. [[00:18:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1130.3400000000001s)]
*  But you go beyond that. [[00:18:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1130.66s)]
*  It's just you're content with the idea that that is the best way to explain it scientifically. [[00:18:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1132.42s)]
*  Exactly. [[00:18:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1137.5400000000002s)]
*  Yeah. [[00:18:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1138.2600000000002s)]
*  But it leaves out. [[00:18:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1138.42s)]
*  But science is not everything. [[00:18:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1139.3000000000002s)]
*  So it's exactly. [[00:19:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1140.5800000000002s)]
*  But science can be very, very useful and helpful in many ways. [[00:19:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1142.26s)]
*  No, no questions. [[00:19:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1145.22s)]
*  Much better to know mechanically what is going on than to simply know nothing at all. [[00:19:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1146.5s)]
*  All right. [[00:19:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1152.74s)]
*  So I was going to bring this up later, but let's go ahead and talk about it because you [[00:19:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1153.06s)]
*  have taken an alternative kind of path thus far. [[00:19:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1156.26s)]
*  Well, maybe it didn't start off alternative, but at some point, you would you say that [[00:19:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1160.18s)]
*  you're out of it? [[00:19:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1165.94s)]
*  Did you leave academia? [[00:19:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1166.82s)]
*  I don't know how to phrase this exactly. [[00:19:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1168.1s)]
*  We could see it as an academic nonprofit institution. [[00:19:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1169.7s)]
*  But I was in a way more or less trying to recreate what I understood by academia. [[00:19:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1174.82s)]
*  And also, I would say how it started with me personally, because I think the world has [[00:19:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1180.66s)]
*  changed in that respect. [[00:19:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1185.94s)]
*  When I was a student, there was a lot more freedom and independence. [[00:19:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1188.26s)]
*  And when was this? [[00:19:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1193.38s)]
*  Tell the listeners when this was and where it was. [[00:19:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1195.06s)]
*  Oh, that was in Munich. [[00:19:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1196.98s)]
*  And actually, I had by chance obtained a job at a computer science company, digital equipment. [[00:19:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1199.78s)]
*  They don't exist anymore. [[00:20:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1208.9s)]
*  At the time, they had money. [[00:20:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1210.26s)]
*  And so I got a freelance position trying to do natural language processing. [[00:20:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1212.02s)]
*  And the guy who hired me was himself a linguist. [[00:20:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1219.06s)]
*  And so we understood each other well. [[00:20:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1222.74s)]
*  And for a year and a half, they would just give me a computer, you know, and Lisp and [[00:20:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1225.38s)]
*  Prologue and do something with it. [[00:20:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1231.8600000000001s)]
*  And at some point, he actually showed it to his boss because he thought what I had achieved [[00:20:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1234.18s)]
*  was quite good. [[00:20:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1238.5800000000002s)]
*  And it was very nice, but he never came back to it. [[00:20:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1239.7800000000002s)]
*  And so with that experience, I then went to the to the old professor in logic. [[00:20:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1243.46s)]
*  He was actually a physicist whom I liked very much and asked him if I could do my [[00:20:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1250.42s)]
*  dissertation on this because up to that point, I hadn't used a computer. [[00:20:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1254.5s)]
*  They gave me a computer and I taught myself Lisp and Prologue and also some language [[00:20:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1259.62s)]
*  Prologue. [[00:21:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1266.34s)]
*  And then I pieced things together. [[00:21:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1266.9s)]
*  What year about was that? [[00:21:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1269.22s)]
*  Very nice experience. [[00:21:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1271.06s)]
*  I was actually paid for that. [[00:21:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1272.82s)]
*  About what year was this? [[00:21:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1276.42s)]
*  Oh, that was between 1986 and 1989. [[00:21:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1278.02s)]
*  OK, so computers were still pretty early on. [[00:21:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1282.66s)]
*  It was early on and I was happy about and I can actually actually say something in terms [[00:21:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1285.8600000000001s)]
*  of feminism at this point, because I really loved the computer experience. [[00:21:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1291.5400000000002s)]
*  I had also this experience as a young woman at that time in Munich in logic, in the math [[00:21:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1296.74s)]
*  classes, that people wouldn't listen to me. [[00:21:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1302.98s)]
*  I would say something and then nobody listened. [[00:21:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1306.42s)]
*  And then some guy, some man said the same thing. [[00:21:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1310.1s)]
*  Oh, yeah, that's very interesting. [[00:21:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1313.4599999999998s)]
*  And so and it annoyed me. [[00:21:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1314.8999999999999s)]
*  And I had this computer and I thought, ah, I have a computer. [[00:21:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1316.58s)]
*  This computer doesn't care, right? [[00:21:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1319.86s)]
*  The computer has no conception of what I'm telling him, what I'm trying to make him do. [[00:22:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1322.98s)]
*  It comes from a field or mail. [[00:22:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1327.6999999999998s)]
*  It was very liberating. [[00:22:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1330.8999999999999s)]
*  So eventually then you eventually you went to the United States. [[00:22:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1333.4599999999998s)]
*  And so what we're eventually going to get to, and that's interesting that you just said that [[00:22:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1340.02s)]
*  your mom was had a PhD in biology because I wanted to ask about her sort of approach, [[00:22:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1343.3799999999999s)]
*  right? [[00:22:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1349.54s)]
*  Because you have this like, well, it's mechanisms in science. [[00:22:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1349.78s)]
*  But the old biologists were accused of just stamp collecting, right? [[00:22:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1353.62s)]
*  Just collecting the data without a theoretical background. [[00:22:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1357.7s)]
*  So it made me curious if maybe your mom. [[00:22:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1360.6599999999999s)]
*  Yeah, well, as of course, the Karl Collins aspect, which is my great grandfather, [[00:22:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1363.78s)]
*  was also a biologist. [[00:22:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1368.66s)]
*  And I used him then for this foundation. [[00:22:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1371.5400000000002s)]
*  And I asked the others what they thought. [[00:22:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1375.7s)]
*  And it's okay, because it's just a family relation. [[00:22:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1377.46s)]
*  But then it occurred to me it's not just a family relation. [[00:23:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1380.74s)]
*  There's something else. [[00:23:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1383.5400000000002s)]
*  At the time when the Mendel letters, Mendel's Laws was set up and my grandfather wrote this [[00:23:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1385.14s)]
*  paper where he actually added a law that was never Mendel's Laws. [[00:23:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1393.38s)]
*  So he really pushed it along. [[00:23:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1397.14s)]
*  This is Karl, Karl, [[00:23:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1399.22s)]
*  Coran. [[00:23:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1400.42s)]
*  Karl Coran, yeah. [[00:23:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1400.8200000000002s)]
*  He was much attacked, that said my mother from the Berkson people. [[00:23:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1401.8600000000001s)]
*  So there was this Henri Berkson, and they had this life force. [[00:23:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1406.26s)]
*  So biology is different from physics because there's a life force. [[00:23:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1411.14s)]
*  And because of the life force, everything's different. [[00:23:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1415.3000000000002s)]
*  So it's not like- [[00:23:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1418.1000000000001s)]
*  The Elan de Tal, right? [[00:23:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1418.5800000000002s)]
*  That was much maligned eventually. [[00:23:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1420.0200000000002s)]
*  But it's a little bit misunderstood from Berkson's point of view. [[00:23:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1422.3400000000001s)]
*  But you said the Berkson people who did take it on. [[00:23:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1426.5s)]
*  Exactly. [[00:23:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1430.18s)]
*  Often happens like with Marxists or Freudians or so. [[00:23:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1431.78s)]
*  They don't take certain aspects and make them very big. [[00:23:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1434.98s)]
*  And one of these was that biology is separate from the material world, from physics, [[00:23:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1439.22s)]
*  and also from mathematics. [[00:24:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1446.74s)]
*  You can't use mathematics for biology because it's messy. [[00:24:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1448.42s)]
*  It has a life force. [[00:24:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1453.7s)]
*  It is a living organism and so on. [[00:24:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1455.54s)]
*  And so you have to study it completely differently. [[00:24:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1459.38s)]
*  And it is not part of science in the same way. [[00:24:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1462.58s)]
*  And so he took a lot of flack from these people because genetics was then, [[00:24:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1466.02s)]
*  was only appeared as a discipline. [[00:24:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1472.66s)]
*  And it was the first, you could say, mathematical discipline in biology. [[00:24:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1474.98s)]
*  And my grandfather had a different outlook on that. [[00:24:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1479.54s)]
*  Of course, he studied plants. [[00:24:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1484.74s)]
*  You could say in a way he loved plants. [[00:24:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1487.3000000000002s)]
*  But he took them very seriously as objects, as physical objects. [[00:24:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1489.3000000000002s)]
*  As physical objects which could be understood in a rational way. [[00:24:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1494.5800000000002s)]
*  You didn't have to appeal to some supernatural forces or so to understand how, [[00:24:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1498.74s)]
*  for instance, he was, I think, the first who pointed out that the chloroplasts, [[00:25:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1505.46s)]
*  which do the photosynthesis, probably were earlier bacteria which were incorporated. [[00:25:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1510.1000000000001s)]
*  Oh, he posited that theory? [[00:25:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1517.46s)]
*  Yeah. [[00:25:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1520.1000000000001s)]
*  And so it's actually true, I think. [[00:25:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1521.22s)]
*  And you see things like that. [[00:25:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1522.8200000000002s)]
*  So that was just this, an outflow from this mechanical, physical approach to it, to plants. [[00:25:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1524.18s)]
*  And so from this perspective, I thought it was good as a, [[00:25:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1532.02s)]
*  for the name of the foundation for mathematics. [[00:25:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1536.34s)]
*  Yeah. [[00:25:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1541.3799999999999s)]
*  So you have this linguistics background, and you're into the computer science and the math. [[00:25:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1541.9399999999998s)]
*  So what was the turn into neuroscience? [[00:25:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1547.22s)]
*  Yeah, that was exactly the point. [[00:25:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1549.86s)]
*  That was when I was, I had all this high-level thing. [[00:25:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1551.54s)]
*  And anyway, linguistics, as I said, was degrading into natural language processing. [[00:25:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1554.98s)]
*  And at the time, I thought Google would take it all. [[00:26:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1560.26s)]
*  I have no interest in this anymore. [[00:26:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1562.74s)]
*  What does that mean, degrading into? [[00:26:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1564.26s)]
*  Well, natural language processing is the question of how to do information processing [[00:26:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1566.26s)]
*  in a natural language on a machine. [[00:26:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1572.26s)]
*  And my question has always been, how do we do language in a human brain? [[00:26:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1575.54s)]
*  But you don't think we can learn about the human brain by building machines? [[00:26:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1581.14s)]
*  Yes. That's one of the best ways, yeah. [[00:26:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1586.82s)]
*  So then what's the problem with natural language processing? [[00:26:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1590.34s)]
*  They wanted to use language to communicate and deal with machines. [[00:26:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1592.1s)]
*  And that is not what language is made for. [[00:26:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1598.1799999999998s)]
*  You have to change it. [[00:26:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1600.1799999999998s)]
*  You have to use a stupid kind of language for it. [[00:26:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1601.4599999999998s)]
*  You have to take many things out, all the jokes, all the fun, all the poetry. [[00:26:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1604.1799999999998s)]
*  The machine won't understand it, and therefore it's not a topic anymore. [[00:26:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1610.1s)]
*  But for us humans, it's all a part of it. [[00:26:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1615.06s)]
*  Yeah, and confabulation and lying and anything creative, essentially. [[00:26:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1619.7s)]
*  Yeah. [[00:27:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1624.82s)]
*  This is a total aside, but do large language models generate neologisms? [[00:27:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1627.86s)]
*  Because the nature of language, it's always evolving and changing. [[00:27:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1635.1399999999999s)]
*  Like a word, it's called semantic drift. [[00:27:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1640.34s)]
*  I don't know what it's called, but the meaning of a word changes over time, [[00:27:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1644.1s)]
*  because people elect to use it differently or to use it in a funny way. [[00:27:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1647.14s)]
*  And then sometimes that catches on, sometimes it doesn't. [[00:27:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1651.22s)]
*  And so it's always changing. [[00:27:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1653.46s)]
*  And I was curious, I was talking with a friend the other day about [[00:27:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1655.5400000000002s)]
*  whether large language models can or will sort of, what effect they'll have on that drift. [[00:27:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1658.9s)]
*  It almost seems like they will crystallize language into one thing. [[00:27:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1666.18s)]
*  Well, I think what happens is you have an exchange between brains. [[00:27:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1668.74s)]
*  And this exchange uses this route of language. [[00:27:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1673.54s)]
*  So you don't need a chip in your head in order to show the content of your brain to somebody else. [[00:27:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1678.5s)]
*  You can use language. [[00:28:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1685.06s)]
*  And if you do this, and if this happens between different people over time, [[00:28:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1686.98s)]
*  then you will always have access to different experiences these people do have, [[00:28:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1692.82s)]
*  extra linguistic, that they have in other areas of their lives. [[00:28:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1699.94s)]
*  And so as you use this communication method, the sort of the substrate which interprets it, [[00:28:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1704.8200000000002s)]
*  my substrate interprets what we are saying and yours tries to interpret what I'm saying to match [[00:28:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1713.8600000000001s)]
*  it to your own thought patterns. [[00:28:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1720.5800000000002s)]
*  And this happens all the time between people. [[00:28:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1723.22s)]
*  And I think this is the explanation why semantics changes and also why it's such an interesting and [[00:28:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1726.1s)]
*  also I think such a joyful topic. [[00:28:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1734.1s)]
*  It's very, very interesting. [[00:28:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1736.42s)]
*  Now, if you have a machine, like let's say an Elisa machine or any kind of QA machine in between, [[00:28:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1738.02s)]
*  you can of course communicate to this machine. [[00:29:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1744.9s)]
*  And actually, if you know it's a neural network setting there and there's certain things, [[00:29:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1747.86s)]
*  it may also have changes to the communication process. [[00:29:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1752.26s)]
*  That's what many people are not very concerned about. [[00:29:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1756.9s)]
*  That if we have lots of AI generated linguistic content that younger generations are exposed to [[00:29:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1759.86s)]
*  without understanding sort of that this may affect their thought processes in negative ways. [[00:29:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1768.42s)]
*  And I think that's quite true. [[00:29:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1776.18s)]
*  I personally think it's to use language for communication with the machine. [[00:29:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1777.7s)]
*  From my point of view, it's something I never wanted. [[00:29:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1784.5800000000002s)]
*  People I know, of course, computational linguistics, I was a computational linguist myself [[00:29:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1793.7s)]
*  for three years in Heidelberg Institute for Computational Linguistics. [[00:29:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1798.5s)]
*  That was one of the goals. [[00:30:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1802.1000000000001s)]
*  People say, I want a microphone, I want to talk into it. [[00:30:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1803.46s)]
*  And the machine should give me everything that I want. [[00:30:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1807.0600000000002s)]
*  And I always thought, no. [[00:30:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1810.98s)]
*  What's the danger there? [[00:30:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1812.74s)]
*  Also because it's not suitable. [[00:30:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1815.22s)]
*  Language is suitable to human brains. [[00:30:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1818.5s)]
*  It's produced by human brains, it's understood by them and so on. [[00:30:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1821.7800000000002s)]
*  Many communicative issues shape our language. [[00:30:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1825.7800000000002s)]
*  Now, if I communicate with the machine, then it's almost as if you have... [[00:30:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1832.1s)]
*  Of course, it's different, but you have a child and you have an adult. [[00:30:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1842.34s)]
*  And you talk to a child and you talk to the adult, you have to adjust yourself. [[00:30:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1846.4199999999998s)]
*  You have to talk differently to the child and to the adult. [[00:30:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1850.98s)]
*  And now you have a machine and you have to adjust yourself to the machine. [[00:30:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1853.86s)]
*  Oh, right. [[00:30:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1857.38s)]
*  Because we have to assume the machine has, again, a very different level of understanding. [[00:30:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1857.8600000000001s)]
*  Well, I worry and I don't know if this is related to what you're saying, but [[00:31:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1863.22s)]
*  it doesn't matter how we treat the machine, right? [[00:31:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1868.18s)]
*  Because it's just a machine. [[00:31:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1870.02s)]
*  And because you speak differently in different contexts, when I'm talking to a machine, [[00:31:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1871.8600000000001s)]
*  if I say please, I think it's ridiculous, right? [[00:31:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1878.5800000000002s)]
*  You know, so I'm not going to be polite necessarily, as polite to a machine. [[00:31:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1881.6200000000001s)]
*  But I worry that that then affects, especially with younger people growing up, [[00:31:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1886.66s)]
*  how they then they could translate that style of communication to the real world. [[00:31:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1891.38s)]
*  Like social media, how people... [[00:31:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1896.26s)]
*  There are many such aspects. [[00:31:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1897.22s)]
*  Many, many such aspects. [[00:31:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1898.66s)]
*  I can always... [[00:31:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1900.26s)]
*  I always get angry at these things very quickly. [[00:31:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1900.98s)]
*  That's why I don't use them anymore. [[00:31:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1903.6200000000001s)]
*  At the machines, yeah. [[00:31:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1905.14s)]
*  Because I have a lot of patience explaining something to them. [[00:31:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1906.5s)]
*  And since I know it's a machine, I don't have patience because I'm not friendly. [[00:31:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1910.74s)]
*  I think we have programming language and so which are made for machines. [[00:31:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1916.02s)]
*  They're not very made for humans, but they're very well made for machines. [[00:32:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1920.82s)]
*  And that's how we can communicate. [[00:32:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1924.8999999999999s)]
*  Okay. Well, let's go back then to... [[00:32:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1929.06s)]
*  Eventually, you're going to start this Carl Coran's Foundation. [[00:32:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1933.06s)]
*  And what I want to know is like why you did that and how you did it and how I could do it. [[00:32:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1935.54s)]
*  If I wanted to... [[00:32:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1939.62s)]
*  Well, the reason I did was I had this BioCorporate Stanford for about 10 years. [[00:32:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1940.9s)]
*  And this meant that it was actually started by a student and then she went away. [[00:32:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1947.06s)]
*  And did somebody want to go on? [[00:32:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1952.34s)]
*  Yes, I said, I'm ready to go on with it. [[00:32:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1955.14s)]
*  And so I invited people to give talks in the Bay Area, doctoral students or postdocs. [[00:32:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1957.78s)]
*  And they usually came and gave a talk and some of them were very excellent. [[00:32:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1965.86s)]
*  I mean, I read the paper upfront. [[00:32:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1971.1399999999999s)]
*  Somebody actually asked him, how do you manage to get such wonderful lectures? [[00:32:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1973.7s)]
*  And I said, well, I read the papers. [[00:32:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1979.22s)]
*  I read the papers and when I like the paper, then I invite the person. [[00:33:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1981.86s)]
*  And so we had really wonderful people that gave me talks and very interesting research. [[00:33:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1985.06s)]
*  But when I asked them, yeah, how's it going on with basic science, academia? [[00:33:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1991.54s)]
*  No, no, no, no. [[00:33:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1997.1399999999999s)]
*  Pretty much always. [[00:33:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=1999.46s)]
*  Nobody wanted to do academia. [[00:33:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2000.58s)]
*  Nobody wanted to do basic science. [[00:33:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2002.34s)]
*  Everyone was going out and as I said, this occurred to me. [[00:33:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2004.1s)]
*  Imagine this, like say Paul Dirac, Emile Noether, Werner Heisenberg. [[00:33:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2009.46s)]
*  They give their talks on physics and how are you going to go on? [[00:33:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2015.22s)]
*  Oh, well, we're going to do a startup and, you know, rent out garages or so. [[00:33:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2019.54s)]
*  And they might be a successor, but smart people. [[00:33:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2024.8999999999999s)]
*  But it's a waste, right? [[00:33:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2029.94s)]
*  Well, depending on your goals. [[00:33:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2033.1399999999999s)]
*  Of course, on their goals. [[00:33:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2034.8999999999999s)]
*  Now, I mean, I'm talking about society at large. [[00:33:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2036.5s)]
*  Well, I don't know. [[00:34:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2040.6599999999999s)]
*  I mean, I'm not sure. [[00:34:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2041.46s)]
*  I mean, a lot of people who go and do a startup have the intentions to change the world. [[00:34:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2042.82s)]
*  Yeah, but what I meant was that academia and basic science was simply not a valid alternative [[00:34:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2048.9s)]
*  for them. [[00:34:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2058.42s)]
*  And I could understand them and I would not even have contradicted them. [[00:34:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2059.14s)]
*  So they were getting their PhDs, etc. in order to move to India. [[00:34:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2063.14s)]
*  And then so I'd never go back to this place again because they had their experiences. [[00:34:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2068.1s)]
*  That's what I mean. [[00:34:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2073.06s)]
*  It used to be in the earlier world. [[00:34:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2074.1s)]
*  Okay, academia, you don't make as much money, but you have your freedom. [[00:34:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2076.02s)]
*  You have your joy. [[00:34:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2080.02s)]
*  You enjoy your work. [[00:34:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2081.22s)]
*  If for half a year nothing comes to your mind, then you do nothing. [[00:34:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2082.34s)]
*  You know? [[00:34:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2087.46s)]
*  That doesn't exist anymore. [[00:34:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2088.34s)]
*  That was academia. [[00:34:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2089.86s)]
*  And then you write a wonderful paper. [[00:34:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2091.14s)]
*  That was academia. [[00:34:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2093.86s)]
*  And nobody bothers you. [[00:34:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2094.9s)]
*  So you had time to reflect and think and work things out. [[00:34:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2096.58s)]
*  That's different these days, you would say? [[00:35:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2100.98s)]
*  Oh, of course. [[00:35:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2102.9s)]
*  Yeah, it's very different. [[00:35:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2103.78s)]
*  There's always this run for funding, funding, funding. [[00:35:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2105.38s)]
*  You can't do anything without it. [[00:35:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2108.26s)]
*  That was the second observation. [[00:35:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2109.94s)]
*  Then I talked to the people who actually were professors at Stanford. [[00:35:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2112.7400000000002s)]
*  People who might think, oh, they're on top of their profession or something. [[00:35:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2117.54s)]
*  What would they do if they could? [[00:35:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2122.42s)]
*  And pretty much everybody said the kind of stuff they're doing now they wouldn't do. [[00:35:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2124.34s)]
*  They would do something else. [[00:35:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2128.98s)]
*  But they can't get funding for that. [[00:35:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2131.3s)]
*  Right. [[00:35:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2134.02s)]
*  From their own research, what they do, that they would go in a different direction now [[00:35:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2134.2599999999998s)]
*  in order to advance, in order to make an impact or something. [[00:35:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2141.14s)]
*  But they can't because they can't get funding for that. [[00:35:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2145.38s)]
*  They get funding for something else. [[00:35:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2148.1s)]
*  And they have to do something else. [[00:35:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2149.62s)]
*  And as I said, the older they were, the more cynical they had become [[00:35:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2152.34s)]
*  about the value of all this. [[00:35:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2156.34s)]
*  And that was also sad. [[00:35:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2158.9s)]
*  This was not some tiny place in Romania where people are very sad that they cannot do what [[00:36:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2160.42s)]
*  they want to do. [[00:36:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2167.5400000000004s)]
*  This was a place where we would expect them to be able to actually do the kind of science [[00:36:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2168.26s)]
*  which they believe in and which they want. [[00:36:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2177.46s)]
*  So you were feeling that also in your own career? [[00:36:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2180.26s)]
*  Yeah, no. [[00:36:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2185.0600000000004s)]
*  I felt it all the time, but I thought it was just me. [[00:36:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2186.1800000000003s)]
*  Oh, no, no. [[00:36:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2189.7s)]
*  It's everybody. [[00:36:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2191.7s)]
*  Oh, it's 99%. [[00:36:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2192.3399999999997s)]
*  Yeah, that's the part that shocked me. [[00:36:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2194.02s)]
*  And I was in Munich. [[00:36:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2195.8599999999997s)]
*  I thought it's because I'm in Munich. [[00:36:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2196.8999999999996s)]
*  Okay. [[00:36:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2199.3799999999997s)]
*  But then I come to Stanford and it's still like that. [[00:36:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2200.1s)]
*  And that's when I thought this is here something wrong, right? [[00:36:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2202.58s)]
*  As I said, if you go to, I don't know, the University of Banja Luka in Bosnia, [[00:36:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2207.9399999999996s)]
*  they don't have that much money. [[00:36:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2213.8599999999997s)]
*  Okay. [[00:36:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2216.42s)]
*  So you expect once they talk to something, oh, once I get to have it, then I will be able to do [[00:36:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2217.2200000000003s)]
*  what I want. [[00:37:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2222.98s)]
*  It's not the case. [[00:37:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2223.38s)]
*  Right. [[00:37:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2224.18s)]
*  Yeah. [[00:37:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2224.5s)]
*  Yeah, actually, I was just telling a student in the lab the other day, [[00:37:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2226.42s)]
*  I said, you're not going to like this. [[00:37:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2229.94s)]
*  It's going to be obnoxious, but it's true that there is no destination. [[00:37:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2231.86s)]
*  Like you never get there, right? [[00:37:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2236.5s)]
*  Because you're always moving. [[00:37:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2238.26s)]
*  But similar lines. [[00:37:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2240.18s)]
*  Someone in my lab the other day asked me about my research. [[00:37:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2242.34s)]
*  Oh, well, what are you going to publish from this? [[00:37:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2245.7s)]
*  And I just sort of bristled because like, that's not that shouldn't be the question. [[00:37:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2247.94s)]
*  The question is, what are you finding that's interesting? [[00:37:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2252.02s)]
*  Not like you have to think about when you're doing your research. [[00:37:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2254.5s)]
*  Well, what is publishable? [[00:37:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2258.18s)]
*  What can I publish from this instead of what can I do to further advance my understanding of this? [[00:37:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2259.86s)]
*  I know what you mean. [[00:37:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2266.66s)]
*  That's often the problem. [[00:37:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2267.3s)]
*  I've solved it for me. [[00:37:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2268.82s)]
*  For me, it's even worse because maybe that's actually a good thing. [[00:37:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2269.78s)]
*  It's one thing to have results, but it's a different thing to go deeply enough in order [[00:37:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2277.1400000000003s)]
*  to be able to publish them. [[00:38:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2282.5s)]
*  And in that process, sometimes you learn something, of course. [[00:38:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2284.34s)]
*  That is a good thing. [[00:38:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2287.2200000000003s)]
*  And I simply use a blog that I have and some gray literature for things which are not ready [[00:38:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2288.6600000000003s)]
*  to be published. [[00:38:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2294.98s)]
*  I don't think I heard that term before gray literature. [[00:38:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2296.7400000000002s)]
*  Is that like preprints? [[00:38:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2299.1400000000003s)]
*  You mean? [[00:38:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2300.1000000000004s)]
*  Yeah, exactly. [[00:38:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2300.6600000000003s)]
*  Preprints and for instance, on ResearchGate, you can just put in a paper and you get a DOI. [[00:38:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2302.26s)]
*  And then maybe if four years later, you think that this thing I could now use for an actual [[00:38:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2310.1000000000004s)]
*  publication, it's still there. [[00:38:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2315.38s)]
*  Oh, so you can, there's no hoops and hurdles to jump through to put it up on ResearchGate? [[00:38:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2317.6200000000003s)]
*  No. [[00:38:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2323.0600000000004s)]
*  You can do whatever you put up, whatever you want? [[00:38:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2323.78s)]
*  More or less, yeah. [[00:38:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2325.54s)]
*  I did it on language. [[00:38:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2326.5s)]
*  I wrote a piece on language, on the biology of language, simply because I wanted to put [[00:38:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2327.62s)]
*  it together for myself and I put it on ResearchGate and I have no idea whether I ever will publish [[00:38:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2333.22s)]
*  it. [[00:38:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2338.34s)]
*  But when the LLMs came out, I thought it was very necessary to remind myself all the many [[00:38:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2338.82s)]
*  things we know about language and the brain. [[00:39:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2346.1s)]
*  Know many, many things. [[00:39:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2349.62s)]
*  And this LLM was in the process of sweeping it all aside. [[00:39:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2350.98s)]
*  And so I thought I need to write a, I need to put this together and just 10 days, sit [[00:39:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2355.62s)]
*  down and put together, you know, look at the current data travel and so on about, [[00:39:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2361.38s)]
*  we have this N400, for instance, I don't know, event related potentials, if you are [[00:39:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2368.58s)]
*  familiar with them, that's it. [[00:39:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2373.7799999999997s)]
*  It's when you take EEG signals and then over many, many trials, you can align those signals [[00:39:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2375.7s)]
*  to an event and then you average them. [[00:39:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2381.7799999999997s)]
*  And then the way the waveform, the shape of the waveform, different shapes get different [[00:39:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2384.1s)]
*  names relative to like when it happens. [[00:39:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2389.14s)]
*  Yeah. [[00:39:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2391.38s)]
*  Relative to the event. [[00:39:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2391.7s)]
*  There are actually not so many. [[00:39:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2392.98s)]
*  Yeah. [[00:39:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2393.7799999999997s)]
*  Yeah, not so many. [[00:39:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2394.2599999999998s)]
*  Yeah, there's a handful. [[00:39:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2395.22s)]
*  Yeah, it's, in the N400 is up to 400 milliseconds. [[00:39:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2396.18s)]
*  It's a negative. [[00:40:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2401.06s)]
*  And you get it with all kinds of language effects. [[00:40:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2402.3399999999997s)]
*  You get it when you have to make a joke. [[00:40:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2405.54s)]
*  Because something doesn't align and you laugh and you're... [[00:40:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2408.02s)]
*  Oh, is that the unexpected? [[00:40:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2410.74s)]
*  Yeah. [[00:40:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2413.1400000000003s)]
*  Surprise, error, mismatch. [[00:40:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2413.78s)]
*  And that's also for garden pad sentences. [[00:40:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2415.1400000000003s)]
*  So a sentence which starts off grammatically but doesn't end grammatically. [[00:40:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2417.2200000000003s)]
*  Goes like this, right? [[00:40:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2422.02s)]
*  And that's large. [[00:40:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2423.78s)]
*  To generate this EEG signal, this means that essentially your whole brain [[00:40:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2425.86s)]
*  is involved in interpreting this ungrammatical sentence, [[00:40:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2433.46s)]
*  which is interesting because sometimes people think it's very localized. [[00:40:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2437.38s)]
*  Right. [[00:40:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2441.1400000000003s)]
*  But it's not if it's actually a very profound. [[00:40:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2441.78s)]
*  Yeah. [[00:40:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2446.82s)]
*  Well, it doesn't have to be whole brain, but it has to be more than 10 neurons to be... [[00:40:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2447.0600000000004s)]
*  Yeah, yeah, exactly. [[00:40:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2450.34s)]
*  Well, the large part of the cortex maybe be more. [[00:40:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2451.1400000000003s)]
*  Yeah. [[00:40:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2455.6200000000003s)]
*  So why do you... [[00:40:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2456.5800000000004s)]
*  Why did you mention the N400? [[00:40:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2459.3s)]
*  Why that would be important in terms of understanding... [[00:41:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2461.2200000000003s)]
*  Because this is a sign of how we interpret language. [[00:41:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2463.6200000000003s)]
*  And what we do with ungrammatical sentences. [[00:41:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2470.26s)]
*  Ungrammatical sentences have a very strong effect on us. [[00:41:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2473.86s)]
*  Yeah. [[00:41:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2477.6200000000003s)]
*  And they can be funny. [[00:41:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2478.6600000000003s)]
*  That's true. [[00:41:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2481.46s)]
*  The N400 I just read, you can also use this for prices. [[00:41:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2482.6600000000003s)]
*  If somebody quotes your very high price, N400 goes up. [[00:41:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2487.2200000000003s)]
*  It notices unexpected, unexpected, right? [[00:41:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2492.1000000000004s)]
*  So what would you take from that? [[00:41:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2496.98s)]
*  Because you write over and over in your papers like, well, it depends on the level of abstraction [[00:41:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2498.26s)]
*  that's important, right? [[00:41:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2504.1000000000004s)]
*  So you don't think like, well, I think we need to build a system that has an N400 or full language. [[00:41:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2505.46s)]
*  In a way, yes. [[00:41:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2513.38s)]
*  If we build... [[00:41:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2514.42s)]
*  When we build our language model which interprets, for instance, feature landscapes [[00:41:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2516.26s)]
*  by terms of symbols and so on. [[00:42:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2523.0600000000004s)]
*  And now we give it an unexpected series of symbols or a series which first makes sense [[00:42:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2525.38s)]
*  and then some symbol that doesn't make sense at all. [[00:42:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2531.06s)]
*  I do want in my model to see what is happening here, which could cause this N400. [[00:42:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2533.62s)]
*  And then LNM doesn't do that. [[00:42:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2539.54s)]
*  Because it doesn't even model the brain. [[00:42:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2542.6600000000003s)]
*  But there might be some readout of expected versus unexpected [[00:42:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2545.62s)]
*  because it's based on probabilities, right? [[00:42:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2550.5s)]
*  And then eventually collapses and the word with the highest probability or the token [[00:42:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2552.34s)]
*  gets placed next. [[00:42:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2557.1400000000003s)]
*  Yeah, yeah. [[00:42:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2557.94s)]
*  But that's different. [[00:42:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2558.34s)]
*  This is what they use in order to build sentences here. [[00:42:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2560.02s)]
*  I really mean a violation of an expectation. [[00:42:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2563.86s)]
*  Yeah. [[00:42:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2566.9s)]
*  Well, of course, the LNM produces it all the time. [[00:42:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2567.78s)]
*  If it gives you useful answers and then counts the number of R's and strawberry faults, [[00:42:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2571.06s)]
*  you should get an N400. [[00:42:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2577.38s)]
*  But the LNM doesn't. [[00:43:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2580.1000000000004s)]
*  It should, but it doesn't. [[00:43:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2582.1000000000004s)]
*  Yeah. [[00:43:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2583.86s)]
*  Yeah. [[00:43:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2584.6600000000003s)]
*  Well, I mean, that also just speaks to the lack of any dynamics, right? [[00:43:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2584.9s)]
*  In a model in general. [[00:43:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2588.7400000000002s)]
*  Of course, somebody could argue that this N, these signals in the brain are irrelevant [[00:43:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2590.7400000000002s)]
*  or doesn't mean anything. [[00:43:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2597.6200000000003s)]
*  We can build artificial intelligence in a completely different way. [[00:43:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2600.42s)]
*  And still be very happy with the results. [[00:43:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2606.42s)]
*  It is engineering, but it's okay. [[00:43:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2612.1800000000003s)]
*  For my perspective, somebody wants to engineer a language machine. [[00:43:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2614.42s)]
*  I have nothing against it, but it doesn't interest me. [[00:43:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2618.98s)]
*  But you think that there are better ways to do it to engineer artificial intelligence [[00:43:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2621.6200000000003s)]
*  and that's why you're... [[00:43:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2626.02s)]
*  Well, it's two things. [[00:43:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2627.3s)]
*  First of all, I have nothing against people engineering it. [[00:43:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2628.6600000000003s)]
*  It's just something that doesn't interest me because I see myself as a natural scientist, [[00:43:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2631.94s)]
*  as somebody who's looking at the natural world and a natural language, [[00:43:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2636.98s)]
*  and a language is part of a human natural world. [[00:44:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2643.3s)]
*  Okay. [[00:44:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2648.34s)]
*  Yeah. [[00:44:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2648.7400000000002s)]
*  So one of the thoughts that I have recurringly about artificial intelligence is like, [[00:44:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2648.98s)]
*  okay, it's fine, but first of all, it's just an unfortunate name. [[00:44:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2653.86s)]
*  The originator of that name thought it was an unfortunate name also. [[00:44:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2658.8999999999996s)]
*  I think John McCarthy, I think, coined it and then hated it. [[00:44:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2661.94s)]
*  I don't know. [[00:44:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2666.3399999999997s)]
*  It's always been contentious from the earliest days. [[00:44:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2667.14s)]
*  But I just think like, okay, that's fine. [[00:44:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2670.18s)]
*  It's engineering. [[00:44:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2672.02s)]
*  It's not really what I think of as intelligence or I need to rejigger what I think of as intelligence. [[00:44:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2673.2999999999997s)]
*  All of a sudden, people are claiming that they're working on intelligence when [[00:44:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2681.7799999999997s)]
*  I think that's actually missing the mark of what maybe I'm interested in. [[00:44:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2685.38s)]
*  I don't know how to really articulate it, but it's something different. [[00:44:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2689.46s)]
*  It's not what I'm interested in understanding as far as intelligence. [[00:44:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2693.7000000000003s)]
*  Yeah. [[00:44:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2698.34s)]
*  Well, I look, I was also distant from it for a considerable time for the same reason, [[00:44:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2698.58s)]
*  but you see what it occurred to me that of course it can help us focus when we do [[00:45:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2704.58s)]
*  computational neuroscience models. [[00:45:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2710.98s)]
*  We do many of them and they capture different functionalities, different ideas. [[00:45:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2714.5s)]
*  Wouldn't it be useful from time to time to say, let's see whether we can build [[00:45:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2719.3s)]
*  a functional model which actually do some task or so on the basis of our knowledge about the brain. [[00:45:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2723.86s)]
*  Let's not just do simulation models which do new experiments and then show in the model how you can [[00:45:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2733.3s)]
*  explain the experiment, but let's try to build a functional model on a higher level [[00:45:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2740.26s)]
*  and see whether we can use this to achieve some goal, to let them do some task. [[00:45:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2747.1400000000003s)]
*  Task that's useful. [[00:45:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2759.5400000000004s)]
*  Why shouldn't we do this on the basis of our computational neuroscience experience? [[00:46:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2760.5800000000004s)]
*  Because we're so far behind in computational neuroscience. [[00:46:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2765.3s)]
*  That's actually the contention. [[00:46:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2768.74s)]
*  That is exactly the idea why I had this idea about the spin off. [[00:46:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2770.1s)]
*  That I thought I think the time is right. [[00:46:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2773.86s)]
*  Okay. [[00:46:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2777.2999999999997s)]
*  So let's go back to the Karl Korans because I want to, [[00:46:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2777.62s)]
*  because there's a lot of science that I want to talk to you about also [[00:46:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2780.8199999999997s)]
*  and the things that you have worked on. [[00:46:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2783.7s)]
*  So let's get to the spin off that you're developing or have developed, but [[00:46:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2787.22s)]
*  go back to, I want to know how to start a Karl Korans. [[00:46:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2791.2999999999997s)]
*  Karl Korans. [[00:46:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2794.34s)]
*  Well, that was, I asked friends and colleagues whether they wanted to be on the board. [[00:46:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2794.98s)]
*  I set up a non-profit foundation, California law, tax deductible, took some time, [[00:46:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2799.3s)]
*  took a little bit of money, mostly time. [[00:46:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2805.3s)]
*  You had to make the decision to step out of academia too, right? [[00:46:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2808.6600000000003s)]
*  Yes. [[00:46:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2812.5s)]
*  Well, I still see it as a part of academia. [[00:46:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2813.06s)]
*  There's so many. [[00:46:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2816.1000000000004s)]
*  I mean, look, by the way, I almost ended up with OpenAI at the time because that [[00:46:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2816.9s)]
*  was a non-profit. [[00:47:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2824.18s)]
*  And as I was doing this, people told me, you know about OpenAI, that's a non-profit too. [[00:47:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2825.7s)]
*  It's just like your idea to do exactly the same thing. [[00:47:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2830.2599999999998s)]
*  Why don't you work with them? [[00:47:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2834.02s)]
*  And I looked at them and I already then had the idea. [[00:47:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2835.7799999999997s)]
*  Somehow I don't really trust them. [[00:47:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2839.14s)]
*  I think that their legal structure seemed a bit strange because, [[00:47:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2840.8999999999996s)]
*  so I missed out. [[00:47:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2847.14s)]
*  I admit it. [[00:47:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2848.8199999999997s)]
*  It would have been nice, but knowing me, I probably would have left way too [[00:47:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2850.1s)]
*  early and so on. [[00:47:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2854.1s)]
*  And besides, I really don't like their approach, but I could, of course, [[00:47:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2857.38s)]
*  we have a small endowment for the Carl Collins Foundation from our family. [[00:47:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2862.5s)]
*  And of course, it could have been larger, right? [[00:47:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2866.9s)]
*  I could have sifted off some money, cycled off some money from the OpenAI [[00:47:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2869.7799999999997s)]
*  in terms of my own work or in terms of how you call it, stock or so. [[00:47:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2875.7s)]
*  Oh, yeah. [[00:48:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2883.14s)]
*  But the idea was right. [[00:48:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2884.9s)]
*  There are people like that. [[00:48:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2886.42s)]
*  There is the Allen Institute. [[00:48:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2887.46s)]
*  Of course, they all have much larger endowments, much larger. [[00:48:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2888.82s)]
*  But how do you keep going though? [[00:48:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2893.14s)]
*  So do people donate? [[00:48:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2894.7400000000002s)]
*  Because there's the fundraising aspect to it, which would be... [[00:48:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2897.38s)]
*  We have the endowment that generates a bit of money and some people donate. [[00:48:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2899.7000000000003s)]
*  And we have essentially just one scholar per year. [[00:48:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2904.18s)]
*  So you pay, is it like an intern almost? [[00:48:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2907.46s)]
*  Yeah, well, you could say that, something like that. [[00:48:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2910.82s)]
*  It depends. [[00:48:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2913.8599999999997s)]
*  We have different people. [[00:48:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2914.58s)]
*  We had a master's student. [[00:48:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2915.62s)]
*  Now I have a... [[00:48:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2917.22s)]
*  This year, I hope there's a PhD student who's doing work on monocotical microcolons [[00:48:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2919.06s)]
*  and he wants to contribute to our work and so on. [[00:48:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2925.14s)]
*  So the possibilities are there. [[00:48:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2930.98s)]
*  If there's more money, we can either put it in the endowment [[00:48:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2934.8199999999997s)]
*  if we don't know what to do with it right away. [[00:48:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2938.98s)]
*  This year, I would finance another scholar. [[00:49:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2941.22s)]
*  Because we have two things for the spin-off. [[00:49:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2943.94s)]
*  One is the cortical microcolon, making it useful for language. [[00:49:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2946.5s)]
*  And the other thing is a neuron model that we are building. [[00:49:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2951.94s)]
*  So I could use another one. [[00:49:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2955.7s)]
*  Haven't got them, the second one yet. [[00:49:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2957.7799999999997s)]
*  So if I'm a PhD student and I'm whatever, [[00:49:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2959.8599999999997s)]
*  but it's my second or third year or something at my institution [[00:49:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2963.62s)]
*  and I come across the Karl Korn's Foundation, [[00:49:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2966.98s)]
*  what do I... [[00:49:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2969.86s)]
*  Do I just... [[00:49:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2970.34s)]
*  Is that sort of a separate thing that I apply to [[00:49:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2970.98s)]
*  and then you send me money to do my work related to what you're wanting? [[00:49:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2973.7799999999997s)]
*  How does that work? [[00:49:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2977.7799999999997s)]
*  Because we have so little, we don't have calls or anything. [[00:49:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2980.1s)]
*  And I also always think the best system for grants... [[00:49:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2983.94s)]
*  Or let's put it this way. [[00:49:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2986.98s)]
*  Different possibilities for grant funding. [[00:49:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2989.38s)]
*  And I think it's good if several exist next to each other. [[00:49:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2991.62s)]
*  And one is what the DARPA argues. [[00:49:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=2996.74s)]
*  And I think there is this McKnight or something. [[00:50:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3000.58s)]
*  Some genius grant kind of thing. [[00:50:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3004.3399999999997s)]
*  MacArthur? [[00:50:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3006.5s)]
*  Is it MacArthur? [[00:50:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3007.06s)]
*  Oh yeah, probably. [[00:50:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3007.94s)]
*  Yes. [[00:50:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3009.14s)]
*  What they do is they look for some people who are already doing work which they like. [[00:50:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3010.9s)]
*  And then they give them extra money. [[00:50:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3015.54s)]
*  Okay. [[00:50:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3017.94s)]
*  So no grant funding, no competition and so on. [[00:50:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3018.42s)]
*  And I don't think it's even... [[00:50:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3021.7s)]
*  I don't even think it's more... [[00:50:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3023.22s)]
*  It is the other model is more democratic, but it's not unjust or something because [[00:50:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3025.54s)]
*  not everybody gets money unless to apply for it. [[00:50:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3033.06s)]
*  And the people who apply and don't get it, they have unpaid work. [[00:50:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3036.2599999999998s)]
*  Quite a lot of it. [[00:50:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3042.18s)]
*  And that's why I think the second model about democratic spreading to everybody is way too much. [[00:50:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3043.2999999999997s)]
*  There's way too much of it. [[00:50:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3051.22s)]
*  And there's way too little of the kind of money. [[00:50:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3052.98s)]
*  Of course, it sometimes happens. [[00:50:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3055.62s)]
*  I remember somebody from Stanford, she went to Harvard and some rich family [[00:50:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3057.06s)]
*  approached her and gave her money. [[00:51:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3062.26s)]
*  So that's of course also nice. [[00:51:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3064.9s)]
*  But I think it's best if they have all these different possibilities next to each other. [[00:51:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3066.42s)]
*  From our perspective so far, we have asked people whether they wanted to... [[00:51:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3073.06s)]
*  Oh, so you are you... [[00:51:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3078.8199999999997s)]
*  Do you search for people then? [[00:51:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3081.7s)]
*  Yeah. [[00:51:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3083.06s)]
*  Or do you... [[00:51:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3083.22s)]
*  Okay, so they don't come to you, you go to them. [[00:51:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3084.02s)]
*  Yeah. [[00:51:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3086.18s)]
*  Yeah, okay. [[00:51:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3087.54s)]
*  We're not making any calls for grants or so because it would be [[00:51:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3089.22s)]
*  ridiculous with the little money we have. [[00:51:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3092.98s)]
*  So that's why you're creating this spin-off, right? [[00:51:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3095.54s)]
*  To generate more... [[00:51:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3098.18s)]
*  It's the hope that we could generate more money and build our endowment. [[00:51:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3098.98s)]
*  That's my hope at the present time. [[00:51:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3105.46s)]
*  If the endowment grows, then we have a regular income for the foundation. [[00:51:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3107.06s)]
*  That puts us on a safe basis. [[00:51:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3112.42s)]
*  Then we don't always have to hope that some donation comes in. [[00:51:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3115.94s)]
*  Are you also seeking money from angel investors and stuff? [[00:51:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3119.94s)]
*  Sure, yeah. [[00:52:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3124.98s)]
*  Yeah, okay. [[00:52:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3125.7s)]
*  It just seems like a lot of... [[00:52:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3128.1s)]
*  For the start-up, clearly. [[00:52:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3129.2999999999997s)]
*  I already have this problem. [[00:52:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3131.7799999999997s)]
*  I have two developers that I will be talking to next week. [[00:52:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3133.3s)]
*  And both make very good impression on me. [[00:52:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3138.1800000000003s)]
*  But they're both people who cannot or would not work for free. [[00:52:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3141.6200000000003s)]
*  So we have to see whether one of them may want to join the company. [[00:52:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3145.46s)]
*  So what do you have? [[00:52:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3150.26s)]
*  Like a pitch deck or something? [[00:52:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3150.82s)]
*  Yeah, they always ask me for the pitch. [[00:52:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3153.3s)]
*  I have something similar. [[00:52:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3154.9s)]
*  But not really because I don't do this VC thing. [[00:52:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3156.42s)]
*  This doesn't fit with my approach. [[00:52:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3160.1s)]
*  Well, right. [[00:52:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3167.14s)]
*  But you're in a situation where you almost have to adapt and... [[00:52:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3167.7799999999997s)]
*  Yeah. [[00:52:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3170.98s)]
*  Now, the goal is actually to come up with a platform also [[00:52:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3171.3799999999997s)]
*  for a simple version of the platform in the near future. [[00:52:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3175.2999999999997s)]
*  So what do you mean? [[00:52:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3179.2999999999997s)]
*  What's the platform? [[00:53:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3180.2599999999998s)]
*  The platform will offer algorithms, tools from the competition neuroscience world [[00:53:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3180.98s)]
*  in order to solve practical problems. [[00:53:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3187.22s)]
*  And we'll come with one or two demos. [[00:53:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3190.66s)]
*  And do you feel like... [[00:53:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3194.4199999999996s)]
*  And then I want to see what traction we get. [[00:53:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3195.3799999999997s)]
*  So are you going to be competing against benchmarks in current AI? [[00:53:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3199.14s)]
*  That sort of thing? [[00:53:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3203.14s)]
*  No, it's more like when you look what AI is built on, [[00:53:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3203.7799999999997s)]
*  then you will find that essentially everything is from the early 90s. [[00:53:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3207.7s)]
*  Yeah. [[00:53:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3214.42s)]
*  In that time, there was a lot of creativity around, [[00:53:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3215.46s)]
*  a lot of different ideas and so on. [[00:53:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3218.1s)]
*  And that dried up. [[00:53:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3220.42s)]
*  People did other things. [[00:53:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3222.1s)]
*  And what came later, deep learning, the transformer architecture, [[00:53:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3224.42s)]
*  then this was called this adversarial training. [[00:53:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3228.82s)]
*  And these are very derivative. [[00:53:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3233.3s)]
*  These things are not a novel. [[00:53:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3236.7400000000002s)]
*  And so I think when you and I, we understand that some parts of the brain works [[00:53:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3238.7400000000002s)]
*  and some of these observations could be put in the platform for people to use. [[00:54:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3247.6200000000003s)]
*  Outside of our community, but inside the software developer AI community, [[00:54:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3257.7000000000003s)]
*  and see whether people become creative with it, whether something will be. [[00:54:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3266.18s)]
*  Of course, I have more ideas which would happen if we had more money, [[00:54:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3270.58s)]
*  but I've decided the best thing is to gain some traction with the platform [[00:54:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3275.7s)]
*  before then again addressing. [[00:54:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3281.38s)]
*  So far, the problem was with angel investors, [[00:54:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3284.34s)]
*  they proclaim they don't understand it. [[00:54:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3286.9s)]
*  That may be me. [[00:54:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3291.06s)]
*  They have their minds full of this AI thing. [[00:54:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3291.94s)]
*  Right. Yeah. [[00:55:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3300.02s)]
*  You need to work on that pitch deck. [[00:55:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3301.78s)]
*  Yeah, but I said this is not, you see, this what they now call AI. [[00:55:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3303.46s)]
*  The reason it's interesting, it's because huge amounts of data. [[00:55:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3308.42s)]
*  And I think the reason why everybody put Paul's money into it because this data is power. [[00:55:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3314.1s)]
*  And it won't be restricted to public data or the problem of copywriting data. [[00:55:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3320.9s)]
*  It will certainly be private data, data that maybe they shouldn't have, [[00:55:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3326.34s)]
*  but they have collected Google, Meta, and so on. [[00:55:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3330.82s)]
*  It gets to the point where they will use help data. [[00:55:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3335.38s)]
*  Of course, they will say it's not individualized, but that is also a hard sell. [[00:55:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3339.38s)]
*  They may have your help data. [[00:55:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3344.9s)]
*  And this is something I feel strongly about because I know that at least [[00:55:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3347.7799999999997s)]
*  German health insurance companies sell our data to pharmaceutical industry. [[00:55:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3354.2599999999998s)]
*  Of course, not identifiable, they say, but still they make money this way. [[00:56:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3362.2599999999998s)]
*  So you pay your insurance and your insurance takes your data [[00:56:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3368.3399999999997s)]
*  and sells them to the pharmaceutical company. [[00:56:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3372.74s)]
*  And I had a person here in Munich and she wanted to talk about it because they make [[00:56:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3375.62s)]
*  these conclusions to death. [[00:56:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3381.62s)]
*  They can tell you at a point when you are going to die [[00:56:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3384.1s)]
*  on the basis of how often you went to the doctor or something. [[00:56:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3387.46s)]
*  They are pretty good. [[00:56:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3391.62s)]
*  You think they can't, but they cannot individually. [[00:56:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3392.58s)]
*  But overall, they're pretty good. [[00:56:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3395.86s)]
*  Yeah, I don't like that. [[00:56:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3397.62s)]
*  All these questions about data analysis rolled up into this AI. [[00:56:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3399.38s)]
*  I don't mind the AI, but I do mind the data. [[00:56:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3408.42s)]
*  So what we do is something entirely different. [[00:56:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3413.22s)]
*  It will in the future use the data that you want it to use. [[00:57:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3420.42s)]
*  What does that mean? [[00:57:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3426.34s)]
*  Oh, the user will provide the data. [[00:57:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3427.54s)]
*  When you use an LLM, all the data is already in it. [[00:57:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3432.98s)]
*  I might not as a user, I might not know which data to put in. [[00:57:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3438.74s)]
*  Yeah, depends on your problem or so. [[00:57:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3442.02s)]
*  One has to see how much. [[00:57:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3444.98s)]
*  I admit it goes too far because I'd rather have the basics ready, [[00:57:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3446.5s)]
*  the algorithms and so on before discussing all the practical problems. [[00:57:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3455.3s)]
*  It's not bad. [[00:57:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3461.46s)]
*  But since you asked for the Carl Korn Foundation, [[00:57:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3462.42s)]
*  then I can tell you, yes, we didn't have enough donations to grow. [[00:57:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3465.38s)]
*  I think we have to earn them with our own work. [[00:57:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3474.5s)]
*  Fun. [[00:57:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3477.54s)]
*  So one of the reasons why I wanted to have you on, Gabriele, [[00:57:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3479.2200000000003s)]
*  is because your interests, so you come at it from a very theoretical standpoint. [[00:58:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3481.94s)]
*  I know that you saw some experimental work and thought maybe that's not for you. [[00:58:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3488.02s)]
*  Because you're coming at it from a theoretical standpoint, [[00:58:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3493.06s)]
*  you remind me of people like Steve Grossberg, [[00:58:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3496.5s)]
*  who basically dabbles in a lot of different things, [[00:58:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3501.38s)]
*  always coming from that theoretical approach. [[00:58:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3505.2200000000003s)]
*  You have done a variety of questions that you approached. [[00:58:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3507.62s)]
*  So I want to talk a little bit. [[00:58:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3514.2599999999998s)]
*  We won't talk in depth about your work on this, [[00:58:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3518.8199999999997s)]
*  but you highlight that neuromodulators have been basically ignored in computational neuroscience. [[00:58:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3520.9s)]
*  That's right. [[00:58:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3527.7s)]
*  And so you have ideas about those. [[00:58:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3529.14s)]
*  One of the things that I do want to discuss more in depth, [[00:58:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3531.2999999999997s)]
*  because it crosses paths with a lot of previous guests I've had on the podcast, [[00:58:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3534.5s)]
*  people like Randy Gallistole, David Glansman, [[00:59:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3541.2999999999997s)]
*  Hassam Akhla Kapoor, which for a different reason that I'll bring up later. [[00:59:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3546.8999999999996s)]
*  But this idea that it's a single neuron model that you're working on. [[00:59:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3550.5s)]
*  And the people that I've mentioned have made the argument that [[00:59:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3555.22s)]
*  our memories, that we need something more permanent to store our memories. [[00:59:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3562.1800000000003s)]
*  Memories are not stored in synapse, in the synaptic clefts, for example, [[00:59:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3569.38s)]
*  that we need like internal cellular processes, something more stable, that's the word for it, [[00:59:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3573.38s)]
*  to allow storage, essentially. [[00:59:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3581.46s)]
*  And you have this model, you've taken that on, right? [[00:59:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3583.86s)]
*  I can ask you this in a second, but you seem to more or less agree that [[00:59:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3586.34s)]
*  the synapse is not where it's at with regard. [[00:59:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3591.46s)]
*  And so you posit this model of a neuron where there are external processes, [[00:59:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3593.78s)]
*  internal processes, and then like core processes in the nucleus. [[00:59:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3599.1400000000003s)]
*  So tell me a little bit, and presumably, is this one of the things that's going to be [[01:00:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3604.1s)]
*  available in the spin-off as well? [[01:00:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3609.06s)]
*  Yes, exactly. [[01:00:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3611.3s)]
*  Okay. [[01:00:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3612.34s)]
*  We will have conventional neural models, and that's exactly what we're working on right now. [[01:00:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3612.84s)]
*  We want to have one of these novel models. [[01:00:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3617.22s)]
*  And the reason why I believe these are important, again, [[01:00:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3620.98s)]
*  the good thing is why do we need such a model? [[01:00:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3625.7s)]
*  And the answer is in computer science, if you have complex blocks, [[01:00:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3629.7s)]
*  then the system as such can be much simpler. [[01:00:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3636.18s)]
*  What does that elaborate on that? [[01:00:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3640.66s)]
*  Yeah. [[01:00:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3642.42s)]
*  If I take a neuron which is nothing but an activation function, [[01:00:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3642.98s)]
*  and synapses which can change the weights, it is no surprise that I end up with [[01:00:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3647.14s)]
*  neural networks the size of a city, because each element is so smallish and has so little [[01:00:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3653.14s)]
*  possibility. [[01:01:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3660.02s)]
*  And I gave as an example already deep learning, imposes a structure, [[01:01:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3661.22s)]
*  on normal neural network will be hidden there. [[01:01:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3667.8599999999997s)]
*  And by imposing the structure, certain a lot of problems become manageable, [[01:01:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3671.46s)]
*  which, mathematically, you could express it with just one hidden layer. [[01:01:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3676.02s)]
*  That would work. [[01:01:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3681.38s)]
*  The deep layer is more restricted. [[01:01:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3682.5s)]
*  But if you try to train a three-layer network on the kind of problems that they could solve [[01:01:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3685.2200000000003s)]
*  with deep layer networks, you probably can't do it because it's a much, much larger, larger [[01:01:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3690.7400000000002s)]
*  network that you would get. [[01:01:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3698.26s)]
*  This is already a step away from the universality of the network towards a more special [[01:01:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3699.54s)]
*  structure. [[01:01:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3706.42s)]
*  And this special structure makes many problems easier to solve because the structure is [[01:01:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3707.3s)]
*  smaller. [[01:01:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3714.34s)]
*  And now I believe when you take instead of the neuron as an activation function, the [[01:01:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3715.14s)]
*  neuron as a more complex building block with storage inside, which has the possibility of [[01:02:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3720.34s)]
*  an internal memory. [[01:02:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3726.5s)]
*  And as such, when I begin to stack or combine these models, I will probably be able to have [[01:02:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3728.34s)]
*  useful functionality with much smaller systems than I have now, even though I lose in generality, [[01:02:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3739.2200000000003s)]
*  the universality. [[01:02:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3747.78s)]
*  So this is why it's tricky because we already know in the brain it works, and so therefore [[01:02:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3749.38s)]
*  it should work. [[01:02:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3754.9s)]
*  But it's tricky because you have to make the right obstructions. [[01:02:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3755.86s)]
*  If you take a building block, which is no good, so to speak, it probably can't build [[01:02:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3759.94s)]
*  the system at all. [[01:02:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3764.98s)]
*  And that's what I say. [[01:02:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3767.54s)]
*  There's the joy. [[01:02:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3768.58s)]
*  There's the fun of it. [[01:02:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3769.78s)]
*  There's the interest in it, which I probably wouldn't have to worry all the time who's [[01:02:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3770.7400000000002s)]
*  going to find me next. [[01:02:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3776.1s)]
*  This thing, they don't like it. [[01:02:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3778.34s)]
*  And how can I position it so that some funding agency feels compelled to give money for this? [[01:02:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3779.78s)]
*  Isn't it the danger that they say, what does she want there all the time? [[01:03:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3789.3s)]
*  And you don't want to hear it and so on. [[01:03:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3793.2200000000003s)]
*  And I work over my grant proposals all the time and I shouted my family. [[01:03:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3795.6200000000003s)]
*  You know what I mean? [[01:03:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3804.5s)]
*  That's not worth it. [[01:03:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3806.34s)]
*  Well, all right. [[01:03:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3810.26s)]
*  So neuroscience for a long time has sort of agreed writ large on the idea that it's all [[01:03:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3810.82s)]
*  all the information is in the spiking and we don't need to worry about the ion channels. [[01:03:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3821.46s)]
*  When we're explaining how cognition works, all we need to do is explain the pattern of [[01:03:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3828.5s)]
*  spikes and the way that the populations dynamically unfold in a low dimensional space, [[01:03:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3832.74s)]
*  etc. [[01:04:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3841.06s)]
*  All through the spiking. [[01:04:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3841.7s)]
*  And we don't want to worry about the details of all the stuff happening inside the neuron. [[01:04:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3843.54s)]
*  All of that stuff is for homeostasis and staying alive and maintaining the ability to spike. [[01:04:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3849.9399999999996s)]
*  But you see it more all of that internal richness. [[01:04:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3856.18s)]
*  You see it as computation? [[01:04:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3859.22s)]
*  I see it as the problem of finding the right abstraction. [[01:04:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3864.4199999999996s)]
*  I could easily say I don't want neuromodulation because it makes it more complicated. [[01:04:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3868.02s)]
*  But I know there is neuromodulation. [[01:04:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3873.2999999999997s)]
*  It's very important. [[01:04:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3875.3799999999997s)]
*  And so I ask myself, what is the indispensable function which this offers to my neuronal cell? [[01:04:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3876.66s)]
*  Why has biology kept it and kept it and kept it? [[01:04:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3884.5s)]
*  Because I can do some very cool and smart stuff with it and I want to have this in my model [[01:04:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3887.62s)]
*  because I want to use this particular thing. [[01:04:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3892.9s)]
*  For instance, neuromodulation, as everybody knows, by activating neuromodulators, [[01:04:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3896.18s)]
*  you can change the ion channel composition of the neuron, essentially changing their open [[01:05:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3902.66s)]
*  probabilities via the G-proteins and the internal signaling. [[01:05:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3909.22s)]
*  You can alter the ion channel membrane expression and therefore alter the function of the neuron, [[01:05:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3915.54s)]
*  its activation function, for instance, on a time basis of seconds to minutes. [[01:05:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3924.82s)]
*  There is the alternative, the horror on the other side. [[01:05:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3935.94s)]
*  You remember Henry Markram and this IBM Blue and this blue brain and so on. [[01:05:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3939.54s)]
*  I remember when he first got the money and I remember that people made remarks that he [[01:05:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3948.42s)]
*  won't use it properly and that they built huge neuronal cells with all the biophysical and [[01:05:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3955.14s)]
*  biochemical detail they could think of and then they didn't know what to do with it. [[01:06:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3962.7400000000002s)]
*  So that's the danger on the wall that you build all those neuromodulation, [[01:06:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3968.1s)]
*  ion channels, internal signaling, and genetic population. [[01:06:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3974.74s)]
*  Then you say, what is this thing good for? [[01:06:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3979.14s)]
*  Then your approach differs. [[01:06:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3983.8599999999997s)]
*  I thought one of the interesting things is in the paper that I read where you talk about this, [[01:06:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3986.5s)]
*  here's the level of abstraction. [[01:06:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3993.7799999999997s)]
*  You say, all right, I'm going to call these unknown variables [[01:06:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3995.3s)]
*  that are occurring internally in the cell. [[01:06:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=3999.2200000000003s)]
*  I'm going to call these parameters. [[01:06:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4001.94s)]
*  Instead of modeling the number of vesicles and how the ligands bind and communicate, [[01:06:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4006.9s)]
*  etc., instead of modeling all that detail, you're saying, well, that can come later. [[01:06:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4014.98s)]
*  Right now, I'm going to call all those things parameters and then figure out [[01:06:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4018.34s)]
*  what those parameters need to be doing, what those variables need to be doing. [[01:07:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4022.34s)]
*  This is one way. [[01:07:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4026.5800000000004s)]
*  As you know, I've written papers before that were purely about internal signaling. [[01:07:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4027.78s)]
*  They easily had some hundred or so proteins, but the reality is we have some [[01:07:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4032.1000000000004s)]
*  15,000 or so which may play a role. [[01:07:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4039.1400000000003s)]
*  There is always these decisions to be made. [[01:07:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4045.6200000000003s)]
*  Where do I draw the line? [[01:07:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4048.7400000000002s)]
*  This is correct. [[01:07:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4052.02s)]
*  This is what I said. [[01:07:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4054.1800000000003s)]
*  This would be the wrong approach when you say, I have 15,000 relevant proteins [[01:07:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4054.98s)]
*  in order to understand internal signaling and get the parameters at the external member, [[01:07:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4059.78s)]
*  which I need. [[01:07:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4066.9s)]
*  I need to build a dynamic system of 15,000 variables. [[01:07:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4067.94s)]
*  At that point, maybe you get the money for it even because the funding is always very crazy. [[01:07:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4073.0600000000004s)]
*  But in that case, you can point directly and say, we know these exist and therefore they're [[01:07:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4079.7799999999997s)]
*  important and I'm going to do something with those, which is different. [[01:08:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4085.2999999999997s)]
*  What you're doing is much more abstract saying, it doesn't really matter what exists. [[01:08:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4088.66s)]
*  There's a computation that has to occur and we'll figure that out. [[01:08:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4092.66s)]
*  Exactly. [[01:08:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4095.46s)]
*  Yeah. [[01:08:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4096.26s)]
*  Because I said the simple thing is, of course, to have an individual learning rate. [[01:08:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4096.98s)]
*  So you assume that the internal signaling somehow figures out the level of plasticity [[01:08:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4101.3s)]
*  that the cell undergoes. [[01:08:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4107.9400000000005s)]
*  You could say that the cell has zero plasticity at some point and then there is some internal [[01:08:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4109.9400000000005s)]
*  signaling going on and this raises the plasticity level of the cell. [[01:08:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4116.1s)]
*  So that would manifest then on the external membrane level as simply as a learning. [[01:08:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4120.26s)]
*  I just had Mitja Shiklovsky on the podcast and he views every single neuron as a controller [[01:08:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4128.26s)]
*  using what's called data driven dynamics. [[01:08:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4134.5s)]
*  The cell is trying to match, see how its output affects its input and then it changes [[01:08:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4138.419999999999s)]
*  what it's doing basically based on that mismatch. [[01:09:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4144.58s)]
*  One of the things I'm curious about that I want to ask you is, how does the cell know [[01:09:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4148.0199999999995s)]
*  when to be plastic? [[01:09:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4152.5s)]
*  What is that internal reference signal that the cell is aiming for? [[01:09:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4156.099999999999s)]
*  How is it so smart? [[01:09:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4160.339999999999s)]
*  How does it know what to do? [[01:09:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4161.299999999999s)]
*  Well, to a certain degree, I think there must be a lot of accumulation of evidence going on. [[01:09:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4162.18s)]
*  Similar as in decisions, you have to accumulate evidence from several sources until you have [[01:09:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4169.3s)]
*  sort of a critical amount, which means that you're going to persist more, for instance. [[01:09:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4176.66s)]
*  But when you mentioned Shiklovsky, I think you were right. [[01:09:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4182.58s)]
*  That was one of the few novel neuron models which I've seen in the past. [[01:09:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4185.62s)]
*  I was very happy with somebody also. [[01:09:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4191.94s)]
*  Like we said, we have essentially just one type of model in all of computational neuroscience. [[01:09:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4194.099999999999s)]
*  Oh, the point, the abstract point. [[01:10:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4204.259999999999s)]
*  Point or not point, it is always a model of... [[01:10:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4207.139999999999s)]
*  Essentially, we have a model which tries to explain when the neuron spikes. [[01:10:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4210.82s)]
*  Yeah. [[01:10:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4216.74s)]
*  Yeah. [[01:10:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4217.86s)]
*  That's the thing to explain. [[01:10:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4218.82s)]
*  Yeah, that's kind of funny. [[01:10:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4220.0199999999995s)]
*  As a matter of fact, we think that in our model, we want to have a rate model. [[01:10:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4222.9s)]
*  We want to have a rate which changes over 100 milliseconds. [[01:10:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4228.339999999999s)]
*  The rate is just the average amount of spiking over some time. [[01:10:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4232.259999999999s)]
*  Exactly. [[01:10:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4235.219999999999s)]
*  In that 100 milliseconds, it either spikes or it spikes two times or whatever. [[01:10:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4235.46s)]
*  And so within a second, it spikes one time or 10 times. [[01:10:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4239.86s)]
*  So it has its frequency because that is one of the earliest things I found about neurons having [[01:10:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4243.86s)]
*  different intrinsic frequencies and sticking to them very much. [[01:10:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4251.62s)]
*  This was back in 2006 at a time when people reported on neurons always in averages. [[01:10:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4256.0199999999995s)]
*  Yeah. [[01:11:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4262.82s)]
*  And suddenly it occurred to me that this can't be right. [[01:11:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4263.46s)]
*  And I tried to get the data from the experimentalists. [[01:11:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4266.9s)]
*  They said, yes, no, of course they're not all alike. [[01:11:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4270.34s)]
*  They're different. [[01:11:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4272.74s)]
*  And I look at it and I see, look, it's a log normal. [[01:11:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4273.78s)]
*  It's a power law. [[01:11:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4276.26s)]
*  This is your log normal. [[01:11:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4278.18s)]
*  Yes. [[01:11:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4279.54s)]
*  And the experimentalists, they didn't care. [[01:11:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4280.0199999999995s)]
*  Describe what that is. [[01:11:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4283.54s)]
*  Well, the thing is in theory, what people did is they initialized all neurons in the same way. [[01:11:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4285.14s)]
*  You had homogeneous neurons. [[01:11:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4292.66s)]
*  They were all initialized as if they were all alike. [[01:11:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4294.66s)]
*  And they're like integrated fire type neurons? [[01:11:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4297.94s)]
*  Yes. [[01:11:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4300.26s)]
*  And the parameters, they were all alike. [[01:11:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4300.74s)]
*  They all had, so for instance, they all had 10 hertz, for instance, all of them. [[01:11:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4302.58s)]
*  On average. [[01:11:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4307.86s)]
*  Okay. [[01:11:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4308.82s)]
*  And every single one. [[01:11:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4309.700000000001s)]
*  And then they would do cognition by modulating within some range. [[01:11:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4311.9400000000005s)]
*  Yes, it was an ideological thing about emergence from interaction of identical particles. [[01:11:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4317.06s)]
*  And therefore the neurons had to be all identical from the ideology. [[01:12:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4325.9400000000005s)]
*  But the experimentalists knew that, but the theorists didn't care. [[01:12:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4332.42s)]
*  So what is log normal and why is it important? [[01:12:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4337.14s)]
*  Well, it turned out when I build a neural network with all these different kinds of frequencies, [[01:12:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4340.42s)]
*  with the high frequency neurons and low frequency neurons and so on, [[01:12:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4347.860000000001s)]
*  then as a matter of fact, I have not mathematically been able to prove or show this, [[01:12:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4352.02s)]
*  but I get all these effects like I did with the symbolic paper. [[01:12:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4358.66s)]
*  I get the effect that the information content concentrates in only a few neurons [[01:12:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4363.46s)]
*  because the neurons which have the highest fire rate also have the most connections. [[01:12:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4376.66s)]
*  So now you're talking about your mutual information work as well, right? [[01:13:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4384.099999999999s)]
*  Yes, that derived from that because I have all these different neurons in my model. [[01:13:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4388.18s)]
*  Okay. All right. [[01:13:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4393.46s)]
*  They are not initialized in the same way. They are initialized over a range. [[01:13:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4394.34s)]
*  And I have low moments and have many low firing neurons and a few high fault. [[01:13:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4399.9400000000005s)]
*  And why is that important? Because it allows the system to be scale free. [[01:13:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4406.5s)]
*  What is the importance of that distribution? [[01:13:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4410.42s)]
*  A good question. I can't really say too much about it really. [[01:13:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4412.42s)]
*  I always focused on the idea that what it means is that I have hub and spoke neurons, [[01:13:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4419.3s)]
*  that I have... [[01:13:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4424.34s)]
*  Hub and spoke neurons. [[01:13:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4425.78s)]
*  Exactly. That I have a structure of important and lesser important neurons. [[01:13:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4427.22s)]
*  Like small world kind of... [[01:13:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4431.62s)]
*  Then it was my idea that the important neurons need to speak to each other [[01:13:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4433.46s)]
*  without regard of the lower important neurons and such ideas. [[01:13:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4438.1s)]
*  But in this paper, I actually wrote this down that I hope somebody with more mathematics could... [[01:14:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4442.5s)]
*  Yeah, it could prove just how many patterns you could really store in such a network. [[01:14:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4451.700000000001s)]
*  And I would like to know whether the storage capacity, for instance, [[01:14:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4461.06s)]
*  is comparable to an associative network, associative memory network. [[01:14:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4464.82s)]
*  It's not for me to calculate these things. [[01:14:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4470.82s)]
*  It would be great if somebody did that. [[01:14:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4474.42s)]
*  Because at this point, I don't really know whether it is actually really much better [[01:14:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4476.58s)]
*  in terms of the number of patterns you can store in a memory [[01:14:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4484.82s)]
*  or whether it's just comparable and really no improvement at all. [[01:14:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4488.259999999999s)]
*  I don't think it is worse because I've looked at the numbers and they seem higher. [[01:14:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4492.18s)]
*  For associative networks, the usual thing is you take a vector and you store the vector [[01:14:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4498.9800000000005s)]
*  and you store the next vector and the next vector. [[01:15:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4503.9400000000005s)]
*  And if they're orthogonal or so, then there are so and so many vectors that you can store per [[01:15:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4506.34s)]
*  size of the network. [[01:15:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4511.700000000001s)]
*  Okay. [[01:15:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4513.9400000000005s)]
*  That has been done, has been calculated and so on. [[01:15:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4514.740000000001s)]
*  And I don't know how one would calculate it in this case. [[01:15:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4518.42s)]
*  What does vertical and horizontal functions mean in your single-neuron model? [[01:15:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4524.82s)]
*  I already wonder whether it was a good choice or what because the internal and external [[01:15:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4530.9800000000005s)]
*  is in a way sufficient. [[01:15:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4535.78s)]
*  It's much more intuitive. [[01:15:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4537.54s)]
*  The idea was the neuron has its connections to other neurons. [[01:15:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4539.54s)]
*  And there's calculations going on in a network. [[01:15:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4544.42s)]
*  We call it the horizontal network for calculating information. [[01:15:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4547.62s)]
*  And then on the other hand, the neuron has, as I said, 15,000 or up to 70,000 different [[01:15:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4551.94s)]
*  proteins that interact with each other in an internal signal network. [[01:15:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4558.5s)]
*  There is the metabolic network, of course, which overlaps with it. [[01:16:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4564.42s)]
*  So there are many, many proteins and they have certain rules of how they interact and how they [[01:16:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4569.22s)]
*  run as a dynamical system. [[01:16:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4577.78s)]
*  And it has any amount of complexity comparable to a neural network. [[01:16:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4580.0199999999995s)]
*  So it's like you have other people have same ideas. [[01:16:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4584.66s)]
*  They saw a neuron model where somebody said, you know, all this dendritic integration, [[01:16:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4589.62s)]
*  we just throw a multilayer perceptron into the neuron. [[01:16:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4594.18s)]
*  And then the neuron gets inputs, does a multilayer perceptron kind of thing and puts out, gives [[01:16:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4599.3s)]
*  the output. [[01:16:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4605.54s)]
*  And here we have essentially neural network inside the neuron. [[01:16:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4606.5s)]
*  If I model the protein network as a neural network, then I have a neural network inside [[01:16:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4611.3s)]
*  that would be the vertical. [[01:16:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4616.9s)]
*  Wouldn't it be more like a graph neural network though? [[01:16:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4618.42s)]
*  Maybe that's too technical because there's no idea. [[01:17:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4623.14s)]
*  But that would be the vertical. [[01:17:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4627.54s)]
*  So I have the neuron and I have the vertical. [[01:17:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4629.06s)]
*  I have a whole complex signal network here. [[01:17:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4632.18s)]
*  A dynamical system, I can model it with the help of ordinary differential equations, [[01:17:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4635.22s)]
*  which is nice, but also, as you know, very complex because as soon as my concentrations [[01:17:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4640.9800000000005s)]
*  are not very precise, then this network may give any kind of information because of too [[01:17:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4646.1s)]
*  many. [[01:17:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4652.18s)]
*  You know, once it's more than three or four, it goes out of errors, become larger and larger. [[01:17:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4653.54s)]
*  And one could say that neural networks have a lot of success because they don't have [[01:17:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4661.22s)]
*  these problems. [[01:17:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4665.38s)]
*  They're not built from differential equations. [[01:17:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4666.5s)]
*  And as soon as having a couple of wrong concentrations in the network, the results are completely [[01:17:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4669.54s)]
*  not useful. [[01:17:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4678.1s)]
*  And then the neuron interacts with 15,000, 100,000 of other neurons, [[01:18:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4680.66s)]
*  building, making a computation, even though inside of itself, it has approximately the same [[01:18:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4687.22s)]
*  complexity in terms of calculating its own activity, its needs, its metabolic needs, [[01:18:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4693.46s)]
*  its ability to read out DNA information. [[01:18:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4705.38s)]
*  When do you need which DNA information? [[01:18:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4711.38s)]
*  When do you want to have more [[01:18:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4713.7s)]
*  This is amazing. [[01:19:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4744.42s)]
*  Well, that's the thing is I don't want to keep track of the thousands and thousands of proteins. [[01:19:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4745.86s)]
*  I want to just be able to say, OK, at some level, I'm just going to model this as a dynamical [[01:19:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4751.62s)]
*  system. [[01:19:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4756.179999999999s)]
*  And I think that's comforting to someone like me who I don't want to talk about the ion channels [[01:19:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4756.74s)]
*  when I'm talking about working memory or trying to explain working memory. [[01:19:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4762.099999999999s)]
*  I mean, I know that those things are important. [[01:19:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4766.82s)]
*  And if it is the case that we do need that internal cellular machinery, that it is essential [[01:19:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4768.82s)]
*  for our cognitive processes as part of that story, I want to be able to model it at a level of [[01:19:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4776.9s)]
*  abstraction that I'm comfortable with. [[01:19:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4780.9s)]
*  Exactly. That is the point. [[01:19:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4782.66s)]
*  I personally am fascinated with this word. [[01:19:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4784.5s)]
*  And I would love to go into details and read up on every single protein because it's fascinating. [[01:19:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4787.62s)]
*  But I agree with you. [[01:19:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4795.78s)]
*  And that's the advantage of trying to do something functional in computational science, [[01:19:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4796.74s)]
*  that you have to tell yourself just by studying what BDNF does in all circumstances. [[01:20:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4802.74s)]
*  It's not going to help the function of the model. [[01:20:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4809.3s)]
*  As you said, we need them for a proper amount of abstraction. [[01:20:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4814.099999999999s)]
*  But aren't you tempted, though, because you're sort of opening that book. [[01:20:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4819.139999999999s)]
*  Aren't you tempted to read all the words in the book then? [[01:20:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4824.9800000000005s)]
*  Or are you like mean? [[01:20:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4827.46s)]
*  You want to keep it somewhat at bay? [[01:20:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4830.18s)]
*  Unfortunately, no. [[01:20:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4832.1s)]
*  I am that kind of person. [[01:20:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4832.900000000001s)]
*  That's why I did linguistics in a way and even started to learn different languages. [[01:20:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4835.860000000001s)]
*  And so there's lots of details, information. [[01:20:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4840.1s)]
*  I didn't mind that. [[01:20:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4842.660000000001s)]
*  Of course, my goal was to understand how languages operate. [[01:20:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4843.620000000001s)]
*  But I didn't mind learning a couple of languages. [[01:20:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4849.22s)]
*  Yeah. [[01:20:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4853.06s)]
*  But that's the thing is like you want to understand how languages operate. [[01:20:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4853.54s)]
*  And now you're going to have to study the nucleus of a single neuron. [[01:20:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4857.38s)]
*  Yeah, it seems like a stretch. [[01:21:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4861.22s)]
*  Yeah. [[01:21:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4863.14s)]
*  That is really interesting. [[01:21:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4864.5s)]
*  I had a conversation with a botanist who is actually a specialist on Mendel. [[01:21:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4866.26s)]
*  And maybe we're doing an interview or so. [[01:21:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4870.02s)]
*  But I don't know. [[01:21:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4874.9800000000005s)]
*  And he said, well, it sounds strange. [[01:21:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4876.02s)]
*  But if you think of it, it's logical. [[01:21:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4878.5s)]
*  If you want to understand how thinking works, you need to understand the nucleus of the cell. [[01:21:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4880.42s)]
*  Because that's not obvious. [[01:21:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4887.38s)]
*  That's what we use. [[01:21:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4889.7s)]
*  That's what he said. [[01:21:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4891.06s)]
*  Yeah, but we also use atoms. [[01:21:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4891.86s)]
*  And we don't have to understand atoms to understand thinking. [[01:21:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4893.46s)]
*  But our thinking uses exactly these things. [[01:21:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4896.26s)]
*  And the idea that the electrophysiological events are sufficient [[01:21:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4900.18s)]
*  for the cognitive content of what's going on in the brain. [[01:21:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4906.18s)]
*  That is already put at absurd. [[01:21:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4914.26s)]
*  As soon as you, let's say, smoke some cannabis. [[01:21:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4916.9800000000005s)]
*  Which we'll do together right after this interview. [[01:22:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4922.9s)]
*  Just as an example. [[01:22:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4924.9s)]
*  That works in your brain. [[01:22:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4926.18s)]
*  But it works on those CB receptors. [[01:22:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4927.86s)]
*  It goes to the G protein. [[01:22:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4931.86s)]
*  The G proteins affect your iron channels. [[01:22:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4933.3s)]
*  It goes into the cell, all kinds of places, certain parts of the brain. [[01:22:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4936.26s)]
*  And your processing is different. [[01:22:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4940.820000000001s)]
*  And don't tell me that a neural network with electrophysiology would be sufficient. [[01:22:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4942.9800000000005s)]
*  Well, OK, right. [[01:22:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4947.62s)]
*  But what I want to say, the way that you just described that, [[01:22:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4948.58s)]
*  I want to re-describe it by saying that smoking the weed [[01:22:31](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4951.78s)]
*  alters the shape of the manifold that I'm operating under. [[01:22:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4956.34s)]
*  However, that is whatever those constituent parts that [[01:22:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4961.06s)]
*  give rise to the emergent property of a manifold. [[01:22:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4965.38s)]
*  G-coupled receptors, cannabinoid receptors, fine. [[01:22:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4968.66s)]
*  You can talk about that. [[01:22:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4971.14s)]
*  But at my level of wanting to understand these things, [[01:22:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4972.18s)]
*  I can just talk about the dynamical system aspect of it. [[01:22:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4975.38s)]
*  I have my doubts about that. [[01:22:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4977.86s)]
*  I mean, think of something more drastic. [[01:22:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4979.3s)]
*  If I call you names now, it could happen that your adrenaline goes up. [[01:23:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4982.02s)]
*  And that's some way down in your kidney. [[01:23:05](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4985.86s)]
*  Do it. Call me names. [[01:23:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4989.54s)]
*  Let's go. [[01:23:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4990.42s)]
*  I wouldn't work right now because you're laughing. [[01:23:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4992.42s)]
*  But I know what you mean. [[01:23:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4994.900000000001s)]
*  You can be in a situation and somebody talks to you in a very angry way. [[01:23:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=4996.5s)]
*  And your adrenaline goes up. [[01:23:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5000.900000000001s)]
*  And your whole body, there's a flight of flight motors [[01:23:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5002.58s)]
*  because of the tone of voice or just the words that you heard. [[01:23:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5005.9400000000005s)]
*  If you just read them, yeah, you haven't even, if you just read them, [[01:23:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5010.9800000000005s)]
*  that's not even and it's clear. [[01:23:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5014.820000000001s)]
*  It's only the language. [[01:23:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5016.18s)]
*  But so now, now of your account on that, [[01:23:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5018.18s)]
*  that's exactly what will go eventually into the media [[01:23:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5020.26s)]
*  and then we'll have the anger molecule, right? [[01:23:42](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5022.900000000001s)]
*  Like dopamine, right? [[01:23:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5026.34s)]
*  Is the happy molecule or whatever. [[01:23:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5027.3s)]
*  Or adrenaline. [[01:23:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5029.9400000000005s)]
*  No, adrenaline is very important. [[01:23:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5030.740000000001s)]
*  The brain works similar to dopamine. [[01:23:52](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5032.42s)]
*  And it certainly activates all kinds of neurons in your brain [[01:23:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5034.42s)]
*  and also change the ion channels on the operation. [[01:23:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5039.9400000000005s)]
*  And yes, it could be if you don't watch out [[01:24:03](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5043.22s)]
*  for like 20 minutes, 30 minutes afterwards, [[01:24:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5046.74s)]
*  that your cognition changes. [[01:24:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5050.58s)]
*  Because you're still angry at an email somebody wrote you. [[01:24:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5054.179999999999s)]
*  Yeah, I had to give a talk. [[01:24:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5058.66s)]
*  You want to make it clear that this sort of talk about electrophysiology [[01:24:19](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5059.46s)]
*  and some dimensions which change or so [[01:24:25](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5065.3s)]
*  is too far away from the properties language really has [[01:24:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5070.179999999999s)]
*  or what our brain really operates with. [[01:24:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5075.54s)]
*  So how would this, let's say you are successful [[01:24:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5079.86s)]
*  in your endeavors to model neurons this way, right? [[01:24:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5083.54s)]
*  So some are important with high mutual information. [[01:24:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5086.339999999999s)]
*  You need these vertical and horizontal accounts, [[01:24:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5089.86s)]
*  this internal machinery. [[01:24:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5093.62s)]
*  How would that change artificial intelligence? [[01:24:55](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5095.54s)]
*  Would, you know, or do you care? [[01:24:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5099.0599999999995s)]
*  Yeah, that's what I said. [[01:25:01](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5101.219999999999s)]
*  Once we have complex building blocks, we can build simple systems. [[01:25:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5102.34s)]
*  And the building blocks are adequate for the tasks [[01:25:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5107.46s)]
*  that we want to use, namely human cognition. [[01:25:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5110.66s)]
*  I make this different, I told you that. [[01:25:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5113.22s)]
*  I make this different with engineering and actually building. [[01:25:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5114.82s)]
*  The original idea of artificial intelligence [[01:25:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5118.74s)]
*  was a small field of computer science. [[01:25:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5121.06s)]
*  It was only sort of building systems that are like human-like intelligence. [[01:25:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5123.3s)]
*  They've changed the meaning all the time. [[01:25:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5129.7s)]
*  But if you just build a system that does a certain task, that's engineering, [[01:25:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5132.1s)]
*  these days it's also called artificial intelligence. [[01:25:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5136.42s)]
*  The original artificial intelligence which I stick to [[01:25:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5139.14s)]
*  was actually building human-like models. [[01:25:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5141.700000000001s)]
*  Old gophi. [[01:25:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5145.22s)]
*  Like humans, yes. [[01:25:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5146.34s)]
*  And if you want to do that and if you have the building blocks from the brain, [[01:25:47](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5147.9400000000005s)]
*  if you can build it like a brain, [[01:25:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5151.46s)]
*  then we should at least be able to get away from [[01:25:54](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5154.02s)]
*  these absolutely huge and wasteful and essentially dumb huge models. [[01:25:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5157.62s)]
*  Yeah, it's funny. [[01:26:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5168.58s)]
*  Like when I, the rote response or the very typical response when I say like, [[01:26:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5169.7s)]
*  often, so this podcast is called Brain Inspired. [[01:26:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5175.139999999999s)]
*  And often I point to the fact that modern AI doesn't pay any attention to brains [[01:26:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5178.42s)]
*  and what a shame that is and stuff. [[01:26:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5184.099999999999s)]
*  Often I have neuroscientists on and I say, well, what do you think of modern AI? [[01:26:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5186.26s)]
*  And without fail, they have to say, well, of course, I'm very impressed with the abilities [[01:26:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5190.5s)]
*  of modern language models and stuff. [[01:26:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5197.22s)]
*  But I sense that if I asked you that, you would not begin. [[01:26:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5199.3s)]
*  I'm not impressed in the least. [[01:26:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5203.3s)]
*  I know very well how they work. [[01:26:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5205.14s)]
*  And as I said, there's my friend who's building something in Austria. [[01:26:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5206.74s)]
*  And long before the Chinese with deep sea, [[01:26:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5210.9s)]
*  he already showed that you can shrink it enormously. [[01:26:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5213.62s)]
*  And then these people came about and so on. [[01:26:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5217.38s)]
*  And it's pure engineering. [[01:27:00](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5220.099999999999s)]
*  And the fact, and actually, language as such is not so complicated. [[01:27:02](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5222.9s)]
*  And the number of words we use. [[01:27:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5229.14s)]
*  Thank you for saying that. [[01:27:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5230.82s)]
*  Thank you for saying that. [[01:27:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5234.58s)]
*  The number of words we use in everyday discourses. [[01:27:17](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5237.14s)]
*  So that's like some 10,000, 20,000 words. [[01:27:20](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5240.0199999999995s)]
*  Yeah. But we are able to communicate in spite of that and quite a lot. [[01:27:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5243.7s)]
*  That is the interesting part. [[01:27:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5250.9s)]
*  And what interests me is not so much the tool of communication that we use, [[01:27:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5253.14s)]
*  but what is behind it. [[01:27:39](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5259.62s)]
*  So with the simple words I use, I'm still able to cause you to come up with similar things [[01:27:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5261.78s)]
*  and ideas that relate to it, which are interesting to me. [[01:27:51](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5271.62s)]
*  Right. [[01:27:57](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5277.54s)]
*  Right. And this is not this in spite of we have so few words, but in spite of that, [[01:27:58](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5278.18s)]
*  because we have these complex memories and experiences and so on. [[01:28:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5284.5s)]
*  And that's a way to access it. [[01:28:09](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5289.62s)]
*  I mean, you Germans, you have many more words than actually neologisms [[01:28:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5293.46s)]
*  are perhaps the German languages. [[01:28:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5298.66s)]
*  Yeah, one of them. [[01:28:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5301.3s)]
*  That's true. [[01:28:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5302.42s)]
*  Yeah. [[01:28:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5302.9s)]
*  Best example of that. [[01:28:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5303.3s)]
*  Yeah. [[01:28:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5304.26s)]
*  Everything is always a word. [[01:28:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5304.66s)]
*  Yeah. Every new expression, many new expressions can be used as a word. [[01:28:26](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5306.099999999999s)]
*  Okay. So then that's AI, right? [[01:28:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5314.18s)]
*  Okay. What I originally asked you there was how this sort of model would change AI. [[01:28:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5316.34s)]
*  And what would it just, it would make everything more efficient or [[01:28:41](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5321.94s)]
*  your pro-symbolic approach to AI, I suppose. [[01:28:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5325.94s)]
*  Yes. Yes. Yeah, there are also people out there, they call, there's a whole movement, [[01:28:48](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5328.98s)]
*  the neuro-symbolic where they're trying to put these things together, but they're already [[01:28:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5333.54s)]
*  shrink in horror because there was a lecture how to put logical reasoning into large language models. [[01:28:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5339.94s)]
*  Okay. [[01:29:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5350.099999999999s)]
*  And I'm so- [[01:29:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5350.419999999999s)]
*  Jam it in there. [[01:29:10](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5350.9s)]
*  No, no, no, no. Just the other way around. [[01:29:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5351.78s)]
*  How to employ large language models to give you the kind of information you need for your reasoning. [[01:29:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5354.5s)]
*  That would be my type of question. [[01:29:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5361.62s)]
*  Wait, okay. Explain this to me more. So you don't want to put reasoning ability into the model. [[01:29:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5364.74s)]
*  You want to use the model to- [[01:29:30](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5370.02s)]
*  To give the knowledge that I need for my reasoning. [[01:29:32](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5372.26s)]
*  Oh, okay. Just use it as a tool. You mean? Not- [[01:29:35](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5375.94s)]
*  There's still the old problem of Reagan, you know, that [[01:29:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5378.58s)]
*  this old problem in AI was of course always where do we get our common sense information from. [[01:29:43](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5383.7s)]
*  Right. [[01:29:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5389.86s)]
*  And these people have made good, have good progress. And then there was always the question, [[01:29:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5390.42s)]
*  how do I immediately know that I don't know something? And there the LLMs are not so great. [[01:29:56](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5396.98s)]
*  Oh, okay. Yeah. Well, they're not great. There's a cottage industry of showing what they're not great at, but- [[01:30:04](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5404.34s)]
*  Yeah, they make it up then. They like to make it up when they don't know something. [[01:30:11](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5411.06s)]
*  Do you use LLMs? [[01:30:16](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5416.58s)]
*  I don't know. I don't remember the examples, but I don't know whether it's a good example. [[01:30:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5418.58s)]
*  It's like asking you, did you see Nixon or so? And you immediately know, yes, you met him or no. [[01:30:23](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5423.38s)]
*  Right, right. [[01:30:28](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5428.740000000001s)]
*  Yeah, because it's Nixon somehow. Or let's say Reagan. [[01:30:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5429.780000000001s)]
*  These are old references. [[01:30:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5433.54s)]
*  Yeah, okay. Reagan then or maybe- [[01:30:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5434.82s)]
*  Say Obama or something. [[01:30:37](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5437.38s)]
*  Exactly. Or Clinton. Did you ever meet Bill Clinton? And you would probably be able to answer that. [[01:30:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5438.66s)]
*  Yeah. [[01:30:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5444.18s)]
*  Yeah. Charlie Chaplin. You're going to- [[01:30:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5444.66s)]
*  Okay. Yes, I know. But it's this ability to immediately be able to, [[01:30:46](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5446.26s)]
*  you don't have to think about it for a long time, whether you ever met him. You know the negative. [[01:30:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5453.46s)]
*  Right. And the LLMs don't know their negatives. [[01:30:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5459.86s)]
*  Okay. [[01:31:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5466.82s)]
*  Not very well. Not very well. [[01:31:07](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5467.139999999999s)]
*  Add it to the list, yeah. But it seems like any criticism of AI, then it eventually gets fixed, [[01:31:08](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5468.5s)]
*  right? I mean- [[01:31:14](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5474.82s)]
*  Well, that's what they say, but you can't fix. Look, this is something simple. You cannot fix [[01:31:15](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5475.62s)]
*  the fact that there are always a high percentage of errors in it or that they have this hallucination [[01:31:21](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5481.7s)]
*  because if you train a neural network and you train it perfectly, then you have overfitted it, [[01:31:27](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5487.7s)]
*  you've overtrained it, and you have no generalization. In order to get a generalization, [[01:31:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5494.82s)]
*  you have to let it leave off and even the training has to be below 100%. [[01:31:40](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5500.179999999999s)]
*  But there's that, after that dip on that, this is where big data comes in, right? And lots of [[01:31:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5504.9s)]
*  training where generalization decreases, like, eventually, but then it re-increases. [[01:31:50](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5510.74s)]
*  So Uri Hassan talks about this phenomenon as direct fit where you actually, we are overfitting, [[01:31:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5519.139999999999s)]
*  and that's how we generalize because we're interpolating. We've fit so much that it [[01:32:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5526.099999999999s)]
*  encompasses everything we need and that we don't need to intentionally- [[01:32:12](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5532.42s)]
*  This is in the areas where we believe we have no lack of data, but in very many areas, [[01:32:18](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5538.1s)]
*  we do have a lack of data, and always will. They automatically assume that you have tons of data, [[01:32:24](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5544.5s)]
*  but you don't always have them. Well, you don't have maybe the right data. [[01:32:34](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5554.1s)]
*  Yeah, that too, but that also, but in general, I would say right now, it's a low-hanging fruit. [[01:32:38](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5558.1s)]
*  You see all the results from the areas where lots of data exists. [[01:32:44](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5564.34s)]
*  Right, right. Which is the stupid internet. [[01:32:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5569.62s)]
*  I still remember teaching in the beginning, teaching the GPT tool about Satterländisch. [[01:32:53](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5573.22s)]
*  That is a Frisian language in North Germany. So I asked him about it, he didn't know it, [[01:32:59](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5579.06s)]
*  and so I explained to him that it was upper Bavarian dialect and so on. And the system, [[01:33:06](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5586.18s)]
*  happily responded and told me, yes, now I know what it is. It is an upper Bavarian dialect. [[01:33:13](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5593.9400000000005s)]
*  I don't like these systems. One time it's fun, but the second time it's not fun. [[01:33:22](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5602.900000000001s)]
*  That's funny that you called the system him and he. [[01:33:29](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5609.22s)]
*  I should call it it, but it is German. [[01:33:33](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5613.780000000001s)]
*  Yeah, right after this, I'll go start my nonprofit and see how far I can take it. [[01:33:36](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5616.9800000000005s)]
*  Okay, Gabriella, thank you so much for joining me and continued success with your work. [[01:33:45](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5625.3s)]
*  Yes, thank you. [[01:33:49](https://www.youtube.com/watch?v=MMirmqzjAWk&t=5629.06s)]
