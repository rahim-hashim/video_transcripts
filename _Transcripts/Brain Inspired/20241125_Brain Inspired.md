---
Date Generated: December 03, 2024
Transcription Model: whisper medium 20231117
Length: 6547s
Video Keywords: []
Video Views: 406
Video Rating: None
Video Description: Hessam Akhlaghpour describes how organisms may have evolved universal computation using RNA sequences and secondary structures.

Show notes:  https://braininspired.co/podcast/199/

Patreon (full episodes and Discord community:  https://www.patreon.com/braininspired

Apple podcasts:  https://itunes.apple.com/us/podcast/brain-inspired/id1428880766?mt=2
Spotify:  https://open.spotify.com/show/2UZj8c8Ap5oc2gh2rJxLLe

The Transmitter is an online publication that aims to deliver useful information, insights and tools to build bridges across neuroscience and advance research. Visit thetransmitter.org to explore the latest neuroscience news and perspectives, written by journalists and scientists. 

Read more about our partnership: https://www.thetransmitter.org/partners/

Sign up for the “Brain Inspired” email alerts to be notified every time a new “Brain Inspired” episode is released: https://www.thetransmitter.org/newsletters/

To explore more neuroscience news and perspectives, visit thetransmitter.org.


Hessam Akhlaghpour is a postdoctoral researcher at Rockefeller University in the Maimon lab. In that capacity, he studies the neuroscience of decision making and cognition in fruit flies. However, his interests took a different turn, or an additional turn, after being inspired by Randy Gallistel and Adam King's book Memory and the Computational Brain. Randy has been on the podcast before to discuss his ideas that memory needs to be stored in something more stable than the synapses between neurons, and how that something could be genetic material like RNA. When Hessam read this book, as you'll hear him describe, he was re-inspired to think of the brain the way he used to think of it before experimental neuroscience challenged his views. It re-inspired him to think of the brain as a computational system. But it also led to what we discuss today, the idea that RNA has the capacity for universal computation, and Hessam's development of how that might happen. So we discuss that background and story, why universal computation has been discovered in organisms yet since surely evolution has stumbled upon it, and how RNA might and combinatory logic could implement universal computation in nature.

0:00 - Intro
4:44 - Hessam's background
11:50 - Randy Gallistel's book
14:43 - Information in the brain
17:51 - Hessam's turn to universal computation
35:30 - AI and universal computation
40:09 - Universal computation to solve intelligence
44:22 - Connecting sub and super molecular
50:10 - Junk DNA
56:42 - Genetic material for coding
1:06:37 - RNA and combinatory logic
1:35:14 - Outlook
1:42:11 - Reflecting on the molecular world
---

# BI 199 Hessam Akhlaghpour Natural Universal Computation
**Brain Inspired:** [November 25, 2024](https://www.youtube.com/watch?v=7wg96ioG2Q8)
*  One of the most important insights of the 20th century, in my opinion, was the finding
*  that with a very simple set of rules, you can achieve what's called universal computation.
*  It's common wisdom that our models of computation achieve universality, but it's wrong.
*  And I'll explain why.
*  When you take a step back, you see that there are these molecules within cells that resemble
*  strings of symbols.
*  And they also fold up into these tree-like structures that, you know, kind of would be
*  very useful for doing computational stuff.
*  This is Brain Inspired, powered by the transmitter.
*  Hello, I'm Paul.
*  My guest today is Hesam Aglakhpur.
*  Hesam is a postdoctoral researcher at Rockefeller University in the Maimon Lab.
*  His experimental work is in fly neuroscience, mostly studying spatial memories in fruit flies.
*  However, we're going to be talking about a different, although somewhat related, side
*  of his postdoctoral research.
*  This aspect of his work involves theoretical explorations of molecular computation, which
*  are deeply inspired by Randy Gallistil and Adam King's book, Memory and the Computational
*  Brain.
*  Randy Gallistil has been on the podcast before to discuss his ideas that memory needs to
*  be stored in something more stable than in the synapses between neurons, and how that
*  something could be genetic material like RNA.
*  When Hesam read this book, as you'll hear him describe, he was re-inspired to think
*  of the brain the way he used to think of it before experimental neuroscience challenged
*  his views.
*  So it re-inspired him to think of the brain as a computational system.
*  But it also led to what we discussed today, the idea that RNA has the capacity for universal
*  computation.
*  So we discussed that background and story, why universal computation hasn't been discovered
*  in organisms yet, since surely evolution would have stumbled upon it by now, and how RNA
*  logic could implement universal computation in nature.
*  And a little bit about how Hesam developed the ideas for how this could all come together.
*  Show notes are at braininspired.co.
*  slash podcast slash 199.
*  If you enjoyed this episode, you might also like episodes with Randy Gallistil and David
*  Glansman.
*  Those episodes are 126 and 172 respectively, which I also link to in the show notes.
*  Thank you to all past, present, and future Patreon supporters, one of whom actually just
*  created a brain-inspired search engine, which was shared in the Discord.
*  So thank you for that, Brian.
*  I hope it's a useful resource for our little community here.
*  Okay, here we go with Hesam.
*  Last time, I guess we were off the boat.
*  So I was at this workshop in Norway that you were at, and that's where we met.
*  You were talking combinatorial logic and RNA then, and that's what we're going to talk
*  about now.
*  So, it was fun on the boat with you.
*  Getting to know you a little bit and good to see you again.
*  Yeah, good to see you too.
*  Yeah, I'm super excited about this opportunity to talk to you.
*  I told you that I was an old fan of this show.
*  I started listening to it very early in my podcast, and to imagine that I'd be speaking
*  on it is a very exciting thing.
*  Well, I would be remiss to say you actually had mentioned the Brain Science podcast by
*  Dr. Ginger Campbell to me and how that was an early influence.
*  And she was like an early...
*  I loved her podcast too, and that was part of the inspiration eventually when I started
*  Brain Inspired.
*  So, shout out to Ginger.
*  Yeah, yeah, I love that podcast.
*  I wish it was still going on, but yeah, sometimes I just catch myself going back to listening
*  to really old episodes.
*  Oh yeah, because she does a really good job.
*  She's a really good host.
*  I'll just leave it at that.
*  Yeah, absolutely.
*  But yeah, unfortunately she doesn't make it anymore.
*  But I mean, I remember going on runs in Nashville, Tennessee.
*  You know, you have that memory of where you were when you heard something or when you
*  were reading something, and maybe we'll talk about that with that Gallistole book that
*  we'll mention in a few minutes.
*  But I remember specific places in Nashville listening to her podcast and just enjoying
*  it a lot.
*  But anyway, good to have you here.
*  So what we're going to talk about is what you've been on lately, lately for the past
*  few years, which is the RNA and universal computation.
*  But that's not how you came here.
*  So I know you've worked with Drosophila.
*  You've done a lot of experimental neuroscience work up to this point.
*  So just what are you doing your...
*  What's the right way to say this in real life, in your day job?
*  Yeah.
*  My day job is basically doing experiments on flies.
*  I'm in Gabby Mamins lab here at Rockefeller.
*  And basically I'm doing fly neuroscience, doing behavioral experiments, using...
*  You're a postdoc.
*  ...opthogenetics, imaging.
*  You're a postdoc.
*  Yes, I'm a postdoc.
*  Yeah.
*  Yeah.
*  Okay.
*  So, all right.
*  So I just wanted to bring that up because what we're going to talk about is something
*  that you and I also shared sort of a...
*  Well, I want you to tell your story of how you came to this, how you came to what you're
*  studying now, just kind of as a background, because I had the same...
*  I wonder how many...
*  What percentage of graduate students have this sort of...
*  What would you call it?
*  Disillusionment?
*  Well, a lot have that, but very specific kind of disillusionment in that like, oh, is this
*  all wrong?
*  Like what...
*  That is a pretty major disillusionment, but not necessarily is this all wrong, but a conniption
*  about what you're doing and stuff.
*  So tell the listeners.
*  Yeah.
*  Yeah, sure.
*  So I did my undergrad in computer engineering.
*  I was really into like computer science, algorithms, data structures.
*  I felt that I was very proficient at that stuff.
*  And then for grad school, I decided that I want to go into neuroscience because this
*  is the most exciting field right now.
*  And the brain poses a very challenging problem to scientists.
*  And it seems like I can use all of the skills that I learned at computer science to try
*  to understand this very complex system that's mainly known for being a computational organ.
*  And so I came in kind of naively thinking that, okay, all of this stuff that I learned
*  about designing algorithms, data structures, figuring out what algorithmic complexity this
*  algorithm runs at, what's the memory complexity, all this kind of stuff.
*  I thought that would be relevant to the study of the brain.
*  And so I...
*  Like just relevant or you thought, oh, I'm going to find all these algorithms in the
*  brain.
*  I'm going to find the computational complexity and it'll map on to processes and stuff.
*  Was it more direct or was it just relevant, you thought?
*  I don't remember exactly what I felt, but I felt that I had the right skillset.
*  But very quickly, I was humbled to learn that actually not any of this is useful.
*  I mean, it might be useful in your data analysis or coding up some kind of behavioral experiment.
*  To understand the brain, classical computer science isn't very relevant.
*  And I guess the talking point that everyone would use is that brains are not designed,
*  they're evolved, they're messy, they don't conform to engineering standards of design.
*  And so you can't really expect it.
*  We're going to come back to that very point when we talk about...
*  Sorry to interrupt, but we're going to come back to that, of course.
*  Yeah.
*  Yeah, yeah, definitely.
*  So yeah, basically, the first few years of my grad school, I kind of learned that the
*  brain is not a computer.
*  It's just like a messy, wet organ and you're going to have to understand it the way it
*  is and not try to impose your own idea of how computation should be on that organ.
*  And then, and towards the end of grad school, I kind of felt that sense of disillusionment
*  that you were talking about, about the whole field.
*  What are we doing?
*  It didn't feel like we're making any progress.
*  I'm saying this in a very, I guess, not in very generous way, but let me just say it
*  in the most extreme way, that we're just collecting data.
*  We're just collecting more facts about the brain and not really making any insight.
*  That's the old criticism of biology when it was called...
*  Was it Ernst Mayr?
*  Who called it stamp collecting?
*  Yeah, stamp collecting.
*  And I agree that this is not a very generous way to frame it.
*  I'm just expressing the feeling that I had at the time because people are doing amazing
*  work.
*  Of course.
*  Not everyone's stamp collecting.
*  Good save.
*  Good save.
*  You know, I really mean it.
*  It's not as the same.
*  Just like the general direction of the field seemed kind of aimless to me.
*  And then that was...
*  Did your own work feel that way also?
*  Because often people think that, but then, except my work, what I'm doing is right on
*  course to solve the thing that I need to solve, right?
*  Yeah.
*  I guess I like the work that I was doing.
*  The issue was I had high hopes for a certain direction.
*  What I was trying to do...
*  So I worked on rodent neuroscience in grad school with Alana Whitten at Princeton.
*  And I started off thinking that I'm going to solve basically some very fundamental thing
*  about how working memory functions.
*  I was thinking in terms of, okay, I'm going to optogenetically turn off all these cells
*  and then get the rat to forget the short-term memory that was in its head.
*  That was a very ambitious goal that I had in mind, and I didn't get to that.
*  I got to something that was valuable, understanding how the stritem is involved in working memory.
*  I made a small contribution, I guess, to that field.
*  It wasn't that related to my own stuff.
*  That disillusionment that I felt was more just about the whole field.
*  Are you familiar with the quote?
*  I'm going to misattribute every single quote I try to quote here, but I think it's Mike
*  Tyson or at least it's usually attributed to him that everyone has a plan until you
*  get punched in the face.
*  That's kind of how experimental neuroscience works, right?
*  Or a lot of experimental science, I guess.
*  Experimental biology, yeah, exactly.
*  I hadn't heard of that, but it sounds right.
*  All right.
*  You were doing good science and Alana's lab is very good.
*  You continued to do good experimental neuroscience research, but eventually you felt that disillusionment
*  with the field as a whole.
*  Yes, until I suddenly got my hands on Randy Gallistole's book, Memory and the Computational
*  Brain.
*  The reason why it resonated with me was that it allowed me to unlearn what I had learned
*  about computer science being irrelevant to the brain.
*  I'm talking about classical computer science, like algorithms and data structures.
*  Because the first nine chapters of the book are basically just ... Honestly, I skipped
*  the main text of those nine chapters because it was stuff that I already knew from studying
*  computer science.
*  I just skimmed through them and read the summaries at the end.
*  But then the rest of the book was actually ... I was a grad student and I was surrounded
*  by very smart people, people who are very knowledgeable that had a certain perspective
*  about neuroscience.
*  Then here comes along Randy Gallistole, this professor in psychology with a very good reputation
*  of being a serious scientist as saying that actually, you know what?
*  It's okay to ignore this common wisdom that everyone is saying and treat the brain as
*  a computer and use principles of computer science and theory of computation in your
*  study of the brain.
*  That got me super excited because that's the reason I came into neuroscience.
*  Yeah.
*  Wait, I don't know if we said the name of the book.
*  It's Memory and the Computational Brain.
*  I'll link to it in the show notes, of course.
*  I've had Randy on and I've had in a similar vein, Dan Glansman on.
*  Now you will be the third person to be talking about this.
*  It could be RNA or something subcellular, something molecular.
*  But yeah, so in that book he talks about path navigation, how ants keep track of where they
*  are and how some of the stories that we neuroscientists, we don't think about ants too much, but the
*  field of neuroscience has a story about how it works and he goes into arguments why it
*  wouldn't work this way.
*  Same with bees.
*  So he goes through lots of examples, carefully saying, well, this would not work.
*  And then, of course, some of the learning studies that he and others have been involved
*  in.
*  So that opens you up into feeling that it was okay to treat the brain like a computer
*  again.
*  But did that make you feel like the brain is a computer again?
*  I particularly remember in the last chapters of the book when they started speculating
*  on where the solution might be.
*  And that's where they brought up the authors of the book, Gallus, Stone, King.
*  They brought up the idea that it could be stored in molecules the same way that we have
*  information, genetic information stored in DNA.
*  Maybe that's how cognitive memories are stored.
*  Or it could be something else.
*  It could be the same way that you could have specific changes to molecules, like phosphorylation
*  of some molecule and the way that those phosphorylation rates are distributed across cells or something
*  like that.
*  There could be various ways that you could imagine memories being encoded.
*  But it allowed me to let go of this synaptic hypothesis that's the dogma of the field.
*  I just want to spell that out really quickly.
*  So throughout the book, Gallus, Stone, and King build the argument, and in Gallus, Stone,
*  and his other works, that there are these problems for behaviors and memory and learning
*  that we don't have solutions for in the spiking patterns of neurons, which has been sort of
*  the hope and the assumption of neuroscience.
*  Everything is spiking, and everything is how the neurons communicate with action potentials
*  and the patterns.
*  However, he goes to great pains to show in multiple cases that there is not a good story
*  and that there doesn't seem to be possible a good story on principles.
*  Just correct me if I'm wrong as I'm sort of spouting the self in memory.
*  Yeah, that makes sense.
*  The arguments were, a lot of them were conceptual in that book.
*  For example, there was an emphasis on the need for a read-write memory.
*  And synapses aren't really a read-write memory.
*  You can't go in and write a specific value into a synapse or read a specific value that's
*  stored in a synapse.
*  And many other conceptual arguments that Gallus, Stone has made in his other writings.
*  How do you encode a number?
*  What's the code?
*  A lot of people kind of brush those questions aside.
*  I kind of understand their arguments, but I just don't agree with them anymore.
*  Yeah.
*  Anymore.
*  Okay, so you had this experience reading the book.
*  You couldn't put it down.
*  And that book specifically, and most of Randy's work is on memory and learning and how those
*  could be implemented at the subcellular level with hypothesized subcellular substrates like
*  DNA, RNA, proteins, et cetera, phosphorylation, methylation, other various possible means
*  of doing things.
*  But then you kind of took a different course on it because is this a good time to talk
*  about your interest in universal computation and Turing equivalence, et cetera?
*  Yeah, this would be a great segue into that.
*  So most of Randy's arguments come from an angle of understanding memory.
*  And the concept of memory isn't like not everyone agrees on what memory is.
*  And there could be semantic debates that just kind of pop up on the side when you're
*  discussing what is the physical substrate behind memory.
*  And there's another angle which you could take, which is just as rigorous, if not even
*  more rigorous, which is computation.
*  You can ask, what is the computational scope of a system from the lens of theory of computation?
*  And when you ask that question, that kind of also leads you down towards molecules and
*  RNA.
*  And a lot of the paradigms that we have, the models for computation in neuroscience, fall
*  short of what's called universal computation.
*  So actually maybe it's better for me to just go straight into what I'm talking about.
*  What is universal computation?
*  And why we care.
*  Yes, exactly.
*  So in the theory of computation, there are various levels of computation power that a
*  system can have.
*  So one system might be able to compute a certain set of functions.
*  Another system might be able to compute more functions, just the same set of functions
*  as another system, but even more.
*  So for example, finite state machines, they can compute things like, what's the remainder
*  of this number when you divide it by seven?
*  There's a single finite state machine that does that.
*  And it will do that for any number.
*  It doesn't matter how many digits you give it.
*  It's always going to be correct.
*  But then there's some problems that finite state machines can't solve.
*  Like, I don't know, what's one example?
*  Like, I don't know, is this string of parentheses balanced?
*  That's a problem that there's no finite state machine that can solve that problem for any
*  given string.
*  However, there are other systems of computation which could solve that.
*  Basically, the point is that you can have different computation systems that are able
*  to solve different sets of functions.
*  OK, now, one of the most important insights of the 20th century, in my opinion, was the
*  finding that with a very simple set of rules, you can achieve what's called universal computation.
*  You can build a system that's capable of solving any solvable function, any computable function.
*  And when I say capable of solving, it requires a description of the algorithm.
*  So it's not like, OK, I have a universal computer and I can solve everything.
*  No, you need to find the algorithm that solves certain problems.
*  So when I say capable of solving, it means there is a description of a program for every
*  computable function.
*  It has the capacity for that description.
*  Yes, that's right.
*  Yes.
*  And a really cool thing is that they had these competing models of computation back in the
*  1930s, general recursion theory and lambda calculus and then Turing's automatic machine,
*  which we now call Turing machines, came along.
*  And within a few years, they realized actually all of these systems, which were intended
*  to be models that capture what it means to compute, they all are equivalent, meaning
*  that you can simulate any one of these systems with another of these systems.
*  And that kind of led to the idea that maybe we've arrived at something very profound.
*  Maybe we've found a limit to what's computable because there are functions that you can describe
*  that are not computable.
*  Like life.
*  Well, we'll get to it.
*  But like one example is Chitin's constant.
*  Actually, I'm embarrassed to say I don't know how to pronounce his name.
*  But let's say Chitin's constant.
*  It's a number.
*  It's a very well-defined number, but you can't compute it.
*  But let's not get into what the things that are not computable.
*  The point is that you can really easily reach that level of computation power where for
*  every computable function, you will have a description.
*  That description can be the description of how a Turing machine's operations work.
*  It could be a description of how a lambda calculus function works.
*  But the point is for every computable function, you're going to have a finite length string
*  that determines how the system operates through time.
*  And that will lead to solving a certain function.
*  This is kind of the theory of computation lens.
*  Now, you can ask, we have these models of computation in neuroscience.
*  Like we have neural networks.
*  How is a neural network a computation system?
*  For every function, you can have a description of a network that may be able to solve that function.
*  The description of the network would be the set of neurons, the weights between these
*  neurons and the activation functions that each neuron has.
*  In a string, I could describe a network.
*  And this network would be solving a function.
*  And then you can ask, okay, well, what are the set of functions that neural networks
*  can solve?
*  And it's common wisdom that our models of computation achieve universality, but it's
*  wrong.
*  And I'll explain why.
*  So wait, our neural models of computation?
*  Well, our models of biological computation.
*  So back in the 1990s, there was a series of papers that showed that you could simulate
*  a Turing machine with neural networks.
*  The problem was that the kinds of neural networks and dynamical systems that were shown
*  to be able to simulate Turing machines, they are irrelevant to biology because they lack
*  structural stability.
*  They're even irrelevant to engineering.
*  You couldn't even engineer these systems.
*  Can you?
*  Yeah.
*  I think you're about to kind of go into more detail on why that's the case.
*  Yes.
*  Yeah.
*  So the crux of the matter is structural stability.
*  When you're describing a dynamical system, the system includes a number of parameters.
*  And then you can ask, what happens if I change these parameters by some infinitesimal small
*  amount?
*  Will it still resemble the same dynamics of the original dynamical system?
*  In other words, is there, in technical terms, for those who are interested, is there a homeomorphic
*  neighborhood of dynamical systems to this system that you're describing?
*  If there isn't one, then you're describing a singular point in parameter space.
*  Fragile.
*  It'd be fragile.
*  Yes, exactly.
*  The smallest error in your parameters when you're trying to implement this system would
*  result to something that's vastly different.
*  This is not my argument.
*  This is Chris Moore's argument, which was actually the first person to show that dynamical
*  systems can be used to simulate turning machines.
*  He argued that structural stability is a reasonable criterion for systems that either an engineer
*  can build or you would be able to find to occur in nature.
*  And then he also conjectured that no universal dynamical, no universal finite dimensional
*  dynamical system would be structurally stable.
*  Okay, so just to pause here, make sure I'm getting this.
*  How do you square this with the idea of degeneracy in circuits in the brain, for example?
*  So you can use this exact same circuit to produce different rhythms or you can use different
*  parameters in the same circuit to produce the same rhythms in this case.
*  So that seems unstable, right?
*  Well, I'm not sure if that would be structurally unstable because the thing is, almost all
*  of the models that people use even in not just in studies of biological neural networks,
*  but even in AI, almost all the models that people use, they are robust to a small enough
*  amount of error in their parameters.
*  Otherwise they would just be irrelevant to deep learning.
*  Like in deep learning, you're searching for a network that fits a certain function and
*  you're just moving in parameter space.
*  If the solution is a single point with no clues nearby, then it's hopeless.
*  You can't find that solution.
*  Right.
*  Yeah.
*  Okay.
*  I thought you were saying the opposite, so I misunderstood.
*  I thought you were saying that biological systems are inherently stable.
*  And that is what you're saying.
*  Biological systems.
*  Yes.
*  Yeah.
*  I would say our models of biological computation that we actually use, that we actually think
*  might be relevant, they're all structurally stable.
*  Okay.
*  Fair enough.
*  The model is stable.
*  Yes.
*  Yeah.
*  We're always talking about, I think this model is how the brain computes.
*  And those models, they don't have this weird feature of structural instability.
*  And it's kind of like, it's as if we're paying lip service to universal computation.
*  If we just say, okay, look, RNNs are universally powerful.
*  And then we never even talk about that kind of neural network that is universally powerful.
*  There's a subset of RNNs that we actually study.
*  And there's another set of RNNs which are universal.
*  And as far as we know, those don't overlap.
*  So for it to be universal, it has to compute that single point.
*  Is that correct?
*  Well...
*  Because you have to be exact when you're computing.
*  I'm sorry I'm so naive here, by the way.
*  No, no, no, no.
*  That's a good question.
*  The way I would say it is, people have come up with a way to describe a single neural
*  network for every computable function.
*  However, each one of those networks is a single point in space.
*  Oh, okay.
*  I see.
*  And just to be clear, are you talking about like the universal approximator theorem?
*  No, no, no, no.
*  That's very different.
*  So I'm talking about Siegelman and Sontag.
*  They had a neural network system that basically uses the...
*  I think it was conceived as the membrane potential of a single neuron as a unary stack.
*  You can imagine there's a string of digits after the decimal point that represent the
*  membrane potential of a single neuron.
*  And if you treat that as a unary stack, you can compute with it.
*  If you have like three stacks, you can compute with it.
*  There are other ways to do it like with dynamical system models that aren't necessarily like
*  neural networks.
*  But they essentially treat digits after the decimal point of a number as a string of symbols.
*  Strings of symbols are really important, actually.
*  That's kind of one of the arguments for RNA.
*  They really allow you to express computational power in a computational system.
*  And you can achieve it with like if you treat a number as a string of symbols.
*  But I really don't think that's how the brain works.
*  Okay.
*  So let me just rephrase this then and see if I get it right this time in my own words.
*  So there is a space of possible neural networks, parameter sets, architectures, activation
*  functions, etc.
*  Of that entire space, there are discrete points of the combinations of all those different
*  things that lead to universal computational abilities.
*  And every other point that's not those discrete points are not universally computed.
*  Yes.
*  Yeah.
*  Basically, the point is if you're talking about the subset of RNNs that are relevant
*  to biology, we don't know if that covers all computable functions.
*  Okay.
*  Okay.
*  We don't know if it matters either, right?
*  So it matters to you.
*  Yeah.
*  This is a big deal, right?
*  Yeah.
*  Yes.
*  Yeah.
*  So the thing is I find it really hard to accept that biology would not have stumbled upon
*  universal computation because it's such an easy thing to accidentally stumble upon.
*  When you're working in abstract systems, there are several examples of this.
*  For example, cellular automatons, like linear cellular automatons.
*  Wolfram's Rule 110 accidentally stumbled upon universal computation.
*  It wasn't intended to be a powerful computation system, but it was discovered to be.
*  Wing tiles.
*  Conway's Game of Life.
*  There's a lot of examples of people stumbling upon these very complex, unpredictable systems
*  and later discovering that they're universal.
*  And so it feels, I don't know, hard for me to believe that biology can evolve something
*  as complex as the eye that conforms to the principles of optics, that uses a lens and
*  an aperture.
*  But somehow it doesn't care about the principles of computation and it can't achieve something
*  that's so much easier to build than an eye.
*  And just from my intuition, it feels like, and this is an intuitive-based argument and
*  it might not be convincing to everyone, but I just feel like a universal computation system
*  would have enormous selective advantages for organisms that are striving to survive and
*  reproduce and solve complex problems.
*  Yeah, that's why I think it's a meaningful and important question to ask, where is life's
*  universal computer?
*  Where can we find it?
*  You had mentioned to me that you think that this is, so we've been talking basically about
*  neuroscience and the models in neuroscience, but you think this is relevant to artificial
*  intelligence as well?
*  Yes, yeah, basically.
*  So one of the things that I've noticed right now in the interaction between AI and neuroscience,
*  which is actually...
*  There's no interaction.
*  There's no interaction.
*  You've talked about this before on previous episodes, I know.
*  So there's this one interaction that I can confidently say exists.
*  So I can't tell you the number of times that I've spoken to someone in machine learning
*  or just non-neuroscience AI, and I've explained how there's a problem that our current models
*  of machine learning are learning functions in a space that's not Turing equivalent.
*  And I can get into that in a moment because that's also something that would seem contrary
*  to common wisdom.
*  But yeah, I have a very similar critique to current approaches in machine learning, and
*  my argument is that, hey, we're not taking universal computation seriously.
*  And then the response that I get, I can't tell you how many times that the response
*  that I got was, okay, well, if the point is to create an intelligent system, aren't we
*  intelligent and aren't we neural networks?
*  So at the end of the day, if your argument is against neural networks, how are we intelligent?
*  So in a sense, those people that are working in AI and working on these neural net models,
*  they're relying on the confidence of neuroscientists that this is it.
*  It's a neural network system that's doing this.
*  Oh, no, they're not.
*  No, they're not.
*  They're not relying on neuroscientists.
*  They're just building their models.
*  They're building their models, but there is an assumption that there's no barrier to the
*  computational ability of neural networks if the target is an intelligent system.
*  Because if you believe that...
*  But let me just interject because that has nothing...
*  I believe that from the common AI engineer's perspective, that has nothing to do with neuroscience.
*  You disagree?
*  I don't know.
*  I think, well, I mean, at least in the discussions that I've had with people, I find them referring
*  to the fact that we are intelligent and we are neural networks.
*  Oh, okay, fine.
*  And so there's gotta be a neural network solution to intelligence.
*  That's true and that is the common assumption among neuroscientists as well, neuroscientists.
*  But I think the reason that...
*  But it's true also.
*  Well, we have neural networks.
*  We are neural networks, but of course we have...
*  But we have a few other things as well.
*  Yeah.
*  What do you mean that it's true?
*  We have a brain.
*  It's true.
*  We have neurons.
*  Yes, but the question is...
*  The question is, is...
*  Is that enough for universal computation?
*  Is thought implemented through a neural network model versus some other kind of model that
*  might be at the molecular level?
*  And so what I was trying to get at was this mutual interdependence of neuroscience and
*  AI, how AI researchers are relying on the confidence of neuroscientists that, okay,
*  computation is happening through neural networks.
*  And the other way around, I feel, that neuroscientists see that the most advanced cutting edge model
*  for AI look really like neural networks.
*  And maybe it's not exactly biologically plausible yet, but there's going to be some mapping
*  at some point.
*  That's kind of how both fields are relying on each other's confidences, that neural
*  by themselves can solve intelligence.
*  Okay.
*  And you think universal computation is required to solve intelligence, whatever the hell that
*  means because something you said earlier was we're human, we're intelligent, so therefore
*  we think we can solve intelligence.
*  I wanted to jump in and say, yeah, we define what intelligence is.
*  So it's not like intelligence is out there and we have some and we know what it is.
*  We actually define it, right?
*  So that's a semantic issue.
*  Yeah.
*  I mean, and then you could come up with a new definition that's not grounded on us.
*  I don't really want to get into the semantic argument of what intelligence is.
*  But my point is like universal computation doesn't care about the needs of an organism,
*  for example.
*  Right?
*  So every definition of intelligence of the million that are out there, there's something
*  about learning in unpredictable environments, adapting to learn to do the thing that you
*  need to do, solving the problem.
*  Right?
*  And these are all like problem solving things related to what you need to do.
*  The universal computation doesn't care about what you need to do.
*  It's just a capacity to do anything.
*  Right?
*  Well, yeah.
*  The question here is it's not about, okay, can I learn to universally compute?
*  The question is when I'm learning, what is learning about?
*  It's about picking a function in the space of all possible functions.
*  Okay?
*  It's about you have a bunch of examples and you want to find the function that solves
*  these examples.
*  Now again, the same question comes up.
*  What's the space of learnable functions in your system?
*  Is it the same space as all computable functions or are you just leaving out a ton of functions?
*  And so for example, like I don't know, if you're thinking about addition, let's say
*  you have a bunch of input and output test cases.
*  You could solve that benchmark for addition with a lookup table.
*  Okay?
*  And if your learning algorithm, if your learning method is restricted to lookup tables, you're
*  going to find a lookup table that's going to solve that benchmark.
*  But you're not going to solve addition.
*  Okay?
*  If you want to solve addition, then I hope that the scope of functions that you're searching
*  for, that you're learning in, includes programs.
*  And you might be able to stumble upon the program for addition.
*  And that program can solve things that are not in that benchmark.
*  It can generalize.
*  Now I'm not saying, I just want to be clear, I'm not saying that current methods are lookup
*  But that was just an example to illustrate the point that the space of functions that
*  you're learning in really matters.
*  So shouldn't we be way better at math if we have universal computational abilities that
*  is guiding our cognition?
*  Sorry, it's a very naive, dumb question.
*  I don't know.
*  I mean, I don't know how to answer that.
*  I mean, I guess we are good at math, right?
*  I mean, there are people who are very good at math.
*  There are examples of people who...
*  So yes, but they're not running on magic, right?
*  I mean, there has to be some kind of way.
*  Yes, they are.
*  Yes, it's magic.
*  No, but yeah, okay.
*  I understand that there are savants in many different areas.
*  Maybe that's not the best example.
*  But shouldn't we all be, right?
*  Or is the brain, are neurons in our way?
*  And if we could just get to the RNA computation, we'd all be...
*  The brains are slowing our universal computers down, you know?
*  No, I mean, I don't view it as like, okay, there's the neural network and then there's
*  the RNA and these two things are like very different things.
*  That's not how I would view it.
*  The neural network just won't listen to the RNA.
*  Who's trying to tell it?
*  Yeah.
*  Yeah.
*  And related to that, there's some...
*  If anyone wants a primer for this small field within neuroscience, I would really recommend
*  Sam Gershwin's paper.
*  And the reason I brought that up right now is because it's an attempt to synthesize the
*  view of synaptic-based memory and molecular mechanisms for memory.
*  So in the second half of the paper, he lays out some kind of model that would synthesize
*  these views.
*  So it's, you know, how do you connect the idea that neurons are talking to each other
*  through synapses with this idea that maybe memories are stored molecularly?
*  The first part of that paper is the primer that I'm talking about because it's the
*  best intro to this field that I know of.
*  It covers a lot of the conceptual reasons and the empirical reasons why the synaptic
*  story of memory doesn't really hold up.
*  It also has a good summary of something that happened back in the 1960s where there was
*  a short period of time where a lot of people were working on what they called macromolecular
*  engram theories, where they thought that memories could be stored the same way that we have
*  genetic information stored within molecules.
*  Maybe memories are stored within macromolecules and RNA was kind of one of the leading candidates
*  for this.
*  Let me just define engram for those listening.
*  It's basically a physical trace of memory in your brain.
*  However, that's instantiated.
*  So some people think the engram is a certain set of cells that are associated with a memory.
*  Some people think the engram is stored within the synapses.
*  Then a growing number of people perhaps think the engram is laid out physically within these
*  molecular structures, macro or micro.
*  Yeah.
*  Let me just clarify something.
*  A lot of the times when I bring up the idea that molecules could be storing memories,
*  one common response I hear is that of course molecules are storing memories.
*  Everything is molecules.
*  Synapses are also molecules.
*  It's going to be molecular.
*  The real point is where is that information stored?
*  Maybe a better description of this would be an atomic theory of memory.
*  How are genes stored?
*  What's the mode of genetic information encoding?
*  It's really about how atoms are arranged within molecules, not how molecules are arranged
*  within the cell.
*  You're taking a very reductionist approach.
*  That was going to be my reaction to what you said about the common response.
*  It was like, well, yeah, of course.
*  It's also in atoms and it's also in quarks.
*  You can do that all the way down.
*  We don't say that about genes anymore.
*  Right now, we say genes are stored as sequences of nucleotides.
*  There could be little tricks that organisms use to also carry information transgenerationally.
*  There's epigenetics.
*  There's also different ways that you can have inheritance of information across organisms.
*  The main way that we conceive of genes being stored is in the sequences of nucleotides.
*  It's about what the right level of emergent properties is the level that carries the most
*  causal information about what we're talking about.
*  Man, that was a mouthful.
*  Sorry.
*  Yeah, that makes sense.
*  There's a lot of parallels.
*  I talked to you about this when I met you a few months ago.
*  There's a lot of parallels between how this issue is being treated now, the issue of memory
*  engrams, how it's being treated now versus how genetic information was treated before
*  the discovery of DNA.
*  People used to think that it's messy.
*  There's not going to be a clean story for it.
*  It's in proteins.
*  Every cell has a different protein composition.
*  Proteins are rich in information because they didn't use that word information, but they're
*  very rich.
*  The protein composition of a cell of a turtle is going to be different from a human cell.
*  That's what leads to a human being formed versus a turtle being formed.
*  Then the central dogma came about, DNA, genes, RNA, proteins.
*  It turns out it is messy, just in a different way.
*  I wouldn't say ... Actually, I don't even know if it is messy.
*  We can't even define what gene.
*  The messiness that we see right now still might be a result of us not understanding
*  the system correctly.
*  The way we need to do that is through universal computation.
*  Is that what you're going to ...
*  Well, I think so.
*  There's a whole debate right now.
*  Over the past 20 years, there's been a debate over the non-protein coding portion of the
*  genome.
*  The junk?
*  Is it functional?
*  Is it not?
*  Yeah, it used to be called junk.
*  Nowadays, nobody really calls it junk, but one end of the spectrum believes that it's
*  not functional, most of it, and the other end of the spectrum thinks that most of it
*  actually may be functional.
*  Actually, when I stumbled upon this literature, it was very exciting to read.
*  It's one of the most heated debates that I know of that's out there in papers that you
*  can read.
*  What, the functional, like the junk versus non-junk?
*  Yes, yeah.
*  Yeah, over the past 20 years, I guess.
*  The main proponent of the idea that the non-coding DNA is functional, or one of the main proponents
*  would be John Maddock.
*  If you look up his publications, you can find the trace of that debate.
*  The idea is that, hey, okay, there's a couple arguments here.
*  The people who say that most of the DNA is non-functional, they usually rely on things
*  like conservation.
*  If you use conservation as a criteria for what's functional or not, you come up with
*  an upper bound of, let's say, 20% of our genome would be functional.
*  What do you mean conservation?
*  Sorry?
*  It's what portion of the genome is conserved across species.
*  Oh, that kind of conservation.
*  Gotcha.
*  Yeah.
*  So it stays the same, stays the same, is the same across species?
*  Yes, yes, exactly.
*  Yeah.
*  Sorry, I'm trying to just make sure.
*  No, no, yeah, that makes sense.
*  Yeah, and so the other end of the debate, they would argue that no, conservation is
*  not a good criteria.
*  There are many other criteria that you can use for hints for functionality.
*  One of the arguments that John Maddock actually has brought up is that you see that the non-protein
*  coding portion of the genome, the ratio of non-protein coding to protein coding increases
*  as a function of organismal complexity.
*  In single cells, it's a lower proportion and it just increases as you go into multicellularity.
*  The criticism towards this is that, well, what is complexity exactly?
*  How can you assign complexity to organisms?
*  That's a fair criticism.
*  But what happens is if you sort animals, if you sort species based on this criteria of
*  what's the proportion of non-coding to coding, it just looks intuitively like it's an increasing
*  complexity.
*  Do you know if you do the same thing with relative brain size, it's the same?
*  It's not.
*  I think ants are above us or something.
*  Not in relative.
*  Yeah.
*  OK.
*  On the logarithmic scale, the brain complexity size to body mass.
*  Yeah.
*  All right.
*  I'm not going to look it up at the moment.
*  I get the point here.
*  It's like we're looking for some sign, some indicator that puts humans on the top of the
*  chart and that's kind of a weird thing to do and it's very human centric.
*  The earth has to be the center of the universe kind of approach.
*  But nevertheless, there is this problem of, OK, what is all this non-protein coding DNA
*  doing?
*  Is it just transcriptional noise?
*  Because a lot of it's transcribed.
*  That's basically what happened 20 years ago is that we realized that these portions of
*  the DNA that don't encode for proteins are being transcribed.
*  There's a lot of specificity within the cell.
*  You can see that a lot of them are localized in very specific ways and we don't know what
*  they're doing.
*  You can find correlations with certain traits and diseases and then you would see that those
*  non-coding RNAs that are associated with a certain trait are actually expressed in
*  tissues that are relevant to that trait.
*  Like if it's a neurological problem, then it's also expressed a lot in neurons.
*  There's a lot of little hints like that that say that, OK, there's a story about genetics
*  that we don't understand.
*  Getting back to your point about, OK, look, genetics was actually messy.
*  The thing that wasn't messy was how proteins are encoded.
*  There's a very clean story to that.
*  There's a codon for every amino acid.
*  There's a lookup table that this system uses and it does a very simple translation of RNA
*  molecule strings to amino acid strings which become proteins.
*  It's a remarkably elegant and clean system to encode proteins.
*  I know the story of how does this actually encode for an organism is messy, but maybe
*  that's because we just don't understand the system well enough.
*  In humans, less than 2% of our DNA ends up in messenger RNA.
*  Half of messenger RNA, usually on average in humans, is untranslated.
*  So it ends up being less than a percentage point of our DNA encodes for proteins, has
*  sequences of nucleotides that encode for sequences of amino acids.
*  Right now, the story is, OK, well, the rest is like there's a lot of regulation and it's
*  all about how are these proteins, how is protein synthesis regulated across different cells.
*  But it seems to me that when you take a step back, you see that there are these molecules
*  within cells that resemble strings of symbols.
*  Strings of symbols that come from a very small alphabet of four letters.
*  They also fold up into these tree-like structures that would be very useful for doing computational stuff.
*  Could it be the case that these molecules are involved in something more than just regulating
*  the synthesis of proteins across cells?
*  Maybe something else is going on.
*  Maybe some deeper explanation would actually make it make sense.
*  OK, hold off on that because I want to ask you how you even came to appreciate the combination
*  of RNA and combining it with combinatorial logic.
*  However, let's just...
*  Yeah, combinatorial logic.
*  What am I saying?
*  Am I...
*  It's combinatorial logic.
*  Combinatorial.
*  So there's two things.
*  There's combinatorial logic and there's combinatorial logic.
*  And combinatorial logic is the one that...
*  What have I been saying?
*  No, you said...
*  You just pronounced it differently.
*  You said combinatorial.
*  Combinatorial.
*  Combinatorial.
*  Yeah, combinatorial.
*  Combinatorial.
*  Yeah.
*  Oh, jeez.
*  All right.
*  Combinatorial logic.
*  Yeah.
*  Combinatorial.
*  Now I'll just have to go back and edit myself.
*  I think...
*  Yeah, sorry.
*  Combinatory.
*  Combinatory.
*  Combinatory.
*  Yes.
*  Yes, that's right.
*  The emphasis is on the first syllable.
*  Yeah.
*  Aglipore.
*  Aglipore?
*  Yeah, exactly.
*  Yeah.
*  Okay.
*  This is standing here, by the way.
*  Oh, no.
*  Yeah, of course.
*  Because it's just me pronouncing things like an idiot.
*  Okay, but what I wanted to hang on to for just a minute because I want to ask you about
*  how you came to appreciate this or how you came to this idea is...
*  The regulation story, right?
*  What I've come to appreciate through works like Alicia Juarero, Terrence Deacon, the
*  autopoetic, like Varela, Montemora, like the whole...
*  Is like in life systems, like if you have in a system, the contextual things, the regulation
*  things are way more important than the thing that we think is doing the thing.
*  So you drop...
*  So in like a water maze, the walls, or let's say a river, you don't have a river without
*  the banks.
*  The river affects the banks and banks affect the river.
*  But when we talk about rivers, it's like the river is the thing.
*  But the river is not the thing.
*  It's the banks and the river and they're affecting each other.
*  So there's top down causation, bottom up causation.
*  And so, but the idea...
*  So then I think...
*  So Alicia Juarero wrote this book, I think it's called Context Changes Everything.
*  And she has argued for this strongly that these processes are all affecting...
*  You have to appreciate the context of whatever process is happening within which a process
*  is happening just as much as what you consider the process.
*  So then, unfortunately, something like DNA to RNA to protein, that manufacturing system,
*  if you want to call it that, could be like a huge bureaucracy where we have like all
*  this super unfortunate regulation that seems somehow necessary for like a giant democracy
*  to get nothing done, but maybe just like the very little that we can get done.
*  I'm sorry, that's a bad analogy.
*  Of course, the other analogy I would make is people who work on cognitive architectures
*  have come to appreciate that, all right, you have a working memory module, you have a long
*  term memory module, you have an executive module.
*  Getting those things to work by themselves, not that hard.
*  Getting them to work in concert, that's the hard...
*  That's the really hard part.
*  So it's how do you regulate?
*  How do you make these things act together?
*  It turns out that the regulation part of it is a huge part of it.
*  So I just wanted to linger on that for a second to say, well, yeah, I mean, there does need
*  to be a lot of regulation.
*  Maybe it's not all regulation, right?
*  Well, okay, I mean, now that you describe regulation like that, I think I would agree
*  with all of what you said.
*  I mean, but I was imagining that as computation, right?
*  There's decisions that need to be made of how do I direct...
*  A protein to the membrane.
*  The cell's function, yes, exactly, a protein to the membrane, the cell function.
*  Where does the cell actually go in space in the body plan?
*  What kind of proteins do I need to...
*  So the issue is there's this concept of gene regulatory networks, okay?
*  And that's kind of, I think, what people mean when they say gene regulation.
*  If what you mean is something more broad, then I think I would agree with you.
*  Because gene regulatory networks, at least the way that they're conceived of right now,
*  are as powerful as finite dimensional dynamical systems.
*  The same issue that comes up with neural networks comes up with gene regulatory networks,
*  where you have this gene is inhibiting this gene, and this other gene is promoting this
*  other gene.
*  And you have a big network of gene interactions that define, okay, which genes are expressed
*  and which are not.
*  And it's very similar to a neural network kind of model of computation.
*  If you think that's how it's being regulated, I think that's...
*  I would take an issue with that because of the computational capacity of the system
*  that you're describing.
*  I think it needs to be...
*  It's very likely that if biology can or has achieved universal computation at the molecular
*  scale, it will use it for development, for implementing a body plan.
*  What about cognition?
*  The cognition too, yeah.
*  The thing is there's so many domains of life in which computation is not just useful, but
*  essential.
*  What is your blog called?
*  Life is Computation?
*  Yeah, that's the name of the blog.
*  Life is Computation.
*  So, there's this...
*  Everything is computation in neuroscience.
*  I'm reacting generally over the past few years to that over the course of a lot of conversations
*  I've had on this podcast.
*  Let's say it's true.
*  Let's say RNA has this universal computational capacity.
*  And man, I don't want to just blabber on here.
*  I want to get to the story.
*  But what if...
*  If life is not computable, and I don't believe it is because the universe is open, and so
*  there are only solvable problems in closed domains.
*  I'm not using rigorous mathematical terms here.
*  I don't know if that's what people mean when they say non-computable in classical theory
*  of computation.
*  Okay, that's your...
*  The thing is...
*  Okay, so you just said there's an open domain.
*  It's an open system.
*  It's not a closed system.
*  And in fact, that's how you get universal computation.
*  A system that is able to recruit more dimensions to store its state, that's the key ingredient
*  for arriving at universal computation.
*  If you think of a program...
*  Yeah, go ahead.
*  No, I didn't mean to interrupt.
*  I'll come back to it.
*  Go ahead.
*  Okay, so just to illustrate what I mean by that, if you think of a program that's running
*  on a computer, it occupies a certain amount of memory.
*  And it has the instructions that would enable it to expand in memory, to recruit more memory
*  if it needs to.
*  It might run out of memory on your computer, which you can conceive of as a closed physical
*  device.
*  But that program isn't really...
*  You can't describe it as a closed system because its progression in time requires it to interact
*  with the environment and recruit more space to actually go on with the computation.
*  And in all of these...
*  The reason I say that that's the key ingredient is that in a lot of these abstract systems
*  that stumble upon universal computation accidentally, they happen to have this ingredient.
*  If you think of Conway's Game of Life, you can think of some pattern of on and off cells.
*  And it's always finite in size, but it can expand in the surrounding space.
*  And if you're implementing it on a piece of paper, you might run out of space on your
*  piece of paper, but you know that you fail to stick to the rules of the system at some
*  point and you need to add more paper to it.
*  You're describing a system that's essentially open.
*  So we have not that much time left.
*  And I want to...
*  Because we haven't talked about combinatorial logic yet, really, and its connection to RNA.
*  So you have this problem...
*  So, all right, let me just sum up here.
*  So you go through this disillusionment in graduate school.
*  You stumble across Galistal's book.
*  You start thinking about computation and you realize, well, maybe you return to the idea,
*  maybe I can think of the brain as a computing system or a computer.
*  How did you come across the idea that RNA is a universal...
*  Universal computational capacity?
*  And then how did you connect that with combinatorial logic?
*  Yeah, so RNA was kind of in the spotlight already, just from all these other people
*  that are in the field that have put it forth as a candidate for storing memories or for
*  computation.
*  I mean, it was in the spotlight for me since grad school.
*  And that's because it's kind of stable enough that it could last, like not a protein that
*  will get degraded over a day or whatever.
*  And for other reasons.
*  Yeah, I mean, we've learned that it's stable recently.
*  I guess 10 years ago, there's a paper that came out earlier this year that shows that
*  you can have RNA strands in the nucleus that last for years for the lifetime of the animal.
*  And I can send you that paper if you want to link that in the show notes or whatever.
*  But I mean, a lot of people think of RNA as being short-lived and transient.
*  I think the reason why RNA, well, there are many reasons that it has come up.
*  But I think just there's something very appealing about it being a string of symbols.
*  But yeah, I mean, it was basically in the spotlight.
*  In the 1960s, it was the main candidate for these macromolecular theories.
*  They would claim that we purified RNA from a planarian and injected it to another one
*  and it worked.
*  And this is related to your interview that you had with David Glansman.
*  He's kind of also landed on RNA methylation as a very promising candidate for memory.
*  An epigenetic mechanism.
*  But anyway, like, hang on, let me ask you.
*  So was it also in the 60s?
*  When did the idea that RNA may have preceded DNA as like the original life molecule?
*  So people used to think, well, DNA is the original molecule and then RNA came out of
*  that and then to produce proteins.
*  Well I don't know if there was a time where people thought DNA was the first molecule.
*  I know that the idea that there was an RNA world, that there was a world where before
*  DNA and proteins there was RNA, that comes from the realization that RNA both has a coding
*  encoding capacity in the sense that you could have a reader like a ribosome actually read
*  its content and translate it to something.
*  But it also has an enzymatic capacity.
*  So it can serve as an enzyme to chemical reactions.
*  And so these two capacities, people would argue, are the main components, molecular
*  components in life.
*  And RNA has both of them, although not as efficiently.
*  Like proteins are way more catalytic and DNA is like way more better at storing information.
*  So then these two things evolved later.
*  I think that's the main argument for the RNA world hypothesis.
*  I don't know actually how serious people take it today.
*  You know what else?
*  So DNA involved for better storage, proteins involved for better enzymatic activity, and
*  brains involved for better cognition.
*  Yeah, that evolved later too.
*  But as long as you're willing to concede that RNA had the computational capacity to begin
*  with.
*  Sure.
*  Yeah, yeah, yeah.
*  It's great.
*  It's just like whether it's implemented.
*  So yeah, yeah, capacity.
*  I'm all about capacity.
*  Sure.
*  Yeah.
*  So where was I?
*  So I interrupted you and asked about the RNA progenitor story with respect to DNA.
*  And the RNA was the early storage thing.
*  But you were about to talk.
*  So you were talking about in the 1960s, that was the molecule that people thought could
*  be used as a symbolic string, string of symbols, right?
*  Yeah.
*  I mean, a lot of people, I guess, based on just the discovery that genes are actually
*  encoded in molecules, maybe that was an inspiration to the theory that cognitive memories might
*  actually also be stored in molecules.
*  And so some people thought it was proteins.
*  In fact, the earliest proposals were in 1950 before the discovery of the double helical
*  structure of DNA.
*  And those were based on proteins.
*  Those were in a time where, yeah.
*  A time when people thought proteins were more stable?
*  Is that what you're going to say?
*  Well, a time that people thought proteins were genes.
*  The genes were proteins, actually.
*  Oh, OK.
*  Yeah.
*  The majority, I mean, at least according to this book, The Eighth Day of Creation, until
*  the discovery of the double helical structure of DNA, most biologists thought that genes
*  were proteins.
*  OK.
*  All right.
*  Yeah.
*  But anyway, the point is that in that era, in the 1960s, there are dozens of different
*  that are working on this idea or doing different kinds of experiments on this idea of memories
*  being encoded in molecules.
*  And they used different approaches.
*  Not all of it was like this crazy feeding planarians to other planarians that James
*  McConnell is known for.
*  People, for example, showed that you have changes in RNA composition with learning.
*  And they would do experiments where, I don't know, you put a rat on a tightrope.
*  And then you would show that, OK, the ratio of RNA nucleotides changes in this brain region.
*  And so, yeah.
*  But the issue, I mean, that field kind of died out in the beginning of the 1970s.
*  And I guess that one of the main critiques to that theory, to that subfield, was that
*  how do you know that the changes that you're seeing are actually encoding memories?
*  You could extract some kind of chemical from a learned animal and inject it to some other
*  animal.
*  But that could just be like a hormone for fear or something.
*  How do you know that that's actually encoding the content of the memories?
*  And they really didn't have the tools at the time to really study that question deeply.
*  OK, so I remember now where we kind of were, because I was asking you how you came to the
*  linkage between combinatorial logic and the RNA story.
*  And you started to talk about the 60s and how this is kind of an old story that went
*  out of favor.
*  But you were...
*  So then how did you...
*  Yeah.
*  Yeah, go ahead.
*  Yeah.
*  So RNA was kind of already in the spotlight for me, just because there's many people that
*  have brought it up as a good candidate.
*  And then since reading Randy Gallistole's book, I had been thinking about, OK, how would
*  a computation system that's really universal, how would a really actually universal computation
*  system look like at the molecular level?
*  Because you could imagine like, OK, it's cool.
*  RNA are strings of symbols.
*  Are you going to treat it like a Turing machine tape?
*  Like with a Turing machine that goes in and edits this symbol and moves next?
*  I mean, that can't possibly exist in cells.
*  You would see it in the ribosome, which does something very simple, which just translates
*  every triplet of nucleotides to an amino acid.
*  That's huge.
*  And it's visible in electron microscopy.
*  So trying to say that something like a Turing machine might exist isn't very plausible.
*  So what could a computation system look like?
*  And this has been on my mind ever since.
*  And I think the connection between combinatorial logic and RNA happened when I realized...
*  Well, two things, basically.
*  One was I just learned that RNA has a secondary structure, meaning that the same way that
*  DNA strands can come in and fold and form these double helices, like you bring in two
*  strands of DNA and they connect to each other and form a double-stranded helix, the same
*  thing can happen within the same RNA molecule.
*  So an RNA molecule is a strand, is a string of nucleotides, and you can have one segment
*  of that strand pair, base pair, with another segment of that strand.
*  And that can happen...
*  So it has to sort of fold on itself, and the pairs have to be the right pairs that would
*  match, and it can do that...
*  Sorry, I'm trying to just be crystal clear.
*  It can do that, let's say it's like 100 pairs long.
*  And if the first and last four pairs are the ones that match, it would fold in on itself,
*  and then you'd have a big loop of all these pairs that weren't matching, and then those
*  four that just connected at the bottom, like a tiny little...
*  Yes, but usually there's a lot of matches.
*  It's not just like...
*  I wanted to go simple.
*  Yeah.
*  Yeah.
*  Yes, yeah, exactly.
*  So people do this, that you can study a certain RNA strand and study its secondary structure,
*  and usually the maps look really pretty.
*  They're very intricate.
*  There's many layers of essentially parentheses.
*  When people want to represent the secondary structure, they use parentheses, because if
*  you think about it, one part of the strand coming to another part of the strand is matching
*  a nucleotide to another nucleotide.
*  And usually it turns out it has a parenthesis structure.
*  Sometimes you get these things that they call pseudonauts, which kind of deviate from a
*  balanced parenthesis structure, but usually it's a balanced parenthesis structure.
*  Yeah.
*  So is there...
*  Sorry, this is an aside, but...
*  So in a given, I don't know, 1,000 base nucleotide RNA sequence, there are going to be lots of
*  places that could attach.
*  So what is the possible number of secondary structures that a piece that long could form?
*  Yeah, that's a great question, and the answer is a lot.
*  And in fact, we know that a lot of RNA strands have many different confirmations that they
*  can take.
*  And it's not always static.
*  It's not always a single structure.
*  Yeah.
*  But they can...
*  So...
*  Like a single...
*  Are you saying like a single thing can fold up one way and then in a given solution relax
*  and then fold up a different way?
*  Yes, yeah, absolutely.
*  And in fact, that's how ribozymes work.
*  There could be an element within an RNA strand that folds differently depending on temperature.
*  And so that can be used as a sensor for temperature.
*  But yeah, okay.
*  So that's like a very important feature of RNA strands.
*  And then just out of curiosity, I was like...
*  I don't know.
*  I can't remember exactly how I stumbled upon combinatorial logic.
*  Did you see lambda calculus first?
*  I mean, you probably knew about lambda calculus.
*  I think, yeah.
*  I think I saw lambda calculus first.
*  I don't even remember the first time I was confronted with it.
*  But I was trying to learn how it works.
*  And then at some point, it just clicked in.
*  I think I remember the moment that it clicked in.
*  Oh, what was that?
*  You got to tell that story.
*  What was that?
*  There's nothing special about it.
*  I was just like...
*  I was sitting at my desk and I was on a Wikipedia page.
*  I think a Wikipedia page for commentary logic.
*  And then I was like, wait a minute.
*  It's very similar to how we represent RNA strands.
*  There's these parentheses that you use for representing a secondary structure.
*  And you have a limited alphabet of combinators.
*  Usually it's like, I don't know, S and K or B, C, K and W.
*  And that's it with that limited alphabet.
*  You can express any computable function.
*  And the rules for running that function are very simple.
*  They're very local.
*  Wait, how long was this moment?
*  Probably a minute.
*  I don't remember.
*  Where you had all these thoughts?
*  Well, yeah, I guess just noticing the parallels between the two.
*  And immediately afterwards, I was sure that somebody had written about this.
*  Because it's so obvious once you...
*  I was sure somebody wrote...
*  There had to be some paper or something.
*  And I kept on searching.
*  I couldn't find anything, which made me more and more excited.
*  Wait, okay.
*  But that was your...
*  Okay, so I'm sorry.
*  I'm interested in this.
*  So you had this moment at the computer and you realized it.
*  And then how soon...
*  So that must have been like, oh my God.
*  And then immediately you're like, oh, well, this must have been done.
*  That's kind of a downer on the moment, right?
*  I don't know.
*  Yeah, I guess, yeah, I was preparing myself to be very disappointed that somebody else
*  had brought this up.
*  That's right.
*  You'd been in academia for a while and an experimental neuroscience.
*  Yeah.
*  Okay, yeah, it all makes sense.
*  Sorry.
*  Yeah, I don't know.
*  And then we had this journal club with my advisor here, Gabby Maiman.
*  He's also very interested in how RNA might be involved in computation.
*  And he shares a lot of the same ideas with this growing group of people that think molecules
*  might be involved in computation more so than is appreciated.
*  And so we had this journal club with two other neuroscientists, Abbas Rizvi and Jeremy Dittman.
*  We were reading papers and just thinking about how molecules could be involved in memory
*  and computation.
*  where I had first tested the waters with these ideas.
*  And it was very critical and just polishing the theory to get the feedback in this group.
*  It was really nice to have this group of intimate four people sitting around and then critiquing
*  that this part doesn't make sense.
*  And a lot of the things, a lot of the perspectives that I had about, that I just recently described,
*  for example, that the ribosome is a very impressive molecule and it's doing something pretty simple
*  and it's large and you can see it.
*  That's something I specifically learned from Jeremy, just that understanding of that appreciation
*  of the ribosome.
*  And so, yeah, so that's kind of where I had the opportunity to kind of flesh out the details
*  of this idea.
*  So I asked you about lambda calculus because I know that combinatorial logic and lambda
*  calculus share a lot of similarities, right?
*  But you've mentioned, I've heard you mention that combinatorial logic precedes Turing machines
*  and lambda calculus.
*  So what the hell?
*  What is that story?
*  Yes.
*  I love that you brought that up because it's not appreciated that the first mathematical
*  system, the first abstract system that humans came up with that had a universal competition
*  capacity was combinatorial logic.
*  It was discovered by this mathematician named Moses Schoenfinkel.
*  And that's kind of the only thing that I know he did.
*  I don't know if he had any other contributions and then he was just forgotten.
*  And then Haskell-Curry rediscovered it again and then realized, oh, somebody else had worked
*  on it and so he gave credit to Moses Schoenfinkel.
*  But I guess even this emphasizes the point.
*  It was discovered twice independently before we had any other system of computation.
*  Only two humans.
*  And if we have this universal computation, shouldn't it happen much more?
*  I'm going to keep coming back to this stupid point.
*  I don't know.
*  I mean, yeah, maybe.
*  Maybe prehistoric times.
*  Okay, four humans.
*  Two prehistoric and two posthistoric.
*  Okay, but so then what's the connection?
*  Why is it special?
*  Because I think the point I'm trying to make about it being the first one is that it's
*  simple.
*  It's very simple.
*  And it's also very beautiful.
*  It starts off, it's a functional programming language.
*  There are no, there's nothing that's not a function.
*  Everything is a function.
*  They call it combinators.
*  Everything is a combinator.
*  The inputs of these combinators are other combinators.
*  There's no primitive data types.
*  So it's functions of functions of functions that take in functions and spit out functions.
*  Exactly, yes.
*  And every function takes a single function and spits out another function.
*  And the way that you can get a function that takes two inputs, the way that you can build
*  a function that takes many inputs is to say, okay, let's say I want a function that does
*  addition.
*  Addition takes two inputs.
*  So what it does, the way I can do that is I can say, I'll define a function that takes
*  a number and then spits out the function that adds that number to any new input that it
*  gets.
*  And that's a technique called currying after Haskell curry.
*  It was the second person who invented a combinatorial.
*  There's no fin shinkling?
*  Is that the?
*  What's the?
*  I guess this technique was actually exclusively Curry's idea.
*  I'm not sure about that, actually.
*  I might be wrong about that.
*  But anyway, so it's very simple.
*  And then it just also very nicely maps on to RNA biology.
*  Because if you want to implement something like this at the molecular level, the main
*  challenge is parenthesis matching.
*  Regulation, in other words.
*  Yeah, I guess we're even broadening the definition of regulation even more now.
*  Okay, it's like housekeeping, right?
*  I mean, it's just counting parentheses.
*  It's not the sexy computational thing.
*  It's like, I got to keep track of where I am in this nested series of functions.
*  Yes, yes.
*  Yeah, and so you could do that explicitly.
*  Like, if I'm actually evaluating a combinatorial logic term on paper, that's probably what
*  I would do.
*  I would keep track of the depth of the parenthesis and just keep on going and then use that technique
*  to determine what's a term, what's a single term.
*  And then you could do stuff with that term.
*  But in RNA, because of that intrinsic secondary structure that RNA have, you don't need an
*  explicit machine that goes in and does this parenthesis matching.
*  Because matched parentheses are already proximal in space, in physical space.
*  So what that allows you to do is you can implement every single one of these handful of application
*  rules in combinatorial logic with local operations.
*  With local strands of RNA.
*  With local...
*  With local operations on a part of an RNA.
*  Some of which is paired with itself in a certain section and some of which is in this open
*  loop.
*  Yes, exactly.
*  So, I mean, I guess most people will be listening to this so there's no like...
*  But I will.
*  There's no illustration.
*  But I'll try to describe it in the most illustrative way.
*  For people who are watching, I'll just put up a still of you giving a talk with the hairpin
*  loop structures, right?
*  Sure, yeah.
*  Yeah, maybe like the rules or like...
*  I'll also look to your talk.
*  I don't have to be in it.
*  But like, I don't have to be in the picture.
*  Just like showing how one of the rules can be implemented.
*  One of the combinatorial logic rules can be implemented.
*  So these application rules in combinatorial logic, they're just very simple operations
*  like swap two elements or like delete an element or add parentheses around two elements that
*  come afterwards or something like that.
*  To implement that molecularly, you only need some kind of enzyme that detects the motif
*  that encodes for that combinator first.
*  Like let's say, I don't know, we have three primitive combinators and that's a key point.
*  There's only...
*  You only need a handful of primitives.
*  So let's say you have three primitive combinators.
*  So you have three different codes for these different combinators.
*  So some enzyme should detect that, hey, we have a motif here that encodes for one of
*  these combinators.
*  And that enzyme also carries with it the rule for the application rule of that combinator.
*  I want to stop you and say, we haven't figured out how this could be implemented.
*  I mean, so these are...
*  Is this completely hypothetical?
*  Yes, completely hypothetical.
*  But I do want to stress that the point of this model is that it doesn't require extraordinarily
*  complex molecules, very different from what we already know to exist in cells.
*  So our RNA strands are frequently modified after they're transcribed.
*  So the most commonly discussed modification is splicing.
*  There's something called the spliceosome that goes in and selects segments within this RNA
*  strands and excises them and then attaches the two loose ends.
*  And that's a way to delete certain parts within an RNA strand.
*  So these kinds of operations exist and we know that they're within the reach of evolution,
*  of molecular biology.
*  The point here is that I can imagine a system that's very simple, that doesn't require
*  huge molecules that do complex operations.
*  And a system like this could have gone undetected over the many decades of molecular biology.
*  But yeah, going back to how it would work, it's basically every enzyme would execute
*  cleavage and ligation operations.
*  So it would cleave a certain part of the strand and ligate the different part of the strand.
*  Cut it and put it back together.
*  Exactly.
*  Cut it and put it back together.
*  The locations of the cuts and the connections are fixed relative to the motif.
*  Because by virtue of the secondary structure bringing the parentheses together, now you
*  can say, okay, I only need to cut at this position and connect these two parts without
*  caring about what's inside the parentheses.
*  I don't care about how many layers of nested parentheses are inside.
*  This enzyme just goes in and mindlessly does this single operation.
*  And so through this system, this hypothetical system, to emphasize it's just a theory,
*  it's obviously going to be wrong in its details.
*  It's wild.
*  I mean, it's cool.
*  It's so cool, but it's wild.
*  I want to acknowledge that it's obviously wrong.
*  It's going to be wrong in its details.
*  I had to come up with details that allow the system to work that I know that I just came
*  up with.
*  But the point is that this is a proof of principle that you can imagine something like this happening
*  at the molecular level, implementing a computation system.
*  And at the same time, you have all this RNA and all this DNA that we don't know what
*  it's doing.
*  We haven't attributed a function to most of the genome, at least in humans.
*  So it's just very, I don't know, it's a very-
*  Intriguing.
*  Yes, intriguing.
*  It's a very compelling problem.
*  It's a compelling problem, but it's a compelling hypothetical solution.
*  Yes.
*  Well, I would call it, I mean, it's compelling me at least towards a research direction.
*  At the end of the day, I want to study things empirically.
*  I don't expect anyone, myself included, to believe this theory until we find evidence
*  for it.
*  We have to do the science.
*  And so it's a research direction that I'm arguing for, not like a specific model.
*  And the direction being, let's figure out if RNAs are being edited in ways that can
*  implement computation.
*  So you were disillusioned.
*  First of all, you were disillusioned.
*  And now you're hopeful.
*  Would you call yourself hopeful?
*  How would you describe your outlook?
*  Yes, I would describe it as passionate.
*  I would say I'm very passionate about this problem.
*  Sure are.
*  I feel like it's extremely exciting.
*  I think it's just, I mean, sometimes I forget and then I remind myself of all of the hints
*  that are obviously pointing at RNA.
*  And it's also heartwarming, I guess, for lack of a better word, to know that there are also
*  many other reputable scientists that take these ideas seriously and that that circle
*  is growing.
*  And I hope it grows.
*  I hope it doesn't end up being something like that subfield in the 1960s.
*  And it really depends on us.
*  It really depends on us trying to make this argument that this is a worthwhile research
*  direction.
*  I don't want everyone to be working on it.
*  I don't want you to pour 50% of all research budgets towards it.
*  But at least in the spirit of diverse approaches, I feel like we should be able to maintain
*  research direction along the lines of molecular computation and memory.
*  You just need a little drip out of the firehose of funding.
*  Basically, yeah.
*  So those scientists, those reputable scientists that you mentioned, often get labeled kind
*  of like, often don't feel fully respected right in the field and often get labeled,
*  I don't know, crazy, but you know, out of the mainstream, out of the dogma.
*  Do you ever feel, do you ever think, am I crazy?
*  I don't know, actually.
*  I might regret saying this, but sometimes I think, do people look at me the same way
*  that I look at Roger Penrose about microtubules and like...
*  That's more Stuart Hammeroff with the Penroses on board with that.
*  But yeah.
*  Yeah.
*  Or the way I look at that, right?
*  So I look at the microtubule things and I'm like, Jesus Christ.
*  Yes, exactly.
*  Yeah.
*  I don't know.
*  No, but do you feel crazy?
*  Not about how you think other people view you.
*  Do you ever think like, oh, am I crazy?
*  I don't think so.
*  I think the arguments and the evidence that I'm resting on are very rigorous.
*  And again, I want to be clear.
*  The threshold of evidence you need to believe a theory is much higher than the threshold
*  of evidence you need to work on pursuing a theory.
*  And I think it meets the latter threshold.
*  So I've had lots of conversations with people right now.
*  Alex comes to mind because he's studying things that are sort of outside the norms of what
*  the scientific community, especially in neuroscience, would consider okay to study, right?
*  Or get funding for something.
*  And you mentioned these people in the 1960s, right?
*  This is not a new idea.
*  As Yuri Buzhaki says, there's no new ideas under the sun.
*  These are all like recycled things, right?
*  He says it in a different way in how brains do computations, which he doesn't mention
*  RNA, but that's besides the point.
*  But so you mentioned these people from the 60s.
*  The idea of RNA kind of came up and then it died down.
*  So what I want to ask you is like, have you reflected on how you feel, what this tells
*  you about how science progresses?
*  Because most people like stay, they get into, let's say, experimental neuroscience, right?
*  And then that's their career.
*  It's just studying this sort of space of problems fairly narrow.
*  But now you've done that and you've learned about an alternative framework for universal
*  computation, which is one of your interests.
*  And then you realized like, well, this was not new, this kind of ebbed and flowed already.
*  How does this make you feel about the history and progress of science in general?
*  It makes me realize that we're in a fragile place.
*  It makes me realize that it may very well be that people look back at this era as some
*  time where some idea just kind of re-emerged and it died out again.
*  Now that's fine if this idea is wrong, but if 100 years down the road, they realized
*  this was all correct, but it kept on resurfacing and dying out.
*  That's a possibility.
*  I kind of want to prevent it.
*  I think there's no inevitability when it comes to these sociologically decided things.
*  And that's why I'm trying to get people to, if they don't want to work on it, at least
*  agree that it's worth putting some resources into.
*  I just want to say that also the era in the 1960s, the ideas that were there were mostly
*  around memory, were mostly around molecules encoding memory.
*  And I think this is not the same thing, really.
*  It's about computation.
*  And it's about actually bringing in the insights from the theory of computation to these strings
*  of symbols.
*  And it's obviously related to memory.
*  Memory comes up in computer science all the time.
*  But it's a different kind of perspective.
*  And also just all of the conceptual arguments are much more mature now.
*  If you read Galstow's work, the arguments are much more solid and convincing than anything
*  that anyone wrote in the 1960s.
*  And also we just have better tools.
*  It's a different era.
*  It's a very different era.
*  And it's a different idea.
*  But it's very related.
*  All right, sorry, I have to ask this.
*  So we've talked a lot about molecules and biology.
*  And you have a computer science, computer engineering background.
*  And then you got into experimental neuroscience.
*  And a lot of people who start off in neuroscience have this computational bent.
*  But then a lot of people who are in cell biology, for example, don't have that.
*  That's where the stamp collecting began and speciation and things like that.
*  But has this made you how...
*  Sorry, I'm baiting you by that.
*  I'm trying not to bias your...
*  How has this altered your appreciation or lack of appreciation for the micromolecular
*  world relative to your computational mindset?
*  I'm just leading you into the answer.
*  Sorry, but I wanted your reflections on it.
*  Yeah, I guess I mean, I kind of maybe wish in retrospect that I had studied molecular
*  biology just because that seems like a very relevant field now for the problem I'm trying
*  to work on.
*  And just to say, it's not that molecular biologists or geneticists are completely foreign to these
*  ideas or find these computational ideas foreign.
*  John Madduck, for example, explicitly argues that these non-coding RNAs might be implementing
*  a digital computation device.
*  And there are people who are definitely...
*  These ideas resonate with their ideas.
*  I guess it's just right now, not in neuroscience, not in molecular biology, is anyone really
*  trying to take universal computation seriously?
*  Are you having fun?
*  I don't know if that was correct.
*  Maybe I misunderstood your question.
*  No, well, my question is, so I've come to appreciate...
*  I've come to have a little more awe just how goddamn complex everything is.
*  And like the world of the cell, that's a whole world.
*  The brain is the most complex thing in the universe.
*  Although Terry Sanowski pointed out to me that his wife said to him, well, actually,
*  two brains is more complex than one brain.
*  So two people talking, right?
*  Which is true.
*  But these stories of...
*  The story that you're working on, if it turns out to have validity in one form or another,
*  just the capacity, the astounding results of evolution that continue on.
*  How...
*  It's just amazing to me.
*  And so that wet biology part.
*  So when I got into neuroscience, it's all computation, spikes.
*  That's how they're doing it, information, blah, blah, blah.
*  But then you look in the cells like, man, that is messy and hot.
*  But it's doing just as awesome a job, whatever job it has.
*  I mean, it's just amazing that anything works in biology.
*  Well, yeah, I mean, it's amazing until you understand how it works exactly.
*  Like, I mean, I guess...
*  Is that what you're saying?
*  Well, well, well, well, then you've explained it.
*  Like until you explain it, it's a mystery.
*  It's like, how the hell is the single cell creating a human fetus with all the intricate,
*  you know, body parts and like all...
*  It looks like a miracle.
*  Now, if somebody writes a program that draws something on the screen,
*  I wouldn't call that a miracle because I know how programs work.
*  Draw something, I mean, like some complex pattern that looks really cool
*  and as complex as a human fetus or something, I don't know.
*  Maybe that was a bad example.
*  Well, no, no, but well, this gets back to...
*  Now, we're out of time.
*  Another time, another time, perhaps.
*  Because I've taken you over, I've gone over.
*  That's some good to see you again.
*  Thanks for doing this.
*  It looks like you're having fun.
*  You having fun?
*  Yes, yeah, this was extremely fun.
*  No, no, not this conversation.
*  I mean, in your...
*  In these research questions.
*  Oh, in life, yeah, yeah.
*  Hey, am I fun?
*  Am I fun?
*  Yeah.
*  No, I meant...
*  You are definitely fun, Paul.
*  Yeah, thanks.
*  But I meant, it seems like you're having fun.
*  That's a great place to be at.
*  Yes, as long as I know that I can survive in academia, it would be the condition that
*  I would add to that.
*  Yeah, there's...
*  Yeah.
*  Okay, I wish...
*  There's that question too, yeah.
*  I wish you survival.
*  I will, if we are on a boat again and you go overboard, I will throw you...
*  What's the life vest or something like that?
*  Yes, thank you.
*  I appreciate that.
*  I appreciate that.
*  Okay, thanks, Esam.
*  Thank you so much, Paul.
*  Thank you for your time.
*  This was really fun.
*  Take care.
