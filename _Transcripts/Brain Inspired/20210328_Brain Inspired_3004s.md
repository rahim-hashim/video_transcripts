---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 3004s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 4347
Video Rating: None
---

# BI 100.6 Special: Do We Have the Right Vocabulary and Concepts?
**Brain Inspired:** [March 28, 2021](https://www.youtube.com/watch?v=sheqTPSkiu8)
*  Alright, and finally...
*  My favorite, or most irksome question is your last.
*  Do we already have...
*  Do we already have...
*  Do we already have...
*  The right vocabulary and concepts to explain how brains and minds are related?
*  Why or why not?
*  I mean, like, you've gotta be kidding me.
*  That would be...
*  I guess my favorite question because I'm so befuddled by it.
*  This is Brain Inspired.
*  Hi Paul, this is Bill in Las Vegas.
*  You ask what is something we think differently about after listening to your podcasts.
*  For me, this is the realization that neurons are not the simple summation devices that
*  we see in artificial neural networks.
*  Blake Richards in episode 9 talked about segregated dendrites, where he shows how apical dendrites
*  can receive feedback signals which could allow the neuron to learn without using back propagation.
*  And after hearing your podcast with Jeff Hawkins, I read some of his papers, where
*  he proposes additional dendrites segregation, splitting basal dendrites into near and far
*  from the cell body.
*  This could provide a way to allow context input to prime a neuron without actually triggering
*  it.
*  Combining those two things, I can finally see how neural networks might do sophisticated
*  learning and retrieval.
*  Thanks for the first 100 episodes and I'm looking forward to learning a lot of interesting
*  things from your second 100.
*  Oh no!
*  I have to do another 100?
*  Catherine!
*  Pack up the kids!
*  And the psychedelics!
*  Let's get out of here!
*  No!
*  Leave the dog!
*  Leave the dog!
*  Poor dog.
*  Okay, welcome to the final 100th episode installment here.
*  I really enjoyed these collections and I hope that you have as well.
*  So the question of the day that a bunch of my previous guests have answered is, do we
*  already have the right vocabulary and concepts to explain how brains and minds are related?
*  Why or why not?
*  As has been my custom, I will just answer this as well.
*  I say no, not really, but it's kind of a split answer.
*  I don't think we have all of the right concepts.
*  I think that you can see this in a recent episode with David Cicillo and Omri Barak
*  in the dynamical systems theory framework that's popular right now, which I love and
*  you should too.
*  But even people who practice it, like David Cicillo who recently articulated this on the
*  show, even people who practice it, or at least some, see it not as an ultimate explanation
*  of brains themselves or brain functioning to generate mind and behavior, but as something
*  that constitutes progress toward understanding.
*  One way among likely others that get toward satisfying explanations at all the equally
*  special little levels that we talk about.
*  I think it is important to acknowledge how language works though, how our vocabulary
*  can remain the same while the concepts associated with our words definitely change over time.
*  That's just the nature of language.
*  It was Brian Christian recently on the podcast who pointed out that even machine learning
*  networks, when they're trained on newspaper articles from last year, say, can have trouble
*  correctly sorting out the language from this year.
*  So that's again, just the nature of drifting semantics and concepts in our language usage.
*  So in that sense, our language seems to me irrelevant, since it will continue to take
*  on and throw away changing concepts.
*  Even though I myself get plenty frustrated with language usage, since to me it seems
*  to lead to so much wasted time misunderstanding each other.
*  And I think that's probably normal for areas of science where you're dealing with so much
*  unknown and so much complexity.
*  Okay, so that's my little answer.
*  Now you get to listen in random order to many of my previous guests answer that question.
*  So I do look forward very much to 100 more episodes.
*  And I just want to say one more time, thank you for listening.
*  Thank you to my Patreon supporters.
*  Please do consider supporting the podcast for super cheap.
*  If you find it valuable, there's various things that you get when you support the podcast.
*  Check out braininspired.co and find the red Patreon button there.
*  And thank you again to all the previous guests who said yes and showed up to talk to me.
*  I feel very grateful and the audience does too.
*  So thank you so much.
*  Andrew Sachs here.
*  All right.
*  And finally, do we already have the right vocabulary and concepts to explain how brains
*  and minds are related?
*  I don't think we're doing badly in the sense that I think we are using the vocabulary and
*  concepts that we have so far in broadly productive ways.
*  I think we will come up with better concepts.
*  And I think our ability to invent new concepts that clarify new phenomena is underappreciated,
*  actually, at the moment.
*  So sometimes people say there's no way to describe what a deep network does in language.
*  That's true today.
*  We don't have the language for it today.
*  But I don't think it recognizes that in the future we can invent new words.
*  This is just a beautiful aspect of human cognition.
*  So if you think about the gas laws in physics, ideal gas laws, pressure times volume equals
*  nRT.
*  Pressure is natural enough.
*  We all know what that is.
*  Volume, we know what that is.
*  Temperature, kind of have a sense of that.
*  What about atomic number, though?
*  There was an epoch where couldn't you imagine someone saying, we don't have the language
*  to describe what gases do.
*  And then eventually you invent concepts of an atom.
*  You learn about the concept of atomic number.
*  And now it seems routine.
*  We teach it in high school.
*  To my mind, that is going to happen for our deep learning systems and other theories of
*  cognition.
*  And it's a grand challenge that spans neuroscience and AI to find these concepts that we need
*  in order to explain the behavior of these nonlinear high dimensional learned systems.
*  Thomas Nosolaris, Department of Neuroscience, University of Minnesota.
*  Do we already have the right vocabulary and concepts to explain how brains and minds are related?
*  I can't answer for we, but I certainly don't.
*  I think even my own best ideas, I don't really know how to describe them yet.
*  And even when I do have the right vocabulary to describe them, they are probably going
*  to be wrong.
*  So maybe someone else has the right words, the right vocabulary, but I know that I don't.
*  This is John Crackauer.
*  The assumption there is that there's going to be a set of concepts and vocabulary that
*  will allow you to fuse and subsume talking about the mind and talking about the brain
*  with that one language.
*  Right.
*  Now, if it turns out that the question that you're asking in terms of the relevant question,
*  determines the language of explanation you're going to use because of what you've decided
*  is relevant, then you're probably going to find that the language and the concepts changes
*  with respect to the level of the question you ask.
*  And so at a meta level, I think the concept and the vocabulary will be one that doesn't
*  a single set of concepts or words for a single phenomena because there'll be multiple ways
*  to talk about that single phenomena.
*  And that feeds back into the idea that this notion would be less hard to swallow if one
*  were to read a little bit more philosophy.
*  I'm Federico Turcamer at the Institute of Psychiatry, Psychology and Neuroscience, King's
*  College in London.
*  So the last time we talked, we discussed emergence.
*  And I wrote something pretty basic, I would say, which simply stated that we needed to
*  have a quantitative approach to emergence.
*  And I don't exactly remember when was the last time we talked, but during this time,
*  this has actually happened.
*  And I was mentioning to you that, for example, the complexity group, I mean, there is a group
*  of people interested in complexity science, and Imperial, Oxford, and I think Cambridge,
*  worked out a statistical approach to actually look at emergence, quantifying emergent activity
*  from brain, say, standard functional MRIs.
*  And that has been actually integrated with genetic data.
*  And I'm also trying to understand how that comes out of the biology of the brain, which
*  is to be missing.
*  But at least now we have maps.
*  There is this very fantastic map they've shown where they show the two sides of the brain,
*  the very modular brain and the very synergistic brain.
*  And this does correspond to differences in the genetics, genomics, and biology of the
*  associative cortices versus the non-associative cortices.
*  And the numerics do confirm that this double-sided nature of the brain seems to generate the
*  kind of cognition that we call a mind or we call.
*  And I'm trying, I'm doing a project at the moment where I'm trying to understand how
*  that could evolve from the primary brain.
*  How is that come out?
*  What is the mover of that, of those two sides?
*  It must be something simple because evolution ultimately is not that complicated.
*  But why are these associative cortices so different?
*  They have more connected, they have more synapses, they have less myelin than the others.
*  And they are this hat that is sitting on top on something which is more modular, you know,
*  the standard primary and secondary cortices.
*  How is that, did that happen?
*  This is Steve Potter from the Georgia Tech Laboratory for Neuroengineering.
*  Do we have the right vocabulary, this is question five, do we have the right vocabulary and
*  concepts to have a satisfying explanation for how brains and minds are related?
*  We probably don't have the right vocabulary and concepts to have a satisfying explanation
*  for how brains and minds are related.
*  We need a lot more terminology and tools that have to do with complex emergent systems and
*  their dynamics.
*  For example, I often hear computational neuroscientists talking about brain states.
*  But this concept is borrowed from digital computers which actually do have states.
*  Their transistors are either on or off, allowing for a well-defined state during most of every
*  clock cycle on the computer.
*  The brain by contrast doesn't have a clock.
*  It does not, yes there are rhythms and things oscillating in the brain, but there's not
*  a system clock like there is in a computer.
*  Brain is continually changing.
*  Continuously changing you could say.
*  It doesn't go from state to state, it flows, it evolves.
*  So we need more vocabulary to talk about what, for example, does an attractor mean when we're
*  talking about the brain, moving towards making a decision or coming up with an idea.
*  I feel like all the terminology we have for those right now are the same ones William
*  James was using 120 years ago.
*  This is David Crackauer.
*  My favorite or most irksome question is your last, which is do we have the right vocabulary
*  and concepts to explain how brains and minds are related?
*  The answer is obviously we do not.
*  It's interesting because it's a very old problem and it pops up everywhere.
*  You ask the question as brain to mind.
*  In the past, biologists ask the question in terms of life and non-life, geneticists in
*  terms of genotypes and phenotypes, computer science in terms of hardware and software.
*  And they're all instances of the same dichotomy between the material domain and the codicle
*  domain.
*  Most systems that are functional or adaptive permit of both types of description.
*  And it's interesting, it goes way back.
*  You see these distinctions being made in the Middle Ages by Thomas Aquinas when he's talking
*  about intellectual operation or the soul as being quite distinct from the corporeal
*  world.
*  And that gets in some sense elaborated on by Descartes in his Discourse on Method where
*  he introduced what we now know as Cartesian dualism, where he argues that matter cannot
*  have a perfect understanding of itself.
*  And that has never gone away.
*  And the question is why?
*  And I don't have an answer.
*  Part of it has to do with a desire to always reduce an explanation to a single epistemological
*  variety.
*  Somehow the material domain is more appealing than an explanation provided in terms of information,
*  for example, or computation or logical principles.
*  It feels more satisfying because obviously the mental world sits on the physical world.
*  On the other hand, most of what we do in our lives when we talk about the economy or history
*  is articulated in these codical terms and we don't seem to be much bothered by it.
*  And so that's all to say that I think we don't have as of yet the right vocabulary.
*  I think Alan Turing in creating the Turing machine and Alonzo Church in creating the
*  lambda calculus were inching towards what we might need.
*  The Turing machine is obviously a mathematical construction, not a physical one.
*  It's infinite after all.
*  But it does somehow straddle a little bit of those two worlds.
*  And the key concept for Turing was universality.
*  And I would guess that any adequate explanation of why these two alternative forms of description
*  have to exist would turn on a concept like universality.
*  So that would be, I guess, my favorite question because I'm so befuddled by it.
*  This is Dean Buonamano.
*  Do we already have the right vocabulary and concepts to explain how brains and minds
*  are related?
*  Why or why not?
*  Okay, so by mind I'm going to assume you're including consciousness.
*  And in that case my answer is a clear no.
*  I don't think we have the vocabulary or concepts.
*  Understanding the human mind and the nature of consciousness is perhaps the most profound
*  of all scientific questions.
*  And it is the mother of all recurrent problems.
*  The brain is trying to understand itself.
*  I think it's a perfectly valid question to ask if that's even possible.
*  Can any device, can any system actually understand itself?
*  We don't expect chimpanzees or other primates to be capable of understanding themselves.
*  And for the most part we don't expect AIs necessarily to be capable of understanding
*  themselves.
*  So I think this is something that's often not taken as seriously as it should be in
*  this debate.
*  But to see how far we are from having the right vocabulary and concepts to understand
*  the relationship between the brain and mind, one just has to look at the theories of consciousness.
*  While most neuroscientists, certainly myself included, believe that consciousness and the
*  our emergent properties of our neural circuits.
*  But oddly in some well-known neuroscientists and some of the most talked about theories
*  of consciousness are panpsychist theories such as integrated information theory or IIT,
*  which place consciousness in the realm of physics.
*  So this is a serious reason why we don't have the right vocabulary and concepts.
*  So we don't even have general agreement or universal agreement that consciousness is
*  attributable to neuroscience.
*  Some people think it's in physics.
*  And in my opinion I think this highlights the recursive nature of the task.
*  If the brain is to understand itself it has to account for its own limitations and cognitive
*  biases.
*  One of our cognitive biases is to explain away things that we don't understand through
*  supernatural forces or fundamental forces of physics.
*  Like the notion of vitalism or l'un victal, we're used to explain the nature of life at
*  the end of the 1800s.
*  So I think in my mind panpsychism is more a symptom of how the mind works than a consistent
*  theory of how the mind works.
*  So overall I think we're a long way, we have a long way to go before the brain comes to
*  understand itself.
*  My name is Konrad Kalning.
*  I'm a neuroscientist at the University of Pennsylvania.
*  Last point, do we already have the right vocabulary and concepts to explain how brains and minds
*  are related?
*  Why or why not?
*  I mean like you've got to be kidding me, of course we don't.
*  The vocabulary we use now is very different from 10 years ago.
*  Why on earth would we believe that we are very close to solving things?
*  No one is even pretending that they can meaningfully simulate the human brain.
*  We can't really simulate C elegance for crying out loud.
*  So why would we have the right concepts?
*  Now I want to go one step further.
*  I think that because we are so strongly on the mechanistic train where we want to understand
*  the brain in terms of the mechanisms there and because we are so strongly reductionist,
*  a lot of the vocabulary that ultimately deals with the objectives of systems.
*  Why are animals designed the way they are?
*  And why did evolution get us there?
*  And that allows us to argue from ecological niche about organization of the brain.
*  And I believe we will need these kinds of arguments.
*  Uri Hassan from Pritzan University.
*  No, the six million dollars question.
*  First, we're still stuck in representations and operations as classically high systems
*  that we need to get rid of.
*  Now when you switch representation with embeddings that some of your audience will know what
*  is embedding is you start to get to a more dynamical system, but embedding is not enough,
*  right?
*  It's the basis of action, but it's not enough.
*  And then when we ask how from this blind embedding and direct fit you get understanding,
*  this is even missing in the current AI version.
*  I think AI systems are more like system one, intuitive and fast and fit to the statistics
*  and act without understanding.
*  You can get a long way with system one, but we also have system two, right?
*  We also slow and elaborate and thinking and deciding this is completely missing in current
*  AI.
*  We're really missing out to get from system one, other parameter memorization interpolation
*  to system two.
*  And that's the big question for the coming years.
*  So I'm Rodrigo Kianchiroga, neuroscientist at the University of Leicester.
*  Well, this is a centuries long discussion and the one that put it up front was Descartes
*  dualism.
*  I don't believe in this kind of like essential distinction between mind and brain.
*  I think it's just different levels of seeing the same problem.
*  So sometimes you want to see behavior, I mean like high level behavior and this is more
*  or less what psychology focus on.
*  And then in some other cases you want to go to level of single neurons and see more detailed
*  mechanisms and this is a little bit more the realm of neuroscience, although you can argue
*  that neuroscience can encompass everything because you can also have cognitive neuroscience
*  and so on.
*  So I think basically it's kind of like certain other people when I say that, particularly
*  the churchlands.
*  I mean, mind and brain are the same thing.
*  I mean, the mind is nothing more than the activity of neurons.
*  And if we talk about the mind or if I talk about neurons, it's basically just choosing
*  the right level of description to describe or to try to understand some phenomenon.
*  But I mean, in principle, I see mind and brain as the same thing.
*  My name is Jim DeCarlo.
*  And clearly I don't think we have the right vocabulary and concepts because we don't even
*  agree on concepts or goals of what it would mean to explain.
*  I think there's an important thing to think about humans not having a vocabulary to explain
*  something to each other in the terms that we thought we should versus humans having
*  the ability to build systems that effectively act as explanations.
*  And those are two different modes of understanding.
*  And it's the latter that I think we need to figure out how to be comfortable with.
*  That's again related to the idea that things are complicated.
*  Explanations are going to be complicated and not held within human minds.
*  OK, so my name is Marcel van Gerven.
*  I'm chair of the AI department at the Donders Institute.
*  So I think we have the right vocabulary to describe brains and to describe neuronal dynamics
*  and to model that.
*  I think that's there.
*  But at the same time, we have minds and they basically live on top of those neuronal dynamics.
*  So these are cognition is basically defined in terms of symbols, cognitive states, representations,
*  etc.
*  And these things live within the neuronal dynamics, but they unfold at much slower time
*  scales than the time scales you typically associate with single neuron dynamics.
*  So we need to gain an understanding of how these dynamics within neural networks relates
*  to more complicated, stable states that do reflect something which has to do with cognition.
*  And I think people have realized that a long time ago as well, right?
*  So if you look back, there's a lot of work on linking recurrent neural networks to nonlinear
*  dynamical systems theory and actually finding descriptors that describe these higher level
*  states that might be more related to cognition in the end.
*  But we didn't nail it.
*  So there's something missing still.
*  Let's take a quick little break and then we'll get back to the responses.
*  My name is Josh Sandeman.
*  My introduction to your podcast was the crack hour episode and that drew me in.
*  You know, I found it to be an incredibly thought provoking and engaging conversation about
*  some very fundamental issues of how nature creates pattern and the difference between
*  what nature is actually doing in all of its detail and how we're able to model it without
*  losing, finding that balance between the amount of detail we need but also being able to extract
*  the principles.
*  In other words, finding the perfect degree of sphericality of the cow.
*  You know, and that was I think one of the big take home points for me from that discussion.
*  And it just was, it inspired me to continue to follow the podcast.
*  Like I said before, I've listened to virtually everyone since and just always been able to
*  take something from it in terms of some of these overall issues, in terms of how brains
*  can exist at all, how they extract information, process information and then can act upon
*  it and then how brains can study themselves as a result of that.
*  It's been very fascinating and edifying.
*  Masrita Cherimutta.
*  Yeah, do I think we have the right vocabulary?
*  No, I wouldn't say right now.
*  I mean, the current best guess at the right level of simplification for understanding
*  the brain has been the computational theory.
*  But I think there are a lot of problems with just thinking that computation is going to
*  be the final theory that will unlock all the secrets of the brains because I think it's
*  bound to miss out a lot of the very important biological details that probably allow brains
*  to do what they do and allow brains to be generating thoughts and be the basis of thought
*  and being the substrate of the mind.
*  So I think as long as our understanding of how the brain works is so closely tied to
*  the computational framework, I don't think we're going to be able to make sense completely
*  of how it relates to the mind.
*  Just to give an example, I mean, within the computational framework, people talk about
*  mind as software and brain as the level of implementation.
*  So they really directly take those concepts from computer science.
*  And I think there are so many disanalogies between brains and computers that that cannot
*  be the right answer about how brains and minds are related.
*  This is Brad Love from UCL.
*  Do we already have the right vocabulary and concepts to explain how the brain and minds
*  are related?
*  Why or why not?
*  Yeah, there's a lot of discussion about this.
*  And I think it's somewhat of a red herring.
*  I know your listeners like philosophical ideas.
*  So if you just look at like Quine and Wittgenstein, like how they talk about meaning arising within
*  a larger system.
*  So I think that's the same with vocabulary, science vocabulary.
*  I mean, saying attention doesn't mean anything alone.
*  It's within a system of other concepts.
*  So right off the bat, it's not really about vocabulary itself, but about use and how it's
*  used.
*  And for me, these words change over time.
*  It's not like attention means the same thing now than it does before.
*  The meanings evolve with use and how they relate to other terms.
*  For me, someone that makes computational models, I just don't really care what things
*  are called.
*  So you could say attention is not meaningful or somehow outdated, but it's just an equation
*  in the model that's doing something valuable.
*  And if you want to call it something else or not, that makes no difference.
*  So I think this is really not a real debate or something that we should be using our time
*  on.
*  As science progresses and evolves, maybe we get a new vocabulary.
*  Maybe the old words change meanings.
*  Some are lost, some are added.
*  But I don't think this is really something that you just go out and try to redo or reject.
*  It just doesn't really make sense to me.
*  It's Patrick Mayo.
*  Do we already have the right vocabulary and concepts to explain how brains and minds are
*  related?
*  Why or why not?
*  I'm one of those people who doesn't really use the word mind.
*  I majored in cognitive science in college.
*  And one of the reasons I'm doing neuroscience is because I got a bit frustrated with the
*  word mind and with people sitting around and talking about things, sort of like a philosophy
*  class.
*  So I learned a ton from those classes, and it certainly had sparked my interest in how
*  the brain works.
*  But I don't really know what the mind is.
*  There's the mind meld from the Vulcan Star Trek mind meld.
*  I know what that is.
*  But otherwise, I'm studying the brain by doing extracellular electrophysiological recordings.
*  Whatever terms we have for that right now, I'm okay with.
*  Hi, Paul.
*  This is Yuri.
*  What ideas, assumptions, terms do you think is holding back neuroscience and so on?
*  And the other one is related in my mind.
*  Do we already have the right vocabulary and concepts to explain how brains and minds are
*  related?
*  My answer.
*  Scientists began to study the brain, buying into a system created by philosophers and
*  psychologists for understanding the soul and the mind without ever asking how those terms
*  whose brain functions we are trying to understand, such as consciousness, were brought into our
*  thinking in the first place.
*  Neuroscience has inherited this paradigm from such philosophy driven framework, which portrays
*  or more precisely, the soul and the mind as a tool to learn about the true nature of the
*  world.
*  Early thinkers used introspection and gave names to mental operations.
*  And now millennia later, we search for neural mechanism that might relate to their dreamt
*  up ideas.
*  Of course, an inevitable consequence of this framework, what I call outside in, is the
*  assumption that the brain's fundamental goal is to perceive signals from the outside world,
*  process such information, correctly interpret them.
*  In order to respond to these signals, an additional operation is needed.
*  Wedged between the perceptual inputs and the organism response is the terrain of a hypothetical
*  central processor.
*  This is an entity that chooses what to do with the processed information.
*  This poorly understood but often speculated about terrain has been referred to by various
*  terms, such as free will, homunculus, consciousness, executive functions, intervening variables,
*  black box, or more recently, decision maker, depending on the experimenter's philosophical
*  inclination, or whether the hypothetical operation is applied to the human brain, brains of other
*  animals or computer models.
*  Yet, of course, they all refer to the same thing.
*  The key assumption in this perception, decision, action paradigm is that information is processed
*  properly so that something somewhere in the brain can decide to select the correct action.
*  An implicit practical implication of this outside in framework is that the next frontier
*  for progress in contemporary neuroscience should be to find the central processor somewhere
*  in the brain and systematically elaborate the neural mechanisms of decision making.
*  This is exactly what's going on at full speed in today's neuroscience.
*  Over the past decade, decision making has become a bus term and applied to virtually
*  all research without pausing a bit and asking ourselves, do we know precisely what we are
*  looking for?
*  In my new book, The Brain from Inside Out, I argue that this outside in framework may
*  not be the best strategy to understand the brain.
*  Brain evolution didn't start out to generate a program where the end product should be
*  the human level cognitive faculties.
*  Instead, brains evolved to induce actions and learn to predict the consequences of those
*  actions as afforded by a particular environment.
*  The brain is not interested in the true nature of the world.
*  Instead, its main preoccupation is to help its host to survive and prosper in its niche.
*  I speculate that this action centric approach is more strongly embedded in evolution.
*  The neurophysiological findings are more compatible with it and the problems can be formulated
*  differently, including the problem of the relationship between brains and minds.
*  I suggest that by trying out this Inside Out strategy, perhaps some of the currently controversial
*  terms may become dispensable.
*  The choice of a particular framework is important in our everyday practice because frameworks
*  shape our ideas, both about experimental design and interpretation.
*  I don't think that my suggested strategy is perfect.
*  Yet, I believe that this alternative is perhaps more fruitful than the currently dominant
*  outside in framework that so strongly influences AI.
*  Peter Rufsema, so I mean about the vocabulary, what I can say is definitely the way that
*  we talk about concepts like consciousness and attention are really important, but they
*  have a very complex relationship to the things we measure in neuroscience, in neurons.
*  Take for example, attention as an example.
*  When I started to work on vision, I tried to avoid the word attention because I thought
*  it was completely misdefined or at least differently defined by different workers in the field.
*  So I thought, let's just not talk about attention because it will make my life easier.
*  But at some point I came to realize that that's not good because there are many aspects in
*  vision that are really related to how attention works.
*  There is a very important literature developed by psychologists that use the word attention
*  and there's no way of avoiding it.
*  So then you need to redefine attention because there's selective attention, there is attention
*  in terms of alertness and there are many types of attention.
*  You really have to keep these things in mind if you work in neuroscience and try to address
*  questions about attention.
*  For me then, consciousness was basically a word that I then tried to avoid.
*  I did that successfully for a number of years, but at some point I also realized I cannot
*  avoid it anymore.
*  I think there the problem is even more severe.
*  I think even categorizing different types of consciousness and the different definitions
*  is still in the beginning.
*  So that will take some time to sort it out.
*  David Popol, and I work at NYU and at the Max Planck Institute.
*  We have the right vocabulary for our particular concerns right now.
*  So we have good vocabulary for certain parts of the cognitive sciences and we have good
*  vocabulary for parts of the neurosciences.
*  What we lack are convincing linking hypotheses between the vocabularies.
*  So we have coherent hypotheses about the ontological structure or the cognitive ontologies in cognitive
*  science and the biological ontologies in neuroscience, but we do not have ontological linking hypotheses,
*  which makes us ontologically incommensurable.
*  And then it raises questions about where do you start?
*  You start with the psychological or computational or cognitive theories or the biological ones.
*  Are you an inside out person like Yuri wants to be?
*  Or are you an outside in person like I want to be?
*  And where do you meet in the middle?
*  So we have some good vocabulary actually, some good decomposition of the problems, but
*  we lack the links so far.
*  Let's pay attention to that and maybe we'll move on a bit.
*  This is Paul Ciszek from the University of Montreal.
*  So no, I don't think we quite have the right vocabulary.
*  I think we are still influenced too much by pre-scientific concepts about the mind, sort
*  of assuming that they'll happen to map one-to-one to real mechanisms in the brain, but I don't
*  think we can really make that assumption.
*  But unfortunately, I think by the time a graduate student has the confidence to question the
*  stuff they read in their textbooks or journal articles, they've already spent too much time
*  being an undergraduate student just absorbing information on how to think exclusively in
*  terms of that kind of stuff.
*  So it seems preposterous to question the idea that the brain is an information processing
*  system or that concepts like memory or attention should define our research programs.
*  That's just the vocabulary and the relevant questions or phrase in those terms.
*  But I think that some of those definitions might just be wrong and then they lead us
*  the wrong way.
*  So I think, as you know, that I think the best way to subdivide the problem of behavior
*  is to do so with the guidance of evolutionary history.
*  So in other words, the definitions of functions or systems can be done through the gradual
*  differentiation of functions and systems that mirrors how ancestors transition to their
*  descendants because that's how the functional architecture of the brain was actually constructed.
*  So after all, and I think we all agree with that, so it seems like it's the right way
*  for us to build models of that architecture.
*  And that leads to rather different types of questions.
*  You focus instead on specific transitions that occurred at specific times in our history,
*  doing so from both a neural and behavioral perspective.
*  And so the example I'll use here is related to this question of memory, but it doesn't
*  sound maybe like it.
*  So the point is that the example I would give is I think it's a fascinating question of
*  how our ancestors took the hippocampal complex, which evolved over hundreds of millions of
*  years in the service of guiding navigation through physical space, and at some point
*  started using it for more abstract tasks, including constructing episodic memories of
*  the sequential events in our lives.
*  In other words, I think we shouldn't think of memory as some kind of a thing that some
*  kind of problem, some kind of like abstract platonic solid that our brains finally succeeded
*  in implementing after millions of years of trying different ways of encoding information.
*  Instead, we should think of our brain as modifying its control systems, in particular idiosyncratic
*  ways that extended specific behavioral capacities like navigation.
*  And at some point, certain things emerged.
*  And some of those things that we call memory is just a set of a phenomena that were produced
*  by that gradually evolving system, which is still a work in progress.
*  So in other words, rather than define the problem to be solved, think about the capacities
*  that modifications enabled and then how those capacities produce certain phenomena like
*  memory or attention or some of the things that we traditionally think about.
*  I think it's possible to sort of reconstruct the vocabulary so that you don't start with
*  those things.
*  You start with more fundamental biological processes.
*  Now, most of that is just about neuroscience.
*  It doesn't really apply to AI.
*  In AI, if you want to build a system, then how well it works is the most important thing.
*  You don't necessarily have to be concerned about biology.
*  You could make a memory module and work out what's an efficient way for it to store information.
*  But I think if you want human-like AI, then you really want to add those additional constraints
*  of biological plausibility.
*  And the way to do that, I think, is to think about some of these evolutionary and philosophical
*  issues that I think face neuroscientists.
*  I think they'll provide the right kind of insights for AI as well.
*  TALIA CONKLE
*  Do we already have the right vocabulary and concepts to explain how brains and minds are
*  related?
*  Why are we?
*  Yes and no.
*  Again, I think there's...
*  I'm going to just tweak the question a little bit.
*  I think that hidden in the question is a sense that there's the right vocabulary and concepts
*  to explain how minds and brains are related.
*  And I think we need a lot of vocabularies.
*  I think different levels of abstraction are really important.
*  There's some sides that think if we can build it, we've got a really detailed model, like
*  a computational model that's almost a direct map, sort of silicon implementation of a brain.
*  Well, then we're done.
*  And in some sense, yeah, that's true.
*  You can do a bunch of experiments on it.
*  You can test it.
*  You can make predictions.
*  And I think that is a really useful level of representation and a particular kind of
*  vocabulary.
*  But I also want a level of understanding that lets me give sort of intuitive answers to
*  questions like, well, how does this work?
*  And why does that happen?
*  I kind of want them compressible into simple language and ideas, the kind that scaffold
*  how we teach the next generations.
*  We talk about dorsal and ventral stream and hierarchy.
*  And these are really compressed concepts that clearly are making some simplifications that
*  are hugely powerful for situating our concepts for how we think about what the next problems
*  are and what are the problems we need to solve.
*  So yeah, I think you want sort of a multi-scale vocabulary, one that's really detailed and
*  some that are super high level and really good for sort of conveying broad swaths of
*  ideas and a few phrases.
*  And I think that a multi-level vocabulary is going to be really important for understanding
*  how brains and minds and models are related.
*  I'm Steve Grossberg.
*  Do we already have the right vocabulary and concepts to explain how brains and minds
*  are related?
*  Why or why not?
*  Well, as you might guess from my previous answers, I reply, yes.
*  My discoveries with many gifted colleagues over the past 63 years provide insights into
*  most of the fundamental processes whereby our brains do make our minds.
*  There are over 550 articles on my webpage, sites.edu.edu.
*  Steve G summarizing these discoveries.
*  But for people who don't want to have to browse over so much stuff, as well as lectures there,
*  let me just remark that an introductory and non-technical overview of these discoveries
*  is provided by my book.
*  Actually it's my magnum opus that's now in press with Oxford University Press.
*  It'll be published this spring and its title is Conscious Mind, Resonant Brain, How Each
*  Brain Makes a Mind.
*  All you need to do to get started is to read my book or study a subset of the articles
*  on my webpage that interest you.
*  Both routes should stimulate a lot of thinking and new discoveries.
*  So thanks very much for listening.
*  The full versions of all the episodes, plus bonus episodes that focus more on the cultural
*  side but still have science.
*  Go to braininspired.co and find the red Patreon button there.
*  To get in touch with me, email paul at braininspired.co.
*  The music you hear is by The New Year.
*  Find them at thenewyear.net.
*  Thank you for your support.
*  See you next time.
