---
Date Generated: February 12, 2025
Transcription Model: whisper medium 20231117
Length: 3031s
Video Keywords: ['neuroscience', 'machine learning', 'deep learning', 'artificial intelligence']
Video Views: 2344
Video Rating: None
Video Description: Show notes:
https://braininspired.co/podcast/11/

Grace shares her recent work adding an attention signal to convolutional neural networks - ones that emulate the ventral visual stream in the brain - to test the "feature gain similarity" model of attention. Lots more, of course.
---

# BI 011 Grace Lindsay:  Visual Attention in CNNs
**Brain Inspired:** [October 15, 2018](https://www.youtube.com/watch?v=0GtIO3j7jOE)
*  It's so hard to say. I mean, ultimately, yes, especially if the goal is human behavior, [[00:00:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=0.0s)]
*  not just like being the best at everything, because that's not very human. So if you're [[00:00:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=5.72s)]
*  actually trying to mimic a human, you're probably going to do well to look at human brains. [[00:00:09](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=9.32s)]
*  Grace, what is attention? [[00:00:15](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=15.8s)]
*  Yeah. It is a problem that it has so many meanings. [[00:00:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=19.0s)]
*  This is Brain Inspired. [[00:00:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=30.0s)]
*  Hey, this is Paul in Little Brooks in my new little studio in my new home here in Durango, [[00:00:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=37.0s)]
*  Colorado. Settled in with stable and fast internet, which I haven't had in over a year, [[00:00:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=44.0s)]
*  so it's a good day in my world. I hope it's a great day in your world, and you're approaching [[00:00:50](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=50.0s)]
*  life with curiosity and a bias toward acting on that curiosity. I hope this podcast helps [[00:00:56](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=56.0s)]
*  satisfy and continue to drive that curiosity. If you have a question you'd like me to ask [[00:01:03](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=63.0s)]
*  one of my guests, send it to me, and maybe I can get on the show. Send it to paul at [[00:01:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=68.0s)]
*  braininspired.co. If possible, record your voice and send it to me as an audio file. [[00:01:13](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=73.0s)]
*  Otherwise, I'm happy to just read the text of the question. [[00:01:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=79.0s)]
*  Thanks for supporting the show. Right now, the only support I request is that you review [[00:01:23](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=83.0s)]
*  or rate the show on iTunes, and please tell a friend if you find value in the Brain Inspired [[00:01:29](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=89.0s)]
*  podcast. I continue to appreciate the emails I've received lately. It's really a pleasure [[00:01:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=94.0s)]
*  to hear from you guys, and I look forward to hearing from more of you. [[00:01:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=100.0s)]
*  We have some great guests coming up. Next week, I'm talking with Dalip George, who co-founded [[00:01:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=104.0s)]
*  the AI company Vicarious. They're working on developing general AI for robots, so that [[00:01:50](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=110.0s)]
*  should be fun and take us in a new direction here. After that, I'll have Nico Kriegeskort. [[00:01:56](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=116.0s)]
*  I'll have to ask him how to pronounce his name correctly. Nico is a professor at Columbia [[00:02:01](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=121.0s)]
*  University who uses deep learning to better understand our brains, much like we've been [[00:02:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=128.0s)]
*  talking about on some of the previous episodes here. And he runs the new annual conference [[00:02:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=132.0s)]
*  called Cognitive Computational Neuroscience Conference, so I'll get the lowdown on that [[00:02:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=138.0s)]
*  as well. Today, I talk with Grace Lindsay. She definitely has a bias toward action. She [[00:02:23](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=143.0s)]
*  gets things done. She's a postdoc at Columbia University, exploring how convolutional neural [[00:02:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=150.0s)]
*  networks can be used to model how the brain works, specifically how attention might be [[00:02:36](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=156.0s)]
*  implemented in the brain's visual system. In her spare time, she writes an excellent [[00:02:41](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=161.0s)]
*  blog, manages to tweet a lot. She is at NeuroGrace on Twitter, and she co-hosts the podcast [[00:02:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=165.0s)]
*  Unsupervised Thinking, all of which we discuss during the show. When we start to talk about [[00:02:53](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=173.0s)]
*  her recent work, you'll hear me suggest listening to my interview with Dan Yeamans for a deeper [[00:03:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=180.0s)]
*  primer on how convolutional neural networks are used to model the brain's visual system. [[00:03:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=185.0s)]
*  We do summarize it over the course of a minute or two during this episode, but you might [[00:03:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=191.0s)]
*  want more. So in this show, I say that it's episode eight with Dan Yeamans, but that's [[00:03:17](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=197.0s)]
*  wrong. It's actually episode seven, so refer to that episode. Or like I say in the show, [[00:03:22](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=202.0s)]
*  Grace wrote a great piece on the same subject that I link to in the show notes, of course, [[00:03:29](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=209.0s)]
*  at braininspired.co.slash.podcast.slash.11. Without further ado, please enjoy our conversation. [[00:03:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=214.0s)]
*  Grace Lindsay, I welcome you and your convolutional neural networks to the show. [[00:03:43](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=223.0s)]
*  Thank you. [[00:03:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=229.0s)]
*  Actually, so what do you call them? Convolutional neural networks, ConvNet, CNNs? [[00:03:50](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=230.0s)]
*  I usually call them convolutional neural networks when I'm talking, and when I write, I use [[00:03:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=235.0s)]
*  CNNs, not ConvNets usually. [[00:04:01](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=241.0s)]
*  Okay, very good. So maybe we might switch a little bit between the different ones today. [[00:04:03](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=243.0s)]
*  I think I'll be able to keep up. [[00:04:09](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=249.0s)]
*  Well, yes, of course you can. So you got your PhD at Columbia University last year. Where [[00:04:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=251.0s)]
*  are you these days? [[00:04:17](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=257.0s)]
*  I'm still, I'm a postdoc at Columbia University still. I'm in the same lab as my PhD was in. [[00:04:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=259.0s)]
*  I'm kind of finishing some stuff up there and starting new stuff to hand off to other [[00:04:26](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=266.0s)]
*  people before I switch to a proper postdoc. But I'm living in London, so it's kind of [[00:04:32](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=272.0s)]
*  a weird situation. [[00:04:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=277.0s)]
*  You are kind of all over the place on the internet as well. So you have a great blog [[00:04:39](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=279.0s)]
*  where you cover neuroscience and other topics. You co-host the Unsupervised Thinking podcast. [[00:04:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=285.0s)]
*  You're writing a book. You've covered a lot of ground in your other writings as well, [[00:04:53](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=293.0s)]
*  and I won't list them all. People can visit your website to see that stuff. [[00:04:58](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=298.0s)]
*  But let's start with the most important fact here. I found out that you and I were at the [[00:05:01](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=301.0s)]
*  University of Pittsburgh together, sort of. You were getting your undergraduate degree, [[00:05:06](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=306.0s)]
*  and I was in graduate school. But my office in the basement of the Mellon Institute there [[00:05:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=311.0s)]
*  was one door down from Taising Lees. Now, Taising would attend these weekly multi-lab [[00:05:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=316.0s)]
*  meetings that we would have, and he'd always have his little brown teapot. I don't know [[00:05:22](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=322.0s)]
*  if you ever came across that teapot. [[00:05:27](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=327.0s)]
*  Oh, yeah, yeah, yeah. [[00:05:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=330.0s)]
*  But he co-advised you as an undergraduate, so I bet we crossed paths a few times. Do you think? [[00:05:32](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=332.0s)]
*  Yeah, that's possible. I went to some of the graduate student journal clubs and stuff there [[00:05:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=337.0s)]
*  when I was making my transition to computational neuroscience. And yeah, I was in that building all the time. [[00:05:43](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=343.0s)]
*  We must have been in that same room together at some point, I bet. Oh, well. Interesting. [[00:05:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=349.0s)]
*  So I like Pittsburgh, but there are a few things that I don't really miss. Although you're in London [[00:05:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=355.0s)]
*  now, so maybe you went to a similar kind of place. Do you miss the amorphous gray blanket, [[00:06:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=360.0s)]
*  otherwise known as the sky in Pittsburgh? [[00:06:07](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=367.0s)]
*  I really like clouds. I don't like I find the sun like intrusive. So I'm happy in London when there's clouds. [[00:06:10](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=370.0s)]
*  I was happy in Pittsburgh when there was clouds. No problem. Well, good for you. I don't miss that. [[00:06:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=379.0s)]
*  But it also helped having to be in the basement of the Mellon Institute. I didn't miss the windows or anything like that. [[00:06:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=385.0s)]
*  Oh, yeah, that's true. And the frequently flooded basement of the Mellon Institute. [[00:06:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=391.0s)]
*  So all right. Tell me a little bit about your forthcoming book, Models of the Mind. [[00:06:36](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=396.0s)]
*  Yeah, this is I'm still shocked that it's happening. [[00:06:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=402.0s)]
*  But yeah, so the idea is that from my perspective, it's kind of a way of introducing computational neuroscience to a general audience. [[00:06:48](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=408.0s)]
*  It's meant for, you know, the layperson, general public kind of popular science book. [[00:06:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=415.0s)]
*  And each chapter is going to be basically an area of neuroscience and the math that's been used to describe it. [[00:07:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=420.0s)]
*  So the chapter that I've written already is on memory and attractor networks like the Hopfield Network. [[00:07:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=428.0s)]
*  So these are concepts that are known to a lot of computational neuroscientists, but aren't known to the general public. [[00:07:14](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=434.0s)]
*  And even this kind of way of thinking about the brain, I don't think is well represented in popular science about neuroscience or about the brain. [[00:07:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=439.0s)]
*  So, yeah, it's just supposed to bring it to everybody. [[00:07:27](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=447.0s)]
*  And there's no well, at least there won't be equations in the main text of the book. [[00:07:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=451.0s)]
*  It's all about explaining the concepts behind the equations without requiring people to have the mathematical knowledge. [[00:07:36](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=456.0s)]
*  Probably lots of pretty pictures as well. Yeah, hopefully. Yeah. [[00:07:41](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=461.0s)]
*  Well, that's good. So you've got one one chapter down. How many chapters is it going to have? Do you know? [[00:07:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=465.0s)]
*  Yeah, I've had it planned for 13 chapters. [[00:07:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=469.0s)]
*  One is kind of an introduction to why we would even try to use math to understand the brain, because that's not an obvious thing to most people. [[00:07:52](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=472.0s)]
*  Right. Yeah. [[00:08:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=480.0s)]
*  And then the other 12 are on these pairings of neuroscience and the mathematics used to describe it and to study it. [[00:08:01](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=481.0s)]
*  Well, congratulations. I hope to talk to you another time to see how the rest of the writing goes, because I hear writing books can be challenging and daunting, [[00:08:07](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=487.0s)]
*  much like writing a dissertation, I suppose, but even more so perhaps. [[00:08:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=496.0s)]
*  Yeah, it's a big undertaking. And I've given myself less time than I had for the full PhD. [[00:08:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=500.0s)]
*  So, man, good luck. Well, I mean, that's not all you do. [[00:08:27](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=507.0s)]
*  That's your book. But you also co-host the Unsupervised Thinking podcast, which is an excellent educational podcast about artificial intelligence and neuroscience and other science topics. [[00:08:32](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=512.0s)]
*  So here on this show, it's still pretty new and I'm still learning how deep and how technical I should be going on topics. [[00:08:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=524.0s)]
*  So people send me an email or a tweet and let me know just how far off I am. [[00:08:52](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=532.0s)]
*  I may be a delicate little flower, but I can take the criticism and I do want it. [[00:08:56](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=536.0s)]
*  So, but so, Grace, can you just give us an overview of the show, like who's on it and how it works and who it might be best suited for? [[00:09:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=540.0s)]
*  Yeah, so we were inspired by this other podcast that I and the two other main members of the podcast, Josh and Connor, who were or when we started, we were all PhD students at Columbia at the Theory Center. [[00:09:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=548.0s)]
*  And so the podcast that that inspired it was called Partially Examined Life, which is a philosophy podcast. [[00:09:21](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=561.0s)]
*  And it happened to be that all three of us had like found that podcast independently and had listened to it and then kind of realized that we all knew what it was. [[00:09:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=568.0s)]
*  And the style of that podcast and the style of our podcast is that there's kind of a general topic, but there's specific readings that everyone who's on the podcast has read. [[00:09:35](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=575.0s)]
*  And then we talk about it. So it's like a journal club style. [[00:09:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=585.0s)]
*  The idea was to have an informal discussion amongst people who know each other about these topics. [[00:09:47](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=587.0s)]
*  But in a way that if you didn't read the papers or didn't know about the topics beforehand, you could still follow along. [[00:09:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=595.0s)]
*  So it's this balance of explicitly describing the topic, but also just having a casual conversation about it. [[00:10:01](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=601.0s)]
*  And we set out at the beginning to have it be barely general audience because there's a lot of people who listen to this philosophy podcast. [[00:10:06](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=606.0s)]
*  We thought maybe there'd be a lot of different types of people who listen to something on neuroscience. [[00:10:15](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=615.0s)]
*  I think empirically it is a lot of neuroscientists who listen to it. [[00:10:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=619.0s)]
*  But like undergrads in neuroscience, so it's people who are just getting into it or people who are in other science fields that want to know a little bit more. [[00:10:24](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=624.0s)]
*  I think we appeal to that crowd. [[00:10:33](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=633.0s)]
*  Well, it's well done. It sounds like you guys get along well on the show. [[00:10:35](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=635.0s)]
*  I'm my own boss here, so I get to make all the decisions for better or worse. [[00:10:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=640.0s)]
*  But is there ever any disagreement about what to discuss or how to go about it? [[00:10:43](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=643.0s)]
*  Or maybe you can. Can you tell us a time about when you guys got into a massive altercation behind the scenes or something? [[00:10:47](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=647.0s)]
*  There isn't so much about that. [[00:10:53](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=653.0s)]
*  Probably the biggest problem we have is scheduling and making sure that everyone's like read the paper by the time the podcast recording starts and remembers to show up for the podcast. [[00:10:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=657.0s)]
*  You mean it's like it's like a regular journal club in graduate school, like no one reads the paper. [[00:11:06](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=666.0s)]
*  Yeah, exactly. Yeah. [[00:11:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=671.0s)]
*  And it's you know, it's been a lot of force to make it not fall apart. [[00:11:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=672.0s)]
*  I basically I usually pick the topics and I find the papers and I realize that just making it low effort for anyone else who's involved because sometimes we have guests on as well as is the best way to go. [[00:11:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=676.0s)]
*  And then there aren't many problems. [[00:11:29](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=689.0s)]
*  Oh, you're wise. So your latest episode is great. [[00:11:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=691.0s)]
*  And it's all about what it means to explain something. [[00:11:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=694.0s)]
*  What explanation really is and you leave it with a cliffhanger for part two that you're going to release pretty soon. [[00:11:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=697.0s)]
*  But do you have maybe a favorite episode or episodes that you think people should check out first? [[00:11:43](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=703.0s)]
*  Yeah. So this most recent one is very explicitly about kind of philosophy of science. [[00:11:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=709.0s)]
*  The guest that we have on that one is David Barrick, who does neuroscience and philosophy. [[00:11:54](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=714.0s)]
*  And so I usually do like the episodes where we get a little more philosophical. [[00:12:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=720.0s)]
*  We did a different two parter on the concept of coding in neuroscience and the idea that like neurons encode information and like what does that really mean? [[00:12:04](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=724.0s)]
*  And, you know, everybody just says it and takes it for granted. [[00:12:13](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=733.0s)]
*  But what are we really saying when we talk about that? [[00:12:15](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=735.0s)]
*  So that was a good one. [[00:12:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=738.0s)]
*  There are also just other ones that are a little bit more fun. [[00:12:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=740.0s)]
*  I think our neuroscience of sleep episode in my mind stands out as something that's like a nice listen because it's got a good balance of like biology. [[00:12:23](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=743.0s)]
*  But we also talk about computational elements of what sleep can do. [[00:12:32](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=752.0s)]
*  So, yeah, just some of the episodes are a little lighter and a little more balanced in terms of, you know, heavy computational stuff or anecdotes or that kind of thing. [[00:12:36](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=756.0s)]
*  So there's a spread. I'm terrible at being the judge of this, though, because I participate in the discussions and then I edit the episodes. [[00:12:46](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=766.0s)]
*  And by the end, I can't tell if it even makes any sense. [[00:12:52](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=772.0s)]
*  I hear you. Yeah. [[00:12:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=775.0s)]
*  Well, keep up the good work. [[00:12:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=777.0s)]
*  And do you think that writing the book is going to affect your your rate of releasing? [[00:12:59](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=779.0s)]
*  Well, in my mind, in like the ideal setting I've created, I'm just going to anything that I want to read for the book. [[00:13:06](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=786.0s)]
*  I'll make a podcast episode about it. [[00:13:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=792.0s)]
*  So it'll just be a great excuse to to find readings for the podcast based on what I need for the book. [[00:13:14](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=794.0s)]
*  So hopefully it'll keep up. [[00:13:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=800.0s)]
*  I think the we do one episode a month and they're about an hour long so that I was modest in the expectations when we started for a reason. [[00:13:22](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=802.0s)]
*  Yeah, scheduling, especially. [[00:13:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=811.0s)]
*  Well, good. OK, so let's go and move on and get into your work with convolutional neural networks and attention. [[00:13:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=814.0s)]
*  So your paper with Kenneth Miller is called How Biological Attention Mechanisms Improve Task Performance in a Large Scale Visual System Model. [[00:13:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=820.0s)]
*  It's in bio archive and I'll link to it in the show notes, of course, and the listeners I think should listen to my interview with Dan Yeamins. [[00:13:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=829.0s)]
*  It's episode eight, I think, or for a more complete and excellent review of using convolutional neural networks as models of the visual system. [[00:13:58](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=838.0s)]
*  I'll also link to a post in your blog, Grace, that covers just that very well and just shows off how well you write as well. [[00:14:07](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=847.0s)]
*  But for now, I'll remind those who have listened to episode eight or are familiar with how convolutional neural nets are are used to model the visual system. [[00:14:15](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=855.0s)]
*  So starting about four years ago and Grace, you should jump in here and correct me and add on anything. [[00:14:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=865.0s)]
*  But starting about four years ago, some work started coming out where convolutional neural networks were used to model the ventral visual stream. [[00:14:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=871.0s)]
*  So the ventral visual stream is a series of hierarchical brain regions that process visual information. [[00:14:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=880.0s)]
*  And as the neural signals pass from one region to the next, the information becomes more and more abstract until the activity can encode, I'll say, for lack of a better term right now, whole objects that a person is seeing, for example. [[00:14:46](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=886.0s)]
*  And when a model of this system is trained and the model is built of hierarchical layers of convolutional neural networks to mimic the layers in the brain, under the right conditions, the model units mimic the properties of the neurons. [[00:15:03](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=903.0s)]
*  And they do so within each layer so that lower layer units encode lower level features like edges, et cetera, that would be encoded in these lower layers in the brain like regions in the brain like V1. [[00:15:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=918.0s)]
*  And higher layer units encode things like whole objects, for example. [[00:15:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=930.0s)]
*  So let's see, what did I miss there? [[00:15:35](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=935.0s)]
*  I don't know that you missed anything. [[00:15:38](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=938.0s)]
*  I guess I would just emphasize that there is some relationship between these models. [[00:15:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=940.0s)]
*  They were inspired by the visual system, but then they kind of went off on their own course via people in computer vision and computer science who were playing with them for their own reasons for just wanting to have artificial vision that works. [[00:15:46](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=946.0s)]
*  So a lot of the progress made on them wasn't by neuroscientists explicitly, even though it's come back around to be a good model of the visual system. [[00:15:59](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=959.0s)]
*  Right. That's a good point. [[00:16:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=968.0s)]
*  Okay, good. So while I was at the University of Pittsburgh, we had a weekly sort of journal club where one of us would present an interesting and relevant research paper and the rest of us would critique the paper as well. [[00:16:10](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=970.0s)]
*  And I remember my friend Patrick Mayo one day after a presentation on some neural correlates of attention. [[00:16:21](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=981.0s)]
*  He asked, do we understand what attention is? [[00:16:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=988.0s)]
*  You know, what is attention? [[00:16:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=991.0s)]
*  So it kind of drew the air out of the room because nobody really knew. [[00:16:33](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=993.0s)]
*  I like the word consciousness, for example. [[00:16:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=997.0s)]
*  Attention can have lots of definitions depending on who you ask. [[00:16:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1000.0s)]
*  Terms like visual attention, the spotlight of attention, selective attention, top down, bottom up and on and on. [[00:16:43](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1003.0s)]
*  So, Grace, what is attention? [[00:16:50](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1010.0s)]
*  Yeah, it is. [[00:16:53](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1013.0s)]
*  It is a problem that it has so many meanings. [[00:16:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1017.0s)]
*  And it's not just a neuroscience that has a lot of meanings in psychology. [[00:17:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1020.0s)]
*  And now it has its own meanings in the machine learning literature that are separate. [[00:17:04](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1024.0s)]
*  I can define what I study. [[00:17:09](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1029.0s)]
*  That'd be great. [[00:17:13](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1033.0s)]
*  I can define that also in opposition to what people could mean by attention. [[00:17:14](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1034.0s)]
*  Perfect. [[00:17:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1038.0s)]
*  So what I study would be called covert feature attention, mostly visual feature attention. [[00:17:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1039.0s)]
*  And so what that means, it's covert because when you attend to something in your visual field, you could just move your eyeballs and look at it. [[00:17:27](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1047.0s)]
*  And that would be overt attention. [[00:17:35](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1055.0s)]
*  And so just be like, there's something happening, like to the right of me and I want to know what's going on. [[00:17:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1057.0s)]
*  So I'm just going to directly look at it. [[00:17:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1062.0s)]
*  And that would be overt spatial attention. [[00:17:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1064.0s)]
*  Alternatively, you could have spatial attention where you keep your eyes looking where they are and you just kind of like try to focus on something you're not looking directly at. [[00:17:46](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1066.0s)]
*  And so that would be covert spatial attention. [[00:17:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1075.0s)]
*  And there's a lot of reasons why you might want to do that. [[00:17:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1077.0s)]
*  One reason is that it might be a way to kind of plan where you look next. [[00:18:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1080.0s)]
*  You kind of covertly scan other areas to look at and then decide which one is going to be most fruitful to actually move your eyes to. [[00:18:04](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1084.0s)]
*  Also, there's reasons to believe that because primates are social animals, you might want to be able to kind of be paying attention to what somebody is doing, but not let them know that. [[00:18:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1092.0s)]
*  So you don't want to look at them like eye movements have meaning to other primates around you. [[00:18:21](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1101.0s)]
*  So there's reasons why we might want to covertly attend to things. [[00:18:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1105.0s)]
*  Now, that's the spatial side. [[00:18:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1108.0s)]
*  The feature side is that it's not about a location, but about a certain visual feature. [[00:18:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1111.0s)]
*  So the example I give a lot of times to explain this kind of attention is if you are looking for your cell phone on a messy desk, which is a relatable thing for a lot of scientists, and you might know that it has a blue case. [[00:18:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1117.0s)]
*  And so basically, you're going to be kind of trying to enhance anything that's blue or rectangular and just kind of try to make that pop out when you're looking on this messy desk, whereas maybe another time you're looking for your keys or something. [[00:18:52](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1132.0s)]
*  So you're going to make something silver and small pop out. [[00:19:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1145.0s)]
*  So that's feature attention. [[00:19:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1148.0s)]
*  It's not trying to attend to a spatial location in your visual field. [[00:19:10](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1150.0s)]
*  It's trying to attend to or make more salient the features of something that's in the visual field. [[00:19:13](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1153.0s)]
*  And all of these kinds of attention are this top-down kind where you have in mind what you want to look at or be looking for. [[00:19:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1160.0s)]
*  The other type of visual attention would be something like bottom-up or saliency in the sense that like, you know, a big flash of light happened and you can't help but have your attention drawn to it. [[00:19:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1170.0s)]
*  I thought you were going to go for the tiger analogy there. [[00:19:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1180.0s)]
*  Sure. Yeah. [[00:19:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1182.0s)]
*  Or there's a tiger. [[00:19:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1184.0s)]
*  Right. [[00:19:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1185.0s)]
*  Yeah. [[00:19:46](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1186.0s)]
*  That's a lot of the categories of attention in the visual system. [[00:19:47](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1187.0s)]
*  There's a whole other definitions of attention that are more about arousal and just kind of if you're awake and alert and that kind of thing. [[00:19:50](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1190.0s)]
*  But yeah, that's again a whole different set of definitions. [[00:19:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1197.0s)]
*  Right. [[00:20:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1200.0s)]
*  Yeah. Well, yeah. [[00:20:01](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1201.0s)]
*  So there's lots of different types. [[00:20:02](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1202.0s)]
*  So thanks for the explanation. [[00:20:03](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1203.0s)]
*  And there are also lots of competing models of how attention works. [[00:20:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1205.0s)]
*  And the one that you focus on in test is called the feature similarity gain model of attention. [[00:20:10](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1210.0s)]
*  So what is the feature similarity gain model of attention? [[00:20:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1216.0s)]
*  Yeah. [[00:20:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1219.0s)]
*  So to explain this, you just have to start with kind of the basic idea that neurons have preferred things that they represent. [[00:20:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1220.0s)]
*  And by preferred, we just mean there are stimuli that make the neurons fire a lot and then they don't fire that much to other stimuli. [[00:20:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1228.0s)]
*  And the ones that make them fire a lot are their preferred stimuli. [[00:20:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1234.0s)]
*  So in the visual system, you'll have neurons that prefer, say, the color blue. [[00:20:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1237.0s)]
*  And then when you're trying to look for your cell phone or attend to those features, those neurons that share the features of the thing that you're looking for will have their firing rate enhanced. [[00:20:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1242.0s)]
*  If they prefer blue, their firing rate will go up. [[00:20:54](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1254.0s)]
*  And then if they don't prefer blue, their firing rate will go down. [[00:20:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1257.0s)]
*  And so that's the basic premise is that neurons that are tuned to the thing that you're looking for, that the visual features that you're attending to, their firing rates will go up. [[00:21:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1260.0s)]
*  And ones that don't like them will go down. [[00:21:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1272.0s)]
*  And then within that, this is a multiplicative process. [[00:21:14](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1274.0s)]
*  That's why it's the gain model, feature similarity gain model, which just means that it'll go up in proportion to its firing rate already. [[00:21:17](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1277.0s)]
*  So it just means that the firing rate is scaled multiplicatively. [[00:21:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1285.0s)]
*  And one of the things that you examine in the paper or that your paper deals with is some of the debate about attention within the visual stream. [[00:21:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1288.0s)]
*  So what's that about? [[00:21:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1297.0s)]
*  Well, there is just a lot of questions reasonably because, you know, a lot of these studies that are done in non-human primates or in humans are, you could say they're kind of correlation studies. [[00:21:39](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1299.0s)]
*  You have someone attend to a visual feature and you record from the neural activity. [[00:21:52](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1312.0s)]
*  And so when you do that, you can get a lot of different changes that happen in the visual system and outside of the visual system and then different types of changes within the visual system. [[00:21:56](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1316.0s)]
*  So I focus on these firing rate changes, but there are also changes in how correlated the activity between neurons is. [[00:22:06](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1326.0s)]
*  And so that's a whole other aspect of attention that people study. [[00:22:14](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1334.0s)]
*  And so there's just a question because most of these studies are these correlation based. [[00:22:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1338.0s)]
*  There's a question of what is actually leading to attention making you better at a task. [[00:22:23](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1343.0s)]
*  So basically, when you look for your cell phone, you'll find it more often than when you're not looking for it is kind of the idea. [[00:22:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1348.0s)]
*  And it's known via behavioral experiments that, yes, if you cue people to attend to a certain category, they will be able to spot what they're looking for in a noisy stimulus better than if they're not cued to do that. [[00:22:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1354.0s)]
*  And so just making that connection between the observed neural changes and the performance changes, it's not enough to just say that they both happen at the same time. [[00:22:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1365.0s)]
*  You actually want to be able to probe a causal relationship. [[00:22:54](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1374.0s)]
*  So what changes are actually important to making that performance go up? [[00:22:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1377.0s)]
*  OK, so you have the large scale hierarchical network of convolutional neural networks to model the ventral visual stream like we discussed. [[00:23:02](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1382.0s)]
*  Now, before we talk about adding attention to it and how you did that and what happened, maybe you can just broadly overview the model itself or talk a little bit about what we might need to know about the model before we talk about the attention. [[00:23:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1391.0s)]
*  Sure. For this study, I just used what's kind of a standard convolutional neural network. [[00:23:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1405.0s)]
*  It's called VGG-16. That's just the architecture. So it just kind of defines the layers in it. [[00:23:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1410.0s)]
*  So in total, it has 13 convolutional layers and then it has other layers thrown in and a few layers at the end that lead to the classifier. [[00:23:36](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1416.0s)]
*  So it's trained on the ImageNet task, which means it's trained to do object classification of a thousand different categories. [[00:23:46](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1426.0s)]
*  And yeah, it's used a lot in neuroscience and in machine learning. I didn't even train it myself. [[00:23:53](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1433.0s)]
*  You can just download the weights for these networks and have it at hand. [[00:23:59](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1439.0s)]
*  Right. So this is pretty similar. If I remember Dan Yehmans, and I don't mean to only focus on his work, but I believe his current stuff has 13 layers as well. [[00:24:03](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1443.0s)]
*  I don't know that that matters so much. [[00:24:14](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1454.0s)]
*  Yeah, a lot of, I mean, it depends on what you're interested in. [[00:24:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1456.0s)]
*  There's a lot of work out there that's trying to figure out what architectures best predict neural activity. [[00:24:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1459.0s)]
*  So obviously, Dan Yehmans is interested in that. And for a while, it just seemed like kind of deeper networks got better. [[00:24:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1465.0s)]
*  But then maybe if you can go too deep and it stops being a good model of the brain and so on. [[00:24:32](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1472.0s)]
*  For what I'm doing, I also tested the same attention procedure on a smaller network that is like people who are familiar with know AlexNet. [[00:24:36](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1476.0s)]
*  It just has five convolutional layers. So it's a smaller network, but the same principles held in that. [[00:24:47](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1487.0s)]
*  So for my work, it's not super relevant how many layers there are, at least. [[00:24:52](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1492.0s)]
*  So how did you add attention into the network, a la the feature similarity gain model? [[00:24:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1497.0s)]
*  Yeah, right. So my hope was to just kind of transfer the feature similarity gain model to this network as directly as possible. [[00:25:03](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1503.0s)]
*  And as I said, the feature similarity gain model says that the tuning of a neuron determines how it's modulated by attention. [[00:25:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1511.0s)]
*  And so I had to start by getting the tuning of the fake neurons in the network, basically. [[00:25:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1519.0s)]
*  And so I did that the same way people do in electrophysiology experiments with monkeys and things. [[00:25:24](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1524.0s)]
*  You just show images to the network and you record from the fake neurons in the network. [[00:25:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1530.0s)]
*  And you do that for a bunch of image categories. [[00:25:36](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1536.0s)]
*  I use 20 different object categories just because I didn't want to have to do all 1000. [[00:25:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1540.0s)]
*  And you get a tuning curve and then you use that information to determine how the fake neurons activity should be modulated when you want to have the network attend to a certain object category. [[00:25:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1545.0s)]
*  So if you have a fake neuron that fires a lot for dogs, then when I tell the network to attend to dogs, [[00:25:59](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1559.0s)]
*  what that means is that I'm just going in there and kind of by hand turning up kind of the volume of that neuron. [[00:26:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1565.0s)]
*  You're the dog neuron. OK, I'm going to turn you up when I want to attend to dogs and I'll turn other ones down. [[00:26:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1571.0s)]
*  And so basically, yeah, you just determine who gets turned up and down based on if they fire above their average firing rate for the category or if they fire below the average firing rate for that category. [[00:26:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1576.0s)]
*  That's how I define it. And what happened? [[00:26:27](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1587.0s)]
*  How did attention affect performance? Yeah. [[00:26:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1590.0s)]
*  So I basically a theme in the attention literature is that you have to make tasks challenging for attention to be engaged and for the effects of attention to be seen, [[00:26:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1594.0s)]
*  because obviously the effects are that you get an increase in performance. [[00:26:46](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1606.0s)]
*  And so if you're using a really easy task, you won't even be able to see if attention is doing anything. [[00:26:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1609.0s)]
*  So to start, I had to create challenging tasks for these networks. [[00:26:54](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1614.0s)]
*  And I did that by creating images that are actually combinations of individual images from this ImageNet data set. [[00:26:58](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1618.0s)]
*  So one variant of that is you take two images. [[00:27:06](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1626.0s)]
*  So like an image of someone holding an umbrella, if it's from the umbrella category and a plate of bagels, if it's from the bagel category, and you just kind of transparently overlay them. [[00:27:09](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1629.0s)]
*  So to look at this, you would see this like weird mix of umbrella picture with bagel picture. [[00:27:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1639.0s)]
*  I can tell you're really familiar with all these pictures, by the way. [[00:27:24](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1644.0s)]
*  Yeah, ImageNet is a weird data set and I've gotten to know it. [[00:27:27](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1647.0s)]
*  It also has a lot of individual dog breeds, which I'm terrible at knowing the difference between. [[00:27:32](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1652.0s)]
*  So one time I was trying to check if my labels were right and I opened a few files to be like, oh, well, I'll know like if this is a picture of a teapot. [[00:27:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1657.0s)]
*  And they were like dog breeds. I'm like, I don't know if this label is right. [[00:27:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1665.0s)]
*  Yeah, so yeah. [[00:27:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1669.0s)]
*  So yeah, there's the one way of combining the images is this transparent overlay. [[00:27:51](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1671.0s)]
*  And then the other way is to just kind of shrink them down and put four images into one image. [[00:27:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1675.0s)]
*  So it's like a two by two grid of images. [[00:28:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1680.0s)]
*  And so this is just ways of making the task more challenging. [[00:28:03](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1683.0s)]
*  And then the task of the network is to say if a given object is present, but in these crowded kind of images, it's a little bit harder for the network to do that. [[00:28:06](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1686.0s)]
*  So starting from that baseline, when we have impaired performance from the network, I then do this attention modulation and say, OK, here's this weird bagel umbrella image. [[00:28:14](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1694.0s)]
*  Is there a bagel in here? And I turn bagel neurons up and other neurons down. [[00:28:23](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1703.0s)]
*  And what you see is that the network does get better at identifying the category in the images that have that category. [[00:28:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1708.0s)]
*  So the performance goes up overall. [[00:28:36](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1716.0s)]
*  But importantly, to be fair, you have to also compare performance when the object you're attending to isn't in the image, because you don't want the effect of this attention to just be that the network says everything is a bagel, because that's not a good strategy. [[00:28:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1720.0s)]
*  And that's not what we want attention to do. [[00:28:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1735.0s)]
*  So it is the case that the number of times that the network says that a bagel is there when it is, it goes up, but it goes up much less than the number of times it says it's there when it really is. [[00:28:58](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1738.0s)]
*  So overall, you have an increase in performance with a little bit of an increase in what's what's called a false positive error. [[00:29:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1752.0s)]
*  So overall, the performance goes up. [[00:29:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1760.0s)]
*  So you used you made it difficult in those two different ways that you described. [[00:29:23](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1763.0s)]
*  So the overlapping images or images in the four quadrants that allowed you, if I'm remembering correctly, to also to test for spatial attention and feature attention because of the images were spatially located in the four quadrant image. [[00:29:27](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1767.0s)]
*  Do I have that right? [[00:29:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1782.0s)]
*  Yeah, I have tested for spatial attention. [[00:29:43](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1783.0s)]
*  And so within the context of the feature similarity gain model, the spatial location of something is just considered another feature. [[00:29:46](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1786.0s)]
*  So you can apply spatial attention in the same way that you would apply attention to a color. [[00:29:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1795.0s)]
*  It just means that you look at the neurons preferred location and you scale its activity up if you're attending to that location and down otherwise. [[00:30:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1800.0s)]
*  And so that's how I implemented it in this network. [[00:30:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1808.0s)]
*  And so in that circumstance, you would attend to a spatial location and then you could just read out what object exists at that spatial location. [[00:30:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1811.0s)]
*  It's a little bit different than the detection task, but it's aligned with what's usually done in spatial attention tasks. [[00:30:22](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1822.0s)]
*  So another thing that that you tested was where in the network when you added attention, so you added you could add attention to the whole network. [[00:30:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1830.0s)]
*  You could add attention to various layers to the network or combinations. [[00:30:39](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1839.0s)]
*  What did you find adding attention to what helped the model perform the best? [[00:30:43](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1843.0s)]
*  Yeah, so I applied attention at each layer individually as well as all layers simultaneously. [[00:30:51](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1851.0s)]
*  And what you see is just kind of a nice curve where if you apply attention to each layer individually, performance gets better and better the later in the network you go. [[00:30:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1857.0s)]
*  So farther from the input. If you apply attention at early layers, it can't help performance that much. [[00:31:07](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1867.0s)]
*  But if you apply attention at later layers, that's where kind of the peak increase in performance can come from. [[00:31:13](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1873.0s)]
*  And this is roughly in line with what we see, which is that in the visual system, the effects of attention neural activity are much stronger later in the ventral stream. [[00:31:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1879.0s)]
*  So in areas like V4 or IT, whereas areas like V1, you can kind of get attention effects in certain experiments, but they're usually much weaker and they usually occur much later in the visual response. [[00:31:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1891.0s)]
*  So the fact that attention works better at later areas is at least consistent with the fact that we see stronger modulation of attention in later areas of the ventral stream. [[00:31:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1904.0s)]
*  And it could possibly mean that the attentional effects in the earlier layers in the cortex are, I don't want to get too in deep here, but maybe aren't as causal for the attentional effects of action and behavior. [[00:31:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1915.0s)]
*  Do I have that right? [[00:32:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1931.0s)]
*  That the earlier layers might be less involved in the benefits of attention? [[00:32:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1932.0s)]
*  Yeah, I mean, again, everything is so specific. It probably depends a lot on the exact task that you're doing. [[00:32:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1938.0s)]
*  The thing that I'm trying to model in my work is something that would be akin to if an image was shown really quickly. [[00:32:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1945.0s)]
*  So you can show people images for 50 milliseconds and they can tell you if something was present in the image or not. [[00:32:33](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1953.0s)]
*  And so that's kind of meant to be analogous to the CNN that I'm using because it's just a feedforward convolutional neural network. [[00:32:41](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1961.0s)]
*  So it's kind of represents like a single pass of the visual system. [[00:32:52](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1972.0s)]
*  When you get into more natural vision, the fact that things are continuous and you can look at things for a while and you can allow more processing to happen, then it's less clear because you do get these effects in V1 later on. [[00:32:56](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1976.0s)]
*  V1 might be very important for what's happening later on, but that's not what's being tested in the experimental setups where you're flashing an image really quickly. [[00:33:09](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1989.0s)]
*  So yeah, for what I'm doing, it seems likely that effects that later layers are more important. [[00:33:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=1998.0s)]
*  But there's a lot of other things you could test or ask about the visual response and attention. [[00:33:23](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2003.0s)]
*  Let's see. So there's plenty of other stuff that we could talk about in the paper. [[00:33:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2008.0s)]
*  Maybe I'll let you suggest any of the other tests that you did or any of the things that you think are worth discussing. [[00:33:32](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2012.0s)]
*  Well, first, I want to point out that the performance changes, the fact that both the true positives and the false positives increase, but true positives increase more. [[00:33:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2020.0s)]
*  And so it's overall beneficial. That is seen in human behavioral data as well. [[00:33:50](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2030.0s)]
*  So that was kind of a nice validation because that didn't have to be true. [[00:33:55](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2035.0s)]
*  Attention could have made all errors go down rather than giving you this slight penalty of false positives. [[00:33:58](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2038.0s)]
*  So that was something that was nice to see in the model. [[00:34:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2045.0s)]
*  Yeah. And your results. I mean, the overall take home is that your results really do support the feature similarity gain model of attention as being very possible being implemented in the brain. [[00:34:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2048.0s)]
*  Yeah, I guess the caveat to that is one of the things that we look at in the paper is that we see if we can calculate a better way to apply attention. [[00:34:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2060.0s)]
*  And that's the benefit of using these models is that you can do whatever you want with them and you can even calculate how should the neural activity change to make the network better at detecting objects in these images. [[00:34:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2070.0s)]
*  And when we did that, we saw patterns of neural activity change that aren't exactly aligned with the feature similarity gain model in that they don't always say that you should increase the firing rate of the neuron that prefers the category the most. [[00:34:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2084.0s)]
*  It's not yet clear exactly what these calculations are saying, but it is the case that when we apply attention according to the way that these calculations suggest that attention does increase performance even better than when you apply it according to to tuning. [[00:34:58](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2098.0s)]
*  So that's a complication for this model, which assumes that attention modulates neural activity based on the neurons preferred stimulus according to its tuning. [[00:35:14](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2114.0s)]
*  Right. So, so what's next? Are you going to do more work along these lines? Are you going to go down that road? Are you moving on to other things? [[00:35:24](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2124.0s)]
*  I am definitely planning to stay in the realm of using these convolutional networks as models of the visual system for a while. I think that there's a lot more that we can get out of them, especially in terms of trying to understand how they work rather than just kind of using them as a stand in. [[00:35:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2131.0s)]
*  Yeah, and people should go read your blog post because you make a great argument about how these are very useful as models of the brain and how much more work we really can do with them. So I'll really encourage people to go read your blog post on that. [[00:35:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2149.0s)]
*  Yeah, to me, it's like an ideal setting because, you know, I don't really want to have to be in the lab all day. So if I can do experiments on this stand in system and try to understand it, and then someday that will lead to understanding the real visual system. [[00:36:04](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2164.0s)]
*  I think I think that's great. So I definitely want to keep doing that. A big question when studying attention, this top down attention where it's kind of you think about what you want to pay attention to and your visual system changes in response to that is just how does that actually happen? [[00:36:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2178.0s)]
*  Yeah, how is my thinking about my cell phone actually changing the neurons in my possibly primary visual cortex, secondary visual cortex? How does the brain know what neurons to target for that? So that's a big open question that I'm pretty interested in. [[00:36:33](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2193.0s)]
*  That's a good segue. I have a bunch of, you know, general kind of speculative questions if you're game for it. [[00:36:51](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2211.0s)]
*  Sure. [[00:36:58](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2218.0s)]
*  What you just said leads nicely to this first one is what's one idea that you can't do or don't have time to do, for example, that you wish someone else might pursue? [[00:36:59](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2219.0s)]
*  Yeah, well, I'm hoping to look into the feedback connections myself. So no one else do that. [[00:37:09](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2229.0s)]
*  Okay, that's serious. That's serious. [[00:37:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2236.0s)]
*  So one thing that I've been wanting to do for a long time that's very related to this is to just try the same attention and modeling, but for the auditory system. [[00:37:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2238.0s)]
*  Yeah. [[00:37:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2250.0s)]
*  Because there is work from people at MIT, especially that compares convolutional neural networks that were trained on auditory data to the neural activity of auditory system. [[00:37:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2251.0s)]
*  And you can also do this mapping between layers and areas between the model and the brain there. [[00:37:43](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2263.0s)]
*  And audition is a topic that has cared about and thought about feature attention for a long time because there's this kind of famous issue, the cocktail party problem. [[00:37:48](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2268.0s)]
*  The idea being that if you're in a crowded cocktail party and there's people chattering all around you, how are you able to really hear the person that you're trying to talk to? [[00:38:01](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2281.0s)]
*  There could be someone kind of equally close to you who's part of a different conversation that you need to ignore. [[00:38:10](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2290.0s)]
*  And so that's kind of exactly what feature attention is. [[00:38:15](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2295.0s)]
*  It's saying I want to pay attention to the voice that has these qualities to it because that's the person that I'm talking to and I want to ignore other voices. [[00:38:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2298.0s)]
*  And so I feel like this kind of attention could kind of do the cocktail party problem in a model that's meant to represent the auditory system as well. [[00:38:26](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2306.0s)]
*  I think to the I mean, everyone I talk to and of course, on my background is visual decision making in neuroscience. [[00:38:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2317.0s)]
*  So, you know, the visual system is the one most understood and most studied. [[00:38:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2324.0s)]
*  And there's still a lot of room in auditory neuroscience. [[00:38:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2329.0s)]
*  We had when I was working at Vanderbilt as a postdoc, one of the researchers there came in and did his auditory lab and neurophysiology lab. [[00:38:53](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2333.0s)]
*  And he was doing like these really basic experiments that had not been performed in in auditory land. [[00:39:02](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2342.0s)]
*  They had been performed years ago in the visual neurosciences. [[00:39:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2348.0s)]
*  So it's still there's a lot of room there, I think. [[00:39:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2352.0s)]
*  Yeah, yeah, yeah, for sure. And it is I think there is this like an assumption. [[00:39:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2356.0s)]
*  Well, like if we found it in visual in the visual system, it's probably the same in the auditory system. [[00:39:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2359.0s)]
*  Well, yeah, yeah. That's kind of what this CNN finding is. [[00:39:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2365.0s)]
*  It's like, well, they worked for vision. Let's try them on the auditory system. [[00:39:29](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2369.0s)]
*  Well, how about olfactory? Let's try olfactory. [[00:39:33](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2373.0s)]
*  Oh, God, I don't know what's going on there. I can't do that. [[00:39:35](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2375.0s)]
*  Good. OK, that's good. So you guys hear that? Get on it. [[00:39:38](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2378.0s)]
*  But yeah. So how about this? [[00:39:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2382.0s)]
*  Do you think that the big breakthrough for understanding our brains and our minds will come from neuroscience or come from A.I.? [[00:39:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2385.0s)]
*  Things like working with these convolutional neural networks, the collaboration between them or somewhere else? [[00:39:53](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2393.0s)]
*  Yeah, I mean, I think if the question is how will we understand the brain, it's going to have to involve neuroscience a lot. [[00:39:58](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2398.0s)]
*  You can understand intelligence maybe by studying A.I. [[00:40:06](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2406.0s)]
*  I don't even know what it means to understand intelligence, but I assume that you could do it by making artificial intelligence. [[00:40:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2412.0s)]
*  What I'm kind of getting at is we're pushing forward and making tons and tons of progress understanding the brains. [[00:40:18](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2418.0s)]
*  But it feels I have this sense and I've heard other people articulate the sense that that really the big breakthrough has not come yet and that there's there's going to be some turning point where some kind of moment in the field that we feel like we really have a better grasp on how the brain works. [[00:40:26](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2426.0s)]
*  And so that's what I'm kind of asking about. [[00:40:45](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2445.0s)]
*  Yeah, I mean, I think the new marriage between A.I. and neuroscience, what's happening now with deep learning, I think it's great. [[00:40:48](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2448.0s)]
*  I know there are other people who are skeptical and like, oh, it's overblown and it's overhyped. [[00:40:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2457.0s)]
*  But, you know, let it be overhyped for a little bit. [[00:41:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2460.0s)]
*  It'll still leave important and useful residue after the hype is gone. [[00:41:02](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2462.0s)]
*  I think that that has been a profound change. [[00:41:07](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2467.0s)]
*  I don't know that that means that like, oh, now now we've got it. [[00:41:09](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2469.0s)]
*  But yeah, I appreciate the hype, too, because it means that people are going to be pressing forward on it and making progress. [[00:41:13](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2473.0s)]
*  So, yeah, exactly. [[00:41:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2479.0s)]
*  So, yeah, I think that the introduction of these models is really good. [[00:41:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2480.0s)]
*  I also think that just it's a different style of thinking that's being introduced. [[00:41:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2485.0s)]
*  So the fact that in my work, applying attention according to tuning, is it necessarily the best way? [[00:41:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2490.0s)]
*  I mean, neuroscience has been obsessed with tuning curves for a long time, especially visual neuroscience. [[00:41:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2497.0s)]
*  It's like you show a stimulus, you record a neuron, and that's how you define the function of that neuron is how it responds to that stimulus. [[00:41:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2502.0s)]
*  But obviously, the function of a neuron is dependent on where it sends its projections to and how those neurons respond to it. [[00:41:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2509.0s)]
*  And so just saying how it responds to an input doesn't tell you how that turns into an output. [[00:41:56](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2516.0s)]
*  And in reality, it's incredibly complicated. [[00:42:02](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2522.0s)]
*  You can't assume that because it responds a certain way, especially at some low area like V1, that you could predict how that will impact behavior. [[00:42:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2525.0s)]
*  There's just so many layers of processing between that response and the output. [[00:42:13](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2533.0s)]
*  And to me, these networks are like really good at showing that, like I can perturb this neuron down here and you will not be able to predict what will happen because this is a crazy nonlinear system. [[00:42:17](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2537.0s)]
*  So just having that as proof of like, no, we really need to be thinking harder about these things in neuroscience. [[00:42:26](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2546.0s)]
*  Yeah. Okay. So what's something that you believe will come out of the interface of neuroscience and AI that might be a little less conventional, a little out there? [[00:42:33](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2553.0s)]
*  Yeah, I think the mindset change is a big one. [[00:42:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2564.0s)]
*  I mean, there's also it's funny to me because neuroscientists use machine learning the same way other fields use machine learning, and that is to do data processing. [[00:42:50](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2570.0s)]
*  So people use convolutional neural networks to analyze images from microscopy to like find cells. [[00:43:00](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2580.0s)]
*  And that's just funny to me. It's like this is a model of the visual system that I'm using as a model of the visual system that someone else is just using to automate the thing that they used to have to do by hand. [[00:43:07](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2587.0s)]
*  Sure. [[00:43:15](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2595.0s)]
*  But yeah, I think other things that could come out of the relationship, I mean, maybe neuroscience influencing the direction of artificial intelligence. [[00:43:17](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2597.0s)]
*  I think I'm labeling that as out there because I don't actually think that that will be the case. [[00:43:29](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2609.0s)]
*  The probability is low enough that you call it out there. [[00:43:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2614.0s)]
*  Yeah, exactly. Just because there's other motivations in AI and it's not obvious that mimicking the brain and in all its detail is the right way to go for what they're trying to do. [[00:43:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2617.0s)]
*  Well, do you? But do you? Sorry, go ahead. [[00:43:48](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2628.0s)]
*  The other topic that I was just going to throw in there is that I think there will be some weird stuff that happens around like personhood and consciousness and how we think about those things. [[00:43:51](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2631.0s)]
*  If we do end up with AI that's very human-like, it's going to make people confront stuff. [[00:44:01](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2641.0s)]
*  I think that's already happening a little bit, just the thought of it. [[00:44:09](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2649.0s)]
*  I mean, that's happened in science fiction for decades or centuries. [[00:44:12](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2652.0s)]
*  But that might be something that comes out of that. [[00:44:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2656.0s)]
*  That's something I actually worry about a little bit is having to... [[00:44:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2659.0s)]
*  I was just watching a talk by Noval Hariri, I think is his name. [[00:44:23](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2663.0s)]
*  He wrote Homo Sapiens, Homo Deus, and then recently 21 Questions for the 21st Century, I think. [[00:44:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2668.0s)]
*  Anyway, I really enjoyed the interview. [[00:44:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2674.0s)]
*  But he talks about these stories that we've told ourselves through the centuries and religion now is we can kind of say that was a story that doesn't hold up as well anymore. [[00:44:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2677.0s)]
*  It kind of made me worry. [[00:44:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2689.0s)]
*  Once we do have general AI or things of that nature that really replicate what we do in a very general sense, what will I be faced with in my own internal... [[00:44:52](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2692.0s)]
*  The story that I tell myself about who I am. [[00:45:03](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2703.0s)]
*  Because the threads of religion, I'm sure, have not left me because I was raised in a Methodist house. [[00:45:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2705.0s)]
*  Sure. [[00:45:15](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2715.0s)]
*  But then I wonder, I know I'm holding on to things and I don't know what I'm holding on to. [[00:45:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2716.0s)]
*  And it's a little scary to think about how I will perceive what humans are and then what that means for my own awareness and sense of self. [[00:45:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2720.0s)]
*  But this isn't about me. [[00:45:29](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2729.0s)]
*  Sorry, I just went on a little thread there. [[00:45:30](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2730.0s)]
*  But do you think that we'll need to incorporate more neuroscientific principles into AI to start to get at more general AI? [[00:45:33](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2733.0s)]
*  It's so hard to say. [[00:45:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2742.0s)]
*  Ultimately, yes, especially if the goal is human behavior, not just being the best at everything because that's not very human. [[00:45:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2744.0s)]
*  So if you're actually trying to mimic a human, you're probably going to do well to look at human brains. [[00:45:51](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2751.0s)]
*  But of course, there will be details that won't be relevant and we won't know in advance what those are. [[00:45:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2757.0s)]
*  So it's complicated. [[00:46:03](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2763.0s)]
*  I totally see why people in AI would not care that much or only want loose inspiration. [[00:46:04](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2764.0s)]
*  Whereas people in neuroscience, you know, probably think that or at least some people in neuroscience might think that the brain is the best way to go. [[00:46:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2771.0s)]
*  Of course, their brain is the best way to go. [[00:46:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2779.0s)]
*  Okay, so take a deep breath. [[00:46:22](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2782.0s)]
*  What's one idea that you've been really wrong about? [[00:46:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2785.0s)]
*  Yeah, I feel like I don't hold things with a lot of confidence. [[00:46:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2794.0s)]
*  So it isn't like jarring to hear otherwise. [[00:46:39](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2799.0s)]
*  One thing I was wrong about is that when I started undergrad, I was like very explicitly not interested in computational neuroscience. [[00:46:44](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2804.0s)]
*  That wasn't wrong in like an objective fact way. [[00:46:52](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2812.0s)]
*  But I was wrong about what computational neuroscience was and wrong about it not being useful. [[00:46:56](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2816.0s)]
*  Well, so that leads me to another question that if you were going to start over, how would you approach the, you know, would you learn neuroscience first or AI first or would you learn them concurrently? [[00:47:02](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2822.0s)]
*  How would you approach the study to get where you are now and beyond? [[00:47:16](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2836.0s)]
*  Yeah, that's something that I thought about a lot towards the end of my undergrad. [[00:47:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2840.0s)]
*  Like, did I do this the right way? [[00:47:26](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2846.0s)]
*  I always kind of thought that if I did it again, I would probably double major in neuroscience and computer science just because when doing computational neuroscience, just the hard skills of being able to code well is really useful. [[00:47:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2848.0s)]
*  It's not necessarily for, you know, because I think that computer science principles are helpful for neuroscience. [[00:47:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2862.0s)]
*  It's more like as a tool and then also like as a backup job, which anyone in academia should have. [[00:47:48](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2868.0s)]
*  So I think I would be more explicit. [[00:47:56](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2876.0s)]
*  And then also, though, it would be great if I could have also majored in physics or something because that's helpful tool set to have as well. [[00:47:58](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2878.0s)]
*  Although I do, I value being someone coming from neuroscience who's in computational neuroscience because there's a lot of people who come from physics or come from other topics. [[00:48:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2885.0s)]
*  And I think that you do think about things very differently. [[00:48:15](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2895.0s)]
*  If you come from physics, you start with like the physics that you know and try to see how it can be mapped to neuroscience, you know, roughly. [[00:48:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2899.0s)]
*  And when you come from neuroscience, you're like, oh, there's this really complicated problem. [[00:48:25](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2905.0s)]
*  Let me see if I can pare it down into something simpler. [[00:48:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2908.0s)]
*  And, oh, it turns out physicists have already studied the simple version. [[00:48:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2911.0s)]
*  That's useful. So I don't know. [[00:48:34](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2914.0s)]
*  It's different. Both perspectives are needed. [[00:48:36](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2916.0s)]
*  But I think it's it's nice to have some first neuroscience than the quantitative approaches. [[00:48:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2920.0s)]
*  OK, good. There's there's so much to know. [[00:48:47](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2927.0s)]
*  It's just hard to know. There's so much that's useful to know. [[00:48:50](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2930.0s)]
*  You just want to I want to know it all right now. [[00:48:54](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2934.0s)]
*  Yeah, I mean, that's why I'm on Twitter, because it's just a feed of things that I should know that I can at least learn a sentence about at a time. [[00:48:57](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2937.0s)]
*  OK, so last question. [[00:49:05](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2945.0s)]
*  What is something that you wish was on your CV that's not yet? [[00:49:08](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2948.0s)]
*  That it's a traumatic question because it just makes me think of all the things that I applied for and didn't get. [[00:49:11](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2951.0s)]
*  Oh, I'm sorry. [[00:49:19](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2959.0s)]
*  I put a pen on my CV. I am I'm not sure. [[00:49:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2960.0s)]
*  I'm struggling with this one. I don't want to I don't want to introduce any trauma. [[00:49:28](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2968.0s)]
*  So but but now you can add to your illustrious CV. [[00:49:31](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2971.0s)]
*  You can add that you've been on the Brain Inspired podcast. [[00:49:35](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2975.0s)]
*  So congratulations. Yes. Yes. Thank you. [[00:49:37](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2977.0s)]
*  So thanks for spending the time with me. [[00:49:40](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2980.0s)]
*  What's the best way for people to learn more about what you do or to follow you? [[00:49:42](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2982.0s)]
*  Yeah, if you're on Twitter, I'm NeuroGrace. [[00:49:46](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2986.0s)]
*  Pretty straightforward. I do have the podcast on supervised thinking. [[00:49:49](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2989.0s)]
*  And you can follow me on Google Scholar if you only care about the strict academic stuff. [[00:49:54](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=2994.0s)]
*  But yeah, Twitter is where I'm mostly at. [[00:50:01](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=3001.0s)]
*  And make sure you send me an email when when your book is going to go live and I will inform my listeners of it. [[00:50:04](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=3004.0s)]
*  So so thanks again for taking the time. Appreciate it, Grace. [[00:50:10](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=3010.0s)]
*  Thank you. [[00:50:13](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=3013.0s)]
*  All right, guys, thanks for listening. [[00:50:17](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=3017.0s)]
*  I hope in episodes moving forward, I can spend a little bit more time with the bigger picture questions like we did in this episode because it's fun. [[00:50:20](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=3020.0s)]
*  All right. Goodbye for now. [[00:50:29](https://www.youtube.com/watch?v=0GtIO3j7jOE&t=3029.0s)]
