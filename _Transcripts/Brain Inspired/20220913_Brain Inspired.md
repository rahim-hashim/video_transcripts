---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 5829s
Video Keywords: []
Video Views: 2288
Video Rating: None
---

# BI 147 Noah Hutton: In Silico
**Brain Inspired:** [September 13, 2022](https://www.youtube.com/watch?v=ajLbNKm2OpA)
*  It was the first time I'd really heard a scientist plant a flag in terms of a timeline on a certain
*  time in the future when a great insight will be gained.
*  This was a crazy idea that we could do a human brain in 10 years, and I continued to run
*  into that criticism.
*  And to this day, I mean, people who have seen this film and reacted to it think that that's
*  a crazy landmark to be thinking of in any kind of time frame of a decade.
*  You want to feel like the work you're doing has an actual impact in your lifetime, in the
*  community of humans you live amongst.
*  And when you're doing such a long-term speculative project that's building a model from the bottom
*  up over so much time, what keeps you in it?
*  What keeps you bound to the work?
*  This is Brain Inspired.
*  That was Noah Hutton, and I am Paul Middlebrooks.
*  Welcome to Brain Inspired.
*  This is a different kind of episode for Brain Inspired, partly because Noah is not officially
*  a scientist or philosopher, but a filmmaker.
*  Starting today, his documentary, InSilico, is available to stream on Vimeo.
*  InSilico is the result of Noah's 10-plus year journey capturing the progress of massively
*  funded projects in neuroscience, the Blue Brain Project and the Human Brain Project,
*  which we discuss in the episode.
*  The reason it took about 10 years is because that's the time frame that Henry Markrum set
*  for himself and a large team of scientists given enough funding to build a full simulation
*  of a human brain in all its gnarly detail and complexity.
*  That aspiration was first articulated in a 2009 TED Talk by Henry, a TED Talk that drew
*  Noah in and sparked what has become InSilico.
*  Noah was generous and allowed myself and Brain Inspired Patreon supporters to screen the film,
*  and he agreed to record this episode live with a bunch of those Patreon supporters to field their
*  questions and mine about his experiences and the science and the people involved in the science.
*  So a different kind of episode on that front as well.
*  Especially if you enjoy Brain Inspired, you'll enjoy InSilico, and you're doing yourself a
*  disservice if you don't watch it.
*  I'm actually recording this before I have the Vimeo link, but I will put that link in the
*  show notes at BrainInspired.co.
*  Or you can just go straight to the film's website, which is InSilicoFilm.com, and you'll find links
*  there.
*  So I said that Noah is not a scientist, but you might not know that by listening to him.
*  As you'll hear, he's always been interested in neuroscience and is quite knowledgeable about it.
*  So enjoy Noah.
*  Noah Hutton, InSilico.
*  Congratulations.
*  First of all, congratulations on the film and a huge thank you for sharing it with my podcast
*  supporters.
*  You were gracious enough to give us a screening, and now we're all, many of us are here anyway to
*  ask you questions and learn more about the film.
*  So thanks.
*  Thank you so much for having me.
*  I'm an avid listener of your show, so I really, it's an honor to be here and I appreciate you
*  all watching the film.
*  So I guess this will come out either the day of or maybe the day after the release of the film, but
*  are you going to have like a premiere or an event?
*  There is an event in New York City on the premiere date, so that's September 13th.
*  And Sandbox Films, the company that financed the film, mostly we also got some funding from the
*  Sloan, Alpha Peace Sloan Foundation.
*  Sandbox Films is going to host this event at the Angelica Theater in New York, so I'm excited for
*  that.
*  I've never seen a film with a real audience.
*  We had a virtual theatrical run, which is, which was a big COVID term, and I had two films come
*  out during COVID.
*  This one also a narrative sci-fi feature called Lapsis, and both of them had these virtual
*  theatrical runs where I never got to see them with an audience.
*  So I'm particularly excited to be able to be in a room with people watching the film, because
*  that's how I'm used to releasing the work and it's been a funny time to do it all virtually.
*  And I'm really naive about how film works, but is it going to be in theaters after that,
*  in some limited number of theaters, or is it just going to be the premiere event, or is that
*  something that gets determined after?
*  It might have been, but because we did this virtual theatrical, that blew our theatrical run.
*  We were in theaters virtually all across the country, but they were hosting it on streaming
*  services, so it won't be in physical theaters.
*  So that day it's released on streaming platforms, so people can access it on iTunes, for example,
*  on Apple TV.
*  And the one that I'm pointing people to the most is Vimeo On Demand.
*  I don't know how many people watch or rent movies on Vimeo, but it's the only platform for us where
*  the film will be available all over the world.
*  So it's sort of the widest reach.
*  So Vimeo On Demand on September 13th.
*  After the premiere, what's the after party going to be like?
*  I don't know.
*  It's also a strange thing having not gone out much.
*  And I live in upstate New York, so it's going to be quite a shock for me to go into the big city
*  after all this time and have a party.
*  I don't know.
*  Some people might be well used to this already by now, but I've been up in the country.
*  And last question about the premiere.
*  Are you going to invite Mark Rimm?
*  Is he going to be there?
*  I don't think so.
*  We can talk about this more, but it's been a pretty icy response from him in the project
*  to this film, which I totally expected and understand.
*  Well, so the film ends with you showing them making their own movie, which may or may not
*  be a response to your documentary.
*  We'll get into more here in just a moment.
*  But I mean, is that did that come out or are they in production on that?
*  Do you know?
*  I don't know.
*  I've actually heard rumors at some of these virtual screenings I've been doing
*  that they are working on a response documentary.
*  I'd be eager to see that.
*  I don't I haven't heard anything more about it.
*  I don't know when it will come out.
*  That film that there, as you mentioned at the end, not to give away too much,
*  but the end of in Silico, my film, there is a film that they are working on.
*  And at the time, it struck me as just another of in a long series of promotional films that
*  they make about their work.
*  And that's how I got into making this film.
*  In the first place, I saw one of their stunning fly through videos of this little piece of
*  cortex.
*  And I decided to make my film.
*  So I understand well the power of the visualization.
*  It's what got me involved in the first place.
*  But I came to be quite critical.
*  And we can talk more about that of the promotional efforts and the emphasis on them.
*  And I think that film that they're making near the end of in Silico is just sort of
*  another one of those.
*  So you started off, I guess, an undergraduate taking a bunch of neuroscience courses.
*  And I understand that you took enough of those courses to have majored in neuroscience.
*  Should you have wanted to?
*  Is that right?
*  Well, at my university, I went to Wesleyan University, which is a liberal arts college.
*  And so I was actually an art history major, although I took as many neuroscience classes
*  as art history classes.
*  So I felt like I was double majoring, but I actually didn't get a neuroscience degree
*  because to get that degree, you do have to do a year of orgo, a year of physics, a year
*  of biology.
*  So I didn't really want to do that.
*  I wanted to take the upper level neuroscience classes, which I did.
*  And I took like nine of those, I think.
*  And I think you had to take nine art history courses to major.
*  So I felt like I was double majoring, but I wasn't.
*  I was just getting an art history degree.
*  But it felt like a good preparation to go make this film because we were assigned.
*  I was taking a million cortical circuits class and we were assigned the Markram papers
*  from the 90s with Bert Sockman and others.
*  And I was already enamored by that work.
*  And then so to see his TED talk and to have that trust, that foundation of trust built,
*  it allowed me to, I think, to be swept away in a certain way.
*  But not you didn't fall in love with neuroscience enough to be swept away with neuroscience
*  because you your real passion is filmmaking, I suppose, and art.
*  Yeah, I guess my craft is filmmaking.
*  But I think some people go to school for film.
*  A lot of people go to film school and are swept away in a certain more direct way by
*  film and film history.
*  And I never got into all that.
*  I never was like a film nerd and I never got into the craft in that way.
*  I was always trying to make films about the things I was interested in.
*  And so neuroscience was really the thing I was interested in.
*  And it was my intellectual passion.
*  And film for me was a craft.
*  And art history I never got.
*  I never did anything with.
*  It's one of those stale liberal arts degrees sitting on my shelf.
*  I don't know.
*  I thought maybe sometime I would be like working a museum or something,
*  but I never went down that road.
*  OK, so well, you read these papers by Markrum and others.
*  And then you saw this TED talk.
*  It kind of starts with Markrum's infamous, I suppose now, TED talk, where he
*  describes a project whereby within 10 years they will fully simulate a human brain.
*  And you were optimistic, I suppose, in the beginning.
*  And this sort of set off the beginnings of the project.
*  Do I have that right?
*  Yeah, that's right.
*  I mean, as I mentioned, I came out of reading these papers.
*  I went over there very wide-eyed.
*  I'd also read, maybe listeners remember, I read there was this profile.
*  By Jonah Lehrer at the time, who was writing, I believe, in Seed magazine
*  and wrote a very glowing portrait of Markrum as this kind of rock star of neuroscience.
*  And had gone over there himself and had gotten a tour around their machine room.
*  And so I'd read that.
*  I had seen their videos online.
*  I'd seen the TED talk.
*  And I went over there.
*  And this came out of also a place that I did want to make a film about neuroscience.
*  I had already made a documentary about the oil boom in North Dakota.
*  And that was my first film.
*  And I made that as a senior in college called Crude Independence.
*  I had gone and lived in North Dakota for a while.
*  Wow.
*  Wait, hang on.
*  Just how was that experience living in North Dakota?
*  It was really the beginnings of this wild west oil boom out there.
*  It was the beginning of fracking and oil drilling in North Dakota,
*  which continued for and continues to this day.
*  But people were lining up at dawn at the courthouse to get land deeds.
*  And it really had this boomtown feel.
*  And it was great for me to kind of cut my teeth as a new documentary filmmaker
*  and on my own out there getting out of my East Coast bubble for sure.
*  And I learned a ton making that film.
*  But I wasn't necessarily passionate about that.
*  It wasn't my intellectual passion.
*  I think I had seen There Will Be Blood, that movie.
*  And I think I was like, oh my God, this is the real world version of that happening.
*  And that swept me away enough to make the film.
*  But no, I met some wonderful people out there.
*  And I actually ended up making another film there in 2015 called Deep Time.
*  So I kind of had this parallel track all these years of making
*  these environmental films about North Dakota.
*  But I really wanted to make a film about neuroscience.
*  I want to make a brain documentary of some kind.
*  But it's difficult, I found, because you often think when you go into making a film,
*  as a documentary, certainly if you're writing a screenplay, you need to think about this.
*  But I think a lot of people who go into documentaries,
*  it is a little risky to go into it totally open-ended,
*  not knowing exactly where your story might land for an ending.
*  Especially if you're spending your own money on it.
*  Or if you're trying to get funding, you definitely need to do this.
*  You need to write what the equivalent of grant applications are to get
*  someone to believe that you actually have a film here about something.
*  But for me, with my brain documentary, with the beginnings of this film,
*  I was self-funding.
*  And I was doing freelance work then in New York, doing commercials and so forth.
*  And so it was very risky for me to think about beginning a film with my own money.
*  Where was this going to go?
*  And I couldn't figure out with neuroscience stories where the ending would be.
*  I really found it difficult to see out of anything any lab was doing.
*  In the discussion sections and conclusions of papers,
*  there's stuff dangled about curing a cure for Alzheimer's.
*  Or this will lead to...
*  Or certainly about consciousness.
*  There's the dangling fruit of, will we crack the secret of consciousness?
*  I thought, well, maybe I can make a film about these things.
*  This was so far-fetched.
*  It was always kind of punted over the horizon of
*  whatever research I was tracking that year or something.
*  So I found it difficult to think about what would the third act be for
*  a documentary about this subject.
*  And it was when I saw this TED talk in 2009 by Henry Markram,
*  where it was the first time I'd really heard a scientist plant a flag
*  in terms of a timeline on a certain time in the future
*  when a great insight will be gained.
*  And in retrospect, listen, I was 22.
*  As I mentioned, I'd read the papers and I was enamored by the scientist.
*  And I think I was much more easily swept away then than I would be now
*  in my 30-something brain.
*  But now that you're cynical and pessimistic.
*  Yeah, right.
*  So I was taken by the idea that 10 years felt like long enough
*  that anything could happen.
*  But yet for a 22-year-old somewhat short enough that I could imagine
*  finishing this film.
*  32 felt like so far away for me.
*  But still, a decade didn't seem crazy.
*  And I thought if I just stick with it, if he says he's going to do this
*  in 10 years and if I go once a year at least and I track this,
*  that's an interesting timeline for film.
*  And I liked the idea of longitudinal films.
*  I was inspired by the series Michael Aptit had done, the 7 Up series,
*  if people are familiar with that, where he tracked a group of people
*  every seven years for their entire lives and made this ongoing documentary
*  about it.
*  And so there's been some wonderful longitudinal documentaries
*  that were kind of reference points for me.
*  And I thought, okay, I'm going to jump in and do this.
*  I'm going to go over there the first year.
*  I had done a music video for Joe Ladeau's band, the Amygdaloids.
*  Oh, I saw that he was like a producer in the credits and I was wondering
*  how that came about.
*  So is that...
*  Yeah, I was doing music videos and commercials in New York and I was into
*  neuroscience.
*  So I crossed paths with Joe Ladeau.
*  A real cool band, right?
*  Yeah, right.
*  So he's at NYU and he had this band called the Amygdaloids.
*  And I did a music video for them, which is on YouTube somewhere.
*  And Joe knew Henry, I think not super well, but knew him from the community
*  of scientists working at a high level.
*  And so he helped me get in touch with Henry.
*  I had emailed Henry already a couple of times and hadn't written back.
*  So Joe helped me, said that he vouched for me to Henry.
*  And that's kind of how I got my first interview with Henry.
*  And then I had just come from going to...
*  I had gone to a neuroesthetics conference in Copenhagen with my kid.
*  I was just so...
*  I was so like...
*  I was wide-eyed.
*  I was taking everything in.
*  I was trying to see what I could make my film about.
*  So I think Henry was impressed.
*  I had come from this conference.
*  But I really was genuinely...
*  I wasn't there to get the scoop or show the real blue brain project or something.
*  I really was genuinely going in thinking that this was going to happen and that I
*  was going to be there to document it along the way.
*  I had not an iota yet of sense of what the criticisms were.
*  I'm sure on that TED Talk, if I had just scrolled down into the comments section,
*  I could have seen some early criticisms.
*  It probably would have helped me sharpen that side of the film a little bit earlier.
*  But it took me a few years actually to even realize that there were criticisms of this project.
*  So that's how into it I was in the beginning.
*  Yeah.
*  So you were working under a lot of uncertainty, which must not have felt great at times.
*  There's already a couple of questions in the chat that I'll weave in here.
*  One is just...
*  I guess it was 10 years or was it beyond 10 years?
*  It went a little bit beyond.
*  I did 10 visits to the project.
*  There was a nice sort of wholeness in the end about that.
*  There was once a year for 10 years, but it takes a couple of years to finish.
*  This was a big edit.
*  I had a lot of footage.
*  Oh my God.
*  I was going to ask you about that.
*  Yeah.
*  Oh yeah.
*  So it took a good year to just get the film edited after all that.
*  And then it takes a while to get the film out.
*  So that's where we are now.
*  But at a certain point, which is in the...
*  I put in the film purposely because I wanted to be a little
*  self-aware about my own...
*  The way I was selling my film to the world because I got carried away, I think,
*  with what I had become.
*  When the Human Brain Project happened and Henry Markram leads this team that gets
*  a billion euros from the European Commission as part of this flagship award,
*  I was really like, oh my God, what have I...
*  I've really stumbled into it here.
*  I've hit gold.
*  I'm part of this even bigger project now.
*  I'm making a film about this billion-dollar global project.
*  Oh my God.
*  And so I went on MSNBC and I said, I'm making a 15-year film because at that point,
*  it was five years in and they had launched the Human Brain Project,
*  which had a new 10-year timeline.
*  So I thought, okay, well, I'm making a 15-year film now.
*  So I got carried away.
*  I want to put that in the film itself.
*  But in the end, I went back to my original promise to myself and to Henry,
*  which was a 10-year film.
*  So I cut my 15-year timeline short and the Human Brain Project continues now.
*  And so is the Blue Brain Project.
*  This was an arbitrary timeline in the end set by the TED Talk and then followed very
*  closely by me and maybe nobody else.
*  Okay.
*  So here's a couple of questions from the chat already.
*  So you did these 10 visits to the site.
*  Someone's wondering,
*  how much time you actually, when you visited, how much time you would actually spend on site?
*  And then I'll add what the nature of those visits were like.
*  Were you having to try to pull people in to get people's attention or did you have set
*  meetings, that sort of thing?
*  Yeah, I would go.
*  So I went 10 years in a row.
*  Some years I did two visits.
*  So it wasn't an orthodox 10 trips and only 10 trips.
*  There were several years where I went twice because there were notable things that would
*  come up and they would sometimes let me know about them and sometimes I would
*  realize that, oh, the yearly summit is happening this year in Barcelona or something.
*  I'm going to go there and then I'm going to go back with the team to Lausanne or something.
*  So I would sometimes try to hit some notable event to see them outside of their labs and
*  their offices too.
*  And so there's a bit of that in the film.
*  But yeah, when I would go on these trips, the first eight years I self-funded everything.
*  And that was difficult because it's very expensive to travel to Europe and especially Switzerland
*  was quite expensive.
*  I'm not sure what the exchange rate is now with the dollar is much stronger now.
*  But at the time, Swiss francs, it was just very expensive to get there and to stay
*  for any amount of time.
*  So I would freelance in New York.
*  I would save up.
*  I could afford a four-day trip-ish usually.
*  And I would stay maybe three nights.
*  So I would usually have three full days or so at their building and they would help me
*  create a schedule of people to interview.
*  And they had new people that might have joined the project that year.
*  They wanted to make sure I would include.
*  And it always told a bit of a line of I was very careful to make sure that I was retaining
*  my independence and my own control of what I was interested in, what I was filming.
*  I did not want to become the de facto videographer for this project who would come over and they
*  would think was capturing something for them.
*  I did retain my independence.
*  We never had any agreement that was signed or any kind of...
*  Was it implicitly understood from them that you might be sort of on their side?
*  I think they hoped that.
*  They hope that.
*  I don't think I let them on in any way.
*  In fact, we had to have a couple tough conversations because in the first five years of this project,
*  I was releasing yearly updates to this.
*  And I don't know if anyone had seen those back then.
*  But at the time, my film was called Blue Brain and Scientific American premiered one,
*  Vice premiered one.
*  And there were like 10 or 15 minute edits that I would make from that year of footage
*  and post online.
*  And the first couple were probably felt to many people like they were just promotional
*  videos for the Blue Brain project because they had no critics in them.
*  It was just Henry talking, showing the visualizations, blah, blah, blah.
*  Then year three, I included...
*  And this all got thrown up in the air and re-edited for the film in the end, plus the
*  end of the five years as well.
*  But I had Sebastian Sung's interview in year three.
*  And that was the first piece of criticism because Sebastian had included in his book
*  Connectome a bit of criticism about Henry and the Blue Brain project.
*  I'd read that.
*  I had gone and sought out Sebastian, interviewed him.
*  And then in that year's edit, I put that in there.
*  And I didn't tell Henry and the project I was going to do that.
*  And I posted that publicly.
*  And they were taken aback by that.
*  And their project manager at the time, sent by Henry when I got there, sat me down and
*  sort of had a talk to talking to with me about how if I was going to include critics in the
*  future, I would need to tell them about it, not run the material by them.
*  They were still to their credit.
*  They understood my independence and respected it and never challenged it directly.
*  But I think they were a little frustrated that they had given me all this access.
*  And I think that's fair on their part.
*  They'd given me all this access.
*  And then I had kind of blindsided them with this criticism, which they knew.
*  They were quick to tell me, we know all the criticism.
*  It's not like this is new to us.
*  But just let us know because when you're going to make your edit, we're going to be in dialogue
*  with these critics when you cut back and forth.
*  And we want to know who we're in dialogue with.
*  So we had that friendly tension throughout the years, I would call it, of what I'm doing,
*  what their awareness of what I'm doing is.
*  And again, to their credit, they kept letting me come back to do what I was doing.
*  And in the end, I wonder if they knew the extent of the criticism I had captured
*  because I didn't release anything the last five years.
*  A lot of the material, the most critical material in the film,
*  comes from people responding to the open letter and all of the fallout over the human brain project.
*  And that all was material I just kept until the end.
*  So we had a very interesting relationship along the way.
*  But there was no implicit promise or anything about what this film was going to be.
*  OK, so this leads nicely to the next question.
*  I'm curious how you perceived the shift, if any, in Henry's attitude from year one to year 10,
*  having spent a lot of time with him.
*  I'm wondering because it struck me as a bit arrogant to be so confident about a 10-year timeline
*  to build one of the most complex things known to science.
*  In parentheses, just like Elon Musk's attitude with regards to brain-computer interfaces.
*  Did you see a shift in how he approached his project idea slash vision as a scientist
*  and not as a messiah?
*  Over the whole course of the film?
*  Yeah.
*  Over the whole course of the 10 years?
*  Yeah.
*  Wait, can I just say before you answer that, because the messiah aspect, I don't know.
*  My reading of Henry during the film was that he just remained sort of focused and confident.
*  And the salesmanship part of his delivery was definitely there.
*  But I don't know the full extent of how arrogant and salesmanship he was.
*  And I don't know if you want to comment on that.
*  But yeah, so maybe just as a preamble to the answer to the question.
*  Yeah.
*  Right.
*  You're saying you're wondering if there was material left on the cutting room floor,
*  or you're wondering if I saw stuff that didn't make it in the film
*  that spoke more to those qualities?
*  Well, no, this is from the chat.
*  That question is from the chat.
*  But just from my reading of it, he seemed sincere and focused the entire time.
*  And not bitter.
*  He didn't seem terribly bitter.
*  But okay, that was just my reading of it.
*  Yeah.
*  It's complex.
*  And a lot of the dynamics of salesmanship are complex because as a salesman,
*  you often believe in the product.
*  You believe in the possibility of the product.
*  But you also, especially I think when you're garnering funding for a dream like this,
*  a grand division of where something could get if all of the variables line up.
*  If the computing track continues on the way you expect it to,
*  and you continue to get better and better machines that can simulate more and more detail,
*  that's one track.
*  You also need to have access and to standardize on the informatics track.
*  You need the data to fit in in the right way and be able to
*  load massive amounts of data into the simulation.
*  There were all these tracks.
*  And when he does the TED Talk in 2009, does he know for sure that the tracks are
*  going to line up in 10 years?
*  I don't think so.
*  Fuck no.
*  Fuck no.
*  I don't think so.
*  And I don't think anyone would think that he did.
*  And I didn't.
*  I mean, I trusted him though because of the papers and because of his career before that.
*  I trusted that like other scientists, he wouldn't say something unless he really did
*  think that these tracks could land there in 10 years.
*  And that's where I wonder if I was a little mistaken in that trust because I think there's
*  a degree of salesmanship that went on with this project over the years.
*  Potentially, there was a little bit of we need to run out and get a bunch of funding so that we
*  can see, so that we can try to get there.
*  But we're not really sure if we could get there in 10 years.
*  And all of the criticism I ran into then, headfirst a few years in, was really that this
*  was a crazy idea that we could do a human brain in 10 years.
*  And I continued to run into that criticism.
*  And to this day, I mean, people who have seen this film and reacted to it think that that's
*  a crazy landmark to be thinking of in any kind of time frame of a decade.
*  And maybe you could get a generalized model of a human brain with very abstracted
*  point neurons or whatever.
*  But to think of the level of detail they were talking about and were proposing in that initial
*  proof of concepts, cortical column that they simulated back in 2009 could be scaled to a
*  human brain.
*  I don't think anyone would believe that.
*  And that's where it's complicated because I'm not sure even Henry really, really thought that
*  that could happen in a decade.
*  It's impossible.
*  It's a fiction.
*  You're kind of writing science fiction as you make the proclamation in a way.
*  And you're maybe hoping that the tracks catch up and science fiction becomes reality.
*  He might have really thought that it could be, you know, Henry really, in my time with him,
*  his thinking is much closer to the kind of futurism of someone like Ray Kurzweil than it is
*  the very traditional academic biologists, many of whom I interview in this film, who are speaking
*  about the Blue Brain Project.
*  But that kind of futurism, you know, it's a way of thinking where anything could be possible in
*  a decade if we just all got together and worked on the same vision in concert.
*  It's just not how the world works, though.
*  So it's a little divorced from reality.
*  I think that becomes problematic when public funds are at stake.
*  So when the salesmanship is from the largesse of one billionaire and you want to go out and run
*  and try to solve a problem, it's a little bit of a different conversation, I think.
*  And it's interesting to see what the Allen Institute did with the money from Paul Allen.
*  They made tools that have been widely used and so well regarded in the community as sort of
*  cornerstone, now foundational maps and so forth.
*  So I think it's difficult.
*  But my point is that if they had gone out and tried to do the same project,
*  I don't know if I would have been as critical.
*  But when you're dealing with state-funded science, money coming originally from taxpayers,
*  I think the criticism is you open yourself up to the public gaze and you should be responsible
*  to absorb that criticism and to deal with it and to respond to it.
*  And you should be in dialogue with it, I think.
*  So I think in many ways this film audits the kind of salesmanship in regards to public funds
*  in a great dream like this.
*  But I've gone a bit on a tangent here.
*  Your original question was about how Henry himself changed.
*  Well, if you could, yeah, sense that change or what sense you had of his change.
*  As a scientist, not a salesman.
*  Yes.
*  So as a scientist, I saw Henry really continue to focus on the mouse brain the whole time I was
*  working on the part.
*  Really?
*  We never even got to the work going on there is just like, it continues to be completely
*  focused on the mouse brain.
*  They're still trying to work towards a full-scale simulation of that mouse brain.
*  The Cell paper in 2015 was their crowning achievement to date from their point of view.
*  And you had a guest who used to work on the project a few episodes ago on your podcast
*  who told you about this great calcium triumph that they had, which I didn't put in the film.
*  I thought it was a little too technical to get into in the film.
*  But by the way, that guest will remain unnamed.
*  However, I was going to bring up the blue brain and human brain project and I was asked
*  not to.
*  Yeah.
*  Well, you still did.
*  You still tried to, right?
*  You still asked them a couple of questions.
*  I was just interested that a lot of people don't want to talk about this project and
*  certainly people who work there still and people who used to work there.
*  I just think it's...
*  Listen, I kind of get it.
*  It's been such a lightning rod for so many years for these people.
*  And a lot of these people are humble scientists who came up through the project
*  and wanted to just do their work and move on with their careers.
*  And they shouldn't necessarily have to respond to answer to this stuff directly.
*  So that's fair.
*  But okay, back to the changing as a scientist.
*  So one thing that has changed that I've noticed is that
*  there is no really mention of the human brain anymore.
*  They've scrubbed it from their website.
*  When this started, Henry gave the TED talk and it was human brain in 10 years.
*  Those were the headlines.
*  That was the press they were ginning up.
*  And there was a roadmap that they were going to do,
*  mouse brain, cat brain, primate brain, and then human brain.
*  And I saw PowerPoints with that roadmap laid out.
*  That kind of got scrubbed and has disappeared.
*  And now I think Henry has realized that being more realistic and targeted with the milestones
*  helps dissuade people from being so vocally critical towards it probably.
*  If he just talks about simulating the mouse brain, it's a little more feasible.
*  Still a pretty big pipe dream, but a little more feasible than throwing out the human brain
*  10 years timeline.
*  That's been one change.
*  I don't think that his core beliefs changed in the work.
*  I didn't see him waver one inch.
*  And I was looking for that in the last couple of years of making this film.
*  And in the last interviewer, too, I'm asking him,
*  do you still believe in this project and in this attempt to simulate at this level of detail
*  the same way you did when you began?
*  And the answer is always yes.
*  And I assume continues to be.
*  And I think in order to run a project like this and to continue to get the funding that they do
*  from the Swiss government, you have to believe.
*  Everyone around the project speaks to the vision of the project.
*  There is an element of that leadership that has to remain inspired and positive.
*  And in order to keep the people around him believing in it and keep the funding coming.
*  I'm going to jump in with a question of my own.
*  And by the way, there's lots of questions in the chat.
*  So nice job, guys, and keep those questions coming.
*  Just a little anecdote.
*  I think I've told this on the podcast before.
*  But when I was interviewing for postdocs, I had a conversation with a fairly new faculty member.
*  And he said that the lab that he came from, his advisor, gave him this advice to just say crazy
*  shit. And eventually you'll get the funding and you might be right.
*  And that always stuck with me.
*  Whenever I think of projects like this or ambitions like this, I had a friend growing up in high
*  school and in college. And it always bothered me so much that in a group conversation,
*  to overtake, he would just overtake and get attention.
*  He would just speak louder. And he would just yell above everyone else.
*  And it always really bothered me. And that problem exists in science as well.
*  Essentially that attention seekers get attention.
*  I mean, it's the same with children. And I don't know how to fix the problem.
*  And I don't even know if you want to comment on this.
*  Maybe reflecting on your experience, do you have the same sense that it's an open problem?
*  And if so, how do we fix it?
*  Yeah, I think you've put your finger on a universal problem with human psychology.
*  But we can apply it. We can drill down in science in particular.
*  The scientists in your crowd probably know more about this than I do in terms of the
*  day-to-day pressures that you feel as a scientist to attention seek.
*  Scientists operate in a system that incentivizes
*  metrics and pushing out publications and being loud about the implications of your publications.
*  And so, seeking attention for your metrics and then writing books that pump it up even further,
*  probably. So, I don't know how to change that system. But just to affirm what you're saying,
*  I mean, I think yes, yes, people do that. But there is this sort of danger, I think.
*  This is obvious to people. But when you don't deliver, when you over promise and under deliver,
*  that's when public trust and faith in science can potentially erode. And you can promise a lot of,
*  get all this attention for promising nice shiny things. But then the sort of stultifying slog of
*  the realities of research ensue. And you are in institutions that, from my point of view,
*  and I tried to include some of this critical context in the film, there is a sort of culture
*  of corporate bureaucracy around science in these institutions in many ways. And it's hard, I think,
*  to take risks and play and fail in smaller ways. And many people are just pushed to be loud and
*  produce and produce what I've heard other people call salami publishing, like this kind of just
*  getting, just churning stuff out, sort of mimicking what other people are doing,
*  changing it slightly. And listen, there's a mountain of science that comes out of that,
*  that is valuable. But there's not maybe as much null results and the sort of other underside of
*  that mountain we could use to see a little bit more, the less loud, less flashy side.
*  What about those experiments that didn't go the way they thought they would go? And so I don't
*  know how to, I'm not prescriptive with policy or anything. Come on, you gotta fix it, man.
*  Okay, so another question here, Chris asks, if I remember correctly, what did it feel like when he
*  did not sit down for the last meeting? He, meaning Henry, if you could just briefly take us through
*  that visit, please. Yeah, that was, so he did sit down for the last two meetings. That was,
*  the one where he stood me up was actually two, was actually the third to last interview that I did
*  with him. So again, to their credit, to his credit, he came back, even after that, he came back and
*  maybe it's because he felt bad, you know, and even that year that he stood me up, he made sure to
*  do a video call with me to, you know, to sort of catch up when I got back to New York. But
*  it was, yeah, it was tough to go over there, again, self-funded at that point still.
*  Yeah. And make that trip and spend thousands and, you know, and then get stood up. Yeah. And now
*  it was interesting because I had, we'd been in this rhythm of doing it for like seven years at that
*  point. And I had become, I was becoming increasingly critical with my angle and I
*  think they could probably feel, he could probably feel that. And listen, I don't know, I mean, he
*  might have just been a, I don't know how intentional it was, but from my point of view, people are
*  busy. We had this on the calendar for months, you know, I was coming, I was only, he knew I was
*  only coming for a few days, it was tough. It was a tough one. And it sort of, to me, felt like,
*  you know, my relationship with them was changing a little bit.
*  This is from Rokas. I like how you pinpointed that simulating imperfections is super hard
*  and might be the necessary ingredient. Do you think using computer science terms
*  to explain the neuroscience concepts are harmful for the field?
*  By the way, you don't have to answer any, you know, or any of these questions, if it's going
*  to give away too much of the film, you know, feel free because, you know, to keep it in your
*  pocket, of course. Using computer, I would love an example from, of the kinds of computer science
*  terms that they're thinking. Okay, if you want to jump in Rokas to clarify. Because I would
*  actually, something that I talk about sometimes is, I worry sometimes, and listen, I, you know,
*  your show is called Brain Inspired. This is a two-way street. So we were talking about,
*  you know, computer science inspired by brains. And now in this, in the context of this question,
*  brain science that people are using computer language to talk about. I actually, I sometimes
*  bristle at the overuse of brain language in computer science. I think that people
*  dignify their computer science to too large of a degree sometimes by extracting the language of
*  biology that has been hard won by millions of years of biological evolution. And just plopping
*  that onto the network that they've designed and saying, this thing is a neural network and it
*  learns. And it's like, man, wow. Okay. So, evolution took millions of years to do that thing. And you've
*  done it in the computer. So I think people just need to be a little careful about
*  bringing the language of biology into computer science. And I get it. Listen, I'm not, it's a
*  little bit of a stickler to say like, well, it's not a neural network. I get why people call it
*  that. And of course, and people calling point neurons in their deep learned networks, neurons,
*  using the word neuron, it's like, wow, neuron has a lot more going on with it than what you have
*  going on in that model. And so, it's like, yes, there's a degree of what neurons do and how they
*  fit into networks. And that's why we're using it. But I worry that people, that it leads, what it
*  does, and this is why I'm a little critical of it, is it potentially overinflates our sense of where
*  we are with the way in which we're capturing biology in machines. And so, one of the things
*  that the question has pulled out of the film, and I intentionally put this line of criticism in the
*  film about imperfections, or I call them tiny mistakes in the film, is that this is something
*  that I was hunting around for in the 10 years of making this film was how are they capturing
*  true variability and chaos from biology, stochasticity, we could also say.
*  What are the models to capture that in a computer simulation of biology? And I found in the end that,
*  yes, we use very state of the art random number generators to generate some of that noise, and
*  they call it jittering in the blue brain simulation. But ultimately, a scientist tells me in the film
*  that, well, we can never know the right kind of variability. And I just found that to be a pretty
*  revealing answer. So ultimately, if you don't know the right kind of variability, then you're
*  really creating a model to do what you want it to do. You're injecting a bit of jitter, just enough,
*  okay, that seems somewhat realistic, but really, I'm going to fit this model to the question I'm
*  answering and that I, as the human researcher, want to figure out. And it's important to realize,
*  to draw a bit of a line in the sand that you have not necessarily captured
*  the actual variability that has driven random natural selection over millions of years.
*  How much did you have? And then, well, did you debate how much neuroscience to put in the film
*  versus making it more accessible to the general public?
*  Yes, this was a difficult balance to strike, had to put a little bit of basic neuroscience in the
*  film to be able to get to that general public audience. I wanted to not have this just be a
*  film for the field. But I also wanted the film to appeal to the field and to have conversations like
*  this with people who think deeply about this in their professional lives and are very knowledgeable
*  about the subject. And I don't know if we hit the right balance, but that was, yes, the answer,
*  that was an active debate in the edit room. Do we need a little bit of a primer here on what
*  axons and dendrites are? Probably, yes, we need a little bit of that.
*  Got to do it.
*  Yeah. Do we need a little section on models? Yep, we got to have a little bit of a thing about what
*  models are. But man, there could have been so many more primers that we went into. This could have
*  been so much longer, this film. It was a real challenge to get this. I always wanted it to be
*  less than 90 minutes. I feel like for a documentary, I don't like asking people to watch
*  something longer than that. And listen, that's my own thing. I think people are used to these
*  days watching things maybe longer than that. But that was my challenge.
*  Yeah. I mean, like all good stories, it's about people.
*  And so I guess you had to have the science in the background at least to extract where people were
*  coming from, perhaps. Harry says, I like the sequence where they debated using 2030 versus
*  2050. I guess this is toward the end of the film. I wonder if you think Blue Brain could have
*  gotten funded with a 30 plus year timeline. I guess that wasn't on the table though, was it?
*  I mean, it was a 10 year grant that was being awarded from the government.
*  Yeah. So the 10 year grant was the Human Brain Project where there was actually
*  money earmarked for a specific decade window of a project which continues to this day.
*  The Blue Brain Project, and I wasn't privy to their inner finances, but my understanding was they
*  actually were funded just yearly and that they had yearly reviews. Or maybe every two years,
*  I'm not sure exactly the pace of the reviews, but I don't believe that the Blue Brain Project
*  was technically funded for 10 years from the beginning. They were funded on a reviewing cycle.
*  It's more that the dream that was set out with what this project will do was 10 years.
*  The actual benchmarks had to be reviewed by whatever committee would come in and look at it.
*  I don't know that the excitement would have been generated by saying we're going to do this by 2030.
*  That would have felt in 2009 so far off. I just don't think you get the same kind of response.
*  Well, you see in the film, I believe Henry says something like, well,
*  2050 is just too far away. Let's bump it up.
*  That would be the equivalent. That's how 2030 would have felt in 2009.
*  Now, they were in that scene. They're talking about the session titles for an upcoming summit.
*  It was, I thought, very interesting to hear them talking about time again.
*  At one point, he had been talking about 10 years from 2009 and now here they are.
*  That's pure sales. That's right.
*  It's like what feels better? What just feels closer and more tangible? It doesn't really
*  have anything to do with what can actually be accomplished by a certain date.
*  Yeah. At what point, Chris asked, at what point did you become aware that they were kind of doing
*  a bait and switch, dazzling you with the pinstripes rather than the progress and performance, so to
*  speak? That was year three, right? Year three is when I started to realize there
*  are critics out here. But to be fair, I didn't yet think in my mind of a bait and switch.
*  I also don't know that I would go so far as to call this a bait and switch. People look at this
*  film and they look at Henry and I think when they don't know much about it or they're coming into
*  seeing my film for the first time, I think there's an expectation given what's gone on in our world
*  in the last decade of a kind of story like an Elizabeth Holmes type story, a Theranos type
*  story of a real snake oil salesman who was selling a product that was completely vacuous inside in
*  the end. That isn't the story. So this is more complicated. It is. Yeah. And so, you know, and
*  yes, and as I just mentioned, they have been reviewed very regularly by very serious scientists.
*  I've just seen that there's so much politics in science. I mean, my goodness, the people who come
*  in. Isn't that so disheartening? It's just incredible. I'll go and talk to scientists who
*  think that the whole thing is a fraud and that the people who come in to review it are like in the
*  back pocket of this project. Like, it's amazing the stuff I've heard that people won't tell me on
*  camera because of course they won't, you know, it's like, but if I were, if I was some muck
*  cracking investigative journalists writing, you know, an article, maybe I could have gotten those
*  in quotes and really, you know, but, but again, that, that, that's their feeling that I don't know
*  that there's proof of that. I didn't find any proof of that. And, you know, people, people making
*  claims that, that the media, that they're, they're like journalists who are friendly to this all
*  those years and stuff. I don't know. I mean, I think that I never felt a bait, a true bait and
*  switch as the question implies, but I did start to feel like, oh wow, there's, there's like a critical,
*  there's a critical response out there that I wasn't familiar with in the beginning that I am
*  becoming more familiar with as of year three of this film. I really felt the fallout after the
*  human brain, after the open letter, you have over 800 scientists speaking out against this thing
*  in an open letter. That was when I thought, wow, I mean, is this like, is this completely hot air
*  and should I stop making this film? I really thought about, I really thought about stopping
*  after all that because I had, I had to really fall from my, that was really when I, my dream,
*  my dream was crushed about being there. And it was more, it was honestly, it was more about like,
*  there's nothing, there's no third act, there's no end here. I'm going to just continue making this
*  film. And there will be no moment of that I had dreamed of, which is like, at the end of the decade,
*  the switch is turned on and the simulation comes alive. That was my own science fiction dreaming.
*  But how close did you come to quitting? And did you have, you're kind of, were you working in a
*  vacuum, like super solo or what, you know, did you, were you in constant contact with your
*  producers and editor and did anyone try to dissuade you from continuing or did people try to pump you
*  up and say, come on, man, you can do it. It'll, something will happen. Just my, just my family.
*  I had no one else. I wasn't working with anyone else on, on this film for eight years. I was
*  completely solo. Did you, did you ever cry? I definitely had some, some dark flights home from
*  feeling like I got no footage out of that year. You know, nothing interesting happened.
*  I had to kind of lean into that. I had to, I had to lean into the,
*  the kind of tantric quality of time, of time in this project. There was nothing going there.
*  I mean, listen, from their point of view, it was very exciting every year. There were things going
*  on. They were getting closer to the, to a model of the entire mouse neocortex,
*  at which they continued to do, to work on. And I would come home and be like, well, okay, that,
*  that might be true for them. And they are seen very earnest about it. I was here to make a film
*  about a 10 year simulation of the human brain and we're, we're not going to get there.
*  And so I had to fall. I had to kind of like fall from that in a very classic arc of like a coming
*  of age story in a way. I had to like, my heroes had to be, had to fall from grace for me to decide
*  what was I interested in and the rebirth for me in like climbing back into this project was getting
*  interested in these questions of, of chaos and variability. That was what got me back in
*  intellectually to explore how they were capturing that in a, in this level of detail in a simulation.
*  And that once I got interested in that, I felt like I could now explore something
*  in a genuine way each year again. So yeah, no one, I didn't have anyone. I had wonderful producers
*  on this project, but they came in in the last couple of years of the film. Once we got funding
*  and I could actually afford to, to have to pay people to, to work on this project. And then we
*  had, and then I worked with another editor at the end in the end too. So that was at that point,
*  there was no quitting anymore. We had fine. We had funding. We were going to,
*  we're going to finish the film. How did you know when it was the end?
*  I just decided in an Orthodox way that I was going to do 10 years. And so ultimately, but, but
*  I still needed to feel like I had that last trip to Blue Brain Project that tied it up.
*  I was feeling like by year nine that I could feel the ending. There's a, there's a particularly
*  potent moment for me in the film. I don't know if it resonated for other people, but for me,
*  it's a potent moment when Henry sort of, we have a long sequence of people making, including Henry
*  making the 10 year promise over and over again. And Kurtzweil is in that sequence too,
*  of forecasting of where we're going to be by certain years. And I just wanted to show
*  the, that there is a Silicon Valley streak in, in the kind of salesmanship that Henry was doing
*  all of those years and that, and the kinship with Kurtzweil. And so it resolves with Henry
*  kind of saying, well, a 10 year project, a 15 year project, a 20 year project. Well, what do you
*  think? And he just kind of asked me and, and then we end there on that scene. It moves on to the,
*  I think the final year after that. So I honestly, at that point I was like, okay, so I like,
*  we're wrapping up here. We can, we can work like where it's kind of, it's all arbitrary in a way,
*  these timelines. I need to just decide how my story wraps up here. And part of that journey too,
*  was realizing I needed to put my journey into this film. I did not think from the beginning.
*  And I, and my other two documentaries that I've made about North Dakota do not have my journey
*  in the film. And I was alert. Yeah. My daughter, who's nine, asked me to ask you, I said, I asked
*  her if she had any questions. And that was her question is why you decided to put yourself in
*  the film. Sorry to interrupt. Good question. I didn't want to, I was allergic. I just, I never
*  liked documentaries where the filmmaker decides that their story is as important or more important
*  so you feel like sometimes people decide then, then whatever's going on in the film,
*  with the subjects that they started following initially. So I, I didn't want to do it. And I
*  realized by the end that, you know, there's something, there's something we talk about in
*  filmmaking, like the reliability of, of a narrator. So we, we often critique an unreliable narrator,
*  for example. And this is a, this is something I started to think about. I was like, who's going
*  to narrate, who's, who's telling the story of this film if I'm not telling the story?
*  It's going to have to be Henry, really. I mean, he's the one he'd like, he, I have the most
*  interviews with him. I'm going to have to just keep showing interviews with him. And he'll narrate
*  where this project is each year, but because he maintained his positivist belief in, in this project,
*  the full time and continues to this day, as far as I understand, to, to believe in it and has not,
*  you know, doesn't, hasn't become self-critical or isn't self-effacing at all. I felt like I had to
*  be self-critical and self-effacing in this story in terms of my original salesmanship and, and
*  awe and, and, and sort of being swept away by the salesmanship. I had to curdle that myself
*  in the film and be self-reflective about it. And I didn't know how that was going to happen.
*  Unless I jumped in and became a character in a way in this film. And that's how that's,
*  it was really because I felt like I had to get, I had to be critical and I had to be self-critical.
*  Could I jump in with a question about the salesmanship? I'm wondering, especially because
*  you mentioned, you know, you had that montage of all these different people saying 10 years, 10
*  years, 10 years for different projects. Although I think they were all computer science related.
*  I wonder how much of it is salesmanship and how much of it is just the perennial human,
*  you know, foibles of underestimating how hard things are in the short term, but then also
*  underestimating how impactful they can be in the long term. You know, it seems like five, 10 years
*  is all, or, you know, 20, if you want to be conservative is always the timeframe for the
*  thing, whether it's electric cars or, you know, whatever. So I'm wondering if you think it really
*  was salesmanship in the maybe slightly dishonest sense, or it's just like, we're just bad at
*  estimating timelines and we always feel like 10 years is the right number.
*  Yes, I think actually that you have a good point there. 10 years, listen, it was the right,
*  it felt like the right number for me to, as I said, to, it was long enough, anything could happen in
*  my film. It was short enough, I could imagine actually doing it. And I think that probably is
*  actually how Henry felt about his promise. Long enough, like, give me that amount of time,
*  I might do it. But, you know, it's also not too much time, you're not going to be, you're not
*  going to forget about it. It's like, you're going to keep giving me funding to do it. So there's a
*  lot of truth in that. Psychologically, I'd love to see some sort of study about why the 10-year
*  horizon is, you know, attractive in that way. It does, it has probably some proportional
*  relationship to our lifetime or something. You know, the way we think in decades and
*  generations and there's a lot of our thought that's organized around that,
*  totally arbitrarily, right? But it's a great point.
*  I had the thought that, I just, the thought just occurred to me a moment ago that your journey,
*  your mental journey, parallels that of a lot of people in neuroscience PhD programs
*  and throughout they're kind of, you get beat down sort of, you come in wide-eyed and think
*  you're going to really do something and think you're going to learn a lot about the brain.
*  And then you start to focus on these narrow questions, things don't work, and it kind of
*  beats you down. And so it's interesting that there are people like Henry that remain super optimistic
*  and I don't, I wouldn't call them wide-eyed, but seem to have escaped this sort of beat down
*  that a lot of us go through. Anyway, that was just a comment.
*  You know, thinking about like timelines also, I had an idea for a business,
*  oh, I don't know, five, 10 years ago, where it was a business to hold construction companies
*  accountable for their timelines because like in construction and in all arts, film, all sciences,
*  you're always over budget and over the deadline, but there doesn't seem to be any accountability
*  for it. And I don't know how I would make a profit in this business. I don't know who would
*  pay for it, you know, it would have to be like publicly public funding. But yeah, I don't,
*  did you go over budget and over time? I, you know, I, there was no budget. I was,
*  I was self-funding your budget. You know, I was, it was my budget. So I, I couldn't go over budget
*  and still pay my rent in New York. So expensive, but I ultimately, you know, I didn't, the timeline,
*  I, I, I repromised as I said, 15 years, and then I ended up coming in under the, under that reboot.
*  I had to don't know unless arbitrarily with the human brain project. And then we got funding,
*  we ended up getting these two grants, one from Sloan foundation, one from Simon's foundation
*  through their entity, sandbox films. And, you know, we, we didn't go over, I'm proud to say
*  we didn't go over budget with our grants. We stay under we, and you know, we, we,
*  we have a little bit left over for marketing now, which is nice. So, so yeah.
*  Okay. So back to the science a little bit. I'm gonna, there are two questions that are kind of
*  related here. One is, so I'm gonna ask them both, and then you can comment on both or either.
*  One's from Michael, I was curious, did the final brain simulation do anything productive,
*  and how long could they run it for? And then a related question from Hannah is,
*  how close did they, did they get to matching the number of cortical columns to the scale of the
*  mouse brain? Good. Yeah, those are good questions. So that there wasn't, it's, I just reframed it a
*  little, there wasn't a final simulation in my film, even that I captured. It, it, it's ongoing.
*  They don't have a full simulation of a mouse brain yet. And that's what they're working towards
*  still. I've stopped really following so closely, the research, honestly, I felt like I did my part
*  for 10 years. I'm not done. You're out. I'm not going to continue to monitor their releases and
*  everything. It's, it's okay. I've done my part. So, but, but to answer the question a little bit,
*  the last major release that they had of work was really the cell paper in 2015. That was when they
*  released their cortical column simulation, showed what it could do. And they were able to mimic in
*  that paper, which is voluminous. It's, it's a huge paper. It's actually like much more about the
*  methodology of doing a simulation. It's a huge method section. And, and, but in the paper, they
*  were able to basically mimic, mimic some classic electrophysiology papers from in vivo work. And
*  that was how they showed. And I think why they got this paper published eventually. And they had to,
*  as we mentioned before, people had listened to this previous episode with this former researcher
*  at blue brain. They were having an issue with calcium levels. They realized that in vitro and
*  in vivo calcium levels are actually slightly different. They made a tweak in the simulation.
*  All of a sudden the simulation is behaving. That's showing not behaving. It's not an animal,
*  it's showing signatures of electrophysiology that you would expect to see in a typical
*  cortical slice, like they simulated. So that's the, that's what it did. That's what it did. That was
*  the big moment as far as what I captured. But people were even skeptical of that. I think
*  people are skeptical of how much parameter fitting it happens. If the calcium thing could be tweaked
*  so easily, what else could be tweaked to get this kind of excitation that they're showing and these,
*  these little oscillations they're showing. I don't think that there's anyone who thinks that some
*  sort of scam, as we were talking about, that it doesn't actually do this stuff. I just think
*  people are skeptical to the significance of what this, this model will actually be able to reveal
*  about the brain. So they haven't had results that have, have, I would, from my point of view,
*  have broken new ground in, and reshaped our understanding of the brain in any way, in the
*  way that, you know, discovery like grid cells and the hippocampus or something, something monumental
*  like that, like some sort of foundational work has not come out yet of this project, not to say it
*  won't, but that's basically as far as the work got that I captured. And then in terms of the question
*  about the columns, my understanding is they really, you know, there are, there is even
*  controversy of the column, the New Yorker column as a unit. People, people are skeptical that the,
*  that the column, which comes originally from work by Vernon Mountcastle is actually a,
*  a unit that could be, that could be meaningfully scaled up in a simulation like this.
*  And that maybe there is actually more, more intricate stuff happening at mesoscales where
*  there are different types of geometric formations and topologies that aren't, it isn't just this like
*  clean column. When you see that they're, when you see their simulation, and there's some of this in
*  the film, it really feels like they're treating the column as a microprocessor and they're treating
*  each one of these things as a sort of chip, and then they're going to scale it up to the size of
*  a neocortex. And that, listen, that might work. We'll see. I have no idea. No one really knows yet.
*  But it's just important to point out that that isn't even found, that isn't even a widely like
*  agreed upon concept that the column is, is the foundational unit in the neocortex.
*  Let's say it's fairly agreed upon, but not universally.
*  Okay. Not universally.
*  Yeah. I really, Milan says, I really appreciated your metaphor of kahal at the end. I'll say Ramon
*  e Kahal. Milan, you're supposed to always say Ramon e with the kahal is what I learned at some
*  point. Did you spend some time with Henry's family and son?
*  I didn't get to spend time with his son because he lives in Israel, I believe, and still, and
*  I never made it there for the film, but I spent a bit of time with him and his family in Lausanne,
*  and that was his two daughters and his wife, Camilla, who's in the film briefly. So
*  they were very warm to me and yeah, I was at their home. I spent some time with them.
*  So back to science real quick, and I don't know if you'll have an answer for this.
*  Sammy asks, how scientifically relevant does the community
*  consider those oscillations that emerged after reaching a certain scale?
*  I can't speak to the community, but I can speak to the... I included a bit of the community in the
*  response to that work in the film. When that work came out, Corey Bargmann and Zach Manon were
*  quoted. Zach Manon being one of the fiercest critics of this project coming from his original
*  co-authorship of The Open Letter with Alex Puget. He was very enjoyable in the film, by the way.
*  Yeah, he was a wonderful interviewee, and I thought he had great stuff to say.
*  For me, it was nice to interview an American over there. He was in Portugal, so I went to Lisbon to
*  interview him. But I just noted that he was less than impressed by what they had shown, the
*  oscillations they had shown in The Slice. Corey Bargmann also said, it's a nice start, but
*  there's a lot to do before this airplane takes off or something. So I did monitor the response a bit,
*  and I felt like it was tepid. I felt like the community didn't feel like this was a revelatory
*  signature of life or something inside the simulation. I didn't get that sense, and maybe
*  people can correct me if they feel otherwise. But I felt like people saw this as a
*  magnum opus of methodology to get of how to do a hyper detailed simulation,
*  not necessarily that the effects coming out of it were all that revelatory or impressive.
*  Okay, so by the way, in a weird twist of fate or coincidence, I guess on Monday,
*  perhaps, I think it's on Monday, I'm interviewing someone from the Human Brain Project who gets
*  funding from the Human Brain Project and who does this super detailed bottom-up modeling.
*  So it'll be interesting. I'm going to send him this video, and it'll be interesting to get his
*  reaction to the movie as well. So it would be fun to do another one of these live things with him,
*  but I'm not sure that that's going to happen. Well, just to say briefly before you move on,
*  I have found that in some of the early screens we've done with this film, some people have
*  thought that this is like the film about the Human Brain Project. It really isn't. I only
*  went into the Human Brain Project briefly with Henry when he was steering the ship there and
*  when he proposed the idea, went through all the hoops to get it funded. And a lot of people give
*  him credit for that, rightly so. I mean, he led a neuroscience project to winning this flagship
*  grant that could have gone to any other field, and a lot of scientists continue to get funding from
*  it and do really interesting work, as I'm sure your guest will talk about. So Henry did that.
*  There was a lot of problems with his leadership style that people had, and it's a mixed bag,
*  as much of this is. But I didn't continue to follow the Human Brain Project in any way. As
*  soon as Henry was mediated out of his leadership position, I went right back to the Blue Brain
*  Project and continued to make my film about that. And I don't purport to have told or continued,
*  you know, that like the Human Brain Project is its own can of worms and that it has retooled itself
*  in what looks like a more promising direction and they are doing other work now. So I just wanted
*  to say that. And generating methodologies and technologies that are clearly going to be useful.
*  Okay, this is a comment from Anna, and I was going to ask, and then I'll follow up with a
*  question I was going to ask you anyway. She says, I'm in a social environment where people are very
*  confident about, quote, short AGI, artificial general intelligence timelines, end quote.
*  This is so back to the timelines. I'm curious to see how that will actually develop. So my question
*  for you is, you know, future projects wise, I know that you're kind of taking a break from
*  neuroscience documentation, but you know, the AGI community is filled with many colorful characters
*  and very smart people, of course. So maybe it's not a question. Maybe it's a comment. That would be an
*  interesting, Nick, you should be the timeline, the 10 year timeline documentary person. Auditor.
*  Auditor. Yeah. Yeah. Okay. That's a good way to put it. But have you, do you have a, okay,
*  so this will lead into my next question, but do you have a sense of the AGI community? Or is that
*  anything that you're paying any attention to? And do you have a, you know, thinking about your
*  experience with this neuroscience based project? Do you have opinions or perspectives on, you know,
*  the AGI community and their timeline? I guess, you know, you put Ray Kurzweil in the film. So.
*  Yes, right. I do pay attention to it a bit. I mean, I find myself agreeing with the skepticism
*  of Gary Marcus more than I, you know, find myself getting into. People could probably expect that
*  given the tone of my film. I understand why people, again, it goes back to the question before
*  about the psychology of these 10. I just saw a little Twitter debate open up the other day
*  between Gary and someone maybe from OpenAI. He's always debating someone. Yeah. It's like 17 people
*  at a time. That's right. About someone who, you know, was willing to place a bet that AGI
*  would be here in 10 years. And Gary said, okay, well, what do you want to bet? And then he ended
*  up just saying like a T-shirt or something. So I was like, okay, well, that's not much of a bet. But
*  I think like, I would love to make a film about that. I think it's tough to think about doing that
*  now. I'm a little burnt out from doing this. I am paying attention to it, though. I wouldn't
*  have anything that your listeners don't know already to say about it. Just that I definitely
*  am a skeptic and come at from that point of view. But I think I've heard some of your
*  interest in sci-fi right now. Right. So I wrote and directed this narrative feature called Lapsis,
*  which came out last year. And so I'm writing more sci-fi now. And that is sort of what I'm
*  heading towards next. But I do want to go back and forth as time moves on here between documentary
*  and fiction. And I find both to be rewarding in different ways. So I would love to make another
*  documentary at some point. I probably need a little beat, a little time off from it. And then
*  if there's an AGI story to be told, I would love to get involved. Although I might have a somewhat
*  critical take on the timelines. There are always AGI storytellers. I don't know if there's a story
*  to be told, however. Right. Exactly. Okay. So this takes me to my next question. So this podcast is
*  Ostensibly, although we talk about a lot of different things about the intersection of
*  neuroscience and artificial intelligence. And I don't know how much you have followed
*  the artificial intelligence boom since 2012, the deep learning revolution. And now you have all
*  these large language models that are just scaling and scaling. So A, just generally, do you have
*  perspective and thought about the artificial intelligence push? I know that you are
*  sympathetic with Gary Marcus, but that's AGI we were just talking about.
*  And then I'm curious. So that happened in, let's say the deep learning revolution,
*  quote unquote, took off in 2012. Although there are many advances before that as well. But that's
*  when convolutional neural networks really came on the scene. And then from then there have been
*  other kind of milestones and landmarks. And people are using, neuroscientists are using these
*  artificial intelligence, machine learning models to say, try to understand how the brain is doing
*  things and look at the dynamics and compare the activity of the models to brain areas, et cetera.
*  Was there any talk about that within the people that did AI ever come up as an alternative means
*  to understand our brains? Because the flip side of that is these super detailed simulations, right?
*  In some sense, you could say it's the flip side. Were there any conversations had about that? And
*  then I don't know if you just have a general perspective on it.
*  Yeah, it is the flip side. So what did come up often was a real skepticism and a disdain for
*  what was seen as the overhyping. And over, it was so funny to hear that it was sort of like,
*  yeah, well, you guys think that they're overselling something? That's interesting.
*  But so there was a lot of criticism from them. And I put a little bit of it in the film
*  about Google's big triumph with AlphaGo beating that player in Go. So I put a little bit in the
*  film of that because I thought that was just, it was interesting to see their disdain for this
*  project that was announcing this amazing achievement in AI and whatever. So there was
*  talked about like that. And there's also even going back further, there was in the beginning,
*  when I first got involved in the project, and this was my first whiff of criticism,
*  but I didn't take it seriously was when Henry Markham was beginning and was really involved
*  with IBM because they were supplying the machinery. There was an IBM researcher named
*  Dharmendra Modha, I believe, who had come out around that time with what he was calling like a
*  a point neuron model of a cat brain or something. There was some sort of point neuron model he'd
*  come out with. It was getting a lot of hype. Henry wrote some sort of open letter about
*  about Modha's point neuron model being very critical of it. And I remember it because it
*  was an early taste of what became even a wider rift between these two projects and these two
*  efforts, a really hyper detailed simulation of the brain from the bottom up, and a deep learned
*  convolutional neural net built model that was extracting principles of biology, as we've talked
*  about, but wasn't worrying about glia and vasculature. So I don't, you know, I think that
*  that might be a bit of a false rift, as you've identified that there's ways in which the tools
*  of AI now will be able to cross the rift and help. And I've heard of that from other labs.
*  It's not really something I followed in this film, but, you know, automated techniques to
*  improve understanding of the brain, basically foisting AI upon, I know this is something you
*  talk about a lot on the show, but using the techniques of AI to improve biological neuroscience
*  and to speed things up and to automate things so that humans don't have to spend hours at the bench
*  doing them and all of that fun stuff. I will say that something else to note here, which I
*  happened a bit after my film was done, but it might be interesting to your audience, is that
*  Henry ended up doing a spin-off company called Innate, and they have a website up people can
*  check out. It's I-N-A-I-T, and it's an AI startup that he has in Lausanne where he's using insights
*  from the Blue Brain Project to basically, it feels like what they're doing from their website
*  is to create like a sort of Watson-styled AI model that could be useful for businesses.
*  And so it seems like, I don't know if they have any actual use cases yet or anything, but
*  it's not a Watson. It's not a deep learning network. It is, I don't know exactly what it is,
*  but what they're sort of marketing it as is different than AI because it is from the insights
*  are generated from these hyper-detailed models of real brain. So Henry is now dabbling, it seems,
*  in this sort of like booming business of business services from AI. And there's a long history of
*  publicly funded research being spun off into patents. And so Henry, I also noticed that
*  Henry now has a few patents he's filed about related to the Blue Brain simulation.
*  There's a long history of that, of scientists sort of spinning off into privately,
*  private businesses and filing patents and what have you. But I also noticed that as I talk about
*  in the film, there are a number of researchers who have left Blue Brain and moved to AI. And
*  Elif Mueller is one of the head of the simulation platform moved to Mila in Montreal. And then a
*  couple others now have gone to work more in AI. So there is actually this sort of like
*  highway between the two that I think this rift is a little, I think it's more of a competitive
*  energy than it is a real academic or intellectual rift. There's a lot of crosstalk going on.
*  Do you still consume, enjoy and or believe Ted Talks?
*  I haven't watched a Ted Talks in maybe a decade. I actually don't. I haven't watched a Ted Talk in
*  a long time. I don't listen. I don't have anything against them. I just, I maybe it's a little
*  dangerous. Like if I watch another Ted Talk, I'll make another 10 year film. I don't know. I
*  consume more podcasts these days. You're going to be drawn in. Yeah, it's interesting because
*  right now in neuroscience, there's this, well, at least from the slice that I talk with a lot of
*  people who are into these low dimensional dynamical structures. And it's all about how to relate those
*  to cognition. And I've been around enough to know that, so there's this kind of hype right now in
*  neuroscience. And because there's been a lot of traction using these kinds of methods to relate
*  populations of neural activity to ongoing behaviors and cognition. But I immediately am like
*  skeptical and I don't know how to articulate my skepticism, but it feels good that I'm skeptical
*  because I don't want to make a 10 year documentary about it. I'm also excited about it, but that's
*  kind of the way that I feel about artificial intelligence too and neuroscience writ large.
*  So yeah, do you just, do you sense that you have a more measured discernment when things are
*  being hyped up just in general? Yes, I would definitely say measured. If not, I'm just more,
*  I am more critical now. And I don't think that this is the type of person who would start making
*  a 10 year film again. Like yes, when you do have that kind of criticism as a filter for what comes
*  in now, you have to check that too. It's important to check your own criticism and your own bias and
*  not overlook something that is, I listen with care because I really respect her work. And
*  someone who I've been interested in a long time in neuroscience, who I've felt like is very different
*  from Henry. Yves Martyr. Ah, you got it. I thought you might. Yeah, that's Yves Martyr. So I've
*  listened with care to your recent talk with her because I just think she's fantastic. And
*  you know, I think that, and she was, so I was interested with what she had to say about modeling
*  and about where these machines might take us. And she seems, you know, a bit on the positive side
*  about. Yeah. Yeah. So that's nice to hear. And it actually made me look at my, you know, think to
*  myself for a second and go like, I got to be open to this stuff still, because, you know, look at
*  this amazing scientist who's focused on the same little network. And, you know, it's only little
*  from our point of view. It's a vastly complex network in the gut of a lobster for all these years.
*  And, you know, she's stayed open to the possibilities of machine learning and modeling. And
*  she's continued to use modeling in her work very effectively. So it's important to stay open. I am,
*  I am more, my criticism actually comes more from the sort of like cultural and political implications
*  of some of this work where I see that I worry that the AI hype machine kind of leads to
*  a culture where these things are used for, you know, labor surveillance and like,
*  like the actual applications of AI in our world have so much more to do with the ways in which
*  our market, the marketplace, our economy, and the way in which, you know, labor is organized these
*  days is broken. And I worry about, you know, I have much more sympathy with the kind of like
*  ethical criticisms of AI. And I hope that those are taken more seriously as time goes on too.
*  And aren't just ethics for ethics sakes and sort of like nice dressing up on the top of the
*  AI cake, but actually get baked into the cake itself. Something else that has bothered me again,
*  this is just more of a comment. Something that has bothered me is hero worship in science because,
*  you know, people are there, there is hero worship across, you know, all different sectors in society
*  and stuff. But I think as well, especially in AI, talking about the godfathers of deep learning and,
*  you know, people are worshiped like Jeff Hinton, Jan LeCun and stuff. And I have a really measured
*  take on that as well. I think, you know, admiration is one thing, but it's borderline worship
*  in many cases. And do you, you know, within Blue Brain, did you see any kind of hero
*  worship of its leader? Yes, this is this is probably important to continue doing work,
*  speculative work that doesn't have, you know, you're not, I think as a human being,
*  when you're doing work, and I felt this with my film too, like it's hard to not release,
*  this is why I was releasing stuff in those first five years. You want to have a dialogue with
*  other people in your community. You want to be either feel like you're helping them by providing
*  insights through the podcasts you're releasing or the episodes of your yearly film update you're
*  releasing. And as a scientist, I can imagine, although I've never done it myself, you want to
*  feel like the work you're doing has an actual impact in your lifetime in the community of
*  humans you live amongst. And when you're doing such a long term speculative project that's building
*  a model from the bottom up over so much time, and it's starting with a mouse, and you might not even
*  get to the it's like a cathedral, you know, it's like you're building, you might not in your
*  generation ever see this thing finished. What keeps you in it? What keeps you bound to the work? And
*  I think it is a deep part of our psychology that hero worship and the following of a powerful
*  leader is something that can keep you doing work. And I think we've all felt that to a degree.
*  And it, you know, it might feel a little dirty after the fact, but like when you get out of
*  that and you're like, Oh, God, I what you know, what was I taken with there, but I think we've
*  all been there. And I did feel a bit of that the project, I mean, everyone talked, talked with this
*  same vocabulary about the vision of the project. And there's actually a wonderful anthropologist
*  named Tara Mahfoud, who did her dissertation on the on the Blue Brain project. And I was there
*  overlapping with me a bit. So she's written a very academic text, but nicely academic, like it goes,
*  it's much more able to be much more detailed than my film can be about this kind of thing
*  we're talking about about the sort of sociological dynamics within that project and the leadership
*  style and this use of the vision as this kind of, you know, shining light on a hill that everyone
*  was walking towards. And that I think it happens with these figures you're talking about. It helps
*  us walk towards something that is undefined. All right, no, it's been an hour and a half
*  almost here. Before my last question, and if anyone else has any more questions, put it in the
*  chat, or just speak up. But is there anything else from the film that you'd like to highlight?
*  You know, joys, concerns, more terror? And then before I ask you a final question.
*  No, no, I think we've covered a good deal of it. In fact, I don't want to give I don't want to give
*  away too much because I would like people to still go out and watch this movie we've been talking
*  about. Yeah, yeah, yeah, it's a it's a great film. And again, I want to thank you for just letting
*  my podcast supporters screen it, you're getting screen it, I got a couple emails already saying
*  that it was a great film and just appreciative that you did that. So thank you for that.
*  My last question to you is given that so you know, this film has taken you a really long time,
*  and you know, you're kind of done with communicating with the blue brain project.
*  And, and you're kind of done with neuroscience for now. But you're going to release this film,
*  and I know you've done a lot of screening. So you've already gotten a lot of feedback,
*  but you're going to release this film, it's going to go out to a wider audience. Are you
*  prepared for blowback? Are you prepared? You know, maybe my question also is, what has been
*  the feedback? The nature of the feedback? Has it been half positive half blowback? Or it must
*  been a small proportion of blowback? And are you prepared to sort of re engage? And I know
*  we've already just had this conversation, but re engage with those kinds of discussions?
*  Yeah, I'm I'm, I feel like when people watch a film, you know, and want to engage in good faith,
*  criticism, or, or a dialogue, I'm here for it. They've watched the film, they've engaged, I owe
*  it to people to to engage a bit. So I'm not just going to walk away from from this. And if there
*  are conversations to be had, I'm more than glad to have them. I have had a good deal of feedback,
*  yes, already, because we've been doing a lot of screenings around at universities and other
*  institutions for about a year now. And they've been generally, you know, warm audiences and
*  receptive and some, you know, some probing questions about my methodology, and how I went
*  about it, and my relationship with the project. And that's all wonderful. But the certainly the
*  toughest thing has been the dialogue with the Blue Brain Project and with Henry, because,
*  and I think you're kind of asking about that in a way too. But, but that that is difficult,
*  just because I, but I had a feeling was coming because I had seen over the years,
*  every time there was something written, every time a journalist went in and tried to do a piece,
*  and usually the way journalism is done, and documentaries are done, there's a much shorter,
*  you know, time scale. So they come in, they do interviews, they write a piece and wired or and
*  wherever. And that happened many times over the time scale, I was there making my film. So I got
*  to see other journalists come in, talk to Henry, talk to other people, write their piece. And
*  there wasn't much positive press over that decade, to be honest. And it, you know, it culminated in
*  Ed Young and wrote a fairly critical piece, not too long ago, sort of also calling out the fact
*  that this 10 year promise didn't come to fruition, just to remind people of that. So anytime something
*  like that would happen, I would hear from Henry and the project when I would get over there the
*  next time, like, oh, these journalists, no one gets it right, you know, these journalists,
*  basically, just sweeping critique of journalists, journalists trying to understand the project,
*  no one was taking the time, no one was really engaging with the science, and they all got it
*  wrong. And I had a feeling the same would come for me at some point, too, even though I was treated
*  a little differently because of my time scale, I was the one who hadn't released the thing yet,
*  I was still trying to understand, I kept coming back, you know. So when I did release my thing,
*  they had a very sharp, similar response, right directly to me. And I sent the film
*  before I had locked it, locked it to Henry, as a sort of good faith agreement I had with him,
*  where I was going to show him the film, really, for me, it was for fact checking more than his
*  editorial feedback, I wanted to know if I'd gotten, you know, basic things wrong. And they pointed out
*  a couple things like, oh, you use this, you know, clip of a celebration, celebrating the wrong
*  moment and good, I changed some of that, I got the, made sure I fact checked and got that stuff right.
*  They had much more sweeping editorial feedback about my take on the project and my interpretation
*  of the tepidness, let's say, for example, to the reception of their cell paper, stuff like that,
*  which is, which is, you know, they purported to know the objective truth of how their project
*  stands in the world. There is no objective truth about subjective responses to this work. And so
*  I'm not purporting to have made an objective film. I am someone who believes documentaries are
*  always to a degree subjective. Every time you make a cut and assemble something, you're bending
*  time, you're putting someone's words after another person's words, changing the context they're heard
*  in. And that is the editorial process. It's subjective. This is my point of view, this film.
*  And I anticipated the blowback, it happened. Henry, I don't, I believe Henry really doesn't like the
*  film. There was almost a little bit of a legal threat, although I'm very secure, I was almost,
*  I feel very secure in, you know, I, the way I went about it and, and crossing on
*  even close to slander. It's not that like, yeah, yeah. I mean, they, I think that they feel like,
*  like it is and sensitive. So I, you know, I, I'm pretty secure in feeling like it isn't. And,
*  and I, and I'm also buff, buffered by conversations I had that I hope to have with Henry with like
*  someone like Elif Mueller, who's in the film, who was Henry's right hand man for many years. Elif,
*  you know, left the project and when he viewed the film, he texted me right after he said, you know,
*  this is tough for me to watch, but I think you did a really good job. And we, and we had a dialogue
*  for a film festival where we were in, we were, we had like an hour long debate kind of about the
*  film. And that was actually wonderful. I love doing that. And it's productive because people get to
*  see both sides talking to each other. I, the, the behind closed doors, like threatening sort of
*  animosity isn't, isn't helpful because I feel like I did stuff above board and, and was respectful.
*  And by the way, they, I always credit them for, you know, keeping the door open for me and giving
*  me access. Cause that's, that's a difficult thing to do too. I mean, if you're a scientist giving a
*  documentarian access for 10 years, boy, that's a big ask. So they did that. They let me in and,
*  and they're to be credited for that. So I, I, I anticipate maybe some more criticism, sure, but
*  it can't be, you know, it can't be harder for me to, to deal with than the, the relationship
*  with Henry, the fallout I've had with Henry and the project. Cause that was, after 10 years, it's
*  hard to see it just crumble like that, but I kind of had to do it for the independent angle that I
*  took with the film. And that was the sacrifice. Noah, impressive. It's an overused phrase toward
*  the force, but kudos to you for sticking it through and just what, what a hell of a project,
*  man. So congrats again. I hope the premier is fun. Send me a picture with a drink in your hand,
*  please at the, uh, after, uh, after party. So thanks again. And I appreciate you being here.
*  Thank you so much, Paul. It was a great chat and thanks for having me on.
*  I alone produce brain inspired. If you value this podcast, consider supporting it through
*  Patreon to access full versions of all the episodes and to join our discord community.
*  Or if you want to learn more about the intersection of neuroscience and AI,
*  consider signing up for my online course, neuro AI, the quest to explain intelligence,
*  go to brain inspired.co to learn more. To get in touch with me, email paul at brain inspired.co.
*  You're hearing music by the new year. Find them at the new year.net. Thank you. Thank you for
*  your support. See you next time.
