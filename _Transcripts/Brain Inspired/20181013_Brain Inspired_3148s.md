---
Date Generated: February 12, 2025
Transcription Model: whisper medium 20231117
Length: 3148s
Video Keywords: ['neuroscience', 'artificial intelligence', 'machine learning', 'robots']
Video Views: 3523
Video Rating: None
Video Description: Show notes at:
https://braininspired.co/podcast/13/

Dileep and I talk about how his company, Vicarious, aims to create general artificial intelligence for robots, using tons of inspiration from brain structure and function. We also discuss his recent graphical model that, among other things, breaks CAPTCHAs with very few training examples.
---

# BI 013 Dileep George: Vicarious Robot AI
**Brain Inspired:** [October 13, 2018](https://www.youtube.com/watch?v=1XeHyeshoOc)
*  This is a problem that machine learning has to tackle if you want to go after problems [[00:00:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=0.0s)]
*  which are more general AI like. [[00:00:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=6.08s)]
*  How possible is it do you think that focusing on the brain as a guide for developing general [[00:00:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=8.84s)]
*  AI that that could actually limit our potential to go beyond that level of intelligence? [[00:00:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=13.68s)]
*  It doesn't in my mind and I explain why. [[00:00:20](https://www.youtube.com/watch?v=1XeHyeshoOc&t=20.42s)]
*  So one. [[00:00:22](https://www.youtube.com/watch?v=1XeHyeshoOc&t=22.92s)]
*  This is Brain Inspired. [[00:00:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=23.92s)]
*  Hello, this is Paul Middlebrooks. [[00:00:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=32.36s)]
*  You heard at the beginning, they're my guest today, Dalip George. [[00:00:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=39.6s)]
*  Dalip co-founded Numenta with Jeff Hawkins over 10 years ago and most recently he co-founded [[00:00:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=44.2s)]
*  the company Vicarious with Scott Phoenix. [[00:00:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=49.88s)]
*  The goal of Vicarious is to build general AI robots in the long term. [[00:00:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=53.6s)]
*  As you may know, I've had mostly people on the show so far whose goal is to understand [[00:00:59](https://www.youtube.com/watch?v=1XeHyeshoOc&t=59.32s)]
*  the brain, but that's not Dalip's goal. [[00:01:04](https://www.youtube.com/watch?v=1XeHyeshoOc&t=64.12s)]
*  But he does believe that the way to get to general AI in robots is to understand the [[00:01:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=66.84s)]
*  brain. [[00:01:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=72.04s)]
*  It's interesting, we talk about the model that they've developed at Vicarious that does [[00:01:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=73.04s)]
*  things like breaking captures, as you'll hear in the show, but we go on to talk about his [[00:01:17](https://www.youtube.com/watch?v=1XeHyeshoOc&t=77.32s)]
*  most recent work, putting further biological constraints on that model to map it onto what [[00:01:22](https://www.youtube.com/watch?v=1XeHyeshoOc&t=82.64s)]
*  we know about how the cortex is organized so he can have a model that functions and [[00:01:28](https://www.youtube.com/watch?v=1XeHyeshoOc&t=88.72s)]
*  resembles our brains. [[00:01:34](https://www.youtube.com/watch?v=1XeHyeshoOc&t=94.46000000000001s)]
*  And try as I might, I was unsuccessful getting Dalip to just hire me on the spot at the end. [[00:01:37](https://www.youtube.com/watch?v=1XeHyeshoOc&t=97.66s)]
*  I'm going to keep swinging on that though, damn it. [[00:01:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=104.08s)]
*  Occasionally I add extra stuff into the show notes, that's the case for this episode. [[00:01:48](https://www.youtube.com/watch?v=1XeHyeshoOc&t=108.04s)]
*  I link to a nice 10 minute talk that Dalip gives summarizing some of his outlook and [[00:01:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=113.12s)]
*  approaches and some of his work. [[00:01:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=118.08000000000001s)]
*  So check the show notes for that and all of the other stuff that we talk about. [[00:02:01](https://www.youtube.com/watch?v=1XeHyeshoOc&t=121.16000000000001s)]
*  It's at braininspired.co slash podcast slash 13. [[00:02:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=125.16000000000001s)]
*  Remember if you have a question you think I should include for a future guest, send [[00:02:10](https://www.youtube.com/watch?v=1XeHyeshoOc&t=130.56s)]
*  it my way to paul at braininspired.co. [[00:02:14](https://www.youtube.com/watch?v=1XeHyeshoOc&t=134.6s)]
*  If you find value in the show, here's what I would love for you to do. [[00:02:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=138.44s)]
*  Think of a person or two that you'd love to collaborate with on some AI brain related [[00:02:22](https://www.youtube.com/watch?v=1XeHyeshoOc&t=142.6s)]
*  project and of course tell them about the Brain Inspired podcast. [[00:02:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=147.68s)]
*  But also I suggest that you propose with them a weekly mastermind meeting to get the ball [[00:02:33](https://www.youtube.com/watch?v=1XeHyeshoOc&t=153.56s)]
*  rolling. [[00:02:40](https://www.youtube.com/watch?v=1XeHyeshoOc&t=160.56s)]
*  A mastermind meeting, if you don't know, is a term that's often thrown around in the [[00:02:42](https://www.youtube.com/watch?v=1XeHyeshoOc&t=162.0s)]
*  entrepreneurial world. [[00:02:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=165.84s)]
*  It's basically a meeting with other minds where you share your progress on things, ask [[00:02:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=167.52s)]
*  for help and ideas from other members, and you help the other people where you can as [[00:02:52](https://www.youtube.com/watch?v=1XeHyeshoOc&t=172.16s)]
*  well. [[00:02:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=177.52s)]
*  So this was a huge tool in Andrew Carnegie's bag for instance and many others. [[00:02:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=178.58s)]
*  And as we all know, collaboration is always the best way to go. [[00:03:03](https://www.youtube.com/watch?v=1XeHyeshoOc&t=183.78s)]
*  Alright, enough preaching from me. [[00:03:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=187.6s)]
*  You can find Dalip on Twitter, he is at Dalip Learning, that is Dalip Learning, a very good [[00:03:10](https://www.youtube.com/watch?v=1XeHyeshoOc&t=190.96s)]
*  handle. [[00:03:17](https://www.youtube.com/watch?v=1XeHyeshoOc&t=197.56s)]
*  And you can learn more about his company, Vicarious, just go to vicarious.com. [[00:03:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=198.56s)]
*  Okay, here's my conversation with Dalip. [[00:03:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=203.92000000000002s)]
*  Alright, Dalip George, welcome to the podcast and thanks for being here. [[00:03:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=207.88s)]
*  Thanks Paul, great to be here. [[00:03:34](https://www.youtube.com/watch?v=1XeHyeshoOc&t=214.28s)]
*  So Dalip, you've been a busy person. [[00:03:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=216.24s)]
*  You were the co-founder of Numenta with Jeff Hawkins, sort of in the neuroscience world, [[00:03:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=219.36s)]
*  I guess he is famous and infamous. [[00:03:46](https://www.youtube.com/watch?v=1XeHyeshoOc&t=226.08s)]
*  He wrote a book called On Intelligence, which has inspired a lot of people, including me. [[00:03:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=229.54000000000002s)]
*  And so you co-founded Numenta with him and there you developed the algorithms for the [[00:03:54](https://www.youtube.com/watch?v=1XeHyeshoOc&t=234.48000000000002s)]
*  hierarchical temporal memory technology that he uses, that you guys use. [[00:03:59](https://www.youtube.com/watch?v=1XeHyeshoOc&t=239.96s)]
*  And actually that has recently been released as open source software, so people can go [[00:04:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=246.92000000000002s)]
*  and play with it. [[00:04:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=253.48000000000002s)]
*  There is even an HTM school on YouTube. [[00:04:14](https://www.youtube.com/watch?v=1XeHyeshoOc&t=254.48000000000002s)]
*  So yeah. [[00:04:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=258.08s)]
*  Okay, I didn't know about that. [[00:04:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=259.08s)]
*  Those are all recent. [[00:04:21](https://www.youtube.com/watch?v=1XeHyeshoOc&t=261.08s)]
*  I left Numenta in 2010. [[00:04:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=263.40000000000003s)]
*  So a lot has happened there since then. [[00:04:26](https://www.youtube.com/watch?v=1XeHyeshoOc&t=266.16s)]
*  Yeah, right. [[00:04:29](https://www.youtube.com/watch?v=1XeHyeshoOc&t=269.2s)]
*  Well so most recently you have co-founded Vicarious and here is what I think I know [[00:04:31](https://www.youtube.com/watch?v=1XeHyeshoOc&t=271.44s)]
*  about Vicarious. [[00:04:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=276.52s)]
*  So you guys are working on general AI for robots with a long-term vision in mind and [[00:04:37](https://www.youtube.com/watch?v=1XeHyeshoOc&t=277.96s)]
*  you're doing it from the perspective that it's important to understand human brains [[00:04:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=285.28s)]
*  and incorporate features from neuroscience and maybe even to begin with a theory of how [[00:04:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=289.15999999999997s)]
*  human brains work. [[00:04:54](https://www.youtube.com/watch?v=1XeHyeshoOc&t=294.88s)]
*  Now my first question is, I've got a few dollars laying around extra. [[00:04:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=297.16s)]
*  How much can I pay you to buy Vicarious? [[00:05:02](https://www.youtube.com/watch?v=1XeHyeshoOc&t=302.6s)]
*  Yeah, we might be able to accommodate that. [[00:05:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=305.48s)]
*  Okay. [[00:05:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=312.48s)]
*  So in preparation, I'm extremely well prepared. [[00:05:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=313.48s)]
*  I actually looked up the definition of Vicarious just to make sure I had it right. [[00:05:17](https://www.youtube.com/watch?v=1XeHyeshoOc&t=317.44s)]
*  The definition is experienced in the imagination through the feelings or actions of another [[00:05:21](https://www.youtube.com/watch?v=1XeHyeshoOc&t=321.96s)]
*  person. [[00:05:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=327.96s)]
*  So how did you come up with that name and can you just tell me a little bit more about [[00:05:29](https://www.youtube.com/watch?v=1XeHyeshoOc&t=329.91999999999996s)]
*  the company and your current role in the company? [[00:05:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=332.88s)]
*  Sure. [[00:05:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=336.0s)]
*  Vicarious, the name. [[00:05:37](https://www.youtube.com/watch?v=1XeHyeshoOc&t=337.0s)]
*  So this is also reflects our philosophy on how to build intelligence and what is intelligence. [[00:05:38](https://www.youtube.com/watch?v=1XeHyeshoOc&t=338.91999999999996s)]
*  So to experience something vicariously is to experience it through somebody else's eyes. [[00:05:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=345.68s)]
*  And for that, one, you need to have a model of what that person is going through. [[00:05:54](https://www.youtube.com/watch?v=1XeHyeshoOc&t=354.96s)]
*  You need to be able to model some other person and you should be able to see the world from [[00:06:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=360.98s)]
*  some other person's viewpoint. [[00:06:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=366.88s)]
*  And that means modeling is important. [[00:06:09](https://www.youtube.com/watch?v=1XeHyeshoOc&t=369.28000000000003s)]
*  You have to build models, not just about the world of other people in the world and see [[00:06:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=372.38s)]
*  the eyes through there. [[00:06:16](https://www.youtube.com/watch?v=1XeHyeshoOc&t=376.9s)]
*  And that is the ultimate form of intelligence. [[00:06:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=378.18s)]
*  And that's why we chose to name the company Vicarious. [[00:06:21](https://www.youtube.com/watch?v=1XeHyeshoOc&t=381.38s)]
*  And it kind of reflects all our philosophy that models are important. [[00:06:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=385.62s)]
*  It is not just pattern recognition, etc. [[00:06:29](https://www.youtube.com/watch?v=1XeHyeshoOc&t=389.54s)]
*  So as you mentioned, the long term goal for Vicarious is to build human level intelligence. [[00:06:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=392.2s)]
*  And we are doing that by building an AI layer for robotics. [[00:06:41](https://www.youtube.com/watch?v=1XeHyeshoOc&t=401.17999999999995s)]
*  And this is also important because we think understanding the world just like a child [[00:06:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=405.78s)]
*  does. [[00:06:52](https://www.youtube.com/watch?v=1XeHyeshoOc&t=412.02s)]
*  A three year old child has a very good understanding of the physical world around them, can manipulate [[00:06:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=413.02s)]
*  objects, has common sense knowledge about how to interact with objects and has the concepts [[00:06:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=418.9s)]
*  And that three year old child has the mechanism to acquire concepts and to build language [[00:07:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=425.98s)]
*  on top of it. [[00:07:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=432.74s)]
*  For us, that is in our way of thinking, that is the way to build intelligence. [[00:07:14](https://www.youtube.com/watch?v=1XeHyeshoOc&t=434.74s)]
*  Start from the ground up, have a sense of understanding of the world and have it in [[00:07:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=439.74s)]
*  a way such that you can build concepts on top of it. [[00:07:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=443.82s)]
*  And that's why we are using robotics as the domain to drive both the products and the [[00:07:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=447.3s)]
*  research in the company. [[00:07:33](https://www.youtube.com/watch?v=1XeHyeshoOc&t=453.86s)]
*  Yeah, and some of your talks, which I'll link to in the show notes, you give really nice [[00:07:35](https://www.youtube.com/watch?v=1XeHyeshoOc&t=455.34000000000003s)]
*  talks and you show assembly lines, factory workers, just a crowded factory full of factory [[00:07:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=459.82s)]
*  workers a hundred years ago and then you show today and it's still the factory workers and [[00:07:48](https://www.youtube.com/watch?v=1XeHyeshoOc&t=468.0s)]
*  the goal is to replace those factory workers with the robots. [[00:07:54](https://www.youtube.com/watch?v=1XeHyeshoOc&t=474.18s)]
*  It's really nice imagery. [[00:07:56](https://www.youtube.com/watch?v=1XeHyeshoOc&t=476.94s)]
*  Yeah, many of this work is very routine for humans. [[00:07:59](https://www.youtube.com/watch?v=1XeHyeshoOc&t=479.53999999999996s)]
*  It is not challenging, it is pretty routine jobs and it's hard for factories to actually [[00:08:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=485.3s)]
*  find people and retain people to do these kinds of jobs, some of them which might be [[00:08:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=493.38s)]
*  dangerous, some of which are just repetitive and economically not very convenient, etc. [[00:08:17](https://www.youtube.com/watch?v=1XeHyeshoOc&t=497.41999999999996s)]
*  However, it's a problem that is still very hard for robots. [[00:08:24](https://www.youtube.com/watch?v=1XeHyeshoOc&t=504.78s)]
*  It is still very hard to automate because you need some amount of common sense understanding [[00:08:29](https://www.youtube.com/watch?v=1XeHyeshoOc&t=509.7s)]
*  of the world around you so that when the problem structure changes, you can easily adapt to [[00:08:35](https://www.youtube.com/watch?v=1XeHyeshoOc&t=515.98s)]
*  the new situation. [[00:08:41](https://www.youtube.com/watch?v=1XeHyeshoOc&t=521.98s)]
*  So it needs a really powerful AI layer so that robots can adapt to these varying situations [[00:08:43](https://www.youtube.com/watch?v=1XeHyeshoOc&t=523.18s)]
*  which humans are really good at doing. [[00:08:50](https://www.youtube.com/watch?v=1XeHyeshoOc&t=530.1s)]
*  Very good. [[00:08:52](https://www.youtube.com/watch?v=1XeHyeshoOc&t=532.34s)]
*  We're about to talk about one of your recent papers published in Science but before we [[00:08:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=533.34s)]
*  do that, what's something right now that Vicarious is working on that you're excited about? [[00:08:59](https://www.youtube.com/watch?v=1XeHyeshoOc&t=539.1s)]
*  Oh, everything. [[00:09:04](https://www.youtube.com/watch?v=1XeHyeshoOc&t=544.1s)]
*  We are working on the full stack in robotics so that except building hardware, we buy hardware [[00:09:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=547.1s)]
*  so we use off-the-shelf hardware but all the software stack, we are working on all layers [[00:09:16](https://www.youtube.com/watch?v=1XeHyeshoOc&t=556.7s)]
*  of that software stack starting from perception and then closing the perception action loop [[00:09:22](https://www.youtube.com/watch?v=1XeHyeshoOc&t=562.62s)]
*  so that perception leads to good control and then having another layer on top of that which [[00:09:31](https://www.youtube.com/watch?v=1XeHyeshoOc&t=571.34s)]
*  is learning concepts from these sensor-motor interactions so that you can actually convey [[00:09:37](https://www.youtube.com/watch?v=1XeHyeshoOc&t=577.1800000000001s)]
*  a concept to a robot in a very simple way, in a more human-like way. [[00:09:42](https://www.youtube.com/watch?v=1XeHyeshoOc&t=582.38s)]
*  So we are working all the way from perception and action to cognitive level. [[00:09:46](https://www.youtube.com/watch?v=1XeHyeshoOc&t=586.9399999999999s)]
*  And how much sleep are you personally getting these days? [[00:09:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=593.14s)]
*  I do sleep. [[00:09:56](https://www.youtube.com/watch?v=1XeHyeshoOc&t=596.86s)]
*  Sometimes I stay up late but I catch up on. [[00:09:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=598.86s)]
*  Okay, good. [[00:10:02](https://www.youtube.com/watch?v=1XeHyeshoOc&t=602.46s)]
*  Okay, well, so I want to talk to you a little bit about the recent paper that was published [[00:10:03](https://www.youtube.com/watch?v=1XeHyeshoOc&t=603.46s)]
*  in Science called A Generative Vision Model that Trains with High Data Efficiency and [[00:10:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=607.94s)]
*  Breaks Text-Based Captures. [[00:10:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=613.74s)]
*  So you and your team at Vicarious published this. [[00:10:16](https://www.youtube.com/watch?v=1XeHyeshoOc&t=616.9000000000001s)]
*  Now on recent episodes, we've had guests and we've talked a lot about how deep learning [[00:10:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=619.82s)]
*  might be implemented in the brain and how we can understand brains better using deep [[00:10:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=625.1s)]
*  learning methods. [[00:10:30](https://www.youtube.com/watch?v=1XeHyeshoOc&t=630.22s)]
*  But what you do isn't deep learning. [[00:10:31](https://www.youtube.com/watch?v=1XeHyeshoOc&t=631.8000000000001s)]
*  You use what's called the recursive cortical network. [[00:10:33](https://www.youtube.com/watch?v=1XeHyeshoOc&t=633.86s)]
*  It's a model I know with a lot of neuroscience-based features and it performs well on a ton of [[00:10:38](https://www.youtube.com/watch?v=1XeHyeshoOc&t=638.54s)]
*  tasks and benchmarks, including breaking captures. [[00:10:43](https://www.youtube.com/watch?v=1XeHyeshoOc&t=643.1s)]
*  Now I'm just going to explicitly define CAPTCHA. [[00:10:46](https://www.youtube.com/watch?v=1XeHyeshoOc&t=646.86s)]
*  I'm sure everyone knows what a CAPTCHA is. [[00:10:50](https://www.youtube.com/watch?v=1XeHyeshoOc&t=650.98s)]
*  The word stands for Completely Automated Public Turing Test to Tell Computers and Humans Apart. [[00:10:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=653.38s)]
*  So basically, it's these things when you log into a website or download a file or something [[00:11:01](https://www.youtube.com/watch?v=1XeHyeshoOc&t=661.3399999999999s)]
*  like that. [[00:11:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=666.22s)]
*  It's that curvy text that comes up that you enter in to prove that you're a human, essentially. [[00:11:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=667.26s)]
*  Correct. [[00:11:14](https://www.youtube.com/watch?v=1XeHyeshoOc&t=674.26s)]
*  And breaking a CAPTCHA in, I guess, the machine learning world is when a machine can automatically [[00:11:15](https://www.youtube.com/watch?v=1XeHyeshoOc&t=675.26s)]
*  solve it at a rate higher than 1%. [[00:11:20](https://www.youtube.com/watch?v=1XeHyeshoOc&t=680.5400000000001s)]
*  So I have a really naive question, Dalip. [[00:11:24](https://www.youtube.com/watch?v=1XeHyeshoOc&t=684.74s)]
*  Why is the 1% seems like a really low bar. [[00:11:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=687.82s)]
*  Why is that so low? [[00:11:30](https://www.youtube.com/watch?v=1XeHyeshoOc&t=690.52s)]
*  Oh, because if a machine can solve it even at 1%, you can just try 100 times and you [[00:11:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=692.0s)]
*  will get one right. [[00:11:38](https://www.youtube.com/watch?v=1XeHyeshoOc&t=698.1999999999999s)]
*  I see. [[00:11:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=699.52s)]
*  So it is low cost to try, so a machine can easily get through just by trying 100 times. [[00:11:40](https://www.youtube.com/watch?v=1XeHyeshoOc&t=700.52s)]
*  So 1% is kind of a bar that people have said is something achievable. [[00:11:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=707.96s)]
*  Initially, they wanted it to be much lower than that. [[00:11:52](https://www.youtube.com/watch?v=1XeHyeshoOc&t=712.8s)]
*  They wanted it to be 0.01% or something, but that was not even achievable. [[00:11:56](https://www.youtube.com/watch?v=1XeHyeshoOc&t=716.44s)]
*  So they took 1% of the number that is kind of achievable and still meaningful. [[00:12:02](https://www.youtube.com/watch?v=1XeHyeshoOc&t=722.24s)]
*  Oh, OK. [[00:12:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=727.9200000000001s)]
*  I told you it was a naive question. [[00:12:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=728.9200000000001s)]
*  And it's interesting. [[00:12:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=731.96s)]
*  You guys actually had solved this a few years ago, but you waited to publish because at [[00:12:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=733.2800000000001s)]
*  that time, when you had the technology to solve it, CAPTCHAs were mainly the text-based [[00:12:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=739.2s)]
*  ones like I just described. [[00:12:24](https://www.youtube.com/watch?v=1XeHyeshoOc&t=744.1600000000001s)]
*  So hackers and spammers could have used your technology to run rampant, but now a lot of [[00:12:26](https://www.youtube.com/watch?v=1XeHyeshoOc&t=746.52s)]
*  CAPTCHAs use images, so there is less worry about that nefariousness. [[00:12:33](https://www.youtube.com/watch?v=1XeHyeshoOc&t=753.4s)]
*  And you guys felt safe to publish it now. [[00:12:37](https://www.youtube.com/watch?v=1XeHyeshoOc&t=757.12s)]
*  Also, I know you tested your model on a lot of different tasks and a lot of known benchmarks, [[00:12:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=759.92s)]
*  and you tested against a lot of other models. [[00:12:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=765.4399999999999s)]
*  And it excelled across the spectrum of tasks and other models. [[00:12:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=767.64s)]
*  So for simplicity and time constraint, we will focus on how it breaks CAPTCHAs. [[00:12:50](https://www.youtube.com/watch?v=1XeHyeshoOc&t=770.58s)]
*  So why is breaking CAPTCHAs a good problem to work on, or why is it a good benchmark? [[00:12:55](https://www.youtube.com/watch?v=1XeHyeshoOc&t=775.88s)]
*  Yeah. [[00:13:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=780.88s)]
*  So CAPTCHAs are a very nice example for the generalization power of human brains and human [[00:13:01](https://www.youtube.com/watch?v=1XeHyeshoOc&t=781.6s)]
*  vision. So I can show you a new CAPTCHA, which is created in a completely new style, maybe [[00:13:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=792.32s)]
*  different clutters, different way of occluding letters, different way of filling in the letters, [[00:13:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=799.36s)]
*  and you would have no trouble understanding what the letters are parsing out the letters from the [[00:13:24](https://www.youtube.com/watch?v=1XeHyeshoOc&t=804.8s)]
*  CAPTCHA, understanding what the occlusions are, etc. If you think about it, it is miraculous, because [[00:13:31](https://www.youtube.com/watch?v=1XeHyeshoOc&t=811.84s)]
*  it is completely off the training distribution. You are mostly trained on clean fonts when we grow [[00:13:38](https://www.youtube.com/watch?v=1XeHyeshoOc&t=818.88s)]
*  up. And even if I show many of these CAPTCHAs to a five-year-old child or four-year-old child who [[00:13:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=825.28s)]
*  have just learned to parse the characters, they can still parse the CAPTCHA without having to get [[00:13:51](https://www.youtube.com/watch?v=1XeHyeshoOc&t=831.92s)]
*  any training data from that particular style of CAPTCHA. And this is not the way current pattern [[00:13:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=837.76s)]
*  recognition systems work at all. If you need to solve a particular CAPTCHA, you need to give it [[00:14:03](https://www.youtube.com/watch?v=1XeHyeshoOc&t=843.52s)]
*  lots and lots of training examples from that particular CAPTCHA in the same distribution, [[00:14:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=848.9599999999999s)]
*  and then it will learn to parse that CAPTCHA. But if you change the distribution, even in terms of [[00:14:14](https://www.youtube.com/watch?v=1XeHyeshoOc&t=854.4s)]
*  moving the characters a little bit further away from the training distribution, the current pattern [[00:14:20](https://www.youtube.com/watch?v=1XeHyeshoOc&t=860.64s)]
*  recognition systems will break. So CAPTCHAs in our mind, and it is true, it shows the generalization [[00:14:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=865.12s)]
*  power of humans, that you can just train on data that looks completely different from the test data [[00:14:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=872.88s)]
*  in terms of the distribution, and humans still do fine. And this is a problem that machine learning [[00:14:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=879.2s)]
*  has to tackle if you want to go after problems which are more general AI-like. And that's why [[00:14:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=884.88s)]
*  we took CAPTCHA as an example problem to tackle. And I mentioned this in my talks, Douglas [[00:14:51](https://www.youtube.com/watch?v=1XeHyeshoOc&t=891.2s)]
*  Hofstadter, who is one of the famous AI researchers and philosophers, he had this quip that the central [[00:14:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=898.16s)]
*  problem in AI is to understand the letter A. And that is true. If you can solve the problem of [[00:15:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=906.72s)]
*  what is the letter A, and if you can recognize the letter A in all circumstances, you have actually [[00:15:15](https://www.youtube.com/watch?v=1XeHyeshoOc&t=915.44s)]
*  made a good amount of progress towards the general AI question. So I'm making it a habit now to [[00:15:21](https://www.youtube.com/watch?v=1XeHyeshoOc&t=921.12s)]
*  come down on his famous book, Douglas Hofstadter's Girdle Escher Bach, and how it's way too long. [[00:15:29](https://www.youtube.com/watch?v=1XeHyeshoOc&t=929.6s)]
*  But there are other books which are more relevant for AI. I like the book. I think one was called [[00:15:34](https://www.youtube.com/watch?v=1XeHyeshoOc&t=934.8000000000001s)]
*  The Mind's Eye or something. Yeah, I think that was with Daniel Dennett, maybe. [[00:15:43](https://www.youtube.com/watch?v=1XeHyeshoOc&t=943.28s)]
*  Okay. Yeah, I like that book a lot. And so yeah, there are some, you know, GEB is definitely hard [[00:15:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=949.12s)]
*  for me to penetrate. But there are other, right, which I found to be much more useful for AI. [[00:15:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=957.12s)]
*  Yeah. Well, I was going to say that that statement about understanding the letter A is one of the [[00:16:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=965.04s)]
*  most succinct things that I've heard from him. So that's good. Okay, so before we talk about [[00:16:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=968.4s)]
*  the recursive cortical network, the technology that you use, so this is the Brain-inspired podcast. So [[00:16:16](https://www.youtube.com/watch?v=1XeHyeshoOc&t=976.0s)]
*  can you describe just a few of the principles from neuroscience that are included in the RCN? [[00:16:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=983.2s)]
*  Should we call it the RCN? I don't know. What do you call it? Yeah, we call it RCN. Yes. Okay. [[00:16:29](https://www.youtube.com/watch?v=1XeHyeshoOc&t=989.28s)]
*  And so can you describe a few of the principles from neuroscience that are included in it and [[00:16:34](https://www.youtube.com/watch?v=1XeHyeshoOc&t=994.16s)]
*  why it was important to do that? Yeah, so we did use a lot of insights from neuroscience to [[00:16:38](https://www.youtube.com/watch?v=1XeHyeshoOc&t=998.24s)]
*  design the representational choices of this model. And this is also tied with our overall philosophy. [[00:16:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1007.4399999999999s)]
*  So if you can, if you think about machine learning problems in general, if you do not make [[00:16:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1013.52s)]
*  too many assumptions, if you try to learn tabula rasa, you know, just a blank slate, then you need [[00:16:59](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1019.52s)]
*  enormous amount of training data, and it might not generalize from the training distribution. [[00:17:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1028.6399999999999s)]
*  So you will be just capturing the training distribution and it won't generalize. [[00:17:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1033.44s)]
*  Whereas if you want to generalize to new things, then you have to make assumptions. You have to [[00:17:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1039.2s)]
*  put assumptions into the model. Now, if you make too many assumptions, then you are building [[00:17:28](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1048.0s)]
*  a specific circuit for a specific problem. So that doesn't generalize as well. So evolution [[00:17:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1052.96s)]
*  through millions of years of experimentation has figured out this, like, you know, Goldilocks [[00:17:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1059.52s)]
*  magical structure, which makes just the right amount of assumptions to be general enough. [[00:17:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1064.4s)]
*  But at the same time, it is specific enough so that you can learn quickly and generalize to [[00:17:50](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1070.32s)]
*  distributions that are outside the training distribution. So that's the way we look at [[00:17:56](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1076.16s)]
*  the visual cortex. And when we look at the whole cortex, we look at it to see what are the genetic [[00:18:01](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1081.04s)]
*  assumptions that we can get from this new cortex, you know, that will make your model [[00:18:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1088.08s)]
*  more specific than a tabula rasa model, but still very, very effective in solving the [[00:18:14](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1094.6399999999999s)]
*  very broad domain of problems. So for example, our model, RCN, will be terrible at solving [[00:18:21](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1101.6799999999998s)]
*  QR codes. If you want to classify QR codes, our model will be terrible at doing that. [[00:18:30](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1110.56s)]
*  Just like humans, if you try to show different QR code patterns to a human and ask them to ask [[00:18:37](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1117.12s)]
*  them to recognize it, you know, okay, they will be terrible. So that shows that the visual cortex [[00:18:42](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1122.3999999999999s)]
*  is not just completely general pattern recognition system. Deep neural network will be fine in [[00:18:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1129.12s)]
*  recognizing these QR codes. So the brain is making some assumptions that lets you that doesn't let [[00:18:54](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1134.08s)]
*  you model QR codes very efficiently, but lets you deal with captures and natural images very [[00:19:01](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1141.76s)]
*  effectively. So that's the philosophy, you know, with which we look at the neocortex. What are those [[00:19:09](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1149.28s)]
*  assumptions that, you know, lets you do this thing? And I can go through some of the properties that [[00:19:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1153.92s)]
*  we observed from cognitive science and neuroscience and use those as the presentational choices in our [[00:19:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1159.36s)]
*  model. One is this idea about factorizing objects and backgrounds, representing objects as different [[00:19:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1165.92s)]
*  from the background. And then having this idea about object based top down attention. So even when [[00:19:33](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1173.6000000000001s)]
*  objects are overlapping completely in space, if you have transparent objects that are overlapping, [[00:19:41](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1181.3600000000001s)]
*  humans have the ability to separate out in a top down manner, oh, these are the features or contours [[00:19:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1187.1200000000001s)]
*  belonging to object number one, and these are the features or contours belonging to object number two. [[00:19:52](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1192.88s)]
*  And so you use something called top down attention. So this is, we took this idea that you have to [[00:19:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1197.68s)]
*  be able to do top down attention on this model seriously. So that brings in some constraints [[00:20:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1205.1200000000001s)]
*  on what kinds of models can do that. Not all kinds of models can do this top down attention. [[00:20:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1211.92s)]
*  Another idea is the property about contours versus surfaces being represented on separate channels, [[00:20:17](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1217.04s)]
*  but they do interact, but they are represented in a factorized way. And where this is useful is, [[00:20:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1227.1200000000001s)]
*  if I show you a chair made of ice, for example, and you have never seen a chair made of ice, [[00:20:34](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1234.64s)]
*  you can still recognize it because you model the shape of the object [[00:20:41](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1241.04s)]
*  separately from the appearance, whatever texture, I might paint it in a different color and you can [[00:20:46](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1246.3999999999999s)]
*  still recognize it. So that's the property of the visual system that we wanted our model to have. [[00:20:51](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1251.9199999999998s)]
*  So we put in a scaffolding in our model, which lets it have this property. So those are examples [[00:20:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1257.28s)]
*  of insights that we use from neuroscience. And I have more, so I just wanted to see whether you [[00:21:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1265.76s)]
*  have any questions on that. No, no, I mean, that's a great place to start, I think. So I know that [[00:21:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1272.24s)]
*  there are a lot more actually. Yeah. So another one is feedback. So this is a big one. So in the [[00:21:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1278.72s)]
*  brain, while you are doing recognition, feedback connections are just as active or more active [[00:21:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1287.36s)]
*  compared to feed forward connections. In fact, feedback connections are more numerous compared [[00:21:35](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1295.12s)]
*  to feed forward connections in our visual cortex. And feedback connections are largely ignored in [[00:21:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1299.9199999999998s)]
*  multilevel perceptrons or deep neural networks. And so we asked, what is the role for this feedback [[00:21:48](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1308.7199999999998s)]
*  connections? What is the computational property? And people have studied this, of course, people [[00:21:56](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1316.4799999999998s)]
*  have studied it, saying that, okay, this is, you know, the feedback connections are part of doing [[00:22:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1320.96s)]
*  inference, a Bayesian inference. So visual cortex is doing inference rather than just pattern [[00:22:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1326.4s)]
*  recognition. And people have hypothesized the roles for these feedback connections. And for us, [[00:22:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1332.0s)]
*  having the feedback connections was crucial. Without that, we wouldn't be able to solve [[00:22:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1339.76s)]
*  captures with the data efficiency that we had. And we do give examples of this in the paper. [[00:22:24](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1344.64s)]
*  So what often happens is that you, you know, locally, when you look at part of the image [[00:22:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1352.72s)]
*  in a complicated capture, you can see letters that are created by combinations of other letters. [[00:22:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1359.1200000000001s)]
*  And these are kind of previous patterns that you will see if you look locally. So the only way [[00:22:46](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1366.3200000000002s)]
*  humans are not confused by that is because you can explain away that evidence based on the presence [[00:22:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1373.6s)]
*  of other letters. And this idea of explaining evidence is inference. And this requires not just [[00:22:59](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1379.4399999999998s)]
*  feed forward connections, actually have feedback connections. And, and they, the feedback connections [[00:23:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1387.6s)]
*  need to be active all the time. When we are doing, you know, visual inference. So this was another [[00:23:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1392.8s)]
*  crucial piece that we, you know, it is well known in neuroscience that this exists. And people [[00:23:20](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1400.56s)]
*  explain it from different angles, that the Bayesian inference or predictive coding, etc. And, [[00:23:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1407.28s)]
*  but this was one case where we completely showed its use in a large scale visual perception task. [[00:23:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1412.08s)]
*  Well, so I, you know, I have a neuroscience background. Plus, let's be honest, I'm just not [[00:23:41](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1421.04s)]
*  that bright. So I found the paper pretty challenging, actually. So, and I have to [[00:23:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1425.04s)]
*  confess, I got a little lost in some of the technical details and features of the [[00:23:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1433.68s)]
*  recurrent cortical network model, RCN model. So do you want to just give a high level description [[00:23:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1438.08s)]
*  of the RCN and how it works? Sure. So it's easiest to understand if you have a background in [[00:24:02](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1442.96s)]
*  probabilistic graphical models. Okay. But let me try to explain it in, like, you know, [[00:24:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1451.68s)]
*  so maybe I can make a distinction between neural networks and graphical models, and that will, [[00:24:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1459.2s)]
*  that will anchor it. Great. So one way to think of, so, you know, neural networks, you know, [[00:24:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1465.28s)]
*  people are more familiar with neural networks now, because of the deep learning revolution. [[00:24:30](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1470.6399999999999s)]
*  And so an input to a neural network is always a pattern, you know, it doesn't matter what the [[00:24:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1476.16s)]
*  input is, the neural network will treat it like a pattern. It will treat it as a vector of numbers. [[00:24:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1484.24s)]
*  And the output, of course, you can train it to mean, you know, probability distributions or [[00:24:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1489.28s)]
*  another pattern. So the input is always treated as a pattern. The output, you can train it to [[00:24:55](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1495.76s)]
*  have semantics associated with them. You can say, oh, the, this number represents the probability [[00:25:01](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1501.92s)]
*  of a particular class being active in the image. So in graphical models, it's one, there are no [[00:25:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1507.92s)]
*  inputs and outputs. Like, you know, every node can be an input or an output. And the inputs and [[00:25:15](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1515.8400000000001s)]
*  outputs both have this semantics associated with them. They're all statements about something. So [[00:25:21](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1521.76s)]
*  when I say a node in our model, the input to that is the number 0.9. That means it's a statement [[00:25:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1527.76s)]
*  about that node being on versus off. The probability of that is 0.9. So at a rough level. And [[00:25:34](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1534.8s)]
*  the second thing about the graphical model is that information flows in all directions all the time. [[00:25:43](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1543.92s)]
*  It is not, so a graphical model you can think of is a set of states or random variables. And the [[00:25:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1549.84s)]
*  connections between them, which are modeled in these nodes called factors. So we have the random [[00:25:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1558.32s)]
*  variable nodes and the factor nodes and factor nodes model the correlations or dependencies between [[00:26:03](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1563.92s)]
*  these states. And once you have a network of these random variables and factors, then you can ask [[00:26:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1571.84s)]
*  questions like, if I have more evidence for this pixel being on, which, you know, that pixel [[00:26:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1579.52s)]
*  corresponds to a random variable, what will be the effect of, how will it change my belief that [[00:26:26](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1586.08s)]
*  this image is a dog or a cat? You can ask questions like that. Or you can ask questions like, [[00:26:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1592.24s)]
*  if somebody tells me that this image is more likely to have a dog or a cat, how likely, you know, [[00:26:37](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1597.28s)]
*  how does this change my belief on this pixel being on? So you can ask questions in many, [[00:26:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1604.24s)]
*  different ways. Or you can ask the question, if I have a dog in the image, how does it change [[00:26:50](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1610.8799999999999s)]
*  my belief on a cat being also present in the image? So once you have built this graphical model, [[00:26:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1618.72s)]
*  you can ask it many, many different questions than, you know, what you are actually, you know, [[00:27:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1625.76s)]
*  when you train a graphical model, you're training it to just model the data. You are not training [[00:27:10](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1630.24s)]
*  it to answer a particular question. Then you can ask it then different questions during different [[00:27:14](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1634.56s)]
*  times. So that's, you know, I just wanted to give that as a very simple tutorial on the [[00:27:20](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1640.56s)]
*  neural distance between neural networks and graphical models. And now, our model, like, [[00:27:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1647.2s)]
*  you know, the RCN is a probabilistic graphical model. So you construct it, you train it to model [[00:27:34](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1654.08s)]
*  the data. And then you all the other questions, you know, classification, segmentation, [[00:27:41](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1661.6s)]
*  reasoning about occlusions are all questions that you ask this model after after training, [[00:27:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1667.76s)]
*  you are not training it to answer that particular question. And so how does it model images? So as [[00:27:52](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1672.7199999999998s)]
*  I mentioned, so you, you do have good assumptions into the structure of the model, so that images [[00:28:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1680.32s)]
*  are constructed of objects and backgrounds, and objects are constructed of contours and surfaces. [[00:28:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1686.32s)]
*  So these broad assumptions are there in the model. But, you know, what kind of features do you use [[00:28:14](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1694.6399999999999s)]
*  for the contours? What kind of features do you use for the surfaces? Those are all learned from [[00:28:21](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1701.12s)]
*  the data. But the idea that, you know, there are contours and surfaces as two separate things, [[00:28:26](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1706.48s)]
*  and how they interact is, is an assumption in the model. So you structure these broad assumptions [[00:28:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1712.64s)]
*  of the graphical model. And some parts of this structure are similar to the structures that we [[00:28:40](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1720.5600000000002s)]
*  find in convolutional neural networks. For example, the idea that the contour features [[00:28:46](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1726.0s)]
*  do local feature detection, and then pooling, and then do again, another local feature detection, [[00:28:51](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1731.8400000000001s)]
*  and pooling on top of that and gradually build a cone, you know, feature hierarchy, that is [[00:28:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1737.76s)]
*  somewhat similar to the structure that we find in convolutional neural networks. [[00:29:04](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1744.4s)]
*  The difference is that one, the features are generative. So it is not just discriminative [[00:29:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1748.24s)]
*  features, you can take a feature at any intermediate level and sample from it so that [[00:29:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1753.76s)]
*  it will generate all the way back into the pixel space. So you can associate features at intermediate [[00:29:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1759.36s)]
*  levels with the patterns that they are associated with in the input. That is one difference. Another [[00:29:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1765.2s)]
*  difference is that we also have lateral connections between these features. And lateral connections [[00:29:30](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1770.96s)]
*  are important because, again, this is another insight that we use from biology, lateral connections [[00:29:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1776.48s)]
*  enforce contour continuity. So when you have features which are local, and when you pull over [[00:29:42](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1782.32s)]
*  those features, you lose some amount of constraints between these features. So you can think of a [[00:29:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1789.68s)]
*  horizontal line in one location and another horizontal line in a slightly transverse location, [[00:29:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1797.2s)]
*  and if you pull over them, then you lose the relative positioning between them. And lateral [[00:30:02](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1802.16s)]
*  connections bring that relative positioning back and enforce some amount of contour continuity, [[00:30:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1808.0s)]
*  while also keeping the flexibility of these pools. So this is another insight that we use from [[00:30:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1813.68s)]
*  biology. So the contour hierarchy is in some way similar to a convolutional neural network [[00:30:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1818.4s)]
*  in the structure, but in many ways dissimilar because of the generative structure and because [[00:30:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1825.68s)]
*  of the lateral connections. And then this contour structure interacts with a surface model, [[00:30:31](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1831.92s)]
*  and the surface model is reasonably easy to understand. It's pretty intuitive. What the [[00:30:37](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1837.2800000000002s)]
*  surface model is saying is that if I see a patch of surface in one location in space, [[00:30:42](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1842.72s)]
*  I am expecting to see similar patches in nearby locations. So if I see a small patch and it is [[00:30:48](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1848.8s)]
*  blue, then I am expecting to see blue patches as its neighborhood. And the way this model, [[00:30:54](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1854.48s)]
*  this surface model interacts with the contour is that I expect this to be similar, except when [[00:31:01](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1861.28s)]
*  there is a contour in between. So surfaces will be roughly of the same characteristics, [[00:31:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1866.0s)]
*  except when there is a contour breaking their property. And so that's how the surfaces and [[00:31:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1872.4s)]
*  contours interact in the model. That's great. And well explained. Thanks. So [[00:31:17](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1877.0400000000002s)]
*  a major strength of the RCN is its efficiency. So most machine learning models, like deep neural [[00:31:24](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1884.72s)]
*  networks and stuff, require tons of training examples. And the RCN achieved good accuracy [[00:31:33](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1893.0400000000002s)]
*  with just five training examples, at least on the CAPTCHA data. So it achieved 66% [[00:31:38](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1898.72s)]
*  breaking, I supposed. And whereas humans, on average, I guess, break the CAPTCHAs at 88%. [[00:31:46](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1906.48s)]
*  That might even be high for me. I don't know. So how does it achieve such training efficiency? [[00:31:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1913.04s)]
*  Is it the inference that you were mentioning previously? It's the combination of all the [[00:31:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1918.24s)]
*  things that we have done. Basically, we have put more assumptions into the model. So we [[00:32:02](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1922.8s)]
*  assume that an image is constructed of objects and background. That is an example of the [[00:32:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1928.48s)]
*  assumption that goes in. We assume that objects are composed of contours and surfaces. So those [[00:32:15](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1935.92s)]
*  two assumptions plus the way in which we do inference, it's a confluence of those things [[00:32:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1943.52s)]
*  that lead to the data efficiency. So you keep mentioning the assumptions, and a lot of these [[00:32:30](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1950.16s)]
*  assumptions that you build into the model are brain-based. But I suppose the goal of engineering [[00:32:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1956.24s)]
*  in general isn't to capture brain dynamics necessarily, but to solve problems. So I'm [[00:32:42](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1962.96s)]
*  assuming that there are plenty of non-brain-concerned assumptions in the model as well. So is there a [[00:32:48](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1968.48s)]
*  balance between those things, or what's going on there? Oh, yeah. So for example, we don't try to [[00:32:55](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1975.52s)]
*  model all the things from... We don't even have neurons. When we talk about our model and when we [[00:33:03](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1983.6s)]
*  build in software, we don't talk about neurons and pipes or dendrites or anything. We talk about [[00:33:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1991.4399999999998s)]
*  random variables and factors between them. We talk about maximum likelihood as the learning [[00:33:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=1999.12s)]
*  mechanism. Or maybe here we are using pseudo likelihood, here we are using maximum likelihood. [[00:33:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2005.6s)]
*  And then we talk about message passing based inference. So this is another concrete idea, [[00:33:30](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2010.8s)]
*  which comes from the probabilistic machine learning and probabilistic model community, [[00:33:37](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2017.6s)]
*  but it's very much connected to neuroscience. So we implement our inference algorithms using [[00:33:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2024.08s)]
*  message passing, but the scheduling of those messages is actually very much inspired by [[00:33:48](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2028.8s)]
*  what we observe in biology. So we don't try to replicate the details of the biology. We [[00:33:55](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2035.04s)]
*  try to get the information processing principles from biology and put it into our model. [[00:33:59](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2039.6s)]
*  Okay, cool. What's something that the RCN is not good at? You mentioned the QR codes, right? [[00:34:04](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2044.9599999999998s)]
*  So what's something else that's important that it wouldn't work with? [[00:34:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2052.88s)]
*  Oh, yeah. So right now, for example, RCN will not be competitive on some of the standard [[00:34:17](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2057.44s)]
*  classification benchmarks that we tested, for example, the ImageNet data set. And the reason [[00:34:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2063.76s)]
*  for that is clear. It is not just a problem with RCN. It is also a problem with most generative [[00:34:29](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2069.76s)]
*  models that will try to solve that problem. Because one, the problem is set up as a classification [[00:34:35](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2075.1200000000003s)]
*  problem. And so it is straight set up for a system that is good at discrimination. And generative [[00:34:40](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2080.0s)]
*  models will get good at that problem eventually, but they will have to solve it in a much more [[00:34:48](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2088.0s)]
*  deliberate way. So when humans look at an image, you'll use the context in that image. [[00:34:53](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2093.76s)]
*  You see a patch of grass, so you know that, okay, here is the ground. And now on grass, [[00:35:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2100.88s)]
*  cows are more likely compared to some other object, some alien object. So humans use this context, but [[00:35:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2108.0s)]
*  they use it in a dynamic and generative way. So we have to build all those things into our model. [[00:35:16](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2116.32s)]
*  Of course, that is part of the research project that we are doing. But until we build all of them [[00:35:22](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2122.32s)]
*  in a generative way into our model. Because generative models try to explain the whole scene. [[00:35:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2127.2000000000003s)]
*  So what we did in the paper was being able to explain objects and backgrounds, but not any idea [[00:35:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2136.2400000000002s)]
*  about a whole scene structure. So those have to be trained and put into the model. And once we do [[00:35:43](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2143.84s)]
*  that, of course, it's a significant research undertaking. So being able to get to the level of [[00:35:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2149.92s)]
*  what deep learning discriminative systems are able to do on ImageNet, [[00:35:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2158.0s)]
*  getting there is going to be a challenge for the generative models. But there are places where [[00:36:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2166.48s)]
*  our models excel, even in the real world. For example, we tried on many of our robotic tasks [[00:36:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2172.2400000000002s)]
*  where we need to pick up objects. So these are objects that you don't get a lot of training data [[00:36:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2179.52s)]
*  for. They occur in very cluttered bins. And we see that our system is very, very good at [[00:36:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2185.92s)]
*  getting proficient at that with very few training examples. [[00:36:34](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2194.4s)]
*  That's great. So there are a growing number of labs, research labs, at least, trying to figure out [[00:36:38](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2198.16s)]
*  how brains can implement something like back propagation, the way that neural networks are [[00:36:43](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2203.2s)]
*  trained. So your model, the RCN, it has a backward pass in the model. Is that anything similar to back [[00:36:48](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2208.56s)]
*  propagation? Oh, no, not at all. So the distinction is the backward pass in our model happens during [[00:36:55](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2215.68s)]
*  recognition. It is not something that happens just during training. So the backward pass is always on. [[00:37:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2226.7999999999997s)]
*  It is required even during recognition. So this is like the feedback connections in the brain, [[00:37:12](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2232.88s)]
*  which are active during the normal recognition hours. There is no separate training hours. [[00:37:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2239.6s)]
*  So the mechanism that we use is called belief propagation. So it has the name propagation in it, [[00:37:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2245.2000000000003s)]
*  but it's different from back propagation. It has lots of similarities in the sense that it is a [[00:37:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2252.6400000000003s)]
*  local algorithm. You are just sending messages to your neighbors, and the neighbor is sending [[00:37:40](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2260.4s)]
*  messages back to you. So it is a very local algorithm, which is trying to arrive at a global [[00:37:46](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2266.32s)]
*  consensus. But it is doing something very different compared to back propagation. [[00:37:51](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2271.76s)]
*  Gotcha. Well, I know recently also, beyond this paper, you have, I mean, I know that this is just [[00:37:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2278.8s)]
*  a work in progress all the time, but you've added some more constraints, biological constraints, [[00:38:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2285.28s)]
*  to the model, enough that you've tacked on the word neural onto the beginning, and now you have [[00:38:10](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2290.08s)]
*  a neural RCN. So what further biological constraints does the neural RCN have, and how do they affect [[00:38:15](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2295.68s)]
*  the model? Yeah, you know, as I mentioned earlier, the RCN model, when we build it for putting on [[00:38:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2303.6s)]
*  our robots or as published in the science paper, that is purely explained using a probabilistic [[00:38:33](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2313.6s)]
*  graphical model. So the whole model is explained in probabilistic graphical model terms. Although [[00:38:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2319.7599999999998s)]
*  the representational choices of the model, a lot of it, and also the inference dynamics of the model [[00:38:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2324.96s)]
*  in how we schedule the messages, a lot of those insights came from neuroscience. Now, this [[00:38:50](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2330.72s)]
*  mathematical model that we have can be mapped back into biology. So you can take those, [[00:38:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2337.52s)]
*  the computations that we do in the model, and then find a mapping between that and the cortical [[00:39:04](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2344.48s)]
*  circuits. These are, you know, the columnar and laminar circuits that we find in the visual cortex. [[00:39:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2351.04s)]
*  So you can basically find the correspondence between the computations that we do in our [[00:39:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2358.16s)]
*  factor graph, the probabilistic graphical model, and the computations that happen in [[00:39:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2363.92s)]
*  these cortical circuits. And how do we do that? Because we do know a lot about cortical circuits. [[00:39:29](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2369.8399999999997s)]
*  You know, we know a lot about the laminar organization. We know, you know, column to [[00:39:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2376.72s)]
*  column connectivity. We know which laminar connect to which laminar. We know where the [[00:39:42](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2382.48s)]
*  forward connections originate from. We know where the feedback connections come from. We know quite [[00:39:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2387.12s)]
*  a bit about path through the thalamus. So you can think of these as, you know, pieces of a puzzle [[00:39:52](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2392.16s)]
*  given to us. You know, we know this is how roughly the cortical sheet is connected. Then we can ask [[00:39:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2397.44s)]
*  questions, what is the computational role for that? And can we explain those computational roles [[00:40:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2405.92s)]
*  in terms of the model that we already built? Although the model is, you know, purely in, [[00:40:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2411.3599999999997s)]
*  you know, factor graph terms. And the correspondence should exist because many of the [[00:40:16](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2416.64s)]
*  representational choices that we put into our model did come from, you know, observing the [[00:40:20](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2420.88s)]
*  biology part. So then what you can do is you can actually build a full cortical circuit, [[00:40:26](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2426.08s)]
*  which is elaborated in terms of columns and laminate. And that will be a way of instantiating [[00:40:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2432.7200000000003s)]
*  these computations that we do in the factor graph in terms of neurons and columns and laminar [[00:40:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2439.6800000000003s)]
*  organization. So that will be a functional canonical cortical circuit model. So it is [[00:40:48](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2448.0s)]
*  different from that other canonical cortical circuit model in the sense that this [[00:40:55](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2455.44s)]
*  cortical circuit model will actually do some function. It will recognize objects and fill [[00:40:59](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2459.44s)]
*  in the missing pieces and etc. So it will do exactly the same thing as our RCN model is doing [[00:41:05](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2465.7599999999998s)]
*  in recognizing these objects in complex scenes. But it will do it in a way such that [[00:41:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2473.6s)]
*  it, you know, you can find a mapping to the cortical circuits. And in addition, you can also go and [[00:41:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2478.6400000000003s)]
*  reproduce some of this visual phenomena that we find in real brains. For example, the subjective [[00:41:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2485.76s)]
*  contour illusions and neon color spreading illusion. These are all examples of visual [[00:41:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2492.56s)]
*  phenomena that are well known. And these phenomena happen as a as the combined effect of [[00:41:39](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2499.28s)]
*  feed forward propagation, feedback propagation, lateral connections, all of them need to be there [[00:41:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2505.52s)]
*  for this phenomena to occur. And we can reproduce many of those in our neural RCN model. [[00:41:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2509.52s)]
*  Well, Dalit, this is really nice work. And I'm looking forward to seeing what comes next [[00:41:56](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2516.96s)]
*  for you guys. I know you're working hard. Thank you. So let's switch here, if you don't mind, [[00:42:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2520.88s)]
*  to in our in our last few minutes here, I, are you ready to get in trouble? I want to ask you [[00:42:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2526.64s)]
*  for some speculative questions. Some general question. Also, you wanted to, you had a question [[00:42:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2531.76s)]
*  about backprop in the brain. Yeah. Yeah. Yeah. So as you mentioned, you know, many labs are focused [[00:42:20](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2540.4s)]
*  on this question of how does the brain do backprop? You know, if it does backprop? Yes. And, [[00:42:28](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2548.32s)]
*  you know, it's a good question to go after, you know, from our perspective, and my perspective, [[00:42:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2556.56s)]
*  I am willing to take it for granted that brain can do backprop. But that just leaves us where [[00:42:42](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2562.1600000000003s)]
*  we are currently that leaves us just with our current techniques for building the systems. So [[00:42:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2567.52s)]
*  while it is it is, you know, undertaking in terms of saying, what can the current AI techniques, [[00:42:55](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2575.84s)]
*  what might it teach about the brain? It doesn't help me go the other way. It doesn't tell me, [[00:43:02](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2582.8s)]
*  you know, what insights can I from the brain can I use to build the next generation of AI systems? [[00:43:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2587.84s)]
*  So I do think it's a it's a worthwhile research question. But that's something I'm kind of taking [[00:43:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2593.6s)]
*  for granted in some ways. Yeah. Yeah. Interesting. Good. Well, so are you ready to leap for some? [[00:43:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2599.12s)]
*  Yes. Okay. So what is something that you have been really wrong about or failed at in the past? [[00:43:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2607.12s)]
*  Oh, I don't I keep failing every day. That's what everybody says. Okay. All right. How about [[00:43:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2616.48s)]
*  this? What's one idea that that you can't do or you know, you don't have the the time or the [[00:43:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2624.88s)]
*  resources or something that you wish someone else might pursue? Oh, oh, my God. Lots of them, right? [[00:43:51](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2631.6800000000003s)]
*  Oh, well, I don't know. I just want the time and to pursue it. I don't want anybody else to pursue. [[00:44:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2640.4s)]
*  Okay. Okay. So it's a secret. Bad answer. But you know, [[00:44:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2646.2400000000002s)]
*  it's a good. So so from your from your perspective, sort of on the industry side, [[00:44:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2651.52s)]
*  do you think that the trend is increasing or decreasing or both maybe to incorporate more [[00:44:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2658.4s)]
*  neuroscience features into AI models? Yeah, that is a mixed bag, I would say. Really insights being [[00:44:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2663.8399999999997s)]
*  incorporated are rare. And I think people always like to, you know, a lot of people always like to [[00:44:31](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2671.44s)]
*  think about the brain. And, and there is also a tendency to, like, you know, kind of sell things, [[00:44:40](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2680.56s)]
*  you know, this was inspired by the brain, right? By putting in some stuff, you know, one caricature, [[00:44:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2687.68s)]
*  I sometimes present snarkily in some meetings is that, oh, I can put a different nonlinearity as [[00:44:54](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2694.48s)]
*  the at the first level of my deep neural network and call that the thalamus layer. Oh, yeah. So, [[00:45:02](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2702.08s)]
*  I mean, those kinds of things actually do happen, like, you know. So, so that that is that is more [[00:45:09](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2709.6s)]
*  like naming the different modules in the in the system as thalamus and this is ventral stream, [[00:45:15](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2715.68s)]
*  dorsal stream, those kinds of things. And yeah, they're they're kind of inspired by biology. But [[00:45:23](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2723.6s)]
*  I am, you know, we are looking for deeper inspiration, I would say. How possible is it [[00:45:29](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2729.2799999999997s)]
*  do you think that focusing on the brain as a guide for developing general AI, that that could [[00:45:34](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2734.48s)]
*  actually limit our potential to go beyond that level of intelligence? [[00:45:40](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2740.64s)]
*  It doesn't in my mind. And I explained why. So one, you know, without using that as a human [[00:45:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2745.36s)]
*  intelligence as a benchmark, you know, there is no other example or existence proof that we have for [[00:45:51](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2751.2799999999997s)]
*  intelligence. So we do have to use it as a benchmark to guide our development. And the [[00:45:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2757.84s)]
*  question that I ask others, if you are not using that as a benchmark, then, you know, how do you [[00:46:04](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2764.7999999999997s)]
*  know that we already haven't solved the problem, you know, because, because, you know, how do you [[00:46:09](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2769.68s)]
*  determine that your system is not already a GI? Because, and whenever you do that, you always [[00:46:15](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2775.3599999999997s)]
*  compare with humans, say that, okay, look, it's a gap. And so we are, of course, using even for [[00:46:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2779.8399999999997s)]
*  people who are not willing to admit it, we are actually using human intelligence as a as a [[00:46:26](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2786.08s)]
*  benchmark implicitly. So now, and as soon as you build something that is modeled after the human [[00:46:30](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2790.64s)]
*  intelligence, and based in a benchmark after the human intelligence, it will automatically go [[00:46:38](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2798.0s)]
*  beyond it, because it doesn't have the substrate limitations of human intelligence. Yeah, one, [[00:46:43](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2803.92s)]
*  you can build it bigger, you can train it longer. It doesn't have to, you know, it doesn't have all [[00:46:50](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2810.24s)]
*  the other drives of humans that are distracting. So it can be, it can be really efficient in doing [[00:46:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2817.44s)]
*  what it does without without having to worry about survival and, you know, paying mortgages and taking [[00:47:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2827.92s)]
*  care of kids, all those things. So it will automatically be beyond human level. I'm going to [[00:47:14](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2834.32s)]
*  I'm going to just skip the joke about my wife finding some of my drives distracting. So [[00:47:19](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2839.44s)]
*  so. Okay, so here's a big one that you might want to skip. So how does consciousness fit into the [[00:47:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2845.04s)]
*  long term story of building general AI? Are you worried about it? Is it something you think about? [[00:47:31](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2851.04s)]
*  So consciousness is, in my thinking, modeling, you know, it's self monitoring and modeling yourself, [[00:47:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2856.0s)]
*  the modeling power that we are using to model the external world, you can turn that same system on [[00:47:44](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2864.56s)]
*  the models that you're building so that you know, so that will build you a kind of self monitoring [[00:47:52](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2872.8s)]
*  ability. And if your model is powerful, and it's sophisticated, that self monitoring ability will [[00:47:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2878.2400000000002s)]
*  start to feel like consciousness. That's my thinking about it. And yeah, so, and as we build [[00:48:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2888.32s)]
*  these systems, our self monitoring capabilities are, you know, will become more and more important. [[00:48:15](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2895.04s)]
*  And we see this all the time, even when you when you're in robotics, you you kind of see this, [[00:48:21](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2901.6s)]
*  you know, you have to build it from the very beginning. And as you as your model starts [[00:48:26](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2906.88s)]
*  becoming more and more complex, the self monitoring capabilities also will become [[00:48:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2912.3199999999997s)]
*  more sophisticated. Yeah. And to me, that is consciousness. You don't do something too [[00:48:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2916.96s)]
*  different. So there's no magic in there. Yeah. Okay, so I asked this sometimes that, you know, [[00:48:43](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2923.2799999999997s)]
*  like parties, not that I get to parties much anymore. But so, so I think we can safely say [[00:48:49](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2929.84s)]
*  that, as a species, we're kind of embarrassed at this point about slavery, you know, that that's [[00:48:55](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2935.44s)]
*  wrong. And so we can look back and say, Oh, God, that's kind of embarrassing that we ever did that [[00:49:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2940.1600000000003s)]
*  things like that women's suffrage, things like that. What do you think? What do you have something? [[00:49:04](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2944.0s)]
*  What is something that as a culture or species? Do you think that our generation are doing right [[00:49:08](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2948.5600000000004s)]
*  now, that we will be collectively embarrassed by? And this can be in the realm of science, [[00:49:13](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2953.1200000000003s)]
*  neuroscience, or just in general? Oh, lots. I mean, still getting into politics and [[00:49:18](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2958.0s)]
*  that was low hanging fruit. But yeah, it's a, you know, climate change. I hope we can do a lot more [[00:49:27](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2967.68s)]
*  about it. And a lot of our entrepreneurship can be directed in that to attack that problem. And, [[00:49:36](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2976.56s)]
*  you know, I do have several friends who are running companies which are trying to tackle [[00:49:45](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2985.2s)]
*  this problem that is going to take a step on, you know, a few years down the line. So, [[00:49:51](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2991.92s)]
*  that's good. So that's, you know, an example of a problem where we should be all collectively [[00:49:58](https://www.youtube.com/watch?v=1XeHyeshoOc&t=2998.7999999999997s)]
*  embarrassed that we haven't got our act together. Okay, that's a good answer. So if you had to be [[00:50:04](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3004.4s)]
*  frozen and then thawed in the future, when would you when would you want to wake up and why? [[00:50:09](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3009.12s)]
*  Oh, I don't know. It's a question of am I frozen with other people or is it just me? [[00:50:16](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3016.72s)]
*  Damn it. I can't be that specific with these questions, man. Okay, so I'll take tomorrow [[00:50:25](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3025.52s)]
*  because life is good for you right now, I think. So yeah. So, Dilip, what can we expect from [[00:50:32](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3032.0s)]
*  Vicarious in the next year or two? Well, one, definitely products. We are pushing some of our [[00:50:38](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3038.4s)]
*  work into products and doing real life deployments. So one thing very rewarding for us would be [[00:50:46](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3046.32s)]
*  when our products get, you know, start getting used in the real world. Yeah. And, you know, [[00:50:54](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3054.96s)]
*  seeing something being used, that is very rewarding. So that is one thing. And we are [[00:51:01](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3061.2000000000003s)]
*  working on some cool ideas related to how high level concepts can be learned. And we hope to see [[00:51:07](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3067.2s)]
*  some of those, you know, getting published and those ideas getting discussed. And also we hope [[00:51:16](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3076.24s)]
*  to see some of the things that we kind of championed in terms of data efficiency, [[00:51:24](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3084.16s)]
*  and using insights from the brain in a deep way being taken up by the broader community. [[00:51:30](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3090.88s)]
*  Well, I'm looking forward to it. So my last question here, so this whole podcast has been [[00:51:42](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3102.08s)]
*  a ruse really. So can I skip the whole applying for an interview and can you just hire me now or? [[00:51:47](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3107.36s)]
*  Or? [[00:51:52](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3112.56s)]
*  We are always looking for smart people. Yeah. [[00:51:57](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3117.84s)]
*  Okay, great. Now I don't have to blackmail you. That's good. [[00:52:00](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3120.08s)]
*  Well, thanks a lot, Dalip and continued success to you. [[00:52:03](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3123.2s)]
*  Thanks. Thanks, Polykos. Pleasure talking to you. [[00:52:06](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3126.64s)]
*  All right. I hope you enjoyed that departure from all the deep learning talk that we've had lately. [[00:52:11](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3131.28s)]
*  Next week, I will have Konrad Kurding on the show and hopefully pronounce his name right. [[00:52:17](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3137.36s)]
*  At the time, we'll talk about a lot of things. He's a bit of a polymath. All right. See you next time. [[00:52:22](https://www.youtube.com/watch?v=1XeHyeshoOc&t=3142.48s)]
