---
Date Generated: April 19, 2024
Transcription Model: whisper medium 20231117
Length: 5263s
Video Keywords: []
Video Views: 941
Video Rating: None
---

# BI 167 Panayiota Poirazi: AI Brains Need Dendrites
**Brain Inspired:** [May 27, 2023](https://www.youtube.com/watch?v=4FQctMJOYPE)
*  I often wonder whether this huge variability, this complexity is not necessarily linked
*  to a unique function, but rather there is a very high level of redundancy in the brain
*  that was never punished, evolutionary speaking.
*  All these aspects have to do with efficiency, efficiency in terms of computations and utilization
*  of resources.
*  And I think that's where really the dendrites shine.
*  Initially I was thinking that dendrites are really, really important because they allow
*  the brain to do more advanced, let's say computations that we could do.
*  But I now kind of think that they are more important role.
*  This is Brain Inspired.
*  I'm Paul.
*  Pana Jota Poyrazzi is my guest today.
*  Jota runs the Poyrazzi Lab at the Fourth Institute of Molecular Biology and Biotechnology.
*  And Jota loves dendrites, those branching tree-like structures sticking out of all of
*  your neurons.
*  And she thinks that you should love dendrites too, whether you study biological or artificial
*  intelligence.
*  So in neuroscience, the old story was that dendrites just reach out and collect incoming
*  signals for the all-important neuron cell body to process.
*  Jota and people like Matthew Larkham, with whom I chatted in episode 138, are continuing
*  to demonstrate that dendrites are themselves computationally complex and powerful, doing
*  many varieties of important signal transformation before signals reach the cell body.
*  So for example, way back in 2003, Jota showed that because of dendrites, a single neuron
*  can act as a two-layer artificial neural network.
*  And since then, others have shown that single neurons can act as deeper and deeper multilayer
*  networks.
*  On top of that, and in Jota's opinion, an even more important function of dendrites
*  is increased efficiency in computing that they bring to the table, something that evolution
*  surely favors and something that artificial networks will need to favor as well moving
*  forward.
*  So we talked about some of her work and reflections and ideas about the computational properties
*  of dendrites with respect to cognition and efficiency.
*  As always, go to braininspired.co if you have a couple bucks to support this podcast through
*  Patreon.
*  Or if you're interested in learning more about neuro AI topics, you can check out my online
*  course, Neuro AI, The Quest to Explain Intelligence, also at braininspired.co.
*  Show notes for this episode are at braininspired.co slash podcast slash 167.
*  Okay, here's Jota.
*  Jota, you've been studying dendrites for, since your master's thesis at least.
*  So I was kind of assuming that maybe you came in from studying something else and eventually
*  came to love dendrites.
*  But have you always been interested in dendrites?
*  Or how did you come to love the dendrite?
*  Good question.
*  Well, I was always interested in the brain, right?
*  Since I was a high school student, I wanted to study something related to the brain.
*  But you know, this is a long story.
*  There was no university in my home country in Cyprus where they would offer a neuroscience
*  or even a medical degree, let's say as an undergrad.
*  So I studied mathematics instead.
*  Then I wanted to find my way somehow back into biology and in particular the brain and
*  neuroscience.
*  So I went to USC to study biomedical engineering, which was the way to get back through a mathematics
*  degree.
*  And there I met Bartlett Mel.
*  And I met Bartlett like, you know, the first few months that I arrived at USC.
*  And he was doing dendrites.
*  So I wasn't in love with dendrites at that time.
*  I just fell in love with them when I started working with Bartlett.
*  That's how it all started.
*  So you were at USC and you decided to leave the United States and go back to Greece.
*  And I understand that you were like one of the or the youngest research director at your
*  institution.
*  Is that true?
*  I was the youngest researcher to be hired when I was first hired.
*  So I was 27, I think, when I got to that position.
*  There were only like three other people, right?
*  In that kind of area of study?
*  In the entire country, you mean?
*  Oh, okay.
*  That's quite larger than.
*  No, my institute is pretty big, but computational neuroscience is not big in Greece, unfortunately.
*  There are less than five labs throughout the country that do computational neuroscience.
*  So it's a kind of unique skill around this place.
*  What about experimental neuroscience?
*  Because I know that you've transitioned your lab.
*  I'm going to ask you about that later to include experimentation.
*  Is that a big scene in Greece?
*  Well, there are quite a lot of people doing molecular neurobiology, but not really systems
*  neuroscience.
*  There are a few people that used to work on monkeys in Crete.
*  Some of them still do, but there is not a lot of mice electrophysiology or in vivo behavior.
*  So it's still kind of lonely here.
*  There is at least one other lab that has recently joined and is a person who came from the
*  US and has the expertise for systems neuroscience in mice.
*  And that's why I also decided to expand.
*  So we're sharing a lab and he's helping a lot with training and the people in my lab
*  to start doing experiments.
*  Okay.
*  You said it's lonely.
*  I was thinking that there are pros and cons, right?
*  Because a pro is that you sort of stand out and you don't have much fellow competition
*  in your area.
*  But a con is that it's a lonely endeavor.
*  Yes.
*  I think it's really important to have colleagues with whom you can discuss problems, troubleshoot,
*  write joint grants, write papers together, mostly run by them, your ideas.
*  And I really felt this difference when I was doing my sabbatical at UCLA in 2008.
*  Then it really stood out how different it is to be in Greece and to be kind of a loner
*  on this endeavor.
*  I appreciated a lot the collegiality that I found there and the opportunity to talk
*  to people on a daily basis.
*  Okay.
*  So it's like passing people in the halls and actually physically attending talks and having
*  conversations after and before.
*  Yeah.
*  All right.
*  So I'm going to kind of skip ahead here because a lot of what you do and have done in the
*  past is computational modeling of dendrites.
*  And you argue essentially that artificial networks need dendrites.
*  And yet, you know, there's been this recent explosion in the capabilities of artificial
*  networks.
*  And I'm kind of curious how you have viewed that explosion and watching artificial networks
*  getting better and better and better.
*  Have you just been thinking, ah, if they only had dendrites the whole time?
*  Or are you thinking, oh, maybe they don't need dendrites?
*  What's that been like?
*  Yeah.
*  So that's a very important question because I think that brains need dendrites.
*  And there's a big distinction between a brain and an artificial system.
*  And the reason why there is such a big distinction is that the brain is under evolutionary pressure.
*  We have a limited size of the skull.
*  We have a neural tissue doing the computations.
*  We run on very low energy.
*  All these aspects have to do with efficiency, efficiency in terms of computations and utilization
*  of resources.
*  And I think that's where really the dendrites shine because they bring this efficiency to
*  biological brains.
*  In many ways, we can discuss that.
*  Now, you can think of child GPT, for example, right?
*  And you know, it's a really big thing right now.
*  It needs the energy of a small city to be trained.
*  It's not comparable to my brain or what your brain is doing.
*  Not to mention the size of the infrastructure, the number of GPUs that are needed to run
*  this thing, right?
*  It's still not smarter than a seven-year-old child.
*  So I still think dendrites are really important.
*  They're important for two reasons.
*  One which we haven't really mastered yet in artificial intelligence systems is like the
*  ability of the brain to learn continuously, you know, lifelong learning, for example,
*  or to transfer skills from one task to another.
*  There's great improvement in the new systems out there, but this is still an open task,
*  I think.
*  And the most important aspect, obviously, is efficiency, sustainability.
*  I mean, we are reaching a ceiling in the technology of cheap manufacturing.
*  And this is not enough to answer to the very high demand of computational intelligence
*  systems that we need on our daily lives.
*  So efficiency is going to become a bottleneck in the next few years.
*  And there are already a lot of people out there talking about neuromorphic computing
*  with the idea of doing what the brain is doing so that we can achieve the same or better
*  let's say computations and intelligence with a much more sustainable technology, smaller,
*  cheaper, you know, low cost, low energy.
*  And I think that's where dendrites really matter.
*  So I appreciate the efficiency story and importance of efficiency, but there's a part of me that
*  wants to, that is more excited about the expansion of cognitive abilities, the improvement in
*  cognition for dendrites because we're living in a world today, right, where, yes, it costs
*  a small city to train these models, but you can just go to a medium sized city and it
*  gets smarter and a bigger city and it gets smart.
*  Maybe eventually we'll get to the earth sized models and it'll just be like super smart.
*  So do you think that scaling up will just accomplish the same cognitive capabilities
*  or is there some secret sauce in dendrites?
*  That's a wonderful question.
*  If you had asked Matthew Larkum, I'm sure he would say that there is a secret sauce there.
*  I am not entirely convinced to be honest because deep neural networks, which is essentially
*  the technology behind the systems, right?
*  So if they scale big enough, they should be able to approach any problem, any kind of
*  computation.
*  That's what we know from theoretical math, but they're general approximators.
*  They should be able to solve any problem, right?
*  So it could be that we haven't really reached the size of the network that is required
*  to come up with cognition.
*  We don't know, right?
*  It is also possible that there is something special about dendrites, which however we
*  have not really put our finger on yet.
*  I mean, there are really cool things that happen in dendrites and one of the really
*  interesting things that our work with Matthew, for example, is looking at is related to
*  perception.
*  And Matthew, these are not my studies, so I'm not taking any credit for this.
*  So Matthew has shown that when the animal is very close to perceiving a new sensory
*  stimulus, that is when the dendrites light up and you have this massive activity measured
*  with calcium imaging in the tufts of the distal dendrite of cortical neurons when the
*  animal perceives a stimulus.
*  So it is possible that without dendrites, you cannot have this aha moment, right?
*  Which is what happens when you realize that you're now perceiving something.
*  So that's that's the other possibility that answers your question with respect to the
*  magic sauce. Can we not do that with dendrites?
*  Is it really that we need dendrites to actually have this kind of computation?
*  I don't think so, because in terms of a computation, what happens is like, you know,
*  now the dendrite is signaling to the cell body that something really important is coming
*  in. So, you know, kind of pay attention to it.
*  And it's done within the single neuron by talking the dendrite talking to the cell
*  body, which otherwise would not have done right.
*  If it's not important signal, you would not see these calcium, these hydridic spikes.
*  You could definitely do that with a pair of neurons and you have them disconnected and
*  then they talk to one another under specific conditions.
*  Now, the brain might want to do this with dendrites again, for reasons of efficiency.
*  You save much more space by not having these cell bodies that are huge in the
*  medium and having them talk to each other conditionally.
*  You also have a lot of dendrites that cover a very small surface area so that you can
*  have a lot of combinations of when you want this dendrite to talk to the cell body.
*  And therefore, presumably, you can think that you can, let's say, learn many different
*  things by combining the different dendrites with the same neuron, right, which if you
*  did not have dendrites, you'd have to have as many neurons to implement this computation.
*  So I'm not sure whether it is a matter of a special source or just a matter of, you
*  know, this is a much more efficient and smarter way to do this, to solve the same
*  problem. We don't know for sure.
*  I mean, I wouldn't bet all my money on the fact that there is no special source in
*  dendrites. In fact, I wish there is, right.
*  I've dedicated my life studying on dendrites.
*  We just haven't seen it yet.
*  I was thinking, I just had the thought that a line in math, right, is an infinite set of
*  points all jammed together.
*  And I mean, not only would you consider, you know, replace a dendrite in an artificial
*  system with another unit, but you might have a hundred units like all connected together
*  because dendrites are so complex.
*  They have like these propagating properties and their shape.
*  They have different shapes.
*  They have different ionic conductances and all sorts of things are happening and in
*  constant flux.
*  And so is that a crazy idea to just chain up a bunch of units together with different
*  properties?
*  It's not a crazy idea.
*  And people have already proposed this chain of units that represent, let's say, the
*  three compartments, not the whole dendrite, each of which is doing its own computation.
*  And this is supported by experimental data.
*  In fact, we have proposed that a cluster of synapses might be the smallest computing
*  unit because you only need something like, you know, five to eight spines activated together
*  to generate a dendritic spike within a compartment.
*  And if you consider this computation, a nonlinear computation, which essentially that's
*  what it is, right, you're crossing a threshold, you're mimicking the nonlinearity of the
*  cell body, then you can think of having many such clusters of synapses within a long
*  dendrite that each of them would be a computing unit.
*  All right.
*  I'm going to go real broad here.
*  Where are we?
*  I mean, you mentioned earlier already that we don't know the extent.
*  We don't know everything about dendrites.
*  Where are we in that progress?
*  I mean, you know, we have Hodgkin-Huxley models for neurons, right, and conductances
*  and membrane capacities, et cetera.
*  But in terms of...
*  So I guess this is like two wrapped up questions.
*  One is just where are we in the broad scope of understanding the properties of dendrites
*  and how they contribute to neuronal function and cognition?
*  And now I'm forgetting the second question, so we'll stick with the first.
*  Where are we?
*  OK, so in terms of tools for modeling dendrites, we use the same tools as we used to model
*  the cell body.
*  So Hodgkin-Huxley equations are perfectly fine for describing the different ionic conductances
*  that are found in the dendrites.
*  Capacitors also describe their membrane properties.
*  But in terms of experimental data, we don't know as much.
*  And unfortunately, people are now kind of abandoning the methods that would tell us
*  more about dendrites, which would be patch clamping in vitro.
*  So we're kind of moving away from that technology because it's not as sexy and people are doing
*  a lot of in vivo experiments now.
*  And in vivo, you cannot really map out the type of conductances that you have, you know,
*  in different parts of the dendrites and you cannot measure their concentrations, their
*  conductances.
*  So we know mostly about dendrites from studies that were done in previous years.
*  And that's a shame.
*  And we know very little about interneurons.
*  We know more about pyramidal neurons, but we don't know a lot about interneurons.
*  And interneurons come in such a large variety of shapes and electrophysiology profiles.
*  So when we want to study interneurons, that problem, the dendrite of interneurons, that
*  problem becomes even bigger.
*  So I am hoping someone who will listen to this podcast will want to go back and study
*  dendrites using techniques that can tell us about their electrophysiological profiles.
*  Oh, that's going to be a hard sell.
*  Yeah, I know.
*  Maybe we will do it.
*  Yeah, you have to do it, right?
*  And you are kind of starting to do it.
*  Are you patch clamping?
*  We do have a patch clamp facility here in the University of Crete that, in fact, my lab
*  has helped establish many years ago.
*  But in the new direction of the lab that we are starting now, we are also turning to in-depth experiments.
*  Okay, yeah.
*  All right.
*  So again, we'll come back to that.
*  But it's overwhelming.
*  So, okay, the neuron, right, which used to be considered the functional unit of the brain.
*  We have lots of neurons, and they are all connected and recurrently connected and in
*  complex ways.
*  And you can kind of think about the small circuit level in brain areas, and that's kind
*  of more coarse-graining things.
*  And you think, well, okay, I am getting a little bit closer to cognition, whatever that
*  means.
*  But it's already overwhelming to sort of think about the number of neurons and the way that
*  they are connected.
*  And you think about not just the number of neurons, but there are like, I don't know
*  how many different types of neurons there are these days.
*  What's the classification?
*  Hundreds?
*  Probably.
*  I remember something like 30 interneuron types at least, and these are the main classes.
*  And you have all the subtypes.
*  I don't know how many different neurons we have by now.
*  Yes, hundreds, I would say.
*  Then how many different types of dendrites are there?
*  Because you have active versus...
*  How do you define...
*  Well, I know that's what I'm asking, right?
*  So the complexity is just off the charts, right?
*  Because I wanted to ask you about what an active dendrite is versus a passive.
*  Maybe you can answer that real quick before I just...
*  Yeah, I can.
*  An active dendrite is one that is able of generating dendritic spikes.
*  A passive one is one that only integrates the signals without ever crossing a threshold
*  for a dendritic spike, and therefore the integration is sublinear, linear to sublinear, whereas
*  the other type is super-linear in some cases, and then it can get more complicated than that.
*  Yeah, yeah.
*  You're almost wincing right now.
*  And then you have just the different distance from the cell body, the different shapes,
*  the different connectivities between the neurons, between the dendrites where they join and
*  where they branch, et cetera.
*  You mentioned synaptic clustering earlier, and we're going to talk about plasticity because
*  then you have a hundred different plasticity rules.
*  It just seems...
*  Do you ever just sit back and think this is too daunting?
*  Yes, and I often think whether it doesn't really matter that much in the sense that
*  in the light of evolution, everything that worked would get selected, and maybe we are
*  placing too much attention on things that are different, but they're different simply
*  because they all observe the same function.
*  So I often wonder whether this huge variability, this complexity is not necessarily linked
*  to a unique function, but rather there is a very high level of redundancy in the brain
*  that was never punished, evolutionary speaking, because it did not have a negative impact
*  on the brain function.
*  If that's even remotely true, it would explain why we have such a huge variability in the
*  brain and why we don't really need to explain every piece of it, because maybe it's doing
*  the same thing.
*  But you mentioned earlier you think algorithmically, and algorithms are very clean.
*  Well, not evolutionary algorithms.
*  Oh, well, explain that to me then because I think of mathematical algorithms are clean,
*  and it's almost like modern computational neuroscience sees an algorithm, let's say
*  the backpropagation algorithm, just to throw one out there, sees that as somehow evolution
*  is driving toward that.
*  But it seems much messier to me.
*  So evolution doesn't work that way.
*  It's not normative.
*  I don't agree that evolution is driving towards that.
*  Evolution is definitely selecting the optimal solution, but it's not actively searching
*  for it, which is what the backprop algorithm is doing.
*  So an evolutionary algorithm is essentially randomly making changes like mutations in
*  genes.
*  That's how they work, right?
*  They randomly happen.
*  And then those that lead to some advantage, they improve the fitness of the organism,
*  they get selected, and the others slowly die off.
*  So we get better by chance.
*  We don't get better by instruction, like the backprop algorithm, which essentially
*  finds out how much away you are from your optimum target, you correct yourself to the
*  right way so that you get there faster.
*  That's another kind of optimization that I don't think personally is what the brain
*  is doing, and it's definitely not what evolution has been doing for the previous eons.
*  So forgive me.
*  I'm going to probably ask in a naive way.
*  I guess what I'm sort of driving at is how should I think of algorithms, for instance,
*  and mathematics like an equation, right, that we want to map onto how the neurons and dendrites
*  and circuits are functioning?
*  Do I think of it as like an attractor sink that it's just kind of, I guess, via gradient
*  circling around, you know, like some sort of stable or unstable attractors?
*  Like how should I think about the mathematical tools that we use to map onto our messy biological
*  brains?
*  First of all, there are mathematical algorithms for implementing, you know, evolutionary algorithms,
*  which is what I describe, random changes, and then you just keep the good solutions.
*  And the way you imagine those, at least in my mind, is not like an attractor that continuously
*  travels towards the minimum point, which would be the center, but it's like having multiple
*  wells on a surface and you try to move to the optimal, but meanwhile you fall into many
*  of those local minima.
*  And then there is something that push you out of this well.
*  You know, the energy goes up and then you jump out of it and you fall to another one,
*  and then slowly you converge, if you ever converge, to the right minimum.
*  There is an algorithm called simulated annealing, for example, which is doing precisely this.
*  Now, if we want to go back to neurons, the way that we learn is dictated by the different
*  plasticity rules, as you mentioned initially.
*  Now, these plasticity rules, there are so many and they're very different and they don't
*  necessarily simulate something like this, right?
*  Maybe they simulate a part of an algorithm that when you look at it from a higher perspective
*  will look like an evolutionary change.
*  And maybe we have different plasticity rules because we want to attend to different aspects
*  of learning.
*  For example, if what I want to do, a young child, for example, doesn't really know much
*  about the world, right?
*  So the best thing to do is to attend to regularities, things that happen together, things that
*  happen coincidentally.
*  So how do you detect the regularity?
*  Well, everything that fires together, wires together, like HEP said.
*  So you have a local Hebbian rule, which is just looking for these things that consistently
*  occur together.
*  That would be one hypothesis for why you have a Hebbian rule, right?
*  Let's see.
*  And then this, the Hebbian rule is implemented in many different ways.
*  You can have the spike timing dependent plasticity, which is very sensitive on the timing of these
*  events happening together.
*  We have the BCM, which is dependent on changes in the calcium.
*  This is a slightly different time scale, but again, it's kind of a correlation based algorithm.
*  And you have, you know, various of these kind of rules where neuromodulators come into play,
*  but they all underlie the same idea.
*  At least that's how I understand it, that we're looking for regularities in the environment.
*  Yeah.
*  And this is unsupervised, right?
*  There is no teacher there telling the system that this is the right thing to do or not.
*  So the teaching signal has to come from somewhere else.
*  Right.
*  Yeah.
*  And in animals and humans, we, our brains are directly connected to our bodies.
*  So we execute actions.
*  And then the teaching signal comes from the result of the action.
*  Right.
*  If you're trying to reach to take a glass and you fail to do it, then, you know, it doesn't work.
*  But if you succeed, then you have some kind of a signal that I got this thing right.
*  So the teacher comes, the teaching signal comes externally.
*  It's the result of the action and not something that happened inside the brain, which somehow,
*  of course, is propagated back to the brain and serves as a feedback within feedback information.
*  So it's a loop that involves, you know, a thought and execution and end result and a signal back in artificial systems.
*  What is the feedback?
*  Right. So it's just an external label and it gets back propagated.
*  Yeah.
*  Which we give it as the answer to the fact that the artificial intelligence system does not have an arm to reach out and execute the action.
*  And generate the feedback.
*  Yeah. But I mean, even OK, so let's go back to a biological system.
*  So you have that feedback loop.
*  But then not only do you have the Hebbian style plasticity, you have homeostatic plasticity, you have intrinsic plasticity.
*  And these types of changes are constantly in flux.
*  It's not like they're sitting there and waiting like homeostatic plasticity is just a function of the cells needing to survive.
*  And, you know, self-regulating, et cetera.
*  So how do we square all of those dynamic changes with some sort of feedback that eventually it gets right, right enough?
*  So I think that all these plasticity rules, they are solving different problems and they act at multiple scales.
*  Like homeostatic plasticity is needed to make sure that you don't keep changing the synaptic weights in a positive manner
*  so that you reach a hyper excitability and then you have seizures in the brain.
*  Right. So you have to scale the weights down to make sure that you don't burn your brain.
*  You also have to scale weights up occasionally if there is something happening in the brain that is pushing towards depressing synapses because you want to maintain excitability.
*  So as a result of learning, there will be changes in the synapses.
*  And then to make sure that these changes are not driving the system away from a stability point, you have homeostatic plasticity.
*  So they need to operate together with heavy ampersicity, which is going to be upregulating or downregulating selectively some weights without a way to stop this thing.
*  Right. Because if you don't have a gradient descent, let's say like system, then you don't know when you actually reach your target.
*  It will keep on changing. And that's another one of the things that we're frequently thinking when we're building models.
*  How do the neuronal circuits know when to stop? What is the stopping criterion in the brain?
*  One stopping criterion could be that you, let's say you reach the limit of the resources that are available to the synapses.
*  So you don't have any more plasticity related proteins. So you have to stop.
*  Another criterion could be, I don't know, that you've done so many changes and you run out of ATP, let's say.
*  They will mostly be related to resource availability rather than a signal that says, OK, you've got it right.
*  Now you need to stop. Because we don't really know what is it that tells the circuit that now your task of updating is done.
*  Yeah. How do you choose what to implement in your models then?
*  Well, in fact, we are implementing lots of plasticity rules, all of them working together.
*  And then we take one out, we take the other out and see what is the impact on the model, on the model's ability to learn.
*  And we try to figure out what is the contribution of each one of these rules.
*  And yeah, I mean, I'm not sure if it's the right way to do it,
*  but it's definitely a good way to gain insight as to the necessity and the complementarity of the different rules that operate.
*  I mean, what other way would there be to do it?
*  Well, many people just use one plasticity rule, you know, and look at what you can get with a system that implements this learning rule.
*  And I think that's a big problem because you miss out on the interactions between these different kinds of plasticity rules and the contributions that they have, let's say, at the circuit level versus a much bigger scale or a smaller scale.
*  All right. Let me ask you this. So there are, you know, all these different types of plasticity, all these different types of dendrites, all these different types of neurons.
*  I believe I read in one of your manuscripts that you suggested that the dendrite, we might should start considering the dendrite, the functional unit of the brain.
*  So I mentioned earlier that for a long time, the neuron was the functional unit of the brain.
*  And now people are talking about, you know, circuits, microcircuits as the functional unit of the brain and relating related to cognition.
*  Does there need to be a functional unit of the brain and might dendrites be that in at least in your head?
*  So the people who first proposed, let's say, that dendrites should be the functional unit of the brain. They did so back in 2010.
*  In fact, there was a nice review paper by Branco and Hauser, which was based on our work and their work and many people's work showing that dendrites are essentially doing nonlinear computations like the cell bodies.
*  I'm sorry to interrupt you, but I mean, I just would be amiss without mentioning your work in 2003 showing that a single neuron is comparable to a two layer artificial neural network.
*  And then, and since then there have, you know, that number has grown. Right. And so was yours the first study to show that?
*  To my knowledge, yes, we were the first to predict that essentially dendrites act like small cell bodies and they can solve the same kind of problems using a similar activation function, a sigmoidal activation function like, you know, the cell bodies of neurons.
*  This was back in 2003.
*  And then soon after people started talking about having more such nonlinear computing units inside the neuron. So not only individual dendrites, but maybe you can break them down into their distal apical, proximal apical and basal apical compartments.
*  And in those compartments, you have multiple of these nonlinear units. So you have like a three layer, let's say, or a four layer neural network.
*  And then recently in 2021, there was a nice paper by the lab of Michi Landon and Ida Kisegev where they showed that you can may even need a deep neural network of up to seven layers to approximate the temporal computations that are done in a single cortical neuron.
*  Yeah. Okay.
*  Okay. So it's increasing. We started with a two layer pointing to the dendrites unit and now it's becoming a multi-layer deep neural network in a single neuron.
*  Yeah. Okay. All right. I just wanted to mention that because you were talking about the 2010 review where the authors suggested that dendrites should be considered a functional unit of the brain. So carry on. Sorry to interrupt.
*  Yeah. Yeah. So I was saying that I think we are now beyond the individual dendrites being a computing unit and the computing unit gets much smaller. And I think that it's just a bunch of synapses, small clusters of synapses.
*  That will be the computing unit of the, you know, the computing unit of a neuron, let's say. Because you have units of multiple levels. As you said, the micro circuit could be the unit of cognition.
*  So it depends on what kind of unit that we're talking about here.
*  Yeah. Right. Okay. So you mentioned the synaptic clustering earlier and I was going to ask you just to explain what that was and its significance because you just brought it up again in terms of being a functional unit. So could you describe that more?
*  Yes. So this was another one of the early studies that we've done with Bartlett-Mett back in 2001 where we essentially showed that if you have dendrites that are capable of generating spikes, they are nonlinear dendrites, and you have a plasticity rule that depends on detecting inputs that fire together and therefore they should wire together.
*  So a Hebbian plasticity rule, but which rule is now local. So it depends on what happens in the dendrite, not what happens at the cell body. So if two inputs, let's say fire together and they cause a dendritic spike, then they would undergo plasticity within the dendrite and they will become strengthened together.
*  And as a result of such a rule, you have all the spines or the inputs that are correlated in terms of their firing profile to be co-strengthened within a given dendrite. And therefore you form small clusters of synapses that are spatially close to each other because of their temporal, let's say, correlation.
*  And temporal correlation in this case would also mean somewhat of a functional correlation because typically inputs that project onto the same dendrite and fire at the same time, they also carry similar information. If you think of the visual cortex, they are probably sampling from the same location in the visual field, let's say.
*  Or if you think of the auditory cortex and the animal is hearing a particular sound, these inputs would carry frequencies that are found in that particular sound, in that word, if you want. So the functional correlation would result in the spatial, temporal strengthening of inputs in a small part of the dendrite.
*  So that's which is mediated by this Hebbian rule, which is now local. So considers the ability of the dendrite to fire. As a result now, you have the formation of groups of synapses within the dendrites. They are close to each other.
*  They are strengthened together and they have the ability to fire the dendrites. We think that this is a unit because if a signal that comes in by, you know, four or five synapses, having a significant enough information,
*  that has induced plasticity this way through this formation of a cluster of synapses, then this would be an independent computation that is propagated to the cell body through the dedrytic spiking mechanism.
*  So that's what we think is, you know, why we think is a computing unit.
*  A computing unit of a neuron.
*  You could think of it as a dendrite because you can have multiple such clusters within a dendrite.
*  Okay, because I want to, you know, the dream, right, is to link these really low level mechanisms, low level, like a synaptic cluster to higher level cognition and not just like say, well, you know, piano playing is linked to these three clusters.
*  That's naive, but have some sort of way to look at the different scales, right, and kind of link them.
*  Is that I will answer that.
*  Okay. Yes. So first of all, I should say that this clustering was a prediction back in 2001 when we used our models and now it is verified experimentally numerous studies.
*  So people see that experimentally you have the formation of these clusters and many of the times, most of the times they carry correlated information.
*  So, you know, a prediction that was 20 years ago was verified.
*  You know, it started being verified 10 years ago and now many papers come out.
*  So I think that's really important for the role of models that I wanted to highlight.
*  Now, how do we link this to a computation at a higher scale?
*  So we have some really nice, I think, work with the lab of Alcino Silva, which was published in 2016, where we showed that the mechanism that links information across time.
*  So like two memories of an animal experience that are separated by a few hours is through the synaptic clusters, because you have one memory, let's say a given context that is formed in a population of neurons.
*  And then a couple of hours later, the same animal experiences a different context.
*  And now the actions that carry information about the second context end up being co-clustered to the actions that carry information from the first context.
*  Why is that? Well, there are interacting plasticity rules here.
*  One is the plasticity of intrinsic acceptability, which says that a group of neurons that has learned something will remain excitable for several hours and therefore it will be, let's say, ready to capture another memory.
*  And this would be the mechanism that also underlies the formation of episodic memories in the brain.
*  So that's how you link them. But beyond storing the memories in the same population of neurons, we predicted with our models that they would also be
*  ending up forming clusters into common dendrites.
*  I should say that this was a prediction of the model. And now we have a paper on the review, which hopefully will come out soon, that supports, I wouldn't say 100% verifies, but supports this idea that this linking within dendrites is the mechanism by which you bind information across time.
*  So that's how you go from a dendrite to a behavioral phenotype, you know, at the circuit and the behavioral level, which is how do I take two independent entities to memories and associate them and link them across time.
*  I mean, I'm not trying to criticize or harp on this at all but, you know, the real dream is connecting synaptic cluster to composing a symphony or imagining a, you know, story or something like some quote unquote, higher cognitive ability.
*  The way I think about it, but this is a hypothesis, is that these small clusters, we have a review on this, every cluster is like encoding a piece of a sound that you frequently hear together, like a word, right?
*  Which consists of phonemes, because these phonemes are frequently counted together in a given word, they are encoded by a small cluster.
*  So you can think of clusters as words or pieces of music. And then you can combine them in different ways by activating different dendrites, let's say, or the critical compartments that contains these words and generate sentences and generate the sounds or music or a symphony.
*  So this gives you the opportunity to form many, many different combinations of items that have a meaning. They form a word or a sound. And that's how it's easy to encode this, you know, using fewer resources like five synapses.
*  But in a way that is when you activate them, the signal will go through because it will generate a dendritic spike. So it's a strong enough input, let's say.
*  And it's a way to increase the signal to noise ratio also by having these small clusters carry the meaningful information. That's how I think about it. But as I said, it's a hypothesis.
*  I mean, thinking just about music and you said phonemes, I had David Popol on a long time ago. And I've had other people also, you know, even recently, Earl Miller, and they're interested in oscillations and their contributions to, in David's case, like words and the different bits of words like the phonemes and the, you know, whole words, etc.
*  And just the rhythm that we speak and understand, etc. Do you have, do you consider waves as important? Have you thought about that as part of the story with an interaction with the synaptic clustering?
*  To be honest, I haven't thought about that a lot. We haven't modeled the waves in our models at all. I think they are important for sure. Especially when you think about the role of interneurons and how they are modulated by, you know, oscillatory rhythms. But yeah, I don't have much to say because we haven't really worked on that yet.
*  But you do incorporate interneurons into your models.
*  We do, but we don't really study rhythms that much. We have them being modulated by rhythms like in their inputs. So the fire at the peak or the trough of theta depending on the experimental data. So we do that. But we haven't really studied explicitly what would be the impact, let's say, of these rhythms on encoding, which would be a very interesting question to ask.
*  Yeah, we are kind of enforcing them in some way then.
*  Yes, exactly. We are enforcing them. They are not, you know, an emergent property of the system.
*  Right. Yeah, you define the timing. The other thing I was going to ask about when you're talking about intrinsic plasticity.
*  So this has to do like with your work with Silva, the engram. So you buy into the idea of an engram. So with intrinsic plasticity, right, you have correlated signals coming into a neuron and it stays active or ready to be active in a state for a short period of time, right?
*  So then you can associate more things. And that would be an engram cell, correct?
*  So an engram cell by definition is, my definition at least, is a neuron which is involved in the encoding of a particular memory. That's why you call it an engram. So you learn something and this something is somehow stored in the brain.
*  It's, you know, somewhere and this somewhere is, you know, a group of neurons that when you try to recall that particular memory, they become active. So that's an engram.
*  It's a part of a memory. It's a cellular correlate of the memory and engram cells. There is a lot of literature saying that they remain active for a few hours so that they can capture more memories and they remain active because they have increased levels of
*  So essentially it's like lowering the threshold for somatic activity so it's easier that they get activated by subsequent inputs. So yeah, I think the engram is a valid story. Many people are working on memory engrams. How else would a memory be stored in the brain? It has to be somewhere in the neurons, right?
*  Well, that's what I was going to take us to next. I'm sorry, maybe this is I'm getting us too far afield, but someone like Randy Gallistole would say, given, you know, this just constant turnover of plasticity, connections, disconnections, new formations, strengthening, weakening, homeostatic, intrinsic, that all that's too changing and you need something much more stable. And, you know, his idea is that you have to encode it in some sort of longer form.
*  Material like RNA or DNA or something, right? And I guess the story would be that during this plastic time, this intrinsic excitability time for a few hours, it's actually the neuron like subcellular machinery, quote unquote, molecules, right? Encoding that activity in some sort of RNA sequence.
*  Does that I'm not sure if you're familiar with that story, but his argument is that it's just you can't an engram is too plastic. It's changing too much. Like how could a memory be stored in an engram?
*  Okay, so there are two answers to this question. First of all, I agree that there is a lot of dynamic activity in the brain. And in fact, this turnover is extremely useful, at least in our models and in animal models, it shows that if you have higher spine turnover, then you learn learn faster.
*  One reason could be because you're overriding previous stuff, right? And that's why you learn faster if it's possible. But on the other hand, the number of synapses that are activated every time we try to recall something or we learn something is very small.
*  It's like 2% of the inputs in a given neuron. So I don't think that capacity is really a problem here. Every pyrrhymedal neuron has 10,000 excitatory inputs. If you only use your 2% of those for a given memory, and then consider that you have all those combinations of neurons that you can use to form a cellular engram, you know, the number is huge.
*  And even if you consider what we are claiming that the actual engram is at the dendrites level and not necessarily the neuronal level, then it increases massively. So I'm not sure I'm convinced with the argument that we run out of space in terms of storing memories.
*  That's one thing. The other thing is that you have much higher, let's say, turnover or dynamic activity in particular areas of the brain like hippocampus, for example, where its job is not to store these memories forever.
*  Its job is, let's say, to create episodes. Its job is to link things together. And then according to the two-stage memory hypothesis, whatever is really useful information is extracted and stored elsewhere in the cortex, where the turnover is slower and the hippocampus is there essentially to reach out to these places and bring back the pieces of information that will then be integrated and form a memory.
*  So there are solutions to this problem by existing theories, and I don't think they are unrealistic. Now, it is also possible that some aspects of, if you want to call it memory, are also stored in the DNA.
*  People talk about epigenetics as another mechanism for storing memories for a very long time. And I am not rejecting that idea. I just think that those are different kinds of memories than the ones that we use on a daily basis.
*  Yeah, okay. Yeah. So this is another thing I was going to ask you. So I'll just ask it now. Sorry to kind of interrupt there. But yeah, I mean, should we think about memory as being at multi-scales also, right? And that kind of...
*  Absolutely. Yeah, yeah. And distributed.
*  And distributed. Yeah. Yes. Because you're familiar with the RNA transfer in worms and what is it, sea slugs? I don't... Where you can train a conditioned response in one organism and then extract some RNA, put it in another organism, and that new organism will have that, quote unquote, memory, which is a behavioral output in this case.
*  Yes. Yes.
*  But how should... So then you think, well, maybe that's not that complex of a memory. Maybe it's just that is somehow encoding the right activities for that given behavior or something. So is that how you think of it as kind of a multi-scale memory?
*  Yes. Yeah. I think there are also experiments in mice when they've shown that there is a hereditary aspect of different behaviors that they think they are transmitted, let's say, to the offspring through epigenetic mechanisms in the sperms and the sperms, I think, or both of the eggs.
*  I can't remember it quite. And seen in multiple generations later, which are changes in the behavior. So that's why I'm saying I'm not rejecting that idea. I'm not fully convinced either because you have a lot of behavioral mimicry here.
*  So you can... I don't know if you can for sure make the distinction between an animal learning from another animal through behavioral mimicry versus inherited memories. But yeah, I like to be open-minded, let's say. And definitely, I believe that that memory is multi-scale and distributed and there are different kinds of it taking place, different parts of the brain and possibly other organs.
*  It's fascinating. I find myself sort of surprisingly, to me, just becoming more and more enamored with the multi-scale capacity, just the capacity, right? For that to be such a beautiful... It's becoming more and more beautiful to me as we go along. Anyway, it's nice to still remain in awe of things, right? After such a long time studying stuff. You have children, right?
*  Yes.
*  Three.
*  Three. Okay.
*  Yeah.
*  Oh, man. That's like three too many for me. I have two kids. But do you ever worry like, are you like me that your former self wasn't as careful and not the best human? And you know that I worry, what did I pass on? Did I pass on some trauma through epigenetic mechanisms to my children? Do you ever think about that?
*  Yes, I do. I do. Especially because in our line of work, we work very long hours. We're very stressed and then, you know, it's possible. I mean, there are studies showing that the stress can impact the embryo in many unforeseen ways. So yeah, I hope not.
*  Maybe just the good parts, hopefully.
*  Let us hope.
*  I keep telling myself that. So again, I'm kind of jumping around here. But one of the things that dendrites do is they had this nonlinear effect, right? Which is kind of emulated in sigmoidal functions somewhat in artificial networks. But these days, artificial networks don't care about sigmoid functions. It's all ReLU, which are these like linear functions, and they do just fine. What does that mean? What should we take from that?
*  Very interesting point. In fact, the ReLU is not, I mean, most of the people, they don't use the fully linear one, right? It's saturated even. So it's not linear, first of all. It's not sigmoidal.
*  It's not sigmoidal. It's not logger. Yeah. Yeah.
*  It's not sigmoidal, but you couldn't call it linear, right?
*  It's linear with two parts. I mean, do we, how picky do we need to be?
*  Well, a sigmoid can, any function can be approximated with small linear parts, if you think about it that way.
*  Okay, true. Your calculus is coming through.
*  So it depends how many linear parts do you need, right? That's a big question here.
*  Okay.
*  Yeah.
*  Good question. They're doing great with ReLU, I know. And we are using it in our networks as well.
*  Maybe it has to do with the plasticity rules, the learning rules that these networks use, which are not very similar to the biological ones.
*  Well, so would the suggestion then be that those artificial learning rules are more powerful than the biological ones?
*  Well, I think that nobody can say that the back prop is not a super powerful learning rule, right?
*  Well, people talk about how ungodly slow it is.
*  Backflow?
*  Yeah, because you're just taking very small nudging steps, right, toward a gradient, right? And it takes a machine.
*  Yeah, but you're always taking the right steps. You're always moving towards the right direction.
*  So in fact, you know, happy end rules are slower.
*  Well, there's a guarantee, but computationally slow, perhaps. I'm not an expert enough to argue about this, but yeah, that's what...
*  No, I don't think that the argument is that it's very slow.
*  The biggest argument for us, at least in your scientists, is that I am not convinced that it's biologically plausible, personally.
*  And because I don't see how exactly would one layer know what the signups of a layer, you know, three, let's say, three steps deeper.
*  How would that know a particular weight of a neuron? How did it contribute to the output that was computed five layers higher?
*  Right. Yeah, it's clearly not biologically plausible as such, but I mean, you're aware of the approximations, right?
*  Yes, yes, yes, I am. That's one thing that I'm not convinced of.
*  And the other thing that I don't really buy with this theory of correction is that a lot of the studies show that dendrites in fact compute associations.
*  They compute coincidences. That's when you have the generation of dendritic spikes.
*  It's not when you're making an error and therefore you don't have input coming in, but when you have two inputs that happen to coincide, so you are positively detecting conjunctive signals.
*  Whereas in a method that is based on errors in order to correct a system, it doesn't really align well with the experimental evidence that dendrites normally fire when you have conjunctive inputs coming in.
*  So these are the two things that for me, they don't sit very well with the way dendrites are teaching the brain, are helping the brain to learn.
*  Is that why you're modeling spiking neural networks?
*  We're modeling all kinds of networks, biophysical spiking and artificial neural networks. And I think the spiking neural networks are important for many reasons. First, they are closer to the real thing, right?
*  Oh, they're going to say efficiency.
*  No, I was going to say they can generate spikes. So they are closer to biological neurons.
*  Secondly, they are much easier to be implemented on neuromorphic hardware, which is designed for this purpose. And I think that neuromorphic hardware and any new technology that is trying to consume less energy is the future.
*  So yes, they are efficient in that sense. They are faster. You can implement unsupervised learning rules much more easily on these systems.
*  And you don't have to incorporate all of the complexity of the biological neuron like we did with Huxley and Huxley models that we also use in the lab extensively.
*  So I think that a very good compromise between the detail networks and the very, very abstract networks that we use in artificial neural systems.
*  How do you decide what level of biological detail is the right level?
*  Excellent question.
*  Is it a matter of your computing resources? I'll just leave it as an open question instead of putting answers in your mouth.
*  We try to follow outcomes razor. So as simple as possible, but not simpler to answer the particular question at hand.
*  So if you want to study receptors, let's say how the NMD receptor or how sodium channels influence the dredic integration, I would go to a detailed biophysical model because that's the only way to capture the kinetics and the special temporal interactions
*  between mechanisms in a dendrite. You have to incorporate the morphology and the conductances of the other channels and all the gating parameters.
*  So if you want to go very subcellular, you need a detailed model. But if you're interested, let's say, in how dendrites impact circuit computations, then you don't really need all this detail.
*  You just can abstract these local computations into a mathematical function, a transfer function like the induction of a long lasting spike, let's say, not a purely mathematical one like a sigmoid, but something that somehow incorporates the temporal dynamics of dendrites and put it in a spiking neural network.
*  And then now you can build a big network because you don't have very expensive subunits now. You don't have tons of differential equations. You have a few and then simulate large circuits and see how the dendrites influence circuit computations.
*  And then if you want to go to machine learning and see whether you can make a difference there by adding, let's say, some of the dendritic features, you can also build classical artificial neural networks that don't consider time like spiking neural networks.
*  So we do all three, let's say, approaches in the lab.
*  So this is what, well, maybe you can just say a word about dendrify.
*  Dendrify. So dendrify is a new tool that we just published in January. It was published in Nature Communications. It's a tool that is very close to my heart because the idea is to convince the community that you can put dendrites into your model in a very, very easy and straightforward manner.
*  So essentially we find a way to describe the dendritic nonlinearities without using the Huxley and Huxley equations, which are computationally heavy, but also mathematically demanding for some people.
*  So we are describing the nonlinearities with event-based mathematics. So it's very simple. You have an upswing and a downswing, let's say, current to simulate an action potential, so the maximum potential in the dendrite.
*  And similarly for an MDA and calcium spikes, we're now building in those aspects. In fact, we initially they were not there. So this is a tool. It's very well documented.
*  It's built on Python. We have examples in there for any naive user so that they can go in and play. And we are maintaining the tool in the lab.
*  And we, in fact, we are going to give a technical workshop in the CNS meeting this summer. So if people are interested, they can attend that. And we're looking forward to convincing more people to work on dendrites.
*  How's that going?
*  I think it's going very well so far. Yeah, I see a lot of publications, in fact, lately incorporating dendrites, not necessarily through Dendrify because this was just developed, right? But people, a lot of people are getting more and more interested about dendrites, and especially with respect to their impact on the machine learning and AI field, which is great.
*  Yeah, well, I don't know, is it? I mean, do you think that it so now I'm going to ask about the AI field. So, I mean, I don't know how much interaction you have with people in AI in like the industry side right applications and stuff but not much.
*  Okay, so they don't give a damn about dendrites. I'm sure. Yeah, I know.
*  Someone was I can't remember who it was was talking about.
*  It seems like almost every lab, especially computationally oriented labs considers like building will will build this standard tool that and make it open source and then the community will use it and will share it and and it takes a lot of effort to probably to build something like
*  dendrify. And then, often what happens is you build the tool.
*  You put it out there and then you know you're expecting like a lot of collaboration and to have interactions and stuff but you almost have to like sell it to the community, right.
*  How much of how much of what you're doing, by the way, how much of what you're doing is actually you know getting out there and saying use dendrify here's the thing, you know, or people do much selling to be honest I know I haven't done it for two reasons.
*  First of all, I think we have to convince people to be interested in dendrites, and then to use dendrify right because the community is not that large anyway. So I'm definitely focusing on convincing people that dendrites are important and they should be looking into them.
*  Dendrify essentially, we didn't really initially wanted to make a tool. It's the work of a PhD student that just wanted to make his life easier.
*  Okay, because he wanted to build the spiking models and you know he wanted to avoid the complicated equation so he came up with dendrify. So yeah, so we, we did not plan to generate a tool for the community and maybe that's why we're not selling it as much.
*  But there are a lot of people that expressed an interest so far to use it and they reached out and we've helped them. And I definitely believe that it's not enough to make a tool and just put it on a website because people need to be trained to use it right so you have to offer some
*  training opportunity. In fact, it's a responsibility if you want the community to you know take advantage of what you created you have to show them how right and that's why we are organizing some training workshops for that.
*  But yeah, but we don't plan to become tool developers we just want, you know, whatever we think is helpful for us to make it available to the community who is interested in dendrites.
*  But now you can't help it but you feel that responsibility, it's, it's taken on a larger role than originally planned just to solve students problem. Yeah, that's a good point. I'm hoping the student will still be interested in maintaining
*  you running a lab. I'll never know. Yeah, perhaps.
*  Maybe you're better off.
*  Oh, I don't know what do you think you think I'm better off. Now I actually I'm kind of like looking for a job I don't think I'll be running a lab, necessarily, but, well, maybe that's a separate conversation.
*  Running a lab, yay or nay.
*  Running a lab is difficult, especially if you are in Greece.
*  Funding resources are very limited we already mentioned the lack of collaborations and you know,
*  Which are like seven other people in the world studying. Yes. Yeah, I mean, that may be good because it offers a niche opportunity, but it doesn't, you know, make sure that you have enough funding for it.
*  So, you know, the efforts to secure funding are exhausting I think that exhausting for everyone nowadays and that's why many people leave academia, unfortunately, but yeah, it's a lot of work and a lot of responsibility towards the people in the lab right that depend on you securing funding for their future.
*  So, on the other hand, it's super fun and it's so rewarding because we're always trying to figure out something new. I mean, I love my job right that wouldn't change it for anything, but it's certainly very stressful.
*  So I just moved to Pittsburgh, Pennsylvania, where I did my graduate school.
*  And there are a couple people a couple friends still here, and I'll reach out to them saying hey it'd be great to go, you know, grab a coffee or a dinner sometime and they're like yes great, but it needs to be like two months from now.
*  You know because they're running on quote unquote running on fumes you know and I don't think that that never changes does it.
*  Well, I think maybe the US is worse than Europe, but yeah it's I mean if you're running a successful lab or you want to have a successful lab it means working over time working too much.
*  And, you know, I often wonder whether it's worth it, because there are other important things in life, family, shelter, you know enjoying life, and you've already ruined your children by passing on your stress.
*  You know they don't want to be scientists so good for them good for them good for them yeah.
*  Let's talk a few more minutes about so.
*  Alright so you've created this dendrify, and it was when it in nature communications which I don't was that a hard sell getting it.
*  Is that easier than I expected. Oh really, I wouldn't I wouldn't I don't know like I don't I haven't like watched and I don't have a track record but like it's essentially a resource, you know.
*  And it's a tool. Yes, it's a tool and maybe that's maybe that's what nature communication specializes in and I'm just naive. No, no, no, it doesn't.
*  It. I think the reason they really liked it is because it bridges multiple fields, so it's good for modeling in your science, but you can also use it for machine learning and artificial intelligence applications and it's readily implementable in
*  neuromorphic computing. And we also with it we propose a framework about why gender rights are important and how you study it. So it was a bigger thing that spans multiple communities and I think that that's why they, they really liked it.
*  Okay.
*  Yeah. Okay.
*  Right. So way back when I had Nathaniel DA on my podcast and he was talking, so he is a traditionally computational cognitive scientist neuroscientist.
*  We got. Okay, we got into a conversation about I'm sure you do. Yeah, through your match and everything.
*  We got into a conversation about how he, he and his friends lab, lab advisor friends, principle investigator friends were thinking hard about whether they should start an experimental lab, because they have all these theoretically driven computational research, research approaches,
*  and that they make predictions, but then you have to like convince people to do the experiments and the question is well do we should we just start our own wet lab to like do the experiments that our computations suggest our theories suggest, and I said no, but you didn't take that
*  advice because you're.
*  You have transitioned your lab to become also an experimental lab.
*  How has that transition gone was that was that a wise move.
*  Well, it's kind of early to tell because we haven't published our first experimental paper yet. Until that moment comes I don't think I can answer this question, but I can tell you why I did it.
*  And I did it because, well, one reason is, as you said, we have to convince our collaborators to do the experiments we want and that rarely happens.
*  In fact, most of it, and I am a strong believer of collaboration. I have a lot of collaborations with many people, but most of the times it's, you know, the model comes in to explain the experimental data which are generated by the experimental labs.
*  Right.
*  And I really wanted to be able to have a control of the type of experiments that we do so that we can test our own predictions as you said this it's it's let's say the satisfaction that you get by making sure that someone looks into all this hard work that we've done over years to generate
*  these testable predictions. The other reason is because, you know, the animal is the real thing.
*  The model is a model it's great it's an amazing tool. Right. It can allow you to do experiments which are not even feasible experimentally so it has an immense amount of power.
*  But the real thing is what happens in a biological brain, and I really wanted to get a better inside the, you know, of these processes. It's been fun.
*  It's much slower than I expected, more expensive than I expected.
*  So, the development or the actual research or like the development, like getting the both labs set up and okay both both both, I mean and behavioral experiments that we do right now.
*  They last a month. And then you have to wait another two months for the animals to be at the right age and then start again and it's taking forever, which is something I had not really considered because modeling is much faster.
*  I'm just saying that I've been anytime I asked that people say, well no it's not necessarily faster. It really is faster right. It is faster. It is faster. I mean, it can take a very long time to troubleshoot to find the back to optimize a model but you know it's faster.
*  It's definitely faster. It's not significantly easier. I wouldn't say that. In fact, I think that doing experiments is easier because you need to have really good skills with your hands.
*  Whereas for modeling you really need good skills with your brain.
*  And with live experiments you're doing a lot of waiting around often. Yeah, exactly. Which is nice. It's you know more social more relaxing it gives you more time to think.
*  Yeah, but producing results is faster with models and with experiments for sure.
*  So when can we expect the first paper, experimental paper?
*  Well not very far. But then again, I don't have a good feeling of what reviewers will ask.
*  Oh, oh right. Because you have to submit it first and then see.
*  You know, and it's also always the fear that when you are a newcomer in the field, you have to convince people that you can actually do experiments. So yeah, we'll see.
*  Good luck. Good luck with that. Thanks.
*  These are rodents though right?
*  Yes, we're working with mice and we're doing the in vivo head fix behavior, looking at the prefrontal cortex and looking at behavioral flexibility and how the dead rates or you know spines and spine turnover may contribute to behavioral flexibility.
*  And in fact, we started this project with funding from Germany together with Matthew Larkum. So we have an aspect of the work that is done in Matthew's lab actually.
*  Founded by German grant and now we're continuing it here at IMBB.
*  And I'm actually very happy because we have set up the first two-photon microscope in the Institute.
*  Congratulations.
*  So this is going to help others as well.
*  I think it helps create excitement around dendrites that people like you and like Matthew are working on them and doing such interesting work. I mean, you're good spokespeople for the dendrites community maybe I would think.
*  Thanks. Yes, we'll try our best.
*  I asked about the rodents because
*  Ultimately, we're interested in human brains, right?
*  A. So, so first of all, you start many of your talks with a slide that shows the progression of dendrites over the course of our lifetime.
*  And it's pretty striking actually. You and I are right now at the peak of our dendritic arborization.
*  And our life.
*  Well, I'm at my peak but that ain't saying much for me.
*  But it really shows it's pretty striking because like, you know, from birth, you have these neurons with with kind of small branches, right, at least on these in this on these slides that you show.
*  And then from I think 30 to 60, they get bigger and bigger. And then, you know, there are these beautiful outstretching trees when you're your age.
*  And then we're going to start to decline, you know, sooner rather than later, I suppose. And then they kind of shrink back down again and you show like dementia and Alzheimer's and how they shrink back down in different conditions and just with aging.
*  But, and those are human cells that you show right? Yes, those are human cells. I'm not sure about the difference between human aging and other organism, for example, mice.
*  I'm sure that you know the answers to this like the dendritic arborization, you know, actually I don't I should look it up and have a similar slice for a slide for mice. I bet it's similar but I have not looked at the, you know, the same figure for my
*  their cognitive peak must be like around 30 days.
*  From 30 days to two months they are adults and I think that's when they have their well up to six months they're still considered young and then they start to age.
*  But I have not seen a respective slide with, you know, the dendritic anatomy for these animals. So I should be better prepared. I'll find one for my next talk.
*  Yeah, please prepare yourself better.
*  But are human dendrites special?
*  Excellent question. Yes. Well, some people think so. I mean, we even thought so three years ago when we published this paper with Matthew Larcombe in Science where we discovered that there was a new type of a dendritic spike in human dendrites that was not previously seen in rodents,
*  and which allowed these dendrites to solve complex mathematical problems like the exclusive or, but then a year later, the same kind of the dendritic spikes were found in rats.
*  Yeah. So, at least that particular aspect was not what makes us humans was not what differentiates the dendrites of rodents from the dendrites of mice.
*  It's a very interesting feature, nevertheless, because it was the first time that we discovered a mechanism that has a non-monotonic activation function. As we discussed previously, we use sigmoid activation functions which are monotonic to model dendrites in abstract models and in detailed models as well.
*  And this was non-monotonic. So it goes up and then it falls, which means, and that's why it allows the dendrite to solve the exclusive or problem which requires a non-monotonic function.
*  So it's interesting to know that there are these kind of computations in dendrites as well, even in rodents. We had not considered that before.
*  But whether there is something else that is unique, I mean, we know there are differences, right? There are differences in the size, there are differences in the compartmentalization. Human dendrites are much more compartmentalized than mice.
*  What do you mean compartmentalized? Like smaller, like more...
*  They are longer. First of all, they are bigger. And the compartments, they don't communicate with the cell body with the same strength as they do in a mouse neuron.
*  So there is much more attenuation of the signal to reach the cell body, which means that they are more independent because they don't talk to each other as much as they do in the mouse. And they don't talk to the cell body as much.
*  So you can think of them as having more parallel units if we are to think each part of the dendrite as an independent unit, which could be one reason why humans can do more difficult cognitive tasks if you correlate the number of parallel units in the mouse and the human.
*  That could be one reason, let's say.
*  Yeah, I guess we could tell ourselves a bunch of gesso stories about this though, right? I immediately thought, well, it's more compartmentalized, more attenuation. That means like you can have like subtler differences and finer scale and thus higher capacity, but I'm just telling myself a story there, perhaps.
*  Well, I mean, we know that if you have more compartmentalization and every compartment is nonlinear, then you do have a higher capacity. I mean, we've known that for mathematical models. So it's not the story. I think you can, you know, it's a convincing story, let's say.
*  Whether that is the reason we can solve more difficult problems though, that's, you know, hypothesis.
*  Yeah.
*  Because you have many such neurons and circuits in the mouse brain that maybe is sufficient to solve the same type of problems that you would with fewer neurons in the human brain. So we cannot tell that this is a differentiating factor.
*  It's a matter of scaling up.
*  If it's just a number of compartments, it's just a scale up version. And is that the reason we are, why we are better? Is it a matter of scaling up?
*  We have, I mean, we also have like a larger brain to body ratio. We also have opposable thumbs, which helps.
*  Right.
*  So what has your career gone? Let's see. Have you made the right choices? Did you get in the right field? Are you doing the right thing? Are you happy with the trajectory and the journey?
*  Yeah, I think I've done a lot of wrong choices that ended up putting me in the right spot.
*  Oh, that's a nice way to put it.
*  Yeah, I mean, I'm very happy with where I am right now and with my life and career right now. But, you know, the path was not easy.
*  As I said, I, you know, I couldn't study neuroscience early on. Then I went back somehow. Then I returned to Greece and there was no competition in neuroscience.
*  I did bioinformatics for 10 years. So I had to change my research direction and then wait for an opportunity to come back to neuroscience. It was complicated.
*  Luckily, your brain is very plastic with all those things.
*  Exactly. I think I feel fortunate that I was able to, let's say, take advantage of all of the misfortune, if you want to call them like that, or opportunities to deal with different things.
*  So I ended up being where I wanted, even though the, you know, the road was not the easiest one.
*  Yeah.
*  The path was not the easiest one.
*  Okay, Piotr, I have one more question for you. And I don't know if you can answer this, but if you kind of zoom way out and just think about how you have viewed dendrites with respect to their importance and role and computation and life and intelligence, how have your views changed over time? How have they evolved?
*  Well, in fact, they have because initially I was thinking that dendrites are really, really important because they allow the brain to do more advanced, let's say, computations that we could do with the point neuron systems, which is true, right?
*  A point neuron cannot solve a nonlinear problem, whereas a neuron with dendrites can, and we've shown that, right? But I now kind of think that their more important role is not necessarily their ability to solve more complex computational problems, but they do this as a means of increasing the efficiency and the, you know, power savings and the resource savings of the brain.
*  And that you could do the same stuff with point neurons, but it will be so much more expensive. So now I look at them from a slightly different perspective, trying to figure out what are the advantages that are offered by dendrites in circuits, in large neural network systems that are not necessarily focused so much on the improved computational capabilities, because, you know, we've known they are there, right? We've shown them.
*  But with respect to efficiency, speed, energy, you know, making a system more sustainable and how we can take this knowledge and use it in other fields, transfer the fields to machine learning and AI, for example.
*  So what I want to happen, I want to be more excited about efficiency just as a, as a phone. I know it's important, but just from an intellectual curiosity vantage point, like I want to like think, oh yeah, efficiency is really cool.
*  Okay, let me give you some examples. Edge devices, right? If you want edge devices, you know, devices that...
*  Yes, edge computing. So if you want ChachiPT or the next version of it to run on your smartphone or even something smaller, you have to fit it in, right?
*  Yeah, that's the, I know that's important.
*  But that doesn't, you don't care about. Let's say the sustainability of our planet. We cannot burn...
*  I know it's important. I know our planet is important. It's just there's something that, that's not like the wonder and awe of our intelligence is not contained.
*  I know efficiency is part of the story, but I'm thinking more of the capacity and the plasticity and all of that stuff is like cool to me, right? And efficiency is necessary.
*  Yeah, I see what you mean.
*  So, but all of these properties, why are they more, why are they cooler than, you know, doing all the kind of problems, solving all the kind of problems that you're interested in, in doing it in an efficient way, because you need to have both, right?
*  Efficiency on its own is not enough.
*  You need to also have very powerful computing systems.
*  Right.
*  Right.
*  Well, not if you're super, super, super efficient, right? You can then you can reduce the computational power if you can just run a lot faster and with less energy, because it would just do this.
*  It will take longer to compute, but it would be compressed in a lower efficient, lower power efficient system. I don't know. I'm not a computing...
*  No, no, no. But what I'm saying is that we want to have smarter systems, right? We want child GPT to be better. We want whatever the AI to reach the generally...
*  Well, I'm not sure we do actually, Hinton resigned, right? So this is a controversy issue, let's say. But let's say if we wanted to have systems that learn like the human brain, they don't forget, they don't mess up things.
*  They are great. And you run out of technologies to generate them because they are not efficient. You will never get there. So you need to have both. You need to have a way to build intelligent machines and you need to have a way that these intelligence machines, you know, can run on a laptop.
*  Here's why I'm not excited. Here's why it's not exciting to me because I what what is exciting to me is the explanatory part, the understanding.
*  You're right. I should have mentioned that. That's a great point. So the other reason we are interested about understanding how dendrites achieve efficient computations is because we want to understand how they do it.
*  Right. And in a computational model where you explicitly simulate dendrites and you look at the readout impact at the circuit level, for example, and you measure the differences within without dendrites and you try to look at what is it that dendrites encode?
*  If you have them and what do you miss out if you don't have them, you increase the explain explainability of these systems massively. So you no longer have a black box.
*  That's that's another reason why we care a lot about understanding how dendrites contribute to advanced computations.
*  OK, you've taken me one step closer to caring about the caring.
*  Otherwise, you wouldn't care about them. That's terrible. That's really sad.
*  No, no, no. Yeah, no, I think it's exciting. I think it's really cool.
*  As I started this podcast, it's this episode, it's just daunting.
*  You know, it's like one step further removed from being able to grasp what's going on.
*  Right. Because there's so many more dendrites and so many different types of plasticity within the dendrites and configuration.
*  And, you know, as you've demonstrated.
*  Don't think. Yeah. I mean, biology is complicated. Right.
*  But we've we've come a long way. And now we know so much more than we knew 20 years ago.
*  And now the technology has advanced so much that we can manipulate dendrites in vivo in the behaving animal.
*  There are like five or six laps we can do it, but they can do it now. Right.
*  And we found really exciting things experimentally that they underlie perception that they may be responsible for the for anesthesia.
*  These studies are from the lab. They may be implementing predictive coding across different regions.
*  So we've we've learned a lot of stuff about why dendrites are important in the biological brain.
*  Right. Well, if we can take some of these understand understanding and transfer it to artificial systems, that's already a major win.
*  I think. Yeah. But the but the community doesn't care.
*  Well, they actually you're wrong on that. There is a lot of papers right now coming out talking about the need to come up with more sustainable technologies.
*  And in that search in the search of more sustainable technologies, I bet they will care.
*  They are already care about bio inspired properties that they want to add to their systems in the hopes of making them more efficient.
*  Dendrites are unfortunately not on the map for them.
*  And I think they are not on the map yet because they are thinking of them in terms of the computing capabilities which they offer to the systems as additional units and not for their efficiency properties.
*  That's why I think it is important to understand them and characterize them because they will become a key player in the years to come.
*  What are the things that they have their eye on in bio inspired like neuromodulation, modularity.
*  Different plasticity rules, biological plasticity rules, you know, restricted connectivity, sparsity, things like that.
*  Some people are starting to look at them. Right.
*  Some people have looked at the data customer action potentials that we publish.
*  So the human like let's say features, but again in hopes of providing more advanced computational power with the systems, which I really think that that should not be the main focus for the bio inspiration.
*  All right, Johto. Johto, I think that I've taken you far enough. I appreciate all your work in bringing dendrites to the fore as well and I hope it continues to grow.
*  And although you'll continue to stand out, especially now that you're going to be doing experiments to back up your modeling.
*  So thanks for joining me here. I really appreciate it.
*  Thank you so much, Paul. I had a lot of fun. I hope people enjoy this.
*  I alone produce brain inspired. If you value this podcast, consider supporting it through Patreon to access full versions of all the episodes and to join our discord community.
*  Or if you want to learn more about the intersection of neuroscience and AI, consider signing up for my online course, Neuro AI, the quest to explain intelligence.
*  Go to brain inspired dot co to learn more. To get in touch with me, email Paul at brain inspired dot co.
*  You're hearing music by the new year. Find them at the new year dot net. Thank you. Thank you for your support. See you next time.
*  Yeah.
