---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 5247s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 3701
Video Rating: None
---

# BI 103 Randal Koene and Ken Hayworth: The Road to Mind Uploading
**Brain Inspired:** [April 26, 2021](https://www.youtube.com/watch?v=WjGvPrJvR8k)
*  Whole brain emulation, mind uploading, that is something that is a logical consequence
*  of a successful neuroscience.
*  Then you have to look in more detail at your philosophical reasons for thinking one thing
*  or another and why do some people feel okay with it and some don't.
*  And then you end up coming down to something where you realize, oh, those aren't really
*  based on any evidence at all.
*  They're based on beliefs.
*  I think that we understand the brain enough today we can preserve a brain or an entire
*  body so that if neuroscience is successful in the future, that preserved person would
*  be able to be revived as an emulated copy.
*  I see this as sort of an understanding ourselves and a launch point for what I guess I think
*  of as a kind of Cambrian explosion of new ways that we can develop and that human culture
*  can develop not just by itself but also sort of in cohesion with this whole ecosystem of
*  intelligences that we're developing along the way.
*  Why don't other neuroscientists talk about this?
*  And the answer that as far as I can see is that...
*  This is Brain Inspired.
*  Greetings friends.
*  Today I have on two neuroscientists, Randall Kern and Ken Hayworth, who in addition to
*  being neuroscientists are both interested in mind uploading and they devote a lot of
*  their cognitive resources to figuring out how we can go from where we are now to uploading
*  our minds.
*  Randall Kern does this through his carbon copies.org organization that he co-founded
*  and their goal is to advance building substrate independent minds.
*  In other words, minds that run on stuff that isn't brains.
*  And to do this, Randall and his colleagues are seeking to implement whole brain emulation.
*  That's also what Ken Hayworth is interested in.
*  Ken is a neuroscientist at Janelia Research Campus where he does cutting edge electron
*  microscopy to look at the fine structure and connections of nervous systems.
*  And he's scaling that up to larger and larger brains, larger and larger brain volumes.
*  Ken is also the president of the Brain Preservation Foundation and their goal is to preserve brains.
*  More specifically, it's to preserve the structure in brains down to a level that would be necessary
*  to eventually implement whole brain emulation.
*  So that's the central idea here.
*  And both Randall and Ken know that this is a long term project.
*  So during this episode, we cover some of the current issues that they talk about and that
*  they're working on.
*  And there are so many of those issues that we really just scratched the surface here,
*  but my main goal in the podcast was to introduce some of the ideas and hit on some of the issues.
*  But it's worth me probably just summarizing the two main approaches that are thought to
*  be the best approaches to pursue whole brain emulation from where we stand now.
*  One is called scan and copy and the other is called gradual replacement.
*  So scan and copy is when someone dies, you can perfuse their brain with a solution and
*  preserve it so that later you can actually slice the brain up like brains are sliced
*  up in electron microscopy.
*  In doing so, you can scan the entirety of the brain structure down to subcellular levels.
*  And what you would end up with then is an entire scan of someone's brain.
*  And the idea is that we hang on to that scan until our technology advances to the point
*  that we can use the structural information to create a whole brain emulation in some
*  other substrate.
*  So that's one idea.
*  You scan the brain and then you essentially copy it into a whole brain emulation functioning mind.
*  The other, gradual replacement, would basically seek to replace little parts of your brain
*  and replace their function.
*  So let's say you could put a prosthetic hippocampus in one day with one surgery such that you
*  retain your memories and your ability to remember and spatially navigate and all those other
*  functions that the hippocampus performs for us that we continue to learn.
*  But then you go on and you have another surgery next Tuesday where you replace your prefrontal
*  cortex and on and on and on until gradually you replace all of the parts of your brain
*  and your mind is still constituted.
*  By now your brain is basically a replacement made of different parts like little computers, etc.
*  Those are very simplified descriptions of what we talk more about including all the
*  surrounding issues that are related to that.
*  There's a lot to think about.
*  So there are a lot of links in the show notes of course.
*  A link to carboncopies.org and brainpreservation.org.
*  So those are the two main websites but also other links to various talks and related content.
*  That's at braininspired.co.uk slash podcast slash 103.
*  Also on the website you can support the show through Patreon.
*  The little Patreon supporter discord group that I recently started has gotten more and
*  more active and fun lately.
*  I'm continuing to figure out how to make that more useful and enjoyable for everyone but
*  there's been a lot of back and forth there.
*  Anyway, that's one thing you get when you support the podcast through Patreon.
*  So thank you to those of you already tossing a few dollars toward the podcast through Patreon.
*  This is obviously a fun and exciting topic and it's really exciting that serious scientists
*  like Randall and Ken are working on these things and it was really a joy to talk to them.
*  So here they are.
*  I thought I'd start by asking you, you know, a broad overview.
*  What is it that each of you want, you know, with respect to brain preservation, with respect
*  to whole brain emulation and mind uploading and why personally that you want it?
*  Ken, maybe we'll start with you here.
*  So I'm a neuroscientist.
*  I spend my days building electron microscope machines to map brain tissue at the synaptic
*  level.
*  So at some level I am deeply committed to neuroscience being successful.
*  It is difficult for me to be this embedded as a neuroscientist and pushing forward the
*  field of conectomics and at some level not contemplate what this is going to lead to
*  in 100 years and 200 years and 300 years.
*  So that's, I think that sums it up mostly but very particularly and this is where I
*  think the vast majority of people disagree with me.
*  I think that we understand the brain enough today to be reasonably sure of how memory
*  and function are encoded in the nervous system and to know that we can, using techniques
*  that are common in neuroscience, that we could preserve a brain or an entire body so that
*  if neuroscience is successful in the future, if the technologies continue to develop, that
*  preserved person would be able to be revived as an emulated copy of their brain in the
*  future.
*  So that's, at one level, if there wasn't a thing called brain preservation, if that
*  was not an option, then all of this would be completely academic to me.
*  It would be kind of like if I was building rockets, I might casually say, oh, well, I'm
*  building rockets because one of these days we're going to colonize Mars but I'm going
*  to be dead by the time we do that so I'm just going to focus on building some rockets today
*  because I'm okay with this having, the future is out there and I have no connection with
*  it.
*  I think neuroscientists can definitely get into that mode today without realizing that,
*  hey, there is an implication today.
*  We do have, we certainly don't have anywhere near the technology to upload anybody today.
*  That is off the table for probably at least 100 years but we certainly do have the technology
*  to preserve people today in a way that most likely would allow them to be uploaded in
*  the future.
*  That's pretty much what I want out of this.
*  Why do you personally want it?
*  When you want to be re-uploaded to do what?
*  I have always wanted to experience the future.
*  You asked how did I get into this stuff?
*  I got into this stuff when I was, I don't know, 12.
*  I was dreaming about traveling to space, building rockets.
*  I wanted to explore other stars and when I dug into that, I found out, when I dug into
*  the science, I found out how very difficult it is to get a human being to another star.
*  It's almost impossible and it's certainly impossible within a lifetime.
*  Then for some reason, I was reading some neural network books around that time.
*  When you're 12?
*  You were 12 reading?
*  When I was 12.
*  Yeah, there was some books out there that was very low-level popular type of stuff.
*  But it made clear that we are just information that is stored in the nervous system.
*  It's like a light went off in my head that said, oh, if we're information, then we can
*  potentially travel at the speed of light.
*  We shouldn't be designing rocket engines to take 100 kilogram human beings across
*  to other star systems.
*  We should be figuring out how to copy that information so that it can be put on a laser
*  beam and beamed to the next star system.
*  It almost immediately switched me from reading all these books on fusion propulsion and
*  antimatter propulsion and all this other stuff that I was reading at the time.
*  It switched me over into looking at neuroscience.
*  I've never gone back.
*  I guess by 12, you had already read Einstein's relativity work as well and realized thatâ€”
*  I was a very stupid 12-year-old.
*  You have no idea.
*  I'm still catching up so much.
*  Well, that's great.
*  Every line that you guys are going to say is just going to make me want to stop and
*  open up the whole can of worms.
*  I'm going to try to be disciplined here.
*  Randall, I'm going to ask the same thing about you.
*  What is it that you want and why?
*  I think what I want is in many ways very similar to what Ken just said.
*  I don't think I have any major disagreements except that I did discover that there is a
*  slightly different motivation or at least a different way that I make my decisions
*  about the motivations involved.
*  By the way, I think just so that we can put that off to the side,
*  I completely agree with this notion of space travel that it is ridiculous to think that
*  we're going to send spaceships full of humans living in oxygen bubbles,
*  making their way across the galaxy.
*  That makes no sense.
*  You can see today that we're sending robots everywhere for a reason because they're
*  adapted to that environment.
*  That's the same thing you're going to get eventually.
*  At that point, it is also not essential whether or not that's traveling near the
*  speed of light because if you're adapted to those distances, you're also adapted to
*  the time it takes to travel those distances.
*  You're thinking beyond Mars.
*  Beyond Mars.
*  Because we're in our solar system.
*  Yeah.
*  What do you mean?
*  Look, if you think about it in the grand scale of things, the amount of time available in
*  the universe, even if you have to travel a million years to get to the next galaxy,
*  that's not an enormous chunk of the available time if you can make it.
*  I'm just saying we can think about time differently as well if you're thinking about
*  a different kind of embodiment.
*  Yeah.
*  So, and actually this gets to my main reason for wanting this.
*  I regard this as, Ken also said this is kind of the endpoint of where neuroscience is going and
*  we have to actually look at that and realize that.
*  But I also think that it has extreme value for the culture that we've created and what
*  we care about in a sense.
*  Because I think that this is similar to how we are exploring the genome.
*  It's to understand our blueprint and not just so that we know what's going on in there,
*  but also so that we can tweak and fine tune as necessary to overcome certain problems or
*  limitations or to achieve new possibilities.
*  So, why should we be stuck with memory that isn't real?
*  We're just reconstructing something according to certain patterns that we've learned and
*  so we can only see things that we think are already plausible because that's the context
*  we were exposed to when we were young and that sort of thing.
*  Or why should we only be able to experience the universe in a way where say a tenth of a
*  second is the smallest time interval that we can comprehend and respond to?
*  All that sort of stuff.
*  And more of course.
*  I see this as sort of understanding ourselves and a launch point for what I guess I think of
*  as a kind of Cambrian explosion of new ways that we can develop and that human culture
*  can develop not just by itself but also sort of in cohesion with this whole ecosystem of
*  intelligences that we're developing along the way.
*  That's part of it and I think that ties back into sort of the way that I see what I like
*  about life.
*  If I choose things that I care about versus things that I don't care so much about,
*  I often make that decision based on what I think of as say making ripples in the future.
*  So things that you do that don't make ripples, they can be cool, they can be fun.
*  Sure, I don't mind experiencing them but they're not as valuable to me as the things that do cause
*  a ripple that cause some kind of change going forward.
*  I don't know exactly why that is.
*  Nothing has an objective purpose, right?
*  Right.
*  So it's not better or anything, it's just how I seem to personally experience value.
*  I consider like, you know, so I have kids, my children could be considered ripples into
*  the future because if I give them a good shot at things then they may cause further ripples, right?
*  And if I can help inspire people to care about whole brain emulation and to reach a technology
*  level where we are no longer bound to a specific embodiment and we can expand and extend in various
*  ways, that will cause hopefully some ripples that do something into the future.
*  You know, whereas many other things I could do don't.
*  So interestingly, that's I think where I depart from what Ken said because Ken said at some point
*  that if brain preservation wasn't possible then it would be meaningless.
*  I don't see that at all.
*  I think even if there was no brain preservation, though I like the idea
*  because I'd love to be there, I'd still do it.
*  You know, just like someone in the early industrial age trying to develop
*  the things that caused the industrial age to explode or the space age or the computer age or
*  whatever and I sort of see this as the same sort of thing.
*  Well, Ken, I was a little surprised when you talked about brain preservation in that manner
*  as well because under the umbrella of whole brain emulation, the two main approaches that you guys
*  talk about, one of them is brain preservation method and then reconstituting scanning and
*  then doing a whole brain emulation through the scan and knowing the structure and inferring
*  function and etc. And the other major approach that you guys discuss is a gradual replacement
*  approach where you figure out the function of some cluster of something in the brain and then you can
*  replace it with a little machine or model and then you do that over time and you gradually replace
*  brains. Although, Randall, what you were just discussing seemed to suggest that what you're
*  interested in is different types of experiences and different dynamics of those experiences.
*  And I don't know if you're a deadhead. I just recently watched a Grateful Dead
*  documentary, whom I never enjoyed, but you know, the whole psychotropic,
*  psychedelic experience also kind of different types of experiences seem to be what a lot of
*  people are interested in and we're really, as humans, we have this very narrow possibility
*  of scope, I feel like, within our own subjective experience of time and how we experience time
*  and our own bodily experiences and how we view the world, sensations, etc.
*  So maybe, Ken, before I just continue to ramble, maybe you can answer his volley to you.
*  Well, I was saying something very specific. I'm not saying that it's useless to work on whole
*  brain emulation, even though it's a long-term goal. I think that it's obviously incredibly useful. So
*  for instance, if I had stayed in space propulsion, I would probably be fine working on
*  fusion designs, even though those fusion designs may not come about for another 100 years and I
*  would be long dead before it ever happened. The reason why I bring this up is because
*  what's unique about Randall and I is that we are out there and vocal about the idea that
*  whole brain emulation, mind uploading, that is something that is a logical consequence
*  of a successful neuroscience. And so the next question to ask is, why are you only vocal?
*  What's with all these other neuroscientists? I mean, you must be, and a person outside the
*  neuroscience community looking at this would say, okay, I would assume, would say, Ken, Randall,
*  they must have some crazy theory that any neuroscientist would bash down in a minute
*  because we all know that neuroscientists don't touch this topic with a 10-foot pole.
*  Well, they want to get funded.
*  Or maybe they won't get funded or something like that. But in matter of fact, and correct me if
*  I'm wrong, Randall, we are holding to the textbook models probably better than most neuroscientists.
*  We're not pushing radical theory. We're saying this is, we want the consensus view. We want to
*  know exactly what the consensus view of the last decades and decades and decades of neuroscience
*  are so that we can better project into the future what the consequences are. And we come back
*  time and again that this is a logical consequence of neuroscience. So the question comes back to,
*  why don't other neuroscientists talk about this? And the answer that as far as I can see is that
*  because mind uploading is we are not going to see anything close to that for decades and decades,
*  possibly centuries and centuries. The mind is so complex. The brain is so complex.
*  We are just beginning this journey of neuroscience. Ask any neuroscientist and they will say this over
*  and over again. There's so much we don't understand about the brain. There is so much complexity
*  our tools are so primitive in terms of getting to the circuitry and how it works. And that is the
*  excuse that they give to not rile up the public over something like the possibility of mind
*  uploading. And I would agree with that to the perspective of why wild people up? Because they're
*  going to be dead anyway. Let's talk about it internally. Let's work on it. Let's understand,
*  put our work in perspective, but let's not rile up the public. And if brain preservation was taken
*  out of the picture, that would be good enough. It would be, yes, this is a possibility in the future.
*  Everybody agrees that this is a possibility in the future, but we're not going to get there.
*  There's a lot of work to get from where we are now to there. And it doesn't make a lot of sense
*  talking about colonizing Alpha Centauri when you haven't set foot on Mars yet.
*  And brain preservation changes that dynamic because brain preservation is something that
*  we could be doing today. We could be doing it correctly given all that we know about neuroscience,
*  but we have decided as a society that that is also a taboo topic, presumably because
*  it's too futuristic, which is absolutely illogical. And that's why I keep coming back to it.
*  You say that we could be doing it today, but in fact, I mean, we quote unquote, you are doing it
*  today. I mean, there's there've been prizes awarded for this, you know, kind of what I wanted to do
*  just for not knowing exactly what to talk about. I wanted to come. I wanted it to take its own
*  pathway. But I thought we might start about what is known or what you guys are confident about
*  what we can accomplish right now with the current technology and with our current understanding and
*  maybe why you're confident about it. And I don't know, maybe just the brain, the glutaraldehyde
*  preservation technique is something to start with. If you want to give a broad overview of that,
*  maybe then we can. Yeah, let me just put this in perspective. So the idea of cryonics has been
*  around for since at least the 1960s. OK, the the scientific community has looked at cryonics and
*  said very clearly, we don't think that cryonics works because it has not demonstrated the ability
*  to preserve those structures of the brain that are obviously necessary for any type of future revival.
*  The baseball player Ted Williams is cryogenically preserved, I think, right? So he's a goner though,
*  probably. We don't know. But what I'm saying is that there has been a skeptical argument
*  that is rationally based in science for decades that the cryonics community had not ever
*  addressed adequately and still has not addressed adequately. OK, that is the so, for instance,
*  if you look at a skeptic like Michael Shermer, he would write in Scientific American that
*  people that are putting their faith in cryonics, they don't realize the amount of damage that is
*  occurring to the brain in a cryonics person. And they're putting all their faith in some essentially
*  magical technology of nanotechnology to repair just about anything. And as a good skeptic,
*  Michael Shermer would say, I'm skeptical of that. Air quotes. He can just give air quotes. There
*  you go. There's no video. So I have to do some play by play. Thank you. So about 10 years ago,
*  I came into that kind of discussion, that skeptical discussion, and said,
*  dude, I'm a neuroscientist. I do electron microscopy every day. OK, we look at synesthesia
*  every day. At the very least, we should be able to determine how good a preservation occurred.
*  And as neuroscientists, we should probably have some tricks up our sleeves to say, you know, how
*  well a preservation could be done. And so that was the genesis of this brain preservation prize.
*  That was a hundred thousand dollar prize to either the cryonics community or anybody else that could
*  demonstrate that they could preserve the synaptic connectivity of a brain in a static state for at
*  least 100 years. And I literally thought of this as on par with James Randi's prize. You know,
*  it's like a good skeptic does not dismiss something. A good skeptic says, steal man's the argument.
*  Steal man's it instead of straw man's it. Steal man's the argument and says, OK, show me this
*  and then I will believe you. And of course, the James Randi Paranormal prize that went unanswered
*  for years and years and years because there's no such thing as paranormal behavior. So but something
*  like this cryonics challenge, I thought, you know, this is something that is it's a technological
*  challenge. So let's put it out there. And the unfortunately the cryonics community is still
*  working on it. And I'm still in communications with people that say that they are still working
*  on it and they really believe that they are going to be able to show in published papers in the
*  coming years that that the current cryonics protocols are preserving the connectome. I am
*  very enthusiastic that they are continuing to do that work. But again, they haven't shown it. So
*  that's all I can say about that. But there was a technique that came out of a cross between
*  cryobiology and a glutaraldehyde perfusion fixation that's used in neuroscience research
*  or memory. There was a technique that came out of the cross of those two that actually did win our
*  prize. And that's called aldehyde stabilized cryopreservation. It was invented by a guy named
*  Robert McIntyre. And it is a very straightforward technique that uses chemical fixation of the brain
*  with aldehyde fixatives and then follows that up with cryo-protectant perfusion at room temperature.
*  Very similar to cryonics, but very different from cryonics in the sense that because the brain is
*  stabilized with aldehydes to begin with, you can have a much longer room temperature,
*  thorough perfusion of the cryoprotectant agents. That allows you to get the brain to a
*  state that can be lowered in temperature to minus 130 degrees Celsius without any ice crystal
*  formation. And it can stay there forever if you want. They did this on rabbit brains. They did
*  this on pig brains. Michael Shermer and I went to their facility to witness because he was on the
*  prize committee. He was kind of our resident skeptic, if you will, what he likes to call
*  a devil's advocate. So we went there. We witnessed them preserving a rabbit. We picked up pig brains.
*  I brought them back to my laboratory and did a very thorough electron microscopy on them.
*  They had been preserved, stored at low temperature, brought back up, and then
*  evaluated. All the synaptic connections look fine. It looks like textbook preservation of the
*  ultrastructure of synapses and neurons. But farther than that, we know that glutaraldehyde
*  fixation is preserving a wide range of biomolecules. If you're interested in
*  the receptor proteins or the ion channels, those are being preserved. How do we know that? Because
*  we have 50 years of neuroscience papers that have used aldehyde fixation and then done
*  molecular analysis afterwards. So the current state of the art for brain preservation
*  is that we know for a fact that if we wanted to preserve human brains, we could
*  perfuse people with glutaraldehyde fixative. We could perfuse them with cryoprotectin agent afterwards
*  and we could store them at liquid nitrogen, not liquid nitrogen, we could store them at minus 130
*  degrees Celsius at the vitrification point and they would stay constant forever. We know that
*  that technique verifiably preserves the entire brain, no cracks, no damage to the ultrastructure,
*  and it preserves the vast majority of the molecular information in the brain. These are simply facts
*  that are existing now. And they won the prize. Obviously, I thought that would change the mind
*  of skeptics because again, it was a steel man. It's like, okay, this is what you've been asking
*  for all along. And the idea that you can preserve those things, those things are the things that
*  neuroscience textbooks say you would have to preserve in order to have a reasonably good
*  chance of reviving somebody through whole brain emulation in the future. Unfortunately, the world
*  went on. It's like, oh yeah, we can preserve brains. So what? There's no social consequence of that.
*  And yet, the neuroscience community, and I talk to every neuroscientist I can on this,
*  ask them what am I missing? What am I missing? And they don't say that I'm missing anything.
*  They don't say this technique doesn't work. They don't say this technique doesn't preserve
*  these crucial things that the textbooks say need to be preserved. So that is the current state
*  of the situation. It's kind of like, yes, we have an ability to preserve exactly what
*  neuroscience thinks would have to be preserved. And yet, we have decided as a society to completely
*  ignore this possibility. Randall, do I have it right that you, thanks Ken for the description,
*  that's one of the main ways to make progress in whole brain emulation. And the idea there would be
*  you eventually, however many hundred years, timeline doesn't matter. Although I know it's
*  always very important to people to ask, when is this going to happen? But it actually doesn't
*  matter. If it works, well, it doesn't matter. But then the idea would be eventually to use the
*  structure, scan it, and then build it into a new system. The idea is not to reanimate the old body.
*  Essentially, although we could talk about that as well, but for whole brain emulation, the idea is
*  to use the structural information to reconstitute the functional connectome as well. And then you'd
*  have essentially a mind that you could then implement in some other hardware or some other
*  substrate, what Randall's calling substrate independent mind. Randall, do I have it right
*  that you formerly were, if you had the two sides, I suppose, were on the gradual replacement
*  approach to whole brain emulation, and you've come around a little bit to the brain preservation
*  alternative technique? Yeah, that's probably a slightly sort of-
*  We have to be simplistic here on the show. It's a simplified way of looking at it. That's not
*  really where I was coming from. We still talk about both methods, gradual replacement or scan
*  and copy, and we do so for a very particular reason. We do that because, first of all,
*  the two are the kinds of things that people think about and come to us with and need to be thought
*  through from a philosophical point of view to explore, is there really any difference, which,
*  in our opinion, there isn't in terms of the outcome, if you could do both of them.
*  But the other reason is that the gradual replacement approach, it is something that
*  ties directly into how work has been done in vivo in neuroscience so far, how in vivo data is
*  collected and how models are constructed based on what we observe in vivo by recording from the
*  activity of neurons in certain contexts, in a behavioral context, for example. In that sense,
*  it gives you this connection between the data you collect and something that is actually a working
*  brain that has a mind that has cognitive function. This connection is important because when you're
*  talking about whole brain emulation, of course, you want to eventually get from the data back to
*  a working thing. We can talk about very abstract terms there that are important like scale
*  separation. Is there a level at which we can do scale separation? What is the evidence for it?
*  Or resolution of data? What data do you need to collect in order to reconstruct something that
*  works? Or the representation of information in neural systems? Is that a robust representation
*  or not? So these sorts of things are explored using models that are based on dynamics or based
*  on in vivo recording and so forth. Now, gradual replacement as a theoretical exercise for mind
*  uploading is something that you can certainly contemplate. But I really think that from a
*  practical point of view, there are only two places where it applies. One is in the immediate here and
*  now in terms of these very small investigations, let's say, neuroprosthetic or understanding how
*  a piece of the brain works, exploring what is necessary to create a working brain,
*  that part of it, and then far future, you know, beyond where scan and copy would be possible.
*  Because to do that in vivo to replace all your neurons or to do that in a sensible way where
*  it's not way more risky would be that's way far ahead. Because imagine, I mean, just imagine,
*  you know, people worry about what it's like to undergo scan and copy as a procedure towards
*  mind uploading. And then they worry about things like personal identity, which is a whole other
*  topic we can get into. But, you know, in terms of preserving what's there, there's a really good
*  protocol. In terms of scanning what's there, obtaining data from it, there's a very good
*  protocol using electron microscopy and perhaps also detecting some other things like proteins
*  of various kinds. And then there's just that gap where we still need to understand how to transform
*  this sort of sculpture that you create from that three dimensional reconstruction
*  into something that works, right, which is where you need to do correlation, say, between what we've
*  learned about the functions of the parts and what we can observe in the recording we've made in the
*  structure. It's always normal that what we record, the things we measure are not actually the same
*  things that go into the parameters of our model when we build something that works, we always have
*  to make a transformation. So there's something really good there. There's a good procedure that,
*  you know, you can imagine that within a few decades, you can do that for perhaps a Drosophila
*  brain and then a few decades more for another brain and eventually human brains. But gradually
*  replacing all the neurons or say pieces of your brain over and over until it's all artificial,
*  imagine all those surgeries, imagine the risk involved, even if you had the technology put
*  in there. So it's not a practical approach in the near term. Maybe someday, you know, the same future
*  that the cryonassists are hoping for when all the nanobots are there. In that future, you can imagine
*  doing that procedure as a way of achieving mind uploading. I mean, maybe by then everyone's used
*  to the other approach anyway, so then they're not worried about it. But then you can imagine it. So
*  really near term, very far term, but for the actual feasibility of say the first
*  whole brain emulation, that in my opinion is a scan and copy approach.
*  I just want to jump off at every moment and talk about what may be people's biggest resistance
*  to these ideas, which are metaphysical concerns and concerns about souls and personal identity and
*  awareness and subjective experience. And I hope that we do get there. But let's continue along
*  science lines first of what can be known. So in any problem, there are things that we know or that
*  we're confident about. And like you were just describing, Ken, with the brain preservation,
*  the ability to preserve the structural components, at least as well as we think,
*  as current textbooks suggest, is enough to preserve the information of our memories, etc.
*  In these sorts of problems as well, there's a bunch of stuff that we know that we don't know.
*  And I know there's a huge bucket within the whole brain emulation, roadmapping exercises of things
*  that we don't know. And they have like various timeframes associated with them. And then of
*  course, there are the unknown unknowns, which we can thank, Donald Rumsfeld for most recently,
*  at least using that term, but it is a thing. And maybe we can talk a little bit by way of like some
*  of the many issues. I mean, Randall, you mentioned already, you know, there's the issue of scale
*  separation, what is the right scale of modeling that we need to do we need to model the ion
*  channels? Do we need to model down to the, you know, string theoretical entities? Or can we model
*  just a certain brain region? Can we treat that as a black box, right? There's all these different
*  levels of scale separation. You know, there's the problem of what hardware to run it on,
*  potentially, do we need, you know, some neuromorphic hardware? Or can we just,
*  you know, run it via simulations or, you know, constituted in models in von Neumann type computers?
*  Where does brain computer face, you know, interact with these different issues? And we've already
*  talked about the brain preservation, you know, which is one of the big issues. And I don't I
*  could spend the rest of the time just listing all of these issues that you guys have workshops,
*  and then you touch on all things, all these sorts of things. And so that it doesn't get lost in this,
*  I just want to say like the workshops that you guys conduct through carbon copies, and the roadmaps
*  that you have to continue to come back to. It's a brilliant thing, because this is a huge, huge
*  project. And this keeps all of the pieces from straying too far, right? So it keeps all the
*  pieces together, and you have to revisit them all the time. And I think that's such an advantage
*  for something as massively large of a project where there are so many unknowns. So in that sense,
*  like roadmaps seem to be an important aspect of huge projects like this. Do you think that that
*  is a real advantage of the roadmap approach? Well, it's it's certainly necessary to work on
*  a roadmap. Although I don't think that what we really have right now that we could really call
*  it a roadmap. It's pieces. Yeah, it's pieces. Yeah, that's right. We're still putting them together.
*  And I suspect that once we end up with something that we could call the first iteration of a
*  roadmap, then of course, it's going to iterate and iterate over and over again. The exercise is,
*  is one of continually identifying the things that seem least well understood or least well described.
*  It's about keeping ourselves honest. And it's also about making sure that that we're really
*  concrete about the issues that are at hand, right? We don't want to be doing hand wavy stuff.
*  And we don't want to do hand waving about technical problems. Like how do you even scan
*  something of that volume? Or or how do you actually go from having something that is a structure to
*  something that is a dynamic model? How do you do that? How do you validate that that model's
*  correct? Because I mean, everybody who makes models these days, the biggest problem is making
*  a model that's correct, because all models are wrong, right? All models are not correct. So you
*  want to get it to be just barely not correct, but only within the context that you care about. And
*  so you need to describe the context you care about and everything else. So none of those things are
*  deserve to be kind of glossed over, or to be hand wavy about. And then there's the other side of
*  stuff, you know, you're not allowed you shouldn't be hand waving about other big statements either,
*  you know, so we already slightly we touched upon this, this, you know, the crayonists and how they
*  believe that things are going to work in the future. The ones who don't want mind uploading,
*  let's say, versus the ones who are okay with mind uploading, and and Ken pointed out that probably
*  the ones who are thinking, oh, I'm just going to walk here, like Steve Austin, that they're thinking
*  somehow, that what they're going to be experiencing there is vastly different from what happens if you
*  do an upload. But that's because they're hand waving, right? They're just sort of not looking
*  at the details, the concrete details of what's involved. And when you really think about what
*  would you what you would have to do to make that happen, it turns out that maybe those processes
*  are extraordinarily similar. And that actually, you're just adding on, you're tacking on this
*  extra complication of then having to put it all back into biology, after you've already built the
*  upload, basically. And similarly, when you talk about the difference between gradual uploading
*  and scan and copy, and whether or not one is more or less likely to preserve your personal identity,
*  it seems like a lot of the arguments that that you're involved in those two camps, or in looking
*  at those two different possibilities, they are also hand wavy, those arguments. And once you stop
*  waving your hands around, and you look in detail at what's going on, they both seem to
*  have the same issues at a small detailed sort of microscopic level. And that you probably either
*  have to agree that both would work or both would not work. And then you have to look in more detail
*  at your philosophical reasons for thinking one thing or another. And why do some people feel okay
*  with it, and some don't. And then you end up coming down to something where you realize, oh,
*  these philosophical arguments where something is said about this is why it shouldn't work,
*  those aren't really based on any evidence at all. They're based on beliefs. And you start
*  discovering that that is not a scientific conversation. That is a conversation about
*  people's beliefs in the absence of anything testable. So a lot of these workshops, as we drill
*  down, and it's not just the workshops, it's also the projects that we do internally at Carbon Copy,
*  they are about drilling down on specific things, either technical, philosophical,
*  and otherwise also just outreach, educational, and drilling down to where at least we discover
*  what we've been hand wavy about and how we should really look at it, and then trying to put it into
*  words or videos, so that others can also see that. I just want to add one thing to that. I think that
*  the specific question of what level would be necessary. If you look at the neuroscience
*  community as it is working, its day-to-day process, thousands of papers, thousands of discussions,
*  thousands of bottles, that is where this answer is, our best guess. The neuroscience community
*  really has a best guess at what the level would be. I read this literature, the best guess is that
*  firing neural activity is what encodes information in the brain. Duh, that's what we've been doing in
*  recording. The neuroscience community is able to very readily look at
*  a multi-unit recording or calcium imaging and look at the firing patterns of neurons and say,
*  this firing pattern means that the mouse is seeing this type of grating, or this firing pattern
*  means that it thinks it's at this location in the maze, or this firing pattern means that it is
*  about to take this particular action, or this firing pattern means that it's recalling this
*  fearful memory when it was shocked. We can manipulate those things and get the mouse to
*  recall a memory, etc. There is real concrete experimental evidence that there is a level
*  of representation at the firing patterns of neurons. If you go into the theories of where
*  those firing patterns come from and how they are learned, how they're manipulated, how they function,
*  you get to models that talk about neurons as having ion channels and having receptor proteins,
*  neurons that are connected to each other synaptically, the weights of the synapses
*  and where they're connected is what is storing the information, is what is encoding the learning.
*  This is bedrock neuroscience here. I think as we're projecting into the future, there is a
*  known level that is being assumed today. The next question comes to, is that being assumed because
*  it's easy to assume that, but there might be another level below it that's so complex
*  that we haven't gotten to it yet. That's fine as well because there's plenty of neuroscientists
*  that are searching around at that sub-level to see if there's some neural information that's
*  actually being stored in particular conformations of molecules, how is the learning being done,
*  etc. I always look at it this way. You have a standard level that textbook neuroscience
*  is assuming today. It might be the case that you could get away with
*  a more abstract level for a whole-brain emulation and it might be the case that you have to go one
*  level deeper perhaps, but that gives you a range of models that we should be looking at that a
*  rational person trying to decide what is possible would be constrained within. Things that fall way
*  outside of this are, for example, on the top side, there is no way that you're going to
*  upload somebody's mind by MRI. It's not going to happen. Going down to a lower level,
*  there's no way that you need to know the confirmation of every protein or some kind of
*  quantum mechanical effect in order to capture the functioning of the mind. It is just way
*  outside the bounds of what neuroscience has learned already on both sides. I think this is
*  a very concrete question that really does not have to be talked about abstractly. It needs to be
*  understood and this is the core thing that I would like your listeners to understand.
*  The neuroscience community is working on mind uploading. Whether they admit it or not,
*  they're working on mind uploading. It is a logical consequence and everything that they've
*  learned already is something along that pathway that we're taking very seriously and I think
*  other people should as well. I'd love to jump right in there for a second because I think there
*  is a point, while I agree with everything that Ken said, I think there's a point where it's important
*  to point out why maybe neuroscientists want to be cautious when they say things like,
*  but this is just what we know right now and it's our current consensus and this is how we're doing
*  our experiments, but there could be more. Part of the reason is that every time when a scientific
*  question is explored and we're doing that experimentally, we do it in a constrained
*  context. You have a rat that is running a certain maze or a rat that has to-
*  Doing a task in a lab.
*  Right. Within that context or if it's patients using a hippocampal neural prosthesis or something
*  like that, it's always a constrained context and in that constrained context, we can say, yes,
*  that all of the patterns that we're observing, these firing neurons firing together, it makes
*  sense we can make these correlations that every time when we see this happening, this correlates
*  with that behavior. There must be a relationship between those, but because the context is
*  constrained and not the complete context of everything a human mind can do in a normal
*  everyday life, it is useful and correct to be careful and to say, we haven't actually explored
*  the entire realm of how that works, so it's possible that there are some additional things,
*  either across the system emergent behavior or lower level mechanisms that are important,
*  something that may still play a role that we don't currently understand, like Newtonian physics
*  eventually had to give way to Einsteinian physics. There may be something like that. We don't know
*  that for sure, but there is a pretty strong consensus about the things that we have explored
*  so far and I don't necessarily expect there to be a hurdle like that. I don't know that there is. I
*  haven't seen any evidence for it right now and that's where I apply this Occam's razor principle,
*  which is basically I'm not going to add something complicated to my theory unless there's a good
*  reason for it. For instance, I won't jump to quantum states and I won't jump to, oh, it has
*  to be done in hardware because integration information theory and because Tononi suddenly
*  adds this caveat that you can't do it in software or something like that. Or Miguel Nicolaeus,
*  who was like, no, no, no, it's going to matter all the way down. All the non-linear analog connections,
*  they're all going to matter all the way down. I think in fact that for some of these, there are
*  counter examples where at least you can make thought experiments where you can say it wouldn't
*  make sense for those all to matter or for it to be that complicated. And part of it is just because
*  the brain doesn't just exist as a weird philosophical exercise that nature did. It exists
*  as the thing that was supposed to keep the body alive and keep the genes continuing because it's
*  all natural selection. So there has to be a certain robust function and you live in a world
*  full of noise and you live in a world full of, yeah, all sorts of unpredictable things that are
*  happening in this gelatinous system that you have here. So you can't have a system where
*  you depend on details that would be so easily disrupted that the outcome is something that
*  you may not survive, like not recognizing something correctly or not responding correctly.
*  Or even just not having good communication between different regions of your brain.
*  They need to be able to communicate reliably. So you're going to do things like rely on entire
*  populations of neurons, our entire populations of synapses, bursts rather than spikes,
*  lateral inhibition between neurons so that they separate their patterns, all that sort of stuff.
*  All the kinds of things that you do if you want to make a device reliable,
*  just like we didn't cobble together analog computers by just putting a bunch of transistors
*  together and then seeing how that whole analog thing works. No, we imposed a clock, we imposed
*  ones and zeros, we imposed parity bits, we imposed all sorts of stuff to make it reliable.
*  And I think that you're going to find that in the brain as well.
*  Since you mentioned natural selection and brought up evolution, let's just go down that road for a
*  moment. One just worry that jumps out at me is, yes, so thinking about the robustness of brains,
*  they are extremely robust and they are also extremely tailored to our environment and
*  honed to very particular arm reaches that will get food to our mouth. A large part of a large
*  swath of our brain is devoted to thinking about reaching our arm to go grab a berry to then put
*  it back in our mouth. And let's say, there's just so many different ways to go, but let's say you're
*  reconstituted in a robot or something with effectors. I guess this relates to embodiment
*  and the embodied cognition movement these days that's been around for a while.
*  Yes, you have a very robust brain that can fit various scenarios in our environment,
*  but it's also very tailored to being in our bodies and reaping reward from reaching to get
*  something to maintain homeostasis or be hedonic or however many different ways you want to take it
*  within our bodies. And how robust does it need to be to then be uploaded into a robot or into some
*  software? And we're going to have to get into subjective awareness eventually with this too,
*  because really you want to experience being in the galaxy beyond Mars. And it's because
*  you want those experiences for yourself. So is there a worry that we have to somehow get
*  the environment right or some middle ground of programming to work with what we have in our
*  brains and how we know that our brains work and constitute our minds to have a middle man, a middle
*  layer between the way our minds work and the effectors that the robots are going to use that
*  somehow translates between the robust yet very tailored aspects of how our brains have been
*  shaped through evolution and how this new environment that they've been put in. I'll open
*  up to either of you who wants to answer this because I know that was just a lot of rambling
*  that I just did. I have a side take on that. I'm interested in what Randall has to say
*  about this, but let me just point out something. If my computer broke and I could only recover
*  90% of the information on the hard drive, is that my same computer? That's a stupid question.
*  Nobody would question a computer that way. It would be like, well, what were the files that
*  were lost? What were the files that were not lost? There is no further fact about whether it's
*  really your computer or not. When I hear questions about would it still be you if it isn't embodied?
*  What would the embodiment take in and out? Things like that. The most direct answer is
*  when you say what is being taken out and what is being preserved, you've got the answer.
*  That's all there is. There is no further fact. If you're asking for a further fact of, well,
*  is that still you, then you've crossed a philosophical bound that I won't go because
*  there is no you in that full psychological sense according to what we know about the brain.
*  This hinges on a computational approach to mind. This is a kind of functionalist account.
*  As long as the input, we give the same input and we get the same output, whatever's acrossâ€¦
*  I disagree with that. I definitely would not go there because that's saying that
*  as long as somebodyâ€¦ If you replaced my mind with a lookup table that behaved the same as I do,
*  this is actually the information integration theory argument against computation, by the way.
*  If you replaced my mind with a lookup table and I behaved the same, then it would still be me. No,
*  I completely reject that. Obviously, the internal mental quality of my life is involved in the
*  internal states as well. When Randall and I are talking about whole brain emulation,
*  we're not just talking about copying the external behaviors. We're talking about copying at a very
*  fine-grained level the internal representations and their dynamics as well.
*  Yeah, I wasn't meaning input and output as sensory and motor output. I was thinking more in
*  terms of at the neuronal ensemble level and communicating between each other, the information
*  input and the information output at whatever level you're dealing with at the time. But that's
*  still a computational account. Assuming that that is right at whatever functional level you care about,
*  how large you make the black box, if you put enough of these together and they emulate the
*  whole brain, what you're assuming is that the subjective experience comes with it.
*  All I would say to that is that, yes, I personally take the computational account of the brain
*  seriously. People will try to straw man that as a, well, you just think that the brain is a computer.
*  Obviously, I don't think that the brain is a computer. But it is a statement that what is
*  mattering to the mind is information processing. There is a possibility, I suppose, that that is
*  not true. But I want to point out that if that was not true, then neuroscience as we know it is way
*  off on the wrong track because it assumes that completely. I would argue that you would probably
*  have to dismiss evolution, biological evolution as well. The minute that you start saying, oh,
*  we're not just functional, you have opened up a can of worms that starts to eat away at the
*  scientific knowledge that we've gotten through the ages.
*  **Matt Stauffer** Yeah, I think that's actually a very important
*  different phrase to use as functional as opposed to computational because computational is easily
*  misinterpreted, as Ken already said, as saying, oh, I think that the brain is a dual core laptop
*  or something like that. That's not what you're trying to say when you say computational. What
*  we're saying is we're materialists and we think of this in a functional, from a functional
*  perspective, a functional philosophical framework. We're trying not to be dualist, even though not
*  being dualist is extremely difficult for a species that has a self-model and therefore starts to think
*  in a very homunculus, Cartesian theater kind of way. So not being dualist is really hard.
*  And everyone succumbs to it in one way or another, I find. But yeah, that's really the basis of it,
*  is the functional perspective. But I think that sort of got a little bit off track from what you
*  were saying about the embodiment argument, right? This is a little different from-
*  **Matt Stauffer** Well, I mean, they're related because the function, let's say, input-output,
*  whether it's information processing in however large a volume that you want to talk about and
*  however many neurons, or at the whole organism level, all of these things were honed through
*  evolution for very specific purposes. And I noticed the other day, just a few seconds ago,
*  while you were talking, my hand came up and I think I put my finger on my chin or something,
*  my cheek, while I was listening to you, completely unconscious of it. But there are all these things
*  that are going on that moving my arm with so many degrees of freedom, and it's such a complex thing,
*  even moving my arm, and so much of my brain activity is devoted to that. If I am reconstituted
*  and emulated in whatever hardware or whatever system, eventually after the scan and copy,
*  or let's just go with the scan and copy for now, the experience, even though our brands are very
*  robust and adaptable, it seems like it could be quite jarring, to say the least, at the beginning.
*  **Matt Stauffer** Right? So I don't know if that gets us-
*  Jarring is always a matter of degrees, of course. Jarring is-
*  **Jaren Levy-Saclaire** Coming home to my children is quite jarring.
*  **Matt Stauffer** Yeah, exactly. It could be. But yeah, I mean, I think the arm movement to
*  grab the cherries, that's still going to come in very handy as a robot, grabbing batteries and
*  putting them into your head, battery receptacle, that sort of thing. So there'll be a place for that.
*  But more seriously, you're right. Of course, it matters what you build around an emulation like
*  that, whether you have a full range of input and output, whether your sensation is still
*  somewhat intact. Then again, though, I mean, studies with locked-in patients, for instance,
*  don't seem to show that locked-in patients feel generally less human or even more unhappy overall
*  than regular people who are not locked in. So there's quite a lot you can take away
*  and still have what is basically a human mind. That's not to say that you'd necessarily prefer
*  that. But it also goes the other way, because one of the things that you mentioned in there is,
*  you know, what would it be like traveling to the stars and this whole other thing, because we're
*  adapted to a specific kind of body. So it's not just about taking things away. It's also this idea
*  of maybe adding something unusual, like a different sense or input about different things that we're
*  not normally aware of or that we don't usually compute. And yes, we are somewhat adaptable.
*  There have been studies where you plug in a new type of actuator or some sensation of magnetism
*  or something like that, and you can kind of learn to work with it in some way.
*  Even holding a tennis racket, right?
*  Or even holding a tennis racket or, you know, an example I like to give because I like kayaking is
*  that when you're sitting in a kayak, it feels like that thing is just part of you. It's not like you
*  have legs, you have a kayak, and you kind of just move with that. So we do adapt a lot like that.
*  And I don't know where the boundaries are or exactly how rapidly you can add different things
*  or exchange things. What is the degree of change that's acceptable so that you don't
*  experience a kind of trauma? You know, trauma either by losing something or by gaining something.
*  I don't know. Yeah.
*  You guys talk about that a lot. It's just the rate of change. Like what is acceptable,
*  you know, in the gradual replacement approach? How quickly, you know, how slowly do we need
*  to replace things to be considered? Oh, I'm still myself. I'm still myself. I'm still myself,
*  you know, to then eventually be completely replaced and having the same person.
*  There are so many questions in that because, I mean, would you even notice? How could you notice?
*  How could you tell? Like, at what point? What is the thing in your brain that is the component
*  that somehow makes a judgment that says, this is me, this is not me? Is it a comparison with memory
*  and then saying, I have a memory of what it used to feel like being me and now it feels different?
*  Do we actually have that? I don't even know if we have that. Maybe we have that.
*  So many open questions there. I don't know. I don't know.
*  But this gets to the point of, you know, Ken originally saying when you ask a neuroscientist,
*  like we know nothing about the brain, but that's because we really know very, I mean, we know a
*  lot. But and we have our best theories, you know, the best and, you know, scientific knowledge is
*  based on, I think, you know, a bedrock of good factual basis, but they're still relative to
*  what there is still to learn. I feel like we're still really early on in the game. And then it is
*  a very young science, of course. Well, I think just one thing I would want to stress is that
*  we take neuroscience very seriously. And I think we are not saying anything that any neuroscientist
*  would strongly disagree with. And yet, so the only real difference is that we're allowing ourselves
*  to kind of imagine what the future of neuroscience, what its success would actually
*  bring. That's really the only difference. You know, what's funny is actually that when
*  neuroscientists come up with reasons why they don't agree with our view of the future or what's
*  possible, they'll tend to come up with something that to me, at least sounds a lot more kind of
*  fringe and not in the sort of middle ground safe, conservative consensus neuroscience.
*  What do you mean? Can you give an example maybe?
*  Or Tononi's argument is pretty much in there. Yeah. Or, you know, Stuart Hameroff and microtubules.
*  Yeah, come on. Come on. I can't believe you said microtubules. Come on.
*  Yeah. So you see what I mean? It's like the kind of the counter arguments seem to come from,
*  I mean, when they don't just come from a place of saying, we don't know enough, so we shouldn't
*  talk about it, then it seems to come from inventing. No, I shouldn't say inventing. That's not fair,
*  right? Like coming up with a reason that is, to my mind, far-fetched and low on evidence.
*  Yeah. And there are more reasons of it may not happen or it may not work because of. And I know
*  that brain preservation is a subset of this. It's not the whole deal. But, you know, when the
*  argument against brain preservation is it may not work, that's a very hollow argument for a terminal
*  patient to hear. Yeah. Yeah, I agree. I mean, you've stressed this multiple times in other venues, Ken,
*  that someone should have that option. If they're terminally ill, you know, you're laying there,
*  you should have the option, yes, perfuse me and I'm ready to go. Even if it's a 0.07% chance that
*  in 700 years. And I would go farther than this, that it's not that you should have the option
*  in some kind of abstract sense. Like, you know, you have an option to have a heart transplant,
*  but we're going to systematically not have any hospital do it, any hospital regulated to do it,
*  any research into it. We're going to make it as hard as you possibly can to get a heart transplant.
*  You know, that we wouldn't accept that for heart transplants. And that is exactly what's being
*  asked to be accepted for preservations. So, for instance, a good friend of mine, a 19 year old
*  terminal cancer patient, he's sharing his story right now, tweeted about his case and asked,
*  you know, why can't my friend get a quality brain preservation? And I got absolute silence
*  from the neuroscience community. And I got a whole bunch of people from the cryonics community
*  saying, well, why don't you just go to get chronically preserved? And my friend thought
*  about this the same way as I do. You know, he was like, I don't want to go to an unregulated
*  third party system outside of everything and wait until I'm dead because I have to be dead
*  for a legal purpose so that I can get a crappy preservation. I want the best quality preservation
*  that I can get. And I want it within the existing hospital system. And I want my NIH to fund research
*  to make sure that it's done better and better and better. Sounds like a good market opportunity for
*  some CD joints in Mexico or something to offer these. Nothing against Mexico. Another thing I
*  wanted to sort of quickly ask about is, you know, the use of animal models in whole brain emulation.
*  And, you know, of course, there's the nematode, which has a structure completely mapped out,
*  the DNA completely encodes the structure of the brain. And you have smaller organisms like
*  Drosophila. Are we going to see a functioning fly, you know, hundreds of years before? And I know
*  this is a timeline question, sort of. I want to avoid timelines. But is that a goal to perform
*  this in an animal model? Of course, the eventual goal is human. So this is where I have to say that
*  it actually does make sense to not over speculate. Because, you know, whereas we are mapping out
*  fruit fly brains, whereas we're mapping out C. elegans and things like that, neuroscience is
*  not ready for the type of comprehensive emulations that Randall and I would consider to be
*  an upload. So we will eventually get there. Will it be, you know, a fruit fly first or a mouse first
*  or C. elegans first? It probably will be not even clear where that boundary happens.
*  Neuroscience is really about understanding different pieces of the nervous system and how
*  they function. And at the very end of that understanding process, yes, somebody will emulate
*  a fruit fly. But all the interesting stuff, if you will, may have already happened before that.
*  I'd love to hear Randall's take on this. I think that's correct. Because everything is a gradual
*  process in science, and we're always working on different pieces. This is exactly what you're
*  going to see. You're not going to have a very clear indication of this is when an emulation of
*  a specific animal has happened. It's more like you'll have a slightly okay model of Drosophila
*  visual system first. And then eventually maybe some other systems or a better model of the visual
*  system of Drosophila. Or you'll switch over to human retina or something like that. Because
*  there's a reason to try to build prostheses for people with bad retinas. And you'll see that kind
*  of thing happening. So all these little steps like that until at some point you just have it all.
*  Unless, of course, there's somebody who's just or some group that is very much interested in
*  just putting together this particular project. They absolutely want to get an emulation of C.
*  elegans. Just thinking of that one because of OpenWorm and other projects out there.
*  And then they find all the right people and get all the funding together and they work on it so
*  hard. And they've got this plan so they can show all these little steps until they get there.
*  You could set it up that way. But that's not the way that you would expect it to work out.
*  If you just let everything take its course. And if you look at the interesting thing that's
*  some of the interesting projects that Conactomics is tackling.
*  Mapping out of the fruit fly brain is really looking at different pathways for navigation.
*  Different pathways for olfactory learning. There's some projects that I'm very excited
*  about that are probably going to happen relatively soon in let's say bird brain
*  or mouse brain where you have a known memory like the bird song. And you know where it's stored
*  because of a whole bunch of other experiments that have been done over the years. And so you
*  go in and you map out the circuitry with a particular theory in mind saying if it works
*  this way we should be able to read off this memory. We should be able to read off the
*  song that the bird learned. Will it be an emulation? No. It won't be an emulation in
*  the sense that we consider it. But it will be an extremely concrete piece of evidence that an
*  emulation is eventually possible. And in contrast it takes a neuroscience theory and puts it to the
*  ultimate test. You can't wiggle around it. It's either there or it's not there. This is I think
*  the current set of neuroscience experiments that we should expect are on that level.
*  â€“ Engineering and science for understanding are not at odds with each other necessarily,
*  but they are two different things. I know this is an open question, but in your opinion how much do
*  we need to understand brains? How much do we need to understand minds and what is a mind and how
*  brains and minds are related? How much is understanding part of this picture? Randall,
*  let's start with you. â€“ Yeah, I think I may have shifted my views on that a bit over time as I
*  understand more. â€“ As you understand more. â€“ Yeah, but also about the practical problem of how would
*  you get from where we are to where you can do whole-brain emulation and just looking at it
*  in that sense. You know, in the past I might have emphasized more that the idea behind whole-brain
*  emulation is precisely that you don't need to know everything about the brain as long as you know how
*  the underlying mechanisms work. If you can scan enough and you can put those mechanisms together,
*  then you're going to end up with a working brain. That's a bit naive because it presumes that we
*  collect data correctly, that we collect the right data, that we know how to transform that data
*  to the parameters we use in the model, that we're using the right model, all this kind of stuff,
*  right? And all these questions that I just mentioned, they all require testing. And so
*  validation is a huge issue. And that's where the understanding of the brain comes in. Because if
*  you want to validate that at least the model you've built works like a human hippocampus,
*  then you need to have a fairly good understanding of how a human hippocampus works. Then you can see
*  whether your system even fits within those boundaries before you can even say is this
*  Steve's hippocampus, right? So I would still say that the thing that whole-brain emulation kind of
*  holds as a sort of a tenet is that we don't need to understand everything about Steve to be able
*  to make a whole-brain emulation of Steve. We need to understand a heck of a lot about human brains
*  so that we can build a testable model of a human brain that will then house Steve.
*  But we can collect the data about Steve that makes that personalized and tuned to be Steve.
*  So there's this, we need to understand a lot about the brain, but in the context of how brains work,
*  not how Steve's brain works. That's where you would then be taking the data. And well, of course,
*  you need to know a lot about that transformation of what makes it Steve's brain in this particular
*  case. But I think you get my point, right? Yeah, this is almost opposite to the way that current
*  AI views this and even current computational accounts view it. That really underlying
*  mechanism doesn't matter, structure, function, mechanism, brain. Why brain? Why brains? It's
*  all algorithms. It's all solving computational problems, the functions, which are implemented
*  via algorithms. And it doesn't matter what substrate you run the algorithms on, which of course,
*  substrate-independent mind would would harken to that as well. So I don't know, are those two at
*  odds, do you think? They're not really at odds. It's a different purpose, a different goal, right?
*  I think that the idea that you can do a whole-brain emulation at all, it means that there needs to be a
*  kind of substrate independence or platform independence. That's what you'd see in AI as well.
*  And that you need to be able to come to at least some lowest level algorithms that you can then
*  use in a replicated way or where you just add in the right parameters. So in that sense, it's like
*  AI. But there will be many more variants of algorithms that you're going to use to produce
*  the system that you want. Because you're trying to build something that came out of a patchwork that
*  you know, evolved over time, and that isn't based on just a single resource with a single algorithm
*  doing a single thing as what you would see in narrow AI today. Now, I'm not saying that this
*  means we would never be able to build a whole-brain emulation where you can abstract away more.
*  I think that may very well be possible. It may well be that we discover that we only need to emulate
*  the behavior of populations of a certain size to a certain degree, and then everything's fine. And
*  that way you can get much closer to what we today would call the type of algorithm you'd see in AI.
*  So I'm not saying that. But it is different in that sense, because we're trying to build Steve's
*  brain. We're not trying to build a de novo artificial intelligence that is good at solving
*  this kind of problem, which is a different kind of question. But you know, you can see in AI that as
*  you get into a situation where your problems are more complex, where the context is much more
*  complex, so you need to have an AI, say, that can live in the real world and drive around and find
*  its way and understand traffic situations and all sorts of stuff like that, that you can no longer
*  make do with just a single algorithm doing a single thing. You have to add in all kinds of pieces,
*  different senses and different parts that compute different solutions and maybe use entirely
*  different algorithms for it. So it begins to look a bit more like a brain, although perhaps
*  not a human brain, right? Not Steve. I mean, I think we can already kind of make this discussion
*  a little bit more concrete. The deep learning neural networks that people use for recognizing
*  objects, those are very similar. There's a lot of papers now that compare directly the types of
*  responses that you get from a deep learning neural network with the ventral visual stream of a monkey,
*  for example. It is certainly not a perfect analogy, but it is probably giving us the main core issue.
*  So the current experiments that people are going to do are going to be, you know, given that we've
*  recorded this particular mouse brain's optical lobe, can we use the connectivity to predict
*  that this particular neuron likes a 45 degree bar moving in this direction? Okay, they've already
*  done experiments like that. So it's like, yes, they can do that from connectivity.
*  Many decades of more refined experiments will be able to figure out what the classes of neurons
*  are, how it interacts with the whole system, what the real synapses are that you should be looking
*  at, how to interpret them. And at the end of the day, you will be able to take all of that information
*  in a particular Steve's brain, let's say, or a particular mouse, and from the connectivity
*  of that visual system, be able to say when the mouse looked at this picture of cheese,
*  this was the neuronal ensemble that would have been firing to signal to the rest of the brain
*  what it was seeing. And so I think eventually we will be decoding particular brains that way,
*  and it will be very similar to how we think about deep learning neural networks today,
*  but we're certainly very far from doing that today. And there's a lot of complexity that
*  goes beyond just a simple layered deep learning network that people use.
*  Soterios Johnson Maybe we can just end on it,
*  because we only have just a couple minutes here. You guys have a lot to think about
*  in projects this size. What is currently on your mind in terms of what you see as
*  in the immediate term, not far term, not intermediate term, but really like what
*  you're thinking about now that feels like a bottleneck in the current hurdle?
*  Yeah, luckily, that seems to have shifted a bit over the last 10, 12 years, in the sense that I
*  used to think that scanning was going to be a huge bottleneck. And it's still probably a big
*  bottleneck, but not as big as it was. The biggest bottleneck that I see right now is the transformation,
*  the transformation from the data you collect to a model that works. Because the examples for that
*  are really few and very tiny, that hardly exists. Most functional models are just
*  sort of theoretical experiments, so they don't use any data at all. Or they are pretty rudimentary
*  and using some in vivo recording data, try to replicate some very limited duration and number of
*  of active states that you see. There's nothing like taking an electron microscope reconstruction
*  of a piece of brain tissue and then converting it into a model that shows how that piece of brain
*  tissue is supposed to work. It just doesn't exist yet. And to me, that is the fundamental,
*  most difficult thing right now. That's really the thing I'd love everyone to be studying if they
*  could. What do you, let's say you, Ken. Well, I completely agree with Randall on that. I think
*  from a neuroscience perspective, that is where neuroscience is trying to go. We've finally gotten
*  the tools to map neural connectivity over large scales. And now we need to use those tools to
*  really test the models that we have and push them forward. I would say that I think
*  neuroscience is doing just fine. It is cranking along with fantastic tools, optogenetics and
*  calcium imaging and connectomics. These are just really making good solid progress toward
*  understanding, really real understanding. From that perspective, we just need to keep doing what
*  we're doing. From a more meta perspective, I just wish that more people in the neuroscience community
*  would open their minds up to what success will eventually look like. It's going to take decades
*  and decades and decades. Nobody's doubting that, but we should be debating what the long-term
*  impact of a successful neuroscience will be for humanity. I had Steve Potter on recently, and I told
*  him that I was going to be talking with you guys soon. He literally applauded while we were talking.
*  I'm not sure if it came through in the podcast. It hasn't been released yet. But I'm glad I had
*  you guys on. I applaud you. I applaud both of your efforts. This is just really fun stuff.
*  My only disappointment is that we didn't have another couple hours here to talk. Continued
*  success. I really appreciate it, guys. Thank you. Thank you very much. It was a pleasure.
