---
Date Generated: April 20, 2024
Transcription Model: whisper medium 20231117
Length: 4822s
Video Keywords: ['Education', 'Science', 'Technology']
Video Views: 2012
Video Rating: None
---

# BI 140 Jeff Schall: Decisions and Eye Movements
**Brain Inspired:** [June 30, 2022](https://www.youtube.com/watch?v=5OkNgJEG5MY)
*  It seems to me a particular computation or mental ability or experience is grounded by
*  or supervenient on, to use another term of art, certain neuron circuits.
*  Some neurons do some things, other neurons do other things.
*  And what they do is identify with different functions.
*  I also meditate on whether a brain state that explains behavior has to be incorporating
*  the state of every channel and every membrane of every neuron.
*  If it does, the game's over.
*  Where it works best is when there's multiple competing hypotheses
*  and you can conceive of an experiment where the outcome resolves a set of questions more decisively.
*  And it's exhausting and, you know...
*  Yes, it is. It's true.
*  That was the voice of Jeffrey D. Schall, a familiar voice to me because I was a postdoctoral
*  researcher in his lab at Vanderbilt University.
*  I am Paul. Hello, everyone.
*  Jeff has recently picked up and moved his lab to York University.
*  And he has for years been studying the neural and computational decision mechanisms that
*  guide control and monitor behavior.
*  That's straight from his website.
*  And the vast majority of his research centers around making decisions with psychotic eye
*  movements in nonhuman primates and connecting the neural instantiation of those processes
*  with mathematical models.
*  A saccade, by the way, is the rapid kind of eye movements we make all the time to look
*  at things, as opposed to smooth pursuit eye movements we make when we track objects moving
*  in space.
*  When I was in Jeff's lab, I worked on the neural basis of and a model of how we make
*  decisions and choices and how we can withhold our responses at the last second as we're
*  preparing to make the response, something called response inhibition.
*  That's just one of multiple tracks of research from his lab.
*  So the circuitry involved in how we move our eyes is well known, which makes studying cognition
*  in the realm of eye movements a seemingly straightforward process.
*  But not so, my friends.
*  It turns out there are many confounds and twists and turns even in this well known system.
*  So that mapping cognitive or psychological functions and sub functions onto the activity
*  of single neurons and populations of neurons within circuits is an intricate affair.
*  One of the reasons I wanted to have Jeff on the podcast is because he has maintained a
*  few guiding principles throughout his career to help clarify how to ask the right questions
*  and how to know whether the answers are reliable.
*  So much so that every year in his lab, we reread the same set of papers that outline
*  these principles.
*  We talk about two of those principles today.
*  One is called linking propositions from Davida Teller in the 1980s, which is a systematic
*  guide for how to understand the relationship between neural activity and psychological
*  functions.
*  And the other is called strong inference from John Platt in the 1960s, which is a systematic
*  recipe for how to most productively and efficiently do science.
*  We discuss these concepts in terms of the many projects Jeff has ongoing and partly
*  in reference to two review papers Jeff wrote, which go way deeper in the world of decision
*  making with examples from Jeff's work and eye movement related research in general.
*  We also discuss how the game may or may not have changed over the years as we can record
*  more and more neurons simultaneously and relate those recordings to the large deep learning
*  models we often discuss on Brain Inspired.
*  We talk a little free will among other things, and Jeff takes some guest meta science type
*  questions.
*  So I encourage you to read all four of the papers that I just mentioned, which you can
*  find in the show notes at braininspired.co.uk slash podcast slash 140.
*  Thank you for listening.
*  Support Brain Inspired on Patreon if you value it, or consider taking my online course about
*  this emerging neuro AI world.
*  Learn more at braininspired.co.
*  Okay, enjoy Jeff.
*  Jeff, we were just talking about how you don't age and you mentioned your knees, but I remember
*  you telling me that you at least could dunk a basketball.
*  How long has it been since you dunked a basketball?
*  Oh, years and years, years and years.
*  I enjoyed coaching my son when he was in middle school and showing those boys how to run suicide.
*  Oh my gosh.
*  Yeah, the suicide makes me hurt just thinking about it actually.
*  He's not still playing basketball, is he?
*  No, no, he actually is a police officer in Nashville now.
*  He's a shooting instructor.
*  Speaking of Nashville, you were in Nashville for over 30 years, right?
*  That's right.
*  So at Vanderbilt University, where I was your underling, your postdoc there, where you taught
*  me many a thing.
*  But you have recently moved to York University.
*  I know that it was quite a process.
*  I guess COVID has had something to do with that.
*  So what is your new title?
*  I'm not sure I even know your new title at York and the nature of your job.
*  Can you tell me about it?
*  Well, I'm a professor in the biology department in the Faculty of Science and appointed as
*  the director of a Center for Visual Neurophysiology.
*  What that means is that I'm involved in helping plan and equip and I guess staff a facility
*  where non-human primate visual neurophysiology experiments will be done.
*  So this is in the context of a large grant that York got from CFREF is the acronym in
*  Canada.
*  It's a 30 million dollar grant or so.
*  York University committed additional funds to fund new faculty positions and build a
*  new building.
*  And so the ground floor of that building will be a vivarium in which five researchers will
*  do neurophysiology experiments of various sorts on vision and action.
*  Speaking of 30 years ago, you've been recording neurons for quite some time.
*  And you've told the story in many a lab meeting that I've been a part of, of how relative
*  to these days things have changed and how you used to sort of manually do things that
*  are now automated.
*  I'm wondering if you could just tell a story of how you used to go in and use holes in
*  boards and such to make experiments.
*  Can you tell a story about what that was like and then we'll compare it to these days?
*  Yeah, well, I mean, in the in the during the postdoc period with Peter Schiller at MIT,
*  we made our own electrodes, glass coated platinum meridian.
*  So you had to etch the wire, make it the right pointiness, not too pointy, not too dull,
*  and then apply the glass coating with a particular device.
*  And these things required manual dexterity and skill, which only arrives through practice.
*  So you ruin a lot.
*  So once the electrode was made for the day, then you could insert it in the micromanipulator,
*  the device that was attached to the chamber on the monkey's head to advance it into his
*  brain.
*  But it was one electrode at a time, one contact, hopefully isolating one neuron at a time.
*  And the isolation process was fiddling with nods, the, you know, voltage as a function
*  of time on various scales.
*  And at the scale of a neuronal spike, it's in the scale of, let's say, three or four
*  or five milliseconds.
*  So that's the trace of voltage by time on the oscilloscope screen we looked at.
*  And there were other electronic devices, variously known as Schmidt triggers and other kinds
*  of spike isolation devices that allow you to set thresholds in voltage and time to
*  generate a TTL pulse only when the voltage by time waveform satisfied the criteria that
*  you set.
*  And you kept an eye on those because over the course of the session, it would drift
*  and change and one could chase the electrode, I mean, chase the neuron with the window discriminator
*  and with the micromanipulator moving in and out.
*  One neuron at a time.
*  If you got one neuron a day, you felt real good.
*  Oh, that's what my PhD advisor, Mark Sommer, always touted that as well.
*  One neuron a day, that's a great day.
*  That's a little different from these days, which now you can't chase neurons because
*  you have so many electrodes on so many leads on each electrode going down.
*  It's just massive populations of neurons that you're recording and you don't really get
*  to choose so much.
*  Well, that's right.
*  So one of the, I don't know if you say revolution, it's a technical evolution for sure is the
*  ability to put more than one contact in the brain in more than one brain area with either
*  linear electrode arrays or Utah arrays, a variety of others chronically implanted or
*  placed day after day.
*  One of the concerns of course is whether the quality of the isolation of the many neurons
*  on many electrodes is comparable to what we used to do when we can focus on one spike
*  at a time.
*  And well, there's different points of view about this, of course, and many people are
*  working hard on algorithms that efficiently isolate spikes according to rigorous criteria.
*  And of course, they never work perfectly.
*  You're never sure that what you've missed and what you hit, but you can't sort spikes
*  it infinitely.
*  And so other people have adopted the point of view that maybe it's not that important.
*  It's just the spikiness of the signal and other frequency bands that provide a perfectly
*  adequate signal to do things with like drive robot arms, let's say.
*  I remember feeling that consternation because I grew up recording one neuron at a time,
*  maybe two a day.
*  That was a great day.
*  But then in your lab, we started using these multi-contact electrodes where you'd have
*  to...
*  I constantly felt like I wanted to better isolate the neurons, but there's just nothing
*  that you can do about it.
*  So I don't know if...
*  Do you feel like back in the day, were they the good old days recording single neurons
*  because you know that you could isolate them?
*  Because there's a give and take also because recording one neuron at a time, you're lowering
*  the electrode, you're having your animal do a task and you're listening for a neuron
*  that also sounds interesting, right, relative to the task, which also you can't do anymore.
*  Was that the good old days?
*  Are the good old days gone or is this a better era?
*  Well, this is a more informative era for sure.
*  We can answer questions that were really impossible or hard to answer before.
*  So for example, the recent work we've been focusing on in the lab involves placing linear
*  electrode arrays like what you used in frontal eye field, but placing them in areas where
*  they can pass through the cortical layers perpendicularly.
*  Areas like the supplementary eye field or parts of V4 on the lunate gyrus.
*  And so we can assess the properties of cells across layers in a manner like Hubel and Wiesel
*  did and others in the 60s and 70s.
*  But this information is rarely available in other cortical areas.
*  V4 has got more than anywhere else, I think, but in the frontal lobe, there's hardly anything
*  known.
*  I just had Matthew Larkham on the podcast and he makes the argument that we need to
*  be paying more attention to where the dendrites are, not so much the cell bodies, right?
*  So thinking about recording across layers of cortex, how do you think about that?
*  Because you have sources and sinks from a few years ago and you're listening for the
*  action potentials, which is the output of the neuron.
*  But thinking about the dendrites and where signals are coming in relative to that, how
*  does that affect your thinking about what you're doing?
*  Right. That's a great question and a great connection.
*  So one of the observations he is known for and others have made is the description of
*  these calcium spikes that are emerging in the apical dendrites of layer five pyramidal
*  cells. So I've been fortunate to be in a collaboration with a colleague at the universe
*  at Florida International University.
*  His name is Jorge Riera.
*  So in this collaboration, one of the products is a biophysical model of a layer five
*  pyramidal cell that includes these calcium spikes.
*  So we were thinking about that concretely.
*  And one of the approaches, the validity of this has not been well, I don't know exactly
*  how valid this is quite yet.
*  We haven't published the paper, had any reviews.
*  But one of the approaches to looking at sources and sinks relative to a spike, let's say
*  recorded in layer five.
*  So we can say we're in layer five because of the linear electrode array and other information
*  that lets us align it.
*  So a spike in layer five can be we can synchronize the current density on the spike to spike
*  triggered current density.
*  And when we've done that for spikes in different layers, we see various kinds of patterns.
*  That relate in interesting ways to the possibility that a current sink in the top could be those
*  calcium spikes.
*  Very good. So in preparation to speak with you every year in lab meetings at the beginning
*  of this of one of the semesters, right, every year we would go through a set of papers that
*  you kind of hold as dear.
*  And, you know, I reviewed those papers again.
*  We're going to talk about some of the concepts from those papers.
*  But it was really interesting going back thinking about where we are today with like these
*  massive recordings and also the quote unquote machine learning or deep learning approach.
*  And I want to get your reflections on some of these ideas, one of which is linking
*  propositions.
*  So I also went back and read your 2004 paper on building a bridge between brain and behavior.
*  And by the way, one of the things that is fun for me is just how maybe not that I didn't
*  realize, but maybe I was just less educated, of course, than I am now.
*  But how much more I appreciate how steeped you are in the history of philosophy and all of
*  the related issues related to mind, psychology versus brains, which I didn't appreciate as
*  much back then. So just a belated congratulations and admiration to you for that.
*  Thank you, Paul.
*  So you wrote this in 2004 and you talk about linking propositions.
*  And I'm going to ask you to explain what linking propositions are in a second.
*  And then you in 2019, 15 years later, revisit these ideas with updating with everything
*  that we've learned about SACOD production, response preparation, decision making, visual
*  attention. So I want to get your thoughts from back then relative to back then and how
*  you're thinking today about linking propositions and where we are and where we're going with
*  them. So what is what is a linking proposition?
*  Well, linking proposition is a is a term of art that I didn't formulate.
*  It comes through to be the teller from a vision scientist named Brinley.
*  The concept is that there are certain identifiable, let's say, psychological functions,
*  cognitive functions or perceptual abilities.
*  So which neurons enable that ability?
*  And the neurons that enable that are the are the bridge locus, the place where the linking
*  proposition holds. So if we want to study visual decision making, let's say it's unlikely
*  the olfactory bone has much to do with that.
*  So part of the identification of a linking proposition is ruling out the neurons or the
*  circuits that can't be involved.
*  And this, of course, is a process of elimination where you falsify certain hypotheses, which
*  brings us to the strong inference approach, which was one of those papers.
*  So it just said it puts in more concrete terms what it seems to me everyone believes in some
*  sense that a particular computation or mental ability or experience is grounded by or
*  supervenient on, to use another term of art, certain neuron circuits.
*  Some neurons do some things, other neurons do other things.
*  And what they do is identify with different functions.
*  So I don't regard it as a very controversial concept at all.
*  Its value is in grounding it and slowing the thinking down to avoid many, many authors will
*  write, and I've written this too before, you'd say this neuron represents this.
*  Right. Well, won't this represent me?
*  Right. In what sense is it represented?
*  And so there's more to say and more to unpack in that concept.
*  And the concept of linking propositions provides a path to help you think these things
*  through. Well, it just structures a set of logical inferences that have to do with, you
*  know, A, if the neurons do this thing, then that mental state exists.
*  If the neurons are disabled, the mental state doesn't exist.
*  If the mental state exists, according to another measure, the neurons better reacted and so
*  on. It makes us slow down and think about what we mean.
*  And then the bridge locus concept reminds us that we're not sure what level of description is
*  the adequate one. So in that paper, I also meditate on whether a brain state that explains
*  behavior has to be incorporating the state of every channel and every membrane of every
*  neuron. If it does, the game's over because we can't even we can't measure it and we couldn't
*  keep track of it if we could.
*  Probably it doesn't, though, just like and this is this concept of functionalism.
*  I mean, we're we're running a computer program that lets me see your image and you hear me
*  through the Internet.
*  I don't know if you're running a Windows machine or a Mac, and it doesn't matter.
*  It matters fundamentally.
*  I can't put my CPU in your computer or yours in mine if we're not using the same
*  hardware. But somehow software is different.
*  So the same software can run on different hardware.
*  You didn't use the term multiple realizability in that paper, I think.
*  But that's essentially what we're talking about.
*  I don't know if that was not a term.
*  Well, it's a concept I was familiar with.
*  And I think it's that paper near the end.
*  I'm meditating on how.
*  Was I'm sorry, I haven't looked at that paper in a while, but I close.
*  So there's the problem of a related problem in all this is.
*  If all we do, if all behavior is caused by neurons discharging and glands
*  secreting and there's nothing else.
*  Well, that's a very deterministic position.
*  And according to many people, then there goes free will.
*  You know, how can how can my wants be anything I control if they control me?
*  And yet in the law and in personal relationships, we do hold each other
*  accountable and we do excuse each other.
*  So the reasons for actions matter, at least in social discourse.
*  And so one of the challenges is reconciling intentional
*  reasons with neural causes.
*  And the multiple realizability, according to many philosophers, is that is
*  is that crack in the window that allows for planning of alternative futures
*  to mean something to think about?
*  What do I want to live in Durango, Colorado or Pagosa Springs until you
*  committed to one or the other, and you're not going to live in a
*  one or the other? Those were both like lively viable possibilities.
*  Decision making and specifically psychotic decision making is kind of
*  in this sweet spot, right?
*  So thinking about a bridge locus and linking propositions for, let's say,
*  you know, like a motor neuron that innervates the muscles, right?
*  Well, that's pretty clear.
*  But and in that paper and in your more recent paper, you still, I believe,
*  worry that higher cognitive function is not necessarily amenable to this approach, right?
*  Well, that's part of what was going on with this transit neuroscience papers,
*  thinking about what we can know and where our uncertainties are in terms of a
*  bridge loci for, you know, let's say the stochastic accumulator decision
*  making kind of framework.
*  So. The work that you were involved in at Vanderbilt,
*  several of us have been working on, sparked from the race model of the stop
*  signal task, the countermanding task.
*  Well, the race model that Gordon Logan formulated explains how behavior in this
*  particular task arises.
*  And it's an abstract model, as you know, a goal and a stop process that have
*  random finish times and they don't interact.
*  The end. That's the model.
*  And the mathematics of finish times let you estimate a quantity that you
*  couldn't otherwise see.
*  Call stop signal reaction time.
*  Well, for the first 15 years of its existence in the literature, you know, it
*  was a number you could get from behavior and it changed in kids with ADHD and
*  other disorders.
*  But what it was, neuro, neuraly was entirely unknown.
*  Hmm.
*  So then Doug Haynes, long time ago, ran into the paper and suggested we do it
*  with monkeys and.
*  And it turned out to be very useful and informative.
*  So we found neurons doing just what they needed to do to be implementing that
*  race model.
*  But now we've got this level of description of an abstract math model and
*  we got neurons and we need to communicate across those levels more deliberately,
*  which leads to the interactive race model, part of which you accomplished in
*  the in that I science paper.
*  You mentioned Gordon Logan.
*  I'm just kind of curious where he is, where he is in thinking about neurons.
*  Does he care about neurons these days or is he still because it was interesting
*  lab meetings to have you, although you appreciate psychology and, you know, the
*  math psych models, but, you know, hardcore neurophysiologist and then Gordon on the
*  other side being a sort of hardcore.
*  I don't care about the neurons.
*  This is the way the model works.
*  And it was hard to move forward on the psychology of these things and meetings.
*  Oh, you know where he is these days on that?
*  Well, we're still collaborating with Tom Pomeri and a group of really talented
*  postdocs.
*  He's still animated by the questions.
*  We're working on one project right now that was was launched with another postdoc
*  several years ago, Brahms and you know, Brahms recognized that we should call it
*  E pluribus, and it was a not a model, a simulation of how ensembles of ramping or
*  accumulators can make reaction time distributions that are realistic.
*  Well, we've extended that more recently to a choice version.
*  So there's two ensembles of ramping accumulators and we can now instantiate
*  speed accuracy tradeoffs and try and understand how these ensembles of
*  accumulators work together.
*  They're not interacting yet, but a number of interesting ideas have emerged about
*  how speed accuracy tradeoff could be governed.
*  That are beyond just changing the threshold, which is the standard
*  psychology model way out of this has also risen some new insights into the
*  judgments of confidence that one can probe after having made one of these choices.
*  So in doing this work, Gordon and Tom and I have different views about what we're
*  doing.
*  So I, well, and it comes to the use of the word simulation.
*  So we've debated whether EPU is a simulation or a model.
*  And the reviewers treated it like a model that could be parameterized to fit
*  behavior and explain something.
*  And in my view, that's not what it is.
*  What we're doing is simulating the essential aspects of a particular group of
*  neurons and then evaluating that performance.
*  One of the things this new modeling is doing, because we have choices now, is
*  instantiate choices across the speed accuracy tradeoff and then simulate
*  distributions of correct and error RTs and then fit those with one of the
*  psychological models like the linear holistic accumulator.
*  And so it's been an interesting thing to explore, you know, as above, so below
*  are the parameters of the of the psychology LBA fit to the performance of
*  the supposed neural instantiation?
*  Do they map onto each other very nicely and accurately?
*  So we're still all engaged, but our unique perspective is coming from our
*  careers lead us to this rich, ultimately synergistic outcome.
*  Yeah, I was going to ask you about this later, but I'll just ask now because
*  because of this kind of collaboration with psychology writ large, I suppose,
*  you just use the word rich, right?
*  You know, how important is it for, let's say, a neurophysiologist to get that
*  perspective from the other side, quote unquote?
*  I mean, it's been a very productive collaboration, you know, specifically
*  with Gordon and Tom, and I know, you know, there's lots of others, but since
*  we're talking about Gordon and Tom right now, but it's also sometimes causes a
*  little friction, I remember as well.
*  But I suppose we need that friction to make progress.
*  Yeah, I think so.
*  I mean, the friction happens just when either of our collective assumptions are
*  violated or compromised and we have to think, you know, why are we saying this?
*  How do, why do we think we know this?
*  And out of each of these, as you said, sometimes, fractious and even heated
*  conversations, because we care, comes new insights that would not have been
*  arrived at unless we'd have engaged like that.
*  I mean, why should a neuroscientist know about psychology?
*  It's certainly because that's what the brain does.
*  I mean, one could study the brain just because it's a cool organ in and of itself.
*  It's beautiful anatomically and in sort of an inner working sense.
*  And the investigation of other organisms and other nervous systems is really
*  interesting and really also enriching.
*  But if we're interested in human behavior and, you know, dealing with disorders of
*  human behavior and cognition and emotion and so on, if we want to relate
*  neuroscience or neurophysiology, let's say to the human condition, we need to say
*  what the human condition is accurately and use words carefully.
*  The problem is the scientific terms of art, like decision or attention, that we
*  try to use those in a scientifically rigorous sense, but they're words we use
*  commonly every day when we go home with our kids.
*  So again, back to the linking proposition idea and a math psych approach, the goal
*  is to expose the assumptions in the use of the words and eventually, ultimately to
*  kind of replace the word with its kind of more functional, even mathematical or
*  neuromathematical underpinning.
*  Going back to the, you know, the idea of linking propositions.
*  Another thing I was struck with revisiting the whole decision-making,
*  quote unquote, decision-making literature specific to psychotic eye movement
*  related decision-making and choosing is just how thorny every step is, right?
*  And how detailed and rigorous one must be to study these things.
*  And in some sense, going back to what I was saying earlier about the right level
*  of cognitive process to study that links up with the idea of a bridge locus and
*  linking proposition, which seems most amenable to the neuron doctrine, right?
*  Of Horace Barlow, back when single neurons were considered to be
*  doing cognitive functions.
*  But even this one little step, the psychotic system in terms of visual
*  attention and choosing targets becomes really thorny with the linking proposition.
*  And, you know, you again, something I admire have that rigor and that attention
*  that is required to go down this road.
*  But even in something that is, you know, maybe less higher cognitive, right?
*  Like decision-making in two alternative forced choice task, even then it sort of
*  explodes and there are so many different issues.
*  So how far do you think the concept of linking propositions can take us in terms of
*  quote unquote, higher cognitive functions, emotions and, you know, this
*  deliberation process, etc.?
*  Right.
*  Well, I want to make sure I'm hearing the question.
*  Well, the question is, how does the linking proposition framework translate to
*  more complex mental states and behaviors?
*  Which you mentioned in 2004 that we may not be able to get there, right?
*  Right.
*  Well, we sure are not going to get there without having gone through the effort of
*  figuring it out for simpler systems.
*  I mean, we worked out the hydrogen atom before we did any others, right?
*  You got to, you know, you walk before you run.
*  But certainly, so there's a bifurcation here on the one so that we can talk about
*  a higher order function, language, social cognition, that kind of stuff.
*  Yeah.
*  That's one way to go.
*  And we can.
*  The other thing is the single neuron is recording that neuron is that
*  neuron, the bridge lobes.
*  Surely no.
*  I mean, it's that neurons embedded in a circuit and now we're now, okay, well, how
*  big is the circuit, which where is the circuit?
*  You know, what are the boundaries of the circuit?
*  Which neurons are part of it?
*  I don't obviously know there's going to be anatomical connections, but I can draw
*  a path from the olfactory bulb to the visual cortex too.
*  It's a roundabout path.
*  Right.
*  Well, that's not the circuit where me we think.
*  Right.
*  So again, these, the, the, the framework of the approach to, to, to identify the
*  questions that need answering, I think is going to be useful all the way through.
*  Then also, I mean, this kind of refers to the calcium spikes too.
*  Neurons have properties that we didn't anticipate things Horace Barlow didn't
*  know like calcium spikes and apical dendrites, active dendrites in the first
*  place took a while to understand.
*  Right.
*  And even in the brainstem, like the models of saccade production, just
*  saccade production, eye movement generation, but David Robinson, you
*  know, of Johns Hopkins, those models are, are, are powerful and effective because
*  they translate into the clinic effectively and help with diagnosis.
*  But what's been discovered is that there are properties of the membranes of certain
*  neurons in that brainstem circuit that were it not for that ion channel, it
*  wouldn't work the way it needs to work.
*  So, you know, okay, well, that's the bridge locus too.
*  And we are talking about channels and it's a good thing we are because there's
*  certain drugs that can be given to act on that channel that treat eye movement
*  disorders.
*  So, you know, we don't want to be hamstrung by these concepts either.
*  Now for something like social cognition, for example, I guess we can use that as
*  an example or, or, um, you know, more complex decision-making about interpersonal
*  relationships and stuff like that.
*  It's still the brain doing it.
*  And maybe the olfactory bulb is more involved now, right?
*  Cause you know, how someone smells matters, right?
*  But, um, it's not clear to me that it's a qualitatively different problem.
*  It's less, we know less about it and maybe, and if we're talking about language,
*  like what we're doing, it's a uniquely human capability, which means there's
*  certain data we may never get.
*  Right.
*  But that's sort of an ethical thing.
*  Scientifically, the phenomena underlying the data we would like to get are
*  happening in our brains too.
*  Do you think that the single neuron doctrine set neuroscience and or psychology
*  back, or do you think it was kind of a necessary stepping, stepping stone?
*  Because now people talk about the population doctrine, right?
*  Right.
*  Well, I don't think that say a neuron doctrine or well, even the word doctrine
*  is kind of self congratulating, but you know, that's the data we had.
*  We had spikes of neurons.
*  And as we said, we can only get one at a time.
*  Then it was sure fruitful.
*  We discovered their tune for orientation and motion direction.
*  And if you'd show a monkey, a rival, a stimulus like Nicos and I did, well, some
*  neurons discharge when, you know, the motion is the thing the monkey says he
*  sees.
*  So single neurons are pretty smart.
*  But again, they're embedded in networks.
*  Right.
*  But like a place, you know, in a cortical area like frontal eye field or superior
*  colliculus, you can still record single neurons and it's, you know, you have these
*  distinct types of responses that they give.
*  So some are like respond to visual stimuli.
*  We'll just talk frontal eye field for a second.
*  Some respond respond just before an eye movement.
*  Right.
*  It's like a movement neuron.
*  And then there are some that are in between.
*  So you can kind of make a story out of recording these single neurons in an area
*  like frontal eye field.
*  But then you get into an area like supplementary eye field or other parts of
*  the cortex, right, where it's less clear or there's more variety in the types of
*  responses of neurons.
*  So in some sense, you know, the frontal eye field is a good area to be in if you
*  want to make these linking propositions, right?
*  Because you can tell you can make progress in that way.
*  Well, it's true.
*  But but partly because the questions were well enough framed and there was a
*  background of knowledge and so on and so forth.
*  So you're right.
*  When you move to an area like supplementary eye field where you've recorded two,
*  it isn't quite as clear.
*  But the same kind of deliberate approach that says let each neuron tell its story
*  and develop, well, mathematical models of alternative functional processes that
*  they could be engaged in or, pardon me, representing has allowed us to sort
*  things out.
*  And and so one paper that Amir Sajjad is the first author on in nature neuroscience
*  describes the laminar organization of supplementary eye field neurons in monkeys
*  doing the stock task.
*  They're not doing stopping.
*  They're not doing reactive inhibition.
*  But there's a lot of neurons active when monkeys make errors and when they're
*  going to get their juice or when they're not going to get their juice.
*  And so those neurons can be distinguished functionally, like when do they
*  discharge and how does the variability discharge rate relate to other parameters?
*  But importantly, they're also different in their distribution across the layers.
*  So if they're different in function and they're different in layer, they're
*  certainly different in connection and morphology.
*  So now we're at that circuit and neuron level.
*  We have another manuscript that is being it's been accepted at Nature
*  Communications from growing out of the same data set, describing three other
*  kinds of neurons that you would recognize.
*  You'd see the profile and say, I saw that neuron before.
*  I'm sure.
*  Yeah.
*  Right.
*  But now there's sort of some other explanations for it, some other
*  possibilities for interpreting it.
*  And so there's the next step.
*  Now, from the population coding idea, of course, lots of lots of labs are happy
*  to put many electrodes in and then, and then combine the activity as a whole
*  through dynamical systems approach, information theory, other, you know,
*  other kinds of things.
*  Now, much of that in, in, in, in the, in the, in the, in the, in the, in the
*  my understanding has been for the purpose of brain machine interfaces, you
*  know, making a robot move out of motor cortex.
*  Right.
*  So now it's an engineering problem and it doesn't really matter how the brain
*  works. It matters how my robot works and how I connect my robot to the brain.
*  It's a decoding problem.
*  Yeah. Yeah.
*  So more power to them.
*  I mean, this is, this is important if they can make progress and help people
*  fantastic, but I don't think we should deceive ourselves into thinking that's
*  how the brain works because structure and function are so intimately connected
*  that if you ignore the layer in which a neuron is recorded, for example, then
*  you're missing a big part of the, of the essential neuroscience story.
*  OK, so this, this brings me to deep learning, right.
*  In these really large learning models that have become all the rage and that we
*  discuss a lot on, on this podcast, but it's interesting.
*  I have a slide in the course that I create all about this neuro AI landscape,
*  and it shows the old way of doing things where you have a hypothesis and then you
*  might build a model.
*  And then the new way of doing things is you build a model and you train the model
*  and then, you know, and then you compare the model to your data.
*  But what I realized, embarrassingly going back and reading the strong inference,
*  John Platt paper, is that I need to update the slide because you don't make a
*  hypothesis. You need to make multiple alternative hypotheses.
*  Right. So I don't know if you want to discuss, you know, well, maybe you could
*  just describe what strong inference is because it's a pretty simple thing.
*  And then I want to ask you about what your thoughts are on this alternative
*  approach of just creating these really large models, training them, and then
*  comparing them to brains and whether that is amenable to a strong inference
*  approach.
*  My understanding of strong inference is that it's basically eighth grade science,
*  the way we were taught.
*  Right. Which no one does.
*  Right. Right.
*  You ask a question that you can answer and the answer is yes or no.
*  A very Sherlock Holmes kind of approach.
*  So that if the answer, you know, whatever the answer is, you have some
*  confidence that the state of the world is such that it's A and not B.
*  And then if it's A, it could be A prime or A double prime.
*  So now we do the next experiment.
*  But it requires grounding the hypothesis in kind of a rigorous
*  network of statements and concepts and facts and math and so on that allow you
*  to articulate something meaningful.
*  Sometimes, now let's be clear, it's not that works when you know something well
*  enough to ask that question.
*  The right questions.
*  Yeah.
*  Yeah.
*  Lots of aspects of brain science are still exploratory.
*  So it would be premature to be too rigorous in your hypothesis testing until
*  you know enough about what's going on there.
*  So, you know, kind of just looking and seeing what's going on, there's still
*  plenty of room for that, but when it works best is when there's multiple
*  competing hypotheses and you can conceive of an experiment that divides,
*  you know, where the outcome resolves a set of questions more decisively.
*  And a sort of Popperian falsification process, I suppose.
*  Well, that seems to be the most rigorous, doesn't it?
*  And it's exhausting and, you know.
*  Yes, it is.
*  That's true.
*  And it's rare that such papers get in the glossy journals for some reason.
*  And that that's a driving force, a social influence that we all have to acknowledge.
*  But again, those social influences are not what has scientific progress,
*  rigorous scientific process happens.
*  I mean, just because the church said he shouldn't, Galileo did see those
*  moons and that's that.
*  What do you think of the, you know, you know, training a deep learning model and
*  then comparing it in a sense, you're not really even asking a question.
*  Do you see, is there room, you know, within the machine learning kind of
*  modeling approach and comparing it to brain data, is there room for strong
*  inference using that approach or is this something that is less than ideal in
*  your eyes?
*  Well, it's a great activity because the network can do things for us.
*  Maybe some of the things it's doing for us, we should think more carefully
*  whether we want that done, like facial recognition that misidentifies certain
*  categories of people more likely than others.
*  So now it's a social problem, right?
*  But the scientists have to be responsible for that.
*  If we stay closer to this world of like, how does the brain work, understanding
*  how, how, how, how intelligent systems networks work, there's things to learn
*  from the, the, the kind of machine learning neural networks.
*  And I think everyone should appreciate that in the beginning of kind of modern
*  ish neuroscience in the 1950s is arising at the same time, the computer's being
*  invented and touring and, uh, McCulloch and a lot of people, they're, they're all
*  the same ideas.
*  So that they should be considered separate seems artificial too.
*  Now with the machine learning networks, there's also, uh, because they're so
*  powerful and because they're so complex, often the, the, the person selling the
*  service cannot explain how they work.
*  And that's becoming an increasing problem.
*  As you know, I've been involved in another kind of activity in, at the
*  interface of law and neuroscience.
*  Yeah.
*  And so we invite the students to think about situations where artificial
*  intelligence system, like in a hospital setting, for example, leads to a bad
*  outcome and the patient wants to sue the hospital when, when the doctor cuts off
*  the wrong leg, we know that the doctor made a mistake and why, and how we see
*  how the system did it, right?
*  If the AI system, if no one knows how it works, it's hard to assign blame.
*  And so I'm, I'm familiar with a, a new, or it's new to me growing interest in,
*  uh, in the phrase explainable AI so that we understand how it works well
*  enough that we can trust it.
*  And when it goes wrong, we know why and what to fix.
*  But so thinking about in terms of models of the brain, right?
*  There's this problem of model memory.
*  Um, that has, well, I won't say plagued because the problem is that multiple
*  different kinds of models can explain psychological behavior, essentially.
*  And a lot of what your research program has been about is using neural data to
*  decide which is the better model because there's this problem of model
*  memory and it's, and so, you know, we were talking about the race model
*  where it's very simple.
*  There's a, a go accumulator and a stop accumulator and they're racing, right?
*  And this, that's two units.
*  And then, you know, you can add more units for choice and things like that.
*  But then these really large deep learning models, it seems like model
*  mimicry, uh, would become more of an issue because lots of different deep
*  learning models can be trained to do the same thing.
*  So then to adjudicate between, to say something about how the brain is doing
*  it, you know, and there are people like Jim DeCarlo who, you know, set up like
*  a convolutional neural network and then the layers of the network seem to map
*  on to activity in layers of our, in hierarchical layers of our visual cortex.
*  On the other hand, you could probably make 30 different models, uh, of the
*  same ilk that would also explain a lot of the variants.
*  So how much, you know, how much of a problem do you think model mimicry
*  is in this deep learning approach?
*  And by the way, before I can, before I forget to tell you this, it was funny.
*  Um, I had someone in, uh, a discord server that I run for, um, the podcast
*  supporters who said he was, uh, using a, a recurrent neural network with one unit.
*  And it looked like the, like one, like, you know, recurring unit.
*  And he said, it looked like what was happening was the unit was
*  just accumulating to a choice.
*  And I was like, oh, okay.
*  You just built a, uh, yeah.
*  You just built a model like I used to work, but in a recurrent
*  neural network, quote unquote, you know, those deep learning terms.
*  Anyway, make sure you heard that.
*  Thank you.
*  Well, my, my instinct is to say, if we're talking about object
*  recognition, let's say, but keep it in the D'Carlo lab framework and we can
*  tell cats from dogs and now the network can tell cats from dogs.
*  Now your brain and my brain are not identical.
*  Right.
*  Right.
*  And we both have V1 and V2 and so on and so forth, but at different places in the
*  network, they're going to be radically different because your dog and cat
*  growing up are different from my dog and cat.
*  So at some point there's differences.
*  And yet at the level of, is it a dog or a cat categorization, we both
*  satisfy the goal of the task.
*  So this is one way I've thought about, you know, if you, if you can build
*  and convolutional neural networks and they all tell dog from cat starting
*  with pixels, you know, so there's the V1 ish thing and at the end it's, that's
*  a cat, not a dog, the stuff in between is going to have, can have as much
*  variability as can be the case, but there's going to be some aspects that
*  are similar across all systems.
*  For example, I think, I mean, I don't know that this is true in all the, all
*  convolutional neural networks, but I think I've understood that the input
*  level is more granular, higher resolution.
*  Then you get the lines and features and then you get components and
*  surfaces and then you get objects.
*  So that flow seems to be the way to do it.
*  I don't know.
*  Has anyone built a system that doesn't have that sequence or
*  could have any other sequence?
*  I don't know.
*  Good question.
*  I mean, that's all ventral stream, stream as well.
*  And dorsal stream is a different beast itself.
*  Although people are building these hierarchical networks that are, I'm
*  unfamiliar and I should be with, you know, the authors and stuff and such, but
*  there is being, there's progress being made in the dorsal stream as well, which
*  is the how or, or where region.
*  Yeah.
*  Well, and in the motor cortex too.
*  And so, yeah, sure.
*  I mean, we think we understand that neurons are just nodes and networks where
*  they influence each other through exciting and inhibiting, and there's
*  lateral inhibition and there's feed forward and there's feedback and there's
*  recurrence, well, that can be instantiated lots of different ways.
*  And then it's a common function.
*  Are students in your lab these days?
*  Is anyone wanting to use these kinds of deep learning approaches?
*  Because in my world, like everyone's using deep learning, right?
*  So, yeah.
*  Yeah.
*  I forbid them.
*  Yeah.
*  So that, okay.
*  That's what I'm getting at.
*  Oh, come on.
*  We're just, we're just dealing with different problems right now, but this,
*  this problem space, of course, is one that's very active in Toronto.
*  And many of the York faculty are interested in active in this area.
*  So it's, it's one of the reasons that it was fun to move to York where this kind
*  of exploration is so vivid and active.
*  So I'm going to harp on the deep learning aspect just a little bit more here,
*  because it's there, there's been this wave, right?
*  With the quote unquote deep learning revolution of popularity and using these
*  approaches to do other things, but also to study brain areas.
*  And you've had a long career.
*  And so you've seen lots of waves of popularity of various brain areas,
*  various cognitive functions to study right now, cognitive maps and the hippocampus.
*  Seems very hot.
*  It's hard to tell from where I sit.
*  I know everyone has a different perspective on these things.
*  So in your judgment, do you think that this little deep learning wave, is this,
*  is it here to stay?
*  Do you think it's going to pass by and move along?
*  Well, I haven't paid as much attention to no, I mean, it is, it does feel faddish.
*  Of course.
*  Fad.
*  That's the right word.
*  Yeah.
*  Yeah.
*  But it hasn't affected your, your work so much, right?
*  It hasn't.
*  No, it doesn't.
*  I don't, I don't read that literature to get inspiration and how to think about things.
*  But it, so on the one hand it's, it's incredibly useful and profitable.
*  So they're not going away.
*  And the problem of understanding when, when a convolutional neural network goes wrong
*  in a bank or a hospital or on a military device or something like that, that's serious.
*  So understanding how they work, I don't think that problem can go away.
*  And it's, it's not clear to me that if you answer it for this network, doing this thing,
*  that it won't be that you'll not have to start all over again for a different network,
*  doing a different thing with credit cards now.
*  I don't know.
*  So that's active.
*  No, will they help us understand the brain?
*  Well, as, as sort of intuition pumps about how you'd organize a ventral stream.
*  I mean, my reading of the DeCarlo and others work is that it sort of endorsed this idea.
*  It's satisfied is that starting with this granular, more pixelated representation of an image
*  that gets features and then they get bigger receptive fields that integrate more information
*  that are shaping, you know, coming to surfaces and shapes and finally to objects,
*  objects that you have to learn.
*  So, you know, the greebles, nobody knew about a greeble till Mike Tarr and Isabel Gautier invented them.
*  Now you can have greebles, you know?
*  Right.
*  So the learning element is a key part of this as well.
*  So it feels to me like we've, we've had sort of an insight into how you make an object recognition system in a primate bank.
*  What, I mean, what else do you want to know with them?
*  I mean, the, you know, the varieties of networks that can, well, I don't know.
*  I mean, I know at MIT, they enjoy these contests of networks, you know, the network that is the best.
*  Right.
*  Recognizer, you know, categorizer or whatever, whether a network that categorizes as well as people is done that work like the human brain.
*  I'm not sure that's guaranteed.
*  And it's not self-evident to me that that's as useful an activity as exploring the human or the primate brain directly.
*  But it may be.
*  Again, as we've said, I don't live in this world.
*  Right.
*  Right.
*  That's why I wanted your perspective on it as well.
*  Yeah.
*  But in terms of just fads, let's say, and not just, you know, the deep learning fad, do you get better throughout your career of recognizing when something is going to,
*  is just a passing phase and what seems to be more important and we'll stick around?
*  Well, in my own work, I feel like I'm confident that I'm addressing the best questions I can address.
*  Given where I come from and what I've done and resources and so on.
*  I mean, there's other, other really important questions.
*  Other people are addressing.
*  It's like, for example, years ago, I mean, it's still the case, but years ago when oscillations became a fad.
*  Yeah.
*  I remember, I don't remember what year it was, but all of a sudden there at the society for neuroscience meeting, multiple labs were reporting oscillations.
*  Yeah.
*  Last year, they weren't working on that.
*  But now they are because, you know, so scientists are faddish like everybody else.
*  And again, it's sort of the social, the social currency of getting the glossy journal paper and, you know, being perceived as working on the hot problem.
*  I haven't been motivated to chase the hot problem because I feel like I'm happy working on these hard problems that seem well and fundamental.
*  There's a lot to do.
*  There's still a lot to do.
*  Yeah.
*  Yeah.
*  So it's a big tent though.
*  There's lots of room for lots of people to do things.
*  If we had enough funding.
*  Oh, that's the yes, of course.
*  Right to your representatives.
*  What's going on in the lab these days?
*  What's new?
*  What are you working on and what's keeping you from making progress?
*  What's keeping you up at night?
*  Yeah.
*  Well, there's three main things.
*  The linear electrode array data collection is the big data collection thing.
*  And so I referred to some work in V4 and some work in supplementary eye field.
*  The V4 work was done by a graduate student named Jake Westerberg working with Alex Mayer.
*  And we've published some papers and there's more to come.
*  Part of it was understanding how V4, the cells across the layers of V4 contribute to visual search performance.
*  Both the target selection, attention allocation, and in association with saccade production.
*  Very, very like what we've done before, but in V4 now.
*  And so there's stories to tell about that and discoveries that have been made.
*  The other aspect of this is relating the laminar distribution of local field potentials to the current source density that produces the EEG signal.
*  And so during visual search tasks, there's an EEG event related potential component called the N2PC.
*  Discovered by Steve Locke a long time ago and Jeff Woodman, our friend and colleague.
*  I work on it and recognize that there was a fruitful path to look at EEG in monkeys and understand where these different components come from.
*  So a paper is being revised for neuroimaging in which we can do forward modeling.
*  We can take the currents and convert them to dipoles, calculate the dipoles those currents are producing.
*  And with a model of the conductivity of the head, the brain, the skin, scalp, and bone and everything, calculate what the voltage distribution would be, which is a unique solution.
*  We're able to do that only because we're collaborating with really smart people.
*  Jorge Riera is the leader of this lab and the graduate student is Beatrice Herrera.
*  So the N2PC comes from V4, but LAP contributes.
*  Frontline field, while it wants to do and influences V4 in the circuit as a biophysical generator of the N2PC has nothing to say, very little because it's too far away and it's pointed the wrong direction.
*  Okay, gotcha.
*  So this is a really interesting insight that a given cortical area can be computationally critically involved, but biophysically invisible.
*  Well, through EEG anyway.
*  Through EEG, yeah, right, right, right.
*  So that's one line of work.
*  The other line of work is extending the medial frontal recordings from supplementary eye field down into both banks in the cingulate sulcus in the monkey.
*  So Amir Sajjad and Stephen Arrington have collected a rich database from two monkeys doing the saccade stop signal task with different reward amounts and kind of reversal learning component to it.
*  And we're re-describing how the dorsal and ventral bank of the cingulate sulcus and the fundus are similar, are different to each other and overlying supplementary eye field.
*  And how each of them contribute to the error related negativity and the feedback related negativity.
*  You have so much going on still.
*  And there's one more to go.
*  Yeah.
*  One more thing to tell you because this isn't even, well, the data is collected.
*  Caleb Lowe and Thomas Rappert collected recordings from frontal eye field of monkeys doing a complex visual search task.
*  So it was complex in two dimensions, two interacting dimensions.
*  And we've never talked about this.
*  You won't know about this.
*  Okay.
*  So it's a color singleton search.
*  So he's looking for the red among green or the red among not so red or the green among red or the green among.
*  And he doesn't know what color anything's going to be until the trial, until the arrays present.
*  So he's got no set for what the target is.
*  And so the reader, right.
*  So you got kind of easy search and hard search.
*  That's one dimension.
*  And then, then what he does with his eyes is dictated by the shape of the stimulus.
*  Okay.
*  And so in the first period, in the first run of this, let's say if it was vertical, make a prosa code.
*  If it's square, make no saccade.
*  And if it's horizontal, make an anti-saccade.
*  Yeah.
*  Hard to train this, I'm sure.
*  Hard to train.
*  Hard to train and a smart monkey learned to cheat in a really interesting way.
*  Now we manipulate the difficulty of encoding the cue by making the long gate, making the thing really long or really stubby.
*  Now in the data that we've collected, we got rid of the anti-saccade for interesting reasons that you can find on a bio archive paper with Caleb Lowe.
*  But we now have what we could call, I don't know if this phrase works.
*  I'm still playing with it, but it's two dimensional decision making.
*  Psychologists would call it multi-factor decision making.
*  But in the, in the, you know, the famous dots task, it's hard on one dimension, you know, motion coherence.
*  So this is hard on two dimensions, the identifiability of the target from the distractors and the categorization of the cue.
*  And those two factors are independent of each other.
*  So you get distributions of reaction times that are fast if things are easy in both dimensions and progressively longer if things get progressively harder.
*  So there's a, we learned a theoretical framework called system factorial technology.
*  Okay.
*  Which sounds like a mouthful.
*  Yeah.
*  And it is Jim Townsend at Indiana University conceived of it with his coworkers.
*  But everybody says signal detection theory and feels quite happy about it.
*  But it's the same mouthful.
*  And it's the same principle.
*  You start with mathematical principles out of which you extract from performance key parameters.
*  You know, signal detection theory is discriminability and bias.
*  System factorial technology is a sequence of analyses of the reaction time distributions that under the appropriate assumptions reveal the architecture producing the behavior.
*  Is it are the factors being processed serially or parallel?
*  Oh, okay.
*  Are they race or exhausted?
*  You know, so the process, the process architecture, you mean?
*  Yeah, yeah.
*  So we've recorded neurons in front of the eye field, and we know neurons in front of the eye field, some of them select targets.
*  And the time it takes to select the target varies with how discriminable the target is.
*  We know other neurons make saccades and when they turn on depends on how discriminable things are.
*  And there's RT variability there.
*  So the expectation is by looking at the time of modulation of different neurons, we'll be able to partition reaction time into these different operations.
*  They may overlap in time, but we may be able to detect that on the premise that the different neurons, again, it's a sort of a strong inference approach.
*  Given that certain neurons instantiate one process and not another, then we can see when those processes begin and terminate relative to one another.
*  That's on bio archive, you said?
*  Well, the cheating monkey paper is on bio archive.
*  It's an N of one monkey paper.
*  Yeah.
*  Oh, okay.
*  Yeah.
*  So we replicated the Bishow effect.
*  So Kirk Thompson, when he was in the lab in our C-species show discovered that monkeys are partially trained to do one color among another color in search have front eye field in which half the cells select the target immediately.
*  They're color selected.
*  Well, one of the monkeys, it was Darwin.
*  Okay.
*  Yeah, yeah.
*  Memories flooding me with memories.
*  Yeah.
*  Yeah.
*  So he had so much experience doing stuff that he saw the cheat.
*  And so his front eye field cells discriminated the orientation of the cue right off the bat, or many of them did, because he wasn't, he was just getting the cue and he wasn't worrying about where the singleton was till later.
*  So this is similar to the to this recent cheating monkey.
*  Yes.
*  Yeah, that's that that won't make it to because you have to have an N of two to publish in a journal, right? So it's going to be forever bio archive bound, I suppose.
*  Out there for people to find if they want, they can evaluate whether the data seem reliable and the conclusions follow.
*  All right, Jeff, I told you I had a few guest questions.
*  Two of them come from you've mentioned a lot of people to them come from Brahm Zandbelt.
*  So I'm going to play these questions for you.
*  And then if we have time, I'll play a third from another previous so I should say Brahm was a postdoc in your lab.
*  I think he'll actually say this.
*  So I'm going to play this and then you can react to it.
*  Okay.
*  All right.
*  Hi, Jeff.
*  I worked in your lab between 2011 and 2014.
*  It was a privilege to work with you and with all the talented, smart people in the lab, Paul being no exception.
*  Quite a few shawl lab members from the period don't work in academia anymore.
*  So my question for you is, how is it for you as a supervisor to see the graduate students and postdocs that you trained choosing a career path outside academia?
*  This is a I guess this is kind of a hot topic in academic society.
*  It seems like people are leaving in droves, especially these days.
*  But so, yeah.
*  Do you have a do you have a reaction to that or an answer?
*  Well, I don't blame you.
*  Oh, that's right.
*  I'm I'm case point.
*  Yeah, you're looking well.
*  And you is collected.
*  So I don't blame you.
*  I don't blame Brahm.
*  I don't blame you.
*  No.
*  I mean, the most recent is this Caleb Love that I mentioned earlier.
*  So he was lined up to do a postdoc actually with Stefan Everling.
*  Oh, right.
*  Oh, he told me that.
*  Yeah.
*  Yeah.
*  And a variety of things happened such that he just decided he wanted to work as a data scientist.
*  It seems that the training you guys collectively, not just our lab, all the labs like this, the training you get as market value out in the real world.
*  Right.
*  And so he seems to be happy doing that.
*  Brayden Purcell, I don't know if he still is, but he after a really successful postdoc with Ruzba Kiani and a K99 basically in his pocket, chose to work for Squarespace.
*  And and that's fine.
*  K99, by the way, is a grant that kind of ushers you into faculty position just for.
*  Thank you.
*  Yeah.
*  So, no, I mean, were I at that time in life faced with situations like we are, you know, limited grant funding, fewer jobs, various kinds of challenges and and more opportunities than were certainly available when I was at that stage.
*  When I was coming out of graduate school and postdoc, I don't think I was marketable for anything.
*  Did you did it?
*  Was it tempting to to I mean, because you seem, you know, you're a lifelong academic rigorous scientist, like I've like we've been discussing.
*  But have you ever been tempted to jump ship?
*  But on the other hand, you've been extremely productive.
*  And as far as I know, you've always been extremely productive.
*  And, you know, I'm not sure if that's played into it or or or what?
*  Well, yeah, I never wanted a job.
*  So so the family business was selling farm implements.
*  And I guess maybe we can reveal to the to whoever might listen to this, that you are living in the town over Wolf Creek Pass.
*  All right. Where I where I grew up in a farming community.
*  So the family business was selling international harvester farm equipment and Heston hay equipment and so on.
*  Shaw Ironworks.
*  And my dad came home every night.
*  He said, if it weren't for money and people, this wouldn't be bad job.
*  And so I never wanted a job with money and people.
*  And of course, I didn't get that.
*  But I have a freedom of exploration as a PI.
*  That is unlike what one has in the in the business world where whoever says what you're supposed to do.
*  So I always was committed to this academic path and just strove to do what needed to be done to be here and stay here.
*  Not a lot of people go ahead.
*  Yeah. Well, I just want to reiterate loudly and clearly for everybody that that and each of you guys who's left the lab knows that I supported you in these new positions.
*  Yes, you certainly have, at least in my personal experience.
*  Yeah.
*  Now, so it's a new day.
*  And when you get rich in the real world, endowments are welcome.
*  OK, very good.
*  Yeah. But but isn't it I would imagine it's a little sad.
*  I don't know if sad is the right word, but you know, because you invest so much time and effort in training us then to have someone essentially not
*  disregard, but then move on to a space where they're not going to be using that training necessarily in the future directly anyway.
*  Is there some some part of you that's a little sad when someone takes a different course?
*  I wouldn't say it's sad, but but there's a here's a reality.
*  When you leave academics, my neurotree doesn't grow anymore.
*  Right. Right.
*  Nor your legacy, right.
*  Because those are directly.
*  Yeah. Yeah.
*  So as as and again, I'm going to elaborate a little bit just for the benefit of those who might listen in the United States, the NIH funds training grants, they're known as a T32 to institutions.
*  And.
*  Through all the years, I was the PI of it.
*  The renewals were accredited by the number of trainees who went on in academic careers.
*  And the trainees that went into other careers outside academia just didn't count as much because they're not publishing papers.
*  They're not sustaining the legacy of the of the lab, the individual and the institution.
*  So that's a frank reality of it.
*  Yeah.
*  Now, I've never said to anybody, no, you have to stay unhappy in academics, just so I can have another citation or something like that.
*  No, I can vouch for that.
*  You you always give a really nice celebration.
*  I remember mine very clearly when I was moving on and have always been very supportive, which I don't you know, not everyone's like that.
*  So another thing I appreciate about you scientifically as well.
*  The other thing. Well, let me the last thought I want to make on this is.
*  Almost everybody who's left has stayed engaged or we've stayed in touch and we've published papers after the fact.
*  So Rich Heights, we're not briefly with.
*  We're still there's another paper on Suburban Night Field with Thomas Repert leading it.
*  Yeah, that manuscript will revise the Excel reports right now.
*  All right. Very good.
*  All right. Here's Brahm's other question.
*  You earned your PhD in 1986 and started as an assistant professor at Vanderbilt in 1989.
*  More than 30 years have passed since then.
*  I'm curious, how has academia changed over the period, according to you?
*  What has changed for the better and what has changed for the worse?
*  All right. So, yeah, I've been at Vanderbilt, was at Vanderbilt for over 30 years and now at another institution.
*  So some comparisons are available.
*  So here's a thing.
*  Here's one of the things that's changed for the better.
*  That is, and it was vivid at Vanderbilt for a long time.
*  That is the interdisciplinarity and the appreciation that you shouldn't stay in your silo.
*  So the places.
*  Well, the interesting places are places where people can work across departments and faculties and colleges and so on.
*  And in a meaningful collaborative way.
*  And ideally, the institution either prevents or lowers barriers to that or even maybe rewards it by things like getting teaching credit for teaching a course that's for an interdisciplinary major and not your main department.
*  That's one of the things that I think has improved or certainly changed over the years.
*  One of the things, you know, a change for the worse is I would identify with the salaries of the presidents and chancellors and the number of administrative staff or sort of the dean's offices have seemed to grow in number and cost.
*  Out of proportion to the what benefits faculty get and the salaries of the staff, you know, the janitorial and the kitchen and that kind of thing.
*  So the factors that have led to disparity of wealth in businesses, you know, the CEOs making I don't know how many hundred times more than the average salary.
*  The same trend has happened in US schools.
*  And so why is that?
*  Do we know why?
*  I don't really know.
*  I think my experience in interacting with the chancellors, the various chancellors at Vanderbilt and Provost is that boards of trust reward.
*  Well, the boards of trust are many CEOs of corporations where that's the mindset is the first thing.
*  The second thing is this almost illness to be the guy with the most money and compare yourself to your peer group in all these various ways.
*  And then, of course, kind of the Kahneman Tversky thing that once you're a millionaire, making another thousand isn't much difference.
*  You have to make another hundred thousand different.
*  And then when you're a billionaire, it's got to be a million more, you know?
*  So it's an insidious process.
*  But the expansion of administration at universities and the sort of the overhead that that's created in terms of just more forms to fill out or less efficiency.
*  Do you think that's going to continue?
*  Well, I don't know how I don't know who's who's turning it around.
*  How long are you going to be assigned to?
*  How long are you going to be in academia?
*  I know you just started a new job.
*  So this is terrible. We won't play this for your university, perhaps.
*  But, Debra, do you see yourself ever?
*  It's not on the horizon, right?
*  Retirement or anything like that?
*  No, I feel very invigorated with the new kind of questions we're working on here and new faculty.
*  So new opportunities for other kinds of collaborations in a new environment.
*  Yeah.
*  So I'm not tired at all.
*  And I haven't run out of ideas and I still enjoy revising manuscripts and working with trainees to get the figure just right.
*  So the process is the process is what I enjoy.
*  And I still enjoy it.
*  I taught in the winter term, taught systems and cognitive neuro class, undergraduate class for a new undergraduate major here and great students, great conversation.
*  So I feel very fortunate.
*  Well, maybe here's the thing that's changed for the better, too.
*  In many places, there's no mandatory retirement age.
*  So I'll keep going a while longer.
*  We were before we before I hit record, I was just marveling at how you don't age.
*  So you don't look anywhere close to retirement.
*  And I know, you know, you've as long as I've known you, you've you've seemed invigorated with these questions.
*  It's quite impressive.
*  Well, Jeff, this has been a lot of fun.
*  I'm glad we finally got you on the podcast and I appreciate your time.
*  And here's to the next 30 years at York.
*  Good luck with the new environment and I hope it continues to go well.
*  Thank you, Paul.
*  And best to you and your and your lovely family in Durango, Colorado.
*  Brain Inspired is a production of me and you.
*  I don't do advertisements.
*  You can support the show through Patreon for a trifling amount and get access to the full versions of all the episodes, plus bonus episodes that focus more on the cultural side, but still have science.
*  Go to braininspired.co and find the red Patreon button there.
*  To get in touch with me, email paul at braininspired.co.
*  The music you hear is by The New Year.
*  Find them at thenewyear.net.
*  Thank you for your support.
*  See you next time.
*  Love a boundless blank page
*  Let me into the snow
*  The covers up the past
*  They take me where I go
