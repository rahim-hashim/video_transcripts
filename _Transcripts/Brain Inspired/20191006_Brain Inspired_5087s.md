---
Date Generated: April 21, 2024
Transcription Model: whisper medium 20231117
Length: 5087s
Video Keywords: ['Science', 'Technology', 'Education']
Video Views: 151
Video Rating: None
---

# BI 049 Phillip Alvelda: Trustworthy Brain Machines
**Brain Inspired:** [October 06, 2019](https://www.youtube.com/watch?v=8wxepE3XDt8)
*  The big epiphany in running a startup or two is once you get the funding to go and build
*  your startup for the first time, just how free you are and how effective you can be
*  at building something really, really fast, incredibly efficiently.
*  If you would have asked me, say, even five years ago, how long my children would live,
*  I probably would have said, you know, maybe to 90.
*  But I don't believe that anymore.
*  Now what? Now what do you believe?
*  This is Brain Inspired.
*  Hey, everyone. This is Paul Middlebrooks. Have you ever built something that was
*  launched into space and took pictures of another planet?
*  Yeah, me either.
*  Philip Alvelda has, though, and he's my guest today.
*  Philip worked for NASA's Jet Propulsion Laboratory in the 1980s and worked on multiple instruments
*  that were launched into space for various reasons.
*  And as you'll hear during that time, he did some related early work with neural networks.
*  That is not what he does these days, though.
*  After running a few startups over the years, winning lots of awards,
*  patenting lots of things, and a stretch at DARPA overseeing multiple biotechnology projects that
*  helped bring about our current brain machine interface technologies, among other things,
*  he has now started a company called Brainworks, where he and his team focus on building brains,
*  essentially, to make trustworthy, powerful AI.
*  They use inspiration from neuroscience to build the hardware that powers their technology.
*  So they're not just using deep learning to do their thing.
*  And Philip is a huge proponent of using as much neuroscience knowledge as possible to build AI.
*  This is a little different than many of my previous episodes.
*  We spend a good deal of time talking about entrepreneurship and startups,
*  and the difference between the academic and industry worlds, a little bit about AI safety
*  and ethics. With regard to his company, Brainworks, we talk a bit about their first product called
*  Ambient Biometrics, which monitors a user's vital signs using a camera, like the camera on
*  your smartphone, to reduce the friction with doctors visits and health checkups and so on.
*  And they are hiring, so check them out at Brainworks.ai.
*  Or you can learn more through the show notes at Braininspired.co.
*  Dripping in diamonds, Rebecca, Philip, Hugo, and David.
*  Thanks for supporting the show on Patreon. Your support and your patience will be rewarded.
*  Speaking of diamonds, I tried last week to get my wife to sell her engagement ring that
*  I bought many years ago now. Since as you know, diamond engagement rings are just a
*  ridiculous manufactured market that, yes, I gave into many years ago, basically just to
*  avoid the judgment of family and friends, which is really embarrassing. But she won't do it.
*  She won't sell yet. If this beautiful support keeps coming in though for the podcast,
*  I may ease up on her. Maybe. Or maybe I can get Philip, Alvelda, to hire me. Hmm.
*  All right. Thanks for listening. I really enjoyed talking with Philip,
*  and I wish him success. And here is our conversation.
*  Philip, welcome and thank you for being on the show.
*  Oh, my pleasure.
*  You know, I thought we were going to be doing a little face to face because it's over Skype,
*  but right now our video cameras are off. So I guess you cannot tell me my heart rate right now.
*  I know if you were seeing me, I know that you could tell me.
*  That's exactly right. Well, at least our product could. I don't know if I could with my own naked eye.
*  Right. Well, I'm excited to have an entrepreneur on the show. So I've had one in the past. I enjoyed
*  having Francisco de Salsa-Weber on the show. He works on natural language understanding.
*  But I've mostly had academics on. And not that you're not an academic, and we'll talk about that in a few minutes here.
*  And I've had a few DeepMind folks on. But I've been working to get some more industry people on too.
*  So, Philip, you're the CEO of BrainWorks, which we will talk about soon as well.
*  And you have a long academic and business career. So you have a different perspective than most of my guests,
*  I guess, is what I'm saying here.
*  Yeah, what you're saying is I'm really old and I've been at it for a while.
*  I haven't had many geezers on the show, so this will be good.
*  Yeah, but you straddle neuroscience and AI, and you're also steeped in the business side of things.
*  So this is going to be good. So when I was younger, I was old enough to reproduce, but still younger.
*  My plan was to have the first baby in space. And since then, I've had a surgery actually that will prevent me
*  from having any more children. And I can send you a picture of that if you'd like.
*  But is that why you worked for NASA when you worked for NASA? Did you have the same plan as me?
*  Not exactly. But I was absolutely captured by the idea of launching things into space.
*  And when I first started, you know, I had the good fortune of being accepted to have a job at NASA's Jet Propulsion Laboratory
*  just before the Challenger blew up.
*  Oh, man, I didn't realize that the timing was such.
*  Yeah, and I was afraid that going in at that time, you know, the whole shuttle program would be stalled or perhaps even shut down.
*  And I'd be going to NASA to twiddle my thumbs where nothing ever got into space.
*  But you know, nothing could have been further from the truth. I went, I kind of buckled down.
*  NASA did a fabulous job of kind of reinventing itself in the process.
*  And I ended up having several instruments fly in space, which was, I mean, how many people, you know, first job out of college.
*  God, that's so cool.
*  You get to build stuff that goes to another planet.
*  Yeah.
*  And I got to do it three times, you know, one to Jupiter on Galileo, one to Venus on Magellan, one to Cassini on Cassini to Saturn,
*  and then a couple of instruments on the space shuttle.
*  So I was I was almost I threaded the needle to come in to have just huge opportunities.
*  Really exciting time.
*  Man, that is exciting.
*  I'm actually I'm going to ask you a little bit more about that later.
*  And I like the way you phrase launching things into space as having children in space.
*  I haven't thought of it that way. So that's a different way to think of it.
*  My babies, my babies.
*  Yeah, that's right.
*  So first things first here, before we really get into it, I would love for your help with some listener mail, which is a rare thing I do on the show.
*  Would you mind helping me answer a question?
*  Have you help?
*  So I had a listener write in.
*  He's an undergraduate.
*  He's trying to decide whether to get an M.D.
*  Ph.D. or just a Ph.D.
*  He's interested in neuroscience and he's also interested in A.I.
*  He says, I can't imagine myself letting go of either possibility, medicinal neuroscience or A.I.
*  slash computational neuroscience research.
*  But one worry is that he doesn't know like how stable and non medical career would be, you know.
*  You know, but he also worries that if he goes the medical route, he could be missing out on super interesting research in the A.I.
*  and neurosciences area.
*  So what would you advise him?
*  What path would you advise him to take?
*  And you can, of course, feel free to.
*  That's a tough one.
*  You know, I would say, you know, from my own experience, whatever you're most passionate about, go all in.
*  And I wouldn't necessarily feel like by choosing one path for the moment, you're giving up another.
*  You know, I think that that my governing principle of academic advice is go in the direction that keeps the most doors open.
*  So if you're going to study something or go, you know, choose an institution or choose a path, think about if you do it, what doors stay open afterwards?
*  Could I go into medicine and focus on clinical care and working with patients and treating them?
*  Or do I want to work on a research program where, you know, I have new problems every day and very different kind of experiences.
*  Both are super fulfilling for the right kind of person.
*  But, you know, you probably have time for two or three careers in your lifetime and try not to be vigilant.
*  As you can attest.
*  Yeah. And as I can as well.
*  But I guess, you know, are we going to have another winter where he's not going to be funded if he goes the research route?
*  You know, of course, there's always need for doctors, right?
*  Yeah, I think, you know, I joke because, you know, my mom had a plan for me when I was a kid.
*  You know, she had imagined from when I was very young that I would be a neurosurgeon.
*  I was good with my hands.
*  You know, she taught medical school.
*  It was, you know, kind of a perfect a perfect match.
*  It was foiled when I when I ended up in the Cornell bookstore looking at that organic chemistry text with a thousand pages of figures that I want to memorize.
*  Yeah. And then I wandered over to the physics section and it was one quantum mechanics book, 300 page book with one equation.
*  So that that I felt I could manage.
*  So I ended up as a physicist and that that worked out well for me because, you know, physics was kind of a foundational science for many disciplines.
*  You know, taught a lot of analytical skills that were very generic and applicable everywhere.
*  And, you know, I went on later in grad school to work in computer science and electrical engineering and and all the artificial intelligence work.
*  So, you know, I think, you know, as long as you get a good foundation and, you know, bio biochemistry, you know, kind of the precursors either for neuroscience or a good career in medicine, I think you've got a lot of jumping off points after that.
*  You really can't lose either way, I think.
*  Yeah.
*  Yeah. And the and the changes in biochemistry and gene science, technology, synthetic biology and whatnot, those are, I think, the really exploding areas of science right now.
*  You know, here's here's a good test for you when you're in a college, you know, kind of visiting, get in the elevator and look at the bulletin board and the bulletins of what classes and seminars are in the elevator.
*  And when you do that, you know, compare it to the bulletins that you saw last month or last year.
*  And if the bulletins are always the same from year to year, that's kind of a stagnant field.
*  But I'll tell you, the bulletins that are new every year right now are all the biology, all the synthetic gene technology.
*  Those are just a rocket ship right now.
*  Thinking of speaking of rocket ships.
*  So there you go, Mitchell.
*  I hope that Philip answered your question there and now and set you on your career path.
*  So blame Philip if it goes awry.
*  Don't try this at home, right?
*  Yeah.
*  Speaking of rocket ships, I say that because every startup has a little picture of a rocket ship and that's their, you know, little logo, right?
*  But you, you are the CEO of Brainworx.
*  And so we're going to talk about Brainworx in just a minute here.
*  And you've been you've had sort of a long history in in entrepreneurship as well, kind of intermingled with your academic work.
*  And if it's OK, I'd love to just ask you about entrepreneurship in general before we talk about Brainworx specifically.
*  Sure.
*  So I was listening to a I don't know if it was a Freakonomics podcast episode or maybe the Knowledge Project.
*  I cannot remember, but the take home message was that a lot of successful people in general have immigrant parents.
*  The idea was that they get their language from their mother.
*  So they have like these great language skills and build good skills that way.
*  And their work ethic from their fathers.
*  Does that resonate with you?
*  Well, I definitely got work ethic from my dad.
*  But, you know, my mom was a workhorse, too.
*  So I would say that she shared equally in that influence.
*  You know, mom was a lifetime academic, you know, even founded a medical school and worked for the CDC.
*  And dad, of course, was a was one of the earliest technical people at the Coca-Cola company and and actually
*  was the one that programmed the first IBM computer ever sold commercially, which was to Coke to work on, you know, distributing bottle,
*  bottle, bottling plant distribution.
*  Oh, my gosh. You know, my dad was the first person to take money out of an ATM in Louisiana for IBM, actually.
*  Interesting. That's awesome.
*  And so, you know, they both were very influential.
*  And, you know, I think there is a lot to be said for the immigrant work ethic where, you know, just just if you take a population and you
*  kind of look at who has the initiative to leave where they are in pursuit of something better versus, you know, just kind of sticking with the status quo.
*  I think there's just an automatic filter for people that have more initiative.
*  Right.
*  And they, you know, as they raise families, they're a good example of, you know, what is it that you have to do to make sure that that your kids' lives are better than yours through your efforts.
*  And that's your responsibility.
*  So that was that was kind of programmed into me for from a very young age.
*  And now that's you have you have children, right?
*  Absolutely.
*  And now that you're programming that into them, even though you're not an immigrant, I suppose.
*  Yeah, you know, we're trying.
*  Yeah, yeah, I get it.
*  Constant struggle.
*  You know, I've got two teens, so I'm, you know, living it.
*  Yeah, yeah.
*  Well, so do you think that there is a fundamental difference in makeup between academics, let's say, and industry folks and entrepreneurs?
*  Is there a bright line that separates these types of people?
*  I think initially, no.
*  But over time, they tend to develop different habits of mind and work.
*  And I think that, you know, I wouldn't I wouldn't say that there's a hard and fast rule that, you know, one cannot transform themselves or straddle the two worlds.
*  You know, I've always really enjoyed, you know, having a hand in on both sides.
*  And I've kind of drifted to both sides of the line from from time to time in my career.
*  Yeah.
*  And in fact, you know, I think some of the best academics are keenly sensitive and involved in commercial endeavors of some sort or the other, where many of them have that that not just, you know, kind of a sense of what is academically interesting and appropriate and fundable.
*  And how do you work within the university and tap that wellspring of innovation and fresh ideas from new students every year?
*  Versus, you know, how do you take those kind of early explorations and expansions of what's possible and turn them into things that at scale can really impact industry and the world at large, which, you know, small academic groups by themselves just don't have the right.
*  The total, you know, man hours and hands and time to do the way they're organized.
*  So, so, you know, I think it's I think both worlds well-leveraged kind of play off well against each other.
*  And, you know, like anything, you've got specialists on one side or the other, and then you've got generalists that can straddle.
*  So all of them, I think, have important roles in advancing our society.
*  Well, it's sort of it used to be kind of celebrated crossing over more like back in the day of Bell Labs.
*  Right.
*  But and then it I don't know if that went away, but it seems like companies these days more and more are teaming up again with academic labs.
*  Like, you know, there's a lot of Google and DeepMind folks publishing paper with university labs and things like that.
*  And, you know, and I know that you've seen a lot of this kind of stuff.
*  And is this a good thing, you think?
*  Well, you know, when I was back at MIT, there was there was a moment where it seemed like every other professor was having a startup on the side.
*  And where the hell are they for my office hours?
*  Oh, they're at their startup.
*  Right.
*  And so sometimes, you know, it was frustrating for the students to, you know, not have the professor around.
*  But then, you know, you turn around next month and, oh, look, I can get an internship at the company next door that my professor is running.
*  This is fantastic.
*  Oh, that is good.
*  Yes.
*  So, you know, I think there is a little bit of a double edged sword in how do you manage it?
*  But but I think, you know, that was at MIT, which was, you know, always kind of innovation oriented.
*  Stanford was very much like that.
*  Cal Berkeley.
*  Right.
*  You know, I spent some time, you know, in the area.
*  And I think that that notion of, you know, empowering the students to create not just, you know, new technologies, but companies to leverage them.
*  That, of course, is that the startup, the tech startup idea, the Silicon Valley culture has started to really propagate beyond, you know, the traditional, you know, New England Silicon Valley corridors.
*  And I think that's a really good trend.
*  But it's hard to kind of recreate the big ecosystem that that lets a company scale quickly.
*  So that's still a work in progress for many cities.
*  Interesting.
*  So you do have kids.
*  And I know, I mean, I have children, too.
*  And trying to explain having children to people who don't have children is just a lost cause.
*  I find, you know, words aren't enough and it's impossible to paint the complete picture.
*  I even say it's only people that have no kids or only one child that give parenting advice.
*  Because as soon as you have to, you realize that what worked for the first one really doesn't apply to the second one.
*  I know.
*  And then it's also that having two actually is somehow twice as hard as having one.
*  I don't understand how.
*  And these people that have three or more that have to go to zone defense, I don't understand how they manage.
*  This is why I had surgery, man.
*  This is why I had surgery.
*  But anyway, I feel that way about entrepreneurship as well.
*  Like nobody really gets it unless they either do it or have done it, you know.
*  And I don't know if you feel that same way.
*  But what is something that entrepreneurship has taught you that you think that academics might be missing out on?
*  Well, I think the the most important thing about a startup in particular, and so not just general entrepreneurship, but being in a startup, is the amount of impact you can have.
*  With minimalist bureaucracy.
*  Today's university is a, you know, is a quagmire of administration and organizations and committees and stagnant processes for starting new schools and new programs.
*  And then, of course, you've got all the vagaries of government agency funding and how to wrangle it and the old boys networks running them and so on.
*  So those are all, you know, things that that constrain you.
*  And and I think that there's kind of intellectual freedom at the university that you don't necessarily have in a company to kind of pursue whimsical ideas that come upon you, assuming you can get funding for them.
*  But there's not really operational flexibility.
*  There's there's big bureaucracy and financial constraints and how many students can you have and all that sort of thing.
*  So I think the big epiphany in running a startup or two is once you get the funding to go and build your startup for the first time, just how free you are and how effective you can be at building something really, really fast, incredibly efficiently.
*  And the type of people, though, that you need to do that, you know, they there's really a different mindset once you're there where, you know, you never know what's going to happen in the next day.
*  Everything's very uncertain.
*  Your paycheck is good for another six months.
*  But after that, you'll run out of money.
*  So you better figure something out.
*  But it's you doing the figuring.
*  There's no committee that's preventing you.
*  There's no bureaucracy that you're waiting on for a decision.
*  You are building it.
*  Well, it forces it forces efficiency to write.
*  Yes, it forces efficiency and it also forces a little bit of kind of flexibility and general kind of tolerance of ambiguity and being able to do the job that needs doing, even though you didn't plan for it in the moment.
*  You know, I'll give you an example.
*  I had one one of the first companies I started micro display.
*  We were making the we'd invented the technology for the displays that were inside the Google Glass, ultimately.
*  And I was I was the CEO of this company.
*  I started as my first company out of MIT.
*  And there's a day where one of my electronic engineers who specialized in circuit board design came to find me and say, hey, Phil, I'm frustrated because I feel like I'm doing technician work and I'm doing like board testing and assembly that any technician could do to get these development kits out to the customers.
*  And I really want to design the new stuff and do some of the more interesting work.
*  And the irony, of course, was that to tell me this, he had to find me in the warehouse where I was moving boxes.
*  Yeah, and I was doing boxes because I was organizing them to be shipped out, you know, and there was no one else there to do it.
*  No one was there.
*  So picks up the boxes and moves them because that's what the job of the day was.
*  And and so I said, well, the boards have to be assembled and tested.
*  The boxes need to be loaded on the trucks.
*  If you want to move the boxes, I'll do the assembly testing.
*  I'll see. That's where you got to fire them on the spot and say, go start your own damn company.
*  And he chuckled and said, OK, all several boards.
*  Yeah.
*  But, you know, I think, you know, it's one way to think of a good startup is that, you know, when it's you and your co-founders, you're wearing all the hats.
*  You have to do everything. Yeah.
*  And your job in a lot of ways is to grow the company as quickly as you can.
*  So you can hand as many hats off to other people to scale the thing up quickly and, you know, wield more corporate ability and operational, you know, kind of strength and capability.
*  How much does that how much does that bog down the creative vision?
*  You know, for the right startup and the right people, it doesn't because, you know, all of those practical issues, they're the real things that you're contending with.
*  I mean, you're not just contending with your ideas.
*  You know, you're contending with the physics of the real world.
*  You know, you have to ship things.
*  You have to satisfy customers.
*  You have to, you know, do all of these things to have real impact.
*  And and it's not necessarily that it's not creative.
*  I mean, you know, part of the creative process in the startup is, you know, how can we do with two people what Cisco does with 50?
*  Yeah. Yeah.
*  And there's a lot of creativity in that frustration, a lot of risk, a lot of ambiguity, you know, some days with dicey paychecks.
*  But but there is nothing like it.
*  Once you do a couple startups and with a good team, you never want to go back to a bureaucracy.
*  Well, as my next question is, do you recommend it?
*  Oh, absolutely. Well, not for everyone.
*  I mean, there are people where, you know, you're in a stage of life where, you know, you can't afford the risk.
*  And and, you know, maybe you have obligations and education support or alimony or mortgages.
*  And, you know, what I find is that that I think it's great for a lot of people who have some tolerance for risk and ambiguity and a thirst for adventure.
*  That it's absolutely something you should try.
*  But timing it is important.
*  You know, I kind of joke that, you know, there's a great time to start a company, which is, you know, just after you get out of school, whether it's, you know, undergrad or grad school.
*  Was that you get well, you've already been kind of hammered into lean and hungry existence, you know, with your budget.
*  Oh, yeah, sure.
*  And, you know, you're used to ramen noodles and mac and cheese kind of dinners.
*  And, you know, I kind of joke that, you know, your first job as a startup founder is you need to get to ramen noodle profitability, which basically you need to be making enough money to pay for your ramen noodles and sustain yourself.
*  Yeah.
*  While you build the rest of the company.
*  So, you know, later in times in life, you know, sometimes there are times when you just can't manage it, you know, financially and logistically.
*  But, you know, every once in a while, life will throw you a curve ball and you can say, oh, you know, I had a minor windfall and, you know, I can survive without a paycheck for eight months, 12 months.
*  You know, let's start a company and see how it goes.
*  But it's absolutely worth it.
*  It's an experience like no other.
*  I'll ask you in a year or so and we'll see how BrainWorks is going.
*  So, yeah, this is number three or four for me.
*  So I'm clearly, I joke about, you know, this startup bug being a little bit like a drug addiction.
*  Oh, man.
*  Yeah, it's got to be.
*  Well, so you're used to, let's talk about BrainWorks a little bit here.
*  So you're used to giving, or you used to be, well, I don't know what you're used to, but you've given a lot of academic like talks where, you know, you dive into technical details like, you know, how much information is encoded in single neurons versus a distributed population of neurons.
*  You know how AI can benefit from understanding how a lot of different brain areas contribute to cognition and so on.
*  But ambient biometrics is a bit of a left turn for you.
*  I've seen you with your CEO hat on in talks as well talking about ambient biometrics.
*  So what is ambient biometrics and how does it fit in within BrainWorks and how does it work?
*  Yeah, well, BrainWorks, I mean, the way to think of BrainWorks is we're a little bit of a dual headed beast where.
*  You know, BrainWorks is intended to be a foundry where we make brains that can solve problems that more pedestrian AI tools, you know, can't manage because we're incorporating some new technologies that came out of the work from DARPA.
*  And for us, you know, when you build a company, it's great to have a nice technology that does new stuff.
*  But the guts of the company has to be something that is a financial engine that people care enough about to pay for that you can use to then grow the company larger.
*  And so what we what we did is we went through quite an extensive process when we were saying, all right, well, these are the core technology nuggets that we have that we think could empower big new industrial capabilities, which are the ones that we build first.
*  And what is the industry and the problem that we're trying to solve that if we build that one piece, we solve this one problem.
*  And that could build our first product that drives revenue that we grow the company on.
*  And, you know, so the second part of the company, besides kind of the technical underpinnings of the new AI engine that we build to make these more complete brains that think more like humans, is that application and service that uses it to do something meaningful.
*  And that really is the ambient biometrics of our first product where we targeted the delivery of health care.
*  And we're looking at the health care industry and kind of the process we went through was to look at the world and say, where is there a big, intractable problem that our current solutions really just can't address them?
*  And we looked at education and transportation and energy and a whole set of potential areas where we could apply these things.
*  And we ended up looking in particular again and again, we kept coming back to the basic demographic problem that is now just a global phenomenon where fertility rates are falling, the age pyramid, the population pyramid is inverting.
*  You look at Japan, Korea, China, Spain, Italy, they are already in a position where they don't have enough young, healthy health care workers to treat the increasing number and needs of elderly.
*  Yeah.
*  And this is something where those nations are kind of ahead of the rest of us, but we're all following.
*  You know, we had the lowest birth rate, UK had the lowest birth rate in their history.
*  Everyone is headed in this direction of an increasingly aged population.
*  So the fundamental question is, how do you care for them when we don't have enough people?
*  So it means you have to automate the things, but health care delivery is a very manual, hands on task.
*  And it's complicated and anything can happen.
*  And so we began looking at that space to say, well, where could we have a meaningful impact?
*  How can we change the equation of how many people does it take to care for, you know, how many need?
*  And we realized that there was one aspect that everyone had taken for granted because we'd been doing it the same way every time.
*  But it turns out it's a huge burden.
*  And that is the taking of vital signs.
*  You know, think about it.
*  Every medical procedure in the United States is mandated by the FDA that it requires you before you engage in a diagnostic activity, that you take the vital signs of the patient and use it to assess their state of health.
*  It's also mandated that you sit in a waiting room for an hour, right?
*  Well, I wish that weren't mandated, but I think that's part of the effect of not having enough people.
*  Yeah.
*  And that, you know, that factors into the cost.
*  So now you've got a waiting room.
*  Everyone's wasting time sitting there.
*  You can need a nurse and a half.
*  You need a, you know, you get taken into the little treatment area, height and weight, any problems, you know, blood pressure, the whole thing takes, you know, something like 30 minutes within the clinic.
*  And, you know, all of that, you know, amortize all that cost turns out it's really expensive.
*  Takes a long time, limits how many people you can treat, limits how much time the doctor and the nurses can spend with you.
*  So it really is a huge burden that everyone has accepted because it hasn't changed for so long.
*  And when we realized that, well, hey, wait a second.
*  You know, it used to be that you have to touch people to figure out, you know, what their pulse rate and blood pressure are.
*  Use a cuff or a lead and so on.
*  But we had seen some demonstrations that, you know, some studio grade cameras at MIT, a guy named Bill Freeman did some really nice work with his grad students there that used a camera to be able to pull out pulse rate.
*  And he demonstrated that it was possible using, you know, a super high quality camera and studio lighting and, you know, patients not really moving.
*  And while that was a good technology demo, it really wasn't a workable product because it didn't account for all the vagaries of people moving around and different skin tones and changes in lighting and, you know, all that sort of thing.
*  And now the patient's talking.
*  So what does that do to the readings?
*  So it showed that it was possible, but it wasn't quite possible with the garden variety tools and in the environment of the common clinic.
*  But this looked like a perfect opportunity for us because it turns out that a lot of the principles of how the brain works, how the retina works, how you know, you have a sheet of neurons in your eye that are light sensitive.
*  You know, it's really remarkable when you think about it, because each one of those neurons, they're really slow and noisy and imprecise.
*  And yet your vision is has very high acuity.
*  You know, you have you have incredible precision and being able to see things with with a good corrected eyesight.
*  But the individual neuron is very poor performing.
*  So how is that? Well, it turns out we've discovered some of those principles of how that operates.
*  And we can apply that to extract more information from regular camera signals than the traditional signal processing techniques.
*  So, you know, you can think of us as taking these new principles and pushing them all the way down in the sensor to be able to get more information from from the from the instrument.
*  So these aren't I mean, I don't know how secretive the actual technology is, but these aren't just convolutional deep nets that are at work here.
*  No, no, it's it's you know, we are using some convolutional techniques and some some deep learning learning components, but it's deeper.
*  It's in it's in the architecture.
*  It's in the data representation.
*  Interesting.
*  It's in the processing.
*  So it's, you know, thinking of it more more physical modeling in the design of the system.
*  Yeah.
*  According to how the neurons operate.
*  So it's it's less, you know, building a neural network than abstracting the principles of how the neural network operates and then using the math to do the analysis.
*  So, you know, we we we often will say, you know, if you think about how do you make a flying machine?
*  You know, we make jets now that are much faster than flapping wings, but it was by looking at the flapping wings that we extracted the math and the physics of flight and how it worked.
*  Same same type of challenges in building a system like this.
*  The other there's another interesting kind of neural aspect to what we're doing, where we look at how the the visual cortex kind of amplifies signals that you're attending to and suppresses signals that you that are that are noisy or not relevant.
*  And we're able to use some of those techniques to kind of enhance and and determine when you take a measurement, we can actually get an estimate of its of its quality and precision as we're taking each individual measurement.
*  So these are the kinds of technologies that we're deriving from these brain inspired learnings from the from the brain machine interface programs.
*  So are these like patent pending technologies?
*  That's exactly right.
*  So we have we have several patents filed and, you know, kind of more in the works.
*  Cool.
*  But that's, you know, part part of the fun in the startup.
*  How do you kind of keep enough secret and tell people enough to get them excited while you're protecting yourself?
*  Well, we kind of skipped over.
*  So, you know, if you I'll link to videos of you presenting this, but you demo the ambient biometrics product on stage where you get into the range of the camera, it recognizes you and it says CEO, yes, may I get you some coffee?
*  And then it starts taking your vital signs, right?
*  We haven't we haven't finished the coffee feature yet.
*  I see.
*  But we'll put it on your feature request list.
*  Yes.
*  I think, you know, yeah, that's that's pretty much more or less how it works.
*  And so the technology that we're applying all of these new brain inspired ideas, we've now built a complete system that has several components of AI assembled in one system that altogether completely automates the process of taking vital signs.
*  And all the person has to do is wander in range of the camera.
*  And so, you know, when we when we talk about ambient biometrics, we mean that it's ambient in the sense that it's part of the environment and you don't have to really pay attention.
*  You don't need a nurse.
*  You don't need a doctor.
*  The patient doesn't even necessarily need to be aware that it's happening.
*  We can use a camera that's overlooking the waiting room.
*  And just by being in the waiting room, your vital signs are being assessed.
*  And you don't necessarily even need a person because, you know, having been to the doctor's office before, we've had pictures of you in the past.
*  We know we use facial recognition to figure out who you are.
*  If you're in one of the consenting patient databases, we then start doing the analysis and the recording of your vital signs and log it automatically to your health record.
*  So it's a system that replaces all of that cost, all that time, all those people in just the administrative and bureaucratic process of assessing your vital signs before anything happens with a doctor.
*  So we can kind of really overturn the physical costs of an operational burden of doing that whole process.
*  And, you know, one of the one of the other exciting bits of it is, you know, we talk a lot about it being ambient in the sense that, you know, you just set up a webcam in the waiting room, but it could also be installed in the laptop that you work in front of.
*  It could be in the smart TV in your living room while, you know, grandma is watching, you know, Jeopardy.
*  It can be in your smartphone or your tablet.
*  When you call up a doctor for advice, the system can be taking your vital signs and relaying them to a doctor that's remote.
*  So a lot of what used to require you to get in the car and drive to a hospital or a clinic, now we can do while you are anywhere within the cell phone network.
*  So I think there's, you know, huge opportunities to kind of reinvent a lot of processes within the hospitals and clinics, but also kind of break down the walls that limit your your necessity to be in a clinic and expand the ability to monitor people, you know, pretty much anywhere anytime.
*  So, you know, a lot of this sounds like Big Brother, right? I'm sure you get a lot of
*  A lot of a lot of immediate reaction about that. So we will have to talk about ethics here.
*  I don't know. Yeah, I don't know if you want to go ahead and talk about it. I mean, camera, camera in the waiting room. And so on the one hand, this sounds so great because it's it's ambient, right?
*  And and the reality is we have cameras on us anywhere we walk around in public just about and we're being recorded. Right. And everyone kind of accepts that.
*  But the
*  But that information is not being used to improve your health. It's only being used in case you do something wrong, for instance. Right.
*  Yes. Well, that's the that's that's the very nature of the double edged sword of advanced technologies, you know, any any advanced technology really can be used for good or ill.
*  And and the ethics of the companies and the and the regulations and certifications.
*  The norms that you have in your company are all, you know, super important in determining, you know, who should have access to the technology and where it can and should be deployed.
*  Because you're right, you know, that the same facial recognition technologies that could be used to, you know, automatically assess your health on an ongoing basis.
*  And, you know, give you preventive warnings when you're headed for a crisis. It's the very same technology that an oppressive government can use to, you know, refine your citizenship score based on how you behave.
*  And in fact, that that is one of the uses that we've seen some press about in China.
*  Yeah, so I was thinking China and raise your insurance as well.
*  Exactly, exactly. Well, you know, we have been approached by insurance companies to help aerial analysis and and but, you know, there's there's applications everywhere that can benefit.
*  So I don't know if you're aware, but, you know, all the new Tesla's Model 3s, they have an internal, you know, passenger facing camera.
*  You know, the airlines have, you know, passenger facing cameras in the seat backs.
*  And, you know, it's not to spy on you. It generally is to help in many ways. And so detect, are you injured? Are you awake? Are you drowsy?
*  You know, does there need to be some sort of intervention or rescue?
*  And I think that we're at a really interesting time where these technologies are advancing so fast that I don't see the kind of societal conversations keeping pace.
*  No, yeah. Well, well, it's it's coming more and more, I think.
*  I just read the the age of surveillance capitalism. I'm not sure if you've read that. But it's about how basically social media companies are terrible and reduce humans to data to be harvested, essentially, you know, and even though they maybe didn't start out that way. Right.
*  Yeah.
*  So, you know, you have like these maybe good intentions that that then can be used for evil later. Right. The the do no evil of Google is no longer in their company slogans and stuff. I don't know. I don't even remember my point now.
*  Well, just just that there are absolutely privacy concerns and
*  Well, that's what I was going to ask is because so the way in the age of surveillance capitalism. Sorry to interrupt. They
*  One of the things that, for instance, Google and I don't mean to harp on Google, but like with the street view camera things, right. They just do it and then get permission later. And then
*  They would have lawsuits, but they would just keep doing it. And then eventually it becomes becomes accepted. Right. And I'm wondering if our own sense of privacy, our right to privacy. If that is changing on a societal level. I mean, people are just so addicted to social media and we'll just post
*  You know their entire lives on it, not knowing that what is actually happening is they are being the data is they're just giving these social companies more data right to improve to then sell them more stuff or whatever. But we don't care. We don't care that people are watching us as much anymore. And I'm wondering if that's a trend.
*  I don't know. I don't know that I would say that most people don't care. I think that, you know, there's probably a very small minority and I mean, you know, less than one or 2% that are technically savvy enough are aware of the technologies and the practices.
*  Are thinking about it and are making a conscious decision about, you know, how how to or or not give away your, your personal data.
*  And I think that part of the challenge is that these technologies now they come about so fast. You know, if you think about the ramp up of Facebook versus the ramp up of say GE, you know, you're 30 years versus three.
*  Faster.
*  Are they going away just as fast to or is it just a ramp up.
*  I don't think so. I think. Well, I mean, we'll see how that broadcase
*  Sure.
*  For G.
*  You but, you know, the bigger issue is that you've got, you know, huge swaths of the US that didn't even make a transformation into the information economy.
*  You know, they they they don't have jobs. They don't have experiences. They're not involved in any of this technology technology development.
*  Right.
*  And yet they are, you know, avid users of technology that they have, you know, no clue of or experience in how they came about or even how they work.
*  And so, you know, I think that that part of the issue of, you know, it's like you, you got to be a little careful when you describe these companies as doing something as if it was unethical or illegal.
*  Right.
*  And and and then, you know, people are catching up with them later. Well, that's kind of the nature of technology development before the thing is even possible. And people are aware of it being possible.
*  There is no legislative framework or laws or regulatory environment to even attribute what's allowable or not.
*  And and so, yeah, they just do it. They're trying to, you know, I think, you know, honestly, in its early days, Facebook was well intentioned.
*  And, you know, their their goal to make money, you know, ultimately subverted a business model that was exploited in a way that they didn't even fully appreciate and expect.
*  And it was only after the fact that they realized the horrific impact that it had.
*  And, you know, but they're making money from it.
*  And, you know, the old saying that it's hard to convince someone against an idea that their paycheck depends on.
*  So, you know, now they're stuck a little bit behind that.
*  But but I think that every technology entrepreneur lives this dream of having real world impact and maintaining an ethical standard of some sort, you know, has different importance in different countries and companies.
*  But but there's no there's no no guide.
*  You're inventing new stuff in the laws and the politicians.
*  They just cannot keep up with the pace of technology.
*  They have not proven capable.
*  Yeah. Well, it's difficult for anyone.
*  Things are happening are happening so fast.
*  I mean, you know, I know that you are you talk a lot about concern for ethical A.I. and, you know, building empathy, for instance, into A.I.
*  I mean, is is the technology that you're building?
*  Are you finding it a hard sell with anyone?
*  I mean, are you coming up against resistance to the ethical implications or anything?
*  Or is it smooth sailing?
*  Well, I wouldn't say so far for us, it has been smooth sailing because we've been very, very careful to make sure that when we talk about what the system is doing, we highlight all of the measures, you know, both within the company and how it operates and within the product and how it's governed and operated.
*  So that it maintains the very highest standards of protecting confidentiality and consent and all of those grounding principles of strong ethics.
*  And so when we show that and we demonstrate how it works and we show the utility and the impact so far, the response has been overwhelmingly positive.
*  Well, it could really help a lot of people.
*  So.
*  Yeah.
*  And it's a sort of thing that's clearly transformative.
*  And, you know, you begin to start to have questions when you're approached by people that want to use it for other purposes that might not be aligned with the benefit of the user.
*  So that's where kind of the ethical backbone of the company and the company leadership come in, where you need to figure out how to hold that line.
*  Yeah, I'm sort of on on board, you know, when you give the demo and it's on your laptop and I mean, there are all sorts of concerns, I suppose.
*  And I know that you guys are working on keeping the keeping it private, you know.
*  But then then you mentioned having the camera in, for instance, the waiting room, right in the in a clinic or whatever.
*  And I think, oh, man, there are just so many different places where data can where there could be a tributary or an offshoot of the data that's just being copied somewhere else.
*  It's scary world out there, man.
*  It is.
*  It is.
*  And then, you know, this is this is where there does need to be some regulation.
*  Yeah.
*  And in many ways, you know, I wouldn't say new regulation.
*  I would I would often point to the fact that we've got, you know, very strong privacy regulations and ethics regulations in medicine.
*  But there needs to be some real diligent work to figure out how do you extend those principles and stay consistent to them as you expand them to to cover these new technologies and applications?
*  You know, it's it's I hear a lot of teeth gnashing and hair ending about, you know, should we regulate AI?
*  You know, regulating AI is like saying, you know, should we regulate cars?
*  Well, we do regulate cars.
*  You know, you have to wear seat belts.
*  You can only drive it so fast.
*  There's all sorts of things that we have as a society kind of agreed to manage.
*  But it's not that the tool itself, it's easy.
*  You regulate its use.
*  So there's there's some really interesting work to be done in figuring out what what are the best mechanisms and tools and societal constructs.
*  To to manage it.
*  You know, it doesn't matter because people will they'll get their biometric data and then just they're going to post it to Facebook anyway.
*  It wouldn't surprise me.
*  Yeah, you'll see like what the rock or something, you know, one of these high profile people.
*  People probably do that with fitness.
*  I don't know.
*  My two max and my Strava.
*  Yeah, altogether.
*  There you go.
*  So this is great.
*  So I know that you guys are developing the ambient biometrics more.
*  It's like, is it ready to go?
*  I know that you're so what's the status of the ambient biometrics?
*  And then I also just want to know the sort of long term vision of brain works in general.
*  Yeah. So so the ambient biometrics product is has made great strides.
*  We've we've integrated, you know, kind of the pulse rate and variability sensing as well as the respiratory rate and information sensing.
*  And then, of course, we're working on a long list of other physical biometrics that we will measure, you know, both remotely and directly.
*  But we have a kind of a long term road map for kind of expanding in two dimensions for this product line.
*  The first dimension is, you know, every quarter we expect to measure more stuff.
*  What is your heart rate?
*  What's your breathing?
*  What's your pulse?
*  Your your blood pressure and then expanding into other biometrics, not just a physical health, but mental health.
*  You know, what is your emotional state?
*  Are you in pain? Do you look injured?
*  Do you have some sort of motion control malady, whether it's, you know, Parkinson's or or dementia that changes how you can move?
*  And can we track the increase of of severity?
*  So so so that's one dimension is, you know, every quarter, you know, just using the same kind of camera sensing infrastructure, we can measure more and more things.
*  So you're built so sorry.
*  So you have like you guys are like doing an agile sprint and every sprint, the you know, the product to ship is is something new to measure with the technology.
*  That's right. Cool. That's right.
*  And you know, the where we've already installed it, it becomes more capable in that existing installation.
*  Yeah, so it's just, you know, this is the power of the cloud.
*  You know, we can spool up a new node and a new geography in about 15 minutes.
*  Max. Yeah, sometimes even faster.
*  It's really remarkable. But so that's one dimension is, you know, always measuring more stuff, learning more about you, having a better idea of what your health is.
*  The other dimension is as we collect data, we're going to be doing more and more with it.
*  So the first product is mostly doing the measurements and collecting the data and storing it in the records and sending some gross alarms of, you know, are you in some sort of dangerous condition?
*  The next stage, of course, is using that data to develop the next kind of stepping stone, which is diagnostics.
*  So having a lot of data, can we identify specific conditions and help doctors make decisions with greater accuracy and covering, you know, broader demographics and finding other conditions that they might not find, you know, with their naked eyes?
*  And then once we've done that stepping stone, then we have plans for a subsequent one, which says, all right, well, now, once we collect a bunch of diagnostic data and the trends of those diagnostics over time,
*  then we can begin to build predictive analytics. So not only are we looking at your state of health, we're looking at, you know, what is the long term trend of your state of health and make predictions as to whether or not you're headed for a crisis or not.
*  And, you know, and so then that's kind of the third stepping stone. And then, of course, you know, we have a progression of those going forward as we make the platform more capable, both in the data that it collects and what it does with that data.
*  There's got to be a lot of competition out there in this domain, no?
*  Well, you would think and I think that, you know, we look at people that are working on narrow aspects of the problem.
*  And so, you know, you have systems that, for example, you know, there's a lot of press of the Stanford group that looked at the radiology to find, you know, breast cancer or flu symptoms in chest x-rays, you know, in advance or with higher performance than the real doctors.
*  But the problem with a lot of those is that they're kind of single point solutions and they're not integrated in the larger medical workflow systems yet.
*  And they're not really trusted yet. And so our goal is to be kind of the system that can pull all of that together and unify it in a way that you can have conversations about it and you can build systems that are trustworthy that that really.
*  Are part of a larger medical solution rather than a point problem in a demonstration.
*  So I would say, you know, more than competition, I think there's a lot of opportunity to take some of these new technologies and fold them into really world changing systems that have huge global impact.
*  Maybe Mitchell needs to go work for you, the guy that we helped at the beginning.
*  Well, send in a resume. We are hiring.
*  Yeah, that's what I was going to say. You're hiring, huh?
*  We absolutely are.
*  So, Philip, let's see. In the interest of time, maybe we could.
*  So I think that what we're going to continue to continue to talk about brain work some, but maybe we can take that hat off and put on an AI in general hat.
*  Does that sound OK?
*  That sounds great.
*  So you have seen the rise of deep learning and you you actually worked with neural nets in the 80s at the Jet Propulsion Laboratory, which we talked about at NASA.
*  And in fact, let me read a title of one of your early papers here.
*  Neural network star pattern recognition for spacecraft attitude determination and control.
*  And I just I want to read just something from the abstract here.
*  Quote, new compute.
*  This is from the 80s.
*  New computer architectures based on the anatomy of the human brain seem to promise high speed and fault tolerant solutions to the limitations of serial processing.
*  This paper discusses the latest applications of artificial neural networks to the problem of star pattern recognition for spacecraft attitude determination.
*  End quote.
*  Cool.
*  What was the last for?
*  Yeah, man.
*  What was the feel of those early neural network days like during during those early during your jet propulsion laboratory days?
*  Because they weren't working as well back then.
*  Were people like kicking their big boxy computers and cursing at the neural nets?
*  Well, at that time, most people had no idea that neural nets even existed as a technology.
*  Well, they barely did.
*  Well, NASA didn't have anyone working on it when I was there.
*  Yeah.
*  And we were in a very traditional kind of electronics and sensor driven group.
*  And in fact, we were using, you know, kind of I'm dating myself a little bit here, but, you know, we were actually using the first ever charge coupled device sensors, the first digital cameras.
*  We built two of the first ones ever that launched on Galileo to take digital pictures of Jupiter.
*  And there were two instruments in parallel.
*  One was a scientific instrument that would take pictures with the digital sensor.
*  And we were working on the one that would control the spacecraft, which would track stars and the limb of the planet.
*  So, you know, kind of the shape of the curve of the atmosphere to be able to point the telescope accurately and keep it pointed in a specific direction.
*  And we also were responsible for the instruments that would figure out, you know, which way the spacecraft was going and which way it was pointing.
*  You know, by using the sun and by figuring out where Earth was.
*  And those instruments were really bulky and really heavy.
*  It was something like 22 kilograms of instruments just to figure out where the sun was and then kind of orient the spacecraft around the sun to figure out where Canopus was another bright star.
*  And between that and the sun, we could kind of figure out where the spacecraft was and know where to point the antenna to talk to Earth and get commands, you know, as to what it should be.
*  And at the time, you know, 22 kilograms of instrumentation was a lot.
*  You know, very expensive to launch that into space.
*  Tens of millions of dollars, you know, per kilogram.
*  You know, think of that sort of budget.
*  Yeah.
*  And so that was a really exciting project.
*  But, yeah, the challenge was, of course, to replace all that with something that would be the space itself.
*  But, yeah, the challenge was, of course, to replace all that with something that would be much smaller and more powerful.
*  And for me, there was this, you know, holy smokes moment when I didn't I wasn't even aware of neural networks at the time.
*  And I just happened to go to a talk by a guy named Terry Sienkowski, who's kind of a grand old man of AI.
*  He's been on the show. Yeah.
*  Yeah. He's awesome.
*  And he was giving a talk at Caltech about using these new back propagation networks to generate synthesized speech.
*  Oh, yeah. His talk net. I don't remember what it's called.
*  Talk. Yeah.
*  Yeah. So that was that was, you know, the moment, you know, in the Caltech auditorium where he plays it.
*  And the holy crap moment for me was, you know, not so much that he's talking about the architecture and that it can perform this well.
*  But there is a moment where, you know, he as the he would play the learning algorithm, you know, he would play the speech output of the synthesizer at each stage of the learning.
*  Right. Oh, yeah. And it was fantastic because it mimicked exactly the sequence of nonsense sounds that babies make when they're learning to speak.
*  And that was the moment like, oh, my God, that's got to be it. Yeah.
*  It's just too close. And, you know, that was the you know, I didn't sleep for like three or four nights and, you know, went home and hacked a simulator to do this and and and see, you know, what else I could apply it to.
*  And I happen to be working on this problem of, you know, figuring out where to point the spacecraft in the instruments.
*  And that's how I ended up developing that technology.
*  And so, you know, it turned out that, you know, the traditional mechanism for, you know, doing that attitude determination task of figuring out how to point the spacecraft used to take 22 kilograms of equipment and about 500 kilobytes of of storage for the star pattern catalog.
*  That would figure out where you were.
*  And I replaced it with like four grams of a single chip sensor and, you know, 4K of memory.
*  You saved millions.
*  So so that that was kind of a watershed moment where people were like, huh, maybe it is useful.
*  So cool. It's come a long way since then as well.
*  You know, in that in that era, I'll confess to, you know, contributing to the AI winter myself, because, you know, I worked in the in the Neural Science Group for a while.
*  And I kind of came to the conclusion that with the capabilities of the computers we had back then, you know, we jokingly used to say kind of, well, I'd say half jokingly really that these neural networks, they were very cool, but they were kind of the second best solution to any problem.
*  You really worked on customizing something with, you know, extreme bit twiddling and limited design of hardware, you know, custom architectures, you could do a little bit better.
*  But that, of course, has changed now, you know, with the explosion and data, the, you know, exponential increases in processing power, you know, those Fitbit, you know, powered, you know, satellites, basically, they weren't they were not really representative of what what the technologies could do.
*  Yeah. Well, I know that you're all in on neuroscience these days, contributing to AI.
*  Absolutely.
*  Yes.
*  I mean, so I mean, it's kind of interesting because there's an argument to be made that AI doesn't need neuroscience, right? So this is you just mentioned that, you know, you could do better with what we had then, better than neural networks, right? If you do kind of tweak things, and you could scrap a few things together, and you could outperform the neural networks and, and very few people, let's say, I won't say no one, but really foresaw the success of what's now known as deep learning.
*  And I know that it's not the end all deep learning, but it was things are just hard to predict how they're going to turn out.
*  Well, I don't know. There were a few of the early acolytes, you know, the three guys that recently got the Turing Award.
*  I know. And Terry was one too. Yeah, Terry's been always been a pusher of the of the networks. No, I mean, and the need for incorporating like the neuro inspired technology into it as well.
*  Yes.
*  But but so so how much neuroscience do you think that AI really needs to push forward?
*  Well, I think that, you know, there's there's productive paths, both with and without neuroscience. And, and I think part of what you have to look at are what what problems are you trying to solve?
*  I often lament, you know, how much effort goes into deep learning, where, you know, there's a, you know, you can spend an infinity of time, you know, worrying about your numerical algorithm optimization, you know, so you don't get trapped in local minima, and you have annealing.
*  And, you know, there's all these kinds of techniques to, you know, increase the training rate and one shot learning and so on.
*  So there's, there's an explosion of those things from a kind of mechanistic and operational perspective. And, and I think that those are important to industrialize the use of the algorithm.
*  So I don't want to diminish or, you know, talk down for efforts to develop that.
*  And, you know, if you look at the way they're being used at scale in industry, they're clearly using it to do things people care about, you know, and they're now being built into the phones and all the photo apps.
*  So you're seeing an explosion of how to use it.
*  But the most exciting opportunities to me are the ones where we create not kind of incremental improvements in numerical or computational efficiency, but the ones where we create a transformative new ability that the system didn't have before.
*  One of the problems that is kind of inherent in the kind of deep learning algorithms at scale is, I'd say, the combinatorial explosion of complexity.
*  When you try to incorporate, you know, multiple problem domains, multiple, you know, data representations and formats, gross disparities in challenge, a couple different domains and ways.
*  So let me give you an example.
*  So a narrow problem that is tractable is one where you've got a single domain and you're solving a very specific problem in it.
*  So you're looking for faces in photos.
*  Yep.
*  Those now we've nailed and, you know, they're getting better every year and there's, you know, better hardware to do it more efficiently with lower power and so on.
*  So that's we're on we're on that development train.
*  But if you say, can you successfully identify sex traffickers, you know, from their facial images?
*  Yeah.
*  Okay.
*  That's a different type of question.
*  Now you're into ethics.
*  Now you're into privacy.
*  Now you're into emotional detection, ideas of abstraction of what represents an emotion.
*  Can you from an images of two different people near each other?
*  Can you infer the relationship between them?
*  Is one the sex trafficking victim and the other the perpetrator or is it a father and daughter?
*  So, you know, those are things that a trained person can actually detect.
*  And, you know, I've actually been approached to think about, you know, could we begin to solve some of those problems and be able to see that in an automated way.
*  But those types of challenges where you're taking, you know, social contracts, individual emotions, legal requirements, privacy protection, you know, you're starting you're starting to make bigger problems that are much more complicated.
*  And we haven't even talked about, you know, asking ethics based questions, which are even more kind of abstract.
*  So I think building systems to solve those more complicated system, those more complicated challenges, that's where I think the real transformative opportunities lie.
*  With incorporating neuroscientific knowledge into it?
*  Yes. Well, because we know that humans can do it.
*  We have examples.
*  We have proof by example.
*  That's right.
*  Sure.
*  And so then then the question becomes, well, all right, what what cognitive armamentarium do you have that you've employed in your head to solve these more integrated, more sensory fusion, more complicated, multi-domain problems?
*  And, you know, the way we talk about it within Brainworx is, well, you know, clearly we haven't built the parts of your brain yet that represent your biological ability to do that.
*  Right.
*  All we need is cortex.
*  Right.
*  That's all we need.
*  Well, you know, we need more of that.
*  You know, we need we need parts of the lizard brain, too.
*  You know, we need your emotions.
*  We need your representation of fear and harm and benefit and all these abstractions that that are so integral to everything that we do and detect and see and and have empathy for that are that are central to our decision making.
*  So the, you know, the longer term vision for AIs to build artificial general intelligence, let's say that's a main one, let's say.
*  And given that we don't agree on the definition of intelligence, or very few people seem to have the same definition or the full story of what even makes us intelligent.
*  How will we know when we've built general AI?
*  Well, I'm not a big believer in this cataclysmic transformation for one moment.
*  We haven't invented it.
*  And then, oh, smokes.
*  And then we have artificial general intelligence.
*  Look out.
*  Yeah.
*  I don't I don't see that sort of evolution.
*  You know, a lot of people say, are we going to are we headed for a robo apocalypse?
*  I don't I don't think so.
*  I'm not I'm not following down the Elon Musk path in that in that regard.
*  As a quick tangent, you know, back in the 80s, when you're working with neural nets, or, you know, even in the 90s, with the connectionism sort of rise, people didn't seem to have these same concerns or they weren't as vocal about it anyway.
*  No, I think I think there's a couple of things that are feeding it.
*  You know, one is this notion that this idea of exponential technologies, when you hit the curve in the exponent, boy, they really advance quickly.
*  Yeah.
*  And I think that that's that's a great kind of general philosophy, but it but it leaves out kind of some of the bigger system complexity issues.
*  And if you look at the way science is advancing in the field, it's not like there's a general aspect of all intelligence and there's one solution that satisfies all of it.
*  Right.
*  You know, the way it seems to be progressing is, you know, we're kind of looking at, well, gee, how does the how does the brain handle, you know, binocular convergence of, you know, integrating your two inputs to figure out depths?
*  Okay, yeah.
*  You know, so we we figured out that circuit.
*  That one's gonna that one's gonna become conscious and take over the world, I believe.
*  Well, the point is, you know, that's that's one circuit among hundreds of thousands.
*  And and so, you know, we've now checked that one off.
*  And and, you know, DARPA has made huge strides in that way where, you know, we're looking at, you know, doing memory integration in RAM and sensory feedback in haptics and, you know, sensory input to the to the visual and auditory cortex in NESD.
*  Yeah.
*  So each program is, you know, you know, working on one portion of the brain.
*  And and the way it's happening in kind of the brain machine interface world is, as we figure that one circuit out of the brain and what the coding is and what the architecture and the data representation and the histology, then we can, you know, for someone that has had that part injured or removed or, you know, absent through genetic defect, we can now put a machine in to replicate the function of that missing piece.
*  But that's just a tiny piece.
*  So what we're doing is, you know, step by step, we're building more and more of the components.
*  You know, is there going to come a day where we connect up enough of them that it begins to, you know, seem more alive?
*  Yeah.
*  Yeah, bit by bit.
*  But I don't think it's going to sneak up on us.
*  Yeah, I don't know.
*  My dad just talking to the the navigator in the car back when there were those little navigators.
*  You didn't use your phone.
*  You know, he talked to the woman and it's embarrassing.
*  But it's like it doesn't take much for us to anthropomorphize machines.
*  I suppose.
*  No, no.
*  And, you know, there's there's a lot of cases these days where that's a good thing, because, you know, for example, there have been some interesting studies where like suicide hotlines and drug treatment hotlines, people will tell an automated bot way more than they'll tell another person.
*  Yeah, that's weird.
*  You know, they don't they don't they're not ashamed to talk to a robot where they would suffer some social damage if they if they opened up to a person and made themselves vulnerable.
*  And that information is useful to someone who's trying to treat them.
*  So, you know, there's kind of an interesting open question of, you know, when we start to build these digital companions that are more lifelike for people that don't have another companion to treat them, it's certainly better than nothing.
*  But, you know, how can we make it so that it's really beneficial?
*  A huge part of your history is working with the brain machine interfaces and developing that work in DARPA.
*  So I'm curious what you, you know, given given your work in DARPA, what do you think of the first of all, what do you think of like the Neuralink efforts or progress or hype train really because of a certain name that's associated with it, like, which is appalling to me, especially given the I don't know if you watched the presentation that was given in Neuralink.
*  And it was God awful.
*  But but because because it's Elon Musk, like it's they've now invented brain machine interfaces, it seems.
*  So I don't know. That's that's kind of setting you up.
*  But what do you think about that?
*  Well, I first off, you know, I think, you know, Neuralink, Colonel, you know, Brian Johnson's effort, the Facebook mental typewriter, you know, they all came about because of our work at DARPA to catalyze that industry.
*  And, you know, when when when I came to DARPA in 2014, there was kind of a stalled program that had had had done the, you know, the prosthetic control, you know, for the motor cortex to control the robot arm for the quadriplegic patients.
*  But, you know, it never advanced beyond the technology demonstration phase and, you know, had been stalled for several years in terms of what sort of bandwidth could you deliver in and out of the brain and, you know, what sort of interfaces could you imagine building?
*  And so, you know, my goal in coming to DARPA in that in that era was, you know, to apply really the latest technologies in all the different fields and bring them together.
*  Because, you know, what we found was, you know, even those early tech tech demos with the prosthetic control that was so revolutionary, and I want to I don't want to downplay it because those those early demonstrations of, you know, plugging the wires into the into the cortex of the quadriplegic patient, Jeff Ling, you know, that created that program.
*  You know, that was a watershed moment where we opened the door for the first time to the fact that, yes, it's possible to control something electronic with your brain directly.
*  And then they went on to, you know, wire up to a 35 flight simulator and have her, you know, become the plane with her mental capacity.
*  It's just mind boggling. So so don't don't take this as a criticism.
*  It's just that, you know, DARPA up until that point had really been focused on getting to that technology demo and then, you know, would often lament about, you know, this idea of the the kind of the valley of death between, you know, that tech demo and the commercialization.
*  Right.
*  And then and that technology had completely stalled.
*  And, you know, one of the one of the reasons, you know, one of the reasons for that was, you know, that just wasn't where they applied the money.
*  There was no industrialization or productization in the budget.
*  It was just show us that it's possible.
*  And when we looked at those prototypes, they were using like 1980s class electronics that they could get through the FDA quickly.
*  And so it was almost like stone knives and bare skins were there shoving things into the brain.
*  And, you know, I just would cringe that, you know, that's never going to get into a healthy person that that isn't already quadriplegic.
*  Right.
*  So so I think that, you know, my goal in coming to DARPA was, you know, take the latest photonics, take the very latest computer science, take the latest, you know, advanced node CMOS semiconductors that are really tiny.
*  And really power efficient.
*  Take the latest wireless data transmission algorithms, take the latest neuroscience models and integrate them in a system that could be kind of a platform for future development of the interfaces.
*  And, you know, when I when I got there, what I found was, you know, 10 different industries that had never spent any time in the same room together, and they weren't even aware of the level of capabilities.
*  And so, you know, the first role we played really was as kind of assembling the ecosystem and making all the key technology and science components aware that they had each individually reached a state that together, if they collaborated, they could make these things happen.
*  And it was it was fascinating.
*  You know, and we joked within DARPA that, you know, if you if you start a new program and you don't invent the Internet or something equivalent, you get a B.
*  And so, you know, we're we're you know, all the program managers there are really pushed to be very aggressive in the tech development goals.
*  And when we published our initial goals, you know, we went through a really in depth analysis from first principles of, you know, what is the energy of the transduction capability in the neuron?
*  You know, how much energy would you have to transfer to make a neuron fire?
*  You know, what is the efficiency of a transistor in a circuit, you know, in the latest technology?
*  Can we relay how much light with different photonic circuits?
*  You know, how efficient are semiconductor lasers?
*  So we went through all of that and we made some targets where we said, you know, we think it should be physically possible to build an interface that would talk to a million neurons in parallel.
*  Now, you know, keep in mind that the latest technology at that point was a hundred wires.
*  The Utah Ray?
*  That's right. That's right.
*  And he showed up and said, no, we think should be able to get to a million and we're going to fund it and we're going to put, you know, sixty million dollars behind it.
*  But we're going to require that you assemble teams with the top talent in each one of these areas.
*  And when we made that that call for proposals, you know, I would say ninety five percent of the people responded.
*  You don't really believe you can do that, do you?
*  I mean, you're going to give us the money.
*  I mean, we'll say we can do it, but you don't really think we can do it.
*  That's a good sign. That's a good sign, though.
*  Well, you know, and the interesting part was, you know, we began hosting workshops and seminars where I would stand in front of the room and say, look, you know, I've met with all of you and, you know, I have to protect each of your independent trade secrets and intellectual property.
*  So I can't tell you.
*  You know what I've learned from each of you in turn, but what I can tell you is that if you look at each segment of the problem, you know, the Seymour circuitry, the telemetry, the power delivery, the neural interface, the genetic programming, et cetera, et cetera, et cetera.
*  You know, in each one of those areas, some of you have demonstrated state of the art capabilities sufficient to reach this scale.
*  But none of you have been talking to each other.
*  And if you but, you know, assemble the teams to make it possible, you should be able to do wondrous things.
*  So we ended up finding six different groups after going through the whole proposal process.
*  And they have done astounding things, some of which I think are quite far ahead of what was demonstrated in the in the recent Neural Link presentation.
*  Yeah.
*  So some of that's not public yet, so I can't really talk too much about it.
*  But, you know, when when Elon did the presentation, I congratulated him on the press because, you know, clearly I want to see them succeed.
*  I'm very glad that Elon and Brian and Facebook and GlaxoSmithKline and Google and all of them, they're in the industry.
*  They're investing in it.
*  They're putting money behind it.
*  They're hiring teams, you know, many of which were plucked from our government funded programs.
*  And they're using base technology that came out of the DARPA funded efforts in many cases.
*  And so, you know, I think that we very much want to see Elon succeed.
*  And yeah, there's hype, I think, in some of the press.
*  But they're making important advances.
*  And I think that the industry is absolutely going to be one of the most impactful in our history and is worthy of attention and investment.
*  I'd love to see more excitement and support industrially for it.
*  So there's there's building something and there's understanding something.
*  I'm wondering what the right balance is there.
*  And I'm wondering, this is an awful question, but will brain machine interfaces actually help us understand cognition?
*  How how we go from the hardware?
*  Yeah, go ahead.
*  They're they're already doing it.
*  You know, the beauty of the DARPA work, you know, it was demonstrated, you know, handily, even before, you know, the program around the world.
*  Even before the program around the brain machine interfaces that I began had started.
*  So just by hosting those workshops and getting the people to start collaborating that had never talked across those interdisciplinary boundaries before,
*  even before we had funded the program, we had two groups that were able to transduce more than a million neurons in parallel on the on the sensory.
*  They haven't integrated it into it in a miniature implantable device yet.
*  They were doing it with benchtop machinery.
*  But but once people realized that it was possible, you know, then the whole thing really accelerated.
*  So, you know, and this isn't just to interface, you know, because really to interface, you need to understand from an engineering perspective, you know, what's the code?
*  How is data represented?
*  You know, how can I, you know, with starting with an MPEG movie, how can I translate that into a pattern of impulses that I impose on the visual cortex so that you perceive that movie as if you're seeing it with your eyes?
*  Right.
*  And so, you know, that that's a really tricky technical problem that that that has a lot of, you know, fundamental biology in it that you can't really do one without the other.
*  So I think that kind of the brain machine interface and the advanced and cognitive science are going to go hand in hand.
*  I hope so. So I know you're just about out of time.
*  I just have a few quick broad questions if you can answer them.
*  I wanted to dive deeper into consciousness, but I'll just ask you this.
*  When will we build consciousness?
*  Well, that's a great question.
*  I think part of it depends on your definition of consciousness.
*  Yeah, of course.
*  You know, there are, you know, any any medical student will give you like three or four different aspects of consciousness.
*  So from, you know, self-awareness to, you know, subjective experience about how awake and aware are you?
*  Can you attend to things?
*  Can you remember, you know, you can.
*  And I think that but there's one there's one fundamental aspect that I think has been unsung for quite some time.
*  And it is really whether or not you can predict a future event.
*  And I think that your level of consciousness is fundamentally tied to the level of complexity of what you can predict.
*  And so I gave a talk not too long ago where one of the questions at the end of the talk is, well, you know, bacteria, you know, in the ocean or plankton in the ocean seem to be able to predict when the sun's going to come up and swim to the top to get light shine.
*  Yeah.
*  Are they consciousness in that sense?
*  And I said, well, in terms of rudimentary prediction, I would say, yes, that's rudimentary consciousness.
*  You know, and if you look at the predictive capabilities of the human brain versus the predictive abilities of your dog, you know, is your dog conscious?
*  I believe the dog is conscious.
*  My dog is not conscious, but that's OK.
*  Well, I can tell you, my dog is definitely, you know, exhibiting signs of consciousness.
*  I don't know if you've ever seen that.
*  There's a there's a great series of YouTube videos where you can see kind of the dog's development of object permanence.
*  And you as a person kind of go together where you kind of stand behind the towel and let it drop as you duck off to the side behind a door or something.
*  And you can absolutely see the dog's expectations violated and surprised.
*  Oh, yeah.
*  And so, you know, these are systems where they were clearly predicting something that didn't happen.
*  And now they're attending to the difference.
*  And I think those sorts of things really are fundamental in consciousness and our capabilities.
*  We can absolutely build into machines.
*  And I think, you know, whether they're conscious or not, I think is going to be, you know, an ongoing debate as we incrementally improve it.
*  But every year, these things are going to be behaving more and more like real people do.
*  And the difference is going to be harder to distinguish as we go.
*  Was Marvin Minsky a good thesis advisor?
*  Oh, he was great.
*  He was he was he was one of those.
*  He was one of those.
*  You know, it's like he's one of those people that had, you know, a legacy of advisees who had advisees.
*  Yeah.
*  So I was I was directly advised by Marvin.
*  And then I was also advised by Tom Knight, who was also a student of Marvin's.
*  And I was advised by Jerry Sussman, who was a student of Marvin.
*  Yes.
*  The Marvin and Jerry.
*  It's like the generational advancements of of access to kind of, you know, how do you think innovative thoughts and create new stuff that has impact?
*  It's you know, you spend time in the company of those people and you can't stop thinking about those things.
*  Oh, it's great. It's great to spend time with good people.
*  That's one of the reasons I do the show.
*  What is what's something that you used to believe that you now consider naive?
*  Well, I used to believe that, you know, if you would have asked me, say, even five years ago, how long my children would live.
*  OK, I probably would have said, you know, maybe to 90.
*  But I don't believe that anymore.
*  Now what now? What do you believe?
*  I think they'll be in the 130 to 150 range.
*  Man, that's going to be.
*  Are you going to be around to see it?
*  I hope so.
*  But I think I may have missed the window.
*  I don't know.
*  Oh, man, that's a great that's a great place to end it.
*  So, I mean, I have so many more questions, but I really appreciate you answered a bunch of my questions.
*  So I really appreciate your time.
*  I wish you much success moving forward with Brainworx.
*  And of course, Philip, don't be evil.
*  And thanks. Thanks for your time, Philip.
*  No, my pleasure.
*  And, you know, if I can help out in the future, please reach out.
*  All right.
*  And those people looking for academic advice, you know, just find me on on Twitter or LinkedIn.
*  I'm happy to respond.
*  Yeah, you are at Alvelda on Twitter and I'll link to it in the show notes as well.
*  All right. Thanks.
*  Thanks, everyone.
*  Brain Inspired is a production of me and you.
*  You can support the show through Patreon for a microscopic two or four dollars per month.
*  Go to BrainInspired.co and find the red Patreon button there.
*  Your contribution will help sustain and improve the show and prohibit any annoying advertisements like you hear on other shows.
*  To get in touch with me, email Paul at BrainInspired.co.
*  The music you hear is by The New Year.
*  Find them at TheNewYear.net.
*  Thanks for your support. See you next time.
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
*  I'm
