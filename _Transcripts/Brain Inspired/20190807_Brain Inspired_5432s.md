---
Date Generated: April 21, 2024
Transcription Model: whisper medium 20231117
Length: 5432s
Video Keywords: ['Science & Medicine', 'Technology', 'Education']
Video Views: 8613
Video Rating: None
---

# BI 043 Anna Schapiro: Learning in Hippocampus and Cortex
**Brain Inspired:** [August 07, 2019](https://www.youtube.com/watch?v=i0krQJHz6uI)
*  We don't even understand how we can understand the universe.
*  We don't even understand how we can perceive that.
*  We have to start there.
*  That's the most fundamental question.
*  What are we?
*  How are we even thinking about these things?
*  I love meetings.
*  We'll see if I say the same thing.
*  I know.
*  We'll see if I say the same thing in a year.
*  But I love talking to people about ideas.
*  This is Brain Inspired.
*  I love talking with people about ideas.
*  I should have that person on my show.
*  Wait, I did.
*  She's my guest today.
*  She's Anna Shapiro.
*  And she's the principal investigator in her PIN, Computational Cognitive Neuroscience Lab,
*  at the University of Pennsylvania,
*  where she and her team ask the question,
*  how do we get into our heads the knowledge that's out in the world,
*  in ways that are actually useful to us?
*  Turns out there are lots of different ways and time courses that our brains use to encode that information.
*  So we can do things like learn something in just one take,
*  as in, I will not walk under that tree full of birds while looking up with my mouth open.
*  Or we can learn things over time, as in,
*  all right, I've had that grocery store version of sushi, oh, ten times now.
*  I think it's time to move on.
*  So on today's show, Anna and I talk about the complementary learning systems framework,
*  which addresses these different types of learning,
*  and which I had wanted to discuss when I had Jay McClelland on the show,
*  but we didn't have time that day.
*  So it was great to talk about it with Anna, who actually was in Jay's lab as an undergraduate.
*  And some of you expressed a little disappointment that Jay and I didn't get to talk about the complementary learning system when he was on,
*  so I hope this makes you happy.
*  Then we get into Anna's work that builds on that framework
*  and proposes additions to fill in some gaps to the original theory, which was proposed in 1995.
*  And we discuss the connectionist model of the hippocampus that she uses to test her hypotheses.
*  We talk about how her work might contribute to AI systems in terms of using different types of memory buffers for learning,
*  and her somewhat more recent push to study how these processes occur during sleep and our sleep cycles.
*  There is plenty to chew on today, and you can find links to it all in the show notes
*  at braininspired.co.uk, slash podcast slash 43.
*  You can also go to braininspired.co.uk to support this little engine on Patreon.
*  Any support is greatly appreciated if you value what I do here, and it costs extremely little, actually.
*  I am loving what I am doing, as you will hear Anna point out.
*  In many ways, what I'm doing is just the perfect amount of stimulation for someone like me.
*  Of course, I'm always hoping to make it better and better for you guys.
*  I hope that you love what you do, and I hope that you enjoy as much as I did my conversation with Anna.
*  All right, Anna, thanks for being here and welcome to the show.
*  Thanks so much for having me.
*  So it probably doesn't feel like it to you, but I understand you just started your new lab at the University of Pennsylvania,
*  which can be found at ShapiroLab.org. So congrats, maybe a delayed congrats.
*  Thank you so much. No, it does feel like I just started.
*  I just showed up a month ago. Was it a month ago? Yeah, yeah.
*  Although the website already looks great. So you're ahead of the curve, I suppose.
*  Well, I deferred a whole year. So I got the job over a year ago, and then I had time to set up my website and stuff.
*  And then I actually started sitting here June 1st. Oh, wow.
*  So then it is a real real timely congrats then.
*  So I remember seeing in the halls of Vanderbilt during my postdoc,
*  I remember seeing new professors literally running down the halls and up and down stairs,
*  you know, to get to the next class that they're going to teach or their next meeting, you know,
*  beads of sweat pouring forth and such. So are you running around these days?
*  What's going on? Well, the summer is not as bad as I expect the school year will be.
*  I am teaching in the fall, so I think things will get a lot more hectic.
*  And I'm kind of ramping up slowly. Like I have two people in my lab right now.
*  And then I have another three people showing up kind of slowly over the next couple of months.
*  So things feel somewhat under control. And then I'm sure they will feel less and less under control.
*  I'll check. I'll check back with you in a couple of months. See how it's going.
*  See how many pounds you've lost or something, you know. Yeah.
*  So how is it going then? Like it's a nice slow ramp up right now. Are you getting things?
*  I'm actually I'm genuinely curious, you know, am I missing out by not pursuing a faculty position?
*  And I'm living a little bit vicariously through you, I suppose, to really wonder.
*  I think in some ways you're doing the best thing.
*  Like you are doing and you are like having interesting conversations with people.
*  You know, you choose the people you want to talk to.
*  And well, actually, I don't even know what you do with the rest of your time.
*  What you're doing with this podcast seems like the height of the kind of intellectual stimulation that we want to get out of these jobs anyway.
*  So I think you're getting it. But I feel so lucky. I totally love this.
*  I feel like it's a huge honor to have this job. And it's really fun.
*  And bringing together a group of people who I mean, so far seem totally amazing.
*  I think they are totally amazing. And getting to and getting to just think about whatever exciting ideas we want to pursue.
*  It's an amazing kind of freedom and ability to be creative.
*  And yeah, I'm totally enjoying it and excited about it.
*  I think that's the you're right, by the way, that I'm loving what I'm doing because I do.
*  I just seek out people that I want to talk to and get to talk to them if they say yes.
*  And it's it's just great because it really does stimulate me.
*  And that's something that I was missing, actually, because I got so specialized and you get such tunnel vision on potentially what you're doing, especially in the monkey world.
*  And I won't go into it. But so I'm my a bit of FOMO on my part is what you just alluded to.
*  And that's the one thing I really think like I could have constructed a lab and you start to get to pursue exactly what you want and ask the questions that you want to ask and and put your lab together.
*  And that seems really exciting, actually. So it is.
*  I'm not I'm not going to lie. It is it is exciting.
*  It is wonderful. I mean, these jobs are hard to get and I do not take it for granted.
*  It's like it's hard in many ways. It's very hard.
*  But yeah, but I wouldn't be doing it if I didn't think it was worth it.
*  But you just you just told me that you had deferred a year.
*  And I know I guess I just had my little two year anniversary of being retired.
*  But when I was a postdoc, everyone was complaining about how hard it was to get jobs in the computational neuroscience world and in the neurophysiology world, especially.
*  I don't so I can't speak roundly to all fields.
*  But did you find that that was the case? Was it was the job market pretty difficult and tough when you were looking and and and do you have advice for people who are sort of near that point in their careers?
*  Yes, it's incredibly competitive and difficult.
*  Yeah, I mean, I've seen many, many people over the years struggle with with the job market.
*  It's I mean, it's just it's not that many jobs, but I've also seen many, many people be successful on the job market and people who really want these jobs and who have programmatic research that combines things in some novel way.
*  And and if they are really creative and doing great things like for the most part, people do end up getting jobs who kind of keep at it.
*  And they're really want to years on the market. And yeah, I mean, that's been my experience among my kind of my peer group.
*  But that's not to say it's not really, really hard. It is really hard. But I do think that that it's possible.
*  Yeah, just looking back and I'm sorry, I'm asking you so many questions career wise right now.
*  But but looking back to you, do you have advice to sort of early graduate students?
*  And one of the things you just said was to sort of combine elements from different fields.
*  I don't know if you said it exactly like that, but do you think that's a key skill moving forward for people?
*  Yeah, I think it's important. I mean, this is a classic thing people say, but I think it's really true.
*  It's important to not become a copy of your advisor and be and be doing something different.
*  So I was very lucky to be a grad student at Princeton where there's this model of you work with multiple people.
*  You have at least two formal advisors, but often people have more than that.
*  I had three formal advisors who I worked with equally, and that was totally crazy, but also really fun.
*  And I created a program of research that was at the intersection of their interests and something different from what they were doing.
*  And I do think that that was really important for people thinking, you know, feeling like I was my own person and I had my own intellectual identity.
*  So I do think that's something to think about.
*  Yeah, it's kind of a perfect situation. It can be a perfect situation if it's a good because it combines collaboration with synthesis, essentially, if you're the synthesizer, if you can synthesize things.
*  Exactly.
*  Well, cool. So congrats. There's a little bit of me that wishes we traded. We would trade places at least for you can come.
*  You can come sit in my can I boss people around to yes, one day, one day you can come and.
*  And then I won't be invited anymore. OK, so I know one way to describe what you do is to say that you use computational modeling and behavioral studies and neuroimaging to study different ways that we integrate information into our memories and our knowledge base,
*  both while we're awake and while we sleep so as to be useful, so as for that knowledge to be useful in various ways.
*  What is a different, better way to describe what you do?
*  Yeah, I'm interested in how we come to represent all of our knowledge of the world, which involves understanding the initial acquisition of that information.
*  So how do you kind of create the initial memory trace? And then how do you integrate those new memories with your existing understanding of the world and your existing knowledge store?
*  So what is that kind of initial process look like? And what is that integration process look like?
*  And if we can understand those two kinds of processes, then we can kind of understand how you come to build up this understanding of your environment over time.
*  But I would also endorse your description. Great.
*  So we're going to talk about a bunch of your work related to just those things today.
*  I just had Brad Imany on the show and he's at Sandia National Laboratories, but he's sort of a former neuroscientist, although he's still a neuroscientist at heart.
*  And we talked about his work in adult neurogenesis.
*  One thing we talked about was his work in adult neurogenesis in the hippocampus.
*  And we talked about the dentate gyrus as implementing pattern separation to encode these distinct memories.
*  And he is the example of needing to distinguish between a red apple and a green apple.
*  So the red and the green apple have a lot of overlapping apple-like qualities, but you need to encode the specific red or green one, not just apple of some color in your memory, for example.
*  And his work was how new neurons that are coming about in the hippocampus affect and contribute to that process.
*  And I mentioned that it's relevant because we're going to talk about the complementary learning system theory.
*  Is it a theory? Is it a?
*  Yeah, sometimes I use the word framework, but I think theory is good too.
*  Framework is less serious. So theory is very serious.
*  So, OK, so but it was originally put forth by Jay McClellan and Bruce McNaughton and Randall O'Reilly in 1995 to account for some memory effects that occur with damage to the hippocampus, namely that damage to the hippocampus seems to affect recently formed memories or new memories, but maybe not so much older, more ingrained memories.
*  And I actually had Jay McClellan on a couple months ago now, but we didn't even have time to talk about this.
*  So I'm glad they were going to talk about it today.
*  You're going to be Jay for the day and Jay to Anna.
*  He was my undergrad advisor.
*  So I'll try my best to channel him.
*  Yeah, OK, good.
*  I was going to say something, but I'll let it pass.
*  So so but the basic proposal for complementary learning systems framework and you're going to make this better in a second is that the hippocampus and the cortex complement each other when learning the hippocampus is a fast specific example based learning system, whereas the cortex is a slower statistics based learning system.
*  And so you have the hippocampus that quickly encodes these new specific memories like I just mentioned, like a red apple, for instance, that was delicious except for a worm in it or something like that.
*  And over time, while those memories get recalled and used, the cortex sort of receives copies of these memories and and slowly encodes more general aspects associated with the memory like apples are generally OK to eat, for instance.
*  And so there's a lot more to this.
*  And maybe you can better highlight those two functions of memory and fill in anything that I missed there.
*  That sounds perfect to me.
*  I think of it as kind of highlighting that there's this fundamental computational tension between having to you.
*  You want your memory to both be able to like distinguish the red apple and the green apple to remember that you saw the red apple that it wasn't a green apple.
*  And maybe you like red apples and green apples.
*  Maybe it's useful to make that distinction or something.
*  But you also want to be able to allow those memories to make contact with each other in order to understand statistics over time.
*  Like, you know, I don't know what you what kind of statistics you want about apples.
*  Maybe you in general, you like apples relative to some other fruit or something.
*  So there's this idea that in one case you want to keep your memories separate.
*  You want to orthogonalize them.
*  That was the idea of this de jure's pattern separation in order to avoid interference and recall each of those individual memories.
*  But on the other hand, you also want to allow your memories to make contact with each other in order to support these other kind of set of functions that are also really important for memory.
*  So we have these two fundamentally competing functions of our memory.
*  And the idea of this framework is really simple.
*  Just well, maybe we separate them anatomically.
*  Maybe we just do these two different things in two different systems.
*  And so I think that that makes a lot of sense.
*  There's something there's something important about doing these two things in separate neural circuits.
*  And then and then, of course, there's the very important ideas about kind of a temporary storage of information and then a long term store of information.
*  So if you try to write new information directly to your long term store, there's danger of catastrophic interference.
*  And in order to get continual learning, working gracefully, you need to first encode individual memories in a short term store in the campus.
*  And then slowly through interleaved learning offline, integrate those memories into your long term store so that you can you can represent the commonalities across kind of all those those experiences.
*  So, yeah, the analogy I'm trying to think of some sort of metaphor like the hippocampus is this witty, smart, smart person.
*  And in this metaphor, the cortex is kind of dumb, kind of takes a long time to slowly gets it, but it sticks or something.
*  Well, it's interesting because it's right in some ways.
*  It certainly the slowness of it feels that way.
*  But the power of the cortical representation is is that you can generalize to new things.
*  So if you have a representation that respects all of the commonalities across your experiences in this nice integrated ways and distributed representations,
*  then if you see a new thing that is related in some way to the to the kind of understanding that you have, you'll immediately be able to see it's that relationship.
*  And you'll be able to generalize features of the new thing based on what you already understand about the world.
*  So that's the I mean, that's just normal neural network learning, like everything that you typically think of as the power of neural network models for generalization.
*  That's what the cortex of CLS is all about.
*  And then the hippocampus in a way is doing something actually just dumber.
*  And it's just saying, I'm just going to create a totally new pattern for every experience.
*  Like, I'm not going to worry at all about how it's related to what I know about before.
*  Of course, I'm just to be clear, I'm characterizing.
*  This is the cartoon of the CLS.
*  This is not what I actually think is happening in the hippocampus.
*  In the cartoon of the CLS, you every new experience that comes in, you give it a totally orthogonal new new representation.
*  And that's sort of dumb in a way, but but very useful if you're trying to remember the details of your individual experiences.
*  So in the analogy, the metaphor, everyone has their own special, everyone's special and has their own special talents.
*  So there you go.
*  Well, OK, so so this theory, this framework has largely seem to have stood the test of time.
*  Right. So I mean, there have been some recent reviews to revisit it and talk about some updates on how recent research has touched on it.
*  And actually, we'll talk in a second about your recent work, which adds a new twist here.
*  Have there been any major changes to that framework?
*  And what you can consider your own a major change?
*  Right, right. Well, I sort of see my work as filling in gaps more than I see it as making changes.
*  It's funny. It's like in some ways, I feel like every single aspect of the framework is wrong.
*  And in other ways, I think like it's just it is fundamentally right.
*  So I think in the in in the broadest view, I think it's right.
*  It has to be something. I mean, there's something important about this idea of having a temporary store of information that has a different kind of quality to it and then having offline training to your long term system.
*  I mean, I think that that that that that is basically right, although not everybody agrees with that.
*  Certainly. But a lot of the details are really tricky.
*  Like the idea that the hippocampus is only involved temporarily is actually super controversial.
*  And and I think there's strong evidence that for truly episodic memories where you really are pulling back up the details of your experience that actually those memories might always require the hippocampus.
*  So that's so that's a tricky the retrograde gradients in the amnesia literature that that paper was relying on are actually a little bit turn out to be messier than than you might want for that story.
*  Yeah. Even even that old behavior, the behavior of a lot of the patients with damage to the hippocampus, I know a lot of it is getting reinterpreted in various ways with the new theories about how things work.
*  So that's interesting. Exactly.
*  And then there's also issues about cortical learning.
*  So how fast is cortical learning?
*  And it you know, I mean, I think Jay had this nice paper a few years ago where he showed that if information if you're learning new information that's consistent with information that you already have stored in cortex that actually it is possible to learn information quickly in cortex.
*  So that's so that's a nice kind of update because it does seem that cortex can learn quickly in some situations.
*  So that might be one kind of situation.
*  But I think there are probably other kinds of situations where cortex can also learn quickly and there might be a diversity of learning rates within cortex.
*  And so I think that that side of the story is complicated.
*  So anyway, but I think it's been a very useful framework and I think it's basically still right.
*  And I mean, it's it's it's been that this is it's basically the driver of all of my of all of my research questions.
*  So I hope it's I hope it's Jack.
*  Well, you sort of anticipated what I was going to ask.
*  You know, we tend to it helps us learn to binarize things or think of things in dual aspect frameworks, you know, the yin and the yang or whatever.
*  But things aren't that clean ever.
*  Right. So so why two learning systems instead of an you know, it's more of a gradient.
*  A hundred or a thousand.
*  Yes, this is a point that I that I've been thinking about making more explicitly.
*  I think different people have have thought about this.
*  I know Jay has thought about this, too, actually.
*  Yes, I think it's it's probably gradients.
*  So so within I mean, I guess we'll get to the to the model that I propose for the hippocampus.
*  But I think that there's actually anatomical and functional heterogeneity within the hippocampus.
*  There's there's the there's the part of the hippocampus that we think of as being the really that dent a gyrus part that you mentioned earlier.
*  That's the part when we think of the hippocampus, we really think about that part.
*  But there's other parts of the hippocampus that I think have less extreme pattern separation and maybe a little bit of a slower learning rate.
*  And then I think if you back outside of the hippocampus to MTL cortex, you get even slower learning.
*  Like there's learning and entrono cortex on the time scale of like days, maybe as opposed to like minutes and hours.
*  And those representations might be even more overlapping.
*  And then there's these beautiful studies, monkey physiology studies from the me ashtag group showing that there's this kind of gradient in the high level visual stream from IT from perinatal cortex to IT where you get responses first, you know, evidence of learning first showing up in perinatal cortex.
*  It'll get kind of reinstated down further into IT.
*  But but you don't get the kind of local learning happening in IT for longer.
*  So there's so I do think and then, you know, you don't really want to be messing with your like early visual cortex representations very often.
*  Those should be learning very slowly.
*  So I think it makes sense that there's that there might be a gradient of learning rates and maybe a gradient of kind of the quality of representations.
*  And then it's a very interesting question whether whether you get consolidation that kind of follows the gradient.
*  Like, are you getting the higher order areas teaching the next layer down kind of in order?
*  I think something like that.
*  It must be must be true.
*  But I think it's still useful to think about these properties in the binary form.
*  But then eventually, I think when we fully cash out this perspective, I think it's going to end up looking more like a gradient.
*  Yeah, I mean, it's almost like approaching it from a sort of the higher level computational level approach that you sort of do need these two at least two ways of approaching it for exactly what you're just talking about.
*  OK, well, let's get into it then.
*  So you have this paper.
*  I'm going to read the title.
*  It's a long title, but complementary learning systems within the hippocampus, a neural network modeling approach to reconciling episodic memory with statistical learning.
*  OK, so.
*  So what is missing in the complementary learning systems that that you were testing here?
*  Right.
*  So the complementary learning systems approach explained how we could quickly learn episodes and how we could slowly learn statistics.
*  It turns out that we are very good at quickly learning statistics so we can pick up on regularities in our environment on the time scale of seconds, minutes, hours.
*  And that is just not a time scale that was addressed in that framework.
*  So that that framework was like cortex is learning on the time scale of maybe days, more like weeks, months, years.
*  And so it's just missing this like very important type of learning.
*  I think in some ways, like the most important type of learning, which is that we can pick up on patterns and regularities in our environment very quickly.
*  I mean, you can like go into a new building and navigate around for an hour and you kind of have an idea of how to get from place to place.
*  Like there's that that's not about storing individual separate episodes.
*  Like you have to see how all the different times you came into the room from different angles, like you have to be able to integrate those those experiences over time.
*  And so we wanted to try to think about how the hippocampus with its known properties and circuitry might be able to support that very different kind of learning.
*  I mean, I said there's this fundamental tension between encoding episodes and encoding statistics.
*  So how could one area be doing both?
*  And I should say that we have empirical evidence that the hippocampus does this kind of learning.
*  Right. So we have there's we have this paradigm we use.
*  It's the paradigm is called statistical learning, which is really way too general.
*  But it often refers to a very specific kind of paradigm where you see a continuous stream of images or you hear a continuous stream of syllables or tones or something.
*  And you are able to cut after this exposure could be passive exposure.
*  It could be totally, you know, often these tasks, you have some kind of cover task or you're not you're not being told that there's any structure.
*  But afterwards, people are able to identify the kind of structure that was in these streams.
*  It can be very simple. Like there can be, for example, three pairs of items that will always occur together in the stream.
*  So two items from a pair will always occur back to back. But but then the order of the pairs is random.
*  OK, and people often won't notice these things as they're as they're watching these kinds of sequences or hearing them.
*  But afterwards, they're able to identify the structure.
*  They can they can tell you, you know, which things went together in the sequence.
*  We are natural pattern completers, I suppose.
*  Yeah. Seekers. Yeah, that's right. So this is I mean, I'm setting this up in this in this way.
*  Talking about like unconscious, like automatic, partly because that's like the opposite of what you would think the hippocampus would be doing.
*  Like the hippocampus is like traditionally about declarative, explicit, overt memory for individual episodes.
*  And this is this is the opposite. This is like you have to integrate information over time in order to see these regularities.
*  It's not any one like individual snapshot isn't going to help you.
*  And you can do this totally automatically and potentially outside of awareness.
*  So anyway, we find in our fMRI experiments that the hippocampus is sensitive to these kinds of regularities.
*  It'll have representations of these items that reflect the other items that that were that were seen with it in the sequence.
*  So there is empirical reason to think that the hippocampus is responsible for this kind of learning.
*  And then the question is, how how do you reconcile that with what we know about the hippocampus specializing and keeping every experience separate to avoid interference?
*  That's the opposite thing. How do you do both those things in one system?
*  Right. So, OK, well, cutting to the chase, then you examine two pathways in hippocampus, right?
*  So the and I'll just let you sort of take over, I suppose, to talk about how the different pathways in different areas in the hippocampus could potentially do this.
*  But before you start that, I'm curious, thinking about that, you know, learning regular statistical patterns quickly.
*  And I mean, so traditionally we think of people with hippocampal damage when assessing these things and figuring out how the hippocampus relates to different behaviors and cognition.
*  Have people I'm sorry, I'm just totally naive.
*  Have people with this really clear episodic memory that what were you doing September 25th, 1974, and they can place it themselves in the building, walking down a hallway or whatever.
*  Have they been studied in scanners and stuff and stuff with these sorts of?
*  Yes. Yeah. OK. Well, with which sorts of tasks?
*  So they've been studied. So these are the highly superior autobiographical memory.
*  I think that's OK. People. Yeah. Yes. These people have been scanned.
*  There's a group at Irvine that's that's doing that. I think they.
*  You know what? I don't know this literature well enough, so I don't want to say anything that's not true.
*  But I'll come on. Come on.
*  Check me. But I think that the the Dente Gyrus area, like their volume or activity and the kind of part of the hippocampus that you would think would be responsible for this kind of memory is, you know, is lighter.
*  Yeah, something. OK. I might have hallucinated that.
*  I think I think that they're definitely doing these studies and that's that's that's what you would expect if if our understanding is right about these systems.
*  Yeah. Well, I just because you had mentioned about being in a building, for instance, and you don't want to only have specific episodic memories you want to or or like really long term.
*  You don't want to take a year to learn the layout of the building and you don't want to have to memorize it anew every time. Right. As if it's a new.
*  So but so that made me think, OK, there are people who do actually have it as if it's a new every time because they can recall it perfectly.
*  So we won't go down that road, but it just made me wonder if those.
*  Well, your question made me wonder whether it would be interesting to take these people and see whether they are good at this other kind of paradigm that I was talking about or not.
*  Right. Like, is there is there a trade off there?
*  If you're really good at remembering these individual things, are you maybe less good at this kind of automatic like extraction of of regularities, which I think is a very interesting question that we don't know the answer to.
*  You're welcome. All right. So, OK, so sorry. Sorry for the diversion.
*  Dear recent Patreon supporters, Deborah, Vaino, Matt, Rex and Harry, thank you guys so much.
*  And all you other generous supporters as well. Guys, I am creating stuff to share with you.
*  I mean, beyond the podcast, which is a ton of time and effort, but I'm making other things.
*  It is a slow labor of love. But because you support the show, as I create these things, I will be sharing them with you as a way to really say thank you.
*  OK, back to the show. Back to the so the let's talk about these pathways that you're that you're examining to test this.
*  Yes. So the so we've talked about this one pathway already.
*  This the pathway that includes the dentate gyrus, I call it the trisynaptic pathway.
*  I read the world calls it the trisynaptic pathway.
*  It runs from entorhinal cortex to dentate gyrus to see a three to see a one.
*  That doesn't matter. The point is that this pathway has a couple of properties that are important.
*  One property is that it seems to be doing this like orthogonalization function.
*  So some people think that the neurogenesis that's happening is helping to kind of take new input and project it to totally different groups of neurons and in this pathway.
*  So this idea that that you're orthogonalizing things in this pathway is really important.
*  And then also you can have very fast learning. So you can have one experience and have and have lasting synaptic changes in this pathway.
*  So those are the that's one pathway and hippocampus.
*  And often when people talk about the properties that campus, they're thinking about this pathway has these very specialized properties.
*  But then there's also a pathway that runs straight from entorhinal cortex, the same input to area one.
*  So instead of doing that detour along the trisynaptic pathway, it's this monosynaptic pathway straight from entorhinal cortex to see a one.
*  And people have different ideas about what this pathway might do.
*  But it seems to have different properties. It seems to be a little bit more cortex like.
*  So in that sense, maybe it's like a little bit more boring.
*  Like it doesn't have all these specialized things that are happening in the dentate gyrus.
*  But it looks like the representations are less orthogonalized.
*  They're a little bit more cortex like. And the learning might not be quite as fast.
*  But that's really interesting because those are the properties.
*  Those are the kind of dimensions that separated the hippocampus and cortex in the complementary learning systems framework.
*  Right. You do fast learning on separated representations or you do slow learning on more overlapping representations.
*  So we noticed that it's kind of like there's a microcosm of the CLS framework within hippocampus.
*  I mean, we're not talking about as slow learning or as kind of overlapping representations.
*  But there's something kind of cortex like to the monosynaptic pathway.
*  So it could be that what's happening is that there's there's again an anatomical segregation happening.
*  There's still a fundamental computational tension that we have to contend with.
*  And that might require separating things out anatomically.
*  And maybe what's happening is that this episodic encoding is happening in the trisynaptic pathway as we typically think about it.
*  But that this other pathway might be useful for this other type of learning that the hippocampus seems to be doing fractal scaling all the way down.
*  That's the that's the thing.
*  So but but so there happens to be this really cool model of the hippocampus that you got to play with and test out these ideas with.
*  So I guess did Randall O'Reilly develop this hippocampus model?
*  Yeah, that's right. So this model has a long history.
*  So Randy, I think, has been involved since the early days of this hippocampal model.
*  It's like it's a it's a model of like a connection style model of the subfields of the hippocampus and kind of abstracting some of these principles that I'm talking about and making sure they're implemented in the model.
*  And there's been different versions of the model over the years.
*  But it's been very useful for explaining episodic memory phenomena.
*  And there was a recent version of the model developed by Nick Katz and Randy's group where they use a data inspired learning.
*  So the older versions of the model use just heavy and learning, which is, you know, OK, but not super powerful.
*  And they wanted to add an error driven kind of learning component to get this model to have better capacity and better performance.
*  And they're using a contrast between different phases of data, which is also an old idea.
*  People like Mike Haselmaugh have been thinking about for a long time.
*  Anyway, so this new version of the model is really great because in the older versions, that pathway, that monosynaptic pathway that I was talking about had to be just the weights had to be set in advance.
*  So they had to be kind of pre-trained and set. And so nothing was happening in that pathway ever in those old models.
*  Is this because they didn't consider that that part of the part of the brain that could change?
*  Yeah, they were. So maybe there wasn't as much evidence at that point that there was learning happening on this time scale in that pathway.
*  And maybe they just weren't as interested in that pathway.
*  And the main purpose of the pathway in those old models was to serve as a translator between the really sparse,
*  orthogonalized representations in the trisynaptic pathway and the more overlapping representations out in cortex.
*  It's useful to have a kind of intermediate amount of sparsity that like helped do that translation function.
*  So it was kind of helping to do this translation, but it wasn't actually doing any learning.
*  But this newer theta version of the model trains both of these pathways up at the same time online as you're learning.
*  And so that's really exciting because it opens the door to thinking about learning in both of these pathways at the same time.
*  So I took that model and exposed it to sequences, these like continuous sequences of the kind I was talking about earlier,
*  and found that the model could learn it just fine with no changes.
*  So this just this model that was designed to, I mean, it's designed to have properties that mimic the actual properties of the hippy campus.
*  But it was used as a simulation of episodic memory phenomena.
*  Like that's what it was like tuned for.
*  But it does no changes are needed in order to get it to do this totally other kind of learning, statistical learning.
*  And if you kind of interrogate the different pathways and do lesions and look at the detailed time scale of when things are happening,
*  you know, like cycle by cycle on a test trial in the model,
*  you can tell that this monosynaptic pathway is what's really responsible for this like integrating statistics over time,
*  which is makes sense given its properties and the trisynaptic pathway does this other kind of episodic learning.
*  Yeah, it's kind of funny to have had it previously not been plastic available, plasticity available because it's in the hippy campus, you know.
*  Right. Right.
*  But it served a very specific purpose, I suppose.
*  So that's really cool.
*  I didn't realize that you just turned it on and it and it worked without.
*  It was still it was still a lot of work.
*  Well, I don't know.
*  The work in this case is interesting.
*  The work in this case was was not in the model development side of things.
*  It was in the analysis of the model because it's a very complex system with all of these recurrent loops happening in different places and these different like ways of getting through the network.
*  And so analyzing the network was the was the hard part of that that project.
*  So yeah, yeah, yeah.
*  Yeah. So easy, isn't it?
*  So, yeah, I guess the take home then with what you found is that the monosynaptic pathway, basically that CA1 does both things.
*  Right. So it translates between the inter-renal cortex or sorry, between CA3 and cortex.
*  So it does translate that information for the slow slower learning, statistical based learning, but also via the monosynaptic pathway.
*  It does the rapid statistical learning itself.
*  So there's a little cortex inside the hippy hippy campus.
*  Exactly.
*  That's cool.
*  I mean, immediately it makes me wonder.
*  And you mentioned earlier that Jay had published this recently.
*  So I'm not I wasn't aware of this.
*  But so you have hippy campus, right, that can do quick, sparse, non-overlapping learning and rapid statistical learning.
*  So then then you immediately think, oh, cortex.
*  So it's known to do the slow statistical based learning.
*  Can it also then do really fast sort of exemplar based learning?
*  Well, so there was always the idea that it could do slow exemplar learning.
*  So like the cortex will represent any any information that is in the environment.
*  I mean, as a neural network model will like to the extent that things are actually not related to each other and they're like actually all arbitrary cortex will rep and neural network model will represent that structure.
*  So so if you if you keep seeing episodes and the details really matter and, you know, cortex is happy to represent those details as well as the kind of shared structure.
*  But the fast part is trickier.
*  It gets back to this point about needing a temporary store of information.
*  So you have to be really careful about writing information to your final kind of long term store because there's always this issue of creating interference problems.
*  And the way that I think about my kind of update to the to the hippy campus model is that, well, you need a temporary buffer, not just for episodic information, but also for for structured information for statistical information.
*  You wouldn't want to try to write that kind of information quickly to cortex either.
*  So if I had to choose a property that I think is like still really separating these systems, it actually is the time scale of learning.
*  Although with the very important caveat that in situations where you're learning something that's closely related to what you already understand about the world, it is possible to integrate information without interference.
*  I'm very interested in understanding the conditions under which that's possible and how that works.
*  That's kind of an active area in the field.
*  And yeah, well, I was going to ask what's next in this realm for you.
*  Are you pushing this forward with or has it branched off or what are you doing with it?
*  Yeah, I am. Well, I mean, I guess we'll talk about sleep later.
*  Like in some ways, sleep is the next step here.
*  It's like once you've encoded this information in the hippy campus, then what happens?
*  Like how do you I mean, we think about like episodic replay, but is there like this kind of is a different kind of replay for this other kind of information?
*  How does this information end up in cortex?
*  Like what is that learning of structured information over this longer time scale look like?
*  What are the hippocampal cortical dynamics?
*  What's the role of sleep in that process?
*  So that's that's in some ways like the next steps for that that line of work.
*  And that's something I'm actively working on.
*  But I also think there's a lot more work to be done just in thinking about the hippocampus side of things.
*  Understanding I alluded to this earlier, like, do these two systems compete?
*  Do they cooperate?
*  Like that's that's a basic both computational and empirical question that we don't really understand.
*  So how do we like in the often in our experiments, we like either have situations where every every there's like these totally arbitrary things happening.
*  Every new experience is totally separate.
*  We're asking people to remember these things that are not related or there's nothing particularly interesting happening on individual trials.
*  But there's like this really important structure happening over time.
*  So it's kind of unusual to have an experiment that combines these two things.
*  But our life is combining these two things.
*  We always have to remember details while noticing the commonalities across things.
*  So I think a really important direction is to figure out like how do we do these two things at the same time?
*  Like, is there is there control process that says like right now maybe it's more important to think about statistics versus episodes or can they really just cooperate happily and do both of those things together simultaneously?
*  So that's that's one direction that I'm interested in.
*  Cool. I mean, this actually does get into the timing of things.
*  And maybe this will come up more when we're talking about sleep and just just a minute here before we move on to to that aspect of your research.
*  So, I mean, do you think that we're going to continue to find more and more gradients so that eventually there will this will be a one hundred fold learning system or whatever, you know, or or is this too is the two the complementary learning system here to stay?
*  And are we going to base everything off of that scaffolding sort of?
*  So I think that there is something special about the circuitry of the hippocampus and in particular this trisynaptic pathway that's distinct from other things.
*  So like cortex is kind of all gradients, right?
*  It's kind of homogenous.
*  It looks like all the like pieces are kind of the same in different places and the and your your connectivity with other regions is kind of just going to determine what you're doing.
*  But in the hippocampus, there's specialized stuff happening.
*  And so in that sense, I do think it deserves its own special status.
*  And it might be that like at the top of this hierarchy where you're really like you need to encode individual things without interference and one with one try.
*  Like there might be something truly special about that.
*  But then I guess after that, I think that the that it might be gradients.
*  Although sometimes I think I don't think there's really any particular evidence for this, but sometimes I wonder whether a day or a period of time between sleep is kind of the boundary of the hippocampus with the rest of the brain.
*  So like the hippocampus like can deal with, you know, things basically the time scale of like your waking day and then you don't really start to shove things out of the hippocampus.
*  And maybe there's a gradient there, but maybe maybe there's something about that period between sleep time that's special.
*  And then and then after that, it could be a more kind of smooth gradient.
*  So we need to take the H Sam people and sleep depth them.
*  And I'm just trying to think of what bad things we can do for the H Sam people for the rest of it.
*  Yeah, I think there's all kinds of interesting things to do with those people.
*  Yeah, sleep studies would be a great idea.
*  Well, OK, so we've talked about the cortex a lot, and it's weird to say that hippocampus is hot right now because it's like the best studied part of the brain, you might say.
*  But it seems really hot these days.
*  I mean, it's it's I don't know if it's coming back or if it's just always been there, but or if it's just because I'm doing this damn podcast that I'm learning more and more about it.
*  But but the majority in deep learning in the world, basically, that's cortex.
*  It's modeling cortex, right?
*  It's like you said earlier, is the slow statistical learning that you can do in cortex and pair anything together that you want is as long as you're statistically correlating them and such.
*  So is what you're studying, do you know, do you see it playing a role in integrating in the building AIs moving forward?
*  Or do you have any thoughts about that?
*  I mean, I think that this work makes close contact with the continual learning, AI kind of world, because the struggle there is is the same.
*  I mean, it's the same struggle that was identified in this in this competitive learning systems, 1995 paper that that it's very tricky to write information directly to your kind of main memory store.
*  And so there's something important about having this buffer.
*  And I think that maybe maybe a new insight from this like more detailed take on the hippocampus is that that it might be useful to have different kinds of buffers, right?
*  Like it might be useful to have episodic kinds of things which already are happening in the world.
*  But yeah, but it might be useful to also have this kind of rapid statistical learning system that also has, you know, maybe offline replay that helps to integrate it into the longer term memory.
*  So maybe that's an insight that could be taken into the kind of AI continual learning.
*  Yeah, it does seem like this is sort of the next push.
*  A lot of people seem to be working on having an external episodic memory buffer or and or, you know, in the meta learning world and, you know, training their systems to not have catastrophic forgetting and all this thing.
*  It really seems to be based in what we know.
*  A lot of it seems to be based or inspired by what we know about and continue to learn about the hippocampus.
*  So, yeah, which is great because there's not I mean, yeah, I think that's a it's a beautiful example of where these things make contact.
*  All right. So sleep replay.
*  We've talked a lot about replay on this show.
*  It seems like everyone has a different story about replay as well.
*  So it's all it's all over the place.
*  So in the in the complementary learning systems framework, replay is used to consolidate memories.
*  Right. So these things get replayed into the cortex to to keep pushing and give it statistical power.
*  Right. And we'll talk maybe in a second about how you have found that offline replay can prioritize the weekly learned information in a task.
*  So it's sort of compensating.
*  And you can talk more about that since I'm sure I'm butchering it.
*  I've had Tim Barons on the show and, you know, he talks about how replay can support our internal models of the world.
*  And this is this goes really along with your ideas of, you know, learning about structural knowledge as well.
*  But, of course, you know, hippocampus is and replay have was discovered in the spatial domain.
*  And he's sort of moving it into the abstract knowledge domain and, you know, coming up with models to help us infer the structure of those abstract conceptual domains.
*  Let's say I had Nathaniel Dahl on the show and he he talks about he has a model about replay as a way to maximize future rewards by prioritizing the right memories to queue up so that when you're in a situation you got you want to queue up the right memory for the right situation to to do the right behavior to maximize your reward.
*  And then the world, of course, somewhat famously, I suppose that these deep QN networks that DeepMind has used have used replay to effectively train their networks to play these Atari games really well.
*  And, of course, deep QN has gone on to, you know, be implemented in AI networks henceforth since then.
*  What do you think about all the hubbub about replay these days?
*  It's great.
*  I'm like I'm so excited right now because there's some really great empirical work happening in humans.
*  So Tim Barron's group just had a paper that came out showing that you can get really nice replay decoding in humans with MEG.
*  And Nico Schuch had a FMI paper that came out showing sequential replay in humans.
*  I mean, we also have an FMI paper looking at replay in humans, although it wasn't this kind of this like sequential variety.
*  So anyway, it's just like it's a very exciting time empirically.
*  And I think it's an exciting time computationally for all the reasons that you were just saying.
*  So, yeah, it's it's great.
*  The more the more theories, the better, I suppose.
*  Well, I think they're all pretty related and consistent so far.
*  I mean, you can think of two general ways that replay might be relevant and implemented these systems.
*  One way is that it's important for planning like this kind of Nathaniel Doss style thing.
*  So in your just awake life, you're you're sampling and figuring out like how you want to what you want to do next.
*  And, you know, you're at a choice point and you're trying to recall your past experiences to figure out what to do.
*  So that's I think of that as being very distinct from the kind of replay that happens when you're kind of outside of of a decision making context.
*  Maybe you're asleep, maybe you're just like quietly reflecting and totally different place.
*  And you get this like automatic reinstatement of experiences coming back up that seems to be related to later memory.
*  So I think those are probably two distinct functions of replay.
*  I'm sure they're related, but we need to.
*  We need to. We need a dual a dual aspect theory of replay here.
*  So that's good. It'll be a gradient.
*  It's all gradients. Yeah.
*  Well, so great. So what's your story about replay and specifically with sleep and and the consolidation of information and memories within Cortex?
*  So you've studied this a lot.
*  And I'm not going to point to a specific paper because it's kind of like a series of papers that address this.
*  Well, I'll tell you about one of our empirical findings and then I'll tell you about the model that we've been developing to try to address this kind of finding.
*  So we we were interested in this idea that as memories come to rely more on Cortex over this process of systems consolidation, that you might expect a change in the quality of the memories in accordance with the change in these in the nature of these representations that we've been talking about.
*  So if if representations are becoming more overlapping in Cortex, then you might expect that to more easily highlight the commonalities across experiences as opposed to kind of the details of each individual experience that you've had.
*  And so we design an experiment to test whether that's true by teaching people about categories of objects where you learn about unique properties of every object.
*  We also learn about properties that are shared amongst exemplars in a category.
*  And we make sure that memory for those unique and shared properties are matched before sleep, which is really important in order to ask, you know, how are these things differentially affected by sleep?
*  And we find that something unusual in the in the sleep and memory world, which is actually that your memory for the shared properties is better after you sleep than before.
*  So that's unusual because typically the like memory effects, at least the kind of like declarative memory effects have to do with less forgetting.
*  So sleep will lead to less forgetting of some arbitrary association that you've formed before sleep.
*  But this is a case where sleep actually seems to lead to a better understanding of the category structure after than before.
*  And so that's that's kind of exciting.
*  And I think it's consistent with this idea that if you're coming to rely, if your memories are coming to rely on this cortical neural substrate where you have these more kind of overlapping representations that that's going to kind of highlight those commonalities for you.
*  Yeah.
*  So that's the kind of empirical work that we're doing.
*  And then and then the model that we're building, I mean, in some ways, it's really it really just is the same as the original CLS paper.
*  I mean, the CLS framework would lead to this kind of a tendency to represent shared structure more strongly over time.
*  But that paper didn't really cash out the mechanisms of how that hippocampal cortical dialogue actually happens.
*  So we're we're like trying to really think about like if we just let a network run by itself, like set it with some random initial conditions and let it run, kind of do something useful.
*  If we have a hippocampus in a cortex, like can they talk to each other?
*  Can they figure out when to learn from each other?
*  Like how do you actually get that working as opposed to more controlling the hippocampal replay in a more like explicit way that it was done in that in that paper and is often done in free play modeling work.
*  So we're interested in can we get a learning framework that will work totally autonomously?
*  No more input or feedback from the environment, just dynamics running.
*  Like how do you even know what a trial is?
*  Right. Like how do you know when to when learning should happen?
*  Like those those kinds of questions.
*  And how do you how do you get like what does it mean?
*  And people talk about hippocampus training the cortex.
*  Like what does that mean?
*  How do you how do you get something like that working?
*  So that's that's what we're that's what we're doing.
*  So I mean there's all sorts of sleep, right?
*  I mean this kind of ties in with the timing aspects of some of the work you've done with is I don't know if it's Chris or Christopher Honey.
*  And I don't know if you want to talk a little bit about the time scales and how that works as well.
*  Yeah, so that work with Chris Honey and Aaron Newman was a was an attempt to kind of synthesize across a lot of different spatial and temporal scales.
*  This this idea that we oscillate between times of being engaged with our external world, processing what's happening and times of being more inter internally oriented.
*  And I mean this is just like a fundamental property of what most many kinds of learning certainly the most successful kinds of learning that there's a kind of you you you generate an expectation about what you think is going to happen next or about what category an image belongs to.
*  Right. And then you get feedback about what that category actually is from the world or you see what happens next in the sequence.
*  And there's this kind of back and forth between an expectation and reality.
*  And there's something fundamental about that, like having these two things to contrast in order to drive learning in order to do air driven learning.
*  And I mean, I think back propagation has this flavor and any you had I listened to your episode with Ruffall Bogatsu has this really great paper where he kind of characterizes the taxonomy of the different kinds of ingredients that are necessary for different kinds of learning algorithms.
*  But but this this idea that there's that you need a separation in time between kind of processing that internal state and processing what's actually happening in the environment is common across a lot of learning not all but a lot of learning algorithms.
*  And we think that we the point of this paper is to point out different cases in the brain where that seems to be happening.
*  And we think that that might be driving learning.
*  So sleep and wake is like the most obvious ultimate form of this oscillation.
*  Like you are mostly almost entirely disengaged from your external environment.
*  You only have your internal model of the world to look to work from during sleep.
*  But I think that same dynamic happens at many different timescales.
*  Like you can even think about it happening across the phases of a theta cycle on the campus or and where alpha and cortex or or you can think about it in terms of like this quiet week kinds of periods versus like engaging the world with the world and the world is like a
*  engaging the world with the world.
*  So anyway we think there might be something in common across all these different these different kinds of oscillations.
*  And you said that the that there's different kinds of sleep.
*  Were you going in the direction of like different sleep stages and that kind of thing?
*  I just and the the finding that the result that you found where the improvement in memory happened was with people who took naps.
*  Right. It wasn't it wasn't the full on.
*  We had both.
*  We had both.
*  OK.
*  Yeah. I want to ask about that.
*  But then since you're talking about just the sort of the rhythms of things you know thinking about the about learning in general.
*  Right. So we evolved.
*  I'm going to pull in evolution here.
*  So we evolved sort of these rhythms right for learning like you're talking about and living on the on this planet.
*  Right. So in our environment with the spinning of the earth with its tilt relative to the sun.
*  So there are all these natural cycles under which we evolved these things.
*  And then and so so then you have the you know the sleep cycle slower learning cycles.
*  Right. And then there are the faster learning cycles that happen via through oscillations let's say theta rhythms we could just say which is very fast compared to a sleep cycle.
*  Right.
*  But you know is there something special or optimal about the rhythms that we experience during learning.
*  So I guess the question is are we taking advantage of cycles that are already ingrained or is there something special about the periodicity of these cycles in particular that optimizes learning.
*  Right. And I guess that's an impossibly large question.
*  Well so I mean one one way to think about to think about this is this idea that you there's different timescales of information out in the world that you want to understand.
*  And so you might want to match your oscillations to these different timescales of what's actually happening in the world in order to in order to kind of appropriately learn about that time scale of information.
*  And so so then it makes sense to have a gradient again of of these timescales of oscillations in order to pick up on the kind of full extent of the time scale of things that's happening in the world.
*  So we're some that we're tied then to the sort of the rhythm of the environment in that respect.
*  I'm curious. I'm asking because I'm wondering if these same constraints will apply to AIs right when in general.
*  And listeners can't see me always roll my eyes when I just bring in a right out of nowhere.
*  That's the point of the podcast.
*  Well yeah I've got to touch on it.
*  Because these are you know what sometimes these are how general are these principles is a question and how much how much can we apply what we're learning here to the domain of artificial intelligence right.
*  But yeah you're right like you know you can't if you observe a flower at the same time every day and maybe you never see its petals open then you're not learning about the flower right you're just learning because it never changes you never experience the change so.
*  Anyway yeah so I'm wondering if presumably a general AI operating in this world would be operating under those same constraints so would perhaps learn under those optimal rhythms as well.
*  But we'll come back to sleep in AI in a minute I suppose but.
*  Yeah I love that idea I love the idea that there might be something about these different timescales that the brain is settled on that are useful to the extent that we want our AI learning same kinds of things that we're learning which you know.
*  Yeah I think we do but then then it might be useful to think about these different these different kind of cycles that that the brain is using and whether those those are useful.
*  Timescales for for AI too yeah well it's a great thing to think about.
*  So yeah so let's get back to the different phases of sleep and the timescales within sleep and you're about to wax poetic about it.
*  Yes so I also think that the same dynamic of this like thinking about your external environment thinking about your existing kind of models of the world I think that's also happening within sleep across the cycles of sleep so.
*  Okay so we have slow wave sleep which is the time when all of this like well not all of it but much of this like hippocampal neocortical dialogue these sharp wave ripples that are sometimes coupled with cortical spindles like these.
*  I mean most replay the vast majority of replay is studied in slow wave sleep and so there's something there's something special about slow wave sleep for creating this hippocampal neocortical dialogue that's maybe leading to this like you know the hippocampal training of cortex and I think of that kind of like it's like a proxy for your for more experience with your environment.
*  I mean relatively speaking it's kind of like thinking again about your external world and then during rapid eye movement sleep which is like a total mystery and people have no idea what's happening.
*  It's been very hard I mean there's a couple of reports of measures of replay like things in REM but very few.
*  We're like we're not looking at that data in the right way like we're not something is happening but I mean clearly like we're having all these vivid dreams and everything but we haven't been able to figure out how to measure it.
*  And so the idea is that what's happening there is that you're going back and thinking about your existing understanding of the world you're using your already kind of built internal model to replay or you know generate ideas about how the world works from that that kind of existing knowledge.
*  So yeah so it could be that part of the reason that people aren't seeing replay is that it's not we're not thinking as much about our recent experiences right we don't have measurements of what these neurons code for for things that happened a long long time ago and if we had that maybe we could decode what's happening during REM.
*  Anyway so I think that there's this oscillation that happens within a night where you have these cycles you go from from slow wave sleep to REM a few times over the course of the night where you're thinking about your what just happened during your day the hippy campus is telling you what just happened and then you're saying oh how do I make sense of this in terms of my existing internal model of the world and then you say okay let me hear again what did I hear what did I see today.
*  So it's a proxy for external stimulation is your own sort of replay of that.
*  Yeah exactly and as you go through the night there's more and more REM sleep so the proportion of time you spend in a sleep cycle and REM increases over the course of the night and that kind of makes sense that you're like getting you're kind of getting it you have it incorporated and so now you can kind of spend more time on that working on that internal model.
*  Since we're speculating let's talk lucid dreaming for a second asking for a friend. I have a friend who's a big lucid dreaming fan he thinks he doesn't think he experiences the best most restful sleep when he lucid dreams and things like that so I don't know if you've studied or considered lucid dreaming but speaking about it this way it's like lucid dreaming that's like the best of an internal model gone external or something.
*  Yeah well right I mean there's some kind of awareness that happens that is not typical. I do not study lucid dreaming but people do. People are totally studying it and yeah there's papers there's a drug that you can take that seems to encourage lucid dreaming that's a new thing I saw come up on my Twitter feed.
*  I think there are lots yeah. Okay I see I'm clearly not an expert on this but people are yeah trying to interact with lucid dreamers while they're doing the full polysomnography set up and understand what's happening in those dreams and what's possible. It seems like there are rules about what's possible like you can't just do anything you can imagine you can only do certain things and that might be really interesting for like thinking about what are the constraints of these internal models that are that are really interesting.
*  Yeah I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's a good point. I think that's
*  a good point. I think that's a good point. I think that's a good point. I'm gonna listen to it probably.
*  I'm gonna listen to it probably.
*  Quote of the show today!
*  Sometimes we forget that most sciences began with ideas that seem a bit loony to us now,
*  but were sound enough in their own time.
*  If we detect lunacy among the ancestors of artificial intelligence, we'd better admit
*  that it's our very own and probably here to stay.
*  That's Pamela McCorduck in her book Machines Who Think.
*  So the concept of replay was inspired by neuroscience and applied to these deep QN Atari playing
*  networks to help train.
*  It's considered offline, but you wouldn't say it's sleeping, so to speak.
*  And presumably there are lots of functions to sleep besides replay, but it makes one
*  wonder you don't think of a computer as ever sleeping.
*  I mean, they quote unquote go to sleep, but that's when they're not being used, I suppose.
*  But I'm wondering what sort of principles, how abstract will we be extracting these principles?
*  How abstract will the principles be?
*  Or will we really consider these agents as, okay, put it into sleep mode so that it can
*  replay the AI needs a nap, that sort of thing?
*  Well, yes.
*  I mean, the way that I characterized it earlier, that there's something fundamental about
*  separating in time your processing of the environment and your kind of updating of your
*  internal models and kind of creating expectations and that kind of thing.
*  So that's a very general thing.
*  There's many, many, many ways you can implement that kind of idea, and the brain does do it
*  in many ways.
*  And it could be that you don't need to sleep in the way that biological systems sleep in
*  order to get that benefit, if that's what we care about.
*  But it could be that you need something like a slow way of sleep and something like a REM
*  in order to really delicately integrate new information into existing knowledge stores.
*  And I don't know at what level of detail it's going to be.
*  So I mean, that's the question of this podcast, right?
*  What is it?
*  What is it about these things we're learning about the brain that will or won't be relevant?
*  But it's interesting that you mentioned time, and I'm glad you came back to it because most
*  of these feedforward deep learning networks really don't care about time, and time is
*  not a factor in training them.
*  But once you start getting the feedback connections and start using recurrent neural networks
*  and those become more advanced, I wonder if time and the necessity of learning things
*  within time periods and within a certain rhythm, just like you were mentioning, if that's
*  going to become more fundamental and more pressing.
*  That sounds right to me.
*  Yeah.
*  Oh, good.
*  I'm glad we solved it then.
*  Has studying sleep affected your sleeping habits?
*  Sorry, if that's a question everyone asks you.
*  Well, I used to joke that when I was up late at night developing this model, the model
*  was getting to sleep, but I wasn't getting to sleep.
*  Nice.
*  Yeah.
*  No, I value sleep very much.
*  I don't think that's why I study it, but I try to get a lot of sleep every night.
*  I usually sleep.
*  I'm getting better and better at it.
*  It's really hard for me to drop things and go to sleep, but I know it's important.
*  Speaking of hippocampus being hot, sleeping is really hot.
*  So you're firing all the cylinders here.
*  Is sleep the main thrust now of what you're moving forward, like you're talking about?
*  I think of it as half of what I'm interested in.
*  I'm interested in sleep insofar as it's going to help us understand memory.
*  I've become convinced that for this process of integrating new information into existing
*  knowledge, there's something really important about sleep for that process.
*  We're going to have to do sleep experiments in order to build models of sleep in order
*  to understand what's happening there, but I'm still just interested in this process
*  of initial learning as well.
*  I think of my lab that just barely exists as being half a sleep lab and half just a
*  kind of basic memory lab.
*  We do have sleep facilities here.
*  We're going to be running.
*  Yeah, people will be sleeping in the lab, all that.
*  Yeah, good.
*  Getting the facilities up and running, you're going to start off strong.
*  That's awesome.
*  Sleep has to be important because we just give up our bodies.
*  My daughter and son, they're four and six, recently went on a little vacation with their
*  mom and they came back.
*  It was a family vacation.
*  Wes, my son, told me that he woke up in the middle of the night.
*  They had a sleepover with their cousin who's an adult.
*  Wes said that he whispered it to me.
*  It's kind of a secret.
*  He said, I woke up and I looked over and Holly's mouth was wide open.
*  I looked over at Nora, his sister, and her mouth was wide open.
*  Then he's like, and then I went back to sleep.
*  I'm like, yeah, we really just are laying out ready for anything, anything that comes
*  our way.
*  Not many spiders to crawl in.
*  Yeah, for spiders to crawl in.
*  I would imagine sleep is pretty important.
*  Must be.
*  It must be.
*  Your funding is going to go well anyway for the sleep, I think, these days.
*  I hope so.
*  I don't know about that.
*  Anna, you are a woman.
*  True.
*  True.
*  Can you tell me a story about how being a woman has affected you in science for good
*  or bad?
*  Yes.
*  Yes, I can tell you many stories.
*  Let me think.
*  I've got all day.
*  I've got all day here.
*  Sometimes I tell this story because, well, you'll see why.
*  One time I was a grad student.
*  I was probably in my second or third year.
*  I was presenting a poster about a model at a conference.
*  I was the first author on the poster.
*  One of my senior male advisors was the last author on the poster.
*  This woman came up to me, a professor, and said, this is really interesting.
*  I'll have to find your advisor and ask him how the model works.
*  A woman did this.
*  Yes, a woman did that.
*  Part of the story is to say, we all do this kind of thing.
*  I do this kind of thing.
*  Maybe not that bad.
*  You make assumptions about people.
*  It's much more common for men to do modeling work.
*  It's just a base right thing.
*  You come and you just assume that I didn't know how the model worked, which is funny
*  because my advisor had no idea how the model worked.
*  These kinds of things happen in much smaller ways all the time.
*  That was one of the most obvious, what?
*  You want to talk to my advisor about this?
*  I'm happy it was at least a woman who came up.
*  Maybe the problem is that you're not very articulate anyway.
*  It's obvious you don't really know what you're talking about.
*  Thank you.
*  People make assumptions about how good you are about that something or how much you know
*  based on how you look.
*  That sucks.
*  It sucks to go through the world knowing that you'll have to prove to people that you know
*  what you're talking about.
*  It's just an extra hard step to have to deal with.
*  You could talk about women in science in general, but especially in computational subfields,
*  it's still really male dominated.
*  Even the influx, even new students coming in is male dominated.
*  I don't know the numbers.
*  That's a great question.
*  I don't know the numbers either.
*  I certainly am seeing more and more women, which is great.
*  I think it's still pretty heavily skewed.
*  That's the type of thing.
*  Does that make you want to do more modeling work?
*  Yeah, absolutely.
*  It does.
*  I feel defiant.
*  I feel like I want to work to combat the stereotypes.
*  I want to do what I can to be a role model, to show that you can be a woman doing this
*  kind of work.
*  I've certainly appreciated, meant a lot to have women role models, people like Yael Neve,
*  who is at Princeton, who is an amazing computational person.
*  I'm going to interrupt you because I've gone back and forth with Yael now multiple times
*  trying to get her on the show.
*  Since the inception of this show, I've tried to be somewhat balanced.
*  In some sense, I'm just going after people that I'm interested in.
*  It happens that a lot of them are men.
*  That's because there's more men.
*  Well, yeah, there are more men.
*  I'm also aware, and you'll have to forgive me, but it's slightly annoying to have to
*  be aware that I'm not getting enough women on the show.
*  I've had this awareness since the beginning and it just hadn't worked out.
*  It's been pointed out to me multiple times on Twitter.
*  I'm not even our vocal about this and not afraid to speak up.
*  It's been pointed out to me and I'm like, come on, guys, I'm trying here.
*  Yeah, well, it's good that you're trying.
*  Let me just try to give you a little pep talk about why it's worth trying.
*  It's so important to see an example of somebody who is like you, who is doing this kind of
*  stuff.
*  When you're in a sea of people that don't look like you, like when I took CS classes
*  at Stanford, I feel like some of them were 90 percent, maybe more men.
*  You're sitting there in the class and thinking, do I belong here?
*  Can I do this?
*  Do you really think that?
*  Does part of you think that as a woman?
*  Yeah, definitely.
*  It sounds ridiculous to say it out loud because it's irrational.
*  Yeah, definitely.
*  Definitely.
*  You feel like you don't fit in.
*  The more that you can do to raise the visibility of women and minorities and show that these
*  people are doing this, we're here, it's more powerful than you might realize.
*  That's why it's worth the pain.
*  I know it's a pain.
*  Keep going.
*  Well, I appreciate you.
*  Thanks.
*  I appreciate you being on the show.
*  We're not done yet, by the way.
*  In fact, I'm going to have a little run of women guests here.
*  It just kind of worked out that way.
*  Great.
*  I'm just reckoning.
*  In actuality, I've always been inviting women.
*  This is just a microcosm for my life in general, but I've gotten shot down.
*  People will just not respond.
*  The majority have been women who have not responded.
*  Maybe that's because I haven't had enough women.
*  Who knows?
*  No, I don't think it's because of that.
*  It's just this issue of how women, the computational women are being invited to all kinds of things
*  and so their time is harder to get.
*  There's a rub there.
*  That's the issue.
*  Keep trying.
*  What do you think about the current trend?
*  It seems women are on the upswing, perhaps?
*  That's my take.
*  For sure.
*  Definitely.
*  The awareness that we should be actively trying to invite more women to be speakers on panels
*  and that kind of stuff, that is changing so quickly.
*  Yale's bias watch thing has been really important for that bias watch.
*  Yeah.
*  In fact, the numbers are like, well, I'll ask her about it, but I was just looking at
*  the numbers and it looks like women are doing great proportionally for being invited for
*  talks.
*  Right.
*  I think that's getting much better.
*  I am seeing more women students.
*  Yeah, I think it's better, but I think it's very far from good enough.
*  How do we know?
*  When is it going to be good enough?
*  How will we know?
*  Is there a number?
*  If we reach 50-50, we can be happy.
*  If we plateau at some other level, we'll have to think a little bit more carefully about
*  it, but I think we should aim for 50-50.
*  What if it goes over 50-50 and it's more women?
*  That's fine.
*  That's fine.
*  There it is.
*  Well, I mean, on average, over the course of history, it'll take a very long time until
*  we even things out.
*  I'm not worried about it.
*  Honestly, what's 50-50 people in the field?
*  What if there is some natural, and let's not go down too far down this path, but what if
*  there is a natural bent, some statistical proportion of people interested in the field
*  and that happens to be 51% men and 49% women or something?
*  That's why I was saying if it plateaus at a different level, we'll have to think more
*  carefully about it, but we're not ready to think about that because there's so many super
*  strong societal factors that are pushing us away.
*  Let's fix all those bad structures and then let's see where we are at that point and we
*  can rethink it then.
*  Okay.
*  I've been reading, it's a super intelligence by Nick Bostrom anyway, and there's a lot
*  of the dangers of AI that will eventually happen.
*  I cannot read it with a sort of a, I don't think I'm going to be able to finish it because
*  it's so ridiculous that every sentence has the word might and could happen.
*  If this happens, this might, every sentence is conditional and it's, so it seems really
*  far away.
*  I know that that's a dangerous thing to say, especially when AI takes over, it will have
*  seen naive.
*  You think that the number, the right number for the women is really far away and we'll
*  worry about it when we get closer to it.
*  Yeah, exactly.
*  I'm also not worried about computers taking over the world, but anyway.
*  Which should we be more worried about, women or computers taking over the world?
*  Okay, I'll leave that one.
*  You don't have to answer that one.
*  Recently I've come across this concept multiple times, reading about consciousness, for instance.
*  Don't worry, it's not going to be a hard consciousness question.
*  The concept is, the universe started, there's the big bang and then there's a bunch of organization
*  and then organisms were formed and multicellular organisms and now we're finally coming across,
*  now we're finally developing that there are these little chunks in the universe that are
*  able to look inward and how special it is that we're conscious and we're like little
*  bits of the universe reflecting inward and there's consciousness.
*  You ever feel that way?
*  You ever feel like a bit of the universe looking inward, looking at itself?
*  Definitely.
*  Yeah, I mean, I first, like when I was in high school, I wanted to be a physicist.
*  I mean, I want to say whatever is the most important thing in the universe and physics
*  seemed like a good candidate for that and I was into string theory and quantum physics
*  and stuff like that and what is the universe made out of and then…
*  You discovered you're a woman.
*  You discovered you're a woman.
*  Sorry.
*  Okay.
*  And then I was in my senior year of high school, I took an AP psychology class and I started
*  to get really interested in the brain and I thought, I mean, this is not, many, many
*  people have had I think the same kind of like insight but we don't even understand how
*  we can understand the universe.
*  Like we don't even understand how we can perceive that.
*  We have to start there.
*  Like that's the most fundamental question.
*  Like what are we?
*  How are we even thinking about these things?
*  And so that got me kind of on that trajectory.
*  Oh, cool.
*  When are you most engaged in what you're doing?
*  What are you doing when you find yourself in flow or most fully engaged?
*  I love meetings.
*  We'll see if I say the same thing.
*  I know.
*  We'll see if I say the same thing in a year.
*  But I love talking to people about ideas.
*  Like I just, I don't, writing, like it's hard for me to get into that state when I'm
*  writing.
*  Like I like talking to people.
*  I like like being at a whiteboard and like drawing out different possibilities and having
*  like different minds to interact with.
*  So that's my favorite thing.
*  So a meeting is the, I was going to ask you how do you get there?
*  But you hold a meeting.
*  That's how you do it.
*  Yeah, exactly.
*  That's the power.
*  I can tell people we're having a meeting right now.
*  Let's meet every day.
*  That's how this works, right?
*  We're having meetings every day.
*  Yeah.
*  Well, you can do that.
*  Actually, there's a, oh, I'll email you after.
*  There's a way of doing that.
*  Standup meetings, but you probably know about them.
*  You're right.
*  Oh, I'll email you some information.
*  What is, what's one extrasensory perception or motor addition or just superpower that
*  like that you think AI can actually help us achieve, you know, in the next whatever, 100
*  years or something.
*  I'm going to, I'm going to try to give you an answer that's different than what you're
*  expecting or what you might've gotten before.
*  But that I think is really important and relevant to my interest, which is that we could have
*  the most incredible memory prosthetics.
*  So we could have.
*  And that's desirable.
*  Well, it would be complicated, but I mean, there's so many, so many things that would
*  be useful for it.
*  Like even just like just basic day to day, like where did I leave my keys?
*  Did I remember to turn off the oven when I left or like things like that?
*  Just like just quick retrieval.
*  This is the answer.
*  What is this person's name?
*  You know, just like all those kinds of little things that are so annoying would be so easy
*  for AI to like do.
*  It's like, it's like, it's, I mean, it's like a Google search, but on your own, like
*  autobiographical memory, I feel like, I feel like that would improve our lives so much.
*  I guess there's room for it to be a bad thing, but maybe it can be done well.
*  I think that would be, that would be awesome.
*  I guess we would need the power to extinguish memories at will as well then perhaps.
*  Yeah, yeah.
*  You know, to get rid of PTSD and things like that.
*  Yeah, that's right.
*  Right.
*  So both add and sort of suppress or subtract.
*  Hey, it's your thing.
*  It's not my thing.
*  Yeah, I'm not going to add to it.
*  So all right.
*  I like that.
*  That's the first time I've asked that.
*  So it's different than any answer I've ever gotten.
*  So well, when people ask, what is your superpower?
*  What superpower do you want?
*  Yeah.
*  Usually the answer is not like, I want to remember where I left my keys.
*  But anyway, yeah, that's pretty good.
*  I don't know.
*  What is a special talent that you have that not many people know about?
*  I am a musician.
*  I play clarinet and piano.
*  Oh, very nice.
*  Yeah, I've played in orchestras and jazz bands and klezmer bands.
*  Klezmer?
*  Klezmer.
*  I'm lost.
*  It's a traditional Jewish music.
*  It's really fun.
*  That's why I'm lost.
*  I really am.
*  I'm really naive about Jewish culture.
*  So but do you have an instrument in your office?
*  By the way, the wall behind the wall behind you is completely blank.
*  Oh, let me show you.
*  The listeners will not appreciate this, but I just bought this beautiful Greg Dunn hippocampus
*  thing that's going to go up on my wall.
*  But yeah, right now it's totally, I do not have an instrument.
*  I'm sorry to disappoint you in my office at this moment.
*  Maybe not as serious as a musician as you think you are.
*  So I have this theory really, it's probably mundane, but about jazz.
*  I really feel like jazz is for the player, not for the listener.
*  Does that hit home at all to you?
*  I think a lot of music is kind of like that.
*  And I personally get a lot more out of playing music than I do out of listening.
*  I do too.
*  You're also a musician.
*  No.
*  What do you?
*  I'm an average white male.
*  I play guitar.
*  What do you think I play?
*  Okay, fine.
*  So yeah, so I think that's true.
*  Yeah, for me, jazz and also classical music, that's especially true.
*  Like I get a lot more out of playing them.
*  Yeah.
*  Okay.
*  So this is like, because you can really enjoy classical music.
*  Sorry, this is a really big tangent, but you appreciate jazz.
*  I appreciate jazz much more than I enjoy it on average.
*  I see what you're saying.
*  Like it's a more like.
*  Doesn't fill my soul.
*  It's like, oh, that's good.
*  That's intellectually, that's good.
*  That's what I think.
*  Yeah.
*  Okay.
*  I see what you're saying.
*  Okay, we'll leave it.
*  So last question, what is one idea that you can't do or you don't have time?
*  I know you're just bathing in time right now before the semester starts with your new job here.
*  But what's something that you don't have time to do or the resources or something that you wish someone else would tackle?
*  So there are.
*  So in this hippocampus work that I've been doing, there are predictions of the model that really can only be tested in animals with, you know, recording individual neurons in multiple areas of the hippocampus at once and really having both high spatial and temporal resolution to say what is exactly happening in these different sub regions at different times.
*  And so I've been trying to if there are any rodent or primate listeners who want to test the ideas of this model, I'm working on a couple of collaborations trying to get people to do this.
*  But unfortunately, that's not my that's not that's not the lab I have set up.
*  So there's that, you know, there's certainly some things we can do in people and that are better to do in people.
*  But some of these like detailed tests of these models that we're developing are really best on an animal.
*  So so there you go.
*  All right.
*  You don't have to hint anymore.
*  I'll come out of retirement and start up a new monkey lab.
*  Don't I get it.
*  Exactly.
*  Yeah.
*  Well, she is on a Shapiro.
*  You can find her on Twitter at on a Shapiro.
*  That's a in a Shapiro.
*  Thank you so much.
*  Shapiro with a C.
*  Shapiro with a C.
*  I can spell the whole thing.
*  S-C-H-A-P-I-R-O.
*  Very good.
*  Thank you so much for your time.
*  I appreciate you spending so much time with me.
*  It's super fun.
*  Thanks for having me.
*  And good luck with the lab.
*  Thank you.
*  And prohibit any annoying advertisements like you hear on other shows.
*  To get in touch with me, email Paul at braininspired.co.
*  The music you hear is by The New Year.
*  Find them at thenewyear.net.
*  Thanks for your support.
*  See you next time.
*  Bye.
