---
Date Generated: April 19, 2024
Transcription Model: whisper medium 20231117
Length: 5036s
Video Keywords: []
Video Views: 729
Video Rating: None
---

# BI 176 David Poeppel Returns
**Brain Inspired:** [October 14, 2023](https://www.youtube.com/watch?v=MgthkaePpGM)
*  If there's any theme coming out here, it's that the memory story is so foundational to
*  no matter what aspect you're in in neuroscience or cognitive neuroscience, we have to get
*  a grip on it one way or the other.
*  Again, just because people wrote it 800 years ago doesn't mean it was idiotic.
*  It was people who thought very carefully about thinking.
*  Science has become replaced by engineering.
*  Or basically, at least in my area of cognitive neuroscience, science is now correlation and
*  regression.
*  And that's engineering.
*  This is Brain Inspired.
*  Hey everyone, I am Paul.
*  My guest today is becoming a recurring character on this podcast, David Popple.
*  He has appointments all over the place, but he runs his lab at NYU where they study auditory
*  cognition, speech perception, language, and music, so says his lab website.
*  So like I said, David's been on the podcast multiple times in the past, once by himself,
*  once with Yuri Buzhaki.
*  And the reason why he's on today is because a few episodes ago, on episode 172, I had
*  David Glansman on the podcast.
*  And David Glansman came on to discuss his work, trying to show that memory is stored
*  not between neurons at the synapse, which is the established story or dogma, but rather
*  that memory is stored within neurons, likely in a more stable form in the nucleus of the
*  neuron.
*  So a week or so after that episode, David Popple popped into my email appreciating David
*  Glansman's work and reiterating how important it is for neuroscience to figure out something
*  so fundamental, how memory works in the brain.
*  So we discussed that and surrounding topics.
*  We discussed similar things for language, which is one of David's focuses.
*  And we end by talking about David and Nina Kazanina's recent reexamination of the idea
*  of what's called the language of thought.
*  So the language of thought is a poorly named construct because it doesn't necessarily
*  have to do with language.
*  Actually, it doesn't really have to do with language at all.
*  But it's the idea that our thoughts must be governed by some orderly logical structure
*  and rules.
*  And David and Nina show how, in principle, neuroscience already has some of the data
*  suggesting that a language of thought is possible and should be studied at the neural level.
*  And besides that, we just talk about how David thinks about brains and how he thinks
*  that brains and minds should be studied, which we've talked about a little bit before, but
*  we go over again and in more detail.
*  And I think it's important to have people like David in the field to remind us that
*  it's important to think critically and think deeply about these topics.
*  Okay, show notes are at braininspired.co.
*  Slash podcast slash 176.
*  Thank you to all my Patreon supporters.
*  You guys make my world go round.
*  All right.
*  And here is David Popple.
*  The reason we're talking today.
*  Welcome back.
*  Good to see you, by the way.
*  Thank you.
*  Good to see you.
*  I'm glad that I'm glad to have a chance to chat and see if we can cause more confusion
*  or make more problems for someone else.
*  Well, this is kind of an impromptu discussion because I recently had David Klansman on and
*  about memories as being stored within the nucleus internally, memory as a molecular
*  process.
*  And this prompted you to reach out and I had forgotten actually because I think of you
*  as the language and rhythms and the linking hypothesis, hypotheses kind of guy.
*  But I had forgotten when I did my little hundredth episode series, and I think it was in answer
*  to the question, what is holding us back?
*  I was surprised that you had mentioned our concept of memory, our understanding of or
*  lack thereof of memories.
*  And so then I was reminded of that when you emailed David and I about that episode.
*  So I really have no agenda, like I told you before, but I wanted to get your thoughts
*  on, you know, well, that aspect.
*  But then you've written about memory recently, too.
*  So we'll talk about that and a host of other topics as well.
*  So I mean, that's why we just so I was sitting in the car and driving from Cape Cod back
*  to New York and I was listening to a couple of your podcasts.
*  And then I had not listened to David Glansman's episode.
*  And I have never met David, but I knew that one of my former research assistants and Emma
*  Laurent, who's actually Gilles Laurent's daughter and herself now a graduate student in psychology.
*  She had worked in his lab and the name sort of crept up and I said, I really must listen
*  to this.
*  And I was absolutely fascinated.
*  It was a really great discussion.
*  People should listen to that episode also because of the really cool historical examples
*  and perspective that that Klansman gives in the discussion with you.
*  And of course, yeah, it's emulated me because, you know, I've been thinking about that stuff
*  from a slightly different perspective, but he is much closer to the kind of perspective
*  that that Randy Gallistil has also articulated.
*  And these people have spent a long time thinking about the kind of conceptual challenges of
*  memory.
*  And I was like, all right, this is not silly.
*  This is, you know, the when you hear this kind of challenge for the first time, you're
*  sort of knee jerk reaction might be a bunch of old cranks.
*  You know, their feelings are hurt that some papers from the 60s weren't carefully read
*  or something like that.
*  Then you get into it and you're like, well, actually, they have some really deep challenging
*  points to our conception of memory and storage in particular.
*  And so it was very moved by that.
*  In fact, I had organized last year in Germany, a little workshop called Beyond Associations,
*  which was organized a little bit about Randy Gallistil's thinking, which so this topic
*  is not dormant anymore.
*  I think an increasing number of us in cognitive science and cognitive neuroscience are aware
*  that there is a serious, serious problem.
*  Well, I mean, David, it's going to possibly hold us back.
*  Yeah, well, I was just going to say, I mean, you said it's not being ignored.
*  But in my conversation with David, you know, his woes in obtaining funding and the arc
*  of his research lab, the size of it has dwindled, et cetera.
*  One might take home the opposite conclusion.
*  Yeah, I mean, I think that's because he's he's he was on this early on, as I guess was
*  Gallistil, maybe they've been thinking and writing about this for 10 years, and that's
*  been tricky. But now, I think in the last couple of years, their message is being received
*  more, I wouldn't say enthusiastically.
*  On the contrary, I talked to my colleagues and friends, they think it's outrageous and
*  stupid. And, you know, we have well-developed synaptic theories and, you know, goes, you
*  know, get out of here.
*  And I think it's just I think a growing number of us in different coming from different
*  fields, as I also then wrote to David Glansman in response to the episode with you, we're
*  thinking about similar problems.
*  We don't have a good story.
*  Right. So Glansman, in his discussion with you, mentioned all these wonderful and really
*  quirky historical experiments on plin area and, you know, chopping up this, that and
*  the other thing and the problem of, you know, what does it mean to have nuclear storage?
*  And likewise, when you talk to someone like Randy Gallistil, he brings computational
*  challenges like how would you in fact have something like stuff that you can put together
*  if you have only synaptic mechanism?
*  Very difficult. Just fundamental problems like compositionality.
*  And so we and why does this relate to what we do at all?
*  And because we have a very concrete question about storage.
*  Which is you have a vocabulary.
*  This is not a complicated idea to get across.
*  Like we're having this conversation.
*  We have a bag of words in our head and it works pretty well.
*  And it's we have pretty decent estimates across languages, what that means.
*  And so you have to have a story for that.
*  You can't blow that off.
*  That's one of the core things of how we communicate, think, deal with ourselves.
*  So that problem is the reason I reached out to David Glansman is not to say, oh, we're
*  very close to have an idea about how the storage of your mental lexicon works.
*  Absolutely not. On the contrary, we don't know our ass from our elbow.
*  But that's a that's a good alternate title.
*  You sent me this piece that you wrote, a short piece in Trends in Cognitive Science.
*  And the title of that says it all.
*  It's we don't know how the brain stores anything, let alone words.
*  But I like like your your recent phrasing there as well.
*  Yes, I mean, there's a more muscular phrasing.
*  And so what I wanted to so so the point I wanted to make is or share is.
*  That not that we have any kind of systematic, sensible understanding of how
*  stuff is stored in the language domain.
*  No, not at all. It's that we have pretty good theories, you know, cognitive,
*  linguistic, computational theories of what has to be accomplished.
*  That is to say, we can kind of decompose the problem in some sensible way and say,
*  like, look, you know, if you can't do A, B, C, D, you're toast.
*  So let's just take, you know, some sub some facet of the memory stuff that you have
*  to accomplish somehow. And so maybe that allows us a kind of way in to have more,
*  you know, mechanistic, implementational approaches to the problem.
*  So the computational theory to be Marian about it is pretty well worked out.
*  And we have alternative implementation levels of analysis.
*  Well, algorithmically, we again, we are kind of stuck.
*  But that's where I think there's a connection between people like David
*  Glansman's concern.
*  And he has a very nice paper that he that I know where he kind of goes through the
*  history and the arguments and why there is actually not so much of attention,
*  or there's a possibility to resolve the tension between the synaptic mechanisms.
*  It's not like they're not there.
*  But then the challenges of long term storage, which may or may not be
*  intracellular mechanisms.
*  So I thought and then so I think there's a game in town.
*  And the fact that it's unpopular probably means that there's some there's a there
*  there.
*  Well, I think I don't know how you feel about this.
*  But one of the things I'm recurringly struck with is.
*  I don't know if in neuroscience with the modern computationalism approach,
*  everything is computation, if we've lost sight of the fact that the super
*  impressive fact that all of these things are are nested across levels, right?
*  Whether you're talking, I mean, of course, the synapse for things to happen at the
*  synapse, you have to have intracellular machine, quote unquote, machinery,
*  biological processes, right?
*  So there is something happening in the cell.
*  And then but but do we need to is that the nexus of memory?
*  Do we need to locate memories inside the cell and how these things interact?
*  I think is one of the to me.
*  Just recurring impressive feats of if you could call it that, of biology.
*  And I don't know if modern neuroscientists missing that or not appreciating it
*  enough. And I don't know your thoughts on this.
*  Yeah, no, it's super impressive.
*  And the and I think that the the
*  attempt to at least sort of speculate, productively speculate or theorize
*  about hypothesize about the what is the relation between all this rich
*  intracellular stuff and what happens to the outside?
*  How do you is totally open and it's impressive that it works at all.
*  Right. So suppose I mean, look, suppose somebody like Landsman or Galistale
*  or others that are, you know, has some of like poor has this extremely
*  interesting theory based on RNA based computation.
*  Super interesting.
*  So if these guys, suppose one of these guys are right.
*  And let's say you store some item, you know, for in the case of Galistale,
*  he's really about number.
*  He thinks a lot of a numeric condition and in particular, inserting values,
*  variables into equations and stuff like that for navigation.
*  Or suppose you're me and you want to store a word syllable cat.
*  Cat video or syllable.
*  And then.
*  How do you actually and how do you then externalize it
*  to the surface so that can, you know, so that information,
*  suppose it isn't for it's a series of ones and zeros.
*  You know, at the most abstract level, how do you actually then convey that
*  so they can say to cats?
*  And so is that actually all done in the cell or is that cells?
*  So we still have synaptic mechanisms, we have communication between cells.
*  That's probably underestimated in its complexity.
*  But you have to then get it out.
*  You have to get the information in and you have to get the information out.
*  David Glansman has some interesting ideas about this.
*  And I think it's important about, you know, short, the short terminess
*  of synaptic mechanisms and let's say a sort of evaluative mechanism.
*  Maybe that's a good way.
*  You know, you don't want to write everything into cells or something like that.
*  But anyway, there's a there's a kind of rich series of problems
*  where we're just, you know, we go, we go to, you know, we open our textbook,
*  whatever, Candel, Bayer, any of these things, Nichols, we say, oh,
*  look at this theory of the synapse. So cool.
*  You know, it's glutamate. Awesome.
*  And then you're like, well, the way to.
*  Now, let's actually think of what you have to do.
*  And so I think the fact that it works is amazing.
*  But the fact that we don't even have the intellectual courage
*  to say we're missing something really profound in our understanding,
*  that's kind of lame.
*  I mean, that that has to change.
*  And it's your job to make a change by pushing it,
*  having people keep talking about, OK, good.
*  That's on you. It doesn't work.
*  Small responsibility.
*  But so, you know, a lot of the experiments that Glansman has done
*  and talks about and, you know, you kill an aplasia,
*  you extract or you extract its RNA, you have to kill it.
*  You extract its RNA.
*  I guess you do kill it anyway.
*  You extract its RNA, you put it in a new one.
*  And that new one all of a sudden has a quote unquote learned behavior
*  or some some sort of behavior is transferred.
*  Some people say, well, OK, that's awesome.
*  But that's, you know, really low level.
*  It's like a procedural memory. It's just behavior.
*  And then so, for instance, in reaction to this episode
*  with David Glansman, someone wrote in our little discord community,
*  they said, I know it's almost cliche to ask, quote,
*  but what even are memories?
*  End quote at this point, because I feel like we run into that question
*  with almost every guest.
*  And, you know, he goes on to
*  articulate just some confusion about, well, you know, he has trouble
*  thinking about storage at the intracellular level at the center.
*  You know, how do we even approach thinking about this?
*  And but anyway, so, you know, back to the kinds of experiments
*  that have been done and what I want to get to is ask you, you know,
*  how do you feel about what's your bet about whether this is a feasible thing?
*  With higher level cognitive stuff like words, concepts, etc.
*  Because what we've seen so far is, I mean, it's sophisticated.
*  Monarch butterfly flying patterns, etc.
*  You know, a caterpillar's brain gets, I think I have this right,
*  gets totally disintegrated and reformed, you know, and it's
*  and it has the memory of what it was taught, etc.
*  But but you could say these are kind of low level cognitive feats, perhaps. Yeah.
*  Why would it be different in kind?
*  I mean, it's information of some form that needs to be stored,
*  it needs to be written down, needs to be written out, right?
*  Retreat, stored and retrieved to be used for subsequent steps, operations,
*  computations, whatever metaphor you prefer.
*  And so I don't see why it would be different in kind.
*  It would be a tremendous, tremendous feat and super informative
*  if we knew anything like that about the caterpillar, the moss transformation
*  or how a word is stored. And all I want to, you know, look, my non-contribution,
*  but just sort of stimulation.
*  Why not? So why again, back to the word stuff?
*  Because it's it's uncontroversial that we store such things
*  and that we have them in long term memory and that they're in some sense abstract
*  or complicated or caught in whatever.
*  No, that's just why. Why would actually navigation be any less abstract, by the way?
*  That's it. That's for later.
*  So you have we know certain things about this.
*  So, for example, here's what we know.
*  You make contact with whatever that stored thing is through sight,
*  through sound, through touch.
*  So you can actually you have pointers from this.
*  So that already tells you something about the form.
*  And the format must be sufficiently flexible or abstract.
*  The different sensory modalities, in fact, any sensory modality
*  can actually reach that stored thing.
*  So that's already pretty.
*  It needs to be in a kind of format that you can actually take another thing
*  and stick them together, make a chain, make a different kind of group.
*  It needs to be connected to something that generates output.
*  So a motor coordinate system.
*  So we have certain criteria or kind of desiderata to be more hoity toity
*  that simply must be met on a logical ground.
*  And I think, you know, step by step peeling away the layers
*  are just kind of interesting computational clues on what has to be accomplished.
*  And if that if it turns out that one of those little clues
*  is solved in a planaria or in the caterpillar demot transition, that's fine.
*  I mean, we're looking for mechanistic hints of how that could even be accomplished.
*  And so here, so my complaint about the literature is,
*  and I'm actually working on a paper with this one of my graduate students, is
*  we have been seduced by focusing on the implementation level of description
*  when we talk about these problems, because we have cool experiments
*  working on synaptic stuff because they're doable, they're cool,
*  they're by and large replicable if you do them well and so on and so forth.
*  We're building an edifice of descriptive stuff that we have kind of been much more cavalier.
*  And this is, I think, where Randy Gallesto is so important about saying,
*  well, what has to be accomplished here? What are actually the what is memory for?
*  What does it mean to carry information forward?
*  I mean, that is the most core sense what memory is, right?
*  So you have information that's stored and carried forward and can be used.
*  Well, that's storage. Is that memory?
*  What should we think of as memory in circling? Because there is storage,
*  there's the encoding, and then there's the retrieval.
*  Is all of that memory? But you just said storage is memory.
*  So how do we think about memory?
*  So, I mean, okay, maybe memory is just a not very useful term.
*  Maybe it's just too, maybe it has too many subparts.
*  So you're right. I mean, I just informally mean it's the stored information that can be written in
*  and written out. So there's an encoding that has to happen, a long-term storage that has to happen,
*  and a retrieval so they can plug these things in.
*  That's the cool thing. Whether you're talking about low-level things or high-level things,
*  let's talk about the ant navigation stuff. Those are small brains and it's not trivial.
*  You pull out some value, you have a counter or a nodometer, and you say, well,
*  I have to put this value into this equation that I get out this vector. I mean, that's pretty cool.
*  I mean, that's pretty amazing. But it's very specialized. And so you don't need huge,
*  you know, integrated information theory or, you know, global network space theories of
*  consciousness to solve that. You need a circuit that does that. But the question is, are we
*  in our enthusiasm of just focusing on description of implementation? Have we lost track of the
*  problem that's actually trying to be, that's under the microscope that we're trying to solve?
*  And so we're so excited about every technical advance at the level of, you know, whatever,
*  now single cell transcriptomics. Cool. It's amazing that you can do it. And it's a wonderful
*  description. But it's not, is it going to yield explanation? And that's where I'm not so enthusiastic.
*  And I think we're being misled.
*  So you're not a fan of the engram, the modern story of the engram.
*  Why would I not be?
*  Well, I think when I think of engram, what I kind of think of, so I had Tomal Ryan on, and
*  I think of that kind of work, Tonogawa, etc., where it's basically like these cells kind of
*  get labeled, right? And then you have a pattern of cells. And that pattern is the physical trace,
*  and so they get tagged, essentially. And the tagging of the cells is another issue
*  to talk about. But I think of it in terms of the cell level and like a pattern of cells,
*  not the internal intranuclear storage mechanism.
*  Yeah, but I think that's a debate between, so Ryan, who's done wonderful experiments on this,
*  I think the question is, what's the physical basis of memory? And their notion of engram is
*  just a different notion of engram than someone like Glantz and Galistow. So I think they're
*  working on this.
*  It's the physical trace of memory. That's what the engram means.
*  Yeah, the physical, I mean, there's a nice paper, I think it's in Cognition by Galistow called
*  The Physical Basis of Memory, where he challenges, he lays out the arguments, what's so difficult to
*  do in a synaptic way. So I think we're all, I mean, maybe we're using terminology in two sloppy
*  ways still, because we have this sort of historical baggage. And maybe the message for me is,
*  it's really critical to be a splitter, not a lumper. It's like you said, like, what is memory?
*  Well, maybe let's be more principled and careful and be like, wow, it has all these parts.
*  Which ones are the ones where we're really, maybe the encoding part at some stage,
*  that's not a one size fits all thing that has lots of complicated steps. Maybe some of them
*  are more obvious, and some of them are totally non-obvious. They're not problems, they're mysteries.
*  So maybe that's one of the things we can do is just to be much more careful, pedantic splitters.
*  Splitting pedantry as a virtue.
*  Splitting pedantry. I mean, maybe we'll get into this in a little bit, but you've recently done
*  some work with large language models. And the paper suggests or argues that, well, we should take
*  use more of what we know about human memory and basically try to build large language models with
*  augmented memory, which is already, there's a lot of that work already being done. But your work
*  says, well, there are these subroutine processes that we know have to occur for encoding and
*  storage and retrieval. So maybe we should use those to inspire large language models. And you
*  guys have done a little bit of that work. Yeah. I mean, I think that seems to me just like
*  much of science where B, let's say, pragmatically opportunist. I mean, stuff is hard. And so look
*  to where you can to get little tweaks and whatever, a good pair of scissors and a screwdriver to put
*  the thing together to help you understand that stuff. I think it's really, I mean, isn't that
*  what we always do? We look around, we're like, oh, that actually could be really useful to solve
*  this problem over here. So this requires pliers. So, oh, look, there's a pair of pliers, you know,
*  the kind of, I think, pragmatic opportunism has to be the partner to principled
*  theorism. I mean, I'm, you know, I like sort of theoretically inspired research, but in our day
*  to day lab work, we would be crazy not to use, you know, the techniques we have available. So I mean,
*  one of the things I've worked on, well, I've worked on one of my postdocs has worked on
*  for a long time now, a postdoc named you is on he's a postdoc at AZ in Frankfurt, on using, you know,
*  computational approaches just or, and sometimes just counting and carefully construct a thing to
*  ask the question. You know, what is the parts? Why, you know, what is the parts lists? You know,
*  we're trying to, we're trying to keep we're like mechanics. That's how I see ourselves, like, what
*  are you know, what is one of the parts and he's just a question, as you'd think, very banal question
*  about, oh, you know, what's a syllable turns out to be extremely difficult, theoretically,
*  computationally. And so we just had a paper come out a week ago or so where, you know,
*  that's many years of work of you it carefully constructing the argument that it's actually
*  it's a primitive, it's one of the basic Lego blocks of the language system. Now you'd think
*  that would have been settled 100 years ago, but it ain't so. So it requires a lot of work and a lot
*  of kind of at the intersection of theory and just basic computational stuff to figure out that that's
*  a Lego block. But that's cool. That's good to know. Now we know, okay, so now we have these three Lego
*  blocks. And maybe we can have some other Lego blocks. And you have to be willing to look to
*  all kinds of weird things to make these cases. I mean, this is maybe that's more like Paul fire
*  obbons against method in terms of philosophy of science, right? So there's a little bit of chaos.
*  And then there are these moments of insight that rejigger your conceptualization of the problems.
*  How have this is an aside and I'm sorry for that. But how have you so you strike me as someone who
*  has always kept your head above the clouds and kind of trying to see the big picture and you,
*  you know, have a philosophical bent and you always seem to have. But how do you stay
*  in both worlds? You know, like the low level, you're the mechanic, but you're also the
*  philosopher, right? And how has that affected your career? Do you think has it helped? Do you
*  recommend that to everyone? Everyone has different personalities and does science differently, etc.
*  I don't recommend it.
*  But no, it's an interesting.
*  I can see you can kind of get sucked down into the inability to move forward if you see all of the
*  problems, right? I mean, you get it can be so but here, I mean, you know, a couple of so as an
*  advanced middle age, you know, privilege, let me say one, you know, as most of us know,
*  the good thing to do, although I don't know, I don't know, it's good in his sense of history
*  of science and philosophy, it's a good thing to do is pick a problem and beat it down. So there's
*  nothing wrong with working on your favorite subtype of the enemy a receptor for 20 years.
*  Absolutely nothing wrong, something important will be built that becomes sort of the test bed
*  for further experimentation and theorize. And so focusing on something that's a well, you know,
*  making the problem well defined and sharpening it and really sticking, you know, I think it's
*  very good. But then if you have intellectual ADHD, like I do, it's very difficult to sit still,
*  because you are not you know, you're I feel like I'm not even close to what I'm actually trying to
*  figure out. So for me, this metaphor, what's not a metaphor, I mean, the notion of a parts list is
*  very important. I mean, it's how I think about stuff. And or, you know, the notion of primitives
*  in cognitive science, or if you're more philosophical inclined, the ontological structure
*  of the domain. And it's important to me, because I understand the nature of the I simply understand,
*  I get it. I could say, Look, there's a bunch of parts. And it's a little more straightforward
*  in the in the case of the implementation level of description, you can say, look, there's cells,
*  but these cells have the following parts. And then there's an endoplasmatic reticulum. And there's
*  this thing, and there's a protein there. And you can really you can make a list. And making lists
*  is in some sense, very satisfying. It's also tricky, because as Feynman says, there's always
*  room at the bottom is smaller and smaller and smaller. But you can have it you can have a clear
*  sense of primitive or elementary pieces and elementary operations. That's something that we
*  do. And it's very clear to understand when we look at the implementation of tissue and biology.
*  And I think we can do the same thing in the psychological and cognitive sciences, or you know,
*  the computational cognitive science or whatever, who cares what we call it, that is, we subdivide
*  the thing into what we think are the elementary constituents there, hence my example of the
*  syllable like is, you know, that's for me now one of the primitives, that's a Lego block, it's
*  necessary for perception for production and for storage. Now, that's I think that's that's a known
*  known. So and as you mentioned, I mean, I think of this in terms of kind of linking hypotheses,
*  if I'm convinced that the district that the list of items that we have, and at the implementation
*  level is pretty well developed or well motivated. And likewise, I have such a list of elementary
*  representations, although that's a red flag for the computations, then the problem becomes a little
*  bit more clear to me. And it's simply for me, I think about it this way, it's a level of sort of
*  philosophical analysis of the problem. Because I'm too dumb to think about otherwise, I need I need
*  like lists and arrows. That's how I can think about it very clearly, is I know it helps me define the
*  problem. It helps me understand that, look, this is extremely difficult, because we know this is done.
*  And we know this is the substance, this is the stuff of brain. And this is the stuff of mind,
*  how's this supposed to work? Here's a way to do it. Be a dualist. Very elegant, no problem.
*  Our work is done. If you're not a dualist, then the shit has kind of hit the fan. And then we have to
*  really, you know, go to great lengths to figure out even the most elementary things such as storage,
*  or encoding storage and retrieval. That's one of the most elementary things that that presumably
*  nervous systems are for. And so if we don't have that right, then how are we going to make progress
*  on anything else? So the kind of so there always is a back and forth between nitty gritty experimentation
*  and zooming out and trying to figure out well, what is this about? What is this? Does this have
*  an aboutness? And for me, that's been because of my ADHD, I just like to read stuff about different
*  things. And I like I found it interesting. But you don't recommend it? I do.
*  But you just said you don't recommend you began with saying that you don't recommend your
*  approach to aspiring scientists. I don't recommend it to if you're if you're if you have a very
*  straight I mean, if you feel like you have to make steady progress. Oh, and that you feel on safe
*  ground, I don't recommend stay at the implementation level of description and work on a very particular
*  thing. If you're already destabilized or neurotic, or you like a lot of things, then I recommend it
*  for two reasons. First of all, access to extremely interesting ideas that are old and that we just
*  forget at our you know, at our own peril. And and kind of new ways to think of an older let's take
*  Plato. I mean, the notion of, you know, the dialogue, me know, me and oh, is a pretty
*  interesting discussion about how can you know something new? What is the notion of discovery?
*  And when you read that kind of stuff, you're like, actually, that's not the stupid, you know, that
*  may be 2500 years old, but these people weren't idiots, right? So, so some of it's a kind of,
*  you're like, well, I actually have to think about that, because there's a it makes interesting
*  arguments for did you have to know it before? Does it have to be innate? How would you actually know
*  it at all? How could you actually discover something new? If you didn't know there was a hold?
*  I mean, it raises sort of the logical inconsistencies with our notion of science
*  or notion of epistemology or knowledge accrual in a very interesting way. So it's worthwhile
*  reading that stuff if you're inclined to think about that way that the danger is that you then
*  get as you pointed out, you go down a bunch of rabbit holes, how can you reconnect it
*  to experimental questions that you're trying to answer? That's the real challenge and that
*  and then sometimes it just goes wrong. Well, this is related to the question.
*  I just another just as a recommendation, which I tell people in my lab all the time,
*  it's one of my biggest recommendations to also just read old stuff, not just because it's just
*  because it was written better. The papers you right now are just excruciatingly boring cookie
*  cutter formula, egg schlock. They all look the same. They sound the same. But these older papers,
*  even like read Journal of Neurophysiology papers from 50 years ago, they're beautifully written,
*  they're fun, they're interesting, they're quirky, see someone like working out an idea,
*  it have like 60 figures and you're like, wow, that's, that's real intellectual engagement
*  with the problem. Our papers are like figure two L. Yeah. No. Why has that changed?
*  I mean, it must have it must be for the better somehow. When you were mentioning earlier,
*  I'm going to kind of switch gears here about the things that we know we need implementation level
*  wise. And we were discussing this in terms of language. I don't think so you need your
*  sensory modalities to be connected with the storage to be connected with the motor modalities.
*  And what you didn't mention is that you have to do it quickly at the milliseconds level
*  timeframe. And you also didn't mention oscillations in that list. So what I so I wanted to bring that
*  up and time and oscillations and large language models. And what what you think of the large
*  language models and what they can and can't tell us or how have they affected your thinking about
*  language, multiple realizability, implementation level, etc. I mean, so at the moment, so well,
*  let's go, you know, outside in some, what is science about? Wow.
*  And there you are above the clouds again. There are. Let's go. Let's well I mean, there's a point
*  that let me just kind of sort of see if I can get to get the questions just step by step. So
*  so I think one way to think about that is historically, and kind of simple distinction
*  is one way to do science and what science is about is prediction and control. I see.
*  And those are two very foundational things. And they and they play a huge role in science and also
*  in engineering. A different way and a complimentary not not you know, not necessarily completely
*  distinct, but a different way of thinking about it in a different way of practice in science is
*  let's say, explanation and understanding. And there are cases where these things come together
*  very elegantly. And then there are cases where that doesn't work, you know, at all. In the worth
*  of Ruth Langmore from Ozark. We don't know shit about fuck.
*  Oh, that's a television show. Okay. Yeah. Okay. Very, very good. And so
*  the current work on this on engineering of speech and language and using models of that form
*  and falls right into this difficult into this difficult tension. So it's very clearly
*  useful. It's obvious. So let's first of all dispense with is it useful? Yes, it's very useful.
*  They can do cool things. Yeah. So this is it's not what this is about. Yes. It's cool that you can
*  do all these things, although one might have some ethical concerns, energy consumption concerns,
*  there's lots of complicated debate that's worth having, actually. Yeah. But just on the science.
*  So it's the kind of work is more on the side of prediction and control. I mean, these are systems
*  we build in order and it obviously the notion of predictions at the very center of this. Right.
*  Predicting the next thing and control in the sense of engineering here. And I think and we can use
*  that we can capitalize on models like that to analyze our data, to think about what we can learn
*  and so on. The question is, does it meet what we are what we think of in the sciences when we're
*  trying to do understanding and explanation? And there I'm not so optimistic at the moment.
*  I think that they're super cool and they're also super far away from what it is that we've
*  accomplished so far in the 100 years of psychology and cognitive science.
*  So I'm certainly I think it's a very interesting test that for looking at things and for developing
*  ideas, I do not at the moment think they have any particularly good relation to our criteria of
*  explanation and understanding of a domain as complicated as language. So now
*  let's take these big model. Can we suppose we start adding interesting stuff to them?
*  Is that you know, is that so let's let's call it biologically inspired AI or something like that.
*  That's interesting. That's an interesting question. I mean, is that going to actually open
*  new ways of thinking about what the models do, how we think about hypothesis formation,
*  and what we think of a theory is supposed to account for and so on. So there I think we're
*  at early days. But for the moment, I very much appreciate the engineering contribution and how
*  we can use models like that for for example, data analysis or labeling. Yeah, very cool,
*  very useful. Actually super totally different questions if we're standing around and saying
*  like, how is this actually going to answer a particular question about let's say storage?
*  I have no idea. I don't even know if it's answer askable. So I have I have. Yeah, I'm both
*  optimistic about one aspect of it and I'm sort of like meh about the other aspects and remains to
*  be seen. I mean, in part that has to do again with the models of the form are high at the level of
*  the form. They load on the level of implementation and not so much on the level of sort of computational
*  theory or explanation. I think that that divide is the very profound one. But even the storage
*  question, I mean, you could say that there's an argument to be said that well, the answer is
*  obviously they don't have nuclei. They're not storing things internal to the units, etc. So
*  they are stored at the connection weights in some sense. Yeah, I don't you know, and pretty
*  long dependencies as well. Yeah, so there there I mean, if we assume that there are sort of
*  analogies, then the analogy would be to kind of empiricist models of sort of, you know, behaviorist
*  empiricists, association as models of storage and computation. So in terms of the way these things
*  are conceptualized, built and then talked about, they're much more aligned with the notion of
*  synaptic type of, you know, I mean, that's what they build on, right, the notion of, oh, well,
*  there's weights all over the place. And so they align well with that. And there's the challenges
*  a la glansman, a la galistel, a la Johansson, a la Peter Balsam is simply, I think it's just simply
*  not arrived there. But I think that so take, let's take the challenge of oscillation. So suppose
*  you build a model. So I mean, I have two colleagues, and in fact, the very distinguished
*  visual neuroscientist Wolf Singer, who's a member of my Institute of Germany, and his, and his team,
*  most notably Peter, sorry, Felix Effenberger, the postdoc in that lab, have worked with building
*  large models in which they explicitly use the notion of a damped harmonic oscillator
*  as being a key of every unit. And then they're sort of saying like, look, that's our notion of
*  what certain certain layers of cortex simply have as part of their infrastructure and say, look,
*  you know, super granular layers, whatever here layer two has, let's just conceptualize this as
*  every unit or every node being a damped harmonic oscillator. Pretty interesting results. I mean,
*  I don't think that I believe the paper is not out yet. But they've they've built this and they've
*  really tried to sort of analyze sort of a range of kind of canonical tasks and new things. And,
*  you know, we're collaborating with them now to test it on, for example, perception things.
*  And it just is it. So that's a way to go that would be let's call it, you know,
*  it's not really biophysics. It's not a biophysical model, but it's sort of biologically inspired in
*  the sense that let's take a feature of cortex and see what does it add. I mean, does it actually
*  it's sort of a hypothesis generation model that says if this works, that's cool.
*  Let's see if we can now turn that around and experiment. So I think there's a lot to be learned
*  and a lot to be gained. So there is even in the case of something as contentious as oscillations
*  that can be I don't actually know why it's so contentious. I mean, I think it's just, you know,
*  people get really exercised about it. Those are things that are physiological excitability cycles.
*  People have shown for a long time. Sometimes they seem clearly to have causal force, sometimes not.
*  Nobody gives a single, you know, one size answer for all of this. People are nuanced. They know
*  it's complicated. They know you have to be very, very careful about your I mean, it's just
*  sort of become a self sustained debate about there's controversy, but no issue.
*  Yeah. Well, that's I mean, this just goes back to the difficulty in thinking across levels and
*  about circular causality, right? Because you need to explain things at one level. That's what we're
*  comfortable with. And as soon as you start going across levels, all hell breaks loose.
*  Because we don't have good linking hypotheses. That's there you go. That's the special thing.
*  That's another thing. Yeah. That's another thing that Jeff Shaw, when I was a postdoc in his lab
*  every year, we read a handful of papers and David Teller's linking hypotheses is one of those
*  papers. So you have kindred spirits out there still. Yeah, I know. I think it's a very, I mean,
*  look, I don't know if you've had, I'm not sure if you've had on your on your podcasts,
*  and Catherine Carr from the University of Maryland, Goldwood Park. I mean, Catherine is
*  absolutely, you know, brilliant neuro pathologists, who's done really foundational work and
*  for example, some of her work that she did jointly with Koneishi on barn owl on the barn owl sound
*  localization is just, it's the kind of work that's that I aspire to for the speech or language case
*  or any aspect of cognition for that matter, because they have, you know, they have really
*  worked out the nuts and bolts from the cellular subcellular level to what kind of math is being
*  done to what kind of behavioral task that can be made explicit and quantified is being solved.
*  And it's one of the most beautiful pieces of biology. I think it's totally underappreciated
*  because it read that is one of those linking things. One of the very few examples I know,
*  where the across level analysis is totally successful, you should really speak to Catherine
*  just as a very evolutionary take as a neuro pathologist, unsurprisingly, she thinks very
*  evolutionary, really beautiful. And someone who also does work like that, that's really
*  is Gilles Laurent, right with this work on, for example, sleep in lizards or that that's,
*  I think, very elegant, trying really to go from from cells and circuits to very interesting and
*  complicated behavior. So the I think one of the things that's coming back that I'm very excited
*  about is ethology and neuro ethology. And, you know, we've talked about this before the value
*  of being, again, principled pedantry, being extremely careful about the behavioral analysis
*  in that doesn't mean you have to have everything in a naturalistic context. I mean, that's almost
*  impossible to do. But to be careful about is the behavior that you're studying for an organism
*  matched to the kind of question you're asking? Or is it just like we do this because we actually
*  have done this experiment for 25 years and it kind of works? Like, yeah, whatever. Nice. Good on
*  you. The I think the bringing back to sort of ethological thinking is super, super helpful for
*  where we are, including for the artificial neural network thinking. It's very, very good. And it
*  gives it brings us away from this kind of the implementation. What do I want to call it? The
*  imperialism of thinking like an implementationist.
*  Like this is the, you know, I had this is the disagreement I have with Yuri Buzaki. I mean,
*  Yuri thinks very strongly what he calls insight on it, characterize, characterize,
*  characterize, measure very carefully. And then the story will tell itself of what is the actual
*  functional analysis of the problem. And I say, I think that's ass backwards, you know, and I
*  respect and love you, but I think it's wrong. I think it's actually you have to have and that's
*  what we call the implementation sandwich. There's actually a secret theory underlying this stuff
*  before you make your measurements. It's just latent. The implementation is actually sandwiched
*  between, you know, latent theory and then actual explanation of what you're trying to do. So you
*  have to have and what neuroethology brings to us, what's so exciting about it is it says,
*  let's try to really understand what this critter is doing. And let's, let's observe, let's measure,
*  let's think about it. What is this? What's actually trying to be solved here? I mean,
*  it's interesting that this, you know, cuttlefish is trying to become like its background.
*  What's up with that? Like, how's that possible? And so to think again, much more to not immediately
*  make the jump, it's this is not to say we're not supposed to do neuroscience supposed to do
*  nurse or neuroscientists, even if we're like, in my case, self hating neuroscientists.
*  And let's not immediately jump to the level of measurement, more measurement and more data
*  collection. And let's see, well, can we characterize what is precisely the problem we're trying to
*  study behaviorally, computationally, whatever, whatever domain you're in before making the
*  leap to let's just measure everything like maniacs, just because we can, because the tools are cool.
*  Yes, we can opt to let's go ahead and have, you know,
*  but it's nuts what we can do. It's amazing the stuff we can do now at the level of the tissue.
*  It's fantastic. But it hasn't has it, you know, can you can you point to a case where you say,
*  well, that nailed it. That solved that problem in person. I think that actually are edifice of
*  knowledge, the body of the body of knowledge is probably more solidly built on behavioral and
*  psychophysical data. And actually deficit lesion data from from long gone, you know, careful,
*  careful deep study of individual cases that had, you know, where you can very precisely
*  characterize the the now of course, the granularity of analysis of the neurobiology is very coarse.
*  But the functional specification has been very impressive. You read those papers from the 60s
*  and 70s. They were beautifully done. Very elegant. deficit lesion work that says, Oh, my goodness,
*  who knew that that actually dissociates so so crisply? Right, that tells you something,
*  right? That's Are you talking about humans, though? I mean, I know you're talking about animals.
*  Yeah, but I was gonna ask you about Well, I mean, it's more compelling. I mean, it's,
*  I mean, I think what captures the imagination of the human cases. Yeah, but it was done, of course,
*  in animal models, just I mean, take the original. So take the original multiple pathway stuff. I
*  mean, this is I spent a long time much of my career on this kind of dual stream model of
*  perception. That's didn't come out of nowhere that came through originally, you know,
*  the the kind of big picture thing became associated with Michigan and Unger Leiter.
*  And a lot of Leslie Leslie Unger Leiter's work when she was early on in more Michigan's lab at
*  NIH, but there were earlier works on this notion of parallel pathways solving different kinds of
*  problems in the visual system was already shown by Jerry Schneider in the 60s in rodents, and
*  showing distinctions between the say the tectum and cortical contributions. And so on the notion
*  that you actually subdivide the problem into computational subroutines to solve particular
*  things. I mean, that was a long story. And was shown. Yeah, I think the first papers I'm aware
*  of are Jerry Schneider's papers from one to say the 60s. And then Unger Leiter in Michigan really
*  made it a big thing. And then people like us just took that we just adopted it and adapted it. We
*  said, Well, that's a clever idea, because it shows you actually how anatomic subdivisions can
*  actually help you solve certain sub problems. And Greg Hickok, and I basically just built on that
*  and said, Hey, suppose that works the same way that would actually solve a lot of our problems.
*  And where did that come from? It came from lesions. The original idea came from lesions in animals
*  that Schneider did with rodents. Unger Leiter in Michigan then did it with primates. And then
*  people like Goodale and Milner showed it in lesions in humans. And so there's a really,
*  that's one of the examples of where kind of ethologically inspired animal work goes from
*  rodent to primate to human to computation to higher order cognition and showing that
*  the divide and conquer strategy is a kind of ubiquitous phenomenon that serves. That doesn't
*  mean we understand it fully, but there's no disagreement that the something of that form
*  is the right theory. Now people, you know, there's all kinds of different versions of this,
*  unsurprisingly, like our own, but that doesn't make it right. It just means but basically there's
*  consensus that that is one way that nervous system solve these complicated problems.
*  And so that's a that's lesion behavior. I mean, it's all of that stuff together. And it's a and
*  again, people want a quick answer, like, you know, well, well, large language models get this. This
*  took like 50 years to get to this rather banal insight. Like, it's just slow stuff is slow.
*  Yeah, but doesn't it feel so fast right now with with the development of the bigger models?
*  Things are moving faster, aren't they?
*  Things are feel like they're moving fast. It's not obvious that insight is moving fast.
*  I mean, the work is moving fast. And the fact that, you know, it feels a little bit like
*  science is being I've talked about, actually thought about writing about this is
*  science has become replaced by engineering. Or basically in at least in my area of cognitive
*  neuroscience, a science is basically regression. You know, science is now correlation and regression.
*  And that's engineering. And so everything moves very fast, if that's sufficient, if you're and
*  if you're like we talked about earlier, if the notion that you're trying to capture is prediction
*  and control. That's that's nice. I don't know about control so much. But you know, that's good.
*  If your notion is explanation and understanding, it's not moving that fast.
*  I mean, what what is it that you want?
*  Yeah, well, that's that's the thing is I'm constantly coming back and
*  so I'm self hating in this regard, I suppose. So we're in the same boat there. You know, what is
*  what is the real value because I want explanation and understanding. But then it's really prediction
*  and control that moves the world forward. And, and it's just a selfish sort of desire for me to
*  understand things. But I'm not sure what I get what the gain is except for personal satisfaction.
*  And I don't feel I'm not sure. I often come back to the notion that I don't I don't matter in this
*  world. So what does it matter if I have an explanation slash understanding? How does that
*  really help? But then mostly I live in the world of like, that's actually what I want.
*  Yeah, I mean, that's a hard question for you and your therapist. I mean, the, the
*  Oh, yeah, I should go to therapy. Because that's what you are. You're my therapist today.
*  So I mean, I think you're right in the sense that we have a very kind of instrumentalized view of
*  this, we want we want progress of a certain form. And that makes us feel like something has happened
*  that we're moving forwards. And, you know, and that's, I think there are lots of cases
*  where that's just not, you know, I don't think that certainly these things are mutually exclusive,
*  like the more understanding and real explanation you have, it doesn't cross cut the value of
*  prediction. But I think it's those are I mean, take something like celestial mechanics.
*  I mean, we have pretty good understanding and explanation of why things move the way they do.
*  At this point, we can't control any of it. But we can predict it. I mean, so like, what,
*  where do you really care? It sounds more like you care about control.
*  And control, I would recommend engineering, or the medical sciences where you can develop,
*  you know, a vaccine, a pill, a cure procedure. But that is not necessarily completely aligned with
*  the sciences. So I'm like, one thing that's really just to say, in terms of sociology of science,
*  one thing that Germany has got it right. And other countries as well, but I'm in Germany,
*  because I work there, I have more intuitions about it. Like the notion of having something
*  like a Max Planck society is an amazing luxury of, you know, for humanity in the sense that
*  there's funding, public funding to pursue pure basic research, no question. I mean, as an actual
*  common good, as a good for society. So there are other parts in Germany, by the way, that do that
*  are much more applied there, you know, the Fraunhofer society and the Leibniz Institute,
*  and those are really, they're more like NIH, the task is to do something very specific.
*  We want actually we want to see an output of this. But the notion that there is something like a
*  Max Planck society, where the people in this 25,000 people work there, and that you are actually
*  encouraged and funded to just follow your hunch, because we just don't know. And probably, you know,
*  90 times out of 20, it's just some rabbit hole. But there's then every now and then, a profound
*  insight from basic research that changes that's game changing. And the fact that we value that is
*  that's something, you know, I think that probably existed more, maybe after World War Two in the
*  United States, I mean, in the sort of, you know, Vannevar Bush or whatever. But era but why? I think
*  that's actually pretty amazing that a country says we're willing to spend public funding on people,
*  where I don't know whether there's going to be a pill, a product, a program, we just don't know.
*  I mean, it could be and I could be wrong. I mean, this is one of the things that convinced me to
*  take a position there that because I assume we're wrong. I take that for granted that and years
*  people are gonna look at that and be like, well, that was cute. Or dumbass. So instead of that
*  really nailed it. That nailed it. Yeah, but I mean, so isn't that isn't that an amazing thing? But
*  that's that that, you know, that is that there are countries who say, look, go to it. I want I don't
*  know, I don't demand that at the end of your five year funding, there is a clear step towards a pill,
*  or something like that, or, you know, a new hearing aid. But in the long run, that's the proof is in
*  the pudding, right? Because it's still the bet is that that will produce progress in some form and
*  some as to now unknown way. In an unknown way that likely won't affect us. So that it's a form of
*  sort of intellectual altruism into the distant future. Oh, okay. Yeah, okay. So it's distant
*  future. So it's really a long bet. It's a long bet. And I think you're right. I mean, I share that
*  intuition that, you know, the assumption is, I'm not allowed to say that because I do work for
*  Max Planck. I'm supposed to be defending basic science here. But you're right. And I absolutely
*  have the intuition that in the long bet is, in fact, something will come out of it that has
*  concrete consequences. But I mean, the I don't have, you know, how will we know until after the
*  fact? I mean, we sit in these things, right? So you go to the NSF, or the NIH, and one of the criteria
*  for grant is, is the work transformative? Yeah, well, that's nice. How would you know that until
*  much, much, much later? Right? So am I really do you honestly think without a deep sense of irony,
*  I can write that paragraph into my grant? Without like laughing at myself? And I mean, this is this
*  is a ridiculous and I've said that in study sections and in meetings, and as a member of
*  the advisory board as a, you know, like, can we please stop being just to save that paragraph
*  to add more interesting stuff about the ideas or the you know, don't don't give me the kind of
*  bullshit paragraph. I you know, like this, we can save that for leave that the the trend is let's
*  just do our stuff and be explicit about what we be very clear, be, for example, be very, very good
*  about how stuff can be replicated. That is in fact, use. Can someone else do it, make some minor
*  variance and get basically the same stuff that's super, super important, because then it allows us
*  to build on that body of inquiry. But forget the kind of game changing I am in my grant, and when
*  I'm done, that's really going to help stroke. Uh huh. Schizophrenia, schizophrenia. It's always
*  about schizophrenia. Depression, mild cognitive impairment. I'm like, yeah, yeah, yeah. Okay,
*  great. Right on. Yeah. I mean, that's one of the shockers of the last of sciences that we are
*  grotesque, grotesque under failure to understand mental illness. I mean, it's absolutely,
*  it's a debacle. I mean, after, you know, 50 years or 100 years of no, it's just shocking how bad,
*  how bad we're doing there. Well, okay, so this is what I was going to ask about, you know, with the
*  neuroethological approaches you were talking about, and whether how far we can take that with humans,
*  because we have our own cognitive ontology of what humans are doing. And maybe this will lend itself
*  to, you know, thinking about these high cognitive dysfunctions, right, disorders. And, you know,
*  does that neuroethological approach, will it, neuroecological approach, you know, can we even
*  use it, apply it to humans? How far can we take it with humans when we're, we're the things that
*  we're trying to understand. And so we have to define what we're trying to understand. If you
*  want to be a Marion, we have to come with a computational previous cognitive ontology and
*  talk about what the function is and the computational goal is. But are we, you know,
*  even good at that? I know this is we kind of talk about this ad nauseum sometimes on the podcast,
*  but you mentioning that disorders made me bring that back in just curious, you know, whether we
*  really can. Yeah, I mean, there's a couple of things to say. Like, I mean, one one is, unsurprisingly,
*  we have epistemic bounds. Right. I mean, we are parochial, we have a brain that is the way it is.
*  You know, like we can, certain things we can see other things we can't see, because that's our
*  receptor structure. And that's the same going to be for cognition, certain things we can cognize,
*  other things will be outside of our epistemic bounds for reasons of our architecture. But that's
*  okay, but we're not going to like get that that can bomb us out in a big, big picture. But we're
*  not going to stop by that. And we can still ask questions as carefully as possible. And so what's
*  what would be the neuroethological approach is this kind of tension between naturalistic
*  experimentation, whatever that is, or just kind of characterization in the wild, and controlled
*  work. And I think, you know, both have extremely high value. Let me give you an example of both,
*  just in my own line of work. So one, an example of really, let's say,
*  psychophysical pedantry taken to the extreme is a series of papers by my student and apostoc,
*  Matthias Grabenhorst and Jorgos Michael-Arias on one particular question of a computation.
*  And that is, do you, so one of the things about prediction, that's kind of ubiquitous
*  in the prediction literature, and especially in the temporal structure of perceptual experience,
*  is the so called is, you know, reaction times and hazard rates. And so, you know,
*  reaction times and hazard rates. So as you think something's likely likely likely to happen,
*  your reaction gets faster and faster, right? So if you like you're standing at the traffic light,
*  it's not green, it's not green, it's not green, it's not green. And then you step. So this is a
*  long literature from over 100 years. And you know, people think about the temporal structure of your
*  experience, because it's so compelling, we all feel it all. So there's a famous theory, it's been
*  around for a long time, and it's been actually most prominently worked on by Mike Shadlin,
*  and other other people in that field, and Mike Shadlin in the monkey case, but
*  others in the human case, which is the so called hazard rate.
*  The hazard rate is basically a function that says, well, as the thing gets more and more
*  likely to happen, I get faster and faster. And you can see certain cells. Now,
*  Matthias Grabenhaus, and Jorgos Michalereas, and they've worked for years, very, very hardcore,
*  super reductivist experiments in the lab to test what is really the function that you're building.
*  And the answer in a series of papers from our lab is actually what you're doing is just,
*  you're able to extract the PDF, the probability density function of the event structure,
*  you don't actually need all the extra steps to get to the hazard rate. To calculate the hazard
*  rate, you have to invert the function, you have to calculate the CDF and so on. There's a bunch
*  of steps, all of which are a little late by. So through very, very careful psychophysical reductive
*  experimentation, you're sitting in a booth and you're doing the same super boring, non-naturalistic
*  experiment, you can, however, extract something very kind of fundamental, which is the calculation
*  and extraction of a PDF is one of the building blocks. So just like I said earlier, for me,
*  in the language case, the syllable is a building block. For me, in the temporal
*  structure perception world, extracting a PDF is a building block. I believe in that now.
*  We've done experiments. You have to infer it from incomplete knowledge, you're saying. Yeah.
*  That's right. Yeah, that's right. So those are kind of, so that's an example of using
*  very lab-centered, non-naturalistic, non-ethological experiments, but there the hypothesis is super
*  clear, it's computationally super explicit, it's this function or that function. And then you do
*  very precise experiments to adjudicate and you fit a bunch of models and you say like, look,
*  this is what it turns out to be. It's actually easier. It's easier to extract the PDF than a
*  hazard rate. I think it fits the data better. It works for hearing, touch and seeing and so on and
*  so forth. So we can make a contribution by saying our new hypothesis is the fundamental
*  computational building block isn't function X, it's function Y. So that's useful. On the other hand,
*  could you do that? So I think that you can make good contributions with these super reductivist
*  lab-based non-ethological. On the other hand, so take the language case. There are increasing
*  experiments and you were alluding to this, where you listen to naturalistic stuff and you use large
*  language models to sort of get at the nitty gritty. And there you can actually make pretty nice.
*  So one of the very, a paper I'm very happy with, I think is very cool was a part of the dissertation
*  of Laura Williams. And she was a graduate student at NYU. She's now just started as a faculty member
*  at Stanford. She's an extremely accomplished neuro linguistics scholar. She did in one of
*  her thesis experiments with naturalistic narratives. So you're doing nothing, you're listening,
*  you're sitting there in the scanner, you're listening to a bunch of stories.
*  But she had a very particular theoretical, theoretically motivated questions. What are
*  you actually tracking and how much of it at any given moment? And so one of the very interesting
*  and beautiful data she found really that's best seen in naturalistic ecological experimentation
*  is as you go through the stream of speech, the, you know, of course there's phoneme by phoneme by
*  syllable by syllable. Let's take the phoneme level, the single speech sounds.
*  How many at a time do you have access to? So she was able to show some very beautiful decoding
*  experiments on neurophysiological data that at any given moment you can actually grab onto three.
*  You can successfully at any time point that you sample here, as it were, or, you know,
*  grab onto for perceptual experience three phonemes as you go through.
*  At the same time, you can keep them separate. That is, they have a separate sort of
*  representational identity. You don't have confusion. It's not that the three become a kind of
*  gimmish of messy, un-separable things. They're actually separable. And so that only works if
*  you have a completely naturalistic case where you don't actually give people individual sounds or
*  individual words. You have to have the stream happen. So you can make a contribution to our
*  understanding of the spoken language recognition by doing a neuroethologically motivated experiment.
*  So I think there's, again, you got to pick your weapon for the question. What's the question that
*  you're trying to answer? And then, so even in the human case, ecologically valid experimentation
*  and people are trying to have it now walking around and having EEG headsets on and having
*  conversation. I think that's very ambitious and bold. I think sometimes it's a little bit cheesy.
*  But more data collecting. If the question is, well, it might work. It might work.
*  But it is a lot more data collecting for perhaps that unprincipled reasons sometimes.
*  That's the downside. There can be a lot of just, yes, it's unprincipled and often,
*  unless it's theoretically very well developed, it's a lot of data mining without a question.
*  That is, of course, something that there I get pretty unhappy or ungenerous as a colleague or
*  reviewer. So David, it's a Sunday. I know that you take this most of your day to reflect on the
*  benevolent Christian God. I have to go hang out with my benevolent family. So I don't want to
*  keep you much longer. But anything else on your mind that you want to get off your chest? Anything
*  else bothering you? Really, I just wanted to have you on to shoot the shit about your thoughts on
*  the memory thing and then get an update from you. Yeah. No, I think that the look, again,
*  that if there's any theme coming out here, it's that the memory story is so foundational to no
*  matter what aspect you're in in neuroscience or cognitive neuroscience, we have to get a grip on
*  it one way or the other. Whichever team you're on here, I think you're doing, it's an important
*  service that you're doing to the field in the sense that you've got to have many people who
*  are reflecting on this because we have to sort it out. We're just kind of stuck. This is why I wrote
*  this paper about things. We never talked about language of thought, which is a completely
*  different kind of story. Oh, yeah. Oh, we do need to talk about that book. Yeah. That's an interesting
*  philosophical idea, which I think is actually correct. Let's talk about that because I did want
*  to talk about that because it's a huge topic. And so you've written this piece talking about how
*  you think it's correct and some of the reasons why you think it's correct. But within the
*  article, you talk about how it kind of disappeared for a while. And is that true? Was the language
*  of thought prevalent and then discarded and now it's reappearing? Is that a correct story?
*  Yeah, a little bit. I mean, so the language of thought was very prominent in the sort of middle
*  age philosophy. And the idea was, well, you have to, you know, we didn't. Well, how do you think?
*  How does it actually work at all? What format do you think in? And then there were in the
*  philosophical literature, most notably by the philosopher Jerry Fodor, he sort of reignited
*  that notion in the 60s and 70s saying like, look, you know, if this is a thing, if we're trying to
*  figure out, I mean, he was really wearing his more cognitive science hat, less his philosophy hat.
*  If there is such a thing of, you know, we were able to think it's very unlikely to be, you know,
*  it has to be a pretty abstract format. And let's just call it the unfortunately he used the
*  expression language of thought, unfortunately, everyone think, oh, he means language, which is
*  precisely what he didn't mean. That's a kind of bummer of a misnomer. He means, you know, formal
*  system of thinking. And he was trying to develop a computational theory, say like, look, for the
*  kinds of things we do, you need stuff like variables, functions. And so we just, something like
*  predicate logic or very, not a very bold claim. But it has things like variables, it is very
*  abstract, it means you insert values into functions and so on. And, but it was a very interesting idea.
*  And it also said that, look, there's aspects of thought that are separate from languages,
*  separate from other domains are separate from just, you know, let's say mental imagery,
*  stuff like that. And it's a pretty interesting idea. And then that idea became pretty unpopular
*  well, it wasn't really addressed at all. But then the neuroscience world basically said,
*  look, it's horse shit. Why is that? It can't be implemented. It's the kind of stuff that simply
*  we don't, you know, it's so far away from, you know, our notion of sensory systems or neural
*  computation. It just doesn't, it such a thing can't really be. It's a, it's a silly idea. But in the
*  last few years, people have been sort of thinking about it again, thinking like, actually, we're
*  trying to get our head around the relationship between thinking, you know, language, other forms
*  of representation. And so Nina Kazanina, our motivation was very straightforward. We think
*  it's a very, you know, whether it's right or wrong, it's a very interesting hypothesis. And we simply,
*  as we wrote the paper, we just disagree with the argument that it can't be done. And the way we
*  construct that argument is super straightforward. We say here, what were the requirements for a
*  language of thought? And then this is what you would have to have. Okay, guess what? Here's an
*  example. Here's a bunch of hippocampal cell types that do exactly what you think can't be done. They
*  meet all the criteria. So there's, you know, filler role, independence, abstraction, scaling,
*  and so on. So it's simply false to assert that it can't be done. Neural systems already have
*  precisely that kind of architecture. It doesn't. And we don't argue that thought is spatial or it's
*  all hippocampal. That's not we wanted, we simply wanted to provide examples, say, look, here's a
*  couple of cell types. They're extremely well evidenced, well known, there's no, you know,
*  there's a fact of the matter. They, they embody precisely those things functionally that are
*  ostensibly not possible. Therefore, it's a bad argument. And the language of thought is, in fact,
*  absolutely nor really possible. Our job is to figure out is it, you know, how do you do it? Where
*  is it done? And so on and so forth. But I think that there's a growing interest in, you know, how
*  this thinking can we begin to get a thinking which is kind of internal, and it's in part separate from
*  language, right? There are aspects that are just ineffable. They can't be externalized for language,
*  because language and thought are dissociable. And so there's, so that's a fun and interesting way
*  to think about it. So our demonstration is a very short and easy paper that simply says, hey,
*  the entire endorhinal and hippocampal system is full of exactly the cells is doing it. So
*  go back and try again, different arguments. But your argument is not you're not pointing to the
*  so just a list of all the different cell types, boundary cells, boundary vector cells, object
*  cells, etc. You're not pointing at those and saying, these cells are doing language of thought,
*  you're just using it as a reflection, a reflection and saying, look, this is language of thought,
*  language of thought type, or like or allowed process is is being reflected in the activity
*  of these neurons. That's exactly right. No, it's exactly as you're saying. This is simply, I mean,
*  one can then have different debates. And some people say, look, oh, we think a lot of thinking
*  is in fact spatial and so on. Because that's not the point. Our argument is precisely as you
*  summarize it, we're showing a principle. Here's the type of operation that cells have to do.
*  Here's an example of them. Best wishes.
*  So where are you with that? Are you going to are you continuing that? Or is that was it really just,
*  hey, everybody, look, and then you're moving on?
*  Well, no, I mean, of course, we so Nina Kazanina, who's now going to be a professor, she's in
*  Bristol, she's not going to be a professor in Geneva is going to continue that I'm going to
*  continue it. But it's that's for young people. That's young person's game. It's very difficult
*  to but it's again, it's a case where there are well developed, theoretical and computationally
*  explicit ideas about what kind of you know, but let's say predicate, predicate calculus or
*  something like that. And there's nothing you know, for anyone who studies vision or navigation,
*  this is not a surprise. You have to do mathy type stuff. Yeah, this is not surprising why this is
*  considered so outrageous baffles me since to even get you know, from here to wherever you're going
*  with your family is requires all those things. This is not like, I don't get it. I just don't
*  get why this is so objectionable. When you you reference a few different kind of review papers
*  that touch on language of thought as well that I guess they're all arguing that hey, we do need to
*  Yeah, one section one starts the reemergence of the language of thought. This is from a
*  mental bomb at all. And there are a couple reviews that you can do.
*  Right. Yeah, there's a reason I mean, basically, in the last couple of years, there's been
*  really kind of acknowledgments that this has been that it's a very important hypothesis about how
*  the cognitive apparatus is organized. And we've sort of now blown and it's time to kind of rethink
*  very carefully what's going on. And so yeah, Quill, Dydone, Mandelbaum, Kazan, others are saying
*  like, hey, there's there's actually a game in town. And certainly for cognitive science,
*  psychology, philosophy, and let's actually see if it has very clear and good and testable
*  implications for brain science. And I think I'm totally on board with that and excited to see it
*  kind of come back because, again, just because people wrote it 800 years ago, doesn't mean it
*  was idiotic. It was people who thought very carefully about thinking, they didn't have the
*  apparatus we have, but they said there's there's something, you know, something smells funny,
*  we have to figure out how we do this. How do you think they only had to copy theory of mind,
*  they had nothing else, no imaging, no, no optogenetics, no single cell transcriptomics,
*  just thinking cat. But what about how do you think of this in terms of the recent popularity
*  of dynamics and attractors and state spaces? How do you think of that and with regard to or
*  compared to something like the symbolic operations needed for a language of thought to occur?
*  Do we need, I mean, I don't quite understand why this should be mutually exclusive. I mean,
*  there might be approaches that solve different kinds of sub problems or different problems in
*  general. I mean, I think that the dynamic stuff is super interesting, I mean, and important to
*  pursue. And that's, I don't see a principled conflict to having that kind of machinery and
*  having symbolic computation implemented. I just don't see why that should be a non starter for
*  both. That doesn't doesn't mean like, look, I mean, look, look how weird stuff is in the brain
*  step. I mean, totally closed configuration, little nuclei that do like very, you know, like,
*  people don't know. Do we argue about that? I really urge you or urge you motivate you invite
*  you to consider inviting someone like Katherine Carr. So I see from her work on evolution and
*  neuroethnology, because there you just see a kind of generosity of spirit and biological
*  principles that shows you how you can actually link levels and not worry about like, maybe this
*  is a dynamics kind of explanation over here, but we really need symbolic computation to solve this
*  equation. And there's not, I mean, you know, brains are complicated place, right? So I don't see a
*  that they rule each other out, and they might not be solving the same kind of stuff.
*  And both seem extremely important and interesting to pursue.
*  Okay, David, well, I appreciate your generous spirit. As always, thanks for thanks for coming
*  on. You kind of did it on a whim. I just I got that email from you, you sent me that paper,
*  I thought I should just ask him and come back on. So I appreciate you sharing your thoughts.
*  That's absolutely it's fun. It's fun to talk about what we do. And it's entertaining. Now you go
*  play. I'm gonna go to the beach. All right. I think I'm gonna go to Rocka Weaving Threatness.
*  So okay, happy beaching. Good talking. Bye, ball.
*  I alone produce brain inspired. If you value this podcast, consider supporting it through Patreon
*  to access full versions of all the episodes and to join our discord community. Or if you want to
*  learn more about the intersection of neuroscience and AI, consider signing up for my online course
*  Neuro AI, the quest to explain intelligence. Go to brand inspired co to learn more. To get in touch
*  with me email paul at brand inspired co. You're hearing music by the new year. Find them at the
*  new year.net. Thank you. Thank you for your support. See you next time.
*  Bye.
