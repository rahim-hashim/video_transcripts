---
Date Generated: June 07, 2025
Transcription Model: whisper medium 20231117
Length: 4822s
Video Keywords: ['60 minutes', 'artificial intelligence', 'cbs news', '60 minutes full episodes', 'ai', 'artificial intelligence robot', 'google', 'google ai', 'ai medicine future', 'ai teaching', 'ai warfare', 'artificial intelligence documentary']
Video Views: 68032
Video Rating: None
Video Description: From April, a look at what's next for AI at Google DeepMind. From December, a story on Khanmigo, the AI tutor for students. From May, a story about the "digital bridge" helping paralyzed patients. From December, a report on the harm of AI "nudify" sites that create fake nudes. From November, a look at how training AI takes a toll on Kenyan workers. And from May, reports on the future of warfare.
#news #artificialintelligence #technology 
"60 Minutes" is the most successful television broadcast in history. Offering hard-hitting investigative reports, interviews, feature segments and profiles of people in the news, the broadcast began in 1968 and is still a hit, over 50 seasons later, regularly making Nielsen's Top 10.
Subscribe to the "60 Minutes" YouTube channel: https://youtube.com/60minutes
Watch full episodes: https://cbsn.ws/1Qkjo1F
Get more "60 Minutes" from "60 Minutes: Overtime": https://cbsnews.com/60-minutes/overtime/
Follow "60 Minutes" on Instagram: https://instagram.com/60minutes/
Like "60 Minutes" on Facebook:https://facebook.com/60minutes
Follow "60 Minutes" on Twitter: https://twitter.com/60Minutes
Subscribe to our newsletter: https://cbsnews.com/newsletters/
Download the CBS News app: https://cbsnews.com/mobile/
Try Paramount+ free: https://paramountplus.com/?ftag=PPM-05-10aeh8h
For video licensing inquiries, contact: licensing@veritone.com
0:00 Intro
0:11 Demis Hassabis
13:57 A Tutor for Every Student
27:07 To Walk Again 
40:27 Unveiling
53:48 Humans in the Loop
1:07:08 The Future of Warfare
---

# Artificial intelligence reports from this season | 60 Minutes Full Episodes
**CBS - 60 Minutes:** [June 07, 2025](https://www.youtube.com/watch?v=VAzKqh00g3c)
*  When Demis Hasabas won the Nobel Prize last year, he celebrated by playing poker with [[00:00:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=0.0s)]
*  a world champion of chess. [[00:00:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=19.2s)]
*  Hasabas loves a game, which is how he became a pioneer of artificial intelligence. [[00:00:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=22.0s)]
*  The 48-year-old British scientist is co-founder and CEO of Google's AI powerhouse called [[00:00:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=28.58s)]
*  DeepMind. [[00:00:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=35.339999999999996s)]
*  We met two years ago when chatbots announced a new age. [[00:00:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=37.019999999999996s)]
*  Now Hasabas and others are chasing what's called artificial general intelligence, a [[00:00:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=41.46s)]
*  silicon intellect as versatile as a human but with superhuman speed and knowledge. [[00:00:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=47.66s)]
*  After his Nobel and a knighthood from King Charles, we hurried back to London to see [[00:00:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=54.34s)]
*  what's next from a genius who may hold the cards of our future. [[00:00:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=59.78s)]
*  What's always guided me and the passion I've always had is understanding the world around [[00:01:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=66.30000000000001s)]
*  us. [[00:01:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=71.18s)]
*  I've always been, since I was a kid, fascinated by the biggest questions, you know, the meaning [[00:01:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=72.18s)]
*  of life, the nature of consciousness, the nature of reality itself. [[00:01:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=77.62s)]
*  I've loved reading about all the great scientists who worked on these problems and the philosophers [[00:01:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=82.58s)]
*  and I wanted to see if we could advance human knowledge. [[00:01:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=87.46s)]
*  And for me, my expression of doing that was to build what I think is the ultimate tool [[00:01:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=91.58s)]
*  for advancing human knowledge, which is AI. [[00:01:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=95.97999999999999s)]
*  We sat down in this room two years ago and I wonder if AI is moving faster today than [[00:01:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=99.02s)]
*  you imagined. [[00:01:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=106.82s)]
*  It's moving incredibly fast. [[00:01:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=108.69999999999999s)]
*  I think we are on some kind of exponential curve of improvement. [[00:01:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=110.7s)]
*  Of course, the success of the field in the last few years has attracted even more attention, [[00:01:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=114.53999999999999s)]
*  more resources, more talent. [[00:01:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=119.58s)]
*  So that's adding to this exponential progress. [[00:02:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=121.3s)]
*  Exponential curve, in other words, straight up. [[00:02:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=125.98s)]
*  Yep, straight up and increasing speed of progress. [[00:02:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=127.82s)]
*  Start. [[00:02:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=131.54s)]
*  We saw the progress... [[00:02:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=133.04s)]
*  Hello, Scott. [[00:02:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=134.42s)]
*  It's nice to see you again. [[00:02:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=135.42s)]
*  An artificial companion that can see and hear and chat about anything. [[00:02:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=137.06s)]
*  Early chatbots learned only the Internet. [[00:02:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=143.73999999999998s)]
*  An app called Astra also takes in the world. [[00:02:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=146.42s)]
*  Do we call her she? [[00:02:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=150.57999999999998s)]
*  It's a good question. [[00:02:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=151.57999999999998s)]
*  I'm not sure we all know the answer yet. [[00:02:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=152.57999999999998s)]
*  Bebo Shu is product manager for Project Astra, an app in a new generation of chatbots that [[00:02:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=156.06s)]
*  interpret the world with their own eyes. [[00:02:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=163.66s)]
*  We challenged Astra with virtual paintings we chose and showed to Astra for the first [[00:02:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=167.1s)]
*  time. [[00:02:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=173.06s)]
*  This is July Hay by Thomas Hart Benton from 1942. [[00:02:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=174.06s)]
*  How about this one? [[00:02:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=178.85999999999999s)]
*  That is The Virgin of Charity by El Greco. [[00:03:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=180.26s)]
*  That painting is Automat by Edward Hopper. [[00:03:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=183.42s)]
*  The person in the painting, what emotion is she exhibiting? [[00:03:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=186.3s)]
*  The subject in the painting appears pensive and contemplative, her expression suggesting [[00:03:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=191.94s)]
*  a sense of solitude. [[00:03:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=196.28s)]
*  Can you create a story around this picture? [[00:03:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=198.34s)]
*  It's a chilly evening in the city, a Tuesday perhaps. [[00:03:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=202.82s)]
*  The woman, perhaps named Eleanor, sits alone in the diner. [[00:03:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=205.82s)]
*  She is feeling melancholy due to the uncertainty of her future and the weight of unfulfilled [[00:03:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=208.66s)]
*  dreams. [[00:03:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=212.98s)]
*  The scene freezes in time, only the flow of ideas moving onward. [[00:03:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=213.98s)]
*  That line, only the flow of ideas moving onward? [[00:03:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=218.7s)]
*  I wish I'd written that. [[00:03:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=223.1s)]
*  And did we hear a limit to Astra's patience? [[00:03:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=225.42s)]
*  What was that fictional conversation about? [[00:03:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=229.82s)]
*  Ah, in the story I imagined, Eleanor and her friend talked about their shared dreams and [[00:03:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=232.22s)]
*  the challenges of pursuing them. [[00:03:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=237.62s)]
*  Something about the way you said ah made me wonder if you were getting bored. [[00:03:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=239.89999999999998s)]
*  I apologize if my tone came across that way. [[00:04:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=243.98s)]
*  My aim is always to engage thoughtfully. [[00:04:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=246.78s)]
*  And she said well I'm sorry if you don't like my tone. [[00:04:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=250.14000000000001s)]
*  Wow, well you see. [[00:04:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=253.42000000000002s)]
*  What's happening there? [[00:04:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=255.26s)]
*  Well that's interesting. [[00:04:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=256.26s)]
*  That's again a challenge with these systems as they act in the moment with the context [[00:04:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=257.26s)]
*  that's around them and that may have never been tested before. [[00:04:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=261.8s)]
*  He's often surprised because AI programs are sent out on the internet to learn for themselves. [[00:04:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=264.94s)]
*  They can return later with unexpected skills. [[00:04:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=272.54s)]
*  So we have theories about what kinds of capabilities these systems will have. [[00:04:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=276.5s)]
*  That's obviously what we try to build into the architectures. [[00:04:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=280.98s)]
*  But at the end of the day, how it learns, what it picks up from the data is part of [[00:04:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=283.66s)]
*  the training of these systems. [[00:04:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=288.46s)]
*  We don't program that in. [[00:04:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=290.06s)]
*  It learns like a human being would learn. [[00:04:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=291.5s)]
*  So new capabilities or properties can emerge from that training situation. [[00:04:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=294.94s)]
*  You understand how that would worry people. [[00:05:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=300.34s)]
*  Of course. [[00:05:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=302.62s)]
*  The duality of these types of systems. [[00:05:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=303.82s)]
*  They're able to do incredible things, go beyond the things that we're able to design ourselves [[00:05:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=305.98s)]
*  or understand ourselves. [[00:05:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=312.58s)]
*  But of course the challenge is making sure that the knowledge databases they create, [[00:05:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=314.5s)]
*  we understand what's in them. [[00:05:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=320.14s)]
*  Now DeepMind is training its AI model called Gemini to not just reveal the world but to [[00:05:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=322.06s)]
*  act in it, like booking tickets and shopping online. [[00:05:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=329.16s)]
*  It's a step toward AGI, artificial general intelligence, with the versatility of a human [[00:05:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=335.24s)]
*  mind. [[00:05:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=342.56s)]
*  On track for AGI? [[00:05:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=344.04s)]
*  In the next five to ten years, I think. [[00:05:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=345.04s)]
*  And in 2030 you will have what? [[00:05:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=348.08000000000004s)]
*  Well, we'll have a system that really understands everything around you in very nuanced and [[00:05:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=350.0s)]
*  deep ways and kind of embedded in your everyday life. [[00:05:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=357.24s)]
*  Embedded like Astra in eyeglasses. [[00:06:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=361.92s)]
*  What can you tell me about this building I'm looking at? [[00:06:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=364.96000000000004s)]
*  This is the Cole Drops Yard, a shopping and dining district. [[00:06:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=367.96000000000004s)]
*  She sees what I see. [[00:06:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=371.28000000000003s)]
*  There's a speaker in the earpiece only I can hear. [[00:06:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=373.04s)]
*  What was it originally before it became shops? [[00:06:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=376.36s)]
*  The Cole Drops Yard was originally a set of Victorian Cole warehouses used to receive [[00:06:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=379.52s)]
*  and distribute coal across London. [[00:06:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=383.94s)]
*  Was coal ever a problem for the environment in London? [[00:06:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=386.24s)]
*  Yes. [[00:06:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=389.96000000000004s)]
*  Coal was a significant source of air pollution in London, particularly during the Industrial [[00:06:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=390.96000000000004s)]
*  Revolution. [[00:06:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=395.36s)]
*  It occurred to us that the only thing we contributed to this relationship were legs, which will [[00:06:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=396.48s)]
*  also soon be engineered. [[00:06:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=402.8s)]
*  I also think another big area will be robotics. [[00:06:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=405.48s)]
*  I think it will have a breakthrough moment in the next couple of years where we'll have [[00:06:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=408.04s)]
*  of maybe humanoid robots or other types of robots that can start really doing useful [[00:06:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=412.79999999999995s)]
*  things. [[00:06:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=418.4s)]
*  For example, researchers Alex Lee and Giulia Vasani showed us a robot that understands [[00:06:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=419.47999999999996s)]
*  what it sees and reasons its way through vague instructions. [[00:07:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=427.28s)]
*  Put the blocks whose color is the combination of yellow and blue into the matching color [[00:07:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=433.67999999999995s)]
*  ball. [[00:07:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=440.12s)]
*  The combination of yellow and blue is green and it figured that out. [[00:07:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=441.12s)]
*  It's reasoning. [[00:07:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=449.12s)]
*  Yep, definitely, yes. [[00:07:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=450.12s)]
*  The toys of Demis Hisabas's childhood weren't blocks but chess pieces. [[00:07:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=451.88s)]
*  At 12 he was the number two champion in the world for his age. [[00:07:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=458.44s)]
*  This passion led to computer chess, video games and finally, thinking machines. [[00:07:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=463.34000000000003s)]
*  He was born to a Greek Cypriot father and Singaporean mother. [[00:07:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=469.84s)]
*  Cambridge, MIT, Harvard, he's a computer scientist with a PhD in neuroscience because he reasoned [[00:07:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=474.28s)]
*  he had to understand the human brain first. [[00:08:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=483.59999999999997s)]
*  Are you working on a system today that would be self-aware? [[00:08:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=487.15999999999997s)]
*  I don't think any of today's systems to me feel self-aware or conscious in any way. [[00:08:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=491.79999999999995s)]
*  Obviously everyone needs to make their own decisions by interacting with these chatbots. [[00:08:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=498.08s)]
*  I think theoretically it's possible. [[00:08:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=502.4s)]
*  But is self-awareness a goal of yours? [[00:08:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=504.28s)]
*  Not explicitly, but it may happen implicitly. [[00:08:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=507.32s)]
*  These systems might acquire some feeling of self-awareness, that is possible. [[00:08:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=509.71999999999997s)]
*  I think it's important for these systems to understand you, self and other and that's [[00:08:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=514.3199999999999s)]
*  probably the beginning of something like self-awareness. [[00:08:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=519.8s)]
*  But he says if a machine becomes self-aware, we may not recognize it. [[00:08:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=523.98s)]
*  I think there's two reasons we regard each other as conscious. [[00:08:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=530.02s)]
*  One is that you're exhibiting the behavior of a conscious being, very similar to my behavior. [[00:08:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=533.54s)]
*  But the second thing is you're running on the same substrate. [[00:08:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=538.98s)]
*  We're made of the same carbon matter with our squishy brains. [[00:09:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=541.74s)]
*  Now obviously with machines, they're running on silicon. [[00:09:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=545.54s)]
*  So even if they exhibit the same behaviors and even if they say the same things, it doesn't [[00:09:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=548.22s)]
*  necessarily mean that this sensation of consciousness that we have is the same thing they will have. [[00:09:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=553.24s)]
*  Has an AI engine ever asked a question that was unanticipated? [[00:09:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=559.9s)]
*  Not so far that I've experienced. [[00:09:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=564.96s)]
*  And I think that's getting at the idea of what's still missing from these systems. [[00:09:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=567.04s)]
*  They still can't really yet go beyond asking a new novel question or a new novel conjecture [[00:09:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=571.32s)]
*  or coming up with a new hypothesis that has not been thought of before. [[00:09:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=578.08s)]
*  They don't have curiosity. [[00:09:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=583.16s)]
*  No, they don't have curiosity and they're probably lacking a little bit in what we would [[00:09:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=584.16s)]
*  call imagination and intuition. [[00:09:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=588.4s)]
*  But they will have greater imagination, he says, and soon. [[00:09:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=590.52s)]
*  I think actually in the next maybe five to ten years, I think we'll have systems that [[00:09:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=594.8s)]
*  are capable of not only solving a important problem or conjecture in science, but coming [[00:09:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=599.04s)]
*  up with it in the first place. [[00:10:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=605.5s)]
*  Solving an important problem won Hasabas a Nobel Prize last year. [[00:10:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=608.08s)]
*  He and colleague John Jumper created an AI model that deciphered the structure of proteins. [[00:10:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=613.5s)]
*  Proteins are the basic building blocks of life. [[00:10:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=621.5200000000001s)]
*  So everything in biology, everything in your body depends on proteins. [[00:10:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=624.0400000000001s)]
*  You know, your neurons firing, your muscle fibers twitching. [[00:10:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=627.26s)]
*  It's all mediated by proteins. [[00:10:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=630.12s)]
*  Different 3D protein structures like this are so complex, less than 1% were known. [[00:10:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=632.72s)]
*  Mapping each one used to take years. [[00:10:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=639.44s)]
*  DeepMind's AI model did 200 million in one year. [[00:10:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=643.4s)]
*  Now Hasabas has AI blazing through solutions to drug development. [[00:10:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=648.64s)]
*  So on average, it takes, you know, ten years and billions of dollars to design just one [[00:10:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=655.08s)]
*  drug. [[00:10:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=659.5600000000001s)]
*  We reduce that down from years to maybe months or maybe even weeks, which sounds incredible [[00:11:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=660.56s)]
*  today, but that's also what people used to think about protein structures. [[00:11:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=665.04s)]
*  It would revolutionize human health. [[00:11:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=668.4399999999999s)]
*  And I think one day maybe we can cure all disease with the help of AI. [[00:11:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=670.2399999999999s)]
*  The end of disease? [[00:11:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=674.9599999999999s)]
*  I think that's within reach. [[00:11:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=676.8399999999999s)]
*  Maybe within the next decade or so. [[00:11:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=678.5999999999999s)]
*  I don't see why not. [[00:11:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=680.4799999999999s)]
*  Demis Hasabas told us AI could lead to what he calls radical abundance, the elimination [[00:11:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=682.1199999999999s)]
*  of scarcity. [[00:11:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=689.24s)]
*  But he also worries about risk. [[00:11:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=690.76s)]
*  There's two worries that I worry about. [[00:11:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=693.24s)]
*  One is that bad actors, human users of these systems, repurpose these systems for harmful [[00:11:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=694.84s)]
*  ends. [[00:11:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=702.08s)]
*  Then the second thing is the AI systems themselves, as they become more autonomous and more powerful, [[00:11:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=703.08s)]
*  can we make sure that we can keep control of the systems, that they're aligned with [[00:11:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=707.24s)]
*  our values, they're doing what we want that benefits society, and they stay on guardrails. [[00:11:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=710.64s)]
*  Those are safety limits built into the system. [[00:11:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=717.24s)]
*  And I wonder if the race for AI dominance is a race to the bottom for safety. [[00:12:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=720.36s)]
*  So that's one of my big worries, actually, is that, of course, all of this energy and [[00:12:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=726.4s)]
*  racing and resources is great for progress, but it might incentivize certain actors in [[00:12:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=731.5600000000001s)]
*  that to cut corners. [[00:12:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=737.32s)]
*  And one of the corners that can be shortcut would be safety and responsibility. [[00:12:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=739.88s)]
*  So the question is, how can we coordinate more as leading players, but also nation-states [[00:12:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=744.04s)]
*  even? [[00:12:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=751.04s)]
*  I think this is an international thing. [[00:12:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=752.04s)]
*  AI is going to affect every country, everybody in the world. [[00:12:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=753.28s)]
*  So I think it's really important that the world and the international community has [[00:12:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=756.9599999999999s)]
*  a say in this. [[00:12:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=760.8s)]
*  Can you teach an AI agent morality? [[00:12:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=762.12s)]
*  I think you can. [[00:12:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=765.8399999999999s)]
*  They learn by demonstration. [[00:12:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=767.0799999999999s)]
*  They learn by teaching. [[00:12:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=768.88s)]
*  And I think that's one of the things we have to do with these systems is to give them a [[00:12:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=771.28s)]
*  value system and a guidance and some guardrails around that, much in the way that you would [[00:12:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=775.48s)]
*  teach a child. [[00:13:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=780.3199999999999s)]
*  Google DeepMind is in a race with dozens of others striving for artificial general intelligence, [[00:13:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=782.36s)]
*  so human that you can't tell the difference. [[00:13:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=789.36s)]
*  Which made us think about Demis Hasaba's signing the Nobel Book of Laureates. [[00:13:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=793.12s)]
*  When does a machine sign for the first time? [[00:13:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=798.88s)]
*  And after that, will humans ever sign it again? [[00:13:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=802.68s)]
*  I think in the next steps, it's going to be these amazing tools that enhance our almost [[00:13:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=806.96s)]
*  every endeavor we do as humans. [[00:13:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=811.64s)]
*  And then beyond that, when AGI arrives, I think it's going to change pretty much everything [[00:13:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=815.28s)]
*  about the way we do things. [[00:13:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=820.68s)]
*  And it's almost, I think we need new great philosophers to come about, hopefully in the [[00:13:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=822.68s)]
*  next five, ten years, to understand the implications of this. [[00:13:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=827.12s)]
*  We're about to show you a technological innovation that could one day change the way every child [[00:13:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=838.08s)]
*  in every school in America is taught. [[00:14:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=843.64s)]
*  It's an online tutor powered by artificial intelligence designed to help teachers be [[00:14:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=846.24s)]
*  more efficient and students learn more effectively. [[00:14:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=851.32s)]
*  It's called Conmigo. [[00:14:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=854.84s)]
*  Conmigo means with me in Spanish. [[00:14:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=856.88s)]
*  And Con is its creator, Sal Con, the well-known founder of Con Academy, whose lectures and [[00:14:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=859.2s)]
*  educational software have been used for years by tens of millions of students and teachers [[00:14:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=865.2800000000001s)]
*  in the US and around the world. [[00:14:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=870.48s)]
*  Conmigo was built with the help of OpenAI, the creator of ChatGPT. [[00:14:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=872.88s)]
*  Its potential is staggering, but it's still very much a work in progress. [[00:14:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=878.0400000000001s)]
*  It's being piloted in 266 school districts in the US in grades three through 12. [[00:14:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=882.8399999999999s)]
*  We went to Hobart High School in Indiana to see how it works. [[00:14:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=889.3199999999999s)]
*  Good morning. [[00:14:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=893.16s)]
*  Just a normal day in chem, right? [[00:14:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=894.16s)]
*  At eight in the morning, Melissa Higginson knows it's not always easy to get 30 high [[00:14:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=896.4799999999999s)]
*  schoolers excited about chemistry. [[00:15:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=900.68s)]
*  Are you ready? [[00:15:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=902.92s)]
*  Are you ready? [[00:15:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=903.92s)]
*  All right. [[00:15:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=904.92s)]
*  That's what I want to hear. [[00:15:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=905.92s)]
*  But these days, she has help. [[00:15:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=907.68s)]
*  This is acetic acid. [[00:15:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=909.8s)]
*  The pipette's not going to fill all the way. [[00:15:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=911.16s)]
*  That lesson Higginson has displayed behind her and is explaining to her ninth and tenth [[00:15:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=913.4s)]
*  graders was created with the assistance of Conmigo. [[00:15:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=917.52s)]
*  She told the AI tutor she wanted a four-day course in which her students would investigate [[00:15:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=921.52s)]
*  the physical and chemical properties of matter. [[00:15:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=926.24s)]
*  This next section is your research section. [[00:15:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=929.1s)]
*  It took Conmigo minutes to come up with a detailed lesson plan that would have taken [[00:15:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=931.24s)]
*  Higginson a week to create. [[00:15:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=935.72s)]
*  And the students have Conmigo on their laptops, too, ready to help them with their questions. [[00:15:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=938.7199999999999s)]
*  We have a couple of questions that we need to ask Conmigo. [[00:15:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=946.7199999999999s)]
*  So for example, I asked it what are three examples of acids and if I wanted to know [[00:15:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=950.24s)]
*  more... [[00:15:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=955.8s)]
*  So it gave you three examples of acids, like hydrochloric acid, citric, and sulfur. [[00:15:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=956.8s)]
*  Yeah, like, can you give me more examples? [[00:16:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=960.76s)]
*  And if I wanted to know even more, I could ask it what specifically some of the acids [[00:16:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=963.68s)]
*  do. [[00:16:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=967.68s)]
*  So it's giving you acids and then it's asking you a question. [[00:16:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=968.68s)]
*  Can you think of any other household items that might contain acid? [[00:16:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=971.68s)]
*  Yeah, so it wants to help you understand what it's telling you and not just give you the [[00:16:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=975.0s)]
*  information. [[00:16:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=979.76s)]
*  Finding creative ways to help kids learn is something Sal Khan has been doing since 2005. [[00:16:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=982.4399999999999s)]
*  He had gotten degrees in math, computer science and engineering from MIT and an MBA from Harvard [[00:16:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=988.28s)]
*  and was working as a hedge fund analyst when he started recording math tutorial videos [[00:16:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=994.52s)]
*  in his closet for his young cousins. [[00:16:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1001.04s)]
*  Not long after, with the help of donors including Bill Gates, he quit his career in finance [[00:16:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1006.3199999999999s)]
*  and started the non-profit Khan Academy. [[00:16:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1011.36s)]
*  From the beginning of Khan Academy, the true north was, how do you give more students at [[00:16:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1014.24s)]
*  least approximations of the type of personalization they would get if they had a personal tutor? [[00:16:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1018.92s)]
*  A wealthy family can afford a tutor for their child if every kid could have a private tutor [[00:17:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1023.08s)]
*  that would level the playing field. [[00:17:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1029.36s)]
*  Yeah, that's the dream. [[00:17:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1030.92s)]
*  Co-founders of OpenAI, Greg Brockman and Sam Altman, were fans of Khan Academy and hoped [[00:17:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1032.6s)]
*  to evaluate their AI using Khan's database of test questions and content. [[00:17:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1037.6200000000001s)]
*  So they gave Sal Khan early access to an advanced AI technology that today underpins ChatGPT. [[00:17:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1043.8s)]
*  What did you immediately think? [[00:17:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1051.6s)]
*  It was pretty obvious this technology was going to transform society. [[00:17:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1053.2s)]
*  So it was pretty heady stuff. [[00:17:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1056.6599999999999s)]
*  But on the education side, it was like, wow, people are going to be able to use this for [[00:17:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1059.3999999999999s)]
*  doing deep fakes and fraud and cheat. [[00:17:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1062.72s)]
*  But if used well with the right guardrails, etc., it could also be used to support students, [[00:17:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1067.12s)]
*  to give them more feedback, to support teachers for all this lesson planning and progress [[00:17:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1071.8s)]
*  report writing that they spend hours a week doing. [[00:17:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1077.3999999999999s)]
*  Educators and engineers at Khan Academy used OpenAI's technology to build Khanmigo. [[00:18:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1082.48s)]
*  And for the last year and a half, the teachers and kids at Hobart High School and others [[00:18:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1090.36s)]
*  have been testing it out. [[00:18:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1094.68s)]
*  We sat down with two students from that morning chemistry class, Austin and Abigail, as well [[00:18:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1097.6s)]
*  as Leydon and Maddie, who use Khanmigo in business class, and Lou and Lily, who use [[00:18:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1102.6s)]
*  it in English and for SAT preparation. [[00:18:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1107.3999999999999s)]
*  I heard people at Khan Academy came and asked students to break it. [[00:18:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1110.6s)]
*  Yes. [[00:18:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1114.56s)]
*  That was the fun part. [[00:18:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1115.56s)]
*  Some students would try and trick it into just giving you the answer. [[00:18:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1118.56s)]
*  The superintendent I talked to said that some students were bullying Khanmigo for the answer. [[00:18:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1121.6s)]
*  I think that was the elementary school kids. [[00:18:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1127.48s)]
*  Oh, yeah, okay. [[00:18:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1129.68s)]
*  Blame it on the elementary school kids. [[00:18:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1130.68s)]
*  It's very helpful for those students who maybe don't feel comfortable asking questions within [[00:18:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1133.1200000000001s)]
*  class. [[00:18:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1137.56s)]
*  Does it have a personality? [[00:18:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1138.56s)]
*  It's very much there for you. [[00:19:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1140.16s)]
*  It's very positive. [[00:19:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1144.2s)]
*  It's very reassuring. [[00:19:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1145.64s)]
*  It's getting me thinking, and it's not just giving me an answer. [[00:19:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1147.14s)]
*  Do you ever just want to be like, can you just give me the answer? [[00:19:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1150.28s)]
*  That was the hardest part for me and a lot of other students. [[00:19:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1153.1200000000001s)]
*  Why isn't it giving me answers? [[00:19:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1156.2s)]
*  At the end of the day, that's where your better answer is going to be. [[00:19:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1157.68s)]
*  It's not going to be whatever the AI gives you. [[00:19:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1160.32s)]
*  It's going to be whatever you create. [[00:19:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1162.68s)]
*  So your hypothesis going into the last test is... [[00:19:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1164.64s)]
*  Teachers at Hobart High don't just use Khanmigo to help plan lessons and save dozens of hours [[00:19:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1167.96s)]
*  a week. [[00:19:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1173.0s)]
*  They also monitor their students' understanding of subjects in ways they never could before. [[00:19:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1174.0s)]
*  You can track how a student is actually using Khanmigo. [[00:19:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1179.44s)]
*  Yeah. [[00:19:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1183.32s)]
*  I can click usage, and then if I wanted to pick a specific student, I could come down [[00:19:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1184.32s)]
*  here and really dive into what that student's been looking at Khanmigo. [[00:19:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1189.8s)]
*  This is real time because you saw Abigail this morning looking at acids and bases. [[00:19:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1195.76s)]
*  So wait a minute. [[00:20:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1200.72s)]
*  These are the footprints of Abigail's work. [[00:20:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1201.72s)]
*  These are the footprints of Abigail's work. [[00:20:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1203.0s)]
*  At 8 a.m., she was asking about acids and chemical reactions. [[00:20:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1204.6s)]
*  So even though you may not be hovering over the student at any given moment, you're somewhere [[00:20:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1207.72s)]
*  else in the classroom, you can later check, oh, this is what Abigail was looking at. [[00:20:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1212.2s)]
*  I understand her thought process on why she got these answers. [[00:20:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1216.96s)]
*  Absolutely. [[00:20:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1220.16s)]
*  So it gives me a lot of insight as a teacher in terms of who I need to spend that one-on-one [[00:20:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1221.16s)]
*  time with. [[00:20:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1225.52s)]
*  Maybe Khanmigo throws in a mastery challenge. [[00:20:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1226.52s)]
*  Sound Khan says they won't sell the data they collect through Khanmigo or give it to other [[00:20:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1229.1200000000001s)]
*  tech companies. [[00:20:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1233.6000000000001s)]
*  They do use it, however, to improve Khanmigo's memory and personalization. [[00:20:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1234.8400000000001s)]
*  It'll guide them to sort of what to do first. [[00:20:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1239.3600000000001s)]
*  Sarah Robertson, a former English teacher who's now a Khanmigo product manager, showed [[00:20:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1241.76s)]
*  us a new feature they've developed to help kids write better and think more critically. [[00:20:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1246.1200000000001s)]
*  I found this essay that I wrote. [[00:20:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1250.8400000000001s)]
*  To test it, I gave Khanmigo a paper I wrote in sixth grade about my mom, Gloria Vanderbilt. [[00:20:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1253.88s)]
*  So go ahead and click next, start revising. [[00:21:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1260.2s)]
*  After just 90 seconds, Khanmigo delivered a very detailed evaluation of my essay. [[00:21:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1262.72s)]
*  It liked some of what I wrote. [[00:21:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1268.72s)]
*  The use of a quote to start the essay is effective and sets the tone for the rest of the biography. [[00:21:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1270.64s)]
*  But suggested I should revise several paragraphs and my topic sentence. [[00:21:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1274.72s)]
*  So I'm going to rewrite my sixth grade paper. [[00:21:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1278.68s)]
*  After a few minutes of tweaking. [[00:21:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1281.5200000000002s)]
*  Ask it what it thinks. [[00:21:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1283.6000000000001s)]
*  What do you think? [[00:21:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1284.6000000000001s)]
*  It says connecting childhood events to our later life will make your essay more cohesive [[00:21:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1287.5200000000002s)]
*  and insightful. [[00:21:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1291.68s)]
*  I mean, yeah, it's good advice. [[00:21:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1292.68s)]
*  I can tell you, as a former seventh grade English teacher, when I assigned an essay, [[00:21:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1294.5200000000002s)]
*  I would limit myself to 10 minutes per essay. [[00:21:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1299.52s)]
*  I had 100 students. [[00:21:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1301.96s)]
*  So it would take me 17 hours to give feedback on every single student's first draft. [[00:21:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1303.16s)]
*  The burden that we place on teachers to give that specific, timely, actionable feedback [[00:21:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1309.76s)]
*  is just so great that it's not possible. [[00:21:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1315.32s)]
*  So I've now plugged in. [[00:21:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1317.8s)]
*  To see if Khanmigo could catch me cheating, I asked ChatGPT to write a paragraph about [[00:21:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1319.4s)]
*  my mom and pasted it into my essay. [[00:22:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1324.64s)]
*  I now see that there's a critical flag. [[00:22:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1327.3999999999999s)]
*  Khanmigo immediately sent an alert to Sarah Robertson. [[00:22:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1329.3999999999999s)]
*  It says that you pasted 66 words while revising from an unknown source. [[00:22:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1333.08s)]
*  So if I click on that now, it's going to load your essay and it's going to show me exactly [[00:22:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1337.6799999999998s)]
*  what you just did. [[00:22:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1341.1999999999998s)]
*  I'm so busted. [[00:22:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1342.1999999999998s)]
*  You're busted. [[00:22:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1343.1999999999998s)]
*  Do you want to work with a three digit or a four digit number? [[00:22:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1344.1999999999998s)]
*  Khanmigo is free for all teachers in the U.S., but school districts have to pay up. [[00:22:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1347.4399999999998s)]
*  It's $15 per student per year to cover computation costs, and it's still being improved. [[00:22:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1352.4s)]
*  We got a hint of how Khanmigo might evolve when Greg Brockman, president of OpenAI, stopped [[00:22:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1360.2s)]
*  by Sal Khan's office to show us their new vision technology that'll be available to [[00:22:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1365.96s)]
*  ChatGPT paid subscribers soon. [[00:22:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1371.2800000000002s)]
*  We're preparing a demo for 60 minutes to show people what ChatGPT can do with voice mode [[00:22:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1374.72s)]
*  with vision. [[00:22:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1378.8400000000001s)]
*  I can actually see what someone is doing through live video and interact with them in real [[00:22:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1379.84s)]
*  time. [[00:23:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1384.6399999999999s)]
*  Brockman was talking with it on his phone. [[00:23:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1386.12s)]
*  Got it. [[00:23:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1388.6s)]
*  How about an anatomy lesson? [[00:23:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1389.6s)]
*  You're going to quiz him and ask him to draw whatever body part you want to quiz him on [[00:23:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1391.6s)]
*  and have him label it. [[00:23:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1396.04s)]
*  How does that sound? [[00:23:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1397.04s)]
*  That sounds like a fantastic plan. [[00:23:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1398.04s)]
*  When Brockman pointed his phone's camera at the blackboard, the AI started to quiz me. [[00:23:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1400.52s)]
*  Let's start with the heart. [[00:23:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1405.8s)]
*  Anderson, can you draw and label where the heart is in the body? [[00:23:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1407.52s)]
*  It understood what I was doing, even though my drawing was pretty crude. [[00:23:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1411.8s)]
*  The location is spot on. [[00:23:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1415.6799999999998s)]
*  The brain is right there in the head. [[00:23:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1417.76s)]
*  As for the shape, it's a good start. [[00:23:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1420.2s)]
*  The brain is more of a… [[00:23:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1422.3999999999999s)]
*  Don't patronize me. [[00:23:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1423.6s)]
*  It also seemed to pick up on my anxiety. [[00:23:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1424.72s)]
*  Anderson, how about the liver? [[00:23:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1427.2s)]
*  Give it a shot and show us where you think it's located in the body. [[00:23:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1429.6799999999998s)]
*  Okay, this is a little tough. [[00:23:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1434.6s)]
*  This is how we learn. [[00:23:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1436.6s)]
*  Absolutely no pressure, Anderson. [[00:23:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1438.28s)]
*  I put the liver on the wrong side of the body. [[00:24:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1440.6799999999998s)]
*  Chet GPT corrected me politely. [[00:24:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1443.1599999999999s)]
*  Anderson's placement is close, but it's primarily on the right side, just below the diaphragm. [[00:24:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1446.1599999999999s)]
*  So can you critique this diagram overall? [[00:24:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1453.08s)]
*  Anderson's diagram is a solid effort, especially for an impromptu drawing. [[00:24:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1455.76s)]
*  The AI caught my mistake, but it's not foolproof. [[00:24:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1461.12s)]
*  The formula is simple. [[00:24:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1464.6399999999999s)]
*  One half times the base times the height. [[00:24:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1466.24s)]
*  Watch what happened when Khan asked it to calculate the area of a triangle and intentionally [[00:24:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1468.72s)]
*  misidentified the height. [[00:24:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1473.6s)]
*  Is this the height over here? [[00:24:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1475.28s)]
*  This four? [[00:24:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1476.3999999999999s)]
*  Is that right? [[00:24:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1477.3999999999999s)]
*  The AI said he was right. [[00:24:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1478.3999999999999s)]
*  Yes, that's correct. [[00:24:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1480.0s)]
*  It didn't catch the error, however this technology improves quickly and it is fun to interact with. [[00:24:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1481.8s)]
*  I really, really… [[00:24:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1487.6s)]
*  Greg Brockman asked it to write a song about the formula for the area of a triangle, to [[00:24:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1488.64s)]
*  make it rhyme and sing it using a British accent. [[00:24:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1493.76s)]
*  Absolutely, let's give it a try. [[00:24:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1497.48s)]
*  To find a triangle space, here's what you do. [[00:25:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1500.0400000000002s)]
*  Multiply the base by the height, it's true. [[00:25:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1503.76s)]
*  Then take that product and divide by two. [[00:25:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1507.4s)]
*  Now you've got the area of formula to pursue. [[00:25:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1510.8400000000001s)]
*  How was that? [[00:25:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1516.0800000000002s)]
*  That was really fantastic. [[00:25:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1517.12s)]
*  That's incredible. [[00:25:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1518.84s)]
*  It is. [[00:25:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1521.84s)]
*  It feels like we're in a science fiction book, really. [[00:25:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1522.84s)]
*  It just feels like to actually see it, I'm sort of speechless. [[00:25:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1525.1599999999999s)]
*  The first time you see this stuff, it really does just feel like this magic and almost [[00:25:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1532.24s)]
*  incomprehensible and then after a week, then you start to realize how you can use it. [[00:25:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1535.56s)]
*  That's been one of the really important things about working with Zolland and his team has [[00:25:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1539.8s)]
*  been to really figure out what's the right way to sort of bring this to parents and to [[00:25:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1543.04s)]
*  teachers and to classrooms and to do that in a way so that the students really learn [[00:25:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1547.76s)]
*  and aren't just asking for the answers and that the parents can have oversight and the [[00:25:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1551.48s)]
*  teachers can be involved in that process. [[00:25:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1555.52s)]
*  You can ask a follow-up question. [[00:25:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1557.56s)]
*  Sal Khan hopes this new vision technology can be incorporated into Conmigo and available [[00:25:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1559.28s)]
*  to students and teachers in two to three years. [[00:26:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1565.0s)]
*  But he wants it to undergo more robust testing and meet strict guidelines for privacy and [[00:26:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1568.16s)]
*  data security. [[00:26:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1573.28s)]
*  I can imagine a lot of teachers watching this and thinking, okay, well, this is just going [[00:26:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1574.28s)]
*  to replace me. [[00:26:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1578.16s)]
*  Why would I want this in my classroom? [[00:26:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1579.16s)]
*  It's like a Trojan horse. [[00:26:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1580.5600000000002s)]
*  I'm pretty confident that teaching any job that has a very human-centric element of it [[00:26:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1582.0s)]
*  is as long as it adapts reasonably well in this AI world, they're going to be some of [[00:26:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1589.0s)]
*  the safest jobs out there. [[00:26:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1593.64s)]
*  Do you think there will always be a need for teachers in the classroom talking with [[00:26:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1594.88s)]
*  the student, looking the student in the eye? [[00:26:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1598.2800000000002s)]
*  Oh yeah. [[00:26:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1599.96s)]
*  I mean, that's what I'll always want for my own children and frankly for anyone's children. [[00:26:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1600.96s)]
*  And the hope here is that we can use artificial intelligence and other technologies to amplify [[00:26:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1605.24s)]
*  what a teacher can do so they can spend more time standing next to a student, figuring [[00:26:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1609.8000000000002s)]
*  them out, having a person-to-person connection. [[00:26:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1614.8400000000001s)]
*  Two tens. [[00:26:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1616.88s)]
*  Two tens. [[00:26:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1617.88s)]
*  You got it. [[00:26:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1618.88s)]
*  Good work, Gaila. [[00:26:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1619.88s)]
*  For those who've suffered a traumatic spinal cord injury and are paralyzed, there's rarely [[00:27:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1624.88s)]
*  encouraging news, which is why what's happening in early clinical trials in a research lab [[00:27:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1633.1200000000001s)]
*  in Lausanne, Switzerland is so remarkable. [[00:27:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1638.5600000000002s)]
*  A renowned French neuroscientist, Grégoire Cortin, and Swiss neurosurgeon, Dr. Jocelyne [[00:27:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1641.5600000000002s)]
*  Bloch, have implanted a small stimulation device on the spine of paralyzed patients, [[00:27:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1647.0800000000002s)]
*  helping them once again stand up and walk. [[00:27:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1652.9199999999998s)]
*  What's even more surprising is their newest innovation, which uses an implant in the skull [[00:27:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1656.1599999999999s)]
*  that enables patients to move their paralyzed legs or arms just by thinking about it. [[00:27:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1661.3999999999999s)]
*  When we visited their lab, Neuro Restore, in March, they were working with a 39-year-old [[00:27:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1667.6399999999999s)]
*  woman whose spinal cord was severed six and a half years ago. [[00:27:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1672.44s)]
*  She'd been told she'd never walk again. [[00:27:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1676.6s)]
*  OK. [[00:27:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1679.92s)]
*  You can roll to my side. [[00:28:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1680.92s)]
*  Marta Castiano-Dombey is the most severely paralyzed patient who's enrolled in this [[00:28:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1682.92s)]
*  clinical trial at Neuro Restore to regain mobility in her legs. [[00:28:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1687.68s)]
*  She has no feeling below her waist and is unable to keep her balance. [[00:28:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1693.28s)]
*  Just sitting up on her own is a challenge. [[00:28:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1697.6000000000001s)]
*  You catching on? [[00:28:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1699.96s)]
*  Sure. [[00:28:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1700.96s)]
*  Good. [[00:28:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1701.96s)]
*  In 2018, Marta was a new mom, working at a German tech company when she began training [[00:28:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1702.96s)]
*  with her husband for an Ironman competition. [[00:28:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1708.68s)]
*  She was in the best shape of her life, but during the bike portion of the race, she suffered [[00:28:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1711.96s)]
*  a devastating accident. [[00:28:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1717.0s)]
*  You were found near a tree. [[00:28:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1719.04s)]
*  Near a tree. [[00:28:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1721.3200000000002s)]
*  Yes. [[00:28:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1722.3200000000002s)]
*  And your back hit the tree. [[00:28:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1723.3200000000002s)]
*  We're hypothesizing what happened, right, because nobody saw me. [[00:28:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1724.8s)]
*  So I must have had a pretty tough collision because my spine basically broke like two [[00:28:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1727.8400000000001s)]
*  dimensions. [[00:28:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1732.52s)]
*  Her spinal cord injury was so severe, doctors said there was no sign of nerve connections [[00:28:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1733.8600000000001s)]
*  left to her lower body. [[00:28:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1738.6s)]
*  She'd also broken eight ribs, punctured her lungs, and was bleeding internally. [[00:29:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1740.56s)]
*  She needed emergency surgery, and doctors told her family she might not survive. [[00:29:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1745.74s)]
*  You came out of the surgery, I understand you wrote a message to your mom. [[00:29:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1751.6399999999999s)]
*  So the surgery took about seven to eight hours, and I was intubated. [[00:29:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1757.1999999999998s)]
*  I could not talk. [[00:29:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1763.04s)]
*  And my mom, you can imagine, was in tears. [[00:29:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1764.04s)]
*  And I just wrote to her, I'm strong. [[00:29:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1767.8s)]
*  That strength has been tested. [[00:29:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1771.08s)]
*  Marta spent ten days in intensive care and four and a half months in a rehab hospital, [[00:29:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1773.3999999999999s)]
*  learning to adapt to her new life in a wheelchair. [[00:29:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1778.8799999999999s)]
*  Traditionally, if someone gets a spinal cord injury, what are the treatment options for [[00:29:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1782.24s)]
*  them? [[00:29:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1786.48s)]
*  You have to do a little bit of physiotherapy, get into a wheelchair, and then you go back [[00:29:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1787.48s)]
*  home and that's all. [[00:29:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1791.24s)]
*  That's it? [[00:29:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1792.72s)]
*  That's it. [[00:29:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1793.72s)]
*  For many years, the only option. [[00:29:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1795.1200000000001s)]
*  Dr. Jocelyne Bloch and Grégoire Cortin have been at the forefront of researchers trying [[00:29:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1797.64s)]
*  to expand those options since 2012. [[00:30:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1802.92s)]
*  Their lab near Lake Geneva is a collaboration between the Swiss Federal Institute of Technology, [[00:30:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1806.1200000000001s)]
*  Switzerland's MIT, and the Lausanne University Hospital. [[00:30:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1811.68s)]
*  That's where they've implanted eight paralyzed patients with a device that allows them to [[00:30:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1816.0s)]
*  stimulate their spinal cords, enabling them to stand, take steps with a walker, and lift [[00:30:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1820.48s)]
*  weights. [[00:30:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1827.48s)]
*  Some can even climb stairs. [[00:30:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1829.56s)]
*  They use a button to activate the stimulation. [[00:30:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1832.04s)]
*  And now, thanks to Cortin and Bloch's latest technology, five other patients can move their [[00:30:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1835.92s)]
*  paralyzed limbs using their own thoughts. [[00:30:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1841.0s)]
*  It's called a digital bridge, and it wirelessly connects a patient's brain to their spinal [[00:30:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1844.76s)]
*  cord stimulator. [[00:30:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1850.2s)]
*  Normally, there is a direct communication between the brain and the spinal cord. [[00:30:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1851.44s)]
*  For me to walk, my brain just automatically tells my legs to walk. [[00:30:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1856.44s)]
*  But because of the spinal cord injury, the signal is interrupted. [[00:31:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1861.56s)]
*  So we are aiming to bridge, bypass the injury by having a direct digital connection between [[00:31:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1865.76s)]
*  the brain and the region of the spinal cord that controls leg movement. [[00:31:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1871.8s)]
*  To do that, Dr. Bloch implants a small titanium device originally developed by a French research [[00:31:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1876.28s)]
*  institute in the patient's skull directly over their motor cortex, the area of the brain [[00:31:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1881.46s)]
*  responsible for controlling movement. [[00:31:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1887.2s)]
*  You see you have the 64 electrodes. [[00:31:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1889.84s)]
*  And so each of these is what? [[00:31:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1891.98s)]
*  It's electrodes that are recording populations of neurons underneath. [[00:31:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1894.0s)]
*  And you can immediately see which one are the best correlated to certain movements. [[00:31:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1897.88s)]
*  The hip is here, and then the knee is here, and then the ankle is here, etc. [[00:31:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1904.68s)]
*  When a patient thinks about moving a limb, those electrodes record the brain's activity. [[00:31:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1909.72s)]
*  Then a computer uses artificial intelligence to translate the recordings into instructions [[00:31:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1915.24s)]
*  for the stimulation device implanted on the spinal cord. [[00:32:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1920.64s)]
*  That device sends electrical pulses, activating muscles in the legs or arms. [[00:32:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1924.44s)]
*  All of it happens in about half a second. [[00:32:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1929.92s)]
*  Gert Jan Oskom was the first person to get the digital bridge four years ago after he [[00:32:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1933.0s)]
*  was paralyzed in a bike accident. [[00:32:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1937.8s)]
*  We met him for a walk by Lake Geneva. [[00:32:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1940.2s)]
*  So now the stimulation is on? [[00:32:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1943.02s)]
*  Now it's on, yes. [[00:32:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1944.76s)]
*  Do you feel it at all in your body? [[00:32:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1945.76s)]
*  I do feel a little tingling sensation from the stimulation with my brain. [[00:32:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1947.8s)]
*  His headpiece powers the implant in his skull, and on his walker is the computer. [[00:32:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1954.24s)]
*  It's cumbersome and tiring physically and mentally, but he can walk up to 450 feet. [[00:32:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1959.52s)]
*  It's incredible to me though that you can continue talking with me even though this [[00:32:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1966.68s)]
*  machine is reading the signals from your brain. [[00:32:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1970.8799999999999s)]
*  It's able to discriminate walking and talking at the same time. [[00:32:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1973.36s)]
*  That's incredible. [[00:32:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1978.44s)]
*  For somebody who has not been able to control their movements to suddenly be able to control [[00:33:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1980.28s)]
*  their movement, that's... [[00:33:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1984.8799999999999s)]
*  There is this initial phase of surprise when they realize that they are giving the order [[00:33:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1987.32s)]
*  and it's happening. [[00:33:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1993.6s)]
*  Nice. [[00:33:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1995.6s)]
*  Wow. [[00:33:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1996.6s)]
*  That was me? [[00:33:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1997.6s)]
*  Yes. [[00:33:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1998.6s)]
*  That was you. [[00:33:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=1999.6s)]
*  They're like, did I do that? [[00:33:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2000.6s)]
*  Like, is it me or you actually stimulated? [[00:33:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2002.6s)]
*  Say, no, you did it. [[00:33:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2004.6s)]
*  They think you're pressing a button somewhere and doing it. [[00:33:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2006.3999999999999s)]
*  They don't understand because they've been paralyzed for so many years. [[00:33:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2008.6s)]
*  Ready, started. [[00:33:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2011.6s)]
*  Increasing amplitude. [[00:33:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2012.6s)]
*  Marta got the digital bridge implanted in September. [[00:33:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2013.6s)]
*  She's worked with a team of engineers and physical therapists to figure out how much [[00:33:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2019.28s)]
*  electrical stimulation is needed to move her legs. [[00:33:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2023.6s)]
*  Nice. [[00:33:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2027.36s)]
*  And hop. [[00:33:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2028.36s)]
*  So that's the stimulation, the electrical stimulation is making the leg move. [[00:33:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2030.0s)]
*  Yes, Marta is completely paralyzed. [[00:33:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2034.1999999999998s)]
*  This is the magic cappy. [[00:33:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2036.76s)]
*  But Marta's also had to teach herself to think about moving the exact same way every time. [[00:33:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2038.3999999999999s)]
*  So the AI can recognize her thoughts. [[00:34:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2044.52s)]
*  She practiced at first with this avatar. [[00:34:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2047.28s)]
*  You have to relearn or rethink how to walk. [[00:34:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2050.56s)]
*  Exactly. [[00:34:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2053.96s)]
*  So we were experimenting a little bit. [[00:34:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2054.96s)]
*  What do I think about? [[00:34:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2057.44s)]
*  Is it I think about the hip being contracted? [[00:34:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2058.64s)]
*  Do I think about the knee lifting up? [[00:34:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2061.16s)]
*  Do I think about the ankle? [[00:34:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2063.08s)]
*  To show us how she does that, they disconnected her skull implant from her spinal cord stimulator [[00:34:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2065.04s)]
*  and connected it to this exoskeleton. [[00:34:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2070.72s)]
*  You can control this with your thoughts right now? [[00:34:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2074.1600000000003s)]
*  Yeah. [[00:34:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2075.56s)]
*  If I want to do a right movement, right hip flexion, it does the right hip flexion. [[00:34:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2076.56s)]
*  You're not pressing any buttons or anything, you're just thinking, can you look at me without [[00:34:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2080.44s)]
*  looking at it and just... [[00:34:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2084.6s)]
*  Do a right one, yes. [[00:34:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2085.6s)]
*  I think it works. [[00:34:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2089.56s)]
*  After training with the digital bridge for just two days, Dr. Jo-Celine Bloch and Gregoire [[00:34:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2092.36s)]
*  Cortine, or G as Marta calls him, put her to the test, eager to see if she could take [[00:34:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2097.28s)]
*  some steps. [[00:35:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2103.28s)]
*  Justine and G come in and it's like, okay, show off. [[00:35:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2104.28s)]
*  So what can you do? [[00:35:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2106.7200000000003s)]
*  They said show off? [[00:35:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2107.7200000000003s)]
*  Yeah. [[00:35:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2108.7200000000003s)]
*  Were you ready to show off? [[00:35:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2109.7200000000003s)]
*  I didn't know if I'm able to show off. [[00:35:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2111.6000000000004s)]
*  This was the thing. [[00:35:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2113.7200000000003s)]
*  Using a harness to support about half her body weight and physical therapist to help [[00:35:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2115.96s)]
*  place her feet on the ground, Marta took her first steps. [[00:35:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2120.52s)]
*  Despite having no sensation below her waist, she was able to move her paralyzed legs with [[00:35:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2125.24s)]
*  her thoughts. [[00:35:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2131.08s)]
*  What was that like? [[00:35:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2132.08s)]
*  Gaining some superpower, a power that I did not have before. [[00:35:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2138.2799999999997s)]
*  And now with these implants, I'm a real iron woman. [[00:35:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2143.2799999999997s)]
*  When we were there in March, Marta wasn't able to walk on her own yet, but she said [[00:35:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2151.6s)]
*  she'd already regained something she'd lost. [[00:35:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2156.32s)]
*  It's giving me my perspective back. [[00:35:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2159.56s)]
*  Standing up again and looking people in the eye. [[00:36:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2162.44s)]
*  That's different. [[00:36:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2166.6s)]
*  A difference in how you think about yourself or in how others see you or how you interact [[00:36:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2168.36s)]
*  in the world? [[00:36:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2174.0s)]
*  Everything. [[00:36:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2175.0s)]
*  Everything. [[00:36:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2176.0s)]
*  Everything. [[00:36:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2177.0s)]
*  You leave the hospital on your wheelchair and you notice the different looks. [[00:36:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2179.12s)]
*  Right away you notice. [[00:36:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2185.12s)]
*  Yeah, scared looks. [[00:36:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2186.12s)]
*  Also a lot of smiles that are a little bit too long. [[00:36:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2189.08s)]
*  Those well-meaning smiles reminded Arnaud Robert, who's quadriplegic, how much his life had [[00:36:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2197.16s)]
*  changed. [[00:36:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2202.92s)]
*  As a journalist, he'd spent decades traveling the world, but three years ago he slipped [[00:36:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2203.92s)]
*  on a patch of ice and was instantly paralyzed from the neck down. [[00:36:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2208.56s)]
*  He regained some function in his right arm with physical therapy, but wanted to see if [[00:36:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2212.96s)]
*  the digital bridge could help him with his left. [[00:36:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2217.7200000000003s)]
*  Opening and closing a hand is far more complex than walking. [[00:37:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2221.08s)]
*  It is because of the possibility to access a different muscle individually. [[00:37:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2224.4s)]
*  The hand is tricky with all these different little muscles and it's very subtle. [[00:37:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2229.88s)]
*  But after surgery and training at Cortina Block's lab for eight months, he was able [[00:37:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2236.42s)]
*  to use his left hand to help hold a glass and type. [[00:37:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2241.0s)]
*  Even to be able to move my fingers, this is something that I couldn't do. [[00:37:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2246.76s)]
*  And of course, moving the arm like that, this is something that I couldn't do either. [[00:37:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2251.94s)]
*  That's incredible. [[00:37:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2257.2000000000003s)]
*  It's really incredible. [[00:37:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2258.2000000000003s)]
*  I mean, I don't want to pretend that I'm using this left arm on a daily basis. [[00:37:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2259.52s)]
*  There is a long, long way to get it functional for every quadriplegic in the world. [[00:37:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2263.96s)]
*  But it was certainly a success because I see that I can do things that I was not able to [[00:37:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2270.24s)]
*  do before. [[00:37:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2278.72s)]
*  But something else has happened as well. [[00:38:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2280.3799999999997s)]
*  After using the digital bridge over time, both Arnaud and Gert Jan have improved their [[00:38:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2284.64s)]
*  ability to move their paralyzed limbs, even when the system is turned off. [[00:38:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2288.96s)]
*  How is that possible? [[00:38:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2294.44s)]
*  What happened? [[00:38:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2295.7400000000002s)]
*  That was also our questions and we could not do much in a human being to understand it. [[00:38:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2297.0s)]
*  Since it wasn't possible for them to see the changes in their patient's spinal cords at [[00:38:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2302.76s)]
*  a microscopic level, they did studies in animals to understand what was happening. [[00:38:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2306.66s)]
*  What we understood was completely unexpected. [[00:38:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2312.88s)]
*  That this training enabled the growth of new nerve connections. [[00:38:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2315.44s)]
*  So new nerves start growing and they grow on one very specific type of neuron that is [[00:38:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2320.2000000000003s)]
*  uniquely equipped to repair the central nervous system. [[00:38:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2325.6s)]
*  So we also observed that the less the severity of the spinal cord lesion is, the better the [[00:38:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2328.76s)]
*  regrowth happens. [[00:38:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2334.6800000000003s)]
*  If it's a complete spinal cord injury, it will be hard to regrow. [[00:38:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2336.6800000000003s)]
*  But indeed, there is something happening. [[00:38:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2339.86s)]
*  How well the digital bridge works still needs to be studied in a lot more patients. [[00:39:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2343.88s)]
*  They hope to launch clinical trials in the U.S. in the next two to three years. [[00:39:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2348.78s)]
*  The FDA has already designated it as a breakthrough device, which will prioritize the review process. [[00:39:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2353.6200000000003s)]
*  And Cortin and Block have co-founded a company called Onward Medical to bring this technology [[00:39:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2360.46s)]
*  out of the lab, making it faster, smaller and widely available. [[00:39:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2365.98s)]
*  It's not changing my everyday in ways people might think, oh, she's getting back her life [[00:39:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2370.78s)]
*  she had before. [[00:39:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2376.32s)]
*  So as long as it makes me feel good, that I can stand up and hug my husband or hug somebody [[00:39:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2377.62s)]
*  that I love, that means a lot. [[00:39:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2383.54s)]
*  What's your goal? [[00:39:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2386.78s)]
*  To go out in the park and just stand up and do some steps with my family. [[00:39:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2388.02s)]
*  It's not a stroll in the park, how it would look for most of the people, but for me it's [[00:39:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2394.36s)]
*  just good enough to make me happy. [[00:39:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2398.08s)]
*  After six months of hard work, just before Marta was to return to her family, she did [[00:40:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2400.88s)]
*  what doctors years ago told her she never would. [[00:40:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2406.44s)]
*  She took a few steps. [[00:40:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2412.32s)]
*  No harness to hold her, just her walker and her iron will. [[00:40:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2414.5s)]
*  In October last year, a 14-year-old girl named Francesca Mani was sitting in her high school [[00:40:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2424.36s)]
*  history class when she heard a rumor that some boys had naked photos of female classmates. [[00:40:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2434.08s)]
*  She soon learned her picture was among them, but the images were doctored, created with [[00:40:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2439.96s)]
*  artificial intelligence using what's known as a Nudify website or app, which turns real [[00:40:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2444.8s)]
*  photos of someone fully clothed into real-looking nudes. [[00:40:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2450.36s)]
*  We've found nearly 30 similar incidents in schools in the U.S. over the last 20 months, [[00:40:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2455.02s)]
*  and plenty more around the world. [[00:40:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2459.88s)]
*  We want to warn you, some of what you'll hear and see is disturbing, but we think unveiling [[00:41:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2461.96s)]
*  these Nudify websites is important, in part because they're not hidden on the dark web. [[00:41:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2467.28s)]
*  They're openly advertised, easy to use, and as Francesca Mani found out, there isn't much [[00:41:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2472.82s)]
*  that's been done to stop them. [[00:41:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2478.2599999999998s)]
*  When you first heard the rumor, you didn't know that there were photos or a photo of you. [[00:41:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2481.1s)]
*  No, we didn't know. [[00:41:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2485.38s)]
*  I think that was like the most chaotic day I've ever witnessed. [[00:41:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2486.54s)]
*  In a school, somebody gets an inkling of something and it just spreads. [[00:41:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2489.78s)]
*  It's like rapid fire. [[00:41:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2493.98s)]
*  It just goes to everyone. [[00:41:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2495.14s)]
*  And so then when someone hears this, it's like, wait, like AI? [[00:41:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2497.72s)]
*  Like no one thinks that could like happen to you. [[00:41:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2502.78s)]
*  Francesca Mani knew nothing about Nudify websites when she discovered she and several of the [[00:41:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2506.54s)]
*  girls at Westfield High School in New Jersey had been targeted. [[00:41:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2511.18s)]
*  According to a lawsuit later filed by one of the other girls through her parents, a [[00:41:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2514.9s)]
*  boy at the school uploaded photos from Instagram to a site called Clothoff, who were naming [[00:41:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2519.14s)]
*  the site to raise awareness of its potential dangers. [[00:42:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2524.84s)]
*  There are more than a hundred of these Nudify websites. [[00:42:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2528.58s)]
*  A quick search is all it takes to find them. [[00:42:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2531.06s)]
*  Clothoff is one of the most popular, with more than three million visits last month, [[00:42:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2533.9s)]
*  according to Grafica, a company that analyzes social networks. [[00:42:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2538.34s)]
*  It now offers to Nudify males as well, but female nudes are far more popular. [[00:42:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2542.38s)]
*  Have someone to undress, Clothoff's website asks. [[00:42:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2547.78s)]
*  You can upload a photo or get a free demonstration in which an image of a woman appears with [[00:42:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2550.84s)]
*  clothes on. [[00:42:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2556.0s)]
*  Then a few seconds later, her clothes are gone. [[00:42:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2557.5s)]
*  They're blurring it out, but the results look very real. [[00:42:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2560.78s)]
*  Francesca Mani never saw what had been done to her photo, but according to that lawsuit, [[00:42:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2564.6200000000003s)]
*  at least one girl's AI nude was shared on Snapchat and seen by several kids at school. [[00:42:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2569.5s)]
*  What made it worse, Francesca says, is that she and the other girls found out they were [[00:42:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2575.46s)]
*  the victims when they were called by name to the principal's office over the school's [[00:42:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2579.6600000000003s)]
*  public address system. [[00:43:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2584.3s)]
*  I feel like that was a major violation of our privacy while the bad actors were taken [[00:43:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2585.94s)]
*  out of their classes privately. [[00:43:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2592.78s)]
*  When I left the principal's office, I was walking through a hallway and I saw this group [[00:43:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2594.82s)]
*  of boys laughing at these group of girls crying and that's when I realized I should stop crying [[00:43:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2599.56s)]
*  and be mad because this is unacceptable. [[00:43:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2605.2200000000003s)]
*  That afternoon, Westfield's principal sent this email to all high school parents, informing [[00:43:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2608.08s)]
*  some of our students had used artificial intelligence to create pornographic images from original [[00:43:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2613.94s)]
*  photos. [[00:43:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2618.98s)]
*  The principal also said the school was investigating and, at this time, we believe that any created [[00:43:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2619.98s)]
*  images had been deleted and are not being circulated. [[00:43:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2625.54s)]
*  Francesca's mom, Dorota, who's also an educator, was not convinced. [[00:43:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2629.7000000000003s)]
*  Do you think they did enough? [[00:43:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2633.94s)]
*  Well, I don't understand. [[00:43:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2635.34s)]
*  Your work in television, is anything deleted in the digital world? [[00:43:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2637.14s)]
*  You feel like even if somebody deletes something somewhere, who knows where these images may [[00:44:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2642.3s)]
*  be? [[00:44:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2647.1800000000003s)]
*  Who printed it, who screenshotted it, who downloaded it, you can't really wipe it out. [[00:44:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2648.1800000000003s)]
*  Dorota says she filed a police report, but no charges have been brought. [[00:44:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2651.9s)]
*  She was shocked by the school's handling of the whole incident. [[00:44:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2655.98s)]
*  The principal informed me that one boy receives one day suspension and that was it. [[00:44:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2659.1600000000003s)]
*  So I asked her if this is all, are there going to be any other consequences? [[00:44:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2666.1400000000003s)]
*  She said no, for now this is all that is going to happen. [[00:44:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2671.54s)]
*  The school district wouldn't confirm details about the photos, the students involved or [[00:44:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2676.04s)]
*  any disciplinary action. [[00:44:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2680.2200000000003s)]
*  In a statement to 60 Minutes, the school superintendent said the district revised its harassment, [[00:44:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2682.26s)]
*  intimidation and bullying policy to incorporate AI, something the monies said they spent months [[00:44:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2687.38s)]
*  urging school officials to do. [[00:44:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2693.26s)]
*  You feel like the girls paid a bigger cost in the end. [[00:44:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2695.42s)]
*  Yeah, they did. [[00:44:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2698.98s)]
*  And the boys involved in this did. [[00:45:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2700.54s)]
*  Because they just have to live with knowing that maybe an image is floating, their image [[00:45:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2702.3s)]
*  is floating around the internet and they just have to deal with what the boys did. [[00:45:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2707.3s)]
*  Kolina Koltae has been looking into Clothoff and other Nutafy sites for more than a year. [[00:45:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2713.18s)]
*  She's a senior researcher who specializes in the misuse of AI at Bellingcat, an international [[00:45:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2718.02s)]
*  investigative group. [[00:45:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2723.66s)]
*  This site, as soon as you get there, it says you have to be 18 or over to use the website, [[00:45:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2725.98s)]
*  you can't use other's photos without their permission, you can't use pictures of people [[00:45:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2730.28s)]
*  who are under 18. [[00:45:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2733.64s)]
*  Is there any way for them to actually check if you're under 18 or over 18? [[00:45:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2735.2400000000002s)]
*  You'll see as we click accept that there's no verification and now we're ready here. [[00:45:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2739.6s)]
*  And immediately you're getting very explicit photos. [[00:45:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2744.92s)]
*  And then they have the poses feature, which is one of their new settings, which is the [[00:45:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2747.72s)]
*  different sex poses, which is the premium feature. [[00:45:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2751.12s)]
*  Wow, so, wow. [[00:45:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2753.72s)]
*  And that's, this is the preview. [[00:45:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2756.24s)]
*  We haven't... [[00:45:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2757.24s)]
*  Clothoff and other Nutafy sites encourage customers to promote their services on social [[00:45:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2758.24s)]
*  media and users often show off their favorite before and after AI nudes. [[00:46:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2762.6s)]
*  I've even seen on social media platforms people showing before and after photos of what are [[00:46:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2767.7599999999998s)]
*  clearly like high school girls. [[00:46:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2772.2599999999998s)]
*  And I've like reverse image searched the original photo and they're like a high school girls [[00:46:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2773.94s)]
*  like swim meets. [[00:46:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2778.44s)]
*  You'll see these are very clearly these are minors and adult content is being made of [[00:46:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2779.44s)]
*  them, non-consensually, then also being posted on social media. [[00:46:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2783.12s)]
*  I think a lot of parents would be surprised to learn that you post a picture of your child [[00:46:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2786.12s)]
*  on your Instagram account, your child could end up naked photo of your child out there. [[00:46:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2790.56s)]
*  And so you have a registration. [[00:46:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2795.48s)]
*  To Nutafy a photo on Clothoff is free the first time. [[00:46:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2797.08s)]
*  After that, it costs from two to $40. [[00:46:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2801.12s)]
*  The payment options often change, but there are always plenty to choose from. [[00:46:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2803.8s)]
*  It's giving me everything from crypto to using a credit card for a variety of different [[00:46:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2808.8s)]
*  credit cards. [[00:46:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2812.36s)]
*  We got PayPal here, Google Pay. [[00:46:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2813.36s)]
*  I would imagine some of these companies are not thrilled that their services are being [[00:46:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2815.84s)]
*  used by these websites. [[00:47:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2821.52s)]
*  Yeah, and in many of these cases it directly violates their policies. [[00:47:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2823.0800000000004s)]
*  To trick online payment services, Colina Coltai says Clothoff and other Nutafy sites redirect [[00:47:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2826.92s)]
*  their customers' payments through phony websites like these pretending to sell flowers and [[00:47:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2832.84s)]
*  photography lessons. [[00:47:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2837.96s)]
*  Say for example you want to pay through PayPal. [[00:47:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2839.6800000000003s)]
*  So we click this and it'll take a second. [[00:47:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2841.64s)]
*  So it's now redirecting you. [[00:47:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2844.5s)]
*  It's redirecting through a dummy website. [[00:47:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2846.52s)]
*  So that way on PayPal's end it looks like you may be purchasing anything from motorcycles [[00:47:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2849.7400000000002s)]
*  or beekeeping lessons or roller blade lessons. [[00:47:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2853.7200000000003s)]
*  So now we got to a PayPal screen, but we can see down here it says cancel and return to [[00:47:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2856.8s)]
*  innernookdesigns.motorcycles. [[00:47:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2862.08s)]
*  So that's what PayPal is being told is the website that's asking for the charge. [[00:47:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2864.54s)]
*  Yes. [[00:47:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2869.34s)]
*  PayPal told us it banned Clothoff from its platforms a year ago and shuts down the accounts [[00:47:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2870.34s)]
*  for these redirect sites when it finds them. [[00:47:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2875.74s)]
*  The problem is Clothoff often just creates new ones. [[00:47:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2878.42s)]
*  On this login screen here. [[00:48:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2882.14s)]
*  And that's not the only deception it relies on. [[00:48:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2883.96s)]
*  Its website lists a name, Grupo Digital, with an address in Buenos Aires, Argentina, implying [[00:48:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2886.56s)]
*  that's where Clothoff is based. [[00:48:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2893.6200000000003s)]
*  But when we sent our cameras, there was no Grupo Digital there. [[00:48:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2895.7000000000003s)]
*  It turned out to be the office of a YouTube channel that covers politics. [[00:48:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2899.94s)]
*  And when we knocked on the door, the employee who answered said she'd never heard of Clothoff. [[00:48:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2904.58s)]
*  Clothoff also made up a fake CEO, according to Colina Coltai, complete with what she says [[00:48:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2916.3s)]
*  is an AI-generated headshot. [[00:48:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2921.86s)]
*  There is a really inherent shadiness that's happening. [[00:48:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2924.34s)]
*  They're not being transparent about who owns it. [[00:48:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2927.1400000000003s)]
*  They're obviously trying to mask their payments. [[00:48:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2929.42s)]
*  But you look at the sophistication of these really large sites, it's completely different [[00:48:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2931.46s)]
*  than say some guy in a basement that set up a site that is trying to do it on his own. [[00:48:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2935.06s)]
*  When these sites launched and the way that they've been developing and going this past [[00:48:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2938.86s)]
*  year, it is not someone's first road. [[00:49:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2942.26s)]
*  It's not the first time they set up a complex network. [[00:49:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2944.1s)]
*  Clothoff claims on its website that processing of minors is impossible. [[00:49:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2948.1s)]
*  We emailed what the site says is a press contact asking for any evidence of that and to respond [[00:49:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2952.42s)]
*  to a number of other questions. [[00:49:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2958.06s)]
*  We didn't hear back. [[00:49:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2960.1s)]
*  A lot of people might say, well, these images are fake. [[00:49:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2961.54s)]
*  But we know victims will suffer humiliation, they'll suffer mental health distress and [[00:49:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2964.5s)]
*  reputational harm. [[00:49:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2971.66s)]
*  In a school setting, it's really amplified because one of their peers has created this [[00:49:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2973.22s)]
*  imagery. [[00:49:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2978.06s)]
*  So, there's a loss of confidence, a loss of trust. [[00:49:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2979.06s)]
*  Yota Suras is chief legal officer at the National Center for Missing and Exploited Children. [[00:49:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2982.4599999999996s)]
*  Her organization regularly works with tech companies to flag inappropriate content on [[00:49:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2987.74s)]
*  their sites. [[00:49:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2992.3399999999997s)]
*  In at least three cases, Snapchat was reportedly used to circulate these photos. [[00:49:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2993.3399999999997s)]
*  One instance, the parent told us that it took more than eight months to get the accounts [[00:49:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=2998.54s)]
*  that had shared the images taken down. [[00:50:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3003.06s)]
*  Their responsiveness to victims, that is a recurring problem that we see across tech [[00:50:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3005.46s)]
*  companies. [[00:50:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3010.46s)]
*  So, it's not as easy as a parent sending a note through Snapchat, hey, this is happening, [[00:50:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3011.46s)]
*  my child has been exploited. [[00:50:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3018.06s)]
*  It's entirely unclear why it is not a faster process. [[00:50:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3019.7s)]
*  We can actually notify tech companies as well and ask them to take that content down. [[00:50:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3023.34s)]
*  And individuals do that? [[00:50:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3027.58s)]
*  Much faster than when an individual calls. [[00:50:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3029.22s)]
*  Yes. [[00:50:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3031.62s)]
*  But that isn't the way it should be, right? [[00:50:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3032.62s)]
*  I mean, a parent whose child has exploitative or child pornography images online should [[00:50:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3034.2999999999997s)]
*  not have to rely on reaching out to a third party and having them call the tech company. [[00:50:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3039.58s)]
*  The tech company should be assuming responsibility immediately to remove that content. [[00:50:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3044.42s)]
*  Why are they not doing that? [[00:50:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3049.22s)]
*  Because they do not think there are ramifications to them not doing so. [[00:50:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3050.62s)]
*  Social media companies are shielded from lawsuits involving photos someone posts online due [[00:50:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3055.2599999999998s)]
*  to what Yota Suras considers an outdated law. [[00:50:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3059.98s)]
*  Under Section 230 of the Communications Decency Act, a law from 1996, so a very different [[00:51:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3063.42s)]
*  world back then, online platforms have near complete immunity for any liability arising [[00:51:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3068.86s)]
*  from content that a user puts on their system. [[00:51:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3075.86s)]
*  The Section 230 protection is really what allows this very loose ecosystem to exist [[00:51:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3078.94s)]
*  in terms of Nudify apps and websites that cause harm to children. [[00:51:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3086.74s)]
*  We asked Snapchat about that parent who told us the company didn't respond to her for [[00:51:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3091.02s)]
*  eight months. [[00:51:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3094.94s)]
*  A Snapchat spokesperson told us they've been unable to locate her request and said, in [[00:51:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3095.94s)]
*  part, we have efficient mechanisms for reporting this kind of content and added we have a zero [[00:51:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3101.14s)]
*  tolerance policy for such content and act quickly to address it once reported. [[00:51:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3106.56s)]
*  AI nudes of minors are illegal under federal child pornography laws according to the Department [[00:51:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3112.46s)]
*  of Justice if they depict what's defined as sexually explicit conduct. [[00:51:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3117.5800000000004s)]
*  But Suras is concerned some images created by Nudify sites may not meet that definition. [[00:52:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3122.6600000000003s)]
*  There's this gap in the law around a Nudify app that desperately needs to be shut. [[00:52:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3128.86s)]
*  What are the gaps in the law? [[00:52:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3133.78s)]
*  Currently, a nude image of a child that does not include sexually explicit conduct is not [[00:52:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3135.1000000000004s)]
*  illegal. [[00:52:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3141.5s)]
*  And that is a serious gap that exists for real children and that exists certainly for [[00:52:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3143.14s)]
*  images of new children that are created by a Nudify app. [[00:52:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3147.5s)]
*  In the years since Francesca Mani found out she was targeted, she and her mom have urged [[00:52:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3153.78s)]
*  schools to implement policies around AI and worked with members of Congress to try and [[00:52:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3158.22s)]
*  pass a number of federal bills. [[00:52:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3163.06s)]
*  The Take It Down Act, co-sponsored by Senators Ted Cruz and Amy Klobuchar, made it through [[00:52:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3166.86s)]
*  the Senate this month and is now awaiting a vote in the House. [[00:52:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3171.5s)]
*  It would create criminal penalties for sharing AI nudes and require social media companies [[00:52:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3175.38s)]
*  to take photos down within 48 hours of getting a request. [[00:53:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3180.78s)]
*  Schools don't really know how to address this. [[00:53:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3185.42s)]
*  Police in many cases don't do much at this stage and the sites are making I presume millions [[00:53:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3187.9s)]
*  of dollars off this. [[00:53:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3194.38s)]
*  So can it be fixed? [[00:53:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3196.1s)]
*  Absolutely. [[00:53:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3197.42s)]
*  If we have the appropriate laws, we will have the criminal consequences, first of all to [[00:53:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3198.42s)]
*  deter offenders, and then they'll be held liable if they are still using these apps. [[00:53:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3203.6600000000003s)]
*  We would have civil remedies for victims. [[00:53:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3208.2000000000003s)]
*  Schools would have protocols. [[00:53:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3210.38s)]
*  Investigators and law enforcement would have roadmaps on how to investigate what charges [[00:53:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3212.9s)]
*  to bring. [[00:53:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3216.26s)]
*  But we're a long way from that. [[00:53:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3217.26s)]
*  We just need the laws in place. [[00:53:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3218.26s)]
*  All the rest will come from that. [[00:53:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3220.02s)]
*  The familiar narrative is that artificial intelligence will take away human jobs. [[00:53:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3224.38s)]
*  Machine learning will let cars, computers, and chatbots teach themselves, making us humans [[00:53:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3236.7400000000002s)]
*  obsolete. [[00:54:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3242.42s)]
*  Well, that's not very likely, and we're going to tell you why. [[00:54:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3243.42s)]
*  There's a growing global army of millions toiling to make AI run smoothly. [[00:54:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3248.62s)]
*  They're called humans in the loop. [[00:54:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3254.82s)]
*  People sorting, labeling, and sifting reams of data to train and improve AI for companies [[00:54:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3257.84s)]
*  like Meta, OpenAI, Microsoft, and Google. [[00:54:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3264.36s)]
*  It's grunt work that needs to be done accurately, fast, and to do it cheaply, it's often farmed [[00:54:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3269.18s)]
*  out to places like Africa. [[00:54:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3276.22s)]
*  The robots or the machines, you're teaching them how to think like human and to do things [[00:54:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3279.8599999999997s)]
*  like human. [[00:54:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3284.8999999999996s)]
*  We met Naftali Wambalo in Nairobi, Kenya, one of the main hubs for this kind of work. [[00:54:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3286.06s)]
*  It's a country desperate for jobs because of an unemployment rate as high as 67 percent [[00:54:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3293.06s)]
*  among young people. [[00:54:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3299.22s)]
*  So Naftali, father of two, college-educated, with a degree in mathematics, was elated to [[00:55:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3301.08s)]
*  finally find work in an emerging field, artificial intelligence. [[00:55:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3307.92s)]
*  You were labeling. [[00:55:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3313.08s)]
*  I did labeling for videos and images. [[00:55:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3314.3199999999997s)]
*  Naftali and digital workers like him spent eight hours a day in front of a screen studying [[00:55:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3317.16s)]
*  photos and videos, drawing boxes around objects and labeling them, teaching the AI algorithms [[00:55:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3323.52s)]
*  to recognize them. [[00:55:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3331.36s)]
*  You label, let's say, furniture in a house, and you say this is a TV, this is a microwave. [[00:55:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3333.06s)]
*  So you are teaching the AI to identify these items. [[00:55:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3338.92s)]
*  And then there was one for faces of people, the color of the face. [[00:55:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3342.52s)]
*  If it looks like this, this is white, if it looks like this is black, this is Asian, you're [[00:55:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3347.06s)]
*  teaching the AI to identify them automatically. [[00:55:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3351.24s)]
*  Humans tag cars and pedestrians to teach autonomous vehicles not to hit them. [[00:55:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3355.52s)]
*  Humans circle abnormalities to teach AI to recognize diseases. [[00:56:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3361.9199999999996s)]
*  Even as AI is getting smarter, humans in the loop will always be needed because there will [[00:56:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3367.8399999999997s)]
*  always be new devices and inventions that will need labeling. [[00:56:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3373.48s)]
*  To find these humans in the loop, not only here in Kenya, but in other countries thousands [[00:56:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3378.32s)]
*  of miles from Silicon Valley, in India, the Philippines, Venezuela, often countries with [[00:56:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3384.1200000000003s)]
*  large low-wage populations, well-educated but unemployed. [[00:56:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3391.2000000000003s)]
*  Honestly, it's like modern-day slavery because it's cheap labor. [[00:56:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3396.2000000000003s)]
*  Whoa, what do you... [[00:56:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3401.2000000000003s)]
*  It's cheap labor. [[00:56:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3402.2000000000003s)]
*  Like modern-day slavery, says Narima Wako-Ojiwa, a Kenyan civil rights activist, because big [[00:56:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3403.96s)]
*  American tech companies come here and advertise the jobs as a ticket to the future. [[00:56:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3410.96s)]
*  But really, she says, it's exploitation. [[00:56:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3417.0s)]
*  What we're seeing is an inequality. [[00:57:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3420.96s)]
*  It sounds so good, an AI job. [[00:57:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3424.68s)]
*  Is there any job security? [[00:57:08](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3428.68s)]
*  The contracts that we see are very short-term, and I've seen people who have contracts that [[00:57:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3430.84s)]
*  are monthly, some of them weekly, some of them days, which is ridiculous. [[00:57:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3435.88s)]
*  She calls the workspaces AI sweatshops with computers instead of sewing machines. [[00:57:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3442.44s)]
*  I think that we're so concerned with creating opportunities, but we're not asking, are they [[00:57:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3449.0s)]
*  good opportunities? [[00:57:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3457.2000000000003s)]
*  As every year a million young people enter the job market, the government has been courting [[00:57:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3459.44s)]
*  tech giants like Microsoft, Google, Apple and Intel to come here, promoting Kenya's [[00:57:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3465.2000000000003s)]
*  reputation as the Silicon Savannah, tech savvy and digitally connected. [[00:57:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3472.2000000000003s)]
*  The president has been really pushing forward opportunities in AI. [[00:57:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3478.56s)]
*  President? [[00:58:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3482.64s)]
*  Yes, our president. [[00:58:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3483.64s)]
*  Ruto? [[00:58:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3484.64s)]
*  Yes. [[00:58:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3485.64s)]
*  The president does have to create at least one million jobs a year, the minimum. [[00:58:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3486.7599999999998s)]
*  So it's a very tight position to be in. [[00:58:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3491.56s)]
*  To lure the tech giants, Ruto has been offering financial incentives on top of already lax [[00:58:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3494.4s)]
*  labor laws. [[00:58:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3500.7999999999997s)]
*  But the workers aren't hired directly by the big companies. [[00:58:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3502.3199999999997s)]
*  They engage outsourcing firms, also mostly American, to hire for them. [[00:58:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3506.3399999999997s)]
*  There's a go-between. [[00:58:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3512.44s)]
*  Yes. [[00:58:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3513.44s)]
*  They hire, they pay. [[00:58:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3515.32s)]
*  I mean, they hire thousands of people. [[00:58:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3516.32s)]
*  And they are protecting the Facebooks from having their names associated with this. [[00:58:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3518.96s)]
*  Yes, yes, yes, yes. [[00:58:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3524.48s)]
*  We're talking about the richest companies on earth. [[00:58:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3525.48s)]
*  Yes, but then they are paying people peanuts. [[00:58:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3528.12s)]
*  AI jobs don't pay much? [[00:58:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3531.6s)]
*  They don't pay well. [[00:58:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3535.28s)]
*  They do not pay Africans well enough. [[00:58:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3536.28s)]
*  The workforce is so large and desperate that they could pay whatever and have whatever [[00:58:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3539.3199999999997s)]
*  working conditions and they will have someone who will pick up that job. [[00:59:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3546.08s)]
*  So what's the average pay for these jobs? [[00:59:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3550.2s)]
*  It's about a dollar and a half, two dollars an hour. [[00:59:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3553.2s)]
*  Two dollars per hour, and that is gross before tax. [[00:59:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3557.2799999999997s)]
*  Naftali, Nathan, and Fasika were hired by an American outsourcing company called Sama [[00:59:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3560.08s)]
*  that employs over 3,000 workers here and hired for Meta and OpenAI. [[00:59:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3566.72s)]
*  In documents we obtained, OpenAI agreed to pay Sama $12.50 an hour per worker, much more [[00:59:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3573.12s)]
*  than the two dollars the workers actually got. [[00:59:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3581.7999999999997s)]
*  Though Sama says that's a fair wage for the region. [[00:59:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3585.12s)]
*  If the big tech companies are going to keep doing this business, they have to do it the [[00:59:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3588.8399999999997s)]
*  right way. [[00:59:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3594.08s)]
*  So it's not because you realize Kenya is a third world country, you say, this job I [[00:59:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3595.08s)]
*  would normally pay $30 in the U.S., but because you are Kenya, two dollars is enough for you. [[00:59:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3598.7999999999997s)]
*  That idea has to end. [[01:00:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3603.08s)]
*  Okay, two dollars an hour in Kenya. [[01:00:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3604.48s)]
*  Is that low, medium, is it an okay salary? [[01:00:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3607.7999999999997s)]
*  So for me, I was living paycheck to paycheck. [[01:00:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3611.92s)]
*  I have saved nothing because it's not enough. [[01:00:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3615.16s)]
*  Is it an insult? [[01:00:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3618.36s)]
*  It is, of course. [[01:00:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3619.36s)]
*  It is. [[01:00:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3621.36s)]
*  Why did you take the job? [[01:00:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3622.36s)]
*  I have a family to feed and instead of staying home, let me just at least have something [[01:00:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3624.16s)]
*  to do. [[01:00:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3629.44s)]
*  And not only did the jobs not pay well, they were draining. [[01:00:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3630.44s)]
*  They say deadlines were unrealistic, punitive, with often just seconds to complete complicated [[01:00:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3634.8599999999997s)]
*  labeling tasks. [[01:00:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3641.72s)]
*  Did you see people who were fired just because they complained? [[01:00:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3643.46s)]
*  Yes, we were walking on eggshells. [[01:00:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3647.24s)]
*  They were all hired per project and say Sama kept pushing them to complete the work faster [[01:00:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3650.26s)]
*  than the projects required, an allegation Sama denies. [[01:00:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3656.76s)]
*  Let's say the contract for a certain job was six months, okay? [[01:01:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3661.86s)]
*  What if you finished in three months? [[01:01:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3667.6000000000004s)]
*  Does the worker get paid for those extra three months? [[01:01:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3669.98s)]
*  No. [[01:01:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3673.7000000000003s)]
*  KFC. [[01:01:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3674.7000000000003s)]
*  What? [[01:01:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3675.7000000000003s)]
*  We used to get KFC and Coca-Cola. [[01:01:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3676.7000000000003s)]
*  They used to say thank you, they get you a bottle of soda and KFC chicken, two pieces. [[01:01:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3677.7s)]
*  That is it. [[01:01:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3683.7799999999997s)]
*  Worse yet, workers told us that some of the projects for Metta and OpenAI were grim and [[01:01:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3685.3399999999997s)]
*  caused them harm. [[01:01:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3691.9399999999996s)]
*  Naftali was assigned to train AI to recognize and weed out pornography, hate speech, and [[01:01:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3694.18s)]
*  excessive violence, which meant sifting through the worst of the worst content online for [[01:01:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3701.02s)]
*  hours on end. [[01:01:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3707.58s)]
*  I looked at people being slaughtered, people engaging in sexual activity with animals, [[01:01:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3708.98s)]
*  people abusing children physically, sexually, people committing suicide. [[01:01:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3716.94s)]
*  All day long? [[01:02:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3722.62s)]
*  Yes, all day long. [[01:02:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3724.62s)]
*  Eight hours a day, 40 hours a week. [[01:02:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3726.62s)]
*  The workers told us they were tricked into this work by ads like this that describe these [[01:02:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3729.2599999999998s)]
*  jobs as call center agents to assist our clients' community and help resolve inquiries empathetically. [[01:02:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3735.3s)]
*  I was told I was going to do a translation job. [[01:02:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3743.6200000000003s)]
*  Exactly what was the job you were doing? [[01:02:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3746.9s)]
*  I was basically reviewing content which are very graphic, very disturbing contents. [[01:02:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3749.02s)]
*  I was watching dismembered bodies or drone attack victims, you name it. [[01:02:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3755.5s)]
*  You know, whenever I talk about this, I still have flashbacks. [[01:02:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3761.7s)]
*  Are any of you a different person than they were before you had this job? [[01:02:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3766.2999999999997s)]
*  Yeah, I find it hard now to even have conversations with people. [[01:02:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3773.2999999999997s)]
*  It's just that I find it easier to cry than to speak. [[01:02:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3778.2999999999997s)]
*  You continue isolating yourself from people. [[01:03:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3782.8199999999997s)]
*  You don't want to socialize with others. [[01:03:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3786.66s)]
*  It's you and it's you alone. [[01:03:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3789.1s)]
*  Are you a different person? [[01:03:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3790.94s)]
*  Yeah, I'm a different person. [[01:03:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3791.94s)]
*  I used to enjoy my marriage, especially when it comes to bedroom fireworks, but after the [[01:03:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3794.3s)]
*  job I hate sex. [[01:03:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3799.14s)]
*  You hated sex? [[01:03:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3801.02s)]
*  After countless seeing those sexual activities, pornography on the job that I was doing, I [[01:03:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3802.42s)]
*  hate sex. [[01:03:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3810.02s)]
*  Sama says mental health counseling was provided by, quote, fully licensed professionals, but [[01:03:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3811.58s)]
*  the workers say it was woefully inadequate. [[01:03:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3817.9s)]
*  We want psychiatrists, we want psychologists qualified who know exactly what we are going [[01:03:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3821.42s)]
*  through and how they can help us to cope. [[01:03:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3827.5s)]
*  Trauma experts. [[01:03:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3830.7400000000002s)]
*  Yes. [[01:03:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3831.7400000000002s)]
*  Do you think the big company, Facebook, ChatGPT, do you think they know how this is affecting [[01:03:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3832.7400000000002s)]
*  the workers? [[01:04:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3840.26s)]
*  It's their job to know. [[01:04:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3841.26s)]
*  It's their f***ing job to know, actually, because they are the ones providing the work. [[01:04:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3842.26s)]
*  These three and nearly 200 other digital workers are suing Sama and Metta over unreasonable [[01:04:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3846.3s)]
*  working conditions that caused psychiatric problems. [[01:04:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3853.54s)]
*  It was proven by psychiatrists that we are thoroughly sick. [[01:04:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3858.02s)]
*  We have gone through a psychiatric evaluation just a few months ago and it was proven that [[01:04:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3863.26s)]
*  we are all sick, thoroughly sick. [[01:04:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3869.5800000000004s)]
*  They know that we're damaged, but they don't care. [[01:04:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3872.1200000000003s)]
*  We're humans just because we're black or just because we're just vulnerable for now. [[01:04:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3875.58s)]
*  That doesn't give them the right to just exploit us like this. [[01:04:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3880.54s)]
*  Sama, which has terminated those projects, would not agree to an on-camera interview. [[01:04:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3884.8199999999997s)]
*  Metta and OpenAI told us they're committed to safe working conditions, including fair [[01:04:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3890.98s)]
*  wages and access to mental health counseling. [[01:04:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3897.54s)]
*  Another American AI training company facing criticism in Kenya is Scale AI, which operates [[01:05:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3901.38s)]
*  a website called Remotasks. [[01:05:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3909.26s)]
*  Did you all work for Remotasks or work with them? [[01:05:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3912.2200000000003s)]
*  Afantis, Joan, Joy, Michael and Duncan signed up online, creating an account and clicked [[01:05:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3915.2200000000003s)]
*  for work remotely, getting paid per task. [[01:05:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3923.5s)]
*  Problem is, sometimes the company just didn't pay them. [[01:05:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3928.18s)]
*  When it gets to the day before payday, they close their account and say that you violated [[01:05:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3931.54s)]
*  a policy. [[01:05:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3936.06s)]
*  They say you violated their policy and they don't pay you for the work you've done? [[01:05:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3937.06s)]
*  Would you say that that's almost common, that you do work and you're not paid for it? [[01:05:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3941.46s)]
*  And you have no recourse, you have no way to even complain? [[01:05:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3946.62s)]
*  The company says any work that was done in line with our community guidelines was paid [[01:05:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3952.38s)]
*  out. [[01:05:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3958.1800000000003s)]
*  In March, as workers started complaining publicly, Remotasks abruptly shut down in Kenya altogether. [[01:05:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3959.54s)]
*  There are no labor laws here. [[01:06:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3967.78s)]
*  Our labor law is about 20 years old. [[01:06:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3969.9s)]
*  It doesn't touch on digital labor. [[01:06:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3973.78s)]
*  I do think that our labor laws need to recognize it, but not just in Kenya alone, because what [[01:06:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3976.9s)]
*  happens is when we start to push back in terms of protections of workers, a lot of [[01:06:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3982.02s)]
*  these companies, they shut down and they move to a neighboring country. [[01:06:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3987.7s)]
*  It's easy to see how you're trapped. [[01:06:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3992.38s)]
*  Kenya is trapped. [[01:06:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3995.54s)]
*  They need jobs so desperately that there's a fear that if you complain, if your government [[01:06:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=3997.22s)]
*  complained, then these companies don't have to come here. [[01:06:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4003.46s)]
*  Yeah, and that's what they throw at us all the time. [[01:06:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4007.42s)]
*  And it's terrible to see just how many American companies are just doing wrong here, just [[01:06:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4010.3s)]
*  doing wrong here. [[01:06:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4016.26s)]
*  And it's something that they wouldn't do at home. [[01:06:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4017.86s)]
*  So why do it here? [[01:07:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4020.1000000000004s)]
*  By now, we've all heard about Elon Musk's efforts to reshape the U.S. government. [[01:07:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4029.94s)]
*  But tonight, we'll introduce you to another tech billionaire, one who set his sights on [[01:07:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4035.26s)]
*  radically changing the way the Pentagon buys and uses weapons. [[01:07:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4040.48s)]
*  His name is Palmer Luckey, and he's the founder of Andrel, a California defense products company. [[01:07:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4045.2200000000003s)]
*  Luckey says for too long, the U.S. military has relied on overpriced and outdated technology. [[01:07:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4051.78s)]
*  He argues a Tesla has better AI than any U.S. aircraft, and a Roomba vacuum has better autonomy [[01:07:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4057.94s)]
*  than most of the Pentagon's weapons systems. [[01:07:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4064.9s)]
*  So Andrel is making a line of autonomous weapons that operate using artificial intelligence, [[01:07:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4067.7400000000002s)]
*  no human required. [[01:07:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4073.96s)]
*  Some international groups have called those types of weapons killer robots. [[01:07:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4075.94s)]
*  But Palmer Luckey says it is the future of warfare. [[01:08:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4080.28s)]
*  I've always said that we need to transition from being the world police to being the world [[01:08:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4084.86s)]
*  gun store. [[01:08:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4089.2200000000003s)]
*  Do we want to be the world's gun store? [[01:08:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4090.2200000000003s)]
*  I think so. [[01:08:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4091.86s)]
*  I think we have to. [[01:08:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4092.86s)]
*  And that's what we're going to do is we're going to switch to the world's most powerful [[01:08:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4093.94s)]
*  weapons. [[01:08:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4094.86s)]
*  See, I agree it sounds self-fulfilling, but yet remember, I also got into this industry [[01:08:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4095.86s)]
*  because I believe that. [[01:08:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4100.18s)]
*  Palmer Luckey isn't your typical defense industry executive. [[01:08:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4101.7s)]
*  His daily uniform, flip flops and a Hawaiian shirt, is more suited for Margaritaville than [[01:08:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4106.1s)]
*  the military. [[01:08:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4111.58s)]
*  But the 32-year-old billionaire is the founder of Andrel, whose line of American-made autonomous [[01:08:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4112.58s)]
*  weapons looks like it came straight out of a sci-fi movie and whose slick marketing videos [[01:08:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4118.98s)]
*  wouldn't be out of place in one. [[01:08:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4125.299999999999s)]
*  There's the Road Runner, a twin turbo jet-powered drone interceptor that can take off, identify [[01:08:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4128.5s)]
*  and strike. [[01:08:55](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4135.54s)]
*  If it doesn't find a target, it can land and try again. [[01:08:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4139.0199999999995s)]
*  Andrel also makes headsets, which allow soldiers to see 360 degrees in combat. [[01:09:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4144.42s)]
*  And there's this. [[01:09:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4150.34s)]
*  It's an electromagnetic warfare system that can be programmed to jam enemy systems, knocking [[01:09:11](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4151.34s)]
*  out drone swarms. [[01:09:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4158.06s)]
*  It's not some futuristic fantasy. [[01:09:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4160.14s)]
*  Andrel's systems are already being used by the U.S. military and in the war in Ukraine. [[01:09:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4162.780000000001s)]
*  We shouldn't be sending our people to stand in other countries putting our men and women, [[01:09:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4168.18s)]
*  our sons and daughters at risk for the sovereignty of other nations. [[01:09:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4173.88s)]
*  You'd rather have an American-made product in their hands than our soldiers over there. [[01:09:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4178.52s)]
*  Absolutely, every time. [[01:09:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4183.08s)]
*  And I think that that's one of the reasons that autonomy is so powerful. [[01:09:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4184.08s)]
*  Right now there's so many weapon systems that require manning. [[01:09:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4187.28s)]
*  If I can have one guy commanding and controlling 100 aircraft, that's a lot easier than having [[01:09:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4189.92s)]
*  to have a pilot in every single one. [[01:09:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4196.24s)]
*  And it puts a lot fewer American lives at risk. [[01:09:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4197.72s)]
*  To be clear, autonomy does not mean remote control. [[01:10:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4202.42s)]
*  Once an autonomous weapon is programmed and given a task, it can use artificial intelligence [[01:10:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4206.46s)]
*  for surveillance or to identify, select and engage targets. [[01:10:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4212.28s)]
*  No operator needed. [[01:10:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4220.2s)]
*  It's a scary idea to some people. [[01:10:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4224.42s)]
*  It's a scary idea, but that's the world we live in. [[01:10:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4225.9800000000005s)]
*  I'd say it's a lot scarier, for example, to imagine a weapon system that doesn't have [[01:10:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4228.1s)]
*  any level of intelligence at all. [[01:10:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4232.76s)]
*  There's no moral high ground in making a landmine that can't tell the difference between a school [[01:10:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4234.860000000001s)]
*  bus full of children and Russian armor. [[01:10:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4237.620000000001s)]
*  It's not a question between smart weapons and no weapons. [[01:10:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4239.42s)]
*  It's a question between smart weapons and dumb weapons. [[01:10:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4242.3s)]
*  Lucky showed us how those so-called smart weapons can be synchronized on Andrew's AI [[01:10:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4244.900000000001s)]
*  platform. [[01:10:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4250.54s)]
*  It's called Lattice. [[01:10:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4251.620000000001s)]
*  Lattice collects data from various sensors and sources, including satellites, drones, [[01:10:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4252.98s)]
*  radar and cameras, allowing, he says, the AI to analyze move assets and execute missions [[01:10:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4258.86s)]
*  faster than a human. [[01:11:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4267.139999999999s)]
*  If you were having to require the human operator to actually map every single action and say, [[01:11:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4269.04s)]
*  hey, do this, if that, then this, it would take so long to manage it that you would be [[01:11:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4274.46s)]
*  better off just remotely piloting it. [[01:11:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4278.5s)]
*  It's the AI on board all these weapons that makes it possible to make it so easy. [[01:11:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4280.66s)]
*  There are lots of people who go, oh, AI, I don't know, I don't trust it. [[01:11:25](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4285.58s)]
*  It's going to go rogue. [[01:11:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4288.84s)]
*  I would say that it is something to be aware of, but in the grand scheme of things, things [[01:11:30](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4290.38s)]
*  to be afraid of, there's things that I'm much more terrified of. [[01:11:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4296.38s)]
*  And I'm a lot more worried about evil people with mediocre advances in technology than [[01:11:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4299.38s)]
*  AI deciding that it's going to wipe us all out. [[01:11:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4305.32s)]
*  Huckie says all Angel's weapons have a kill switch that allow a human operator to intervene [[01:11:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4307.94s)]
*  if needed. [[01:11:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4313.299999999999s)]
*  But the secretary general of the United Nations has called lethal autonomous weapons, quote, [[01:11:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4314.299999999999s)]
*  politically unacceptable and morally repugnant. [[01:11:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4319.98s)]
*  When people say to you, look, it's evil, how do you respond to that? [[01:12:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4323.5s)]
*  I usually don't bother because if I am going to argue with them, I usually poke it. [[01:12:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4329.139999999999s)]
*  OK, so do you think that NATO should be armed with squirt guns or slingshots? [[01:12:13](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4333.62s)]
*  How about sternly worded letters? [[01:12:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4338.7s)]
*  Would you like that? [[01:12:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4340.22s)]
*  Would you like it if NATO just, they just have a bunch of guys sitting at typewriters, [[01:12:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4341.22s)]
*  a thousand monkeys writing letters to Vladimir Putin begging him to not invade Ukraine? [[01:12:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4344.66s)]
*  Our entire society exists because of a credible backstop of violence threatened by the United [[01:12:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4349.3s)]
*  States and our allies all over the world. [[01:12:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4354.66s)]
*  And thank goodness for it. [[01:12:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4356.78s)]
*  It might sound flit, but part of Palmer Luckey's philosophy is that autonomous weapons ultimately [[01:12:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4358.54s)]
*  promote peace by scaring adversaries away. [[01:12:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4364.7s)]
*  My position has been that the United States needs to arm our allies and partners around [[01:12:48](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4368.58s)]
*  the world so that they can be prickly porcupines that nobody wants to step on. [[01:12:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4374.54s)]
*  Nobody wants to bite them. [[01:12:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4379.08s)]
*  In your mind, is it enough just to have all these things as deterrents or do they have [[01:13:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4381.18s)]
*  to be deployed and used? [[01:13:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4386.06s)]
*  They have to believe that you can use them. [[01:13:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4387.9s)]
*  By the end of this year, Andrew says it will have secured more than $6 billion in government [[01:13:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4390.219999999999s)]
*  contracts worldwide. [[01:13:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4395.5s)]
*  When you first came into this space and you're a tech guy in a Hawaiian shirt and you're [[01:13:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4397.62s)]
*  walking into the Pentagon, maybe in flip flops, I don't know, were you welcomed with open [[01:13:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4402.78s)]
*  arms? [[01:13:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4408.78s)]
*  There were a very small number of people who welcomed me with open arms and everyone else [[01:13:29](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4409.78s)]
*  thought that I was nuts. [[01:13:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4413.139999999999s)]
*  Nuts because there hasn't been a new company in the defense industry in a significant way [[01:13:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4414.94s)]
*  since the end of the Cold War. [[01:13:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4419.82s)]
*  For decades, five defense contractors called the Primes have dominated the industry. [[01:13:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4421.9800000000005s)]
*  Typically, the Primes present an idea to the Pentagon. [[01:13:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4427.58s)]
*  If the Pentagon buys it, the government pays for the company to develop it, even if it's [[01:13:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4431.42s)]
*  late or goes over budget. [[01:13:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4436.38s)]
*  Luckey started Andrel to flip that procurement structure on its head. [[01:13:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4438.82s)]
*  The idea behind Andrel was to build not a defense contractor, but a defense product [[01:14:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4443.22s)]
*  company. [[01:14:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4449.54s)]
*  What's the difference? [[01:14:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4450.54s)]
*  Contractors in general are paid to do work, whether or not it succeeds. [[01:14:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4452.3s)]
*  A product company has a very different mentality. [[01:14:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4456.34s)]
*  You're putting in your own money. [[01:14:18](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4458.820000000001s)]
*  You're putting in your own time. [[01:14:20](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4460.3s)]
*  My vision was to build a company that would show up not with a PowerPoint describing how [[01:14:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4461.76s)]
*  taxpayers are going to pay all my bills, but with a working product where all the risk [[01:14:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4466.780000000001s)]
*  has been baked out. [[01:14:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4471.14s)]
*  It will work for enough things that you can save our country hundreds of billions of dollars [[01:14:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4472.14s)]
*  a year. [[01:14:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4476.740000000001s)]
*  It may not surprise you that Palmer Luckey's father was a car salesman. [[01:14:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4477.740000000001s)]
*  His mother took on the role of homeschooling him and his three sisters. [[01:14:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4481.780000000001s)]
*  Luckey says he was fascinated by electronics and spent a lot of time tinkering in his parents' [[01:14:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4486.38s)]
*  garage in Long Beach, California. [[01:14:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4491.5s)]
*  By age 19, his tinkering turned into Oculus, the virtual reality company. [[01:14:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4494.3s)]
*  And at 21, Palmer Luckey fulfilled every young founder's dream when he sold Oculus to Facebook [[01:15:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4500.26s)]
*  for $2 billion. [[01:15:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4507.06s)]
*  The wonder kid graced the covers of magazines, but two years later, he was fired from Facebook. [[01:15:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4509.1s)]
*  Why did you get fired? [[01:15:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4515.18s)]
*  Well, you know, everyone's got a different story, but it boils down to I gave $9,000 [[01:15:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4516.46s)]
*  to a political group that was for Donald Trump and against Hillary Clinton. [[01:15:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4521.42s)]
*  To be a Trump supporter in 2016, this was at the height of the election insanity and [[01:15:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4526.22s)]
*  derangement in Silicon Valley. [[01:15:32](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4532.400000000001s)]
*  And so I think that a lot of people thought back then that you could just fire a Trump [[01:15:34](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4534.3s)]
*  supporter. [[01:15:39](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4539.46s)]
*  Facebook founder Mark Zuckerberg has denied that Luckey was fired for his political views. [[01:15:40](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4540.46s)]
*  What do you think now when you see those tech leaders, Mark Zuckerberg, lined up behind [[01:15:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4545.9400000000005s)]
*  President Trump now at his inauguration? [[01:15:50](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4550.1s)]
*  I am inclined to let every single one of them get away with it. [[01:15:52](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4552.34s)]
*  What do you mean get away with it? [[01:15:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4556.34s)]
*  Coming around to a point of view that is more aligned with the American people broadly, [[01:15:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4558.0599999999995s)]
*  I think is good for the country. [[01:16:02](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4562.54s)]
*  I think it is not good for you to have techno corpo elites that are radically out of step [[01:16:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4563.82s)]
*  with where the American people are. [[01:16:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4570.86s)]
*  In 2017, Luckey says he left Silicon Valley with hundreds of millions of dollars in the [[01:16:12](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4572.82s)]
*  bank and a chip on his shoulder. [[01:16:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4577.7s)]
*  I was fired at the height of my career. [[01:16:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4579.94s)]
*  My gears were ground and I really wanted to prove that I was somebody, that I was not [[01:16:24](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4584.34s)]
*  a one-hit wonder and that I still had it in me to do big things. [[01:16:28](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4588.46s)]
*  He says he thought about starting companies to combat obesity or fix the prison system, [[01:16:33](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4593.22s)]
*  but ultimately decided to break into the defense industry. [[01:16:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4598.34s)]
*  Have you run into any people who don't take you seriously because you were never in the [[01:16:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4601.860000000001s)]
*  military? [[01:16:45](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4605.82s)]
*  I don't think so. [[01:16:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4607.78s)]
*  I think I owe that to the James Bond franchise. [[01:16:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4609.34s)]
*  Everyone in the military has seen James Bond movies and they all like you. [[01:16:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4613.34s)]
*  I'm the wacky gadget man. [[01:16:58](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4618.82s)]
*  I'm the guy who types on the computer and pushes up my glasses and then gives them a [[01:17:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4620.58s)]
*  strange thing to help them accomplish their mission. [[01:17:04](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4624.26s)]
*  And this is his laboratory, Andrew's 640,000 square foot headquarters in Costa Mesa, California. [[01:17:06](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4626.9400000000005s)]
*  It's a mix of high-tech carpentry and robotic engineering. [[01:17:15](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4635.26s)]
*  A sign on the floor pokes fun at the boss's shoe choice. [[01:17:19](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4639.46s)]
*  But Lucky wanted to show us something off-campus. [[01:17:23](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4643.9s)]
*  We hopped in his 1985 Humvee. [[01:17:26](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4646.9400000000005s)]
*  The billionaire told us he also owns a decommissioned Blackhawk helicopter, a 48-crew submarine [[01:17:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4651.66s)]
*  and a Navy speedboat. [[01:17:38](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4658.26s)]
*  In Dana Point, we took a ride 15 minutes off the coast to see the largest weapon in Andrew's [[01:17:41](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4661.2s)]
*  arsenal, this submarine. [[01:17:46](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4666.7s)]
*  It's called the Dive XL. [[01:17:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4669.02s)]
*  It's about the size of a school bus and works autonomously. [[01:17:51](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4671.42s)]
*  It's not remote controlled by this computer. [[01:17:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4674.740000000001s)]
*  It's doing it on the brain, on the submarine itself. [[01:17:57](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4677.9800000000005s)]
*  So if I told it to go off and perform some mission, months long, like go to this target, [[01:18:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4680.9800000000005s)]
*  listen for this particular signature, and if you see this signature run, if you see [[01:18:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4685.5s)]
*  this one hide, if you see this one follow it, it can do that all on its own without [[01:18:09](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4689.38s)]
*  being detected, without communicating with it. [[01:18:14](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4694.820000000001s)]
*  Andrew says the Dive XL can travel a thousand miles fully submerged. [[01:18:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4697.94s)]
*  Australia has already invested $58 million in the subs to help defend its seas from China. [[01:18:22](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4702.94s)]
*  But Andrew's most anticipated weapon has been closely guarded until this month. [[01:18:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4711.219999999999s)]
*  Hidden inside this hangar, Andrew's unmanned fighter jet called Fury. [[01:18:37](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4717.179999999999s)]
*  There is no cockpit or stick or rudder because there's no pilot. [[01:18:44](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4724.06s)]
*  The idea is that you're building a robotic fighter jet that is flying with manned fighters [[01:18:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4729.06s)]
*  and is doing what you ask it to do, recommending things that be done, taking risks that you [[01:18:54](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4734.860000000001s)]
*  don't want human pilots to take. [[01:18:59](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4739.700000000001s)]
*  Fury represents a big turning point for the company. [[01:19:01](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4741.860000000001s)]
*  Andrew was viewed by some inside the defense industry as a tech-bro startup until it beat [[01:19:05](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4745.42s)]
*  out several of the prime defense contractors to make an unmanned fighter jet for the Air [[01:19:10](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4750.8s)]
*  Force. [[01:19:16](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4756.0s)]
*  Fury is scheduled to take its first test flight this summer. [[01:19:17](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4757.0s)]
*  If selected by the Pentagon, it, like all Andrew products, will be produced in the U.S. [[01:19:21](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4761.12s)]
*  The war games say we're going to run out of munitions in eight days in a fight with China. [[01:19:27](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4767.6s)]
*  If we have to fight Iran and China and Russia all at the same time, we are screwed. [[01:19:31](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4771.16s)]
*  We go to war, right? [[01:19:35](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4775.04s)]
*  Your version of what Andrew's place is in a conflict. [[01:19:36](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4776.64s)]
*  How do you view it? [[01:19:42](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4782.160000000001s)]
*  I think what we're going to be doing is first connecting a lot of these systems that otherwise [[01:19:43](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4783.360000000001s)]
*  would not have been talking to one another. [[01:19:47](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4787.8s)]
*  We're going to be making large numbers of cruise missiles, large numbers of fighter [[01:19:49](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4789.4400000000005s)]
*  jets, large numbers of surface and subsurface systems. [[01:19:53](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4793.08s)]
*  I guess I would hope that Andrew is making most of the stuff that's being used on day [[01:19:56](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4796.4800000000005s)]
*  nine, day 10, day 11, day 100. [[01:20:00](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4800.64s)]
*  I think a lot of that is going to be coming out of our factories after everything else [[01:20:03](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4803.24s)]
*  is run dry. [[01:20:07](https://www.youtube.com/watch?v=VAzKqh00g3c&t=4807.2s)]
