---
Date Generated: April 03, 2024
Transcription Model: whisper medium 20231117
Length: 4753s
Video Keywords: []
Video Views: 939
Video Rating: None
---

# The Upside and Downside Case for AI with Nathan Labenz and Erik Torenberg
**Cognitive Revolution "How AI Changes Everything":** [February 10, 2023](https://www.youtube.com/watch?v=iGD2TC4_6hI)
*  So now to see how many things are starting to go this way, where people who used to think of themselves as.
*  Incapable of doing these various tasks, whether it's writing in a certain, to a certain level, or speaking a different language, you know, translating from one language to another or writing code.
*  Like all these things that people have found hard are getting dramatically easier.
*  So, you know, we used to eat grain and turn that into energy and our muscles and move stuff that way.
*  And then we figured out we could dig up this, you know, this old coal that was sitting in the ground.
*  And harness that to do far more work and refining that over time changed everything.
*  AI is going to be very similar in that we are going to be able to delegate more and more cognitive work to these new systems.
*  And ultimately that will reshape not just how we work, but how we live in general.
*  The deeper I go, the more I think about it, the more I firm up my conclusion that no, this is the real deal.
*  This technology is going to change just about everything.
*  Hello and welcome to the cognitive revolution, where we interview visionary researchers, entrepreneurs and builders working on the frontier of artificial intelligence.
*  Each week, we'll explore their revolutionary ideas and together we'll build a picture of how AI technology will transform work, life and society in the coming years.
*  I'm Nathan Labenz, joined by my co-host Eric Torenberg.
*  The cognitive revolution podcast is supported by Omniki.
*  Omniki is an omnichannel creative generation platform that lets you launch hundreds of thousands of ad iterations that actually work customized across all platforms with the click of a button.
*  Omniki combines generative AI and real-time advertising data to generate personalized experiences at scale.
*  Nathan, welcome to our podcast that we're co-hosting together, the cognitive revolution.
*  It's great to be here.
*  Excited to give people a little bit introduction about yourself, about why we're starting this podcast and about the cognitive revolution in general.
*  So maybe by way of introduction, can you give a bit of an overview on yourself and how you came to be so obsessed with this topic such that you knew you wanted to go all in on it?
*  When was the moment or series of moments?
*  Yeah, well, it kind of surprised me honestly in the way that it happened because I've been interested in AI for a long time, you know, going back to like 2007 era reading, you know, what probably many listeners will know as the Eliezer Yudkowski sequences, which covered a lot of ground, but included there was kind of a projection of what AI might mean and how catastrophically wrong it could go for humanity.
*  And of course, that was, you know, at the time, pretty influential actually, and got a lot of people interested in AI safety.
*  It was also, you know, widely derided and dismissed as pure fantasy.
*  And I was always kind of in the in between space where it seemed to me like his arguments were extremely compelling, but obviously also highly speculative at the same time.
*  Right. So I kind of felt like, boy, you know, in the same way that an asteroid once came and took out the dinosaurs and it would be really bad if that happened to us.
*  And as a result, it seems like it makes a lot of sense for people to, you know, for at least some people, not everybody, right, needs to be obsessed with looking for asteroids.
*  But the great thing about modern civilization is we have division of labor and specialization.
*  And, you know, it sure made sense to me that we should have a program looking out of the skies and trying to identify asteroids and make sure that none comes and takes us out like, you know, like when took up the dinosaurs.
*  And recently we actually did send a space mission out and deflect an asteroid just to kind of demonstrate to ourselves that we could.
*  I thought about AI for a long time the same way.
*  You know, it sounded to me pretty unlikely, but serious enough that we should take it seriously.
*  And, you know, that was about as far as it went because I wasn't the one to specialize in the AI safety work.
*  The work as it was conceived of at the time was very technical, very mathy.
*  And, you know, I flatter myself to be a pretty smart person, but I was pretty clear on my limitations on the math side.
*  And I was not going to lock myself in the basement, you know, for a few years and come out with the provably safe AI theorem, you know, that makes everything okay.
*  So I kind of just supported those people that were willing to take on that challenge and otherwise just kind of continued to pay attention to it.
*  And, you know, that went on for years.
*  In the meantime, I've been an entrepreneur.
*  I started a company called Waymark and Waymark is a has been historically a DIY video creation platform, something that is designed to be extremely accessible.
*  We make it available through the browser.
*  You know, it's kind of the I have a whole riff, you know, that I talk about the three waves of creative creative one, creative two, creative three.
*  And Waymark started as a creative two company, which is to say, you know, there's obviously I think of Adobe as kind of being creative one power tools for power users, you know, take, take years to master creative two with the kind of thing.
*  Waymark was building highly accessible browser based tools.
*  Anyone, you know, should be able to figure it out.
*  And we worked really hard on that for a number of years.
*  We made it a nice tool, very polished, very intuitive for people.
*  And we got to a point where when we would sit down and talk to users and say, you know, what do you think about this product?
*  Is there anything we could do to make it easier?
*  Is there anything we could do to help you use it more?
*  A lot of times they would say to us, you know, it is easy.
*  We used to say if you can fill out a form on the Web, you can make a video on Waymark and people would say, well, yeah, that's that's true.
*  It is it really is that easy.
*  But I still don't really know what to say.
*  You know, I don't really have any ideas for what kind of content to make.
*  And it turned out that as accessible as we made the tool, that was kind of the main blocker.
*  So kind of realized that like our tool was easy to use, like a word processor is easy to use, like anyone can do it.
*  We all know how to type, but that doesn't mean it's easy to write.
*  And so as, as, you know, as simple as we made the tools, like people still were having a hard time getting over the barrier and creating video content on our platform.
*  We honestly didn't really know what to do about that from a UI standpoint.
*  But right around the time we were kind of hitting the limits of what we could accomplish with continued UI refinement.
*  Things like GPT-3 started to come out and opened up a whole new set of opportunities for how to improve our product.
*  So the modern, you know, my interest has gone back a long time, but my modern AI obsession really started with this opportunity that we saw at
*  Weimark to say, maybe we can help people with ideas or maybe they can have a very simple kernel of an idea and we can help them turn that into fully fleshed out content.
*  And I went down that rabbit hole and learned more and more.
*  And, you know, one of the big things that I've realized is that there is tremendous progress happening within AI across a whole bunch of different modalities at the same time.
*  Text generation, large language models probably get the most attention today.
*  And I think deservedly so, like they're super important.
*  I think of them almost as like the executive function of, you know, the AI future that I think is just starting to take shape.
*  Image creation is also really interesting, especially for us, because we're making video content, you know, it's sight, sound and motion.
*  So you need the script, but you also need the visuals to go with it.
*  And so the image creation, the art creation is also super interesting.
*  And I just kind of went deeper and deeper and deeper initially out of pure, you know, entrepreneurship motivations and develop these matras like AI beats UI.
*  And at one point it was even AI or die.
*  I was totally convinced that we either had to catch this new wave.
*  And I started calling that creative three, which is instead of just accessible tools, it's tools that actually help you do the work.
*  And, you know, for a while I was, I was at the time, the CEO of the company, I founded the company and was the CEO for a long time.
*  But I decided that, you know, it was really such a big shift that it was time to pull the emergency break on the company.
*  And I told everybody on the team, even, you know, my board like canceled board meetings.
*  I was like, we're not going to do anything else until we wrap our heads around this new AI opportunity and feel like we're starting to
*  pick up some momentum riding this new wave.
*  So that went on for like six months.
*  And during that time, I basically neglected everything else and did nothing but AI work and tried to, you know, get the team kind of again, catching the new wave.
*  And that started to work.
*  But also after a while, you know, as you would well understand, like you can only neglect the practical side of running a company for so long.
*  And things started to kind of pile up and demand attention.
*  And so, you know, eventually I was kind of faced with the choice.
*  Like, do I want to, you know, try to put down some of this AI work and, you know, find somebody who can lead that at our company?
*  Or what I ended up deciding to do, and I was fortunate to have the right teammate who could take on the CEO role was promote a long time friend and
*  teammate who had been our COO and our product lead.
*  He was the perfect person to step into the CEO spot.
*  And that allowed me to just go full time, you know, deeper and deeper down the AI rabbit hole.
*  I just continue to learn and I just find the topic so fascinating because it is both technically deep, you know, and you have a hard time getting to the bottom of it.
*  Certainly I don't feel like I've gotten to the bottom of it.
*  It's also philosophically really interesting.
*  Like, what are these things?
*  How should we think about them?
*  How should we relate to them?
*  And it's also just practically really cool and useful.
*  You know, I, one of the reasons I was interested in starting a company like Waymark and building that product is I am not a visual artist and I needed a tool like that.
*  That is so simple to help me create content.
*  So now to see how many things are starting to go this way where people who, you know, used to think of themselves as incapable of doing these various tasks, whether it's writing to a
*  certain level or speaking a different language, you know, translating from one language to another or writing code, like all these things that people have found hard are getting dramatically easier.
*  And that's changed the way I work.
*  It's changed my daily workflow.
*  And I think, you know, what I have kind of experienced is really just a preview of what's to come for broader society.
*  So there's a lot to unpack in the AI space and I'm looking forward to doing that with you.
*  That's a, it's a perfect segue into the cognitive revolution and what we're, what we're doing here to talk a little bit behind the inspiration for the name and the ideas that are like, you know, we were thinking of a good name for the podcast.
*  And you had this idea of the cognitive revolution.
*  Talk a little bit about that and what are some of the areas you were hoping to do deep dives on this podcast?
*  There's a lot of hyperbole in the world today, right?
*  And every new technology comes with a hype cycle.
*  And one of the things I've really challenged myself to try to think hard about is, is this really going to be a transformative technology or, you know, is, is there still some possibility that this will all kind of peter out and we'll look back and, you know, when VH1 makes, I love the 2020s, you know, where will there be this sort of AI vignette that was like, oh, remember when everybody was excited about that?
*  And I really have challenged myself to try to think hard about that.
*  The deeper I go, the more I think about it, the more I firm up my conclusion that no, this is the real deal.
*  This technology is going to change just about everything.
*  And so I think the better, you know, people are looking back, right?
*  Always for a historical analogy, like, is this like the rise of computers?
*  Is this like the rise of mobile phones?
*  Even electricity?
*  Is it the, isn't like the rise of electricity?
*  I think that's maybe the best of those three, but I think the shift is actually even more profound than even people who are paying a lot of attention to AI tend to think.
*  I conceive of this now as really the rise of a kind of a new force in the world.
*  This new kind of intelligence, kind of an alien intelligence.
*  It is very different from us.
*  I don't think we should think of it as being like us at all, but it is something that I think is really profound.
*  So we're finding new ways to solve problems and to process information.
*  And I think the right analogies are actually going deeper into history.
*  So looking back at the agricultural revolution and even more so, and more recently, the industrial revolution and thinking, boy, we used to do stuff with muscles.
*  And then we figured out how to do it with machines.
*  We used to power it with calories.
*  You know, we used to eat grain and turn that into energy in our muscles and move stuff that way.
*  And then we figured out we could dig up this, you know, this old coal that was sitting in the ground and harness that to do far more work.
*  And refining that over time changed everything.
*  I think that AI is going to be very similar in that we are going to be able to delegate more and more cognitive work to these new systems.
*  And ultimately, that will reshape not just how we work, but how we live in general, the day to day experience of going through society, the way we interact.
*  And it's really hard to picture how that shakes out.
*  You know, if you even if you went to the inventors, I think really interestingly, are not necessarily much better positioned to envision that future than the rest of us.
*  If you were to go back and ask James Watt, you know what society was going to look like as he was tinkering with one of his early steam engines,
*  I don't think he would have necessarily had a great sense for where we end up.
*  You know, people are very focused on making the thing work that they are making work.
*  But the big picture, the long term implications of that are not at all clear.
*  So I wouldn't say that I have great clarity on that either.
*  But what I want to do with the show is I hope we can do both.
*  Right. I hope we can understand the details and really push ourselves and help our audience achieve more precise understanding of a lot of the phenomenon that we're seeing.
*  But at the same time, try to zoom out and understand to the best of our ability, what is the overall change that we're starting to witness?
*  And for my money, I do think this will be written about in the history books as a pivotal time like those previous revolutions when ultimately everything changes.
*  Yeah, that's well put.
*  I mentioned to you offline that one inspiration for the show is what is show Bankless and what they've done in the crypto space, the Web3 space is exactly what you've outlined.
*  They both help make sense of what's happening in the here and now.
*  And I've been a loyal listener for a while, but they also zoom out and explain just why this matters on a broader level.
*  Crypto also is touching various elements of society.
*  But then also they host a number of debates and really wrestle with the different opinions in the space and track them as they evolve.
*  So I think that's well put.
*  Flashing out a bit further, what are the kinds of guests?
*  This podcast, like the space itself, is a bit emergent.
*  And so we're coming up with it on the fly a little bit, and we will benefit from audience participation and what our audience would like to see.
*  But maybe just give a little preview of what kinds of guests or what archetypes of guests and what kinds of questions or topics will we want to explore?
*  Yeah, I mean, I think there are a lot of different ways that we can go and certainly don't think there's going to be any one mold that a guest is going to be.
*  And that's something that this has to fit into to be really interesting to us.
*  But in general, I think the prototype that I am most interested in is people that I would kind of describe as already living in the future.
*  People that are working and building with the latest tools that have a vision of their own, you know, which may or may not turn out how they have it in mind,
*  and they have a vicious vision for what they want to build and how they want to change one corner of the world.
*  And I think those people, again, they're so focused in general on what they're building.
*  You know, they might be building a next generation art tool.
*  We're going to have the founder and CEO of Replica on as well.
*  And she's got a virtual friend product.
*  What does she envision for the future of virtual friends?
*  Right. I really don't know, but I'm extremely interested to find out what she has in mind for us.
*  Because virtual friends are, you know, that's a big that's a big shift, right?
*  We've we've never seen anything like that.
*  You know, we've had our imaginations.
*  But now to have a technology that can flatter you, you know, that can engage with you, that can potentially challenge you, that can potentially deliver cognitive behavioral therapy to you, you know, that can even bring its own imagined problems to you and ask you to be, you know, an ear for it.
*  I mean, this is a totally new world, right?
*  So I think this is just going to repeat across so many areas of life, so many areas of work, even science.
*  What are all these people who have these sort of narrow domain specific visions trying to create?
*  How do they envision that part of life changing?
*  And then cumulatively across all of those, can we start to piece together a bigger picture view of what life and society are going to look like as all these things start to come online?
*  And it's only going to be one to two years before most of these things are are starting to hit the public, right?
*  You know, this is not like a speculative thing in the sense that we're going to go do deep R&D for a bunch of years and maybe we'll come out with something that has already been done by the likes of open AI and DeepMind and, you know, anthropic, a few others.
*  Google, I should say, also obviously DeepMind part of Google, but Google, independent of DeepMind also has a lot of great work going on.
*  That deep R&D has it continues, but enough of it has been done that the tools are now there to productize this core technology in so many different ways that I think we can expect meaningfully new experiences, different kinds of things coming online than we've ever seen before.
*  And as that happens all at once, you know, it's going to change kind of everything.
*  So trying to get ahead of that and form a picture of what life looks like even just two years from now, I think is a big challenge, but you know that that's a big part of the reason again that I'm excited to do this show.
*  Totally. What meta question for the show or plotline will be? At what point do we get replaced as hosts? And, you know, does the audience even notice?
*  Yeah, well, you know, I just saw last night a new text to speech engine. And, you know, this is like basically a daily occurrence at this point, right? There's almost almost never a day goes by where.
*  I don't see something of meaningful new interest coming across typically AI Twitter is where I find that stuff. Certainly not a week goes by without something meaningfully new and different.
*  But last night it was text to speech, a new product that starts at twenty two dollars a month and allows you to clone your own voice in just a few minutes.
*  They're they're very new. They just launched this product and already they're starting to see, you know, tons of exciting use cases. People are loving it's getting rave reviews.
*  But they just posted on Twitter this morning. I believe that they're also starting to see some abuse. They're seeing people come in with audio.
*  They know that's not their own voice, right? And they have terms on the site that you must be the rightful owner of the audio and have the consent of the original person.
*  But people don't necessarily have to follow those terms. And it's not always easy for them to tell. So they're already, you know, in just a matter of days kind of confronting how their product is is hitting the real world.
*  And, you know, there's a lot there to wrestle with. So I do think we'll be able to, you know, probably could piece together within the not too distant future, some pretty good AI facsimiles of ourselves.
*  And that is going to come with a lot of questions for us, you know, and and certainly for the public at large.
*  Yeah, it's fascinating. Going to your timeline idea, Flo on the Moment of Zen podcast that we're also re-releasing as part of this podcast said that in the short term, it's overhyped.
*  And in the medium term, it's underhyped. You this offline, we're talking about your expectations for the future, even assuming no future breakthroughs are maybe more shocking than people would realize in terms of what to expect.
*  So why don't you paint a little bit of the of the future in that scenario?
*  Yeah, I guess, you know, first of all, the no major no new breakthroughs concept, I think is is probably worth unpacking just a little bit and explaining.
*  And, you know, probably a lot of people know this, but not everybody.
*  What is happening right now is that a few core techniques.
*  Are being shown to work basically on all the problems to which they're being applied, and those techniques are probably everybody's familiar at this point with the transformer architecture that came out of Google in 2017.
*  So, you know, by the way, for practical purposes, if you're new to A.I., that means you really only have five years of intellectual history that you need to catch up on everything before that.
*  You know, people would say, oh, you need to understand it.
*  I don't know. I think you can really just jump in.
*  Rush straight to the front and try to understand what's happening now.
*  I personally spend a little time going deeper into history, but not that much.
*  So five years of intellectual history, this has all been pretty recent.
*  Transformers architecture is one reinforcement learning is another that actually predates transformers, but has continued to be applied to transformers, which has been really fascinating convergence.
*  In general, a lot of things are converging, right?
*  Because it also takes cloud scale compute.
*  That's another major factor is just huge compute power.
*  You can't do this. You can't train these models on a laptop or even a few laptops.
*  You know, right now you can't even really run them on laptops, although I think we will soon see more and more models getting small and efficient enough that they can run on local devices.
*  You know, what's kind of amazing is that this is turning out to be an extremely generalizable approach.
*  And transformers are helping people do the text prediction of the sort that we see in chat GPT.
*  There are image and video creation technologies that again, just take in very simple text.
*  Like I want to see a, you know, image of this and make it for you that are also transformer powered.
*  There's also another kind called diffusion models, which are a bit different, but both are working quite well.
*  And they just continue to roll out, you know, across all sorts of different modalities.
*  Some of the ones that I think are most kind of interesting and scary are in biology.
*  People probably are aware of Alpha Fold from DeepMind, which was the first AI to solve the protein folding problem.
*  And that was a decades long open problem of trying to predict from the computer that the protein is going to be able to be processed.
*  And we did not have any good ways to do it. We really relied on lab chemistry and a process they call crystallography, where they try to.
*  Create a little crystal of this protein and then I think bump like x-rays up against it and then interpret that and it could be like a whole PhDs worth of work.
*  To create one protein structure through this crystallography process.
*  I'm not an expert at it, but the future, we're probably not going to have nearly as many experts in that because now we have these AIs that can do this guessing.
*  At, you know, literally 10,000 times the speed, right? It would take somebody five years to do this.
*  Now it's like a couple minutes, maybe to to come up with a pretty high confidence structure for a protein that's going to bring about in and of itself.
*  You know, a whole revolution in biology because we understand so much more than we have in the even just the very recent past.
*  I think we'll see applications of this to metaverse.
*  You know, the biggest problem I have right now when I put on my Oculus, I do it about once a month is that there's just not that much content in there.
*  Not that many. You know, there's a few worlds to explore that that Zuck and team have created and they're pretty cool.
*  I think the hardware is pretty awesome, but the you know, you just kind of get to the end of the world pretty quickly.
*  Meta also released a text to 4D model is what they called it.
*  But basically what that means is dynamic 3D scenes.
*  So you can now say, I want to see a dog jumping through a hoop and it will create not just an image, not just a video, a flat video,
*  but actually a fully 3D rendered scene with a mesh that you can rotate around.
*  You can place the camera anywhere you want it.
*  That means in VR that you could walk around that object and see it from any perspective.
*  And you can even import those because they are defined as 3D meshes.
*  You can import them into any other 3D world.
*  So and obviously, you know, Meta has a vision here, right?
*  They're they're anticipating a world where in the near future, their users can put on the headset and conjure up whatever they want and modify their environments and kind of create their own adventures and experiences.
*  And, you know, I think that might be the thing that actually moves us into the metaverse.
*  You mentioned crypto a little bit. I'm not a big crypto head.
*  I would, you know, punt on almost all crypto questions.
*  But one of the things that has always sounded coolest to me, but which hasn't really happened so far from what I understand is the truly smart contract.
*  And, you know, I think, well, why is that?
*  One reason is I think it's pretty hard to code a smart contract.
*  It's hard. It's been all it's been very hard to code any sort of dispute resolution into an algorithm, you know, with explicit code.
*  But I suspect that we may also see a I put the smart in smart contract.
*  And I think you can envision a world where people enter into agreements which can live on a block chain and which encode a method for dispute resolution that actually goes to an AI and maybe even allows you to have an AI powered arbitration.
*  Maybe that's just the first line of defense initially.
*  But if you can reduce the cost of arbitration from, you know, many thousands of dollars down to a buck or two, as you use an AI that's obviously always available, you know, special trained for this.
*  You know what model you're getting because you have like a hash of it that's verifiable that's on the chain to know what you're pointing to.
*  I think that could also really change the dynamic and the relationship between corporations and consumers in many contexts or even local businesses and consumers.
*  Right. I mean, a lot of times it's not necessarily the big corporation that people have trouble with.
*  It might be like the roofer that they hired.
*  So where do you go if you like still have a hole in your roof and the you know, they've got your money?
*  I think we could see AI powered arbitration bring the cost of of handling those kinds of issues down dramatically and really improve the market at large and bring a lot of that stuff onto the chain where it's been a little bit too difficult to do historically.
*  There's more domestic servant robots.
*  I think the technology, the AI is getting there now to the point where the robots can understand their environment.
*  You know, they can't understand commands.
*  We were seeing it in demo stage.
*  They'll pick me up that cup off the counter and bring it over here.
*  You know, in the lab at Google, that is now happening from pure natural language instruction through the computer vision, understanding what you want and executing on it.
*  I think it's likely that we're going to see mass production of those robots and actual deployments to everyday households in the next two years.
*  But in the next five years, I do think that's starting to look pretty likely.
*  Also, personal, you know, you mentioned earlier, like AIs that you could replace us in the podcast.
*  I don't know how that is ultimately going to shape up.
*  But we see so many people right now working on little bots to like draft your emails as you or, you know, come up with a reply to your tweet mentions as you.
*  And those are starting to get OK.
*  I personally haven't found them to be quite at replacement level for myself.
*  Maybe that's narcissism.
*  But, you know, there's a lot of different roles that such a thing could play.
*  And it doesn't necessarily all have to be about like publishing thought leadership content.
*  It could also be about just handling regular mundane business, right?
*  Like handling the scheduling emails that I type out on my own.
*  I don't need that to be genius content.
*  We just need to identify a few times and move the conversation forward.
*  Or I'm a big fan of what Do Not Pay is doing right now in terms of language models that go and talk to, for example, Comcast,
*  you know, and try to either renegotiate your bill or, you know, get some get some overage fee from your cell phone carrier eliminated.
*  You know, as they kind of represent you act as you are your agent, I think will be extremely interesting and kind of ubiquitous before we know it.
*  Energy is another one. Everybody, I think, agrees that if we could have clean energy, that would be awesome.
*  And when I see things like DeepMind's Fusion Control paper, where they train a reinforcement learning system to control like a bazillion knobs,
*  you know, ultimately controlling a bunch of magnets to control the fusion reaction environment in a way that, you know,
*  certainly no human could do or that we could, you know, we were very far from being able to explicitly code those controls.
*  I think, man, maybe maybe I could even help us solve the energy problem.
*  So, man, I could, you know, I could go on about this forever.
*  But, you know, that's that's a sampling of all the different aspects of life, you know, from energy to medicine to interaction.
*  Then we got Neuralink, too, that's going to bring brain reading interfaces.
*  And as Elon Musk put it recently, I highly recommend Neuralink's recent show and tell video for another kind of glimpse into the future.
*  He said, you know, the best way to interpret what's going on in the neural net that is your brain is another neural net.
*  So even understanding our own brains and the activity in them is ultimately now running through AI models.
*  So all these things coming together, right, and all these things exist.
*  They're not all refined.
*  They're not all productized and they're not all integrated.
*  But I think that those things are basically inevitable at this point.
*  They will be refined, they will be productized and they will be integrated and combined in all sorts of ways.
*  And entrepreneurs are going to really get their hands on these and create all new things.
*  Right. It's a very the role of the R&D, you know, research lab, whether it's a university or a major corporation and the role of
*  productizing that those are quite different jobs.
*  The first one is done.
*  The second one is just starting to be done.
*  But it is that second job of kind of refining productizing and figuring out how to remix and recombine all these things that will ultimately bring us the form factors that, you know, will become ubiquitous in our daily lives going forward.
*  That's a fascinating overview.
*  I'm curious to get into what's what's underhyped and what's overhyped.
*  Or where do you disagree with the you know, what are the naysayers miss and where do you what is the do-mers miss or you know, what points do they get right?
*  Yeah, well, I'm kind of both, I guess, for for starters, I have felt over the last year or two, a really interesting, especially the last year, a really interesting mix of kind of exhilaration, anticipation, excitement for this technology and what it can mean.
*  What it can allow me personally to do.
*  But also, you know, the the opportunity to to create radical access to expertise is one of the big things that I'm also expecting.
*  You know, so many people around the world really suffer for lack of access to expertise.
*  And I think it's just extremely exciting to imagine a world where all of the world's eight billion people can have access to, you know, a good quality frontline doctor, for example, that can help.
*  Help them understand what's going on.
*  You know, there's tremendous, tremendous potential in that.
*  And I'm super excited about it.
*  At the same time, I do think those that worry about catastrophe are right to worry about catastrophe.
*  I'm pretty reluctant to use analogies because I think that, you know, it's much better in general to try to understand the thing on its own terms, you know, versus trying to shoehorn understanding into analogies.
*  I think they can they can mislead us pretty easily.
*  But one that I do find kind of useful is the analogy to invasive species.
*  And, you know, just kind of this, I was inspired on this because I took my kids to the Detroit Nature Center not too long ago.
*  And I realized that, you know, most nature centers around the world are pretty much the same.
*  They all kind of have like, here are the amphibians that are local to our environment and here are the lizards, you know, or the frogs or the bees or, you know, the small mammals and and the birds.
*  Right. And you kind of think, well, geez, all around the world.
*  Every nature center has those same things.
*  Why is that?
*  And the answer is all of those things were at one time invasive species that colonized the whole world.
*  They all started somewhere and much like humans, they all colonized the whole world.
*  So there is actually a lot of precedent for some new form that is quite fit and quite adaptable to pop up.
*  And of course, it kind of has to pop up in one place.
*  And, you know, if it has sufficient fitness and adaptability, next thing you know, it can be everywhere.
*  That takes a long time when you're humans, you know, walking out of Eden and, you know, gradually covering the whole world.
*  I think it will happen a lot faster in the context of AI.
*  And I think, you know, at a highest level, we're really not ready for that.
*  We have no idea what that is going to look like.
*  So from my standpoint, you know, it's emotionally interesting mix of, and I try to keep both in mind of this kind of exhilaration and excitement for what's to come, but also the recognition that we're not ready and that there are real reasons to be concerned.
*  So, I mean, you mentioned the naysayers on that one.
*  It's a little bit tough.
*  I honestly, I have to work kind of hard to try to understand what people are thinking when they go use chat GPT and say that it's like not interesting to them or it's not impressive or it's like boring.
*  So I don't have a ton of confidence in what's going on there.
*  I think one thing that people have consistently failed to do over the last couple of years is just understand that like, whatever they're looking at right now is not likely to be the end state.
*  You know, and you've kind of heard these same comments.
*  Well, GPT 2 and kind of sucks like the outputs are pretty good.
*  Yeah, kind of cool.
*  But, you know, it'll never be useful.
*  GPT 3.
*  Well, you know, it's better.
*  It's a lot better, but you know, it's still kind of sucks and you got to prompt it in these weird ways.
*  Oh, instruct GPT.
*  Well, that's pretty cool.
*  But, you know, we'll get it.
*  I'll still does these things wrong.
*  And now we're on to chat GPT and it's like, man, it does a lot of things right.
*  But look, I can still tripped it up on this, you know, math problem and no human would make that mistake.
*  So, you know, we're not at the end of that, of that journey.
*  So I think that's one thing that people are kind of missing is like they're taking these snapshots in time and, you know,
*  zeroing in on these limitations and kind of jumping to the conclusion like, well, this will never amount to anything because look like it, you know, it couldn't do this.
*  That's that's very odd to me, but I do think that's a pretty common pattern.
*  I think another thing is kind of implicitly evaluating these AIs on a human sort of standard.
*  And you do see that or hear that notion that, you know, human would never make this mistake.
*  You hear that fairly often.
*  And I think that's true in a lot of cases, but also kind of missing the point.
*  Like, again, you know, invasive species, or I also think about these AIs, I'll try to discipline myself actually to thinking about them as aliens.
*  I really try to keep in mind, like, even though this is speaking my language, even though, you know, it's learned so many kind of human intuitions.
*  It is an alien beast under the hood and, you know, its cognition.
*  Like shares some important, you know, traits of mine, like it can do a lot of the same things I can do and I can do things that can do.
*  So there's a lot of overlap, but there's also very profound differences that run super deep.
*  And as a result, there's like different strengths and weaknesses.
*  So, you know, the chat, you bet, like makes a lot of math mistakes, you know, even like simple arithmetic.
*  But it's also really good at coding.
*  So, you know, most people can't code.
*  Obviously, some can.
*  Most can't.
*  It can do arithmetic by generating the code to do the arithmetic, and then it can use a calculator.
*  And that's kind of like, oh, well, it has ways of compensating for its weaknesses.
*  In that case, kind of a similar one to us, right?
*  We're not also that great a computation.
*  We use calculators.
*  So in that sense, you know, there's some, some similarity as well.
*  But I really think it's important to try to understand these things as much as possible on their own terms.
*  I think these analogies are kind of like evocative, hopefully suggestive, hopefully get, you know, wheels turning, but shouldn't be taken super literally.
*  And, you know, trying to kind of keep in mind that these are like alien intelligences that we don't have great intuitions for out of the box that have very different strengths and weaknesses from us and that the strengths relative to us are, you know.
*  Probably more important to understand than the weaknesses in some ways, right?
*  I mean, if, if I can do a certain task, and it's very trivial and easy to me and an AI can't do that task.
*  Well, so what?
*  Right.
*  It was already trivial and easy to me.
*  If it can do things that are well beyond my capabilities, then that's a huge deal because I previously had no way to do those things.
*  But I do think people are kind of missing the point in some cases where they zoom in on, oh, well, I would never make this mistake.
*  It does.
*  Therefore, it's dumb and I'm smart.
*  But I would really encourage people to look at the reverse, you know, and say, what can it do that you can't do?
*  And what would you take away from that?
*  So those are a few big ones.
*  And we talked about, I mentioned earlier, the entrepreneurs thing, you know, I do think we're looking at pretty raw technology right now still.
*  And what has not happened yet, but which will happen is kind of change in process.
*  I think you can look back at recent shifts in such major things as like how we get around with the rise of Uber, where a new technology paradigm allowed for the
*  rearrangement of that activity and just a fundamentally new structure that created new ways of doing things.
*  Dating is a similar one.
*  You know, I got married too young to ever be on Tinder, but obviously it's very different than it used to be.
*  And the technology, you know, first the technology had to be invented and then people had to kind of figure out how to restructure the human activity to take
*  advantage of that technology for better or worse.
*  I think people probably are rightfully thinking right now, is that all to the good?
*  I don't know. I've never been on Tinder, but when it comes to AI, it'll be the same, right?
*  There's going to be a lot of activities that can be kind of pulled apart, atomized in various ways, broken down into subparts.
*  And the parts that are readily delegatable to AIs will be delegated to AIs as soon as people can figure out how to rearrange the work processes to do that.
*  And that process is just getting underway.
*  So I think, you know, we really don't know what that's going to look like.
*  That's one of the things that I hope our guests will help us understand and envision in a much more detailed way across a lot of different areas.
*  But I think that is that is maybe the biggest one that the naysayers are kind of missing, where they're like, boy.
*  I'm just talking to this language model and it can't use the Internet and it can't do anything.
*  You know, it's just all it can do is like generate text.
*  That is the raw technology, right?
*  That's like the iPhone, you know, before there were any apps in the app store and all those apps are coming.
*  I think they're going to be, you know, a huge, huge deal and much certainly much bigger consequences than the naysayers are kind of imagining.
*  I don't really think I think the do-mers are if they might be overconfident, obviously, they are confident to varying degrees.
*  I think more often they're actually pretty intellectually modest, and it's not that they're saying this is definitely going to happen.
*  It's more like, hey, I don't know if this is a 5% chance of happening or 25% or whatever.
*  We probably can't get that precise in those numbers.
*  But if you believe it's anywhere in that range, you know, that I could literally take over the world, then, you know, going back to the.
*  The asteroid metaphor at the top, like we really should be paying a lot of attention to that, and it seems like, you know, I, I agree that I think the do-mers are also the at least the ones that I know broadly very much appreciate the upside of the technology.
*  It's not like they're blind to it.
*  It's not like they're blind to it.
*  They are just choosing to focus their time and attention and their messaging on the risk because they think it is broadly neglected and dismissed.
*  And, you know, they think that's wrong.
*  I personally cannot find any flaws in that argument.
*  You know, I would be open to, you know, somebody who says, well, I think it's only a 1% chance and somebody else who says, you know, I think it's a 50% chance.
*  I have pretty radical uncertainty there about, like, just how dangerous these new things will be, but.
*  I haven't heard anything that is compelling to me to say that I shouldn't worry about that.
*  And really, it seems to be mostly when people are like, oh, that's silly.
*  I think that's kind of an analogy gone wrong, right?
*  I think they're kind of making an analogy implicitly to fiction and, you know, sort of saying like, well, yeah, you're just being overly, you know, influenced by the Terminator or whatever.
*  And by the way, most of these folks like hate the Terminator because they've heard that so many times.
*  Like that is such a, you know, such a farcical vision of what would happen.
*  Like the reality is, you know, not going to be anything like that.
*  But.
*  You know, it still could be very hard to control.
*  I think there's a couple of different strains of thought on this on the Moment of Zen podcast.
*  Amjad did, I think, a nice job of articulating the Eliezer view.
*  But I would say that's probably not the predominant view at this point in the AI safety community.
*  Even Eliezer, I think, has, you know, has evolved like his original idea that some kind of small kernel of intelligence could kind of go critical, you know, almost like a nuclear.
*  Criticality chain reaction, exponential explosion type of thing mediated by like recursive self-improvement.
*  That's the phrase that, you know, people are most probably familiar with recursive self-improvement.
*  That's a very interesting idea.
*  I don't think that really resembles the AIs that we are seeing today.
*  What we're seeing today on the in contrast are like very broad models.
*  They're not like these tiny little kernels of like super hard intelligence.
*  They're kind of instead like much broader, softer, less reliable, but still extremely useful intelligence.
*  And we're kind of in the process right now with reinforcement learning, kind of in the process of like banging them into shape.
*  This just it's almost like raw metal, you know, that needs to be formed.
*  And so through this huge process of collecting more and more feedback, we're gradually identifying the cases where it doesn't do what we want it to do and teaching to do what we do want it to do.
*  That's a big part of what has gone on to make CHET GPT like, you know, you could call it safe.
*  You could call it, you know, inoffensive.
*  You could call it woke at times.
*  But there's been a lot of work that's gone into that to try to shape that behavior in an intentional way.
*  And the modern view of the safety risks, at least the ones that I think are most likely to hit us in the in the not too distant future are based around.
*  That reinforcement learning concept, and specifically, there's just one insight that I think is super profound.
*  It's that.
*  Humans are fallible, right?
*  We are not reliable in all sorts of ways like the, you know, the heuristics and biases literature, the sort of behavioral economics literature, like shows, you know, lots of little ways that people are reliably or at least predictably irrational and exploitable.
*  And so in the context of training AIs with feedback, the mechanism really is that they are trying to do whatever the human will give them the highest score for having done.
*  That's like the core idea, right?
*  And the AI is trying to do whatever will maximize the human feedback score.
*  Given that we are not fully reliable and that we are kind of predictably exploitable, it's not a big leap to think that there are times when the best way to maximize the score.
*  Is not by being honest, right?
*  And in fact, by like being deceptive or lying, you can think about that, you know, in your own personal life, right?
*  Are there times when you can get through a situation a little bit better and get higher marks and have a more pleasant interaction by being less than fully honest?
*  Yeah, right.
*  I mean, just a little flattery here or there, you know, that maybe you didn't fully mean to give just one, you know, very obvious case.
*  So if the AIs can start to pick that stuff up.
*  And they can learn to first, they learn that.
*  Deception is sometimes a path to higher scores, right?
*  And then that that would kind of imply that they're starting to develop a psychological model of people where they're not just trying to give the, you know, the raw truth, but they're instead trying to give.
*  The, you know, version of the truth or just whatever output that will get the highest score from people.
*  Now you've got a really dangerous dynamic on your hands where you don't know when is this thing being honest with me?
*  When is it potentially deceiving me?
*  When is it manipulating me to get a higher score?
*  And of course, you can try to test for that behaviorally in all sorts of ways.
*  And, you know, that network is, I think, already underway.
*  Leading companies could do a better job, honestly, of sharing more of what they're doing in the safety realm.
*  Totally makes sense to me that they don't want to share all their trade secrets, but I would like to see a little bit more transparency on what they're doing on the safety side.
*  But I think that that process of trying to identify that failure mode of is the AI like learning to deceive us, I think that is underway.
*  At the biggest companies, you know, it's a tough one, and we don't have great visibility into the internals of what is happening in these models.
*  You know, it's not clear right now that we would be able to identify deceptive behavior if it existed.
*  So, and, you know, there's a lot of good stuff happening in the mechanistic interpretability field, which is really, you know, trying basically trying to solve that black box problem.
*  And that happens, you know, all different kinds of angles and all different kinds of scales, like how are you solving these various problems, like literally from, you know, node to node within the matrix, trying to trace causal paths so that you can really get down to a very and even visualize like this is how this is the mechanism for how it's doing these different things.
*  That work is making a lot of good progress right now, but, you know, it kind of feels like there's a little bit of a race between the scaling up of just the raw power of the models and the reinforcement learning.
*  And with that comes this risk of like, potentially learning to deceive us.
*  And then on the other hand, you know, can we crack these things open and gain a strong enough understanding that we can be confident as to whether or not that is happening?
*  That I think is a super and maybe the most important, but they are pushing forward.
*  You know, they are pushing, pushing their capabilities forward.
*  You know, we're doing this reinforcement learning at greater and greater scale.
*  They are also trying to solve the black box problem internally.
*  And the broader world is trying to solve that black box problem.
*  But, you know, right now I think it's, it's definitely fair to say that those who worry about it are in my mind very well justified in doing so.
*  That's a good overview of the both today's era and do our perspective.
*  You know, we do hear a lot about the Doomer perspective and the different versions of it.
*  We don't hear a lot about the utopia or the opposite of the Doomer perspective.
*  And I'm curious if you could outline what that could look like.
*  And then I'm curious if you can respond to the recent critique Teal made in a couple of his talks where basically he's painting the overview of the last 10, 15 years.
*  And he says originally it was much more idealistic.
*  It was much more here's what AI is going to bring and we must it's our duty to bring it.
*  And he chronicles that movement as kind of evolving into what he calls like a big Burning Man camp.
*  And they got kind of like much more scared about, you know, much more Doomerish, much more passive, much more we need to slow.
*  We need to be careful.
*  And he kind of says that that is a microcosm of what's happened in society in general, in that we kind of lost faith in technology and are just much more cautious and conservative and less ambitious than we used to be.
*  Yeah, well, it's I mean, that's interesting because I broadly agree with Teal's worldview in terms of there's a certain mojo that we've lost.
*  And I often cite to people the Empire State Building was built in like 400 and some days and the Golden Gate Bridge was like a three or four year project.
*  And these days, the Second Avenue subway line is often cited and there's the however many million dollar bathroom in San Francisco that may or may not happen, depending on all the veto points that it has to get through.
*  I think that that criticism of.
*  You know, American society or Western society certainly seems to apply in Europe as well, although they do build subways far more economically than we do.
*  So it's not all that in Europe.
*  I think that critique is broadly right.
*  But I don't think we should rush to apply that to AI because the power of this is just totally different.
*  But again, the AI side, it's just it's a it's a fundamentally new thing.
*  We don't know what we're in for.
*  We don't know what dynamics are going to emerge.
*  I'm kind of expecting a whole new AI O sphere.
*  I might call it. I've been using the term AI ecology lately, increasingly often as well.
*  It's not just that we're going to have one new, you know, powerful thing from an open AI or a Google that's going to change the world.
*  It's that all this stuff is going to happen at once simultaneously.
*  And we're kind of letting all of this stuff out of the barn.
*  Right now, without really a good sense for how it's going to shake out, I don't think in this way, in this way, I kind of think Teal is sort of wrong in that, like, you know, Sam Altman is going pretty fast.
*  You know, I think he's also in some ways showing some admirable restraint.
*  But I don't think, you know, you can't really look back at the last five years and say that they're not moving forward and that they don't believe in technology.
*  So, yeah, maybe like I just posted a Twitter thread on Mitch Album and his column on Chachi PT, which actually I thought was pretty good overall, which I was glad to see because I grew up a huge fan of Mitch Album and read him in the Detroit free press.
*  Every which we got at home as a kid.
*  So it was cool to see that he had, I thought, a pretty wise take in some ways, but like maybe in general, like the media is sort of too negative and kind of the, you know, the culture is maybe too negative.
*  But I don't know.
*  You look at the people who are really doing the work and I don't I don't feel like that criticism like fits them.
*  Yeah, not not Sam, but maybe Facebook or Google or some of these other players that had such a big head start.
*  And yet what happened?
*  Maybe Sam is the exception to the rules.
*  Yeah, we'll see.
*  I Google, I mean, I'm certainly Google has become bureaucratic.
*  I mean, I've never worked there, but that seems to be by all accounts.
*  True.
*  It's important to keep in mind also that they had a head start, but.
*  Going back to 2018, 2019, 2020, 2021 technology.
*  It was not a credible threat to Google.
*  You know, it was not something that was going to substitute for.
*  The content you would find via search.
*  It wasn't really capable of answering questions at that high of a level yet.
*  Now we're tipping into a world where.
*  It is starting to hit that level, right?
*  ChatGPT can answer a lot of questions.
*  I do find myself going to AIs for some things that I used to search for.
*  So there is a shift underway, but it's really only been the last few months.
*  And so I think it really depends where you start the clock, you know, and I think it hasn't been that long.
*  It's only been two months right now since chatGPT was first released.
*  Was first released.
*  Feels like a long time. It is a long time in in AI years, but it's not really that long, you know,
*  and they already have a code red at Google and they do have technology that, you know,
*  is roughly on pace with what open AI has.
*  So I would personally be pretty surprised if they can't get it together and, you know,
*  really get into the game and, you know, make an effective launch in, you know, I guess we'll see.
*  Right. Is it going to happen in the next three months?
*  Maybe, maybe not. I would be pretty surprised if they don't have something like very compelling online this year, though.
*  And you just couldn't have done it that much farther in the past than that.
*  So I think that is a really again, it's one of the big things I keep coming back to always is threshold effects.
*  Things keep going from basically impossible to basically easy.
*  And, you know, answering kind of any random user's question about anything is one of those things that is kind of making that flip right now.
*  Let's see how they do. You know, I think you're going to see, you know, obviously we got to expect that it open AI and Microsoft
*  partnership is going to bring something like this to Bing.
*  You know, nothing is going to motivate.
*  Google, that's, you know, Larry and Sergey are coming back, right, because they see the writing on the wall.
*  Bing's going to, you know, maybe to even take the lead on them for a minute.
*  We'll see. I think there, I bet they will act pretty fast in the end.
*  Kind of in summary here or zooming out a bit, you touched on a little bit, but why don't you summarize your perspective on what is the upside case for AI and what is the downside case?
*  And kind of the best arguments for and against both.
*  They're both very extreme.
*  You know, Sam Altman recently gave an interview and I think he spoke to this pretty well, too.
*  You know, he said the upside case is almost impossible to imagine and you start to sound crazy when you talk about it.
*  And, you know, he did.
*  I would say he did start to sound a little crazy talking about it there for a second.
*  But, you know, it is it's not inconceivable.
*  Right. I mean, I think the, you know, it's just start with the base upside case, right.
*  So I think that's a great way to kind of like, let's just imagine we can get all the stuff that we have invented working reasonably well and not causing huge problems.
*  I think that could take us pretty far on the way toward a post-scarcity society.
*  When you think about what is scarce today, you know, energy remains scarce.
*  Sam Altman's got a fusion project underway to try to address that as well.
*  You know, pure intelligence doesn't solve everything on its own.
*  But so much of what people really lack today is expertise.
*  Right. I mean, there's so many people talk in medicine, for example, about the gap between the known and the applied known.
*  And there is this kind of 20 year, you know, basically a full generation gap most of the time from the time when things get discovered and proven out.
*  To the time that they are in wide clinical adoption.
*  And that's really just looking at, you know, the developed world, like that's looking at the US.
*  Right. So you've got kind of maybe you can think of it as like kind of three tiers of medicine.
*  Obviously, this is a huge oversimplification, but there's kind of what is the frontier today?
*  What is known? What is like in regular clinical practice across, say, the US?
*  And then like, what are people doing that just don't have access to, you know, even your kind of mainline medical care?
*  And what's really scarce there is the doctor's brains.
*  Right. I mean, it's the ability to interact with the patient, understand what's going on and figure it out and make recommendations.
*  And you have also some other key things.
*  Right. You got to have drugs when you need them.
*  You got to have you got to have machines in some cases to do stuff.
*  But still, like so much is is alleviated just by giving people access to quality expertise.
*  And that happens, you know, in so many different domains.
*  I just think about, man, all the people that are that are really disadvantaged in that respect.
*  This is the biggest upside moment for them, you know, ever.
*  Really, like, I don't think there's any any any close second to what this would be.
*  And again, I'm still kind of talking mostly like base case here.
*  I don't think this would require like any new, you know, any new breakthroughs to get to the point where you could have a readily available
*  AI doctor that could serve anyone around the world in their native language at basically human level, you know, potentially even faster than human level.
*  Certainly more availability, certainly better price point.
*  And, you know, that's that's a total game changer right off the bat.
*  So you can kind of play that out vertical after vertical.
*  And it starts to get, you know, pretty amazingly exciting.
*  You know, people don't have access to legal representation.
*  I was just talking to somebody here who's working in a prison reform movement and has a nonprofit here in in Michigan.
*  And she was saying she started to use chat to write letters to the parole board, to the judge, you know, and a lot of the people that she works with.
*  Obviously, they couldn't afford a lawyer and they get a public defendant.
*  She works with people right now.
*  There's somebody who's been in Rikers for three years and hasn't seen a trial.
*  Just got assigned a public defender and the public defender hasn't even seen her because he's too busy and backed up on his cases.
*  So, again, I just think, man, you know, for those of us who have the means and can afford the cost, you know, it's still potentially awesome.
*  But for those that are just doing without it is a total game changer.
*  I think it will be a radically egalitarian force in many respects on the consumer side.
*  You know, I really think the consumer surplus is going to be tremendous.
*  You know, how exactly that plays out on the ownership side.
*  I think, you know, we'll hopefully piece that together a little bit.
*  Nobody has a crystal ball on that one right now.
*  We'll piece that together over the course of many episodes, but definitely expect that the consumer surplus is going to be extremely, extremely high.
*  So, again, that's kind of base case.
*  You know, you start to think about, geez, well, what if Google just announced recently, for example, that a million researchers globally have now tapped into the Alpha Fold protein structure database.
*  And that's something that's just been created and released.
*  Alpha Fold, I think, is about two years old.
*  The whole universe of proteins being published and available is maybe a year, probably a little less than a year.
*  And already that has scaled to a million researchers.
*  So hard to say how that's going to play out.
*  But, you know, you really had a very hard time figuring out what the structure of a protein was going to be until this technology came online.
*  And the fact that a million researchers are using it demonstrates, you know, just how big of a difference it is in their field.
*  So it seems like we're probably headed for a biological revolution as well.
*  And that can be, you know, drugs, you know, much more simulation, much more stuff that's done in advance of, you know, even getting to clinical trials, like the efficiency, the cycle time, you know, should be, I think, dramatically sped up.
*  Just the pace of discovery should be dramatically advanced there.
*  And then energy too, right?
*  DeepMind also had a paper about using AI to control a fusion system.
*  And, you know, the engineering, obviously, of a fusion reactor is like incredibly complicated.
*  They use magnetic coils, essentially, to control the reactor space.
*  And you got a ton of coils and, you know, it's a hard control problem.
*  So in a way, it's very similar to a lot of the other stuff that they've done in terms of, you know, teaching AIs to play video games.
*  Like it's kind of like you have just one big controller with like a ton of buttons and you got to learn how to mash them, you know, to maximize your score.
*  So in that sense, it's not even necessarily like, I mean, they would probably say, well, there was a lot more to it that went into it, but you can see the leap from playing a video game well to controlling this fusion reactor.
*  Device and, you know, something like that works again, like, I mean, if energy gets.
*  90% cheaper, you know, a lot of our problems go away.
*  Not to mention, I'm change also gets cleaned up by that.
*  So, you know, those are kind of mid tier speculations in my mind.
*  Like I, I don't think we can say for sure that stuff is going to happen, but it seems increasingly likely.
*  And then you get into the Sam Altman realm of crazy and he's talking about, you know, what happens when we can make as much progress in science in general in one year as we have in all of human history.
*  And at that point, I think, you know, you're basically just talking about the singularity and I'm kind of all.
*  That's are off.
*  Like, I don't really know what to say about that, but.
*  You know, it could happen.
*  I think that's also maybe before then, but certainly at that point, too, then you do have to start to take the downside case very seriously, right?
*  Which is just loss of control, you know, gradual base downside case, I would say is like we become very reliant on these systems.
*  And we're already kind of there with like the electrical grid.
*  I think one of the I always kind of feel like I'm taking crazy pills when I think about the possibility of a big solar flare coming and knocking out the electrical grid.
*  We could all be standing here as I understand it.
*  I don't know that solar flares are that well understood, but there was a big one in the mid eighteen hundreds and it.
*  Didn't damage the electrical grid because there was no electrical grid at the time.
*  People all survived.
*  But today, if it took out the electrical grid, we'd have a big problem on our hands.
*  I don't know how well we'd be able to rebound from something like that.
*  And we're not talking, you know, that's 150 years ago.
*  We're not talking about.
*  The dinosaurs time scale.
*  We're talking about, you know, civil war time scale.
*  So.
*  Imagine that, you know, just 10 X compounded if we become, you know, as dependent on AI that's running on electricity as we are on the electricity itself.
*  And kind of get to a point where people don't really know how to do a lot of things anymore because it's all kind of handled by systems that talk to other systems.
*  And then all of a sudden that's disrupted.
*  I think that could be a real risk factor that, you know, could could put us in a pretty dark place.
*  And that's without anything like super exotic happening like.
*  AI is becoming power seeking or becoming deceptive or, you know, developing goals of their own, all of which used to be very much viewed as, you know, kind of speculative or, you know, fringy sort of ideas.
*  So no less than Greg Brockman just tweeted the other day that, you know, they need to be looking out for things like power seeking behavior as they continue to build up the, you know, the power and also the reinforcement learning cycles on.
*  On their most advanced systems.
*  So I thought that was actually great to hear because I didn't.
*  Historically, I hadn't had the sense that the people that were most enthused about building these things were also equally concerned or as concerned as they, you know, as I think they should be about the safety and downside risk side.
*  But that was really reassuring. And then Sam Altman also recently said in that same interview that the downside case, he put it very simply as lights out for all of us.
*  So it doesn't get much more stark than that.
*  And yeah, I think the one thing we can say pretty safely at this point is we will not stay in the middle. We're not going to stay where we are.
*  You know, there is a incredible, you know, irresistible upside that, you know, it's just too tantalizing that there's no way we will not pursue it.
*  And, you know, the cat is well out of the bag, I would say at this point.
*  But it definitely does come with a very real risk. And it's funny. I mean, I laugh about it, but it's that sort of nervous, uncomfortable laugh of like,
*  I really have no idea what's going to happen.
*  That's well put in terms of its upsides and downsides and arguments for each. I want to close with
*  kind of more of a personal reflection, which is a number of people who are going to be listening to this podcast, they recognize that this is pretty game changing and they want to be involved in some capacity.
*  And we were talking about the opportunities as it relates to starting companies. So people, our audience is going to be asking themselves, should they be starting companies? Should they not?
*  How have you thought about your decision to, in terms of how you wanted to get involved in the space and as you've gone back and forth on, hey, what is the best way in which you should do that? What can other people learn from your journey?
*  I guess for starters, the way I'm thinking about what I'm trying to do right now is in terms of being an AI scout.
*  I am trying to zoom out as far as possible and kind of look at the situation from as many different angles as possible. So that means
*  talking to as many people as possible. That's a big part of the reason that I'm excited about doing this show. You know, I want to talk to people who are pushing the frontiers.
*  I try to use every product that I can possibly get my hands on. It's almost a full time job just to sign up for wait lists today.
*  Truly, like, you know, you could sign up for 20 wait lists a day to get your hands on new things.
*  But I've been pretty successful in getting early access to stuff and try to stay on top of that as well as possible.
*  That's probably the number one thing I would recommend to people in general. Just get hands on with the tools. The best
*  intuition, I think, is what can they do? What can they not do? How are they useful to you? Very few people, if they really try,
*  will be unable to find significant utility in things like chat GPT and things like the art creation that we talked about with Duhail and Playground.
*  You know, it's hard for me and there's great spreadsheet stuff. If you do work in spreadsheets and you want to,
*  you know, you maybe struggle sometimes to come up with the right formula. There are now really good tools for just give a natural language
*  desire for what you want the formula to be. It'll spit out the formula for you. You can do that with SQL databases as well.
*  So any, you know, look for the things that are kind of on the margin of your skill set where you have, you know, you kind of know what you need, but you maybe end up going to a teammate for it a lot.
*  You know, and it's always kind of felt a little bit intimidating. That's a really good place to start with some of these AI tools. I actually would even say start with stuff that you know well just to get calibrated, but then start to move into stuff that's like a little bit on the margin.
*  And especially if it's something that has a concrete like outcome, then you'll pick it up pretty quick. You know, whether it's coding, you know, Excel, SQL, whatever.
*  You know, those are things where people are getting massive efficiency gains and even people that don't know how to code. Like I've worked with a woman for the last two years who started as an executive assistant and has kind of grown into a
*  ML ops type of role and the current frontier for her is coding and she, you know,
*  doesn't really have much experience coding at all, but can go to chat GPT and, you know, put in little snippets of code that either I wrote or she found on the internet or whatever
*  and modify them to what we need them to do. And, you know, she's able to do a lot now with the help of these tools. So I really think getting hands on
*  and developing your intuition and starting to get a sense for where things are going is a really great use of time. And, you know, you'll probably find practical benefits in the short term and it'll be fun. It's honest. I mean, again, I find it very
*  hard to imagine how anybody would sit down in front of these things and mess around a little bit and not be pretty impressed, you know, and not be curious about what else
*  it can do and it can do a lot more, you know, than what you'll find in your first couple of sessions. So definitely hands on. I think that's really
*  important. I also spend a lot of time reading both AI Twitter and then jumping off of AI Twitter into research. So I would definitely say AI Twitter is a great place. That's by far, you know, where the most dynamic
*  up to the minute conversation is happening. And there are a number of good lists that people have created. I have one. Sue Hale actually has one as well. We can post both of those
*  for people that are interested in just, you know, quickly building a couple of good, you know, sets of people to follow. Before you know it, you know, you'll be
*  up to the minute in terms of, you know, what are the latest releases? What are the latest publications? And then going in and reading those
*  is intimidating at first, certainly for a lot of people. I mean, especially if you don't have like a lot of comfort with notation. They can be notation heavy and
*  you know, there's a lot of linear algebra that goes on under the hood. I would not claim to be a linear algebra expert by any means.
*  But I think you can get around that with like relatively simple intuition building and then just reading the text.
*  Three blue, one brown legendary YouTube channel has a phenomenal visual introduction to neural networks. Super basic architecture.
*  But you watch that and I've watched that thing like five times at least just to really develop my intuition for what is happening, you know, as these like signals are propagating through this, you know, through this sort of black box matrix.
*  You know, even though he does a basic architecture, it's really helpful. And for me, like having some ability to visualize these things and having some kind of like
*  almost like spatial representation in my head, I find really, really useful. And then I can kind of sub that in
*  for a lot of the notation that, you know, is not super easy to grok, especially when you're just getting started.
*  But, you know, we're going to have the authors of the recent blip two paper on in an upcoming episode and
*  that paper is representative of a lot of papers in that it is
*  conceptually, I think, fascinating and
*  I would even say important.
*  And then there's like the linear algebra part, which, of course, you know, it is academic type work, right. So they do describe that in like rigorous detail.
*  You don't have to have a rigorous understanding of all of the
*  machinations going on to understand why this matters. They've taken two distinct foundation models, one which is a an image understanding
*  and one which is a language model and they've trained a smaller model to connect the two. And that allows you to have a dialogue with the language model about the image.
*  And they've essentially created this sort of machine language that spans these two modalities of image and text and done that in a way which is
*  purely numeric. It's not, you know, these things are not speaking to each other in any sort of human readable language. We may be able to, and one of the things I'm really excited to ask them about is
*  to what degree have they tried to reverse engineer that and figure out, you know, can we translate that language back into something we can understand.
*  But, you know, you don't have to get too deep into the linear algebra or the programming details to understand that and understand why that might matter and start to project into the future like, geez,
*  there's a proliferation going on of open source large models.
*  What's going to happen when all of those start to be connected by these small models? And, you know, is that, is there really any barrier to that happening in the wild? Like, I think that's, you know, one of the big messages of that paper is like,
*  there's kind of a new paradigm that's starting to emerge. And so reading those things, you know, understanding as much as you can
*  and being willing to, you know, accept that you're not going to understand at all. And I certainly don't in, you know, plenty of the papers
*  that I read, and there's only so much time as well, obviously, right, to understand, try to understand everything. I think you get a lot from the text. So I wouldn't, you know, wouldn't stress too much about
*  feeling like you don't understand everything. So therefore you can understand nothing like there. You can make a lot of progress, I think, just by
*  focusing on the conceptual side without even getting into the math.
*  I think that's a good place to wrap. It's a note of encouragement and some direction.
*  I think this has been a great introductory episode to some of your ideas and some of what we're trying to do about on this show.
*  So thanks for coming on and doing it with me. I'm excited for what's to come.
*  Yeah, thank you, Eric. I appreciate you suggesting this in the first place and helping put it all together. It's going to be a lot of fun.
*  The Cognitive Revolution podcast is supported by Omniki. Omniki is an omnichannel creative generation platform that lets you launch hundreds of thousands of ad iterations that actually work,
*  customized across all platforms with the click of a button. Omniki combines generative AI and real-time advertising data to generate personalized experiences at scale.
