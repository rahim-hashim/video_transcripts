---
Date Generated: April 03, 2024
Transcription Model: whisper medium 20231117
Length: 5323s
Video Keywords: []
Video Views: 1089
Video Rating: None
---

# Revolutionizing Patient Care with Neal Khosla of Curai Health
**Cognitive Revolution "How AI Changes Everything":** [May 16, 2023](https://www.youtube.com/watch?v=Sqpkt8bQgsk)
*  If you imagine that for your particular condition,
*  there's one doctor in the world
*  who's like the world's expert on it,
*  that person should be available to you around the clock.
*  It's a little bit alarming to me that in 2023 as a patient,
*  I am still living in a world
*  where it's like a couple of smart people sat down
*  and talked it out as opposed to,
*  we've had millions and millions of people
*  who go through all these medical conditions,
*  why can't we understand what happened to them,
*  what was done to them and really use that data
*  to help improve our interventions.
*  There was that survey data that came out
*  that was like who's most optimistic
*  and it was basically like a direct correlation
*  between like optimism on AI
*  and the wealth level of the country
*  and like basically poor countries
*  are just like abundantly optimistic about this stuff.
*  Like it's very clear to me that in the next 10, 15, 20 years,
*  whenever it happens, we're reaching a point as society
*  where like there's gonna be so much infrastructure
*  that cognitively can do so much for us
*  that you have to decide
*  understanding what spiritual fulfillment means to you.
*  Hello and welcome to the cognitive revolution
*  where we interview visionary researchers,
*  entrepreneurs and builders
*  working on the frontier of artificial intelligence.
*  Each week we'll explore their revolutionary ideas
*  and together we'll build a picture
*  of how AI technology will transform work, life
*  and society in the coming years.
*  I'm Nathan Labenz joined by my co-host Eric Torenberg.
*  Hello and welcome back to the cognitive revolution.
*  Today we continue our exploration of AI in medicine
*  with our guest, Neil Kosla,
*  founder and CEO of Curai Health online at curaihealth.com.
*  As you'd expect for an entrepreneur
*  who's raised more than $50 million in venture capital,
*  even before the current AI moment,
*  Neil is a polished communicator.
*  I thought he did an excellent job
*  of describing Curai's vision for the future of medicine
*  in just the first few minutes of our conversation.
*  So I'll keep this introduction relatively brief.
*  Of course, we do cover a variety of topics and angles,
*  including the impact of GPT-4,
*  Curai's recently published research,
*  which uses multiple instances of GPT-4
*  to improve performance,
*  how Neil personally uses AI for medical advice,
*  what's missing and still needs to be built
*  in order to ensure consistent quality of AI medical advice,
*  Curai's go-to-market strategy,
*  how the medical establishment is reacting
*  to AI progress and potential,
*  whether poor countries are likely to leapfrog rich countries
*  when it comes to AI adoption,
*  an inconvenient truth about today's LLM landscape,
*  how medical use of language models should be regulated,
*  and plenty more.
*  Before getting into it though,
*  I wanna take just a quick moment to again,
*  thank everyone for listening and share a few quick updates.
*  First, we've heard your feedback about sound quality
*  and have recently begun offering to send guests
*  an external microphone, should they need one,
*  to ensure that you can hear them as clearly as possible.
*  This change will come online over the next couple of weeks
*  and sound quality issues should be a thing of the past.
*  Second, if you have any other feedback or questions for me,
*  you can email us at info at turpentine.co
*  or feel free to DM me on Twitter, where I am at LeBenz.
*  I really love doing these interviews,
*  but we've also got great feedback
*  on our Eric and Nathan discussion episodes.
*  So we do plan to do more of those in the future as well.
*  Please let us know what's on your mind.
*  Third, I invite you to subscribe to our newsletter,
*  which is online at cognitiverevolution.substack.com.
*  We send out new episode updates
*  and also cross-publish my AI mega threads there.
*  Finally, for now, if you're enjoying the show,
*  I'd ask you to help pay it forward
*  by writing a review on Apple podcasts, Spotify,
*  or the podcast platform of your choice.
*  I've received a bunch of private messages
*  of thanks and encouragement, which has been super rewarding,
*  but I'd love to see more of this posted online as well,
*  as I'm told that this is the single best way
*  to help others discover the show.
*  Now, without further ado,
*  I hope you enjoy this conversation with CURI Health
*  founder and CEO, Neil Kosla.
*  Neil Kosla, welcome to the Cognitive Revolution.
*  Yeah, thanks guys.
*  Thanks for having me.
*  Super excited for you to be here.
*  We are, and I am increasingly obsessed with the role
*  that AI is gonna play in the future of medicine.
*  So really excited to get your take on it
*  from all sorts of angles.
*  In your role as the founder and CEO of CURI,
*  I'd love to just start off with giving you a chance
*  to give us your vision for the future of medicine.
*  What is my experience as a patient gonna be like
*  as AI starts to have an impact,
*  maybe say two years from now, 2025,
*  and then if you can see that far into the future,
*  end of the decade, 2030?
*  Well, there's a couple of things I say.
*  If you actually take a step back
*  and just think about medicine
*  and what it means to practice medicine,
*  for as long as humanity has been around,
*  it's basically been,
*  you go and spend 15 minutes with a doctor.
*  The only lever we have is how much time
*  you spend with the doctor.
*  If you're wealthy, you get more time with the doctor,
*  you go back to the Middle Ages and stuff.
*  The kings and queens would get a lot more attention,
*  obviously, than anybody else.
*  But now it's still not that different.
*  People pay for concierge doctors.
*  But it all comes down to doctor time.
*  And really the idea is that we have the doctors,
*  they're basically like oracles and sages.
*  They're supposed to be well-read
*  on all the biomedical knowledge
*  that's most up to date that we have.
*  And they spend 15 minutes with you
*  and they give you a recommendation.
*  And if you think back over the last 60 years,
*  the most amazing thing about the computing revolution
*  is it fundamentally has not changed that at all.
*  It's probably the only profession in the world
*  where if you take a human being today
*  and drop them into the same profession 60 years ago,
*  they would function just fine.
*  The only thing that's changed
*  is that there's not an MRI or an x-ray machine.
*  Those things were invented in the 70s.
*  Outside of that, you have some therapeutics,
*  but otherwise it's the same job,
*  which is pretty mind-boggling to think about.
*  And so when we say what's your vision
*  for the future of medicine,
*  I think what we have to start with is fundamentally,
*  what we do in medicine today is a very old thing.
*  It really has not changed at all.
*  And so our notion from the beginning has been like,
*  we should fundamentally mentally reimagine
*  the way that a physician practices with data and computing
*  at their center and at its core.
*  And I think there's some really obvious things
*  that fit into that, that everybody sort of talks about.
*  You should be able to pull out your phone
*  and talk to your doctor or the data from your wearables
*  and your other devices should bake into your health.
*  But I think the main thing that we've really focused on
*  is that we think that AI can be a great equalizer
*  in terms of the ability to make healthcare broadly available
*  to many, many more people.
*  And the way I always explain it is like,
*  if you imagine that for your particular condition,
*  there's one doctor in the world
*  who's like the world's expert on it,
*  that person should be available to you around the clock.
*  And so our conception is that in the future,
*  every human being is going to be able to talk
*  to that person, maybe not directly,
*  but at least somebody who represents
*  the same set of knowledge.
*  And a lot of that starts with building AI systems
*  that can scale more like software does.
*  That's kind of how we think about it at a large scale.
*  I know that's like a 10,000 foot view,
*  but in the future, everybody should be able
*  to pull out their phone and have basically best in class,
*  super personalized knowledge about whatever issue
*  they're going through or their particular health
*  that's available to them basically at zero marginal cost.
*  And I think if you build that future,
*  not only is it going to be really meaningful here in the US,
*  but then broadly across the world
*  where you've got 8 billion people
*  who are never ever going to get access to the kind of care
*  that somebody going to Mayo Clinic, for example,
*  gets here in the US.
*  So I don't know if that maybe answers your question to start,
*  but I'll pause there.
*  Yeah, that's great.
*  I mean, there's a couple of themes there
*  that we've been increasingly developing
*  and kind of obsessed with.
*  I've got this notion of zero marginal cost expertise
*  in general, and you kind of have a obviously
*  much more developed in particular version of that
*  for medicine.
*  And then your comments about the difference
*  between the level of access and therefore kind of the level
*  of impact that developments like this would have in the US
*  versus much of the rest of the world is something
*  that I also kind of harp on every chance I get,
*  because I think that should not be lost.
*  And there's a lot to worry about with AI in general
*  and with turning over medical decision-making to AI,
*  people are certainly understandably cautious and concerned.
*  But boy, when you think about the impact globally,
*  it certainly gets me extremely excited.
*  So it's cool to hear you kind of talk about that
*  right off the bat in your first run through of the vision.
*  Yeah, I would say the one other thing that's popping out,
*  just like hearing you talk was prompting
*  some of these thoughts.
*  One of the things that's most amazing about medicine
*  is like, it is not a particularly data-driven science.
*  It's much more a judgment-based art.
*  Some of the studies on this are actually pretty fascinating.
*  So if you look at clinical guidelines,
*  basically how the medical establishment says
*  that doctors should treat an issue.
*  There was a review done a couple,
*  how probably about five or six years ago,
*  they basically looked at them and said,
*  how many of them are based off of grade A clinical evidence?
*  And the answer was about 11%.
*  So that means 90% of the time when you are getting
*  a clinical best practice guideline,
*  you're getting something that's based off of
*  really what comes down to opinion, expert opinion.
*  And then when they look deeper, they say like,
*  what percentage of time do doctors
*  actually follow these guidelines?
*  It's about 50% of the time.
*  And so if you take a step back, you go as a human being,
*  like 95% of the time,
*  you're not actually getting a very data-driven recommendation.
*  Now there is some data that informs these things
*  and there's usually expert panels that sit down
*  and kind of talk through it.
*  But it's a little bit alarming to me that in 2023
*  as a patient, like I am still living in a world
*  where it's like a couple of smart people sat down
*  and talked it out as opposed to,
*  we've had millions and millions of people
*  who go through all these medical conditions.
*  Why can't we understand what happened to them,
*  what was done to them and really use that data
*  to help improve our interventions?
*  And that is one thing that we've worked on at Curaia as well
*  that I think is a much longer path.
*  That's not something that's gonna have an effect
*  in the next three years or probably even five.
*  But if you look on a 20-year timeframe,
*  I think the ability to create the infrastructure,
*  to collect that kind of longitudinal data
*  on what happens to patients
*  and then use it to surface decision support
*  right at the point of the care
*  so that we can make a decision based on that data.
*  It's never existed in humanity.
*  It's kind of interesting if you go to like a state like Utah
*  where it's mostly been a homogenous population
*  because the Mormon population,
*  many of them have lived there for multiple generations
*  and they were very progressive
*  in getting into electronic health records and genealogy
*  and some of these things.
*  It's one of the few places where they tend to have
*  some of these more longitudinal
*  and sort of genealogical databases on patients.
*  They're just starting to figure out
*  what they can do with that.
*  But the rest of the world doesn't have that.
*  It doesn't even have a glimpse of that.
*  I would argue what they have in Utah
*  probably is insufficient to really getting insights.
*  So that's one other thing is like,
*  I do think medicine over the next 20 years
*  really needs to start thinking
*  about how we lay the foundation
*  so that care can be made in a super data-driven way
*  as opposed to where we are today,
*  which is, I'd say, it's still incredible
*  modern medicine is a miracle in many ways,
*  but it's not all the way there
*  for what I would want as a patient.
*  So let's maybe spend another second
*  just filling in a little more detail,
*  giving a little more color on kind of this future of medicine
*  in kind of an experiential,
*  from the patient's point of view.
*  And then I wanna talk about
*  where the state of AI for medicine is today.
*  A number of exciting things have been published recently
*  including work out of Cura,
*  which I definitely wanna dig into.
*  And then we maybe take a step back and talk about,
*  okay, now where are you today
*  and how are you gonna get to that future
*  and some of the barriers that might arise
*  including like regulatory, et cetera, et cetera.
*  So if I'm a patient,
*  I'm just kind of trying to imagine my experience, right?
*  And this is just a few years from now potentially.
*  The idea would be that I have a 24 seven availability
*  that when I begin an interaction with the system
*  that there is a seamless, presumably embedding backed
*  database of all of my previous interactions that have
*  kind of the semantic representation of issues I've had,
*  conversations I've had,
*  notes that the doctor took in the past, right?
*  Presumably all of that is kind of dumped in
*  and can be used for retrieval.
*  Presumably like the medical literature is also
*  deeply baked into such a system.
*  And then what do I do?
*  Am I like interacting with a doctor
*  in the same way that I would today
*  except it's just like a language model?
*  Like how does that then play out into care?
*  Yeah, so I think it's important to root in
*  like what do patients do today?
*  And there's basically two ways
*  that patients access medical expertise.
*  One is they talk to their doctor or a doctor
*  if they don't have their doctor.
*  And the other is they basically go online
*  and do self research, right?
*  And ultimately I think these two things
*  probably need to become one, right?
*  Like there's a lot of ways in which self research
*  is maybe suboptimal for the patient
*  in terms of coming to the right conclusions
*  because patients are self directing
*  and they may not always know
*  and the information online is not always vetted
*  or it's not always good.
*  And on the other hand, a lot of those pieces of information
*  also should inform what your doctor is doing.
*  Hey, we'll continue our interview in a moment
*  after a word from our sponsors.
*  I wanna tell you about my new interview show, Upstream.
*  Upstream is where I go deeper
*  with some of the world's most interesting thinkers
*  to map the constellation of ideas that matter.
*  On the first season of Upstream,
*  you'll hear from Mark Andreessen, David Sachs,
*  Balaji, Ezra Klein, Joe Lonsdale and more.
*  Make sure to subscribe and check out the first episode
*  with A16Z's Mark Andreessen.
*  The link is in the description.
*  Omniki uses generative AI
*  to enable you to launch hundreds of thousands
*  of ad iterations that actually work,
*  customized across all platforms with a click of a button.
*  I believe in Omniki so much that I invested in it
*  and I recommend you use it too.
*  Use Cogrev to get a 10% discount.
*  I'm sitting here, I take fish oils every morning.
*  My doctor most likely, if I'm an average American,
*  has no idea that I'm taking fish oils
*  or that I'm not taking fish oils
*  and that I've considered taking fish oils
*  because most Americans don't have the time
*  to talk to their doctor about those things.
*  Most people are going on Google, they're going on Reddit,
*  they're going on these other places to figure out,
*  what do I need to do, given whatever my goals are?
*  At the end of the day, we basically think
*  that the appropriate interface does look something
*  like a text box, which is I, as a patient,
*  have a way to say, this is what I'm thinking about,
*  this is what I'm wondering about,
*  this is what I'm dealing with.
*  And on the other end, there's a system
*  that helps me figure out what exactly does that mean
*  I should be doing for my health.
*  So if I'm having symptoms or if I'm considering
*  taking a new supplement or starting a new diet
*  or exercise regime, or if it's something more medical,
*  I'm managing my diabetes long-term
*  or I'm trying to get pregnant or anything like that.
*  It all starts with a text box.
*  And on our end, it's important to build the magic,
*  as you kind of alluded to,
*  to be able to parse through that,
*  understand what the patient's looking for.
*  It almost always starts by asking more questions.
*  And this is something that's completely not present
*  in sort of any kind of online research,
*  is the ability to have a dialogue with a system
*  that says, okay, you're considering taking this supplement.
*  Like, why are you considering taking it?
*  What other things have you tried?
*  How long have you been thinking about this?
*  What are your goals?
*  I don't know.
*  And let's dig into your biomarkers, right?
*  So like, do you actually have,
*  are your triglycerides high?
*  Is that why you're thinking about taking fish oils?
*  And so for us, it always starts with like,
*  what is the patient's goal or intent?
*  And then how do we drill down and understand more?
*  And so that's always an automated questionnaire system.
*  I think, you know, to get into the technical side of things,
*  it inherently does have to tap into a long,
*  large amount of patient history and data.
*  And depending on the patient,
*  we have a very differing amount of data.
*  We are finding increasingly
*  that even with more simple patients,
*  you're starting to extend beyond the context window
*  of the patient pretty quickly.
*  And so you need to find other ways to kind of index
*  that prior data you have on them,
*  as well as what you're collecting
*  in conversation with them right now,
*  and use that to intelligently feed that stuff
*  into your context windows
*  so that you can help the language model make a decision.
*  I'd say the other big thing that we think a lot about is,
*  like, these problems are not totally solvable
*  just entirely with a language model.
*  Like, you've got to build a lot
*  on the guardrails and safety side.
*  So especially for where we are today,
*  just from a regulatory perspective,
*  you can't have a language model
*  giving a patient direct personalized advice,
*  like, go take this medication.
*  That has to be done by a doctor.
*  That's a regulatory requirement.
*  And so you have to build requirements
*  or sort of guardrails around that.
*  You have to build guardrails around
*  when patients have mental health issues,
*  handling those things appropriately.
*  I don't know if you folks saw,
*  there was a news article that came out
*  about a person the other day who killed themselves, sadly,
*  and their significant other mentioned
*  that they felt it was because they were talking
*  to a chatbot.
*  And so these kinds of situations are real.
*  And so for us right now,
*  there's a lot we're building
*  that's sort of like on the safety side.
*  Yes, from an experience perspective,
*  you like come in, you talk about what you want,
*  and then it's our job to drill down with questions
*  and then serve that kind of biomedical expertise for you.
*  And a lot of it is happening on the language model side,
*  but there's a lot that's scaffolding
*  that's being built around these models,
*  as well as support and checking
*  to be able to surface good recommendations.
*  And the thing that we always do
*  before we give a patient a final recommendation,
*  we're always connecting them to a physician.
*  And that's where we are today,
*  where things are getting escalated to a physician
*  for final review and to give that advice.
*  That also allows us to do things like have the physician
*  give you a prescription or a medication,
*  or send you to get lab work,
*  and then further personalize the information
*  or the recommendation we're making.
*  It's such a really simple thing in concept.
*  At the end of the day,
*  we're trying to get people to talk to their doctors
*  about the whole range of things that they're dealing with.
*  And we're just trying to make it scalable and possible
*  for the doctors to actually respond to those things
*  by using tools that maybe do 80% of every visit
*  that they're having.
*  So a couple of things to me about your description there.
*  One is just how similar the architecture is
*  between what you're building for medicine
*  and basically everything else we're hearing about.
*  It's like whether you are trying to build an AI assistant,
*  you have a lot of those same things, right?
*  People are like, I want it to be a text box.
*  It needs to know my preferences for which,
*  if I like the window seat or the aisle seat or whatever,
*  and there's kind of this retrieval component to it,
*  it's striking the degree to which things
*  are just kind of converging architecturally
*  both in terms of the nature of the models themselves,
*  but then also the surrounding tooling.
*  You can complicate that view for me,
*  certainly if you want to.
*  I'd say the main thing,
*  because quality and safety is so important in medicine,
*  one thing that I haven't seen a lot of people working on
*  that we are is what I'll generally describe
*  as kind of like unit testing or regression testing.
*  Completely hypothetical scenario,
*  a patient comes in and is dealing with some issue.
*  They've got some sort of bacterial infection,
*  they need an antibiotic.
*  Great, we can have a language model, interview them,
*  and then the doctor can review the summary
*  of what the language model gathered,
*  and then they can work together to come up
*  with a prescription for this patient.
*  We want to have visibility into how the language model
*  is handling a broad range of these kinds of scenarios.
*  And so instead of just releasing this product,
*  we've been working on a sort of large set of test cases
*  where you basically can run a set of regression tests
*  that say for a common range of clinical cases,
*  how does the language model handle these things?
*  And because these things are non-deterministic,
*  you want to be able to have,
*  it's much like building software,
*  where you want to know that it works repeatably,
*  and unit testing is a great way to get insight into that.
*  So we haven't seen a lot of people working on
*  robust unit testing suites, but at least in medicine,
*  it feels like a must have to know
*  that there's predictability.
*  It's even more so true as you use language models
*  that update over time.
*  If you're doing any kind of fine tuning or human feedback
*  or any of these things, the model is changing,
*  and you wouldn't want a scenario where we do really well
*  with antibiotics today, but then tomorrow,
*  all of a sudden the thing goes haywire.
*  And so that is one area where I'd say our stack
*  maybe is starting to diverge
*  from what I'm reading about on the internet,
*  is like you really want to have a large set of test cases
*  to understand how the model is thinking through
*  and reasoning as it changes over time.
*  Yeah, that's super important.
*  A little glimmer of that type of thing has come out
*  from like OpenAI recently with their evals library,
*  but I'm sure you are going comfortably 10X deeper
*  in the use cases of interest.
*  So maybe let's talk for a second about just kind of
*  what is the state of the art in terms of what AIs can do
*  in medicine now?
*  And devoted listeners of the show will have heard me talk
*  a little bit about my experience
*  with the model we now know as GPT-4.
*  I was just for your knowledge,
*  I was an early red team member and it hit me hard immediately.
*  One of the very first things that I tried
*  was setting up a dialogue between me and GPT-4 as my doctor.
*  Knowing what you said is so true that evaluation in general
*  on language models is hard,
*  but it becomes particularly hard
*  when you don't have the expertise
*  in the domain of interest, right?
*  So as a non-doctor, no real training myself,
*  very difficult to do any sort of evaluation
*  of the model's performance as a doctor.
*  What I did was just attempt to recreate episodes
*  from my own life.
*  And I'm fortunate to have been pretty healthy
*  so I haven't had like a ton,
*  but went in to see a doctor about this,
*  saw my dentist about this, whatever.
*  And I kind of recreated those little episodes.
*  I found that for my like probably pretty routine,
*  certainly not the most difficult cases,
*  the performance that I got from early GPT-4
*  was almost indistinguishable
*  from my actual real life conversation.
*  And I was kind of immediately like,
*  whoa, like this is gonna be a huge deal.
*  It was really that, maybe more than anything else
*  that caused me to become like even more obsessed
*  and just drop everything else I was doing
*  and focus on that red teaming thing for a while.
*  But that's just an anecdote, right?
*  So like, can you kind of characterize for us,
*  I think people are probably gonna be pretty surprised
*  by what you'll say,
*  but I'd love to just kind of hear the characterization
*  broadly of like, what are the state of the art things?
*  What have they achieved?
*  And then we can obviously get to your recent
*  publication as well.
*  Yeah, so there's the quantitative
*  and there's the qualitative.
*  So we've also had access to GPT-4 for quite some time.
*  And I'd say the anecdotal experience of ours
*  as well as most of the doctors on our team
*  mirrors what you're saying.
*  I, at this point,
*  and I would not recommend this to anybody at home
*  who doesn't understand the risks associated with this,
*  but I primarily, like most of my medical,
*  I heard myself the other day working out
*  and the first thing I did was go on chat GPT,
*  pull up GPT-4 and type it in.
*  That is primarily how I'm getting my medicine right now,
*  at least my medical advice
*  with the understanding that it's not always right,
*  but it's easier and faster than trying to get
*  in front of a doctor and it's pretty damn good.
*  We have a doctor who moonlight set Stanford
*  and he really insists on taking these tools
*  into clinic with him.
*  He's found that's made him a better doctor
*  and he said repeatedly that it does an incredible job.
*  So I would say, yes, anecdotally,
*  these things are really, really capable.
*  In terms of the quantitative,
*  there's been a number of folks working on testing
*  these systems large English models
*  on the US Medical Licensing Exam, USMLE.
*  And I believe GPT-3, they said,
*  the paper came out in January,
*  suggested it was basically on par with an average physician
*  and now, sorry, it was passing
*  and now it exceeds the average physician
*  if I have my data correct.
*  And we just published a paper just a week or two ago
*  that exceeded the performance of the state of the art,
*  which we had tweeted out,
*  but I think Microsoft was the one who had formally reported
*  it post GPT-4 launch.
*  And so what we're seeing is these systems
*  are by any objective measure as capable as any physician.
*  I think there's still a long ways to go
*  in terms of investigating.
*  One of the challenges as everybody in AI is seeing
*  is these benchmarks don't really work
*  or make sense anymore.
*  They start being based off of these assumptions
*  that maybe don't work for the world today.
*  One of the interesting things we've seen, for example,
*  it's like on USMLE questions,
*  they tend to be short and have short responses.
*  And so they're little vignettes and cases
*  that are like more easily answered.
*  And so some of the cases where these models struggle more
*  may be on longer form, more kind of drawn out reasoning.
*  And that's where these things don't work as well
*  out of the box.
*  And you've got to build a lot of scaffolding,
*  some of the things that came up, memory retrieval,
*  reasoning systems that help them work over time, especially.
*  So, the short answer is what we're seeing already
*  is that out of the box, they're pretty damn good.
*  And they've pretty much exhausted
*  the state of the art current benchmarks.
*  And qualitatively, what we're seeing is
*  we believe these models can do as well as are better
*  than the median doctor here in the US,
*  but there's work to be done on kind of building
*  the scaffolding and proving that out in a more robust
*  and rigorous format before you make any kind
*  of egregious claims at scale.
*  So can we maybe unpack the nature of these questions
*  a little bit more?
*  I find that these numbers get thrown around so much, right?
*  And like most of our listeners will have taken the SAT
*  presumably at some point, but I would venture
*  that most have not taken, and I have not taken the USMLE.
*  So as part of your recent paper,
*  dialogue enabled resolving agents,
*  which we can unpack more as well,
*  like exactly what that works and how that works
*  and why it works.
*  But I noted that you said that you had exceeded
*  the previous state of the art on these open-ended questions.
*  Could you just give us a little bit of a sense of like,
*  what those open-ended questions kind of are like,
*  just to ground the audience and even me
*  in terms of like, what sort of questions
*  are we evaluating language models on right now?
*  So the type of question you get is like,
*  yeah, I'm reading one right now.
*  Like a 67 year old man with transitional cell carcinoma
*  of the bladder comes to a physician
*  because of a two day history of ringing sensation
*  in his ear.
*  He received this first course
*  of neoadjuvant chemotherapy one week ago,
*  blah, blah, blah, blah, blah.
*  The expected beneficial effect of the drug
*  that causes patient symptoms is most likely
*  due to which of the following actions.
*  Inhibition of thymidine synthesis,
*  inhibition of proteasome,
*  hyperstabilization of microtubules
*  or generation of free radicals.
*  And then the fifth option is cross-linking of DNA.
*  That is the kind of question
*  that is in this open-ended data set.
*  So safe to assume nobody is lucking their way
*  through the exam.
*  I think it's worth just taking an extra second here
*  to reflect on the fact that in some really important ways,
*  current systems are superhuman.
*  And it's a weird shape, right?
*  I'm always kind of interested in the ways
*  that reality kind of diverges from our expectations
*  or our shorthand.
*  And I think one key way is that like,
*  we're seeing sort of superhuman things in some ways,
*  but not in all ways, right?
*  Like I have in all of my obsessive GPT-4 testing,
*  I never saw anything that I was like,
*  that is more brilliant
*  than anything I've ever seen a human do.
*  I never saw any single insight
*  that was like superhuman insight.
*  But then you look at breadth and you're like,
*  man, this same thing can answer that question
*  and it can also do like comparably well in law
*  and it can do comparably well in like basically,
*  many of the professions, if not most of the professions,
*  that is superhuman in and of itself.
*  So that's just kind of worth not glossing over in my mind.
*  One of the other things I'll say about that data set
*  is the interesting thing, the interesting step here too,
*  is we took a step of basically stripping out
*  the multiple choice answers.
*  And historically, when these things have been tested,
*  it's like pick one of these five answers.
*  We kind of said like, answer this question
*  and the model can actually answer it
*  as an abstract concept,
*  which makes the problem statement significantly harder
*  in terms of it doesn't just get to pick from a list.
*  And then we introduced this metric,
*  we actually introduced it a few papers ago
*  called like GPT Recall or GPT Precision,
*  which is basically a way of saying like,
*  you can actually get the model to like ask the model
*  if the stated, if the open-ended answer
*  was the same as the reported answer.
*  So if the model says like high cholesterol
*  and the answer is cholesterol over,
*  200, like those should be noted as the same thing.
*  So you actually have to do this like reverse mapping problem
*  to figure out if the open-ended answer was the same thing
*  as the real, the spirit of the answer.
*  And so this is one of the ways
*  where like these previous benchmarks
*  start to get a little bit broken by these models,
*  which are just becoming so capable
*  and answering these questions.
*  Yeah, there's a really, I'm glad you mentioned that.
*  And it's something that's been on my mind
*  quite a bit recently as well.
*  Going back to the red teaming thing,
*  there were at least two instances of papers
*  that were published during that,
*  my personal two month red teaming window,
*  which was September and October of last year,
*  where the conclusion published was basically
*  language models still can't do X,
*  for whatever X was.
*  And at the time I was like,
*  well, I'm pretty sure GPT-4 can do it.
*  So I kind of spot checked,
*  and sure enough, like in the two that I checked,
*  it was able to do the thing.
*  I know exactly what you're talking about.
*  That sent me,
*  that's still an open question
*  in the broader research community.
*  That sent me down a little bit
*  of a benchmarking rabbit hole in that
*  I started to think, well, how good is that?
*  All these different benchmarks.
*  And I found exactly what you found also,
*  which is that if you set up your benchmarking script
*  with a slightly dated paradigm,
*  like if you take a 2021 big bench script, for example,
*  and you just run it,
*  first of all, it's set up on like a few shot basis.
*  And second, the structure of that few shot
*  is such that the model is basically forced
*  to give you a multiple choice answer straight away.
*  And as a result, its performance really suffers
*  compared to what it would do,
*  not even if you like get really creative
*  and do like amazing prompt engineering,
*  but literally if you just take away the few shot structure,
*  take away the multiple choice
*  and just present it with the question,
*  you'll get like way better answers than you do
*  by using the kind of established structure of the benchmarks.
*  So as an aside, if there's any listener
*  that wants to sign up for a little project,
*  I think there are a number of papers recently published
*  that I would like to go dig in
*  and kind of retry some of the experiments
*  that have been run with like,
*  honestly just more naive prompting strategy.
*  So reach out to us if you wanna do that.
*  And I'm glad that you are on top of that
*  and not falling victim to that pitfall.
*  Well, I think it goes in both directions, right?
*  So like on the one hand,
*  it can hurt the performance of the model.
*  It can also inflate the scores.
*  Like it can reduce the problem.
*  There's no scenario in real life in medicine
*  where the doctor is given five options.
*  If you wanna compare these things to how a doctor would do,
*  in real life, you have a patient in front of you
*  and you have to guess one of five answers.
*  Like, no, that's never the case.
*  You have a patient in front of you
*  and you have to come up with the answer
*  from the depths of your imagination.
*  I don't know where it comes from
*  if you're a human practitioner,
*  but what we've noticed and felt is like
*  measuring these things on multiple choices
*  is just like a bad benchmark
*  because it makes the problem so restricted in domain.
*  And especially for areas like biomedicine,
*  biomedicine is a very open-ended thing.
*  I mean, if you think about real patient cases,
*  they're never like straightforward clinical things.
*  And, you know, we can talk more about the implications
*  of this for language modeling,
*  but like you never have a scenario
*  where like you get a list of symptoms from the patients
*  that are incredibly straightforward.
*  And then like, you just map it to some diagnosis.
*  Like if you actually look at like the history of AI
*  and biomedicine, that's how people started trying to do it.
*  They would come up with these big lists of like,
*  these basically these big graph structures
*  that were like these symptoms map to these,
*  you know, these they call clinical findings
*  map to these diseases.
*  And the problem is the expressivity of those models, right?
*  Like you have somebody who's lactose intolerant.
*  What is the finding there?
*  The find, like if you wanna diagnose the disease
*  of lactose intolerance,
*  the findings have to be like eat milk
*  or like, you know, in some cases
*  they have to be like ate cereal
*  because they didn't even eat,
*  like they never tell you they ate milk.
*  They just tell you they eat cereal.
*  And this is how like the human brain works
*  is it can kind of generalize these concepts
*  to make the diagnosis.
*  In real life, like the world is really messy and open-ended.
*  And one of the things that language models
*  have really unlocked in medicine
*  is the ability to understand this broader context
*  and represent a lot of clinical findings
*  in very abstract conceptual terms
*  and still be able to reason on them.
*  So one of the things that we're a big fan of
*  in these benchmarks is kind of removing
*  this artificial structure
*  because medicine never has artificial structure.
*  Patients come in and really messy scenarios
*  and doctors have to adjust and sort of treat them
*  with very, very messy data.
*  So kind of upshot there is in addition to my complaint
*  that the multiple choice benchmark
*  when presented the wrong way to the language model
*  can lead to understating its performance.
*  You're also piloting equally important point
*  in the opposite direction,
*  which is that just giving it multiple choice answers
*  is like a far cry from actual challenge in practice.
*  And so that's why you've created this additional
*  sort of elaboration where you remove the multiple choice
*  and then you kind of do another language model
*  and you do a more immediate assessment to say like,
*  did it sort of come up with the right answer on its own?
*  Yes, I'll just leave it at that.
*  Yes, I think that's very, very much true.
*  And I think the problem statements themselves,
*  like this is where we're starting to hit the ceiling
*  in the benchmarks is the problems are controlled, right?
*  Like what I read was a very controlled vignette
*  and patients are messy.
*  One of the things we found really messy about like diagnosis
*  and decision support in medicine
*  is that it's an evolving thing.
*  So like a patient comes in
*  and you have one differential diagnosis.
*  As you learn more about the patient, it changes.
*  You're not just dealing with like a snapshot in time.
*  You have a moment and then you talk to the patient
*  and you get more information and it changes.
*  And then a week later, the diagnosis changes again
*  and like so on.
*  So any model you build has to be able to like
*  dynamically reason and change over time.
*  And these benchmarks maybe don't do that,
*  but anecdotally the language models do really well.
*  Well, first let's go to your research
*  because you guys just published this paper
*  and this is the perfect time to talk about it.
*  So you're digging in on this benchmark.
*  You've got GBT-4 access, you know, anecdotally
*  and even quantitatively we're finding that GBT-4
*  can do a lot straight out of the box.
*  And now you've added this layer of dialogue
*  enabled resolving agents,
*  which kind of reminds me of like a couple of different things
*  like the Socratic models paper was maybe the first one
*  that cracked my consciousness
*  that has kind of a similar paradigm.
*  But tell me how it works in this case.
*  Like you guys have brought multiple models together
*  or multiple instantiations maybe of the same model
*  and you're getting better results.
*  So for this paper, we have two instantiations
*  of the same model and the concept is like
*  you give these cases to one of the models
*  we call the decider and then you have another model
*  basically poke holes, we call it the researcher
*  that goes around and pokes holes in the conclusions
*  that the decider is making.
*  And it becomes this Socratic style dialogue.
*  We actually originally before we post the patient paper
*  we called it student teacher.
*  And then for reasons we kind of moved away
*  from that terminology, but it's a really clever way
*  of getting two models to kind of work together
*  to come to a better set of conclusions.
*  And I think the paper basically shows across a variety
*  of tasks that this works to lead to state of the art
*  performance in medicine.
*  I mean, candidly, I'd love for somebody to try this kind
*  of model and go take it to other things other than medicine
*  because I suspect it will work and it's a recurring theme
*  that we're seeing right now in the AI world,
*  which is GPT-4 is great and it's great to like
*  create a prompt and give it a problem
*  and see how the prompt does on a problem.
*  But what seems to be even more powerful is setting up
*  multiple instances of these, of different agents
*  and have them interact in complex ways.
*  And we're sort of unlocking the sort of,
*  we're still unlocking where that can take us as a paradigm.
*  And in medicine, I think it makes a lot of sense.
*  As I mentioned, like the challenges, I mean,
*  for obvious reasons, so much biomedical knowledge
*  is embedded in the latent knowledge base
*  of a large language model.
*  The question is sort of how do you elicit it?
*  And I think what we find in this paper is that
*  skeptical questioning of the deductions
*  or the conclusions made by the model
*  can kind of push you to a better resolution.
*  And I just think this is a super, super exciting paradigm.
*  And we're continuing to kind of explore this
*  as an area of research.
*  You said it's the same model.
*  Is it basically GPT-4 with different lenses
*  on prompt engineering that you're then just bouncing back
*  against one another?
*  For this paper, yeah.
*  That's amazing.
*  You know, another thing that that really reminds me of
*  is one of the authors of the diplomacy paper
*  that came out of Metta.
*  Cicero.
*  Yes, Cicero the model, yeah, that played diplomacy,
*  the game, talked about the very general strategy
*  of trying to bring more compute to bear at runtime.
*  And he was kind of talking about how, you know,
*  if you went back to like deep blue
*  in the original chess days, you know,
*  basically what you had a lot of was deep search
*  and a ton of compute running at, you know,
*  at runtime for each individual move,
*  just crunching, crunching, crunching through, you know,
*  the trees of possibility and, you know,
*  some smart heuristics around like where truncate search
*  and, you know, which trees are worth exploring
*  and which not, but like, it was just a ton of compute
*  at runtime.
*  And then he contrasts that to today where he's like,
*  you know, by and large, the compute is all done
*  in the training.
*  And then at runtime, you're just, you know,
*  predicting one token at a time.
*  And that's like whatever, like a million times less
*  or something, maybe even more than that.
*  And so his kind of paradigm and what they did
*  with the Cicero paper was they tried to figure out ways
*  to bring more compute into the picture at runtime.
*  They had kind of multi-part approach that included
*  like a constellation of models more
*  than purely a language model.
*  And you're doing something similar here where it's two,
*  you know, two kind of summonings of the same language model
*  into different roles that you can then place into dialogue,
*  but effectively you're multiplying the compute with,
*  you know, a certain flavor on it.
*  What if you would add anything to that?
*  And then I also really wonder about like,
*  what about other kinds of models that might be added
*  into this system, right?
*  Like I imagine, you know, people have been talking
*  about forever like, well, the radiologist will be the first
*  to go because you're, you know, you, it should be easy
*  for AI to read a scan.
*  We haven't seen that, but we also haven't seen GPT-4
*  multimodal deployed widely at all either.
*  So yeah, I don't know any thoughts on the kind of bringing
*  computation to runtime and kind of more different kinds
*  of models working together?
*  Yeah, I mean, I'd say there's a couple of things.
*  One, like, yes, I think this is a really powerful paradigm.
*  You know, in the old classical world, you'd call this
*  like ensembling, right?
*  I think one of the really interesting intuitions
*  and why like two instances, it doesn't make sense
*  in a lot of ways to people that like two instances
*  of GPT-4 can like, like in theory, they shouldn't have
*  like independent failure modes.
*  And so like, you know, the model, it shouldn't get better.
*  But what I think a lot of people are finding in research
*  is like this state space of the model is so large
*  that what you're really trying to do is you're trying
*  to figure out how to sort of elicit the right knowledge
*  out of the model.
*  And there was a paper that came out the other day
*  that was about like why, I haven't actually read
*  the whole thing, but I'm very excited about it.
*  People are starting to research this.
*  It was about chain of thought prompting.
*  And it's like, basically argued that like reasoning
*  is emerging like from, I think they call it
*  the locality of experience.
*  So it's like sort of local clusters of variables
*  in the model that influence each other.
*  It's a super cool concept.
*  And I'm curious to see where this takes us,
*  but I suspect that we will go really far with even one,
*  like multiple versions of one language model
*  as these models get bigger and bigger, just prompting.
*  And obviously, you're kind of seeing the auto GPT stuff.
*  There's some differences there in that it's doing
*  more coordination and orchestration, I would argue,
*  but I think it's a lot of the same phenomenons that like,
*  hey, one version of the model that's coordinating
*  and orchestrating can kind of prompt the model
*  to do other things.
*  And that is a very powerful paradigm.
*  I think the other thing you're kind of getting at
*  is other modalities and other kinds of models.
*  To date, what I will tell you, we don't feel
*  that like there is a tremendous amount of value
*  in taking a worst performing model
*  over the better performing models,
*  or I should say I don't.
*  From my vantage point, these models are so large
*  that you haven't hit the performance limit
*  of using X versions of the same model in conjunction.
*  That seems to be better than like use one GPT-4
*  and one GPT-3 and one Bard and what have you,
*  which is very counter to the intuition.
*  I think of a lot of machine learning scientists.
*  It's counter to what my intuition was,
*  but that's not anecdotally what I'm seeing.
*  And then I think on the multi-modal stuff,
*  I think it remains to be seen how powerful this can be,
*  but my suspicion is it's a really powerful paradigm.
*  I actually was looking at a patient conversation
*  this morning where the language model asked the patient
*  to upload a picture.
*  I was kind of sitting there thinking about this.
*  My suspicion is that like GPT-4 multi-modal is,
*  which I have not touched,
*  is going to be able to synthesize information
*  across these modalities,
*  which will lead to like a net improvement
*  in the performance of these things.
*  Like if you think about like having a picture of a rash
*  and the patient describes it as like itchy and flaky,
*  as well as you can see that it's red,
*  like that is a lot of information
*  that if it can be synthesized and combined
*  is much more powerful than like independently a model
*  that knows like can distinguish from the image
*  that it's red and then has the description in the language
*  that it's itchy and flaky.
*  This is pure speculation
*  because we haven't played around with these models,
*  but I'd say what we see is like the more diverse data
*  and the larger data you give any of these models,
*  the more powerful they seem to generalize.
*  And we don't seem to have hit the ceiling there.
*  So I'm very excited for throwing imaging data,
*  for throwing whatever kinds
*  of other multimodal data we can get.
*  I mean, a human being theoretically listens to sounds
*  to do diagnosis.
*  One of the interesting things we found though
*  that you might find surprising Nathan
*  is that these models already generalized
*  to other kinds of data really well.
*  One of the things that really surprised us with GPT-4
*  is that can interpret continuous glucose monitor data
*  out of the box.
*  So you take a glucose monitor
*  and basically you can think of it as a graph
*  of glucose versus time.
*  And I suspect that the model never saw
*  like actual time series data of glucose,
*  but it probably saw a time series data
*  and it probably read things about glucose.
*  And so it can generalize to say like at 1 p.m.
*  the patient's glucose spiked to 170,
*  which was a sign that they ate a carb heavy meal.
*  And you sit there and you go, holy shit,
*  it's never seen this kind of data.
*  And all of a sudden it can generalize to it
*  and do a pretty damn good job.
*  And we didn't do super, super rigorous evaluations,
*  but anecdotally what we saw was it did pretty well.
*  And I think this is like a scary proposition
*  for a lot of people who are talking
*  about their data advantage.
*  Like there are companies who have glucose data
*  and say like, this is our advantage.
*  I believe that these models are generalizing
*  and as we feed them more multimodality,
*  they're gonna generalize even better
*  to the point where out of the box,
*  they're going to be able to do a lot of these things
*  that people historically have thought of
*  as their kind of secret sauce.
*  So that maybe took a different turn
*  than what you were expecting,
*  but I think it's a fascinating area
*  and we're seeing it in medicine
*  and I'd love to see where people are seeing it
*  in other disciplines as well.
*  Yeah, that's a great one.
*  I mean, surprises have not stopped just yet,
*  which shouldn't be not too crazy
*  because we're only on,
*  I've started counting time from GPT-4 release.
*  So we're on GPT-4 four weeks in one day in the new calendar.
*  So there's still, I think probably quite a bit
*  in the vast surface area of these things
*  that will be, is yet to be explored
*  and will continue to surprise us for a while.
*  I guess I'd love to hear kind of how some of this,
*  you're starting to touch on some of the business questions,
*  like moats, where do they come from?
*  Does anybody have them?
*  I'll just get your sense
*  for kind of where you're headed there.
*  It sounds like you're partnered with OpenAI
*  to at least some degree where you had a preview of GPT-4.
*  Do you expect that like OpenAI is kind of,
*  you know, to borrow a phrase,
*  all you need for the foreseeable future?
*  Do you think that that will turn into like
*  becoming a Foundry customer,
*  Foundry being there, you know, as yet unconfirmed,
*  but I think credibly leaked enterprise offering
*  with robust fine tuning that's coming soon.
*  Do you think like at some point you create your own models
*  and, you know, go a totally different route?
*  Maybe it's all of the above,
*  but what do you think is kind of the future of how
*  you and Kirai will use language models
*  over the next couple of years?
*  Yeah, so my general critique of everybody
*  in this space right now is that everybody's trying
*  to believe the things that are convenient.
*  And I think the first like inconvenient truth right now
*  is that OpenAI is way better than everybody else
*  and it's not particularly close.
*  I played around with Google's models.
*  I played around with other models.
*  I won't name other companies
*  because I don't care about insulting Google as much,
*  but they're not anywhere close.
*  And that doesn't mean that can't change.
*  And I really, I think everyone should hope that it changes,
*  that there's good competitive forces.
*  But as it stands, like if you're talking about
*  pure intellectual horsepower and capability,
*  you are sacrificing pretty much no matter what,
*  unless you're using OpenAI.
*  I think it's really important for people to be specific
*  about their problem statement
*  and the problem that they're solving.
*  I would argue for some of the content creation use cases,
*  like something like a Jasper,
*  the performance may be at a point
*  where it's sufficient enough
*  that you don't really need the latest and greatest model
*  and from a cost benefit trade-off,
*  it's probably not worth it.
*  And in that case, it may make sense to train your own model
*  or rely on open source or other models and combined models.
*  And we don't have a problem like that
*  so we can't speak to it at length,
*  but that's my sort of like high level understanding.
*  For something like us,
*  like performance is absolutely critical in medicine.
*  And so we definitely need to use GPT-4
*  and we need to build on it in pretty robust ways
*  to be able to get the performance we want.
*  And that's everything from, like I mentioned,
*  safety and rigor and unit testing
*  to good prompt engineering, to guard rails,
*  to all sorts of like algorithmic improvements.
*  I'd say everything from like,
*  there's people working on how do you increase
*  the context window or the memory of the language model
*  to papers like what we're publishing,
*  which is like, how do you utilize agents
*  to kind of get better reasoning?
*  I think those are all areas of kind of open research for us
*  where we continue to kind of push the envelope.
*  But in many, many cases, we're sort of relying on open AI
*  as kind of the base model.
*  I think we are also really interested in this topic
*  called goal-oriented medicine for us,
*  which is like, much like, you know, like auto GPT,
*  like often in medicine, you have a goal,
*  a patient wants to lose weight,
*  they wanna control their diabetes, et cetera.
*  It's an open problem to figure out,
*  can you direct a language model with that goal
*  to then interact with the patient proactively in some cases
*  to say, how do we work together
*  to accomplish this thing over time?
*  So for where I stand, like the lowest common denominator
*  still is from the language model perspective
*  continues to be open AI.
*  Everything else is sort of like reasoning, safety,
*  improvements, memory.
*  There's so much work to be done to build an advantage
*  on the non-core language model stuff.
*  I think the idea that you're going to train
*  a language model for a specific use case,
*  depending on the use case can be anywhere from correct,
*  but insignificant to completely delusional.
*  I would say companies that are thinking about like,
*  hey, we have a mode, I just brought up the CGM example.
*  I think that's a great example of how these models
*  are starting to generalize in ways that like,
*  your data probably isn't that valuable.
*  And most importantly, like, you know, you know this, Nathan,
*  these things are incredible few shot learners.
*  And so you can give them 10 or a hundred or worst case,
*  a thousand examples of a certain cognitive task,
*  and they tend to generalize incredibly well to that task.
*  And so the idea that like, I have a million data points
*  of thing X and therefore that's going to prevent
*  other people from doing it.
*  I don't know that that's a particularly robust viewpoint
*  when if I can just have somebody, you know,
*  whether it's scale or otherwise,
*  manually label a thousand of these things,
*  and I can get, you know, a 90, 95% of your performance
*  really is going to depend on you needing 99% performance
*  for that to be a substantial advantage.
*  And I'd argue for many, many use cases, that's not the case.
*  And it'll end up coming down to your UX
*  and your distribution and what have you.
*  I appreciate the candor.
*  There's a lot of inconvenient truths,
*  I'd say right now in the AI space
*  and a lot of denial going around
*  in a lot of different directions.
*  So I think the dose of realism is always welcome.
*  The one, one other thing I'll say is
*  I would not underestimate for use case,
*  like how much generalization really matters.
*  So domain specific models are another thing
*  that I think are a little bit overblown.
*  Unless you're worried about cost or latency,
*  again, GPT-4 is probably going to be
*  your domain specific model.
*  And, you know, I brought up the example
*  of like lactose intolerance,
*  but we had another patient case where it's like
*  the patient went to Burning Man
*  and their lungs started hurting.
*  And it's like, how do you actually make a hypothesis
*  about what's going on with this patient?
*  If you're a, imagine if you're trained
*  only on medical records or like biomedical data,
*  you don't have any idea what Burning Man is.
*  And it turned out the patient got dust in their lungs.
*  Right?
*  And so that's what caused the issue.
*  But unless you understand Burning Man, Las Vegas desert,
*  Las Vegas desert, like dust in the lungs,
*  or maybe like there's also a rare fungal infection
*  in the desert, like, unless you know
*  that kind of world knowledge,
*  you're trading off performance there.
*  So domain specific models are another thing
*  that I think a little bit overstated
*  in terms of their potential.
*  I'd love for them to pick up,
*  but I think unless it's like data that the models
*  like never can or will see,
*  like a completely left field thing,
*  I suspect your generalized models
*  are gonna be able to beat you
*  or at least meet you on performance.
*  Life is big.
*  The world is big.
*  The world is messy.
*  There's just, yeah.
*  And especially for something like such a complex system,
*  like our own bodies.
*  I mean, they, yeah, the clues
*  that are just kind of sprinkled into conversation
*  that can be so meaningful.
*  It is, I think what you're saying does make a lot of sense.
*  Like it is very hard to imagine
*  how you could be able to interact with a patient.
*  You might be able to make,
*  you might be able to score well in the USMLE
*  with a domain specific model perhaps,
*  but it does seem like in those real interactions
*  where like the context matters so much
*  and these little hints, these clues,
*  there is a lot of value to all of that.
*  You might even call it a world model.
*  I don't wanna get into trouble for using that term.
*  Out of order, but it does seem like
*  there's something very powerful there.
*  So let's reel it back into present, right?
*  We've outlined your big picture vision.
*  It makes a ton of sense to me.
*  It's incredible to realize that for the most part,
*  it sounds like the core tech that we have today
*  is able to support that vision
*  and that there's like some refinements,
*  some engineering, some integration,
*  you know, savvy usage, guardrails, unit tests,
*  all that stuff that kind of still needs to be approved
*  and vetted out.
*  But if it kind of boils down to the question of like,
*  do we have the core discovery necessary
*  to realize that vision?
*  Sounds like the answer is basically yes.
*  And again, complicate that for me
*  if you think that's wrong, but.
*  I would just say like, it's a very complex problem,
*  but I agree with you.
*  Like the raw natural language understanding tool set
*  and toolkit, yeah, I think it's there.
*  There's a lot of complexity in the problem
*  that needs to be solved for.
*  So tell us like where you are today.
*  Like if I, which I have done by the way, you know,
*  go to Curai and sign up and I become a patient, you know,
*  my own very fortunate privilege is that I honestly
*  didn't have enough medical needs to like really get too deep
*  into how it can help me.
*  So, you know, thank good fortune, providence,
*  whatever for that.
*  But I'd love to understand kind of how much
*  of this vision already exists.
*  And then how are you thinking about getting there?
*  And this is, you know, a topic that Eric
*  is definitely super interested in as well.
*  Like how does the introduction of this technology
*  begin to play with the social, regulatory,
*  governmental, legal systems?
*  I mean, medicine touches everything or maybe medicine,
*  everything touches medicine.
*  So where are you today and kind of how do you navigate
*  a path through the thicket of current structure
*  to get to that future vision?
*  Yeah, so we have a direct to consumer product.
*  You can go online, you can try it out.
*  It's curaihealth.com, C-U-R-A-I.
*  Patients can come online, they download our app,
*  they can match with a doctor,
*  they get ongoing access to care, it's $14.99 a month.
*  But a lot of our focus now as a business
*  is more on our enterprise customers.
*  And that's health plans and provider systems
*  that we're working with.
*  And the concept there that I basically say to folks,
*  at this point, the cat's out of the bag.
*  And over the next three years,
*  most patients are gonna start with chat GPT
*  for medical advice.
*  I genuinely believe that.
*  We saw it with Google, everybody starts with Google
*  for their medical information and advice.
*  And we're gonna see that exacerbated with chat GPT.
*  And I think generally this represents an opportunity
*  for existing health systems and health plans
*  to say, let's get on this trend and in front of it
*  instead of being reactive, where we were 20 years ago,
*  where people started coming in with their printouts
*  from Google and saying, I think in this case,
*  it's even more dangerous,
*  because you're gonna have a lot of scenarios
*  where people are gonna self-serve on chat GPT
*  and never go to the doctor.
*  And that information may or may not be correct.
*  It's really hard to guarantee reliability.
*  I think there's other implications
*  in terms of the business of these institutions
*  where for a health insurance company,
*  if chat GPT says to go to a neurologist,
*  that's an expensive thing.
*  And so we really wanna make sure
*  that you really needed to go to the neurologist
*  before the patient goes and self books
*  or self assigns themselves to a neurologist.
*  We're spending a lot of our time and effort
*  kind of scaling up our partnerships with folks who say,
*  we wanna create kind of our own consumer centric,
*  AI centric version of accessing care
*  that has humans in the loop,
*  that has doctors who can provide oversight
*  and actually close the loop in terms of providing convenience
*  for the consumer.
*  So if the consumer needs medication
*  or they need a lab test or what have you,
*  we see that as a key role we can play
*  is that we can actually deliver medicine
*  in this virtual format
*  instead of just giving you information.
*  Does that mean today,
*  if I have say the app of one of your health system partners,
*  like, do you have this deployed
*  where I can go talk to GPT-4
*  and kind of have that whole interaction
*  and then that gets kind of kicked off at some point to like,
*  okay, now you're gonna talk to the human doctor
*  that's gonna review all that information.
*  Is that all live today?
*  Yeah, so our health system,
*  our first health system partners are going live this year
*  and that is exactly the conception.
*  Like, we don't work with them,
*  so I can say their name as a fake example,
*  but like, Stanford Health Care, which is right here,
*  you download the Stanford Health Care app,
*  you go on their website,
*  there's a button that says get care now
*  or talk to a physician and you click on it
*  and really you get GPT-4 first.
*  And I shouldn't say GPT-4
*  because it's really like this set of models
*  and this system we've built
*  on top of these large English models.
*  And then we sort of, we built the system
*  such that it can appropriately triage you
*  to the right kind of provider,
*  depending on what you need at the right moment,
*  if you're having a medical emergency,
*  and then the doctor can jump in
*  and sort of give you guidance or close the loop.
*  So it's that concept of,
*  we kind of give the patient 80% of their care,
*  and then the last 20% is coming from the clinician,
*  especially in terms of the active decision of what to do.
*  And we've built a bunch of tooling on the backend
*  that sort of speeds up the clinicians,
*  providing them with automation and decision support.
*  So putting together notes for them,
*  automating the follow-up process
*  of checking in with the patient after a visit,
*  automating sort of like the,
*  putting together a care plan for them as well.
*  And those are some of the problems we've worked on.
*  We're in an interesting state right now, Nathan,
*  where like, we're actually,
*  with the public launch of GPT-4,
*  have been releasing, like aging out old models
*  and putting new ones in.
*  So right now, if you actually download the app today,
*  you probably, unless you're in 5% of patients,
*  won't get much interaction with the language model
*  because we're doing a slow rollout.
*  Otherwise, presumably, three months from now,
*  if you're listening to this,
*  this is recorded at the beginning of April,
*  like 95, 100% of people will be receiving
*  that kind of interaction directly with the language model.
*  Yeah, again, it is amazing.
*  Just the timelines are so short.
*  It only came out a month ago, right?
*  So it's like, and I always kind of remind people
*  because the, of course, the hype has,
*  the hype has also come up very quickly,
*  but in a pre-GPT-4 world,
*  I think it was still reasonable,
*  if not necessarily the right conclusion,
*  to say, well, I don't know,
*  I tried GPT-3 and it was pretty dumb still, kind of,
*  and you're telling me this is gonna change the world,
*  and now we're in a moment where it's like,
*  yeah, here's the real deal.
*  It really is gonna change the world,
*  but it's only been available and still,
*  API access wait listed, all that kind of stuff
*  for not even a full month yet.
*  So the timelines are just insane.
*  So that's good to know.
*  So you've got the 5% deployed in kind of your direct model,
*  and then you're working your way up on that.
*  What are you kind of hearing from the establishment?
*  Like, what are the regulatory barriers
*  that you think you're gonna have to deal with?
*  Like, how big of a problem is HIPAA for you?
*  Every time I feel like I do anything with a doctor,
*  it always falls down on my,
*  I can't get the information out wherever I want it.
*  It's always a pain.
*  I'm sure that's a challenge for you,
*  but like, how big of a challenge is that?
*  And what do you think are kind of the most interesting
*  or difficult parts of that overall challenge?
*  Yeah, I mean, one of the challenges with using GPT
*  out of the box is that it's not HIPAA compliant.
*  And so we've had to, like, we've had to be intelligent
*  about where we can utilize it,
*  where we can utilize other models,
*  like where we can have to build our own stuff.
*  Yes, it is a challenge.
*  I know that Microsoft and others are working on this,
*  and I think long-term they all know that healthcare
*  is a high value use case.
*  And so I'm sure this problem will get solved,
*  but for now it continues to be a little bit of an obstacle.
*  From the establishment perspective,
*  what's amazing is how much chat GPT
*  seems to have changed everything.
*  I never thought I would have CEOs of health systems
*  and large health plans, some of whom we work with,
*  that are like, tell us about your work with chat GPT,
*  and how is this gonna change our business?
*  And I think part of it is that it made our business,
*  we've seen a pretty massive acceleration in our business
*  just because it has really made our business digestible.
*  I used to have to explain AI and what it can do
*  and what it can't do, and now people just assume
*  that everything can do everything because of chat GPT.
*  It's so abundantly evident that it's hard to argue against.
*  I mean, you definitely see some more thoughtful critiques
*  in the medical establishment that are like,
*  here's where there's errors
*  and there's hallucinations and things.
*  And when I say you have to,
*  GPT-4 is the most powerful model,
*  you still have to solve for all of those challenges.
*  And things like explainability are really important
*  when you're just deploying to doctors.
*  So how do you combine GPT-4 with other models
*  so you can get interpretability and explainability?
*  These are the types of questions we're getting
*  from the establishment, but I'm not really seeing anybody
*  say like, hey, these models can't do it.
*  And that's remarkable because two years ago,
*  a year ago, 95% of the establishment was like,
*  these models can't do it.
*  And that all seemed to change
*  in a period of three to six months.
*  Are there countries that you think are best suited
*  to take advantage of AI and medicine?
*  I think certainly there will be a leapfrog effect.
*  I don't know if you folks saw,
*  there was that study that came,
*  or that survey data that came out
*  that was like, who's most optimistic?
*  And it was basically like a direct correlation
*  between like optimism on AI
*  and the wealth level of the country.
*  And like basically poorer countries
*  are just like abundantly optimistic about this stuff.
*  If you think about a country like India,
*  there's a billion people, a billion plus people,
*  and there's just no ability to service their patients.
*  One of the practical challenges in these developing countries
*  is that the way that medicine is practiced
*  and even coming down to things like the drug supply chain
*  are not necessarily embedded in these models
*  and are actually like quite nuanced and different.
*  So like, you can ask your favorite large language model,
*  what would you prescribe this patient?
*  And it will generally give you a answer
*  that is like acceptable to the Western world,
*  and especially it's like highly indexed on the US.
*  But when you go to India, it turns out,
*  they really only have like a very limited drug supply chain.
*  And so your answer becomes irrelevant.
*  You can try and ask the model,
*  what should I prescribe if I'm in India?
*  And sometimes it can do okay,
*  but other times it doesn't really have the knowledge
*  of like what that entails.
*  And then there's other challenges
*  like basic health literacy
*  and just like ability to articulate
*  what's going on with you as a patient.
*  Those are all practical challenges that will get solved.
*  And I think the regulatory environment
*  will be a lot more favorable in those countries.
*  But I mean, we operate primarily in the US
*  and I would say we're really optimistic
*  about the environment in the US.
*  Right now we operate sort of really
*  under tight doctor supervision
*  and so our model is, it creates an opportunity for us
*  because we have this sort of like complex,
*  it's like the difference between
*  like brewing a Starbucks coffee
*  and building an entire Starbucks.
*  Like right now we have to build the entire Starbucks.
*  In India, you can just brew the coffee
*  and hand it to everybody.
*  And so it's a little more complex,
*  but building the Starbucks is higher value
*  and I think longer term allows you
*  to kind of optimize everything,
*  like be able to collect our own data,
*  do our own human feedback, do our own fine tuning.
*  And those are all things we're working on
*  that allow us to kind of gain pretty significant advantages.
*  So I am still bullish on the US
*  because the establishment and the regulatory environment,
*  I think they haven't done the thing
*  that some of the other countries are starting to do
*  and come out and say like, absolutely no.
*  I think the mentality continues to be like,
*  let's see and let's be careful and let's have safety,
*  but we're open to this stuff.
*  China, I think is this different thing.
*  I have to imagine the Chinese government's like,
*  in six months, everybody's gonna have
*  a large language model in their hand
*  and there's gonna be no doctors.
*  I mean, I'm only being partially facetious there.
*  It's a little bit alarming,
*  but I think they'll do really well with it long-term.
*  I think short-term there'll be some serious damage done
*  if they do something like that.
*  Yeah, you mentioned China and kind of the,
*  I don't know their medical system at all,
*  but just kind of the ability to make executive decisions
*  on something like this.
*  I was wondering if you also had a point of view
*  around systems like say the UK
*  with the National Health Service or Canada,
*  where there is this kind of much more centralized
*  decision-making structure.
*  Do you think those countries maybe could be like
*  super early adopters or super late adopters
*  just kind of depending on maybe
*  some very idiosyncratic factors?
*  Yeah, I have to imagine that's true.
*  We've looked a little bit at the UK.
*  I haven't looked at Canada.
*  My general concern is that
*  there's such large bureaucracies that it's hard to move.
*  The one good thing about the US is like,
*  you wanna get distribution in the US,
*  like yes, eventually you have to work with Medicare
*  and Medicaid and you have to work with United Health Group
*  and some of these super large players in Anthem.
*  But there's a lot of places where you can start
*  and get some evidence and prove out the model.
*  And that's a lot harder in Britain
*  where everything is under the flag of the NHS.
*  Now, there is a private healthcare system
*  that is cropped up kind of in response
*  to some of the shortages and stuff.
*  And the need is really acute.
*  I mean, pretty much everything you read about the NHS
*  says it's crumbling from the inside.
*  So they need to figure out
*  how to make it economically sustainable
*  and they need to figure out,
*  there's no question in my mind that like
*  large language models can probably solve
*  a lot of the challenges that they're dealing with.
*  Look, governments have to move slow and carefully
*  and most large nationalized health systems
*  are sort of like careful by nature.
*  They might set up some innovation pockets and stuff,
*  but it's not like they,
*  you know, this is like the core of what they do.
*  And so I'm less optimistic that like,
*  this is gonna break through in Britain.
*  Britain does have some interesting examples
*  on the mental health side.
*  There's a company called Limbic
*  that's doing a bunch of a mental health triage
*  using kind of large language models
*  and that's a cool model.
*  And so I think there's some opportunity.
*  The challenge is like, as you move from areas
*  where there's like a clear shortage
*  and like mental health is one of these areas
*  where like nobody's ever gonna have the access
*  that they need.
*  And so you just kind of need to find a solution.
*  The problem is when you start to move more
*  into core medicine and it's like,
*  you kind of get into this territory fighting
*  and you know, elbow jostling kind of thing
*  that I worry that it's gonna be harder,
*  but I'd love to be proven wrong.
*  What do you think is the right way to regulate
*  this kind of new paradigm?
*  Like I've heard a little bit around the FDA
*  is maybe gonna think about a device regulatory paradigm.
*  Does that make sense to you
*  or how would you think about that?
*  I think very clearly the right way is
*  so long as there's doctor oversight,
*  these things should be regulated as decision support
*  and the doctor is ultimately responsible
*  for making the right decision.
*  And I think longer term, these things need to be,
*  you know, if you want one of these things
*  to operate autonomously, it needs to be done
*  much like any other medical device.
*  Like there's a company called IDXDR, yeah.
*  And they are like a diabetic retinopathy screening
*  that has like full scale approval
*  to take AI images of like retinal images
*  and then diagnose the patient
*  and come up with a care plan if I recall.
*  And I think it's a good case study
*  where like you should be able to show the FDA evidence
*  that you can handle certain kinds of clinical cases
*  effectively and they get approval to do them autonomously.
*  But there should be a high, you know, bar for evidence
*  because I do think it's dangerous right now
*  if like in its current state, given what, where we see,
*  like these models are incredibly powerful,
*  but I think releasing them to the average consumer
*  and just letting them practice medicine would be a mistake.
*  So I think right now the way to do it
*  is to start with doctor supervision and then graduate to,
*  hey, we can handle certain kinds of clinical cases
*  autonomously when we get evidence.
*  And then we can kind of go from there.
*  Right now we don't really know
*  what the ceiling of performance is.
*  How close to perfect can these models get?
*  What does it even mean to be perfect
*  in sort of like a probabilistically uncertain environment
*  where we don't really have perfect knowledge
*  of the human body?
*  Those are all questions.
*  And the interesting thing is today,
*  the way that's measured in humans
*  is we measure it based off of
*  what's called standard of care.
*  So basically, like if you get sued for malpractice,
*  it's like, what would the average doctor have done?
*  And the issue here is that these models
*  are incredibly good at doing the average thing.
*  And so right now they probably already meet that bar
*  of like, what would the average doctor have done?
*  And so we're gonna have to figure out
*  some like ethical questions about like, is that acceptable?
*  To me, it should be, it should be the same standard
*  because we don't have,
*  like unlike in the autonomous vehicle world,
*  there's no like perfect driving, right?
*  There's so much ambiguity
*  that I do think we have to compare it
*  to sort of like what's standard of care and what's average.
*  And so I think long-term, that's gonna be the question
*  when you think about regulating these things,
*  it's like, what is sufficient?
*  And I suspect there's gonna be a bunch of lobbying
*  in all directions about like where this ends up.
*  But from my vantage point,
*  these things have a lot of potential
*  to improve access to care.
*  And if they can replicate what, you know,
*  your median physician is doing,
*  that is something that the FDA
*  and others should take seriously and say,
*  hey, we can totally invert the sort of supply demand curves
*  of medicine in this country.
*  How do you think about competing against AI first systems
*  that just do their best and let the patient decide
*  what to do from there?
*  We'll have a couple of them coming on.
*  The main thing, Eric, is that those systems
*  can't actually like provide the utility to the patient.
*  And the utility is in like actually giving them prescription,
*  modifying their medication, giving them a lab test,
*  interpreting those results.
*  Those are all things that need to be done
*  by a doctor in this country,
*  at least from a regulatory perspective today.
*  So while I expect a lot of people would just go to Chad GPT
*  and get a guide, you know, a recommendation,
*  and it says like rest and ice for the next week, great.
*  But if it says, you know, start taking, you know,
*  resubstant, you can't do that for the patient.
*  And so I, you know, ultimately I think that's,
*  you know, the advantage comes in like completing the job
*  to be done for the patient.
*  And then if you can stick with them over time
*  and do the job, like I said, medicine evolves.
*  It's not, you're not solving one problem
*  at one moment in time.
*  You mentioned there's gonna be this like regulatory battle.
*  I'm honestly surprised by how slow that has been to ramp up.
*  And we also kind of talked a little bit about
*  like the possible leapfrogging.
*  I think one really interesting claim that like
*  is starting to maybe be credible now,
*  but I don't know, it's like close, right?
*  I'm gonna be right on the border
*  is that there's sort of maybe an obligation
*  to deploy these kinds of systems.
*  And you could say like, yes, certainly in the US,
*  like you can't get a prescription filled, you know,
*  without a human doctor's signature or whatever,
*  a lot of places where that's not so true, you know,
*  a lot of places where you can buy anything you want
*  at a pharmacy, arguably like if they're good enough
*  and the alternative is so weak,
*  do you see an argument for just kind of saying,
*  hey, this stuff really ought to be deployed
*  even if it's still imperfect,
*  even if we haven't figured out all of the guard rails,
*  even if we maybe haven't got to a level of safety
*  that would like pass an FDA review,
*  but just internationally, right?
*  The billions of people that don't have
*  the standard that we have,
*  I can see a pretty compelling case for,
*  we should put that out there now
*  and accept that there will be some downsides and some harms,
*  but like ultimately the benefit
*  maybe dramatically outweighs that.
*  What's your take on that argument?
*  I certainly think in parts of the developing world
*  where there's basically zero access to care,
*  the answer is absolutely.
*  There's a guy named Rod Punjabi,
*  this is a project called Last Mile Health,
*  and if I recall what they're doing
*  is they basically go and train like high school graduates
*  in how to do community-based primary care.
*  So you're talking about in parts of Africa
*  where you have people who are nowhere close to a doctor
*  who are being trained on like,
*  they basically say these are like
*  the 10 most common things you run into here,
*  it's malaria, it's whatever,
*  and we're gonna teach you how to practice medicine
*  for these 10 things,
*  and you don't have to be particularly trained at all.
*  And so in this way,
*  we can expand access to care pretty massively.
*  There was a story about Bloomberg
*  training high school graduates to do C-sections,
*  I think as well.
*  I think Bloomberg had worked on that at one point,
*  and it's just an example of like,
*  you're talking about parts of the world
*  where access to care is so poor
*  that these kinds of systems are an absolute must.
*  I do think it goes back to my issue
*  that the real problem to be solved is like,
*  how do you adjust to like the cultural
*  and sort of like biomedical norms of that region?
*  That is one thing that will need to be solved to do this,
*  but yeah, I think there is a moral imperative
*  to get these things to a lot of people ASAP.
*  I think that's a great concluding note.
*  I can just give you three kind of real quick
*  rapid fire questions,
*  and you can give me as brief of answers
*  as you like on these.
*  First, any AI products that you use
*  beyond like the obvious chat GPT
*  that you would recommend that the audience try out?
*  Oh man, I've been using a couple of,
*  like I've been playing around with a couple of these
*  like sheets based things for spreadsheets,
*  but I'm not like advocating for any of them
*  super strongly.
*  I am increasingly the ones that I've been playing around
*  with like I've been playing around with some of these
*  YC companies doing like what I'll call like RPA,
*  like kind of Xavier clones using AI.
*  I think those are super cool.
*  There's one called Layup that I liked.
*  I don't have a good answer.
*  I just like, I'm more like playing
*  than I have something in my habits right now.
*  Honestly, this did not start as a trick question,
*  but you are very, you're in very good company
*  with that answer in one of the biggest takeaways
*  that I've had from this series of conversations
*  has been how there just aren't that many applications
*  that are adding that much value to the core model right now.
*  I do think integration, as you said, with sheets,
*  like that'll make a ton of sense.
*  It'll be way more convenient, you know,
*  when it's in the sheet directly
*  than to like flip over to chat GPT,
*  but I think the sad thing is I'm trying to learn
*  how to use these things too.
*  Like I have to teach myself,
*  like I know there's some way to look at what I do in a day
*  and be like, this can be GPT eyes and this can't,
*  but the only thing I can do is like put it into GPT right now.
*  Like that's all I do and everything else is like,
*  I'm trying to learn these new products.
*  You're in good company.
*  We're all learning in real time here together.
*  All right, second quick hitter, you,
*  hypothetical situation,
*  but especially in your take on it,
*  given your medicine lens here,
*  let's imagine a future world where a million people
*  have the Neuralink implant implanted
*  and now it's general availability.
*  If you get one, you have thought to text
*  or thought to UI control.
*  Essentially you can use your devices
*  and transmit information to your devices
*  straight from your thoughts.
*  Would you be interested in getting one?
*  I have long said that like the product that I want
*  is the thing that records my thoughts
*  while I'm falling asleep,
*  because that's when I have all my best thoughts.
*  There's a particular term,
*  it's like a pedagogic state that your brain gets into.
*  I forget the exact word, but you can actually like,
*  you can coerce your brain to be in this state,
*  which is a separate thing.
*  But the direct answer to your question is I don't know.
*  And I think at a certain point we're start,
*  like it's very clear to me that in the next 10, 15, 20 years,
*  whenever it happens,
*  we're reaching a point as society where like,
*  life is more about understanding what's,
*  like it will be about what understanding,
*  like understanding what spiritual fulfillment means to you.
*  And it's not gonna be about like optimizing your performance
*  or blah, blah, blah.
*  Or maybe that will be what it is,
*  but like there's gonna be so much infrastructure
*  that cognitively can do so much for us
*  that like you have to decide like,
*  what do I want my experience life in life to be?
*  Do I wanna live in VR or the metaverse?
*  Do I wanna like just like go out in nature and hike?
*  Do I wanna like have some neural implant?
*  Like, I just don't know.
*  And I think the sad thing about being an entrepreneur
*  is I probably don't have time to think about those things,
*  even though I'm working directionally on some of them.
*  So my sad answer is like,
*  I kinda need to know more about like spiritually
*  what I want out of the next 70 years of my life,
*  or maybe it's 170, I don't know,
*  with this longevity stuff,
*  before I can say like, yes, I need the implant now.
*  On its surface, like I want anything
*  that enhances my life,
*  but I think what we're finding is these things,
*  they have such like, even with our phones,
*  they have these like very unpredictable
*  of second order effects on how we live.
*  And it's a little scary in that regard,
*  but I'm also super excited about it.
*  Well, you kind of anticipate the last question there,
*  which is just zooming out as much as possible
*  and you're just starting to do that.
*  What are your biggest hopes for
*  and fears for society at large
*  as we begin to feel the impacts of AI
*  over the rest of this decade?
*  Yeah, I'm a pretty staunch capitalist,
*  but I do believe that like,
*  we are gonna have to figure out how to redistribute wealth
*  or at least redistribute prosperity.
*  It's not even clear to me that like classical economics
*  are gonna totally hold up the way
*  that they have historically.
*  I do think that there's gonna be an abundance
*  of wealth created.
*  And I think I'm super optimistic,
*  but I think this goes wrong
*  if like you turn into like this dystopian,
*  like a few people control the world kind of thing,
*  or if like we try and stop these things
*  because you won't stop it.
*  People like China and Russia will build these things.
*  And I think the world gets dystopian
*  maybe in a different way.
*  And so for me, if I look out 20, 25 years,
*  like I think the big question for society are like,
*  how are we gonna get people to shift
*  from a scarcity mindset to an abundance mindset
*  as we build it?
*  And if we can do that,
*  then we can build a world where people are really happy.
*  And then I think there's a separate question of like,
*  how do we as humans finally shift to a world
*  where like people don't have to work.
*  They don't have to do stuff just to get by.
*  I remember listening to Bill Gates talk at one point
*  and he said like,
*  if the purpose of a human being is to be a hamburger chef,
*  like that's a pretty depressing existence.
*  And so like, you know,
*  a lot of people worried about work displacement and stuff.
*  And I think there's good reasons
*  because we need everybody to share an economic prosperity,
*  but I don't think anybody aspires,
*  I mean, SpongeBob aside to be like a fast food chef.
*  And so like, I think it's a net good thing.
*  The problem is that we don't have answers
*  for what it means and what the implications are
*  for how people should spend their time.
*  So until we figure those things out,
*  and if we don't, we're sort of in trouble.
*  And so that's kind of like what I'm hoping
*  for the next 25 years,
*  people realize there's so much good that's gonna come.
*  There's a version of the world in 25 years where like,
*  people could live forever.
*  There's like energy is free, intelligence is free.
*  Like, there's just like abundance created everywhere.
*  And like the problem that we're worried
*  about solving long-term is like,
*  how do we then like expand and colonize more places
*  and expand our presence in the universe?
*  And that's like a very exciting version of the world.
*  And people are free to play music and games and socialize
*  and do all the other things that give them joy
*  and meaning in life.
*  But like to get there is gonna require
*  a lot of like societal restructuring.
*  So personally, I'm really optimistic.
*  And I think compared to the average person in Silicon Valley,
*  I do believe that like,
*  we have to work with existing governments
*  and what I call like the public side of the world
*  to make this thing happen.
*  Otherwise, we're just gonna build these things in isolation.
*  They're gonna be more destructive than anything,
*  which is why I kind of have the perspective I do
*  on regulation, which is like, yes, I think if we run,
*  let AI run wild in medicine, it's gonna be a problem.
*  Otherwise, we're really gonna,
*  we could really benefit from this stuff.
*  We collaborate.
*  I just talked for way too long.
*  I rambled a lot today, but guys, this was awesome.
*  We love it.
*  Neil Kosla, thank you for being part
*  of the Cogrev revolution.
*  Omniki uses generative AI to enable you to launch
*  hundreds of thousands of ad iterations that actually work
*  customized across all platforms with a click of a button.
*  I believe in Omniki so much that I invested in it.
*  And I recommend you use it too.
*  Use Cogrev to get a 10% discount.
