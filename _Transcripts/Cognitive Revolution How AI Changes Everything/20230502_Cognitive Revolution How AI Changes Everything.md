---
Date Generated: April 03, 2024
Transcription Model: whisper medium 20231117
Length: 3510s
Video Keywords: []
Video Views: 3317
Video Rating: None
---

# VC Insights on Investing in Artificial Intelligence with Sarah Guo and Elad Gil of No Priors
**Cognitive Revolution "How AI Changes Everything":** [May 02, 2023](https://www.youtube.com/watch?v=2tMDBa9zAwY)
*  and I started digging around. I tried to find people to build an open AI competitor,
*  and I couldn't convince anybody to do it. Everybody said, well, it's not that interesting of a
*  business and are these APIs that good and all this other stuff. And I pitched person after person and
*  nobody was willing to try it. Within consumer character is one of the most interesting
*  companies. Replica is one of the most interesting companies. A lot of people don't like this,
*  even though you see a decade or more than a decade for a lot of looking at consumer company metrics,
*  you're like, shit, right? Like, I'm going to pay attention if people are spending hours a day on
*  this service, because it is so rare. You know, there's base models and there's based models with
*  a D, right? Like, what, what kind of model do you want your kid to interact with? And what do you
*  want them to learn over time? And you know, how did that how does that get selected? And who
*  who adjudicates what that selection process is? Or what's the the ethical framework based on your
*  location around the world that should be applied or shouldn't be applied? And so I think there's
*  lots and lots and lots of interesting questions here. Hello, and welcome to the cognitive
*  revolution, where we interview visionary researchers, entrepreneurs and builders
*  working on the frontier of artificial intelligence. Each week, we'll explore their revolutionary
*  ideas. And together, we'll build a picture of how AI technology will transform work, life and
*  society in the coming years. I'm Nathan Labenz joined by my co host, Eric Thornburg. Before we
*  dive into the cognitive revolution, I want to tell you about my new interview show upstream.
*  Upstream is where I go deeper with some of the world's most interesting thinkers
*  to map the constellation of ideas that matter. On the first season of upstream,
*  you'll hear from Mark Andreessen, David Sachs, Balaji, Ezra Klein, Joe Lonsdale, and more. Make
*  sure to subscribe and check out the first episode with a 16 Z's Mark Andreessen. The link is in the
*  description. Hi, everyone, and welcome back to the cognitive revolution. After taking a deep dive
*  into prompting process automation and jailbreaking over several recent episodes, we're now zooming
*  out of it and talking to some fellow AI scouts. These are people who are not only working over
*  time to understand everything that's going on in AI, but also creating thought leadership and
*  educational content meant to help others get up to speed as well. Today, our guests are investors
*  Sarah Gough and the lot Gil co hosts of the AI focused no priors podcast. Sarah was previously
*  a partner at Greylock and is now the founder of the $100 million AI focused venture fund conviction
*  VC, which she launched last fall. She blogs on her website, saragoa.com. He led Gil is a notable
*  angel investor with investments that include Airbnb, Coinbase, Figma, Square, Stripe, and many
*  more, including recent AI companies such as character AI, Harvey AI and perplexity AI, whose
*  CEO Arvind Srinivas, you may remember, was a guest on the cognitive revolution back in episode seven.
*  He also blogs at blog.eladgil.com. We spoke about how they are approaching AI investment
*  opportunities right now, how that does or doesn't differ from how they've thought about investing in
*  the past, where in the stack from hardware to applications that they expect to see the most
*  value accrue, what modes of human AI interaction they're most interested in developing, and plenty,
*  plenty more. I hope you enjoyed this conversation with Sarah Gough and a lot Gil, Sarah Gough and
*  a lot Gil. Welcome to the cognitive revolution. Thanks for having us. Yeah, very excited to
*  have this conversation with you guys. We're in such a moment right now of just the whole world
*  kind of turning attention to AI. And that's something that I think we're probably four or
*  five months into since the release of chat GPT. You guys have each been thinking about AI very
*  seriously and both independently and together, I think, well before that. So I thought we maybe
*  just start by kind of revisiting a couple things that you guys had published about six months ago
*  and then ask you to just kind of take us through this period of time where, you know, new models
*  are being released, new tools, new paradigms, just, you know, attention piling in investment,
*  you know, dollars, I'm sure piling in from all directions as well. And then we'll take it from
*  there. So Sarah, starting with you, you announced about six months ago, this hundred million dollar
*  conviction fund where you are investing in software 3.0. So I thought for just a start,
*  you know, can you set a foundation for us and tell us how you think about software 3.0 and what that
*  means? Yeah, I think it's shorthand for just believing that there's a very unexpected new
*  set of software businesses emerging that can be very important. Right. So everybody knows like,
*  you know, you have this exponential creation of capabilities in machine learning. I remember a lot
*  and I actually had a debate like six plus months ago, like, hey, there have been a lot of ML first
*  companies that haven't worked in the past and what changes. But I think these these those sort of
*  exponential creation of new capabilities is the thing that got me really excited for the fund.
*  And when you think about like, what's so different about the software, it's what it does, right? I
*  think it attacks like lots of categories of services or like areas that were not like big
*  software markets before. Copying writing, like illustration, law, right? What the companies look
*  like. So this could be how many people does it take to create a one or $10 billion company?
*  Like now we have empirical proof, like 20, right? And like that was not true in previous generations
*  of software. And then I think like one that is still unexplored is just like how the product should
*  work from a UX and a human interaction perspective. I think we're going to get a lot more than just
*  like the single chat box. Yeah, I definitely look forward to unpacking that because I just see so
*  many different possibilities and it feels like we're so early in kind of exploring what the
*  modes of human AI interaction are going to be. One thing that jumped out to me about your
*  announcement was just, you know, there's the AI focus, but then beyond that, just like extremely
*  broad investment thesis, right? Totally up and down the stack, all the different verticals.
*  How has, if at all, how has your thinking evolved in terms of like which parts of the stack or which
*  verticals are kind of most interesting over the last six months? Some of the areas that are
*  really attractive from a demand, like a value for end users or for customers perspective are
*  like obvious in hindsight, but somewhat unexpected, right? And so anybody who has,
*  you know, heard of Babelfish or like interacting with somebody who speaks a different language,
*  like I think they intuitively understand that like translation is interesting and the idea of like
*  dubbing of the service is interesting. But I think if you zoom out more broadly, I think the question
*  around like is synthetic voice and the ability to take one form of media and translate it to
*  others cheaply and easily obvious in hindsight, I think I've been like somewhat surprised by the
*  demand on that side across a range of use cases in terms of things that we are interested in.
*  But like the bar is just very high because the cost to build a company and the advantages and
*  comments are so high. It's like we haven't done a chip company, but we've done companies that are
*  up and down the stack. Otherwise. Cool. Well, I want to ask you guys also about some specific
*  portfolio companies that you've invested in, that you're excited about and get a little tour of kind
*  of some of the use cases and some of the things that will be coming at us from a consumer or
*  business standpoint in the not too distant future. But I also want to kind of do the same thing for
*  you a lot because about six months ago, you published this essay, AI Startup versus Incumbent
*  Value. And that hit me at a pretty opportune moment. I was just at the period, the end of a
*  period of 60 days of super intensive red teaming on GPT-4. And I was basically not even, I hadn't
*  even really tried to synthesize what I had seen at that point. I was really just scouting, you know,
*  all the different use cases and everything I could think of to test and try to understand
*  what this thing could do. And right as that kind of closed, you published your essay.
*  And so I read that and I was thinking, for me, it seemed like, boy, this GPT-4 is incredibly
*  powerful. And the conclusion that I started to leap to is I think that the enterprises
*  are largely going to be able to apply this technology fast enough that they largely
*  won't get disrupted by somebody who's starting with a language model and then thinking,
*  how do I build all this other stuff around that? How would you grade my intuition from six months
*  ago? How has your thinking evolved on that question now that you've had the advantage of seeing
*  GPT-4 launched and the deal flow that you're seeing downstream of that?
*  So let's see. So, you know, I got really interested in generative AI a bunch of years ago,
*  probably four or five years ago, as all the GAN stuff was happening simply because I thought that
*  the GAN-based art stuff was super interesting. And before that, I'd been investing in AI
*  and also worked on AI-related products myself directly for like 10, 15 years. So when I was
*  at Google, I worked on mobile and ads targeting and ads targeting were big amount systems. And
*  then I sold the company to Twitter and Twitter, one of the teams that worked for me was Search.
*  And that was all ML and AI. And then I invested in the area for about a decade. And for about a
*  decade, nothing worked, right? Or I should say a lot of things worked for incumbents, but it didn't
*  work for startups. And so you had the Facebook newsfeed and you had Alexa from Amazon and you
*  had all these really big products. But the startup ecosystem in terms of companies that were started
*  to specifically do ML, just really didn't seem to go anywhere in terms of, you know, building
*  really massive companies. And then this generative AI wave hit. And I think things
*  started to get really interesting around GPT-2. And then maybe as GPT-3 came out with the big step
*  function and functionality, you realized how compelling it was. And I remember, I went on
*  an Andreessen podcast and we talked about it specifically. And I think at the time, a lot of
*  people were ignoring it. And I started digging around, I tried to find people to build an open
*  AI competitor. And I couldn't convince anybody to do it. Everybody said, well, it's not that
*  interesting of a business. And, you know, are these APIs that good? And all this other stuff.
*  And I pitched person after person and nobody was willing to try it. But a lot of people who'd worked
*  in the area before wanted to build applications. And so I started investing in companies like
*  Character. You know, Noam Shazir was one of the main authors on the Transformer paper. I helped
*  out some of the early team that was working at Adapt, although I never got involved there as an
*  investor. I got involved with things like Perplexity and Harvey and a variety of companies that basically,
*  I think ended up forming, you know, some of the more interesting companies now a year or two later,
*  in hindsight, in terms of this wave of AI stuff. And a lot of the question in my mind is if you look
*  at the history of technology waves, there tends to be differential capture between incumbents and
*  startups. And each technology wave is different. And so if you look at, you know, the first internet
*  wave, it was like 80% startups, it was Google, and it was Amazon and all these new companies,
*  and then people like Microsoft benefited too. And then you look at, you know, mobile, and that was
*  80% incumbent value. It was the big platforms were Apple and Google, which were already
*  incumbents. You know, people were talking then about what is Salesforce on your phone going to
*  be and who's going to build it. And it turned out to be Salesforce. Build Salesforce for your iPhone,
*  right? Or search on your phone was Google. But there was new things like Uber and Instacart and
*  Instagram, basically anything with the Insta in it, you should have just invested in.
*  And then you had other types of platforms that emerged, you know, for crypto, it was 100%
*  startup value. There's basically no incumbent capture of crypto, right? And so for the first
*  decade of AI with all the CNN and RNN and again, related approaches, all the value went to incumbents.
*  That first wave of AI was an incumbent wave. And now we're seeing something really interesting
*  where I think it's going to be a differential split. And maybe it's 80-20, right? 80% incumbent,
*  20% startup, but 20% is a lot for what I think is probably the biggest platform shift in, you know,
*  a decade plus, maybe two decades, maybe longer. Because to Sarah's point, you're changing a few
*  things in a massive way in an underlying way, you're changing the compute model and how to write
*  code, you're changing the user interface, but you're also changing the baseline functionalities
*  and what this wave of computing can actually do in terms of both applications,
*  as well as sort of other deep areas. And so, you know, there's tons and tons of places that I think
*  is going to impact Sarah mentioned voice and dubbing and text to speech. And, you know, I think
*  those are super interesting areas. And she and I have talked about those in the past a bit.
*  There's tons of room, I think, for social products. And I'm really interested in like,
*  what is a generative social product look like? There's lots of apps on the B2B side, there's
*  lots of tooling like the lane chain or llama index or other things like that. And then obviously,
*  there's the base LLM layer. So there's just a ton, right? And a bunch of that stuff will go
*  to incumbents, you know, probably the base models are largely incumbents with maybe Anthropic and one
*  or two others being the kind of examples, right? OpenAI, Microsoft, Google, etc. But there's lots
*  and lots of room for people to build, you know, brand new to know about things that will be super
*  exciting. Just just on that for a moment, you know, you mentioned that you tried to get people to
*  build open AI competitors, and they you know, you can can get people to bite. What are you guys trying
*  to get people to build today? For the talented people listening to this podcast who want to do
*  something? And what are the things that people aren't spending as much time as they should perhaps
*  or maybe overlooked opportunities within voice applications, social, certain big B2B applications,
*  and certain types of infrastructure? I know what Sarah what you think, but those would be kind of
*  the four quick ones. Yeah, I'd add this this idea of tool use, right? So, you know, an LLM can be a
*  reasoning engine against knowledge that it holds in the model itself, or some database or, you know,
*  some repository of information, but it can also take action. Right. So if you think that tool
*  form or an automation and the previous generation of products in the sort of RPA category, I think
*  that's going to get a lot more interesting when the approaches get more robust. There's a lot of
*  workflows in every part of the enterprise, but especially the back office and some verticals
*  like healthcare, where like, you have a lot of people moving data around between systems or
*  filling out forms based on some policy. And like, we've been unable to do that flexibly today, but
*  it is a, you know, basic tool use in natural language tasks. So I think that's really interesting
*  one. Like there are some areas that we think are just going to get more important from a core
*  architecture perspective over time. So the idea of retrieval and just like, how do you guarantee
*  like retrieval and memory are two concepts that I think are really interesting in research that
*  people can't figure out how to use in like actual enterprise applications. And then, you know,
*  I'm really interested in some of the more emergent stuff. Like if you look at companies like Mid
*  Journey, the idea of democratizing capabilities, like that people didn't have before, if that's
*  illustration, which I promise you, not a lot of VCs were focused on before, but generally like,
*  I think media creation is really interesting. Omniki uses generative AI to enable you to launch
*  hundreds of thousands of ad iterations that actually work customized across all platforms
*  with a click of a button. I believe in Omniki so much that I invested in it, and I recommend you
*  use it to use Cogrev to get a 10% discount. Alad, can you say just a little bit more about what AI
*  social could look like? You know, I actually have a lot of ideas, but they're probably really bad
*  ideas, right? I think with social products, the key thing is you want to launch things and then
*  quickly iterate and sort of see what gets adopted. And, you know, I know people doing a range of
*  things, but I also don't want to kind of like dox them or something in terms of what they're doing.
*  But, you know, over the last couple of months, I think I've heard a couple of really interesting
*  ideas on the social side. And, you know, it's a variety of different formats and approaches and
*  everything else. And I just think there's a ton to do there. And I think the issue is when I look at
*  social products today, people are basically constantly trying to rebuild Twitter for some
*  reason. You know, every month there's a new, hey, we're doing Twitter, but it's decentralized,
*  we're doing Twitter, but it's whatever. Not with generative AI, right? Or people are trying to do
*  Facebook throwbacks. And you're like, where is the technology heading and what does that mean in
*  terms of entirely new types of interactions where you're still taking advantage of core social
*  behaviors, right? Ruloff has this seven deadly sins, right? Every social product basically is
*  like gluttony or lust or, you know, one of the seven deadly sins. And I think if you think of
*  that through a generative aspect, there's really interesting ideas that you can start coming up
*  with versus saying, I'm just going to throw things back. It reminds me a lot actually, when I left
*  Google, it was a long time ago either way, whenever I left Google, whatever year that may have been,
*  a lot of people were building things that they shouldn't have been building because they were
*  building for the past. So they're like, oh, I'm going to build this SEO-able thing and get
*  traffic that way and blah, blah, blah, instead of saying, hey, I'm going to build a developer tool,
*  which is a new thing, or I'm going to build a mobile company, which is a new thing. And so I
*  think a lot of the social products I see are reflections of the past versus the future.
*  And that may work. It may actually create really big companies. But the flip side of it is there's
*  probably some really interesting things that we can all kind of squint and imagine that's coming.
*  I think that there is a lot of open-mindedness required for some of the consumer stuff. And that
*  if you consume, like within consumer character is one of the most interesting companies. Replica is
*  one of the most interesting companies. A lot of people don't like this, even though you see like,
*  a decade or more than a decade for a lot of looking at consumer company metrics, you're like,
*  shit, right? I'm going to pay attention if people are spending hours a day on this service because
*  it is so rare. I think it's very easy not to like it because it's a weird thing that people want to
*  have these parasocial relationships. And they're because there's demand for NSFW use cases. But
*  that's how a lot of things on the internet start, right? Yeah. We had Eugenia from Replica on as a
*  guest. It was certainly one of the more fascinating conversations that we've had to understand,
*  first of all, just like what the user base is today and has been historically while the models
*  have been so limited, frankly. And then to kind of extrapolate that into the present and the future
*  where it's like, this was not honestly super compelling to me, but I see how it could easily
*  become much more compelling. There is a phase change or kind of a threshold that we've hit,
*  I think, that is going to kind of take Replica 1.0 and make it look pretty quaint as we hit 3.0.
*  Well, I think it's going to be deeper than a lot of people imagine.
*  Seven, eight years ago, we started investing in what you'd think of as like mobile coaching,
*  like marketplace applications for different areas. So that could be like something in health,
*  like nutrition or trick, like people are doing like fitness training and such. And as you might
*  imagine, like having an accountability partner or somebody you're building an emotional relationship
*  with means you can affect behavior change, which is really hard for humans. And one of the most
*  interesting things I've seen recently is bots can, they can convince and like coax people to do
*  things, right? Plan their days, change behaviors. And so I think that's something we're going to see
*  a lot of. Yeah, I think the applications that are going to be broader than anybody thinks,
*  like if you look at it, you know, if you think about education, how do you revamp education
*  and everybody's going to have like a bot? Is there a kid growing up that's going to teach them
*  things and help them with stuff and maybe becomes their best friend? Right. And there's very positive
*  and very negative implications of that, right? And so I do think people are dramatically
*  underestimating the degree to which on the one hand, there's a bunch of lonely people or people
*  who want to interact online more and they don't have the capacity to do it otherwise. And then
*  on the other hand, there are these really deep, fundamental societal use cases that are coming
*  through the generation of these agents that interact with you like a real person. And in
*  some cases, I mean, every parent is going to want the thing that's going to educate their kid in a
*  hyper customized way. And that's going to be both very powerful, but which company is going to
*  control that? And what does that mean for our kids and how they're taught and raised and all
*  the rest of it, right? So I think there's some very deep fundamental things here that people
*  are just barely touching the surface on. And some of it's an old sci fi literature, like the
*  Diamond Age, right? It's the young ladies illustrated primer. But in some cases, I think
*  people haven't really thought about it very deeply. Or there's another book called Lady Amazes, where
*  every time there's a sufficiently large block of people that believe something that substantiates
*  into an AI agent that represents them in Congress. And so why even vote when you can have a perfect
*  representative, you suddenly appear and actually, you know, fight for and adjudicate the things that
*  you truly care about. And so I think there's all sorts of crazy things that are coming.
*  On a more quotidian day to day level, I want an agent that just helps me maximize my productivity,
*  that's watching me at all times, watching all my interactions with people and, you know,
*  tells me when I'm acting out of line or says that no, say this, this would be a better thing to say,
*  kind of like a personal trainer for all things like coach, you know, that's watching me at all
*  time. Yeah, I just want a sycophantic AI. Let's be like, you're so good. That was such a good joke.
*  That'd be amazing. There's a couple of really interesting questions here that I think these
*  examples get at. It's funny you mentioned the training one, going back to my GPT-4 experimentation.
*  One of the things that I tried to do is just see like how many sort of chat, you know, specialized
*  chat agents could this thing sort of play? I did the physical, you know, kind of exercise coach one.
*  And I also did one simulating tech support for my 90 year old grandmother, which was even maybe more
*  eye opening to me because it really spoke to a pain point that we have in my family. But how do
*  you guys think about that as investors, right? Because I'm sitting there using base model,
*  GPT-4, and it's basically working. And then I'm kind of like, this feels like it sort of hits the
*  threshold. I can certainly, you know, wrap this up into an app or somebody can. But at that level of
*  like, I used to go hire a human to do this. Now I can maybe slot in an AI to kind of play that role.
*  Are there businesses there? Or is that all kind of is all that value accrued to open AI in your minds?
*  Or foundation model providers in general? Yeah, I mean, I think there's tons of room for standalone
*  applications. And I think a lot of them will be building workflow against it, or some form of like
*  storage or history or memory or something else that sort of associates with the chain of stuff
*  that you did relative to that. You know, it's kind of funny, I'm going to give an extreme example,
*  which doesn't quite apply. But in the 90s, everybody thought that everybody was going to
*  set up their own email servers, right? Oh, emails are protocol, and everybody's going to use it,
*  it's so easy to use. And then obviously, everything just centralized to like Gmail and Yahoo Mail,
*  and whatever your corporate server was. And I think the same thing happens with a lot of these
*  things where, you know, there may be interfaces like chat GPT, or the like, and things like memory,
*  and some of the other things that, you know, some sort of recursive interaction across a
*  language model will come into play and chaining and all sorts of things, it'll be more
*  complicated. But I think fundamentally, people will need very specific workflow for very specific
*  applications in many cases. And in some cases, you'll have a general purpose tool where chat GPT
*  will be good enough to just do a bunch of stuff for you, right? Or whatever, whatever version of
*  an agent you're using in the future. So I do think we're going to end up in a multi agent world.
*  But there may be like specific things that are dominant for specific use cases, just like
*  everything else that exists today. You know, I feel like the best indicator of how things will
*  evolve is kind of like how do market structures evolve in the past? And I think it's going to be
*  kind of the same thing. So how about like use cases, or not use cases exactly, but modes of
*  interaction? This is something I've really been trying to organize my thinking around.
*  Eric's got this vision for the, you know, AI that kind of rides shotgun all the time and like, you
*  know, helps him maintain his social graces. And you can kind of, you know, that's kind of the
*  Reid Hoffman vision, I would say is like the copilot for every profession, copilot for every
*  phase of life. And then you're speaking to also on the other end, like, people are going to need
*  specific workflows. I kind of think of that. And Sarah, you mentioned like RPA, like there's
*  this sort of process automation context where it's like, I'm a big corporation, you know, I have like
*  these cost centers, which are humans that have to like do these tasks. I've never had any way
*  to even think about automating these tasks in the past. But now I sort of have that. And then
*  there's kind of this third way that's emerging, that's like the agent model, which I kind of think
*  is bridging, I think of as bridging those two, because I can like, talk to it in a sort of ad
*  hoc real time way. But I can also kind of send it off and say, like, you go figure out the plumbing
*  and like how things connect together, you know, so even get me out of the business of having to
*  design, you know, architect the workflow. I guess, you know, that's enough for me. How does that
*  framework resonate for you? Do you have like a different one that you kind of bump company,
*  you know, deal flow up against? And what modes of interaction do you think are ultimately going to
*  predominate? And is that the same as those that give you the best return on your investment?
*  I think when you start to actually like look at the tools that have succeeded at scale,
*  there's like a whole range of ways that users want to interact with the stuff depending on the task.
*  So like prompting is not an easy thing for like 99.99% of humans today. So just because you enjoy
*  like Nathan messing around with GPT-4 and lots of users of your podcast might, it's hard to ask a
*  good question. And I think like one of the things that I've seen in companies that I think will just
*  become more common is like multimodal input passively using context, right? I think there
*  are a lot of companies that figured out like giving end users in a particular category,
*  20 prompt templates that made sense for their use case and an easy button so they don't have
*  to figure out how to engineer a good output. Like that's a company right now, right? And so
*  it's not clear to me that we're going to have, you know, generic interfaces for all the different
*  use cases. One of the things that I think will happen to the point of like, do we like, I think
*  search is going to break. And I'd love to get, you know, a lot of point of view on this since
*  he actually worked on search, but having been invested in search companies prior and having
*  friends starting them now still searches many use cases. It is weird to me that like getting
*  information from the internet has fallen into one box at Google. And I imagine that many of the use
*  cases, like the stereotypical one being like travel planning or buy something like that's something
*  I think an agent should be able to much better do for you in the future. So I think there's like
*  certain things that will fragment from a market perspective. And every slice of that market is
*  like plenty valuable to go after for a new company. So one of the basic frameworks we use, I don't know
*  if I've got like the sort of overarching unification right now the ground is too unstable.
*  Yeah, I kind of have two answers to it. I think there's almost like a two by two matrix of like,
*  is a person busy or do they have a lot of free time? And then as a context, you know, the context
*  maybe it's not two by two, it's like three by two or four by two or something. It's like busy versus
*  free time. And then one of a series of contexts around B2B use cases, commerce slash action based
*  use cases, etc. And then based on that, you're going to have a different modality. And so I think
*  you can almost come up with like a map on it. And it reminds me a little bit of like if you work at
*  a big company, the way that you interact with like the CEO is different from how the CEO interacts
*  with you. You'll write this long email of like multiple paragraphs and the CEO will send you
*  yep, is like a single word or whatever, or you know, execs tend to leave a lot of voicemails or
*  they used to, right? Because it was a more performant way to communicate. And so that's
*  kind of busy versus not and all the rest. And so I think there'll be all these modalities.
*  I think the other answer is in some sense, it kind of doesn't matter. It's funny, I met with
*  this hedge fund guy who's really sharp, like, you know, amazing investor. And we were talking about
*  AI and, you know, a lot of his questions tended to center on this kind of stuff. It's like, well,
*  we just talk into your phone and I was like, who cares? It doesn't matter. That's missing the main
*  point, which is what is this technology fundamentally enable? And we'll figure out the interface and
*  we'll iterate on it. And it'll be one of a series of interfaces that we use today, right? I mean,
*  fundamentally, we have like n senses and we'll have different modalities that matches different
*  senses depending on the use case. But it's clear that, you know, say they use Alexa, right? People
*  with kids love using Alexa because it's voice based and the kid can yell at the thing and it'll reply.
*  But you're not going to have a lengthy information extraction conversation with it unless you're like
*  a three year old, right? And so I think it kind of maps to the, you know, what are you trying to
*  accomplish? And I think the most interesting aspect of all this stuff is just like, what are
*  the fundamentally new capabilities that all this enables? And what does that mean in terms of the
*  applications that can be built in terms of how it reshapes our lives? You know, like, I think
*  there's really, I'll give you an example. You know, obviously, these models now perform better
*  than many doctors on standardized medical exams or other types of tests. And you can imagine a
*  world where you start having models that are basically available to anybody in the world,
*  which allows you to upload an image and, you know, describe some symptoms. And then you end up with
*  medical care that's, you know, in some senses on par with what you get at Stanford or whatever top,
*  you know, medical association. And you can do that anywhere in the world as long as you have like a
*  phone that has certain characteristics. That's really, really, really powerful. And to some
*  extent, the interface is secondary to that impact. And so I'm not trying to denigrate the interface
*  question. I think it's really important stuff. I just think like, fundamentally, the capabilities
*  are so rich that it's almost like, okay, where do the capabilities take us? And then based on that,
*  what happens as the output? It won't be multiple types of outputs. Interface is definitely
*  interesting. There's all, you know, I'd be interested to hear if you guys have seen any
*  really creative ones that, you know, you would recommend that people check out.
*  But I'm also kind of thinking even a little bit more like big picture than that, like,
*  just how do we relate to these damn things in the first place? You know, are the is the co the
*  co-pilot feels kind of like a peer, you know, or something like a real time collaborator. And that
*  could be an audio interface or a text or, you know, UI or whatever. But then there's like, you know,
*  the agent, you're kind of delegating to it. And then there's the sort of, you know, supervision
*  mode, perhaps where like, you largely trust it, but you kind of, you know, maybe trust but verify,
*  and hopefully you like, actually do the verification and don't just, you know,
*  start rubber stamping everything. What about on that level? Do you have a sense for kind of
*  where this is going? Like, another way, maybe to ask this question is like, how weird do you think
*  things are going to get as these tools? I think eventually we're going to call all these things
*  your highness as they sort of take over the world. I love my boss, the AI. Yeah, no, I think the world
*  is going to get really interesting and weird. And I think that's back to the education point,
*  for example, like if you have a bot helping raise your kids, what does that mean? Right, or for one
*  of the primary sources of information no longer becomes YouTube, it becomes some agent that's
*  not only working them through a math and history and other curriculum, but potentially is choosing
*  which form of history gets presented to the kid. You talked about base model and I can't
*  use biology or something else. It sounds like something you'd say, but I don't know if you said
*  it. You know, there's base models and there's based models with a D, right? Like, what kind of
*  model do you want your kid to interact with? And what do you want them to learn over time? And,
*  you know, how does that get selected? And who adjudicates what that selection process is?
*  And so I do think there's a lot of these really interesting things that are coming because your
*  RLHF something and who's that cohort of people who's training the thing that are providing the
*  human feedback? And how do you select who those people are? Or what's the ethical framework
*  based on your location around the world that should be applied or shouldn't be applied,
*  right? Should the Western viewpoint be applied to somebody in another country that may have very
*  different values and mores relative to the model and its output? And so I think there's lots and
*  lots and lots of interesting questions here. You know, I think it's useful to try to imagine
*  the interactions we have with agents in a few different ways, right? And so, like a lot of
*  saying, like your kid or you, like today, we are at the mercy of a bunch of algorithms that control
*  our information flow, right? And we can lightly curate them by swiping correctly on TikTok or
*  Twitter or whatever. But if you can instruct your bot more directly for yourself or your kids or
*  whatever, like that's quite interesting. I think like a fun interaction to imagine is in like,
*  think about the enterprise side, you have different influences in different teams because
*  there are incentives for, for example, like compliance or security in an R&D team. I think
*  there's a simple version of that. That's a bot that's like an early warning system.
*  Like imagine in a fintech company, like, oh, you're like hitting these, you know,
*  these merchant network rules, like the thing that you're trying to do is like a definite no go.
*  But you can also imagine like a debate with that bot or a fight with it as an extension of like
*  that security champion or whatever. I think another really powerful one that I like just looking at
*  some of the examples of how people use like chatGDT and Co-Pilot is code generation,
*  right? Like we're not that far off from a, like, especially in areas where there's just so much
*  content online, like web development, junior web developer, like junior Python developer available
*  to everyone, right? Not like complete my code, which requires a bunch of previous knowledge, but
*  write to a file, run code, like deploy to the cloud, use APIs, like that is really powerful.
*  And so I think, I think there's like, you know, I think of it as like there's new capabilities,
*  right? That are like thought of as human capabilities. There's like interactions
*  where I actually have to negotiate. And then there's like the things that I can control
*  that are like personal. So I think we're going to have a lot of really weird interactions with
*  agents. How does that sort of expectation of weirdness change how you guys are thinking about
*  your role as investors or the investment decisions that you're making? I would imagine that like,
*  it would shift you more toward team relative to like current product, for example, but I'm
*  wondering kind of what shifts you're finding compared to previous, you know, cohorts of
*  companies. You know, it's interesting. I think it was Chris Dixon who said that the next great
*  company starts off looking like a toy. And I think that's true, both on consumer, that's true with
*  crypto, that was true with that with certain types of enterprise. And so I don't think it changes
*  that much. I think the really weird stuff is often the most interesting stuff. And then there's going
*  to be the standard stuff that you just know is going to work, right. And I think it's going to
*  be that same mix. I think social products in general tend to be weirder in terms of the things
*  that actually work, or at least the behaviors tend to break with other affordances, kind of
*  generationally, you know, snap, we're going to make every image disappear. And obviously, that
*  product morphed quite a bit over time. But at the time, everybody's like, what are they doing? You
*  know, that's so weird. My senses are just like Evan taking selfies of himself, and then they would
*  disappear. And that was the whole network for a while, you know. So I think that I think behavior
*  will always start off seeming strange. I tend to be and you know, Sarah and I don't have any like
*  formal business relationship, right? We just like collaborating on stuff and have a podcast together
*  and stuff. So I'm speaking for myself only about like, I tend to be very much like a market driven
*  investor, not a team driven investor, I should say the team is incredibly important, right? I've
*  started two companies myself. So if I didn't think teams are important, you know, I never would have
*  started a company. But I think the markets are more important, or the product market is an
*  important thing. And so often what I look for is like, what are early signs of product market?
*  And then do I think that's an do I think it's in a big town? Do I think the team is great? Do I think
*  there's defensibilities or why now statement, you know, there's all these other things around it. But
*  you know, fundamentally, I've always looked at as product market. And the question is, if something
*  is really weird, how can you tell if the product market is there? And I think almost every great
*  startup has to be non obvious, because if it was obvious, everybody, everybody would already be
*  doing it. Right? So definition of these things have to be somehow offer, there has to be some
*  hurdle to overcome. Otherwise, it's not defensible. I think it's kind of funny that some number of
*  months ago, a lot couldn't convince anybody to start an open AI competitor. And now he probably
*  can't convince anybody because they're like, oh, they're too far ahead. It's too big of an incumbent.
*  So it is like a really interesting pacing related to the I think one one big mistake investors make
*  is they are, they're just kind of blind based on like their current view of the world, right? Like,
*  it's very easy to project your existing view of where the value is, especially if you like are
*  very focused on the more sophisticated customer. And you take that point of view, and then you
*  don't see like the actual demand, which might start with people who like don't have access to
*  something or where like their use case is less sophisticated. And so I think it's like really
*  easy to see this in the media space. So like, if you look at something like illustration,
*  right, there's like, there's this view of like, oh, like, you know, it's never going to be good
*  enough to like make picture books or like do coke ads. And like, pretty sure directionally,
*  we are going to get there like sooner rather than later. But if you if you take that point of view,
*  like, it's not gonna work for AAA games, right? Or it's not going to work for like, people who
*  need Super Bowl quality video, or? Yeah, but I wouldn't like, you know, like use that in my
*  production code base, like you're just gonna miss a lot of like, well, what are people actually
*  using it for? And directionally, where are we going? Yeah, I think people also over index on
*  defensibility related to that. And so everybody at the beginning of a company asked too many
*  questions around how does this become defensible? How is this defensible now? And can't people just
*  build it because two people built it in six months. And that's sort of like every SaaS company.
*  Right? What was defensible about retool in the early days or notion in the early days or sort
*  of choose your startup in the early days. And in the very early days, nothing was defensible,
*  right? It took two people three months to build the thing, you know. And so I think that's kind
*  of similar here where there's a lot of questions around, okay, what's a defensible business model?
*  And you want to have defensibility over time. Absolutely. And if you look at it traditionally,
*  there's all sorts of ways to do that either in terms of platform effects or certain aspects of
*  sales or certain aspects of, you know, integrations or other things that you do over time. But
*  fundamentally, I think, for network effects, right, there's all sorts of forms of defensibility
*  remotes. But I think I think people really early tend to ask almost too much of the thing. And the
*  real question is, does anybody care? And is anybody using it? And then I think later, it becomes,
*  okay, now that people are using it, how does it become defensible and not a commodity? And how
*  does it scale? And how much does it scale? You know, is this an end of one company or product?
*  So what trends are you guys seeing in, like, usage data? I feel like right now, everything has a
*  wait list. The wait lists, some of them are moving, some of them are not moving. This feels like a
*  moment probably where like, everybody can post good sign up numbers. But I would guess retention
*  probably varies widely in the deal flow that you're seeing. I'd love to kind of get a sense for
*  the trends that you're seeing there. My favorite wait list example of all times was this early
*  AI company. I'm not going to name which one it was. It was like 10 years ago. And the founders of the
*  company claimed it was an AI company. But in reality, they had a bunch of ops people like
*  answering queries in the background. And the co-founder of a very well known large tech company
*  went on to it. And anytime we go on, they'd ping all the ops people and they'd all jump on and
*  answer all the queries really fast for that one person. If they end up getting bought by this
*  like major tech company, and it was completely false, like it really wasn't working the way that
*  they were claiming it was. And they always were in private alpha. And they'd say, oh, we just, you
*  know, so there's so much demand and look at this giant wait list and all this other stuff. And they
*  never actually like really launched and they got bought for a bunch of money. And so I feel like
*  often these infinitely closed wait lists are kind of a negative sign that the traction may not be
*  real. Now, sometimes it's a real sign of demand. And there's some scalability issue in the background,
*  or they want to test it and all the rest of it. But I think if you have such raw organic adoption,
*  you know, usually you just open the thing up because you know, more and more people join
*  unless again, there's some constraint that prevents you from doing it. I think in general,
*  the last decade has taught people some wrong lessons on how long they should take before
*  launching a product. And people point to figma, or they point to notion, or they point to other
*  companies where there was a longer period of time for development. And if you talk to the CEOs of
*  those companies and say, I wish it was faster, we should have done certain things faster. Hey,
*  it didn't work the first time. So we changed it and it worked the second time. But we tried,
*  you know, we tried actually to get people fast. And so I think there's this whole like bespoke
*  artisanal movement. Or similarly, one company I'm involved with was doing hand onboarding of every
*  company superhuman style. And eventually one of their customers said, Why are you getting in the
*  way of your customers? I just want to sign up and use the thing. Why are you onboarding me?
*  And so they stopped doing it, and they had a spike in usage. And so in general, I think you want to
*  get out of the way of your users. And that means, you know, you don't necessarily need a waitlist,
*  unless there's very specific reasons behind it, or you really need to test certain things. But
*  after you've tested things enough, if you keep having a waitlist two years later, it means the
*  thing isn't working. Of the companies that you guys are taking a look at, how many of them seem
*  to have sustaining usage versus kind of that surge of interest that, you know, if you give it a month,
*  already starts to look like it's tailing off. It's some tiny percentage, right? But that's kind of
*  like the point of venture is there's like, it's all about the tail of companies. It is not like
*  your average company in the market. There's a big hype cycle in the market right now.
*  And I think it's really, it's like very, it's very easy to feel smart by being cynical and
*  dismissive in venture and investing in general. And like, this is totally useless. You want to
*  be intellectually honest. But like, if that's your orientation, like, don't be an investor in startups
*  that are generally weird ideas. Like, what I'm looking for, is there any real data at all?
*  Because you're trying to invest in the outliers. The outliers right now are insane. Right? Like,
*  I know a founder in the, you know, many, many millions of revenue that was like, ah, you know,
*  like, I'm dealing with some sort of cash flow issue, like GPUs or SVB or something. And he like
*  removed some part of the free tier of his product and revenue went up a multiple. Right? And I'm
*  like, that is some pretty impressive demand. Like, that's not fake when there are consumers who are
*  paying that much for the product. And so I think the most exciting thing right now is that there
*  are capabilities that consumers and enterprises like get that much value from where, you know,
*  one could argue that this, this company that is doing this much revenue hasn't played any of the
*  like good growth games or good product management games that like companies like they play act at,
*  right? Like, oh, I'm going to do hand onboarding because the good company did that. Or I'm going
*  to have this like wait list with the sexy brand companies like in first, because like that's what
*  the best companies did. But the real thing you're trying to figure out is like, can I, can I make
*  something that just creates so much of its own demand and like nothing else is important. Right?
*  And so like, yeah, like the hype cycle is useful for fundraising. But if your investors know what
*  the data should look like, then they're not going to buy it. I think it's especially easy to generate
*  like that sort of waitlist activity right now, because a lot of mention like this,
*  the seven deadly sins, but like greed, like social signaling, like fun, fear, like people feel all of
*  these things about AI right now. And it's very novel. But anybody who's worked on these products
*  understands like the distance between demo and product is very large. And so there are a huge
*  number of companies that have these massive wait lists, because it like looks really cool as an
*  idea, and then it doesn't actually work. Right? Or, you know, people thought they wanted it,
*  but they don't. And so like, that's the whole game of trying to understand like, you know,
*  when I talk to a company that's actually got a reasonable waitlist, like the first question I ask
*  is just like, well, like, what would happen if you gave everyone access? What is blocking real usage
*  growth? And often the answer is like, oh, we know that those are like garbage users anyway. Right?
*  So like, why, you know, don't project that. But the thing I get excited about is like,
*  you know, in the tail, there is usage that is unlike anything I've seen in the last decade plus.
*  I think there's also like a founder perspective on this, which is when should you raise money
*  versus just bootstrap? And I think all too often people get on the venture train,
*  and they could just bootstrap. You know, if the thing is just growing organically really
*  rapidly, and it's spinning off tons of cash, just go for it, you know, in some cases.
*  And then secondly, in some cases, you know, that you're going to have something that goes viral,
*  a bunch of people pay for it, and then it dies off. And that happened in prior social waves,
*  for example, right, like all the social gaming companies, and people made real mistakes by
*  raising tons of money, and then having to play the venture game on those things and blowing up their
*  companies instead of saying, I'm just going to dividend out cash, and it'll last for a year,
*  and I'll make a bunch of money off of it, and I'll move on to the next thing. And in that way,
*  people got stuck for four or five years working on something that was never going to work because
*  they had that initial burst. And you see that with some of the like, social mobile apps that
*  are using like, stable diffusion, was like an underlying thing. And some of them have ramped
*  to, you know, $200 million of revenue in nine months, and then they die off really fast.
*  And some of those companies probably would have been better served just running it off of cash
*  and distributing cash to themselves instead of like raising money. So I think as a founder,
*  you should also think through like, is the right thing for you to raise external capital? And
*  in many cases, the answer may be no, right? If you can avoid it, why would you do it?
*  How are you seeing the use of funds kind of shifting? Because it's kind of a trope at this
*  point to say like, you know, you can probably get by without your like, social media manager,
*  or you know, you can like semi automate recruiting in ways you couldn't in the past. And so you don't
*  need as much headcount as you used to. Arvin from Perplexity said that on the show, in fact. But then
*  on the flip side, like there are like, foundation model costs, I feel like I see some companies that
*  are like, basically taking the investor checks and like turning around and spending them on open AI.
*  So how are you seeing I mean, and some of the checks are pretty big, right? They definitely are.
*  Not everybody is following that like bootstrap, if you can advice, people are grabbing the grabbing
*  the eight figures. Yeah, most people aren't. And I'm not saying most people should. Yeah, I'm just
*  saying like, it's another path. And people always forget that it's another path. You know, there's
*  a lot of companies, I think that have raised like $15 million to build a model, when they should
*  have just gone on GPT four. And they would have had the same rough outcome. And you know, they
*  could have done some prompt engineering or something. And so I do think there's a lot of people
*  who kind of went down the wrong path. And there's a subset of use cases where maybe the model really,
*  really matters. And that could either be specific vertical use cases, maybe certain types of health
*  care, we have certain unique proprietary data sets you want. It could be if you're really training
*  for specific interaction modalities or applications. But and then, you know, obviously,
*  there's a big price differential if you're training a diffusion model versus if you're training
*  transformer based model, right? You're talking about something that may cost hundreds of thousands
*  or millions of dollars instead of tens of millions of dollars, depending on what you're doing. So I
*  think it also depends on you doing things in image and video, or you're doing things in text.
*  Because you guys are seeing so many things, I think you're, you know, be particularly curious
*  about your answer on cool, what are the coolest products, the most useful products, the most,
*  you know, interesting, you know, glimpses into future paradigms or interfaces that you would
*  say, you know, and especially if they don't have a waitlist that you think people should go check
*  out. For your I mean, for your average consumer, like I think the list starts by being very simple,
*  right? A lot of the incumbents have like very nice magical features now. And incumbent is a broad
*  word. But like, I do think that the things that Canva Adobe Figma have shipped are like really
*  useful and cool. Everybody should try chat GPT. I don't know that one of these services is public
*  yet. But, you know, just because it's the bane of my existence, like rich contextual email completion
*  is going to be here very, very quickly. And I think it's like in in waitlist beta. And like,
*  you know, this is meme about like, oh, like somebody is gonna like, make your email longer,
*  and another agent is going to make it shorter. And like, there's gonna be this adversarial
*  interaction between the email agents. But I do think that like, being able to do drafted responses
*  to everything in your inbox is one way to resolve this stupid issue. I think those are those are
*  some of the fun ones. And on the on the consumer stuff, like character and the other like,
*  sort of bought parasocial interactions, I think are great. I think the agent stuff is probably too
*  immature for your average consumer to have a good interaction with it. But I think we're less than
*  six months away from like bots that actually do it for you. You know, I think there's all sorts of
*  cool things happening right now. I think some of the dubbing things feel really magical. Like if
*  you play around with something like easy dubs, and you just drop in a video and it tries to capture
*  like the tonality of the voice of the person as it translates them into Spanish and stuff like that,
*  or from Spanish and English, whatever languages you want to do, I'm still waiting for them to
*  add Hebrew, which is why I'm not a power user yet. So I translate all my content into Hebrew.
*  I'm just kidding about that small audience. But I think there's lots of magical things to come
*  or things that feel magical. And I think it's kind of interesting. I feel like, for example,
*  auto GPT, you know, got a ton of attention. But for anybody who is in the AI community is kind
*  of the obvious thing that was going to happen, or some form of it was going to happen. And so I
*  feel like there's a lot of things that are coming. It's back to the old saying that the future is
*  here is just not equally distributed. And I think there's a lot of things that a lot of people have
*  been thinking about or realizing is going to be really cool or, you know, they built demos of that
*  are going to start hitting broader audiences reasonably soon. And I think some of those things
*  are just going to be really magical, you know, it's just going to be kind of amazing how these
*  things work. So another kind of bit of the future that's starting to take shape is the
*  Neuralink implants, which they've, you know, taken as far as the great apes.
*  Yeah, I do them. Well, then you've answered my question already, I was just going to
*  frame a hypothetical for you and say, let's imagine a near term future, where, say, a million people
*  have one of these things. And it's like broadly, you know, seem to be safe, like they're walking
*  around, you know, doing okay. We're a couple thousand dead monkeys away from that man. But
*  I'm excited to imagine it. Yeah, we're not quite there. So anyway, would you guys be interested
*  in getting one and being able to interface directly with the computing world with your thoughts?
*  Yeah, of course. Right. I think like that's a that's an easy yes. But I have a house full of
*  Gen one, you know, broken consumer hardware. And like here is one we're probably not going to be an
*  alpha tester. But if you just think of it, like actually looked, I've looked at a series of
*  companies around this, like, let's say, like, it's a it's a Nick for your for your brain,
*  right. And like, there's a whole bunch of things that are still immature from a technology
*  perspective. But I think it's very difficult to not imagine that we'd want communication bandwidth
*  to be higher with, like all of our devices and everyone else. And it's also hard for me to
*  imagine that if like, as a as a like, as an input mechanism for you can do, like knowledge capture
*  in this way, and it's an advantage for people, which it will be that it won't become very popular
*  works. Yeah, I'm very skeptical on timeframe for this kind of stuff. So we'll see. I think I think
*  our understanding of the brain is so de minimis that, you know, with the exception of a handful
*  of systems that are easy to interrogate, like the, you know, visual system and things like that,
*  it's actually we are I think, the depth by which we understand how most of the stuff works is
*  really shallow. And most of the deep brain stimulation stuff, which Neuralink is based on,
*  has really been for treatments of things like depression or a few other diseases.
*  So I'm quite skeptical about it, but we'll see. At least anytime soon. And by soon, I mean,
*  five, 10 years even. That might be the most bearish take we've had on on the Neuralink question.
*  Should talk to neuroscientists.
*  So last one's a classic big, big picture zoom out, you know, we're and I feel like we're just
*  seeing this wave starting to build. It's coming right for us. What are your biggest hopes for and
*  fears for society at large, as this, you know, AI wave washes over us?
*  Let's say so on hopes, I feel like we actually talked about a lot of this stuff, right? I think
*  if you're, if you're open minded, like, it's just a really amazing wealth capabilities. And there's
*  actually, I forget the name of the paper, maybe we can look it up and put in the show notes. But
*  what's interesting is, like the, a lot of the enabling technologies today, they help people
*  with a lower skill base more than with a higher skill base, which makes sense, right? Like if you
*  think about the, the training set of like, if it is code or writing or music generation, any, like,
*  if you're, if you're training off the entire set, you're going to help people with the like,
*  minimum of these skills or no skills more than like the highest set of skills. And so I think,
*  I think it's just quite interesting from a democratization perspective.
*  So this technology is going to help me but not Sarah.
*  It's very sweet a lot. I think we're both screwed. Maybe I'm going to get so mad at myself.
*  I think we're both screwed. Maybe I'm going to get speared for saying this, but I do think like,
*  not understanding that alignment and safety research is deeply tied to capability research
*  is challenging, right? If, if like, people don't understand that, policy makers don't understand
*  that. And so I certainly think that should be like a broad democratic conversation. But like,
*  I think that's, there's a version of the world that, you know, we halt a lot of this progress,
*  or there's regulatory capture of a lot of the technologies, like before we really figure out,
*  like, what they can do, which I think is going to be pretty problematic. I think there's obviously
*  going to be nefarious, like, actors that use all these technologies for different things. But we
*  build defensive technologies against that, just like we have in the past. You know, I'm a little
*  bit nervous about, everybody wants like the best opportunity for their kids and for them to like,
*  grow up like well adjusted and like able to go like, you know, be useful to the world and feel
*  good about themselves, right? I actually don't know what to do about that. And like this current
*  environment, this unstable ground, like, what do I teach them? How should they interact with
*  technology? Right? Do I want them to be like, really good prompt engineers? Or do I want them
*  to like, go to Waldorf and like, not interact with tech? I don't know. And I think like, very smart
*  people have different takes on this. But that's one thing that concerns me personally.
*  Yeah, I guess on my side, like I'm short term and by short term, I mean, next five, 10 years,
*  very optimistic about what all this means globally in terms of, you know, you have that chart of all
*  the things that go up in price over time, which is like education and healthcare and all these things,
*  and all the things that go down. And I think this is one of the few technologies that may actually
*  help address those things that have become incredibly expensive in part due to regulatory
*  capture. So in the short run, I'm incredibly optimistic about the global implications of this
*  technology to health education and other areas. And in the long run, and by long run, I mean,
*  a few decades, I'm a huge doomer in terms of eventual species competition with AI or AGI.
*  I think the biggest short term risk to the area in some sense, actually, is regulation. I think
*  there's a very one sided call right now to regulate these things in part because incumbents have an
*  incentive to say that because they want to do regulatory capture on the models and prevent new
*  entrants from coming in some cases. And in some cases, they have specific concerns. But I feel
*  like there is some chance, maybe it's a one in five chance or something that with this next
*  election, we're basically going into the first AI driven election, we're going to see ad copy
*  and targeting campaigns and robo dialing with real sounding voices and all this stuff going
*  into the presidential election. And I think there's a lot of potential for that to turn
*  into a giant regulatory storm, depending on who wins or loses. Just like, you know, when Trump
*  won, there was a giant backlash against social companies who were blamed for that, that win.
*  I think similarly with this presidential election, AI may be blamed for all sorts of things that it
*  may not have really impacted that much. But that may be the moment that it starts to get regulated.
*  And if you look at, and I think there's certain types of regulation that makes sense, like,
*  I don't think we should, we should have like export controls on advanced chips and you know,
*  stuff like that. Maybe there's some NIST style, you know, approach. But I think most of the
*  regulation tends to distort markets in really bad ways, and tends to really kill innovation and
*  tends to lock in incumbents in bad ways. I think it's way too early to regulate the vast majority
*  of the things in this area. And I think all the calls I've heard have been very one sided to
*  regulate it. And I think those are, it's the wrong thing to do right now.
*  Cool. Well, thank you guys. This has been a lot of fun.
*  Thank you guys. Thanks for having us. Good to see you.
*  Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that
*  actually work customized across all platforms with a click of a button. I believe in Omniki
*  so much that I invested in it, and I recommend you use it too. Use Cogrev to get a 10% discount.
