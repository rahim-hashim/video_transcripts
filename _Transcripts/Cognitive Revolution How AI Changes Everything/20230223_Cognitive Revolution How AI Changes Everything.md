---
Date Generated: April 03, 2024
Transcription Model: whisper medium 20231117
Length: 1968s
Video Keywords: ['AI', 'A.I.', 'Artificial Intelligence', 'Chatgpt', 'Singularity']
Video Views: 797
Video Rating: None
---

# The AI Moment with Amjad Masad, Flo Crivello, Antonio Garcia Martinez, and Dan Romero
**Cognitive Revolution "How AI Changes Everything":** [February 23, 2023](https://www.youtube.com/watch?v=oQaA3WE2evM)
*  Today, we're sharing a special episode from the Moment of Zen podcast, which Eric co-hosts
*  with Antonio Garcia-Martinez, founder of Web3 growth metrics company Spindle, and Dan Romero,
*  founder of Farcaster, a sufficiently decentralized social network.
*  The guests for this episode were Amjad Massad, CEO of Replit, a leader in AI coding assistance
*  with its Ghostwriter and Ghostwriter Chat products, Blo Crevello, founder of Teamflow,
*  and myself.
*  We cut the original hour and a half discussion down to the parts that focus exclusively on
*  AI.
*  So in the next 30 minutes, you'll hear a mix of visionary and skeptical takes on short
*  and midterm AI impacts.
*  From the potential rise of the 1000x developer, to the question of what makes this AI moment
*  different from previous hype cycles, to analysis of which types of AI companies will prove
*  enduring, this is a fast-paced, wide-ranging discussion among some very smart people, all
*  of whom are grappling with AI developments in real time.
*  Enjoy.
*  The level of exponential improvement is so tight that, like, you could go to lunch and
*  come back and the world has changed.
*  Right.
*  So that's the singularity because you can't know what's next.
*  And then the sort of the laser branch of that view is that is that the most likely outcome
*  is death of humanity.
*  And the reason that's most likely outcome is because it is impossible to align a enormous
*  computing force that at the same time is sort of dumb.
*  It doesn't understand sort of human preferences.
*  And therefore, any goal that you give it is not going to be specific enough.
*  There are a lot of potential sort of attribution or explanation of that goal that gets you
*  in trouble.
*  Yeah, I call bullshit.
*  I think they're completely fucking full of it.
*  Sorry.
*  You know how in a lot of the sci-fi apocalypse literature that appeals to nerds, like, somehow
*  when literally the fucking world ends and there's no law and order and it's Mad Max,
*  the guys who make the computers work somehow end up running the show?
*  This is an expression of that fantasy.
*  The Cognitive Revolution podcast is supported by Omnikey.
*  Omnikey is an omnichannel creative generation platform that lets you launch hundreds of
*  thousands of ad iterations that actually work customized across all platforms with the click
*  of a button.
*  Omnikey combines generative AI and real-time advertising data to generate personalized
*  experiences at scale.
*  I think we're going to see a great convergence of a lot of different AI advances that suddenly
*  all come together and really make a tremendous impact on modern life.
*  And so calling it the Cognitive Revolution because I think the changes that we'll see
*  are going to be every bit as transformative as what we saw when we weren't here to see
*  it, but as our ancestors saw in the Agricultural Revolution and of course the Industrial Revolution.
*  Yeah, I totally agree that everything Nathan said.
*  I was grabbing Ginnir last night with an AI resculptor who described what we're going
*  through as what he calls the sealed great convergence.
*  So he says the first one was 2012 with the image development and deep learning and all
*  of AI turned into that.
*  The second one was transformers with the attention is only need people in 2017.
*  And then we're going through the third one since roughly 2022.
*  You could think of those convergences that's happening once every five years with large
*  language models.
*  So large language models, the chat dbt is the most famous example, they're really good
*  at manipulating languages, like really, really, really good.
*  It just turns out that they're so good at it that the moment you model out a task as
*  a language fast, which turns out to be a model of another task with a language task, it becomes
*  really good at that as well.
*  So we're starting to use large language models for things ranging from obviously you can
*  ask it questions, but it can also do a little bit of math.
*  We're starting to use it as a search engine.
*  We're starting to use it to code.
*  We're starting to use it in robotics as a sort of reasoning engine.
*  And so I think that like that alone makes AI dramatically underlined.
*  And I say that knowing full well how hype it is.
*  I think even if we start to progress and the discoveries that we've made right now, which
*  will not stop in the going exponential, if any, if we stop them right now, all of civilization,
*  I think, is going to be dramatically impacted in the next 10 years.
*  And then I think zooming out even further.
*  Yeah, I am I am more and more a believer of the AGI moment.
*  My timelines are compressing rapidly, meaning I actually believe that AGI is going to happen
*  sooner and sooner.
*  And my concerns are slowly increasing.
*  As a reminder of what AGI is, that recursive loop of self-improvement, AGI become better
*  and better, and so it ends up with the net 1 trillion.
*  I think that the steel man for it is that, you know, we and the reason why people are
*  so worried is that Moore's law means that there won't be just one AGI.
*  Moore's law means there will be a lot of AGI.
*  And so in the limit, anyone with a laptop has an AGI.
*  And now the risk that the AGI talks about is that it's impossible to align a single
*  AGI, let alone a million AGI.
*  So we need to align it. We need to do that impossible thing a million times.
*  Anyway, that's not to say that I think we should burn all the GPUs or whatnot, which
*  I think is what Yudkovsky may prescribe.
*  I just think it is something that is under discussed.
*  I think it is a real risk. And I just wish there was a lot more funding and attention
*  brought to this issue.
*  Yeah, so the steel man of the flow side of the argument, which is essentially like, I
*  think, Ilyasyr Yudkovsky is like the big, like the major sort of authority there.
*  And then a lot of now there's another guy, Paul Christiano, who's like an offshoot of
*  Leshron or the Yudkovsky.
*  But that sort of branch of AGI is going to kill us all is what started by Ilyasyr.
*  And the sort of main argument there is that if you accept the secular view that, you
*  know, humans have these meat computers, then there's no fundamental physical law that
*  says you can't build this meat computers in sort of Turing machines.
*  Right. So if you accept that, then you also accept that at some point we're going to
*  have human level AI.
*  If you accept that, that we're going to have human level AI, you also have to accept that
*  there's going to be an AI explosion.
*  So an AI takeoff event is basically when the AI comes online and trains the next
*  generation of AI and that next generation of AI creates the next generation of AI.
*  And that could start like a slow process over a year or two.
*  Actually, like, you know, people at OpenAI are already using GPT-4 to train GPT-5.
*  And so that's already in some way happening.
*  And that will shorten to milliseconds at some point.
*  And that's the Raycourse rules singularity, right, where the level of exponential
*  improvement is so tight that, like, you could go to lunch and come back and the world has
*  changed. Right. So that's the singularity because you can't know what's next.
*  And then the sort of the laser branch of that view is that the most likely outcome is
*  death of humanity.
*  And the reason that's most likely outcome is because it is impossible to align a
*  enormous computing force that at the same time is sort of dumb.
*  It doesn't understand sort of human preferences and therefore any goal that you give it
*  is not going to be specific enough.
*  And there are a lot of potential sort of attribution or explanation of that goal that
*  gets you in trouble. Yeah, I call bullshit.
*  I think they're completely fucking full of it.
*  Sorry. You know how in a lot of the sci-fi apocalypse literature that appeals to nerds,
*  like somehow when literally the fucking world ends and there's no law and order and it's
*  Mad Max, the guys who make the computers work somehow end up running the show.
*  This is an expression of that fantasy.
*  Right. That never mind like the weird Western obsession like the original robot was
*  coined in a play in which robots took over or the Golem legend in sign Jewish folklore
*  in which humanity creates a thing and that thing rebels.
*  There's always been this deep latent thing that that's going to happen.
*  But I think it's basically bullshit.
*  And not only that, the transhumanism is also bullshit.
*  You literally take any of Kurzweil's little spiels and like global reg X like replace
*  singularity with rapture and you get an evangelical sermon.
*  It's basically Christian eschatology expressed in scientific form.
*  They're just not aware of it because they don't actually read any religion.
*  That's what I think it is. And I don't think it's ever going to happen.
*  I don't doubt that the house cat theory, though, I.E. that like H.G. Wells time machine
*  thing where they have the Eloi and the Morlocks.
*  And it turns out we just become Eloi in which we're living in the service of it.
*  And the Morlocks are like machines or something else.
*  Maybe that happens. I think it's already happened in the sense that we get worked up
*  about these Twitter fights over nothing in which nothing happens.
*  I think fundamentally like people ascribe agency to two things like, you know, anyone
*  who has kids knows that like one of the first things that kids do when they grow
*  cognitively is they try they give names and they give personalities to their toys or
*  even to like simple things like boxes or whatever.
*  Humans have this tendency to ascribe agency.
*  I think people just extrapolate from this idea that we see some kind of glimpses of
*  agency in these things to the fact that these things can formulate abstract goals and
*  desires and go execute on them, which I don't think is entirely true.
*  Right. So the AI is ultimately a tool for humans to do things in the world.
*  Right. It's another like I think of Alhams are as another computer.
*  That's how I kind of build on top of Alhams.
*  We're doing a lot of things with Alhams at Replet.
*  It's my mental model for it.
*  It's a computer.
*  Right. And it's a very powerful new type of computer.
*  Let's have the intellectual honesty to say that we do not understand what consciousness
*  is and we don't understand the thing that really gives us agency.
*  But I think it's just a tool as it were right now.
*  I think we need some kind of science of agency, of consciousness before we're able to say
*  that we can build these things. To recruit enormous amount of value in the world requires
*  a lot of planning, a lot of emotions.
*  Just think about being an entrepreneur.
*  You've done it multiple times.
*  Just like how much convincing you have to do.
*  You have to have some kind of theory of mind.
*  You have to think what other people think.
*  And I'm not sure we can build that just yet.
*  So no AI girlfriends.
*  Like, you don't think that's a...
*  It won't look like it.
*  It might act like it.
*  It might fool some people.
*  ChatGPT is already fooling some people.
*  But that doesn't make it it.
*  And that doesn't get it to the level of power that kills us all.
*  What the Transformer model brought is a kind of generality.
*  So in a way, there's a generality jump here.
*  I think if you go back to the early era of AI,
*  they would probably think that the larger Irish models that we have today are some kind of AGI.
*  Because it's this boiling frogment phenomenon where slowly we're increasing generality.
*  There's not going to be any point of time where we're going to say,
*  ha, this is AGI.
*  I think every jump is going to be like a significant jump in generality,
*  but it's still going to feel somewhat slow.
*  So this creates a sort of a rising tide and makes everyone more productive,
*  makes software a lot easier to create.
*  Creating software used to mean learning all sorts of arcane knowledge.
*  And now you just have to write English to create a piece of software.
*  You can create a meaningful piece of software.
*  So now you take something that was the capability of expert software engineers
*  and you give it to everyone in the world.
*  And I think the impact of that is going to be A, usually deflationary.
*  B, is going to give people new superpowers.
*  I think new type of entrepreneurship is on the rise.
*  And we're seeing a lot of people that would have required companies and armies
*  of people around them to build something useful are able to do it on their own.
*  And I think we're going to see a new crop of winners and entrepreneurs and sort
*  of millionaires and billionaires coming out of this phenomenon.
*  And it's also like a fundamentally new way of working and automating things.
*  So would you teach your kids to code?
*  Yeah, I would teach my kids to code.
*  And the reason is because code is still going to be super relevant.
*  We have ways to generate more accurate code.
*  We're going to, we're coming up with a chat GPT like thing inside Replet.
*  And that uses a larger model and I'll give you more accurate code, but still
*  the accuracy is not going to be a hundred percent.
*  So you need to learn how to debug that code.
*  I think surprisingly, most programmers were spending most of their time reading
*  and understanding code.
*  Um, that's going to put pressure on tooling for, for debugging and comprehension.
*  And LLMs will help their LLMs can explain code for you, but I think there's
*  going to be more innovation and visualizing code, you know, other ways to
*  debug and comprehend code on the front end side of things, you're going to see
*  super productive front end coders that are heavily powered by code generation.
*  Like it might be the case that they don't actually code.
*  They're actually just like plumbing things together.
*  They're talking to all of the, a lot of different LLMs.
*  They're, uh, they're acting more like project managers and product
*  managers and actual programmers.
*  On a recent podcast, I called us the Steve Jobs black pill in the early
*  vision of, of, of computing.
*  Uh, we thought that everyone was going to be a programmer, right?
*  There wasn't this user programmer dichotomy.
*  And then like Steve jobs popularized end user, the idea of end users with
*  user interfaces, really lovely user interfaces.
*  And that became the dominant thing.
*  And most people are consumers of software as opposed to the creators.
*  I think the idea of software creation will come back.
*  I think there's going to be a lot more people wanting to create, uh, you
*  know, personal software and software for their business use case.
*  And there's going to be a lot of end user programming.
*  Those people were not, will not have to read code because they, the level of
*  accuracy needed is probably not a hundred percent optimization needed.
*  It's not like performance needs is not that high.
*  A lot of the code is going to be throw away code.
*  And so if you're like a professional, you probably don't have to learn to code.
*  Uh, but if you want to be sort of a low level programmer, I think that's still
*  going to be relevant, or if you want to be a front end engineer, you need to have
*  some knowledge of code, but maybe not that deep.
*  It feels like it's, it's going to make the 10 X engineer, a hundred X engineer
*  in the sense that there's still a base level of you need to be able to guide
*  it in the right direction.
*  It's a tool.
*  And so for the person who already has the skill level or the talent, it's
*  going to be a, um, you know, increasing the advantage.
*  Whereas for maybe the mediocre engineer, it doesn't really make a huge difference.
*  And, or maybe they just lose their job completely.
*  Like I'd be curious how you guys think about that.
*  I think of it as a, as a, as a rising pie, lifting all boats.
*  So I agree.
*  I think like the 10 X engineer is going to become a hundred X engineer.
*  I think the one X engineer may become a 10 X engineer.
*  And I think that's all your personal, the LAGM about is that a new step change.
*  I think folks who were not engineers before will become engineers and be able
*  to perform simple tasks at first and more and more complicated ones.
*  I don't think this is like a replacement dynamic, but it's also really worth
*  looking into Anthropics recent publication that they're calling constitution AI.
*  And it's kind of the next generation of reinforcement learning from human feedback.
*  They're now doing reinforcement learning from AI feedback.
*  I think it's interesting also figuring out, I'm not sure whether, uh,
*  AI is going to replace the code.
*  Like we'll got run models instead of running good, or whether it's
*  going to write the code.
*  Um, I do agree with Amjad that these models have a weakness right now, which
*  is that they suck at systematic thinking.
*  So for example, you can give them, uh, this, uh, a task of, Hey, ask this
*  date instead of having me go a day, month, year, have it go month, day, year.
*  Right.
*  And if you give it, uh, for example, GPT-3 will succeed at this task, something
*  like 99.8% of the time, but it will fail 0.2% of the time, um, which shows that
*  it is, it is succeeding and now they kind of understands the task, but it's not
*  thinking about the task in a systematic way.
*  So the other weakness of these models is that they cost a fortune to write.
*  Like they're very, very expensive.
*  And here again, most of it is going to be on your side.
*  It's always going to be more expensive to write, to use a large language model
*  to pass a date than it is to run a piece of code.
*  So I think we're like in this very interesting time right now, where like
*  nobody really knows how these things will shake out, but I think that again,
*  these AIs will learn how to use tools.
*  And I think that on some level, they will be small enough to discriminate, to
*  understand, Hey, is this a task that they expect to perform a lot?
*  Is this a path that I am performing a lot right now?
*  And is this a task that benefits from more systematic thinking?
*  If so, I'm going to write a piece of code to perform this task for me, because
*  it's going to be cheaper and more reliable and more systematic.
*  And you think that the model will know that, or is it the human guides it to
*  saying, okay, this is not a good use of the model?
*  I think there are ways to build systems that are either part of the model or
*  upstream of the model such that the model would, would in a way know that.
*  I actually think that the sort of engineering is like lagging way behind of
*  the capability. It's just, it's kind of frustrating to me because like I'm
*  working on a reflet working really hard to build some LLM into, into
*  replica capabilities. So we have the Ghost Rider product, but I feel like
*  we're all scratching the surface. Like there's so much to do.
*  I think tool usage is possible today.
*  It's possible to build a chat GPT that has a Python interpreter on the
*  side that has a search engine on the other side, but nobody's really built it.
*  So I think it is possible today to ask it a question like book me a flight and
*  it going to kind of Google whatever, and then maybe writing a program,
*  hitting an API and booking you a flight. I think that's totally possible today.
*  Bounties. And the reason why we started thinking about the world this way is
*  that I'm actually like instead of a crypto cannon, but the sovereign
*  individual had a description in it that talks about the sort of the future of
*  work in a way. And it talks about how AI crypto, so the future of the internet
*  would support this sort of world where people are less full-time employed.
*  They're more like freelancers. They're able to jump from work to work.
*  They're able to construct companies on the fly and kind of dissolve them right
*  after the work is done. And that's been the picture in my mind for a long time.
*  And I think for the first time, it's really possible. All these technologies are
*  maturing in a way that allows this new crop of entrepreneurs to be able to be
*  hyperproductive and be able to get things done super quickly and super cheaply.
*  You know, when we talk to younger programmers, like almost without fail,
*  they're ambitious no longer to join Microsoft or Facebook or whatever.
*  They want to build businesses. They want to make money.
*  They want to go into freelancing. They want to be like this free spirit.
*  They want to build a career that is like freedom maximizing.
*  And I think having the ability to use sort of an army of AI assistants
*  and being really powered, supercharged by this technology,
*  will give people amazing opportunities in the future.
*  Yeah, I think that just like the PC was a tool of sort of great individual
*  empowerment, I think you're right that AI is even more labor-oriented than individual.
*  I think like code let companies like WhatsApp sell for like 20 billion with
*  like 40 or 50 people. I think you're right.
*  I think we're going to see 1 billion, 10 billion, maybe 1 trillion dollar company
*  in a decade or so with perhaps one or two people.
*  I totally agree with that. Man, if you pay software engineers to buy the ticket,
*  I think you would see a lot fewer rest investors and you would actually see 10x
*  engineers making 10x the salary.
*  I think if you really believe in the 10x engineer, which they do,
*  I think you should see software engineers make 10 million dollars a year
*  at big companies and you don't see that.
*  And conversely, you see people who might call professional coffee
*  private builders who just rest invest and who make 500k a year.
*  So I'm very excited by the potential.
*  I think that's totally not going to work, by the way.
*  By the way, the bounty system is one of the parts of Web3 that totally doesn't fucking work.
*  There's entire companies that are based around bounties and those are for companies
*  that are based around paying someone a bounty to do a thing are always like the ones
*  that you have to like route around and somehow use the product without it.
*  I mean, think about it. Do you pay anybody in your company in bounties?
*  No. Would you would a 10x engineer who actually wants to make like generational wealth?
*  We're talking 100 million dollar exits, but they sit there and do basically
*  mechanical turks for coding all day or were they actually I mean, you're creating
*  an arbitrary binary duality between rest investors and people working like coding
*  chipmunks on bounties. Right.
*  But the reality is that most coders who make lots of wealth, it's neither one
*  nor the other. It's people who actually do work their asses off.
*  But it's with some sort of committed product in which they have an overarching
*  design ethos.
*  Google needs one hundred twenty thousand employees and most of them are
*  just like making lattes every day.
*  They're really good at making lattes.
*  But at a drop of the hat, they would need them and they would find them there.
*  And there's very low friction on using their labor and their talents.
*  Right. So it's a very rational behavior to sort of hoard talent.
*  It's sort of the billionaire that has all these assistants.
*  You're like, oh, they're just sitting around doing nothing.
*  But at the drop of the hat, when something important happens, he needs all that
*  labor and he can't really hire it from the market at large.
*  So any time technology reduces the cost of going to the market, you see us go into
*  the market more. Again, people had a lot more drivers and personal drivers before
*  Uber came around.
*  And now everyone has access to the market at a very low transaction cost.
*  And that's the same across the board.
*  Like anything that you use today that you find very useful, like DoorDash, people
*  used to have people that worked with them for them.
*  Like people had servants that were around all day just waiting for that one order of
*  the day to go get that.
*  And now you're able to go to the market and get that labor on demand on the fly.
*  Right. So I think bounty type systems and I think crypto as well could
*  allow us to work on some coordination problems in order to solve the transaction
*  cost so you can have like hundreds of coders at any given point working for you so
*  that you can focus on building like a billion dollar idea.
*  Right. So some way to pay people for their contribution, I think, is the ethical
*  thing to do. Like the idea that being able to pay people for the data that they
*  create is not a bad idea.
*  Like, you know, if we can trace the Wikipedia contributions on a character by
*  character or token by token level that gets fed into GBT and a hypothetical company
*  in the future that wants to do the right thing would assign some kind of hypothetical
*  value per token.
*  And they can just like pay out some revenue share to the authors of the of the data
*  that they were trained on or maybe the data that gets used in production for
*  people listening to this who want to join AI companies or want to invest in AI
*  companies. What are the kinds of AI companies that are going to be enduring
*  versus the kinds of companies that are going to be commodities and not capture a
*  lot of value?
*  I view three categories of companies that are created right now.
*  Right. There's like what they call a big model.
*  Right. So it's like as for big companies, I create these giant models.
*  Then there's the application layer on top of those and the application layer is
*  going to be made up. I'll just arbitrarily slice it as like horizontal applications
*  and vertical applications.
*  The mode for the large language models is going to be economies of scale, meaning
*  it costs a fortune to build large language models.
*  It's costing more and more money.
*  And I think GBT4 is going to cost of the order of call it a hundred mil to train
*  between the resource class and the computer.
*  It's very, very expensive, which is why OpenAI is raising all that money.
*  Plus the label to train it using RLHF as I'm just described.
*  So it's just very expensive to train, but that's a one-time cost.
*  And then the inference cost, meaning the cost that it costs to run the AI once
*  you've traded it is many orders of bank to go.
*  So again, if you think of a hundred million dollars to train the AI, running it
*  is more on the order of one cent.
*  I mean, you're right, Flo. We've already saw that with Google, for example.
*  Right. I mean, the reason why Google is as good as it is is not because the
*  AI is so amazing, although no doubt, no doubt it is because they have literally
*  the entire world typing what they want.
*  Right. It was always the data set.
*  It was never the actual algorithm.
*  Algorithms aren't particularly defensible.
*  Right. At the end of the day, AI isn't a product any more than linear regression
*  is, right? You actually have to apply it to something to create something that
*  someone will pay you for.
*  Right. And that's where I kind of don't quite get a little bit of the AI hype.
*  Right. It's like, where is the actual product?
*  If Google can't actually find a way to turn that into actual cash, and a lot of
*  these companies are actually basically thinly veiled, just prompt you eyes on
*  chat to be what is the actual product?
*  Right. For that kind is not expensive.
*  Production of text and production of music and production of images has not
*  been where the value lies.
*  You can hire folks on Fibio to do this thing.
*  You're not fired.
*  But like, you can hire folks to do these things just fine and you'll still not
*  be able to go anywhere.
*  Right. So the value is in the distribution.
*  So I think that if generative AI is going to change anything to the structure of
*  the industry is that anytime you make anything cheaper, its complements become
*  more valuable. So here we're making content cheaper.
*  Not that it was really necessary because it was all pretty cheap.
*  And so the complements, the content, which is distribution is going to become
*  more valuable. So I actually think that this is going to be great for TikTok and
*  YouTube and all of that.
*  All knowledge work will be automated in the next 20 years.
*  And so I think, again, code is the first one that we're seeing automated.
*  That's, I think, huge.
*  I think we're going to see a lot more come out in the next two years, which are
*  going to see action-oriented knowledge work that actually does stuff.
*  I think it's going to be automated pretty soon.
*  I expect support.
*  If it's going to be a pretty big block.
*  When you think about it, all the knowledge work here is, is it's a function that
*  sits in between a keyboard and a monitor.
*  And I think AI is going to be really good at approximating that function.
*  But just to be clear, you're saying that all knowledge will be replaced in 20
*  years. We've been hearing that for 20 years.
*  And in fact, if there's any bit of skepticism around AI, like, you know, AI
*  being at the, like the very pivot of like changing everything, I at least have been
*  hearing that since I've been in tech.
*  And if you go back even further back, Marvin Minsky in the 60s and 70s, he's
*  been saying the same thing, which is why I was sort of trying to quantify what is
*  the change that we're seeing?
*  Because again, there's clearly a trend line, like no doubt, obviously, AI and
*  automation have changed lots of things.
*  I'm not saying it hasn't been a big deal.
*  I'm just trying to understand if we actually are at some sort of clear, like real
*  inflection point, or are we continuing along the same trend line, which already, by
*  the way, I think is a big deal.
*  Right.
*  Like, I mean, what I cited, right, going from the Kernigan and Richies of the
*  world to Replet, there's been a big change, right?
*  Like I'm not trying to underwhelm it, but it's, it's, it's not quite AGI, Terminator
*  end of the world levels of change.
*  When something is not able to do a task, it just can't do the task.
*  But we're now hitting that moment where across very broad sets of tasks, the best
*  AIs are outperforming the average human.
*  They're not yet at the level of the expert human at any specific domain.
*  They can outperform employed college grads on very wide distributions of tasks to a
*  big bench, big bench is a big benchmark.
*  That, that they compared Palm to this like pool of, you know, kind of
*  software QA testers essentially, and AI won.
*  I don't know.
*  I like, this is the same discord I heard about when big blue defeated, you
*  know, Kasparov at chess.
*  I mean, it's the exact same feeling.
*  I mean, in times like this, right.
*  I think a lot, I think a lot of this is actually intellectual
*  narcissism, the part of humans who are, who are assigning a certain
*  anthropic value to computer's thinking.
*  And I think of the, the famous Dijkstra's quote, right?
*  Again, we've been debating these questions for decades before any of us were alive.
*  Right.
*  He was, and he commented that asking whether a computer can think is like asking
*  whether a submarine can swim, right?
*  It, it doesn't matter.
*  The point is that it does 40 knots and the human does one knot.
*  And so along that particular dimension, which is moving through the water, the
*  computer actually does do better than the human.
*  And when it comes to ranking ads or, you know, filtering through stack overflow
*  and coming up with a net result, clearly the computer does better, but that's
*  very different than saying that it's more intelligent and this causes a
*  crisis in the knowledge economy.
*  The generality of LLMs can't be understated.
*  Like for the first time they can learn your intent from just one example.
*  I can build Google translate Antonio in three seconds.
*  I'll just say English.
*  Hello, French.
*  Salut.
*  And then I can say English home and that'll continue the French word.
*  It's sort of like, that's pretty fricking amazing.
*  And that hasn't happened before in any time we have a jump in generality.
*  Like the last time was the Turing machine is sort of an enormous thing.
*  I think every app will get better.
*  And I think actually the biggest beneficiaries of this shift is going to be
*  sort of a growth stage startups.
*  And the reason is because you got distribution, but flow talking about
*  distribution.
*  So notion adding AI is much more interesting than a new sort of knowledge
*  management that's like based on that's like AI first.
*  So it's called bearish on AI first companies, usually bullish on AI
*  infrastructure companies.
*  So open AI or anyone really building deaf tools around prompts, prompt IDEs,
*  building fine tuning sort of technology.
*  Anyone who's who wants who are making it easier to build with transformer
*  models, that's going to be something that every company will buy because again,
*  I think it's a diffused technology similar to cloud.
*  Like every company will integrate this kind of technology into their.
*  So, you know, the financial sort of answer to your question is that if you
*  want to invest in it, probably do do another fang type strategy because I
*  think there's another set of S curve there.
*  Plus maybe invest in infrastructure, like Nvidia, whatever.
*  Then on the startup side, dev tools, AI intelligence layer, like open AI.
*  Those are sort of the beneficiaries and maybe the growth stage startups, early
*  growth stage like us or, or notion or things like that will benefit a lot from
*  this.
*  The cognitive revolution podcast is supported by Omnikey.
*  Omnikey is an omnichannel creative generation platform that lets you launch
*  hundreds of thousands of ad iterations that actually work customized across all
*  platforms with the click of a button.
*  Omnikey combines generative AI and real time advertising data to generate
*  personalized experiences at scale.
