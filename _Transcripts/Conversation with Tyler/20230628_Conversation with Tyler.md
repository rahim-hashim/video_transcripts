---
Date Generated: September 17, 2024
Transcription Model: whisper medium 20231117
Length: 3974s
Video Keywords: ['AI', 'Economics', 'Policy', 'Tech', 'Podcast']
Video Views: 5071
Video Rating: None
Video Description: In his second appearance, Reid Hoffman joined Tyler to talk everything AI: the optimal liability regime for LLMs, whether there’ll be autonomous money-making bots, which agency should regulate AI, how AI will affect the media ecosystem and the communication of ideas, what percentage of the American population will eschew it, how gaming will evolve, whether AI’s future will be open-source or proprietary, the binding constraint preventing the next big step in AI, which philosopher has risen in importance thanks to AI, what he’d ask a dolphin, what LLMs have taught him about friendship, how higher education will change, and more. They also discuss Sam Altman’s overlooked skill, the biggest cultural problem in America, the most underrated tech scene, and what he’ll do next.

Reid's podcast Possible is back this summer with a three-part miniseries called “AI and The Personal,” which launched on June 21st. Featured guests use AI, hardware, software and their own creativity to better people's daily lives. Subscribe to get the series: https://podcasts.apple.com/us/podcast/possible/id1677184070

Recorded May 9th, 2023

Transcript and links: https://conversationswithtyler.com/episodes/reid-hoffman-2/

Reid's latest book: https://www.impromptubook.com/

Stay connected:
Follow us on Twitter, IG, and Facebook: @cowenconvos
https://www.twitter.com/cowenconvos
https://www.facebook.com/cowenconvos
https://www.instagram.com/cowenconvos

https://conversationswithtyler.com

https://mercatus.org

Photo credit: David Yellen
---

# Reid Hoffman on the Possibilities of AI  Conversations with Tyler
**Conversation with Tyler:** [June 28, 2023](https://www.youtube.com/watch?v=qIvOjJsiSO8)
*  Hello everyone and welcome back to Conversations with Tyler.
*  Today I am literally sitting here with Reid Hoffman at Greylock.
*  Reid needs no introduction, but most notably recently he has published a new book, Impromptu,
*  Amplifying Our Humanity Through AI, which has made the Wall Street Journal bestseller
*  list and the book is co-authored with GPT-4.
*  Reid, welcome.
*  Always great to be here.
*  Let's try some GPT questions.
*  Over a 5 to 10 year time horizon, will the demand for lawyers go up or down?
*  In the U.S.
*  It's interesting.
*  I think it will go up.
*  Why up?
*  I think it will go up because I think the questions around sorting out who owns what
*  and so forth and the degree of kind of risk management and detailed legal contracts will
*  of the amplification that AI is as amplification intelligence.
*  And there's this all new class of entities, right, that will need legal treatment.
*  Exactly.
*  What's the optimal liability regime for LLMs?
*  So right now if I Google how to build a bomb, I build a bomb, I kill people, right, no one
*  can sue Google.
*  It's just my fault.
*  How will it work?
*  How should it work for LLMs?
*  That's an extremely good and precise question.
*  A classic Tyler.
*  And this is what the lawyers will be working on, right?
*  Yes, exactly.
*  I think that what you need to have is the LLMs have a certain responsibility to a training
*  set of safety, not infinite responsibility, but like part of when you said like what should
*  AI regulation ultimately be is to say there's a set of testing harnesses that you should
*  be like it should be difficult to get an LLM to help you make a bomb and not it may not
*  be impossible to do it.
*  My grandmother used to put me to sleep at night telling me stories about bomb making
*  and I couldn't remember the C4 recipe.
*  It would make my sleep so much better if you could, you know, like there may be ways to
*  hack this, but if you had an extensive test set within the test set the LLM maker should
*  be responsible outside the test set, I think it's the individual.
*  Will that mean no standard over time as jailbreaking knowledge spreads?
*  Well, I think jailbreaking knowledge will spread, but I think it's, you know, just
*  like cybersecurity and everything else, I think it's an arms race.
*  And so I think and part of what we'll do is we'll have AI hopefully more on the side
*  of angels than on on devils.
*  That's part of the reason I'm an advocate for acceleration, move fast, the future do
*  not pause because it's part of being more safe there.
*  And putting aside truly malicious acts like bomb making, where else should there be
*  liability on the LLM company?
*  Say it books a vacation for you to Hawaii that you didn't want to take and it's
*  non-refundable, should you be able to do some tiny civil suit and get your money back
*  from the AI company?
*  I think, look, I think there's some degree of where we need to have some categorization
*  or regime of where are you relying on it?
*  But I actually think that the provider of the LLM should have it be like it should be
*  pretty reliable that it doesn't book the vacation without confirming with you.
*  Like that kind of thing should be totally within their doable skill set.
*  And so they should be accountable.
*  But say there's some volatility to plugins because you want a fairly creative AI and
*  you don't have enough money to afford it, you know, a reliable AI to book your trips
*  and then a creative AI to tell you bedtime stories and you use one thing for whatever
*  reason or you get confused.
*  Well, I think if it's you're confused because you're using just like you're confused
*  about hitting the submit button, then I think it's your responsibility.
*  But I do think that the the developers of these and the things that are the things
*  where they are much better at providing the safety for individuals than the individuals,
*  then they should be liable because that's that's part of what will cause them to make
*  sure that they're doing that.
*  Will there be autonomous AI LLM or bot agents that earn money?
*  Depends on what you mean by autonomous.
*  No one owns them. Maybe you created it, but you set it free into the wild.
*  It's a charitable gift.
*  It'll do amazing proofreading for anyone.
*  Gratis.
*  I think autonomy is one of the lines that I think we have to cross carefully.
*  So it's possible that there will be such autonomous eyes, but it's one of the areas
*  like self-improving code, autonomy are areas that I pay a lot of attention to.
*  Because right now, I'm, as you know, a huge advocate of its amplifying human
*  capabilities and being a personal AI, being a a copilot to the to the stuff that we're
*  doing. And I think that is amazing.
*  And we should just do when you make it autonomous.
*  You have to be much more careful about what its possible side, like what other
*  implications might happen.
*  And so let's put aside destroying the world and killing people.
*  It's a bother. Tell stories.
*  It gives you comments on your papers.
*  It does useful things, but someone could even sell it to a shell corporation.
*  The corporation goes under.
*  No one owns the bot.
*  Right.
*  Like you can't actually stop autonomy, it seems to me.
*  So it will happen.
*  Look, I think to some degree, you know, one of the earliest regulations we'll see is
*  that every AI has to essentially be provisionally owned and governed by some person.
*  You know, and I think that so there will be some kind of accountability chain, like if
*  you're using it for cyber hacking and so we say, I didn't use it like that bot was doing
*  marketing, but that bot was doing cyber hacking, but I wasn't me.
*  It's like, well, but you were the person who was responsible for it.
*  There's always a thinly capitalized corporation.
*  Again, I'm talking about positive productive bots.
*  Yeah, but it will be autonomous.
*  But like, for example, today, corporations have to have owners have to have boards of
*  directors. There is human accountability there.
*  So but you die and test it.
*  The company goes bankrupt.
*  You give it away.
*  It comes from Estonia.
*  You can't trace it.
*  Something's encrypted.
*  It just seems to me there'll be a lot of bots.
*  They'll reproduce for Darwinian reasons.
*  And we have to face questions about them, even if we'd like to ban them.
*  Look, I do think raising the question is good.
*  I'm not trying to resist the question.
*  What I am saying is I think that our that developer and I do think it's totally like
*  you can hash it with Bitcoin.
*  They can earn money, you know, run things themselves.
*  I think there's various ways that you could get a self perpetuating bot process even on
*  today's bots, which aren't really creatures.
*  They're more tools.
*  Right.
*  You could set up the tool to do that.
*  Totally doable.
*  What I am saying is we as a human society, human tribe shouldn't necessarily ascribe
*  any legal rights to that.
*  We shouldn't necessarily allow autonomous bots, you know, functioning because that would
*  be something that currently has uncertain safety factors.
*  And I'm not going to the existential risk, just even cyber hacking and other kinds of
*  things.
*  So it's kind of it's a yes, it's totally technically doable.
*  But what we should venture into that space with some care.
*  What we wanted is tax their income.
*  Otherwise, their arbitrage against labor, which might pay 40 percent tax.
*  The bot pays nothing.
*  It's not a legal entity.
*  You'd rather legalize it, tax it, regulate it.
*  Some government will do that.
*  Yes.
*  Even if ours doesn't.
*  Well, I also I think, you know, even if you say, well, it's a bankrupt company, but the
*  bots earning money, then the company's earning money.
*  We do have tax regimes or companies.
*  So I think there is there is things, but I think we would want to do that.
*  But I also think you want to like, for example, self evolving without any eyes on it
*  strikes me as another thing that you should be super careful about, you know, letting
*  into the wild.
*  And matter of fact, I think at the moment, if someone had said, hey, there's a self
*  evolving bot that someone let in the wild, I would say we should go capture it or kill
*  it right today because we don't know what the surfaces are.
*  Right.
*  So that's like I think one of the things that will be interesting about these bots in the
*  wild.
*  Will bots rescue the demand for crypto?
*  What else will they use for money?
*  Right.
*  Yeah.
*  Well, I think that that's part of the like one of the talks I gave on crypto 10 years
*  ago was even without these LLMs, I could set up a bot that could pay itself could pay
*  its its server fees and everything else in crypto and then write, you know, eulogies
*  or praise to Reid Hoffman for all time.
*  You know, just as an entertaining, like autonomous bot.
*  Exactly who or what in government should regulate LLMs, new AI products.
*  People say government regulation, but like where is it?
*  The FTC, Department of Commerce, National Security Establishment.
*  Well, I think since AI is going to transform every agency, I think there will actually
*  be needs in each of the departments.
*  Right now, because I think Secretary Raimondo is is a is super smart, capable leader and
*  understands the tech reasonably well.
*  I would go with commerce and there's NIST and a bunch of other things.
*  I do think also some attention to national security, all Jake Sullivan, you know, there's
*  all US context I think is useful to part of I've talked with both of them.
*  Part of my recommendation to them has been that we will there are so many better things
*  in the future, including safety, including alignment with human interest, that the slow
*  down narrative is is is is actually dangerous, that the that the narrative is actually much
*  better to say, which things do we want me to protect against, eg AI in the hand of bad
*  human being, bad actors is the thing to pay attention to.
*  Will the new AI product strengthen the executive branch in the US government?
*  Huh?
*  Since there's national security issues again, even if you're not a doomsday, there's clearly
*  issues. And it seems when national security issues come to the forefront, the executive
*  branch has more power, whether one likes that or not.
*  Well, look, there's reasons why we have an executive branch.
*  There's a reason why in many countries, the executive functions even stronger, even
*  including parliamentary systems, because it kind of aligns the executive with a the
*  parliamentary branch.
*  I do think that the general rise of technology should make the executive branch stronger
*  in various ways. Like one of the things I've been advocating for over years, we need to
*  have a secretary of technology, not just a CTO, because if technology is a drumbeat of
*  industries and a bunch of other things, you know, having that be a first class citizen
*  where you're doing strategy and everything else around, I think is really important.
*  So I think the short answer is yes.
*  But in our system, it's a little incoherent.
*  It's a little incoherent.
*  Let's say you have a coalition system like on the continent with proportional
*  representation desert and you have a governmental AI.
*  Does every party in the coalition have the ability to access it?
*  I think that would be a good thing.
*  I do think that part of the reason why I helped stand up open AI was on the board for a
*  number of years is broadly provisioning safe AI to as much of humanity as many
*  businesses as possible, including as many political parties and all the rest is, I
*  think, a good thing.
*  Amplification.
*  But you'll have some parts that won't be open, right?
*  Yeah. Well, because you have to do safety.
*  Like, so, for example, everyone's like going, well, that we thought open met open
*  source. No, no, open access with safety provisions.
*  Open source is actually not safe.
*  It's less safe.
*  So you're a small party in Northern Ireland.
*  You're part of a coalition government, right?
*  In London, you can just tap into the world's strongest computational power.
*  No risk of Chinese bribing people in this small party.
*  Can you use the AI to run your campaign to be reelected in Northern Ireland?
*  You have to give access to the opposition party.
*  Like what within government rations access to the really powerful stuff that's not just
*  open to the public?
*  Which branch of government should do that?
*  Which standards?
*  Yeah. Well, clearly the notion to reinforce one particular party like we try to make the
*  parties as is equally armed as possible for a democratic purpose.
*  Right.
*  You would want to do that.
*  So you wouldn't say you have unique access for doing this.
*  It'd have to be equally capable, whether or not it's equally intelligently used is a
*  different question, but equally capable across it.
*  I do think that the the general speaking, like part of the reason why I kind of deeply
*  share the open air mission is to say, how do we provide beneficial AI to as many
*  individual human beings and as many organizations and as many institutions as we can
*  is, I think, a really good thing.
*  What does the media ecosystem look like in this world?
*  So let's say a lot of people, rather than reading the New York Times or going to Twitter,
*  they just ask their AI, read it for me, tell me what's new.
*  It seems there's another layer of disintermediation.
*  Or is it like BuzzFeed where people what want that?
*  It will just go under and will more or less be back to the universe we have now.
*  Well, I think. The AI personal assistant for everything you do is, I think,
*  upon us. Sure. It's part of the reason why, as you know, with Mustafa Silliman, I
*  launched a product last week called Pi with inflection, which is a personal AI for
*  your life. And I think that will true for every professional activity.
*  And so I think processing information, I think part of when you say, well, AI can
*  be used for cyber attacks.
*  Well, I can also be used for defense.
*  It could be integrated in your mail system saying, hey, that looks like it integrated
*  your phone saying, oh, this sounds like it's your child calling for money, but you
*  should check on a phishing system.
*  So the defense stuff is is, you know, kind of also totally doable.
*  It's one of the reasons why accelerating to a safer future is important.
*  And so I think that'll be there for all of it.
*  Now, will it be I actually think we're quite some ways away from where you and I
*  will send each of our AI personal assistants to do this podcast chat.
*  I think we'll still be here.
*  We might be looking at it where it says, hey, ask Tyler this question or ask, read
*  this question. And that really you can read my Twitter feed for me.
*  Right. Yes. Pull out the 20 best tweets.
*  Save me time.
*  What happens to Twitter in this world?
*  Are they themselves disintermediated just as Twitter disintermediated a lot of
*  blogs?
*  Well, I think you see what I'm saying.
*  I don't see why the problem of sorts.
*  Yeah. Maybe cutting out some key levels of infrastructure.
*  You know, I don't know.
*  I think ultimately my guess is it would would be it's not because, you know, to
*  reflect back a point that I heard you make, but I now I now I now plagiarize you
*  shamelessly, which is, look, we have these AIs that that play chess, play
*  chess better than human beings.
*  No one watches AIs playing chess, but we do watch now more than ever human beings
*  playing chess.
*  And I think there's a little bit of the human beings tweeting thing, which even
*  though you're getting a summary, people may still want to go tweet themselves,
*  watch other people tweet.
*  So I would guess no, that it doesn't get completely disintermediated.
*  But it might just send me the 10 best links.
*  Like I could email you a Twitter link.
*  Yes. But if no one's reading Twitter, no one's seeing the ads.
*  Yeah. Maybe there's one bot that pays a fee to access Twitter, gets the blue
*  check and then just mails around links to others.
*  Or I don't know. It seems maybe not problematic, but it will be a big change
*  of some kind.
*  Look, I think changes, they are coming.
*  They're here, I would say.
*  Yeah. Let's say in this new world, I want to have influence through writing.
*  So it used to be write a blog, write a substack, write for New York Times.
*  What's the new thing you can do now that you couldn't do before to have influence?
*  Oh, well,
*  I think the creativity thing is the creativity ability amplifier with AI.
*  So, for example, in impromptu, I have things that are poems, I have light bulb jokes,
*  I have a whole bunch of stuff that normally wouldn't be within my quick skill set,
*  but I can do that.
*  So it amplifies me.
*  I think there's a whole bunch of application within the current things.
*  Like I can do things that I couldn't do before.
*  I do think that we will figure out some versions.
*  Like I've been thinking, I mean, I know you yourself are a great kind of student of art.
*  I've been thinking about what kinds of arts you can create and the fact that art could be
*  like, for example, with this stuff, you can literally make interesting forms of art
*  where every x time sequence, seconds or whatever, that you're in front of something,
*  it's new and never replicating.
*  So that's a form of medium.
*  I do think that the question around, like, for example, even in writing,
*  obviously, it's a book is made, a book is made about AI with AI, hence impromptu.
*  Like, for example, we'll have the impromptu chat bot up along with it.
*  And so people wanted to talk to the bot, talk to the book and elaborate on it.
*  The bot's there.
*  And by the way, maybe the bot will talk to other bots that when you're saying, hey,
*  I'm this thing I'm working on.
*  So I think there's a whole stack of amplifications that will lead to some radically new things.
*  Put aside money income.
*  Let's say someone comes to me, they say, Tyler, spend a year talking to this AI,
*  and then you grade it.
*  And at the end of it all, there'll be a Tyler Cowan bot.
*  It'll be excellent.
*  Should I do that?
*  Yes.
*  And how long should I spend doing that?
*  Well, I wouldn't spend a huge amount of time right now because I think that
*  technology will get a whole lot better for it over the next X years.
*  But I'd start playing with it now.
*  And then I would start looking at where that's useful.
*  Like, I've thought about, like, where would be the things like we do podcasts?
*  Right.
*  It'd be fun to actually have a read bot that would be available on social media
*  and everything else.
*  And people had a question about an amplification of some part of the discussion
*  that you and I are having.
*  And the read bot can answer.
*  That'd be great.
*  So at some point soon, investing in the Tyler bot, the read bot,
*  that's the new way to have influence.
*  For sure.
*  What will replace homework in our schools?
*  Oral exams, projects where you work with GPT, homework done in class?
*  Well, I think you'll have all of those, but I think you'll still have homework.
*  But part of it, like, even looking at, we're going to have a whole bunch of tools that help
*  teachers, help grade, a bunch of other stuff.
*  But even if you took ChatGV today and say I was wanting to teach a class on Jane Austin
*  and her influence on, you know, English painting, then what I could do is I could, as a teacher,
*  go to ChatGVT, other AI bots, construct 10 essays with my own prompts, hand them out
*  to the students and say these are D pluses.
*  Right?
*  So go use the tools and make it better.
*  As a way of doing it.
*  And then that's the way that you could still have homework.
*  And they're using ChatGVT.
*  And it causes them to be much better at thinking about what makes a great essay.
*  How would I, I suppose just the mechanics of all the writing it,
*  what could I innovate on the structure?
*  Could I have a bold or new contrarian point and argue in an interesting way?
*  That kind of provocation is a way that we get, again, human application.
*  So I actually don't think homework is going away, although I do think all the things you mentioned
*  will also be growing too.
*  10 years from now, will people be worse writers?
*  And which other ways might we be stupider?
*  Well, like, for example, I think people are probably by default worse spellers.
*  Just because we had spelling things and, you know, we have spelling.
*  But you learn correct spelling from the spell check, right?
*  Yeah.
*  But if GPT can write for you as well as you can write,
*  you may never learn to write from scratch, as say you and I both have done for many years.
*  Well, okay.
*  So I think yes, that's probably a little harder.
*  Like I can't handwrite essays now as well as I can type them.
*  Because, you know, handwriting is mostly signature or brief notes.
*  But just as you were mentioning, the quality of my being able to understand what a great
*  essay and producing it and everything else, a great writing is, goes up because of it.
*  That even when I'm using it for like, how do I write an email response to Tyler about his
*  provocative comment about art?
*  Maybe I'll use GPT to help me do it.
*  But then I got a much better understanding of what a higher level of quality in that discourse is.
*  What percentage of the American population do you think will take an Amish kind of approach
*  to GPT models and the new AI?
*  1%, 10%?
*  Whether they should or not, but they just won't do it, won't let their kids do it.
*  Probably in the world, it'll probably start a little higher.
*  It'll probably start at kind of like call it 20, 25%.
*  And it will probably shrink to five.
*  What's the killer app for multimodal GPT?
*  What's it going to actually do for people that they'll be thrilled about above and beyond what
*  it's doing now?
*  The expression of creativity, like one of the things that if you haven't gotten, you will get.
*  But like I'm doing a chapter in impromptu, which is like a Star Trek plot involving the person.
*  So like if we haven't sent you the Tyler Cowan Star Trek plot yet, you're going to get it.
*  And I think that kind of like people want to express themselves in these arenas and the
*  multimodal models will give them the superpowers of expression, which will also mean a lot of
*  content generation will also mean amplification of how we communicate in discourse.
*  What I send you as a present, how we go on a vacation or go to a conference together.
*  Anyway, as you know, the world is changing.
*  The world is changing.
*  As you know, there's no sharing function in the main current LLMs.
*  Is this genius?
*  Is this, oh, there are just no product people in these companies.
*  Does this mean, oh, Med is going to own everything sooner or later because they know how to do
*  sharing?
*  How do you think about that absence of a sharing function?
*  I think it's coming.
*  You think it's coming and you think that will dominate the market?
*  Yes.
*  But I think there will also be many providers of AIs, just like I think there will be a number of
*  different chat bot agents that play different character roles in your life, just like different
*  people play roles in your life.
*  How will gaming evolve?
*  Well, it's been funny that it's evolved more slowly than I expected, but just like I was
*  discussing the art, think about games that have virtual worlds, whether they're exploration or
*  combat or strategic games, where the world is invented as you go in that format.
*  And NPCs will be super interesting, even in multiplayer games.
*  The game itself is itself a new frontier.
*  How many games will you yourself create using AI?
*  I don't believe that number is, well, okay, I guess I'm making a prediction.
*  At least a thousand.
*  Is the future open source or proprietary or in what ratios?
*  I'm not sure that the ratios, I think both will be amplified.
*  But what's the right way to think about the division?
*  Well, I think proprietary is kind of a classic set of things.
*  One is the kind of safety issues we're talking about before, but also certain things will be
*  access to very large compute, access to certain sorts of customers or business models,
*  business position on those things will tend to lock in certain kind of proprietary things.
*  On the other hand, I think there will be a bunch of open access as well as open source
*  side of things.
*  I think one of the things about open AI and what it's doing with Microsoft is I think
*  people will be broadly provisioned in this stuff.
*  So I think there will be a ton of open access to this, which is part of the reason why I think
*  it's beyond the sky is the limit relative to what kinds of expression and creativity we're going to
*  see.
*  What's the chance that we're in a new AI winter and the next 10 years will just spend developing
*  applications of what we have, that will be amazing.
*  But the sequel to GPT-4 won't be that much better.
*  The chance that we won't have over at least five years really interesting progress
*  is rounds to zero.
*  Because even if the raw capabilities, say you're an Oracle from the future and you tell me
*  that the real scale curve kind of limited at GPT-4 and there's not much coming,
*  there's still a bunch of tuning, there's still a bunch of product specialization,
*  there's still a bunch of making a good for teachers and students, making a good for
*  doctors, making good for-
*  But that's applications, right?
*  Like big breakthrough.
*  But even though, well-
*  A GPT-4 feels like witchcraft compared to two.
*  Yes.
*  And maybe we'll just have 10 years where nothing feels like witchcraft compared to four.
*  Oh, so what's the chance that there's no more astounding?
*  Very low.
*  I mean, look at, for example, what Alpha Fold did with protein folding.
*  And I think that application of this stuff and tuning it within
*  particular kinds of biological sciences and other things,
*  I think there's line of sight to more things.
*  What's the most important binding constraint preventing us from being at that next stage
*  right now?
*  Is it quality of data, degree of data, the system itself, just raw horsepower?
*  What is it?
*  I think it's compute, then talent, then data.
*  And when you say compute, you mean we just need to buy more GPUs and spend more money,
*  and it may or may not be worth it for companies to do that?
*  And also how you organize the compute.
*  Like there's a whole thing about when you're in the lead, you know how to build the computers,
*  you know which configurations are working or not, how to run them, what the training runs is.
*  It isn't just take these algorithms, apply it.
*  There's a whole bunch.
*  That's part of where it gets the talent as well.
*  There's a bunch of people who have had failed large models using the open source
*  techniques and so forth because there's talent and know-how and learning and all of that.
*  That's part of it.
*  That's kind of between the compute and talent.
*  It's both elements.
*  Anyway, so there's a whole stack of things.
*  Ten years from now, how important will the price of electricity be?
*  Well, I think the price of electricity is always important.
*  If we get fusion, and I think it is good to be working on especially carbon.
*  But fusion will be slow even if you're optimistic, right?
*  Yes, 100%, which is one of the reasons why I think along with you,
*  I'm a huge advocate of nuclear fission as well.
*  I think obviously we should be doing everything possible on solar and a bunch of others.
*  But I think electricity, like the AI revolution is the cognitive industrial revolution.
*  Powered by electricity and so super important.
*  So it's like the Dune world with Spice, but now it's electricity.
*  Yes, and the electricity is part of what both creates and helps you see the future,
*  just like Spice.
*  What did you think of the Dune movie, by the way?
*  You must have seen it.
*  Spectacular, almost like a painting.
*  One of the scenes made me think of Caravaggio.
*  I think you know exactly which scene, given the art.
*  And I'm impatient for the November 23rd release of part two.
*  Given GPT models, which philosopher has most risen in importance in your eyes?
*  Fascinating.
*  Some people say Wittgenstein.
*  I don't think it's obvious, right?
*  I think I said Wittgenstein earlier because in Fireside Chatbots,
*  I brought in Wittgenstein in language games.
*  Peirce maybe?
*  Who else?
*  Peirce is good.
*  Now, I happen to have read Wittgenstein at Oxford, so I can comment in some depth,
*  but the question about language and language games and forms of life and
*  how these large language models might mirror human forms of life because they're trained
*  on human language is a super interesting question.
*  So like Wittgenstein.
*  Other good language philosophers, I think, are interesting.
*  That doesn't necessarily mean philosophy of language philosophers,
*  a la kind of analytic philosophy, but the like Gareth Evans kind of theories of reference
*  as applied to how you're thinking about this kind of stuff is super interesting.
*  You know, like Christopher Peacock's concept work is, I think, interesting.
*  There's a whole range of stuff.
*  And then also the philosophy, like all the neuroscience stuff,
*  applied in with the large language models, I think is very interesting as well.
*  And what in science fiction do you feel has risen the most in status?
*  For you?
*  Oh, for me?
*  Not in the world.
*  We don't know yet.
*  Yes, we don't know yet.
*  You think, oh, this was really important.
*  You know, Werner Winger.
*  Well, this is going to seem maybe like a strange answer to you,
*  but I've been rereading David Brin's Uplift series very carefully because the theory of
*  how should we create other kinds of intelligences and what should that theory be and what should be
*  our shepherding and governance function and symbiosis is a question that we have to think
*  about over time.
*  And he kind of went straight at this in a biological sense rather than, but that's
*  the same thing, just different substrate with the Uplift series.
*  So I've recently reread the entire Uplift series.
*  When you can talk to a dolphin, what will you want to ask it?
*  One of the things I love is these words that are in some languages and not others.
*  You know, whether it's like Komorebi or Ubuntu or, you know, like all these different things,
*  because it's these kind of different lenses of human experiences.
*  It would almost be like, what are the words in dolphin that aren't in our language?
*  And can you try to through an ocean darkly, try to share what it is that concept that
*  you're gesturing at to learn it?
*  That would be the question I would most be interested in answering.
*  And by the way, I'm funding a thing called the Earth Species Project,
*  which is an early effort to try to get at this.
*  Which will be the easiest animal for us to learn how to talk to, in essence.
*  Will it be dolphins, chimpanzees?
*  Chimps.
*  Chimps.
*  Yeah.
*  We share not just a bunch of biology, but kind of a world that we're navigating.
*  But we sort of talked to them already, right?
*  Exactly.
*  And gorillas.
*  But dolphins, what are you saying?
*  But you could actually tape the dolphins, apply an LLM to it.
*  That should work.
*  Well, that's what Earth Species Project is working on.
*  And why do you think that costs?
*  We don't know.
*  I mean, we're just trying to get the taping and we're trying to see.
*  What have you learned about friendship from working with LLMs?
*  I would say I haven't learned anything particular about friendship yet.
*  Although the way that I got to impromptu was, as you know, I've been working for decades on
*  one or more books about friendship.
*  So I started using GBD4 as a personal assistant for research assistant on this, which is, I think,
*  one good thing that everyone should use these things on and in depth of doing it.
*  So I started asking questions that I've always been wanting to do research on.
*  How would you compare and contrast Chinese conception of friendship
*  with Western conception of friendship?
*  That question wasn't very good, but the question on Menchus,
*  and give me some understanding of Menchus or Laozi, and their applications of theory of
*  friendship was interesting.
*  It's kind of the prompt directing.
*  I actually prefer directing versus engineering as a thing,
*  but the prompt directing is getting good research assistants.
*  What have you most learned about yourself working with LLMs?
*  Well, I think this is one of the things we always learn.
*  For example, five, 10 years ago, we were beating the drum on the Turing test.
*  And now we've sailed past the Turing test and almost no one's really talked about it.
*  And we learned, like, oh, actually, in fact, what we're unique is not the Turing test,
*  it's these other things.
*  And so what I would say is, and I'm interested in creating PIE and inflection, among others,
*  but I'm interested in creating AIs that ask good questions.
*  But I'd say currently, anybody who's good at asking questions is much better than GBD4.
*  Like GBD4's generation of questions is not that good.
*  I suspect you tried to generate questions.
*  No, I didn't.
*  Absolutely did not.
*  But for most guests, I do.
*  Yes.
*  Well, but the GBD4 suggestions are kind of vanilla.
*  They're just not that interesting.
*  It's like, ask Tyler about economics and what's going to happen in macroeconomics in the next decade.
*  Not an interesting question.
*  The Wittgenstein question, that's an interesting question.
*  And so that, I don't think there's anything structurally
*  that doesn't, but I tried to get it to generate a whole bunch of questions and complete failure.
*  But I think you get better questions from it.
*  If you don't ask it, what should I ask Tyler?
*  What should I ask Reed?
*  If you come up with what's the weirdest question you can imagine
*  concerning both science fiction novels and LLMs, I think you'll get a better question.
*  Well, we'll try it.
*  My guess is it still won't be as interesting as the question you or I could generate in a minute or two
*  on the same prompt.
*  How will human aspiration change due to LLMs?
*  Hopefully get greatly amplified.
*  That's everything that I'm trying to like.
*  Our aspirations should be very ambitious.
*  And I think LLMs and AI should, if anything, increase them.
*  One thing I've learned is I never get sick of watching the magic.
*  At first I thought, well, for how long will I still get kicks from this?
*  Yes.
*  But it's still running.
*  It hasn't asymptoted for me.
*  Yes, exactly.
*  What will happen to social trust as a result of LLMs?
*  Go up, go down.
*  How will it change?
*  Well, unfortunately, probably initially it'll go down.
*  Everything from deep fakes and a bunch of uncertainty.
*  Because humans trusting humans is another issue that we have.
*  I'm hopeful that maybe we can begin to figure out some ways to have shared discourse,
*  shared discovery of truth.
*  And I would love to have LLM work helping and amplifying that.
*  That's part of what I'm doing at Stanford with human centered AI and other places.
*  Because it's really important to solve.
*  Thinking globally, which group or groups in the world will be the biggest gainers?
*  Access and use of AI stuff will be amplifying.
*  And so therefore, people who are using it will be gaining.
*  So the access to it and the amplification, I think, will really matter.
*  But say I gain from it, but I'm doing fine.
*  I just can't gain that much no matter how good it is.
*  My theory is people say in Kenya where there's a lot of internet access that's good enough,
*  they'll have some cheaper open source model.
*  And the young Kenyans who are very smart and ambitious will gain enormous amounts.
*  And the AI itself will send to a trusted intermediary information about their ability.
*  And they will in fact get phenomenal job offers from other places.
*  And they will gain the most.
*  Now that might be wrong, but that would be my answer.
*  So I think that's true.
*  Although I think that's because the more that we have a good global connectivity,
*  the more we have a rise of talent from everywhere.
*  And AI added to that connectivity will exactly amplify that.
*  And I do think that the notion of human amplification,
*  like the people who are best amplified or best connected into our global ecosystem.
*  And I think we all benefit from it.
*  It's one of the things that you and I share about the joy of amplifying talent from everywhere.
*  Is that actually amplifying talent benefits all of us.
*  Are the mediocre word sales the biggest losers?
*  Yeah.
*  Will Marc Andreessen go away happy, so to speak?
*  Funny.
*  I'd say the losers are people who are uncurious, who want to live in the past,
*  who don't care about learning the future at a broad base.
*  And it's like we have a term for this, Luddites.
*  Steve Jobs said that computers are the bicycles of the mind.
*  We now have with AI the steam engines of the mind.
*  Should a co-authored book with an LLM have First Amendment protections?
*  And again, you have such a book impromptu.
*  I'd say the LLM shouldn't have First Amendment,
*  but I think co-authors like I can own the First Amendment protection.
*  It's what I say.
*  But it can always hire a co-author for some nominal sum,
*  where the co-author adds a few words.
*  It's a co-authored output.
*  Once you allow the co-authored work through the door,
*  anything can be co-authored.
*  And who knows who did how much of the work.
*  So you're granting First Amendment rights to LLMs,
*  which maybe I'm fine with, but is that an implication?
*  Well, I don't think you have to grant the rights to them.
*  You have to have a person who is saying, this is me, I own this.
*  Like I actually think…
*  But there'll be a company that hires such people,
*  known for their obedience to go along with what the LLM wants.
*  And they'll pay the person a quarter,
*  the person will add three words to the thing.
*  Can today you buy someone's First Amendment right speech,
*  like right of free speech?
*  Yes, because you can pay them and give them the thing to say.
*  That's just a link.
*  But that doesn't necessarily mean the LLMs themselves have those rights.
*  Your background with LinkedIn.
*  Which features of LLMs do you feel that's given you
*  a better or deeper appreciation for?
*  With LinkedIn?
*  Well, you're bringing a different conceptual matrix to everything,
*  including LLMs.
*  So you've done LinkedIn for quite a while,
*  obviously, key role in its creation.
*  And how does that make you see LLMs differently?
*  And I have my own hypothesis, but I want to hear yours.
*  So one of the things that I did when I was doing this is we've kicked off a product,
*  which is I believe live now at LinkedIn called Bizpedia,
*  which is trying to provide an in-depth Wikipedia for all of the information
*  that professionals might need or anything.
*  Like, what are the different career paths?
*  What is job skills?
*  Like, how would I do this particular job better?
*  How do I learn it if I wanted to transition and get into it?
*  And it's again, that human amplification.
*  So we couldn't afford to do all that stuff,
*  but we could get the LLMs to generate the baseline of it,
*  and then we can use the human network to amplify it.
*  And that was at least one kind of thing that I thought about with it.
*  It obviously also has real implications in search and matching,
*  like, hey, which people should meet each other?
*  Or if I'm looking for someone to solve this particular business problem,
*  it could be hiring, it could be sales, it could be partnering,
*  it could be information.
*  Obviously, that all gets amplified.
*  My answer would be this.
*  There are uses of LinkedIn that might appear anodyne
*  to a lot of snobby outside observers,
*  but are super useful to people who do them.
*  And I think LLMs will be the same.
*  So people in poorer countries,
*  they want it to write a business plan for them.
*  The business plan will sound too McKinsey-like
*  to please a lot of people who think they're better than that.
*  But in fact, it will be super useful.
*  Yeah, I think that's true.
*  And I also think that, again, in the human amplification,
*  look, I think it's like, oh, look, I can write the business plan.
*  I don't need to.
*  It's like, well, but you adding to it will make it a lot better.
*  Yes.
*  But I think also your LinkedIn background makes you more sympathetic
*  to a partial subscription model, which may be the future for LLMs.
*  Well, it's definitely a future for sure.
*  And what percentage?
*  Don't know.
*  Could be 20, could be 80.
*  Do you think subscription is the economic future of LLMs for the next 10 years?
*  Well, I think it's definitely a future.
*  But by the way, LLMs, as has already been announced,
*  will be used to generate advertising.
*  You're allowed to use hindsight here, but as a talent scout yourself,
*  how do you think of the strengths of Sam Altman in doing what he's done?
*  Look, I think this is an amazing gift to the world by Sam and the entire team.
*  Sam, I think, assembles great people and helps them with high ambition.
*  I think that's one of the things that is under-described about Sam.
*  I think that he also, he doesn't try to make himself the hero role.
*  He catalyzes other people.
*  It's one of the reasons I think he is also one of the good people to be leading the kind of safety thing.
*  Because unlike a set of people who tend to have Messiah complexes,
*  it's only safe if I bring it to you.
*  He goes and gets a number of people involved in doing it.
*  I think that's another strength as part of it.
*  His ability to think super big has been helpful here.
*  I mean, he frequently thinks something is going to be here tomorrow where I disagree with him.
*  I don't think it's going to be here even he's younger than I am, even in his lifetime.
*  But like that ambition is awesome.
*  OpenAI right now, I think they have about 375 employees during the critical breakthrough period.
*  Of course, they had even fewer.
*  Is that a good thing?
*  I think that's a good thing.
*  Is that a new model of some kind?
*  Or is it the old model but it's the alliance with Microsoft that makes everything work?
*  Mid-Journey I've heard is like 11 or 12 employees, which is crazy, right?
*  Yeah.
*  Well, on Instagram when Greylock funded it was 13 employees.
*  So it is a model of generally, it's an amplification of the general software model where you can have very small teams
*  that produce things that are Archimedean leverage.
*  Now you do need in all of those cases, massive compute infrastructure.
*  So like AWS existed for Instagram and so forth.
*  So you need that in order to make it happen.
*  But a small team of software people can create amazing things.
*  How is higher education going to change and exactly who or what will do it?
*  Well, as you know, higher education is very resistant to change.
*  It's a very important part of the world.
*  And so, you know, and yet it should be changing.
*  It should be reconceptualizing its way that it amplifies young people, you know,
*  it launches them into the world and it should be providing LLMs that are tutors and helpful.
*  It should be having LLMs that are helping professors do research and communicate with each other,
*  you know, like AI and doing all this stuff.
*  Like it should be improving.
*  It should be improving.
*  It should be embracing all of that with full force.
*  And yet most of it is, is, is, is, I think, ignoring what's currently happening.
*  Sure.
*  But what actually breaks in the system because of that?
*  Who rebels?
*  Well, you know, it's easy to read the tea leaves of the future in the past.
*  You know, Michael Crow at ASU, you know, doing amazing work.
*  I think he will trailblaze with the technology and the technology.
*  And so I think it's going to be a huge challenge for us.
*  Like I think these folks will eventually get other people to say,
*  this is where the world's going and it's really good.
*  And so students will switch to the institutions that are doing a better job.
*  Yes.
*  And you think that will?
*  And the network effects are not too strong to stop that.
*  No.
*  Here's a general question quite removed from the world of AI.
*  I've discussed this with Patrick Collison a fair amount.
*  It seems to me that there are some things that have been removed from the world of AI.
*  I've discussed this with Patrick Collison a fair amount.
*  It seems to me that after World War II, most of the Western world, maybe all of it,
*  we've simply stopped building beautiful neighborhoods.
*  There's plenty of beautiful individual buildings, artworks, music, whatever,
*  but actual complete neighborhoods as a whole.
*  They're now basically boring and mediocre, even if they're very pleasant to live in.
*  Why did that change?
*  You know, maybe you can challenge the premise if you want.
*  No, maybe, look, I don't know if I would speculate.
*  It's because it's the general kind of industrialization that makes it,
*  you know, hey, figure out what is the thing that is closest to what most people want
*  and produce a lot more of that.
*  Right?
*  Maybe it's that.
*  But medieval towns in Europe, they're beautiful.
*  There's a certain sameness to them.
*  But we admire the beauty all the more.
*  So it doesn't seem that it's sameness per se that's lowering the aesthetic quality.
*  Well, it could be production costs, right?
*  And that's part of the industrialization.
*  Like it's like the now how do we produce each one at a kind of lower marginal cost.
*  I would hope that what we will see with, like, for example,
*  I was literally talking to someone last night who was creating a speakeasy for their house
*  and what they did to work with their designers,
*  they went on to mid-journey and they created a whole bunch of different images
*  and the range of creativity, like, I hope that is what our future is
*  and that's what I'm trying to beat the drum on to get us there.
*  What is it about our current culture in America,
*  putting aside politics, but culture that concerns you most?
*  Culture.
*  Well, I would say, and obviously ties to politics a little bit,
*  but I think a culture that says we should have civil discourse
*  to get to reasoned arguments and information,
*  which obviously includes science, about what should be,
*  is the thing that is, like, what, you know,
*  what kicked us off from the Enlightenment and from the Renaissance
*  and it's important to keep that in our fundamental bones and genetics
*  and we are straying from it in very, very dangerous ways.
*  And it's not just on the crazy right stuff with, you know, election denialism and all the rest.
*  You obviously see that in wokeism and everything else too
*  and I think that's where, you know, I think the two sides of this,
*  both left and right, would be surprised for me to say
*  in this respect you both have the same disease
*  and we need to be talking about, like, how do we reason our way
*  to, like, kind of truth and understanding and that that's super important.
*  It seems that a lot of mental health indicators have become worse in this country.
*  Maybe all the more so for young people. Why is that?
*  Well, I don't fully know.
*  I do think that we certainly see the indicators get worse.
*  Is it because kids are always connected to kind of like,
*  it's like a little bit more Lord of the Flies and always connected to other kids.
*  Is it because they have the insecurities of seeing, you know,
*  of being amplified like cyberbullying following you into the home?
*  Is it because the technology is not built the right way to try to reinforce mental health?
*  I think we can do that.
*  Like, part of the thing is how do we help provide support?
*  Like, you can use AI to help provide support on this.
*  I think it's a good thing to do.
*  Whatever it is, it's an important thing for us to work on.
*  Now, we're sitting here in the suburbs in Menlo Park,
*  but will AI save the San Francisco tech scene?
*  Or is that just going to vanish because of poor governance?
*  Well, I think in many ways San Francisco is doing everything it can
*  to self-emolate on the tech scene.
*  But there's some major triumphs as of late, right?
*  Yeah.
*  They're in the city itself.
*  Open AI, yeah.
*  They're not on Sand Hill Road.
*  Yes.
*  Yeah, but it's throughout the entire valley.
*  But yes, open AI is amazing.
*  And I do think that there is network effects throughout all of Silicon Valley.
*  And, you know, my advice to San Francisco, just as my advice to Menloving,
*  is try to channel the stuff that's going on here to help all the rest.
*  Like, for example, it's like, look,
*  don't try to resist the tech industry being in San Francisco.
*  Try to channel it to helping with, you know, the various problems,
*  whether it's homelessness or crime or other kinds of things,
*  and to try to help those problems.
*  Because, like, for example, you could use cameras
*  to help with a whole bunch of the crime problems.
*  Ten or 15 years ago, it seems we had so many tech CEOs,
*  either in the US or in the US,
*  we had so many tech CEOs,
*  either in their 20s or possibly even teenagers,
*  seeing considerable success.
*  It doesn't seem we have people in that age range anymore.
*  Like Sam Altman, he's, I think, 38, maybe 37.
*  So why are CEOs older now, the more important ones?
*  What's changed?
*  Well, look, I think we will see some new additional young folks.
*  And, look, the history of the kind of status quo is
*  CEOs tend to be older.
*  I think it's the younger CEOs that tend to be
*  the new startling companies.
*  I mean, remember, there's not just Sam Altman.
*  There's also Patrick Ollison.
*  There's also Brian Chesky.
*  There's also those sorts of folks.
*  And they were CEOs when they were younger.
*  And I am confident there will be a new crop of them before too long.
*  But what if it's the case there's less low-hanging fruit?
*  The abilities you need are more synthetic.
*  Social networks are more important.
*  This will favor the 35-year-olds rather than the 19-year-olds.
*  Could that possibly be true?
*  It's possibly true.
*  I mean, there are different industrial cycles where
*  you have to spend more time building up your position
*  to get the capital credit to be entrepreneurial,
*  bold, in charge, et cetera.
*  That's definitely been cycles of that in history.
*  So I don't think that, I don't think it's impossible.
*  But I do think it's a little bit like you were gesturing
*  with small groups doing stuff with software.
*  Because you can have small groups doing stuff with software,
*  you'll still have young CEOs, young founders.
*  She or he will still be new blazing entrants
*  into the world change leaders.
*  And the Bay Area as a whole,
*  you think that will remain as important as it's been?
*  Yes, categorically, yes.
*  If there's a tech startup scene that is currently underrated
*  in the world or in the US, where would that be?
*  Well, I'll say something mildly provocative
*  just because it's entertaining.
*  Not Miami, since there's this whole crew that's like,
*  Miami is the future.
*  And I think the network effects of talent
*  and everything else is much more here and other places.
*  I think Austin is doing really interesting things.
*  I think New York's doing interesting things.
*  I think London's doing interesting things.
*  Surprisingly, I think there's interesting things
*  in Paris and Berlin.
*  Sweden or yes or no?
*  Sweden, yes.
*  Obviously Spotify and a bunch of other stuff.
*  They punch way above their population weight.
*  But since they're a small population,
*  they don't tend to have a lot of immigration.
*  I tend to think you need those
*  to really get the flywheels going.
*  Any hope for Poland plus Ukraine or you don't see it yet?
*  I hope for it.
*  I don't see it yet.
*  And obviously, there's other difficulties
*  that are impeding right now.
*  But to say it's centered in Poland,
*  people from Russia and Ukraine, they go to Poland.
*  Poland becomes a new center with talent,
*  basically from three nations.
*  Yeah, totally possible.
*  How much do you worry about low and declining fertility
*  as a social problem for the West, for East Asia?
*  Well, so one thing that I thought about writing an essay on,
*  maybe I still do it, is it isn't,
*  oh, God, the robots are coming for our jobs.
*  It's, oh, God, can the robots get here sooner or not?
*  Can the robots get here sooner enough?
*  Because when we get to,
*  like our whole system has been based upon the fact
*  that we have a growing population
*  so that the growing population can take care of the elderly.
*  If you don't have that,
*  you have a serious reorientation of our entire society.
*  I mean, China's going to run in that in a huge way and so forth.
*  Japan's probably trailblazing.
*  You see it a little bit with the care and robots
*  and everything else.
*  And so I think that, you know,
*  it's like we desperately need the amplification
*  in order to, you know, not create a massive burden
*  for our children if that trend continues.
*  But let's say we can afford it
*  because of something like robots or AI.
*  Doesn't that, in a sense, make the problem worse?
*  We feel less of an emergency.
*  So South Korea, they're at 0.8.
*  Just to keep the clock on ticking,
*  eventually they basically don't have people left.
*  So how can that work out well for us?
*  And the fact that someone pays the bill
*  for our collective extinguishing of the human condition
*  doesn't reassure me.
*  I think in various ways we can cause...
*  I don't think, you know, obviously you can do the math
*  and go to diminishing zero.
*  I think we will both do...
*  We'll do various forms of incentive stimulus,
*  but other things.
*  I think we can get it back to at least a replacement rate.
*  Among other things, we might say,
*  being a parent is a paid job,
*  just because we think that that's an important thing
*  as a society, and we can afford that
*  from kind of the productivity increases
*  we're getting from AI and robotics.
*  So we use the robot surplus, in essence, to pay families
*  for that to be the second or third job in the family.
*  Yes, exactly.
*  And politically, you think that will be super popular?
*  People hate it?
*  I think we could get to a place where it would be popular.
*  I think right now it would be considered
*  to be science fiction and strange.
*  But if a replacement rate keeps going down,
*  then I think people will say,
*  oh, no, I thought that makes sense.
*  And a lot of science fiction has come through.
*  Yes.
*  You and I both love science fiction
*  and trade recommendations on a regular basis.
*  Asimov's three laws, how good were they?
*  I think they were really good,
*  although they were out of conceptualization for a target.
*  If I were to update them,
*  and it's a little bit like,
*  to reveal my nerdishness,
*  Giscard's zeroth law.
*  But I think that what you really want in it
*  is to parallel almost a Buddhist sense
*  of the importance of life and sentience.
*  And that that's the kind of thing that you want
*  if you're creating really autonomous intelligences.
*  I think the kind of the Uncle Tom,
*  if it really is a totally autonomous being,
*  hence being careful about going into it,
*  a new form of robot slaves is perhaps
*  not ultimately where humanity would want to be.
*  There's not enough stress in them, I think,
*  on what the robots are obliged to believe.
*  So a robot is free to believe something crazy
*  and then act on it.
*  That seems to me the biggest weakness
*  of the laws, at least what you see in the stories.
*  Yeah, and hence the alignment with human interest
*  around how do you amplify the quality and value of life
*  is, I think, a very good thing.
*  What's an underrated science fiction novel
*  that maybe our listeners, readers, don't know about?
*  Well, there's lots.
*  Another one that I've been rereading recently
*  because I think it's, you know,
*  I've been rereading recently
*  because I think it's good fun
*  but also raises good questions
*  in a simple, fun format
*  is Martha Wells' Murderbot series.
*  I think it itself does not really address
*  those questions very directly
*  but it raises them in good ways,
*  like persons and being a thing versus a person
*  and so forth within a kind of a classic sci-fi romp.
*  I've been rereading Ursula Le Guin,
*  The Man and the Dead, Dispossessed,
*  and I'm amazed how anti-utopian
*  and almost right-wing it is.
*  Yeah, yeah.
*  Utopian society is a kind of nightmare.
*  Yes, well, and look, it's partially
*  because we need to have diversity in the human species.
*  Like, how do we, it's part of how do we enable
*  as much diversity while, like, you know,
*  not allowing, it's that,
*  the diverse of creative expression,
*  part of like freedom of speech
*  and, you know, it is valuable
*  is that diversity of human,
*  of craziness that also creates genius.
*  What's a game you've been playing more of lately and why?
*  I haven't really had a lot of time to play games
*  because the AI stuff is occupying a total amount of time.
*  I have a stack of games
*  without their shrink wrap taken off
*  that I'm hoping to get to.
*  I find the AI stuff, it's totally erect my calendar.
*  I had a year planned out
*  that I could just do a whole bunch of other things
*  and now, sort of every day,
*  you have to keep up with AI,
*  you have to learn, it's like,
*  this doesn't work anymore.
*  Throw up my hands.
*  And I feel a bit behind on everything.
*  Yes, although, by the way,
*  there will be a chat bot for that.
*  That's good.
*  What's a non-obvious problem
*  we should be worrying about more?
*  Well, I mean, I think because so much of the discourse
*  and the press around is around the macro things
*  is, you know, AI in the hands of bad human actors
*  and there's a range of bad human actors.
*  So I think that's really important.
*  I think also the question around, like, people tend to go,
*  oh, wait a minute, the people who have the AI
*  will be amplified.
*  It's like, how do we get that AI,
*  like, the most natural thing is to pursue where the money is.
*  Well, how do we get AI in the hands of, like,
*  lower income students and school districts
*  and all the rest to make sure that it's there
*  and provisioned.
*  It's one of the things that I love about open AI,
*  the accessibility of chat, GPD,
*  but, like, how do we get as broadly enabled as we can
*  is, I think, another important one.
*  Let's say you're advising a small but tech-advanced nation.
*  Singapore, Israel would be two options.
*  Would you tell them they should build their own LLMs?
*  It will cost them a lot per capita,
*  but they'll have their own LLMs.
*  I don't think they need to,
*  but I think they should get involved
*  and perhaps work with the providers of LLMs
*  to make sure that there are LLMs that fit their needs.
*  That doesn't necessarily need to be
*  that they need to build their own,
*  but they say, hey, we need to make sure
*  that we have LLM provisioning for our companies
*  and our industry and our citizens.
*  Okay, let's make sure that happened.
*  Whether it's the, you know,
*  we spend billions of dollars to build the one ourselves,
*  they could do that.
*  Certainly, no, nothing bad in doing that,
*  but they should make sure
*  that their industries and their citizens are provisioned.
*  But say we have a strategic petroleum reserve,
*  for better or worse.
*  Should Israel have a strategic GPU reserve?
*  Don't nations such as the US
*  get too much leverage over Israel
*  if they're dependent on us for models?
*  And right now, OpenAI is open,
*  but OpenAI can't control how our government regulate it.
*  Our government might decide to use it
*  as a foreign policy tool,
*  hand it out to countries that cooperate,
*  deny it to countries that don't.
*  Look, I think it's an important gesture of the dependency.
*  But by the way, once you have the LLM,
*  then the, and it's, you know,
*  as it were on the soil governed by your laws,
*  the ability of the US to do that is much less.
*  That's the reason why it's like,
*  for example, somebody was like,
*  we need to build the computers.
*  And I do think, like, you know,
*  depth of compute is a strategic advantage.
*  It's an important thing to take a look at.
*  And you may want to say, hey,
*  we've got to make sure
*  that we have a certain amount of compute
*  that's onshore that is then aligned
*  with our interests of our country,
*  our society, our industries, et cetera.
*  But also, by the way,
*  if you just are, there's training and there's running,
*  and if you have the AI models and you're running them
*  and you have that sufficiently within your society,
*  your strategic dependency would be a lot less.
*  So I think you have to plot that strategy with some care.
*  But I do think it's an important strategy
*  to be paying attention to.
*  And I think, for example, we as the US,
*  part of the thing I like about, you know,
*  the kind of the world order of the US is,
*  yeah, we sometimes do stuff
*  that throws too much stuff too much to our advantage.
*  That's a problem.
*  But we also try to provision a lot.
*  Like, we, you know, try to raise the rest of the world.
*  And I think we should continue to do that.
*  As you know, in EU law, there's a right to be forgotten.
*  But that is arguably inconsistent with current LLMs.
*  You can force a new training run
*  by saying, well, you've got to take me out
*  of the current system,
*  but a new training run costs a lot of money.
*  And to have lone individuals raising their hands,
*  say, oh, the model has to forget me,
*  that's just not going to work.
*  Yep.
*  So legally, where do you think the EU
*  will end up on all this?
*  Well, I think if the...
*  There's a smart EU, dumb EU,
*  and which one is up to them.
*  Smart EU is to say, look, what we need to do
*  is we need to be dealing with the function
*  of what are the kind of culture and society.
*  So we say, well, we want to make sure
*  that these AI tools have the right judiciousness
*  in being asked about individuals.
*  That's our particular culture.
*  So we say, okay, you have to at least have a metabot
*  that could interrupt the query
*  and interrupt the query in some way.
*  And that's what that would be
*  if that was our expression of culture
*  and getting tech forward in how you do it.
*  The bad one is say, no, no,
*  a little bit like what the Italians
*  were doing with Chatchi BD.
*  Well, you can't do Chatchi BD.
*  He's like, by the way, you're disadvantaging
*  your entire society and all of your citizens.
*  You're being Luddites with the Loom and the steam engine.
*  And so, you know, be innovative into the future,
*  yes, with European values and European concerns and so forth,
*  but it's the steering into the future
*  versus trying to enshrine the past.
*  And that would be the less smart EU.
*  And you're not sure which of those will happen?
*  I hope they pick the smart one.
*  I try as much as I can.
*  I think European values and insights in the future
*  is something I learn from and value.
*  I want them to contribute that positively into the future.
*  And will chat GPT through VPNs just dominate China
*  at least for some number of years?
*  Or will they somehow force people away from doing that?
*  Because you're getting Western Anglosphere
*  information all the time, right?
*  Including about Tiananmen, China, everything else.
*  They have demonstrated with what they call the golden shield
*  that they are committed to creating
*  an alternative Internet and an alternative series.
*  So I think they will be able to do that.
*  And they even have it on the control through VPNs.
*  So, you know, we as Westerners go to China
*  and we say, hey, look, it works just fine with VPNs.
*  And that's because they're not,
*  they're allowing our VPNs through where as local VPNs,
*  they squash them.
*  But I've seen some numbers, maybe they're not reliable,
*  but they seem to indicate there are more chat GPT users
*  in China than in the US.
*  Now they have a larger population,
*  but still that's a major effect
*  that probably is happening now.
*  And do they just tolerate that and let everyone query it
*  about, you know, Taiwan is a country or whatever?
*  Look, in my view, they should, but I don't think they will.
*  Of course they should, but what will they do?
*  And also what's more is I think they will be
*  able to do that because these models have less ability
*  to put kind of controls in them.
*  I think that will cause problems on even onshore development.
*  And they'll be open source in China, right?
*  Once that's more of a thing.
*  Yes.
*  So they'll just lose their attempt to censor their own
*  society or you think they'll somehow triumph over everything?
*  They're very smart and they're very committed to the
*  censorship.
*  I think that they will, I think it'll create additional
*  problems for them in so doing, but I think they'll figure
*  out how to do it.
*  Before my last question, just to repeat,
*  Reid's new book, co-authored with GPT-4,
*  is impromptu, amplifying our humanity through AI,
*  a Wall Street Journal bestseller.
*  And finally, last question, Reid,
*  what will you do next?
*  Other than talk to dolphins.
*  Yes.
*  Like AI is going so fast, there's a bunch of things
*  that we didn't cover in impromptu,
*  so I actually think we will do another book and set a content
*  around AI possibly within this calendar year,
*  which will be pretty amazing.
*  Reid Hoffman, thank you very much.
*  Thank you.
