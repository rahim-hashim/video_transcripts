---
Date Generated: August 08, 2024
Transcription Model: whisper medium 20231117
Length: 1847s
Video Keywords: ['Economics', 'Policy', 'Lifestyle', 'Culture', 'AI', 'Artificial Intelligence']
Video Views: 14411
Video Rating: None
Video Description: In this interview, recorded at a16z’s 2024 American Dynamism Summit, Tyler and Marc Andreessen engage in a rapid-fire dialogue about the future of AI, including the biggest change we’ll see in the next five years, who will gain and lose status with the rise of LLMs, why open-source is important for national security, the best and worst parts of Biden’s AI directive, the most underrated energy source, what the US can do to speed up AI deployment, what gives Marc optimism about Gen Z, which thinker helps him make sense of American capitalism, and more.

To hear more conversations from a16z’s American Dynamism Summit, please go to https://www.a16z.com/adsummit.

Recorded January 30th, 2024

Transcript and links: https://conversationswithtyler.com/episodes/marc-andreessen-2/

Stay connected:
Follow us on X, IG, and Facebook: @cowenconvos
https://www.twitter.com/cowenconvos
https://www.facebook.com/cowenconvos
https://www.instagram.com/cowenconvos

Join us on Discord: https://discord.gg/JAVWP7vTxt

https://conversationswithtyler.com

https://mercatus.org
---

# Marc Andreessen on AI and Dynamism  Conversations with Tyler
**Conversation with Tyler:** [March 13, 2024](https://www.youtube.com/watch?v=wGWirl2fUwE)
*  Hello, Mark.
*  If your entrance music were to be Beethoven, which symphony and why?
*  For those of you who do care and know who Tyler Cohen is, this is how his podcasts start.
*  This is how he intimidates his guests into submission.
*  First of all, I just wanted to say thank everybody for being here with us today.
*  We're really grateful that you were all able to spend time with us and hopefully it's been useful.
*  Second is I'm going to get new business cards printed up that say you either know who I am or you don't care.
*  Which are both or both.
*  I mean, how can you possibly see?
*  I mean, I guess we have to rule out Beethoven's Ninth Symphony because that's the official music of the European Union.
*  Is that right? That's correct.
*  That's the official anthem of the European Union, which is just such a terrible mean thing for them to do.
*  To such a great piece of music like that, we should lodge a formal diplomatic protest.
*  I guess probably Beethoven's fifth in retaliation.
*  I would pick you as the fifth. Yes.
*  Now, how will A.I. make our world different five years from now?
*  What's the most surprising way in which it will be different?
*  So so there's a great kind of breakdown on adoption of new technology that the science fiction author Douglas Adams wrote about years ago.
*  He says any new technology is received differently by three different groups of people.
*  If you're below the age of 15, it's just the way things have always been.
*  If you're between the ages of 15 and 35, it's really cool and you might be able to get a job doing it.
*  If you're above the age of 35, it's unholy and against the order of society and will destroy everything.
*  A.I., I think, so far is living up to is living up to that framework.
*  What I would like to tell you is A.I. is going to be completely transformative for education.
*  I believe that it will.
*  Having said that, I did recently roll out to GPT to my eight year old and he and he you know, I was like very, very proud of myself because I was like, wow, this is just going to be such a great educational resource for him.
*  And I felt like, you know, Prometheus bringing fire down from the mountain to my child.
*  And I installed it on his laptop and said, you know, son, this is, you know, this this this is the thing that you can talk to any time and it will answer any question you have.
*  And he said, yeah.
*  And I said, well, you know, this is like a big deal.
*  It answers questions. He's like, well, what else would you use a computer for?
*  And I was like, oh, God, I'm getting old.
*  So I actually think there's like a pretty good prospect that like kids are just going to like pick this up and run with it.
*  And I actually think that's already happening.
*  Right.
*  Chet GPT is fully out, you know, and Bart and banging all these other things.
*  And so I think, you know, kids are kids are going to, you know, kids are going to grow up with basically, you know, you could use various terms, assistant, friend, coach, mentor, you know, tutor.
*  But, you know, kids are going to are going to grow up in sort of this amazing kind of back and forth relationship with a.
*  I, you know, at any time a kid is interested in something, if there's if there's not, you know, a teacher who can help with something or they don't have a friend is interested in the same thing, they'll be able to explore all kinds of ideas.
*  And so I think it'll be great for that.
*  You know, I think it's obviously going to be totally transformative and feels like warfare.
*  And you already see that, you know, the concern, quite honestly, I actually wrote a wrote an essay a while ago on sort of why I won't destroy all the jobs.
*  And and the sort of short version of it is because it's illegal to do that because so many jobs in the modern economy require licensing and are regulated.
*  And so, you know, I think the concern would be that there's just so much sort of glue in the system now that that that prevents change.
*  And it'll be very easy to sort of not have a health care or, you know, a education or whatever, because literally some combination of like, you know, doctor licensing, teacher, you know, teacher unions and so forth will basically outlaw it.
*  And so I think that that's the risk.
*  If we think of a and its impact in sociological terms, large language models, who will gain in status and who will decline in status?
*  And how should this affect how we think about policy?
*  Yeah, so first of all, it's important to qualify sort of exactly what's going on with large language models, which is which is super interesting.
*  And kind of this thing has happened that you kind of read about a lot in the press, which is kind of there was this general idea that there would be something called AI at some point.
*  And then large language models appeared and everybody said, aha, that's AI, just like we thought it would be.
*  And then that sort of everybody sort of extrapolates out.
*  And that's true to a certain extent.
*  But large language models are the success of large language models is very unexpected in the field.
*  And actually, the origin story of even even chat GPT is that this is not what open AI actually started to do.
*  They started to do something different.
*  And there was actually one guy who actually his name is, I think, Alec Radford.
*  And he literally was like off in the corner at opening.
*  I like working on this and like, you know, twenty eighteen, twenty nineteen.
*  And then it just it basically was this, you know, was this was this revolution building on work that had been done at Google.
*  So it was kind of this very surprising thing.
*  And then it's important to sort of qualify like how it works, because it's not just like some sort of robot brain.
*  You know, what it is, is it's basically you basically you basically feed essentially
*  ideally all known human generated information into a machine.
*  And then you let it basically build a giant matrix of numbers and basically correlate everything that, you know, in a nutshell, that that's what these things are.
*  And then basically what happens is when you when you ask it a question or if you ask it to like, you know, make a drawing or something,
*  it basically traverses essentially does a search.
*  It does a search across, you know, basically all of these words and sentences and diagrams and books and photos and everything that that human beings have created.
*  And it sort of tries to find the optimal kind of path through that.
*  And that and that's how it sort of generates the answer that it gives you.
*  And so it's it's philosophically, it's kind of this really profound thing, I think, which is it's like it's like basically staring.
*  It's like you as an individual using this machine to kind of stare at the entirety of the creation of all human knowledge and then sort of have it played back at you.
*  And so it sort of it sort of harnesses the creativity of thousands of years of human authors and artists.
*  And then and then sort of derives new kinds of answers or new kinds of images or whatever.
*  But fundamentally, you're sort of in interaction with our with our civilization in a very profound way.
*  In terms of who gains and who loses status, there's actually a very interesting thing happening in the research right now.
*  There's a very interesting research question for the impact on on on job skill, you know, for example, for people who work with words or
*  work with work with images and are starting to use these technologies in the workforce.
*  And sort of the question is who benefits more the high skilled worker and think lawyer, doctor, accountant, whatever graphic designer,
*  the high skilled person who uses these tools to become right.
*  An additional quantum leap, high skilled.
*  And that would be a theory of sort of separation.
*  But the other scenario is the sort of average or even low skilled worker who gets upgraded.
*  And of course, just that, you know, kind of the nature of the economy there, you know, there are kind of more people, you know, kind of more people in the middle.
*  And at least the research, there's been a series of research studies that have been coming back that it's actually the uplift average is actually more significant than the uplift to to the high skill level.
*  And so actually, what seems to be happening right now is it's actually a compression by kind of lifting people up.
*  And so I wouldn't, you know, social questions are often a zero sum game of who gains and who loses.
*  But there may be something here where just a lot of people just get better at what they do.
*  Why is open source AI in particular important for national security?
*  Yeah. So for a whole bunch of reasons.
*  So one is it is really hard to do security without open source.
*  And so there used to be there actually used to be there's actually two schools of thought on kind of information security, computer security broadly that have played out over the last 50 years.
*  There was one school of security that says you want to basically hide the source code and you want to hide the source code precisely.
*  And this seems intuitive because presumably you want to hide the source code so that bad guys can't can't find the flaws in it.
*  Right. And presumably that would be the safe way to do things.
*  And then over the course of the last 30 or 40 years, basically what's evolved is the realization in the field.
*  And I think very broadly that actually that's a mistake in the in the software field.
*  We call that security through obscurity.
*  Right. And so we hide the code.
*  People can't can't exploit it.
*  The problem, of course, is OK.
*  But that means the flaws are still in there.
*  Right. And so if anybody actually gets to the code, they just basically have a complete index of all of all the problems.
*  And there's a whole bunch of ways for people to get to code.
*  They hack in. And, you know, it's actually very easy to it's actually very easy to steal software code from a company.
*  You hire the janitorial staff to stick a USB stick into a machine at three in the morning.
*  So, like, you know, software companies are very easily penetrated.
*  And so it turned out security through obscurity was a very bad way to do it.
*  The much more secure way to do it is actually open source.
*  Basically, put the put the code in public and then basically build the code in such a way that when it runs, it doesn't matter whether somebody has access to the code.
*  It's still fully secure.
*  And then you just have a lot more eyes on the code to discover the problems.
*  So in general, open source has has turned out to be much more secure.
*  So I would start there if we want secure systems.
*  I think this is what we have to do.
*  What's the biggest adjustment problem governments will face as AI progresses?
*  For instance, if drug discovery goes up by three acts, all of a sudden the FDA is overloaded.
*  If regulatory comments are open, AI can write great regulatory comments.
*  What does government have to do to get by in this new world?
*  Yeah. So I think for every scenario, you know, by the way, hopefully at least the first of those two scenarios happens, maybe also the second for anything like this.
*  What there should be is there should be a corresponding corresponding phenomenon happening on the other side.
*  Right. And so the government sort of correspondingly then should be using AI.
*  To evaluate new drugs.
*  Right. So company shows up with a new drug design.
*  There should be AI assist to the FDA to help them evaluate new drugs.
*  A regulatory agency that has public comments should have AI assist for being able to be able to process all that information and be able to aggregate it and then be able to reply back to everybody.
*  And this is kind of true of basically every possible.
*  There's a very interesting thing about AI.
*  So every possible threat you can think of AI posing.
*  Basically, there is a corresponding defense that has to get built.
*  Cyber secure.
*  I'll pick another one.
*  Cyber security.
*  People are quite, I think, legitimately concerned that AI is going to make it easier to actually create and launch cyber security attacks.
*  But correspondingly, there should be better defenses.
*  There should be AI based cyber security defenses.
*  By the way, we see the exact same thing with drones.
*  You know, weaponized AI autonomous drones are clearly a threat as we see it in the world today.
*  So we need AI defenses against drones.
*  The cynical view would be this is just a classic arms race.
*  You know, attack defense, attack defense and kind of does the world get any better if there's just more.
*  Threats and more defenses.
*  I think the positive way of looking at it is we probably need these defenses anyway.
*  Right. So even if we didn't have a drug discovery, I think we should be using AI to evaluate drugs.
*  Even if we didn't have a drones, we should still have defense, you know, defense against standard missiles and against enemy aircraft.
*  Even if we didn't have AI sort of driven cyber attacks, we should have driven cyber defenses.
*  And so I think this is an opportunity for the defenders to not only keep up, but also build better systems for the present day threat landscape.
*  The Biden AI directive.
*  What's the best thing about it?
*  What's the worst thing about it?
*  It didn't overtly attempt to kill AI.
*  So that was good.
*  You never know with these things, you know, what they're going to, you know, how much how much teeth they're going to try to put into it.
*  And then, of course, you know, there's always the question of whether that it stands up in court.
*  But it wasn't it.
*  There were things that were being discussed in the process that were much, much worse and I think much, much more hostile to the technology than that ended up being in it.
*  So I think that's good news.
*  I think it was quite it was quite benign in terms of it's it's just like flat out directives, which is good.
*  You know, the the issue with it, my my people have different opinions.
*  My opinion, the issue of it is it kind of greenlit, you know, essentially 15 different regulatory agencies to basically put AI under their purview in sort of undefined ways.
*  And so, you know, we will now have, I think, a relatively protracted process of many regulators from many agencies without explicit authority in the domain, basically inserting themselves into the space and then, you know,
*  presumably at some point there will be a determination of who has purview over what.
*  But it seems like we're in for a period of quite a bit of confusion as a result.
*  So how much more green energy do we need to, in essence, fuel all of this AI and where will it come from?
*  What do you see the prospect is like for the next 20 years?
*  Yeah. So the good news with the good news of AI and the good news with also, by the way, with with crypto, because there's always a lot of controversy around crypto and Web 3 and blockchain around around energy use.
*  The good thing with these technologies, the good news from energy is these these these systems lend themselves to centralization of data centers.
*  Right. And so if we need a, you know, if we need a million to go into 10 million, 100 million to a billion AI chips, you know, they could be distributed out all over the place, but they can also be highly centralized.
*  And because you can highly centralize them, you can think not just in terms of building a server, you can think about building basically a data, basically a data center that's an integrated thing from the chip, basically all the way to the building or to the complex of buildings.
*  And then and then the way those modern data centers are built by the leading edge companies now is they're sort of built on day one with an integrated strategy for energy and for cooling.
*  And so basically any form of energy that you have, you know, that you could do in a very efficient way, in a very clean way, you know, or new energy technologies, you know, this AI is a use case for developing and deploying that kind of power.
*  And so, you know, just just building what we've seen from Internet data centers that could be geothermal, that could be hydroelectric, that could be nuclear fission, that could be nuclear fusion, solar, you know, wind, big battery packs and so forth.
*  And so the I think the aspirational hope would be this is sort of another catalyst to more advanced rollout of energy.
*  And even if there's sort of net energy increase, the sort of motivation to get the higher levels of efficiency will be will be net good in helping us get to a better energy footprint.
*  And which of those energy sources, in your view, is most underrated?
*  Oh, I mean, nuclear fission for sure is the most underrated today.
*  And so, you know, there ought to be there ought to.
*  Yes. The wave of magic one.
*  We ought to be doing what Richard Nixon proposed in 1971.
*  Right. We ought to build what he called project independence, which was built, built a thousand new nuclear power plants in the U.S.
*  and then cut the entire U.S. grid over to nuclear and electricity, go to all electric cars, do everything else.
*  Richard Nixon's other great, great, great corresponding creation, the Nuclear Regulatory Commission, of course, guarantees that won't happen.
*  The the plan is exactly exactly on track.
*  But we could. And so either with existing nuclear, you know, nuclear fission technology, or there's actually a significant number, you know, now of new nuclear fission startups as well as fusion startups working on new designs.
*  And so this would certainly be a great use case for that.
*  So if the nations that will do well in the future are strong in a and strong in energy, thinking about this in terms of geopolitics, which countries rise in importance for better or worse?
*  Yeah. So well, so OK, so different things.
*  Add a couple more things to that, which is which companies are in a position to best invent these new technologies.
*  And then there's a somewhat somewhat separate question of who's in the best position to deploy because it doesn't help you that much to invent it if you if you can't deploy it.
*  And so I would put that in there.
*  But, I mean, look, I would give the the US I would give the US like a very, very high marks on the invention side.
*  I think we're you know, we I think we're the best.
*  I think we have the best R&D innovation capability in the world and in most fields, not all, but most.
*  And I think that's certainly true of AI.
*  And I think that's at least potentially true in energy.
*  I don't know whether it actually is, but it could be.
*  And so, you know, we should be able to forge ahead on that.
*  You know, China is clearly the other country with critical mass in all of this.
*  And, you know, you could quibble about the level of invention versus sort of fast, fast, follow and and talk about, you know, kind of IP, IP acquisition, things like that.
*  But nevertheless, whatever your view is, they're they're they're moving very quickly and aggressively and have have critical mass, you know, big internal domestic market and a huge number of researchers and a lot of state support.
*  So I think by and large, you know, we're looking for sure on AI and then I think probably also in energy, we're probably looking at a primarily a bipolar world for quite a while.
*  And then spheres of influence, you know, kind of going out, you know, I would say Europe, Europe is sort of a dark horse in a sort of a strange way in that the EU seems absolutely determined to ban everything,
*  to sort of put a blanket ban on capitalism and within that ban, I ban energy.
*  But on the other hand, you know, we have this incredible AI company called Mistral in France, which is the leading open source AI company right now and one of the best AI companies in the world.
*  And the French government has actually really been stepping up to help, you know, the ecosystem in Europe.
*  And so I would I would I would actually like to see sort of a tripolar world.
*  I'd like to see the EU kind of fully, fully punch in.
*  But I'm not sure how realistic that is.
*  So let's say you're in charge of speeding up deployment in the United States.
*  What is it you do? State level, local level, feds?
*  What should we all be doing?
*  Of AI specifically?
*  Everything, because it's all increasingly interrelated, right?
*  It is.
*  AI, energy, biomedicine, everything.
*  Yes. Yes. Well, and AI takes you straight to chips, which takes you straight to the chips act, which exactly has not yet resulted in the creation of any chip plants, although it might someday.
*  The most basic observation is maybe the most of it all, which is, you know, stagnation is a choice, decline is a choice.
*  You know, that as Tyler's written at great length, you know, the U.S. economy downshifted its rate of technological change, you know, basically since the 1960s in technological change
*  as measured by productivity growth in the economy was much faster prior to the last 50 years than the most recent 50 years.
*  And, you know, that that's just the result of just sort of a, you know, you have big argument as to exactly what caused that.
*  But a lot of it is just an imposition of just like, you know, blankets and blankets and blankets of regulation and restrictions and controls and processes
*  and procedures and all the rest of it.
*  So, yeah, so, you know, and then you could start by saying step one is do no harm.
*  And so, you know, this is sort of this is our approach on AI regulation, which is, you know, don't regulate the technology, don't regulate AI as a technology anymore than you regulated microchips or software or anything like operating systems or databases.
*  Instead, regulate the use cases and these cases are generally regulated anyway.
*  It's no more legal to field a new AI design drug without FDA approval than it is a standard design drug.
*  And so apply the existing regulations as opposed to hamstringing the technology.
*  You know, so that's one, you know, energy exploitation.
*  Again, energy is just pure choice.
*  Like we could be building, you know, we could be building the, you know, the thousand nuclear plants tomorrow.
*  My favorite idea there, which always gets me in trouble and so I can't resist is so the Democratic administration should give coke industries the contract to build a thousand nuclear reactors.
*  Everybody gets revenge and everybody else.
*  The Democrats get Charles Coke to fix climate change and then Charles gets all the money for the contracts.
*  And so it's kind of a everybody ends up happy.
*  Nobody yet has bit on that idea when I pitched it.
*  But maybe I'm not talking to the right people.
*  So, you know, look, you know, we could be doing that.
*  You know, we'll we'll see if we choose to look at the chips plant thing is going to be fascinating to watch.
*  There was this really, you know, we passed the chips act and in theory the funding is available and you know, the American chip companies are generally pretty aggressive and I think trying pretty hard to build new capacity in the US.
*  But there was this actually very outstanding article in the New York Times some months back by Ezra Klein where he sort of goes through and he says, OK, even suppose the money is available to build chip plants like is it actually possible to build chip plants in the US?
*  And he sort of talks about all of the different regulatory and legal, you know, basically requirements and obligations that get get layered on top and, you know, sort of speculating as to whether any of these plants will actually get built.
*  So, again, I think we have here we have just sort of a level of fundamental choices in society, which is, you know, do we want to do we want to build new things?
*  I can't say how exciting it's been at least on the West Coast.
*  How exciting it's been for Las Vegas to get the sphere because like it's now impossible to visit Las Vegas without like like everybody's always complaining.
*  The Egyptians built the pyramids like where are pyramids?
*  And it's like, ah, we have a sphere like and so just like flying into Vegas just gets your juices flowing like gets you all fired up because like this thing is like amazing.
*  And by the way, I'm just talking about the view from the outside.
*  I understand that the thing on the inside is also amazing.
*  And so, you know, we clearly can do that, you know, at least in Vegas where Ben lives now, you know, in London, I think they just gave up on building the sphere.
*  So that's you know, that's that's that's the other side of it.
*  And so, you know, we do we do have to decide whether we want these things to happen.
*  You know, it's a little bit dispiriting to see the liquid natural gas decision that just came down.
*  But are the roots of this stasis quite general and quite cultural because parents coddle their children much more.
*  They're higher rates of mental illness amongst the young young people.
*  It seems have less sex along a lot of cultural variables.
*  Have the percent of old music people listen to compared to new music.
*  It seems to be a more general stagnation.
*  So how would you pinpoint our loss of self-confidence or dynamism?
*  Where's that coming from?
*  Yeah.
*  Well, so first of all, to be clear, we're very much in favor of young people not dating because that's very distracting from their work at our startups.
*  So that that works out fine.
*  And fortunately, in our industry, we have a long long experience with not having it having dating lives when we're young.
*  So that works out well.
*  So it's not all bad.
*  So it is really interesting.
*  I mean, it's just that, you know, the view is experience.
*  I mean, look, Silicon Valley has like all kinds of problems and we're kind of a case study for a lot of the I mean, look, it's not like you can build anything in Silicon Valley.
*  Right.
*  So we've got I mean, our politicians absolutely hate us and they don't let us do anything if they can avoid it.
*  So, you know, we have our issues, you know, the view from the Valley is, you know, yeah, a lot a lot of kids are being brought up and trained, you know, to basically adopt this sort of fundamentally pessimistic, you know, sort of pessimistic or,
*  you know, sort of how to put it like, you know, stagnation oriented in there, like, you know, have very low expectations, you know, basically, you know, a lot a lot of what passes for education.
*  Now is kind of teaching people how to complain, which they're very good at.
*  The complaining has reached reached operatic levels lately.
*  And so there is a lot of that, you know, having said that, look, I'm also like actually really optimistic and in particular, I'm actually quite optimistic about the new generation coming up.
*  I think Gen Z and then and then I think it's Gen Alpha and then it's whatever my eight year old is.
*  We're seeing more and more kids that are coming up and they're being sort of exposed to a full load of basically, you know, programming, sort of cultural programming, education programming that says you should be depressed about everything.
*  You should be upset about everything.
*  You should have low ambitions.
*  You shouldn't try to do these things.
*  And they're coming out with sort of a very radical, you know, kind of hard shove in the other direction.
*  And they're coming out with just basically coming up with, you know, tremendous energy and tremendous enthusiasm to actually do things.
*  And so which is very natural, right?
*  Because kids rebel.
*  And so if the system is teaching stagnation, then kids, at least some kids will come up the other way and decide they really want to do things in the world.
*  And so I think entrepreneurs in their 20s now are a lot better than certainly my generation.
*  And they're frankly more aggressive than the generation that preceded them.
*  And they're more ambitious.
*  And so now, you know, we're not dealing with it.
*  We're dealing with a minority, not a majority.
*  But I think there's quite a bit like, yeah, every every hour I get when I can spend a 20 year olds is actually very encouraging.
*  One emotional sense I get from your walk on music, Beethoven's Fifth Symphony, is that the stakes are remarkably high.
*  Now, if we're looking for indicators to keep track of whether in essence things are going your way, greater dynamism, freedom to build, willingness to build,
*  American dynamism, what should we track?
*  What should we look at?
*  How do we know if things are going well?
*  Yeah, I do not come here and do not come to the world with like comprehensive answers.
*  I mean, so the overall answer is productivity growth in the economy is a great, you know, is a great starting point.
*  Economic growth is a great starting point.
*  You know, so the overall questions are there.
*  You know, most of our economy is dominated by, you know, incumbent institutions that, you know, have no intention.
*  I don't think of changing or evolving unless they're forced to.
*  You know, certainly most of the business world now is, you know, one form of oligopoly or another that sort of has various markets locked up.
*  So I don't think there's some like magic bullet to hugely accelerate things.
*  You know, having said that, you know, I think, you know, attacking from the edges, you know, is the thing that can be done, which is basically what, you know, what we do, what Silicon Valley does.
*  And then, you know, when you attack from the edges, the way that our entrepreneurs do, you know, look, a lot of the times they don't succeed.
*  You know, it's a high risk, you know, occupation with a lot of risk of failure.
*  But when they succeed, you know, they can succeed spectacularly well.
*  And, you know, a lot of our I mean, we, you know, we have we have companies, you know, we have companies, the American economy that were venture backed in the 1970s.
*  And actually even some that were venture backed in the 1990s and 2000s, you know, that are now bigger than most national economies.
*  Right. And so, you know, when these was it Apple?
*  I think Apple's market cap is bigger than the entire market cap of the German stock market.
*  I think that's right.
*  Just one company.
*  And, you know, Apple was a venture backed startup, you know, two kids in a garage and, you know, 1976, not that long ago.
*  It's bigger than the entire German, you know, basic industrial public public market.
*  And so, you know, attacking the edges, you know, sometimes you can get really, really big results.
*  Sometimes you get, you know, you just prod the system.
*  You know, sometimes you just spark people into reacting and that pushes everything forward.
*  And then the other question always is just like, what are the tools that you know, from our standpoint, what are the tools that startups have in order to, you know,
*  sort of in order to try to really change things?
*  And, you know, there's a bunch of such tools, but there's always two that really dominate.
*  And one is just what's the magnitude of the technological change in the air that can be harnessed?
*  And so we're always looking for kind of the next super cycle, the next breakthrough technology in which you can imagine a thousand companies doing many different things, all kind of punching into incumbent markets.
*  And AI certainly seems like one of those.
*  And then, yeah, the other is just the sheer sort of animalistic ambition, energy, animal spirits.
*  Of the of the entrepreneurs and of the teams that get built.
*  And like I said, I think those are even I think those are I think I think I think the best of the startups today are more aggressive, more ambitious, more capable.
*  The people are better.
*  They execute better than than at least I've ever seen.
*  So I think that's also quite positive.
*  Who's a social thinker who helps you make sense of these trends?
*  Oh, yeah, my favorite is James Burnham is my favorite who I burn him.
*  Why burn him?
*  Yeah.
*  So Burnham is a famous Burnham is a not famous, but he should be famous.
*  He was a Burnham is a fascinating story.
*  He's a thinker in the 20th century who talked a lot about these issues.
*  He started out life as a lot of people do in the 1920s as a in 30s as a dedicated Trotskyite full on full on communist.
*  And but he's very special guy.
*  Burnham was a very brilliant guy.
*  And so he was such a dedicated communist that he was close personal friends of Leon Trotsky, which is how you really know you've really know how you've made it when you're when you're a communist.
*  And he would have these like huge arguments Trotsky, you know, which is not the safest thing in the world to do.
*  But apparently he got away with it and very enthusiastic, you know, communist revolutionary through the through the 30s and then sort of in the 40s.
*  He's, you know, very smart guy.
*  He started to figure out that was a bad path.
*  And he went through this process of rethinking everything.
*  And by the 1950s, he was so far to the right that he was actually a co-founder of National Review magazine with with William Buckley, who always said he was a very smart guy.
*  And so, you know, he's kind of got he's got he's got kind of works that he wrote that will accommodate the full spectrum of politics.
*  But in his middle period where he was trying to kind of figure out, you know, this is like in the 1940s, he was trying to kind of figure out where things are going.
*  And there and there was a norm.
*  There were enormous questions in the 1940s because it was viewed as like a three way basically war for the future between communism, you know, the far left fascism, the far right, the far left, the far left, the far right.
*  And then and then liberal democracy kind of floating around there somewhere.
*  His best his best, most well known book is called The Managerial Revolution, which talks a lot about the issues we've been discussing.
*  And it was written in like 1941.
*  And it's fascinating for many reasons, part of which is he was still mad about communism.
*  So a lot of it is he debunks communism in it.
*  But also, you know, they didn't know who was going to win World War Two.
*  And so it talks about this battle of ideologies as if it were still a battle of ideology.
*  Which is super interesting.
*  But he did this very kind of sort of Marxian analysis of capitalism.
*  He made the observation that I see every day, which is there are fundamentally two types of capitalism.
*  There's the original model of capitalism, which he calls bourgeois capitalism, which you could think like Henry Ford is the archetype of that.
*  So a capitalist starts a company, runs the company name on the door, and then he's like, well, I'm going to go to the market.
*  You know, sort of complete alignment of a company with an individual.
*  And then he talks about this other emerging form of capitalism at that time called managerial capitalism.
*  And in managerial capitalism, you think about today's modern public companies, right?
*  Think about think about Walmart or whatever any any any public company where, you know, in theory, there are surehold companies that are going to be the most successful.
*  But what really what there are is there are millions and millions of shareholders that are incredibly dispersed, you know, who own small, you know, everybody in this room on some three shares of Walmart stock and mutual funds somewhere.
*  You don't wake up in the morning wondering what's happened to Walmart.
*  It doesn't even occur to you to think about yourself as an owner.
*  And so what you get instead is this managerial class of actually both investors like fund managers and then also executives and CEOs.
*  And they have sort of they have sort of they have control, but without, you know, without ultimate responsibility, right?
*  Without ultimate without ultimate ownership.
*  And the interesting thing he said about that is he said, look, managerialism is basically it's not it's not that it's good or bad.
*  It just is sort of necessary because, you know, companies and institutions and governments and all the rest of the world are going to be the most successful.
*  And so you get a sense of what's going on in the market.
*  It's not that it's good or bad. It just is sort of necessary because, you know, companies and institutions and governments and all the rest of it get to the point where there's too big and too complicated for one person to run everything.
*  And so you're going to have the emergence of this managerial class is going to run things.
*  But there's a there's a flip side of it, which is the people who are qualified to be managers of large organizations are not themselves the kind of people who become bourgeois capitalists.
*  They're the other kind of person.
*  And so they're often good at running things, but they generally don't do new things.
*  They generally don't seek to disrupt or seek to create or seek to invent.
*  And so one way of thinking about kind of what's happened in our system is capitalism used to be bourgeois capitalism.
*  It got replaced by managerial capitalism without actually changing the name.
*  That will necessarily lead to stagnation.
*  And by the way, that may be necessary that that happens because the systems are too complicated, but that will necessarily lead to stagnation.
*  And then what you need is basically the resumption of bourgeois capitalism to come back in and kind of at the very least like poke and prod everybody into action.
*  And that, you know, aspirationally is what is what is what we do and what our startups do.
*  Mark Andreessen, thank you very much. Good. Great. Thank you, everybody.
