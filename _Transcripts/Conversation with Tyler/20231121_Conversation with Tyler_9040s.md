---
Date Generated: February 14, 2025
Transcription Model: whisper medium 20231117
Length: 9040s
Video Keywords: ['Economics', 'Policy', 'Culture', 'Lifestyle', 'Society']
Video Views: 135
Video Rating: None
Video Description: In this special episode, Rob Wiblin of 80,000 Hours has the super-sized conversation he wants to have with Tyler about Stubborn Attachments. In addition to a deep examination of the ideas in the book, the conversation ranges far and wide across Tyler's thinking, including why we won't leave the galaxy, the unresolvable clash between the claims of culture and nature, and what Tyrone would have to say about the book, and more.

Transcript and links: https://conversationswithtyler.com/episodes/rob-wiblin-interviews-tyler/

Recorded September 21st, 2018 

Stay connected:
Follow us on X, IG, and Facebook: @cowenconvos
https://www.twitter.com/cowenconvos
https://www.facebook.com/cowenconvos
https://www.instagram.com/cowenconvos

Join us on Discord: https://discord.gg/JAVWP7vTxt

https://conversationswithtyler.com

https://mercatus.org
---

# Rob Wiblin interviews Tyler on *Stubborn Attachments* | Conversations with Tyler
**Conversation with Tyler:** [November 21, 2023](https://www.youtube.com/watch?v=IpXYTHnj7iM)
*  Conversations with Tyler is produced by the Mercatus Center at George Mason University, [[00:00:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=0.0s)]
*  bridging the gap between academic ideas and real-world problems. [[00:00:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8.42s)]
*  Learn more at mercatus.org. [[00:00:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=12.82s)]
*  And for more conversations, including videos, transcripts, and upcoming dates, visit conversationswithtyler.com. [[00:00:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=15.34s)]
*  Today's episode of Conversations with Tyler is in fact a conversation with Tyler, with myself as the victim. [[00:00:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=30.0s)]
*  And we have here to interview me Robert Wiblin, who is one of the interviewers I most respect and indeed envy. [[00:00:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=37.52s)]
*  Robert is director of research at a nonprofit called 80,000 Hours, and their mission is to figure out and then communicate to people [[00:00:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=44.4s)]
*  how they can do the most good with their careers. [[00:00:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=52.24s)]
*  Robert is a long-standing leader in the Effective Altruism Movement. [[00:00:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=54.879999999999995s)]
*  He runs an excellent podcast called the 80,000 Hours Podcast, and he is from Adelaide. [[00:00:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=58.8s)]
*  Now with all that, we're here to discuss, among other things, my latest book published by Stripe Press called Stubborn Attachments, [[00:01:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=64.88s)]
*  a vision for a society of free, prosperous, and responsible individuals. [[00:01:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=73.28s)]
*  But of course, in the tradition of these interviews, Robert is free to arrange to wherever he wants. [[00:01:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=78.24s)]
*  Robert, thank you for coming on. [[00:01:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=83.12s)]
*  Thanks so much. It's a real privilege to be able to interview you. [[00:01:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=84.56s)]
*  I think you've had perhaps more influence on me than any other writer. [[00:01:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=87.84s)]
*  I'm sure I've spent thousands of hours reading Marginal Revolution over the last 10 or 12 years. [[00:01:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=91.60000000000001s)]
*  Oh, thank you. [[00:01:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=96.0s)]
*  In fact, I think it was reading Marginal Revolution that prompted me to switch into studying economics when I was an undergraduate. [[00:01:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=96.56s)]
*  So you've had a pretty substantial influence on my career, or at least you sped it up. [[00:01:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=102.0s)]
*  And I guess just to be clear, as for all of these episodes, this is the conversation with Tyler that I want to have, [[00:01:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=105.28s)]
*  not necessarily the one that you want to listen to. [[00:01:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=109.84s)]
*  And we've got perhaps enough questions here for two interviews, so we'll be trying to move pretty fast. [[00:01:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=112.08000000000001s)]
*  But first, I always open episodes of the 80,000 Hours podcast with the question, [[00:01:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=116.08s)]
*  what are you working on at the moment and why is it really important work? [[00:01:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=119.36s)]
*  I have started a new project called Emergent Ventures, which is a new approach to philanthropy. [[00:02:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=122.0s)]
*  So the idea of Emergent Ventures is to create a philanthropic fund which will support projects [[00:02:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=128.24s)]
*  that are maybe too weird or too small or too foreign or have results that are too hard to measure [[00:02:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=133.6s)]
*  to be accepted by other major foundations. [[00:02:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=139.6s)]
*  So people are applying to Emergent Ventures. The final decision maker is myself. [[00:02:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=143.04s)]
*  There is a minimum of bureaucracy. There are no layers of approval people must go through for me to see the proposal. [[00:02:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=147.92s)]
*  And we are just now starting to hand up grants. Think of it as a kind of pop-up philanthropy. [[00:02:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=154.07999999999998s)]
*  Yeah, so what are the key selection criteria that you're going to use to judge who gets the money and who doesn't? [[00:02:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=159.35999999999999s)]
*  It should be people who are smart, have good values, really believe in what they're doing, [[00:02:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=164.23999999999998s)]
*  and have been at it for some while, but also just that they're doing something unusual that will be falling into the nooks and crannies. [[00:02:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=170.32s)]
*  So we're getting plenty of good proposals in, but my reaction for some of them is, [[00:02:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=176.79999999999998s)]
*  well, you're going to get support for this elsewhere. And those are some of the ones who are turning down. [[00:03:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=180.88s)]
*  Yeah, so you're really going hard on the kind of neglectedness criteria. [[00:03:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=185.04s)]
*  That's correct. And overall, people where we feel we can change or alter the trajectory of their careers or speed it up [[00:03:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=187.92s)]
*  is something we're looking at quite closely. [[00:03:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=195.51999999999998s)]
*  Yeah, I think in the Affective Autism community, we tend to give top priority to making sure that people are working on a really pressing problem. [[00:03:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=197.52s)]
*  So a problem that has a really huge scale that's plausible you can solve and also that it's neglected by other people. [[00:03:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=203.84s)]
*  Do you think it's more important to focus on finding opportunities that other people aren't funding or to make sure that people are working on problems where they can have the largest impact? [[00:03:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=209.04000000000002s)]
*  You know, if you talk to venture capitalists in the Bay Area where we're chatting, they tend to focus much more on the person than the project. [[00:03:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=216.16000000000003s)]
*  For Emergent Ventures, I think we need both the person and the project, but I still take a person first approach. [[00:03:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=223.52s)]
*  If you don't have the right person, the project simply cannot come off. [[00:03:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=229.04s)]
*  So first and foremost, you're trying to figure out like who's talented enough to do something new. [[00:03:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=232.72s)]
*  Yeah. And throughout your career, kind of how much is doing good guided your choice of what to work on? [[00:03:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=236.96s)]
*  Very little. I'm quite a selfish person, I think, and I enjoy pursuing my own curiosity. [[00:04:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=241.04s)]
*  Part of me at the meta level hopes that does some good, [[00:04:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=247.04s)]
*  but I don't think altruism is really for me a fundamental driving force. [[00:04:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=249.84s)]
*  I enjoy absorbing information and communicating it to other people. [[00:04:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=253.76s)]
*  And that's for me what is fun. [[00:04:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=258.08s)]
*  Yeah, it's interesting how much good people can do incidentally. [[00:04:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=260.08s)]
*  All right, so let's move on to the book, Stub and Attachments, which I guess is coming out in October 16th. [[00:04:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=262.96s)]
*  Yes. [[00:04:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=267.76s)]
*  Yeah, so this is a really fascinating book because it just covers many issues that I've been thinking about for the last 15 or 20 years that I think that people should spend a lot more time thinking about like time. [[00:04:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=268.56s)]
*  How should we think about the long term future? [[00:04:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=278.32s)]
*  How should we be aggregating welfare and outcomes between different people? [[00:04:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=279.92s)]
*  Should we be following rules or just considering every case individually? [[00:04:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=283.2s)]
*  How should we deal with like the massive uncertainty about the effects of our actions? [[00:04:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=286.64s)]
*  Should we respect human rights? [[00:04:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=289.92s)]
*  And like how much should we defer to kind of common sense morality versus thinking things through for ourselves? [[00:04:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=291.28000000000003s)]
*  And perhaps it's especially interesting because I agree with you on so many points where I think other people don't, [[00:04:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=295.52s)]
*  but then we like slightly diverge at the conclusions about what we actually ought to do practically. [[00:04:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=299.68s)]
*  So I guess, yeah, take it away. [[00:05:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=303.84000000000003s)]
*  How would you summarize the key messages of this book and how did you come to write it? [[00:05:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=305.59999999999997s)]
*  The underlying message of the book is simply we're capable of making rational judgments about what is better for society. [[00:05:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=308.71999999999997s)]
*  And in my own discipline, economics, there's a longstanding thread of skepticism about that. [[00:05:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=316.32s)]
*  So Kenneth Arrow developed an impossibility theorem. [[00:05:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=321.76s)]
*  There are a lot of results that imply you can't say much about what's actually better. [[00:05:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=324.79999999999995s)]
*  So this book is in synthesis of economics and philosophy, [[00:05:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=329.76s)]
*  and it's trying to argue to both economists and philosophers, but also ordinary readers. [[00:05:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=333.52s)]
*  There is a such thing as what is objectively good. [[00:05:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=338.24s)]
*  It is based on the idea of supporting economic growth. [[00:05:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=341.84s)]
*  That's the one thing that over time we can say is much better than the alternative of not having as much economic growth. [[00:05:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=345.59999999999997s)]
*  And a lot of the philosophical arguments are directed toward how should we think about the future is something less valuable [[00:05:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=352.71999999999997s)]
*  simply because it's far away in time. [[00:05:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=358.96s)]
*  And I think you and I agree on this point that we should be much more future regarding. [[00:06:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=361.2s)]
*  And then the book thinks through if we treat the more distant future as just as valuable as the near future. [[00:06:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=365.76s)]
*  What does that imply for our actual decisions? [[00:06:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=372.47999999999996s)]
*  And that, again, to me, brings us back to this point that we ought to be maximizing the rate of sustainable economic growth. [[00:06:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=374.79999999999995s)]
*  It's a very different normative standard than what you get from, say, Rawls, Nozick, Parfit or others. [[00:06:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=380.88s)]
*  Yeah. So I guess if I had to pick out 50 words from the book that summarized it, [[00:06:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=385.28s)]
*  I would choose this quote from page 32, which is we can already see that three key questions should be elevated in their political and philosophical importance, namely, [[00:06:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=388.48s)]
*  number one, what can we do to boost the rate of economic growth? [[00:06:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=396.0s)]
*  Number two, what can we do to make civilization more stable? [[00:06:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=398.56s)]
*  And number three, how should we deal with environmental problems? [[00:06:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=401.20000000000005s)]
*  Does that seem like a key quote to you as well? [[00:06:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=403.84000000000003s)]
*  Absolutely. [[00:06:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=405.28000000000003s)]
*  Yeah. So maybe let's show you out in a couple of key ideas. [[00:06:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=406.0s)]
*  So one is the Crisonia plant and compounding growth. [[00:06:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=409.12s)]
*  What do you talk about there in the book? [[00:06:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=412.24s)]
*  The Crisonia plant is a somewhat obscure reference. [[00:06:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=413.6s)]
*  It's taken from the works of Frank Knight, University of Chicago economist. [[00:06:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=416.16s)]
*  And Knight postulated there was such a thing as a Crisonia plant. [[00:07:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=420.32000000000005s)]
*  It was a hypothetical. [[00:07:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=423.36s)]
*  It would simply keep on growing forever. [[00:07:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=424.56s)]
*  So it would be a very high value. [[00:07:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=426.56s)]
*  It's like an apple tree. [[00:07:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=428.08000000000004s)]
*  Seeds fall, you get more apples. [[00:07:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=429.28000000000003s)]
*  Those seeds in turn get you more apple trees and so on and so on. [[00:07:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=431.20000000000005s)]
*  That's like exponential compounding growth. [[00:07:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=434.0s)]
*  So if you don't discount the future at a very high rate, if you had such a thing as a Crisonia plant, it would be very valuable. [[00:07:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=436.88s)]
*  And then if you ask, well, what in fact is a Crisonia plant? [[00:07:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=444.4s)]
*  It's a modern, well-functioning economy that does generate more output every period, has something like an exponential rate of growth, and it's highly valuable. [[00:07:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=447.28s)]
*  So we want to cultivate, again, economic growth. [[00:07:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=455.52s)]
*  Why do you think that the economy grows in this way where kind of shocks or improvements seem to be permanent or at least semi-permanent? [[00:07:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=458.23999999999995s)]
*  People generate new ideas and most new ideas don't disappear. [[00:07:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=464.23999999999995s)]
*  You can lose a new idea or have a dark ages. [[00:07:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=468.23999999999995s)]
*  But if you have good institutions, you build upon those new ideas. [[00:07:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=471.12s)]
*  Also, you can have increases in labor supply and capital. [[00:07:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=475.6s)]
*  Think of those as some key sources of economic growth. [[00:07:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=478.32s)]
*  I remember when I studied time series econometrics, we would sometimes look at series of GDP and you could sometimes see that they're a unit root, which is to say, at least in some cases, they would seem like they had a unit root or unit root. [[00:08:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=480.8s)]
*  Just to say that like any shocks to GDP seem to be permanent. [[00:08:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=491.04s)]
*  And then we just kind of moved on from that. [[00:08:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=494.8s)]
*  And I was like, wait a minute, doesn't this imply that any kind of small perturbations that we have today will just have effects that could last hundreds of thousands of years if this persists? [[00:08:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=496.08s)]
*  And therefore could be of enormous moral importance. [[00:08:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=503.36s)]
*  And I guess you're kind of following through on this logic and saying if it is the case that improvements to productivity or whatever else do just last for extremely long times, then they could have enormous moral significance. [[00:08:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=505.76s)]
*  And we seem to see in the data that countries that have done well several hundred years ago, that has persistent effects even ranging up through today. [[00:08:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=513.6s)]
*  There's even one paper suggesting how well a region was doing in the year 500 as predictive power for how well it's doing today. [[00:08:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=521.36s)]
*  Yeah, and that's not probably not only kind of economic or financial issues, but also cultural. [[00:08:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=528.24s)]
*  Absolutely. [[00:08:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=532.64s)]
*  I think of culture as one of the keys behind economic growth, in fact. [[00:08:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=533.6s)]
*  Yeah. So some listeners might be listening to this and thinking, well, yeah, it might be the case that if we grow GDP today, this will also increase GDP in a thousand years time. [[00:08:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=537.04s)]
*  But I don't really care about a thousand years in the future. [[00:09:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=544.64s)]
*  What would you say to try to convince them that a thousand years in the future does have an impact? [[00:09:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=547.6s)]
*  And what would you say to them that a thousand years in the future does have important moral significance? [[00:09:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=551.2s)]
*  Well, imagine our ancestors sitting around, say, a thousand years ago, saying they didn't care very much about us and they were willing to accept a growth rate, say a percentage point lower than what has been the case for the last thousand years. [[00:09:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=554.5600000000001s)]
*  We would all right now be in extreme poverty. [[00:09:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=567.5200000000001s)]
*  We would be suffering. [[00:09:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=569.84s)]
*  Life expectancy would probably be something like 40 years of age. [[00:09:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=571.0400000000001s)]
*  We wouldn't have created a lot of artistic and cultural wonders. [[00:09:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=574.6400000000001s)]
*  We would have been supported by economic growth. [[00:09:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=578.08s)]
*  And that's the most fundamental thing we should be willing to endorse at a macro level. [[00:09:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=580.08s)]
*  So why do you think that the long term future, you know, kind of like, you know, Earth after you and I have ended our natural lives, why could that be like very valuable all of that all that time? [[00:09:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=584.4s)]
*  The future Earth can support so much wealth, so much diversity, so much prosperity, liberty, aesthetic values, whatever we hold dear, our carrying capacity for doing more of that by having more productivity, better governance, better institutions. [[00:09:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=593.6800000000001s)]
*  There's so many possibilities out there in the future. [[00:10:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=607.76s)]
*  We just need to actually bring them about. [[00:10:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=610.0s)]
*  So if you had to kind of figure out the expected number of like future humans that might live in the future, it could, of course, be very small. [[00:10:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=612.3199999999999s)]
*  We could go extinct soon or it could be very large if we last a very long time. [[00:10:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=619.2s)]
*  Would you would you want to venture a guess for the expected value? [[00:10:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=622.16s)]
*  Is it trillions, like trillions of trillions? [[00:10:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=624.56s)]
*  I'd rather have a pocket calculator. [[00:10:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=626.8s)]
*  I do think population will stabilize and start to decline, though probably not by very much. [[00:10:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=629.52s)]
*  And if you take a Earth with, say, an average of 10 billion people lasting for centuries, but not lasting for 50,000 years and do the calculations, you'd get it by modal prediction that there's many more of them than there is of us. [[00:10:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=634.96s)]
*  That's right. [[00:10:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=647.6s)]
*  Do you think that quality of life will also go up with like high probability? [[00:10:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=648.4000000000001s)]
*  Not forever, but for the foreseeable future. [[00:10:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=652.5600000000001s)]
*  We're in the period right now. [[00:10:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=655.2800000000001s)]
*  We're doing more to improve living standards than the world ever has before. [[00:10:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=656.48s)]
*  That will have big ups and downs, but I don't see why it has to stop. [[00:11:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=660.8000000000001s)]
*  What about people say, you know, I don't care about like welfare that much. [[00:11:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=664.16s)]
*  I care about other things. [[00:11:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=667.1999999999999s)]
*  Do you think this argument for long termism goes through for them as well? [[00:11:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=668.24s)]
*  I think it does. [[00:11:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=671.28s)]
*  I have some early books, some of them on the arts, that argue wealth is good for aesthetic values. [[00:11:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=671.9599999999999s)]
*  So it depends what other values people care about. [[00:11:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=677.8399999999999s)]
*  But wealth supports many different opportunities. [[00:11:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=679.88s)]
*  The whole point of wealth is to enable a kind of diversity and choice within a framework. [[00:11:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=682.6s)]
*  Or if there's some other thing that people value, we can have more of that, too. [[00:11:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=687.0799999999999s)]
*  Do you think, like me, that there's a chance that future technology could make human life just 100 or 1000 times better than it is for people today? [[00:11:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=691.12s)]
*  I don't know that we have a meaningful metric for saying that, but I suppose I don't think that's possible. [[00:11:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=697.92s)]
*  I think we can make it, you know, twice as good and quite a bit longer. [[00:11:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=702.4s)]
*  But I don't think it will be inconceivable to what we can imagine now. [[00:11:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=707.28s)]
*  What about just if we imagine that we find a way for people to take like the best, most enjoyable drugs that they can take today without like having negative effects on their day? [[00:11:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=713.28s)]
*  Like their brain in the long term. [[00:12:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=721.08s)]
*  It seems like that could result in a life that's 10 times better than what typically people typically experience today, at least in at least in some narrow sense. [[00:12:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=722.2s)]
*  I think if you're a pluralist, that life is maybe not better at all. [[00:12:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=729.0s)]
*  It has more pleasure. [[00:12:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=732.08s)]
*  But these other plural values seem to be weaker because you're pursuing only pleasure. [[00:12:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=733.32s)]
*  So that may be a dystopian scenario for the true pluralist. [[00:12:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=737.1600000000001s)]
*  Yeah, I suppose. [[00:12:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=740.5600000000001s)]
*  Well, maybe you could like push it out in that way on kind of all of these margins. [[00:12:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=741.64s)]
*  You get like many different things, but we do them much more efficiently. [[00:12:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=744.6800000000001s)]
*  Some people specialize in drug taking. [[00:12:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=747.9599999999999s)]
*  I'm fine with that. [[00:12:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=750.12s)]
*  It's not harmful, but I don't want the whole world to become low deceders. [[00:12:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=751.12s)]
*  OK, yeah. [[00:12:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=754.52s)]
*  So a lot of economists and people from finance are used to applying discount rates, which causes them to think that, you know, once you're 100 years out, just the consequences don't seem to matter that much. [[00:12:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=755.52s)]
*  And I guess if they applied that backwards, it would mean that kind of toot and come and thousands of years ago was like perhaps individually more important than than anyone or like everyone who's alive today. [[00:12:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=764.7199999999999s)]
*  What do you have to say to people who are used to applying discount rates and use that kind of logic to discount the future? [[00:12:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=773.8s)]
*  Discount rates are very useful for many purposes, especially if you're looking at a small project done in a single firm and you're trying to estimate how valuable to you is a cash flow, say 20 or 30 years from now. [[00:12:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=778.52s)]
*  But if you're asking a question for all of society and if you apply a discount rate of, you know, five percent, seven percent, whatever it's going to be, you can end up with the results that say, [[00:13:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=790.4s)]
*  Well, a nickel today is worth more than saving the existence of the entire world hundreds of years from now. [[00:13:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=800.1999999999999s)]
*  And that's so counterintuitive. [[00:13:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=806.28s)]
*  I think that just as we do not discount the well-being of people who are distant from us in space per se, nor should we do so across time. [[00:13:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=809.0s)]
*  Yeah, you have this neat example of what if people are able to travel close to the speed of light and how this kind of even sharpens the counterintuitiveness of using a discount rate. [[00:13:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=816.68s)]
*  What do you want to describe that example? [[00:13:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=825.04s)]
*  If one accepts Einstein's theories of relativity, which do seem to be true, albeit incomplete, as you approach the speed of light, the whole universe to you becomes like a frozen block of space time that in a sense you can watch or observe from the outside. [[00:13:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=826.64s)]
*  And in that sense, time can be thought of as a kind of illusion and simply all of the things are happening at once. [[00:14:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=842.6s)]
*  And from that perspective, you would wonder, well, why is time such a special dimension? [[00:14:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=849.0s)]
*  But another way to put the point is just to imagine we're sending astronauts up into space and we're sending them away at speeds approaching the speed of light. [[00:14:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=852.72s)]
*  They will, if they return, return in the much more distant future. [[00:14:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=861.52s)]
*  But to them, only a small amount of time has passed. [[00:14:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=865.8000000000001s)]
*  So should we take less care to preserve the well-being and lives of those astronauts simply because we're shipping them away at higher speeds? [[00:14:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=868.64s)]
*  Again, it seems like an absurd conclusion. [[00:14:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=875.64s)]
*  The notion that when you have large benefits for people that matter at the macro level, that you should apply something like a zero rate of discount to well-being, not to financial flows, but actual well-being, I think that's the correct moral position. [[00:14:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=878.08s)]
*  Yeah, so as far as I know, there's almost no moral philosophers who support discounting purely the welfare of people in the future. [[00:14:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=890.6800000000001s)]
*  Then a lot of people throughout society, and I guess influenced by economics, don't share that view. [[00:14:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=898.0s)]
*  What do you think is going on there? [[00:15:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=902.32s)]
*  Is this potentially one of the biggest moral mistakes that we're making and philosophers should be shouting about this much more? [[00:15:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=904.24s)]
*  Philosophers and economists should be shouting about it much more. [[00:15:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=908.1600000000001s)]
*  I think some of the problem is a political one. [[00:15:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=911.4000000000001s)]
*  So I find it relatively easy to convince a lot of philosophers so the moral rate of time discount should be zero, but relatively hard to get them to accept the practical implications of that. [[00:15:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=913.6s)]
*  Namely, that ongoing economic growth is a very, very positive thing, say more important than redistributing income. [[00:15:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=924.1600000000001s)]
*  Economists who tend to be more market oriented, even economists somewhat to the left, are more market oriented than most philosophers, [[00:15:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=931.0s)]
*  they're so drained that there's some kind of embedded positive real rate of interest in an economy that to then get them to accept a moral framework, [[00:15:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=938.36s)]
*  we are talking about well-being and macro effects and long periods of time, and to think in those terms and come up with the right answer of zero, that's the problem there. [[00:15:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=945.36s)]
*  But economists tend to be pretty enthusiastic about economic growth because they study it and they see its benefits pretty clearly. [[00:15:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=953.9599999999999s)]
*  Yeah. If people are convinced by this argument, are you just pointing out to me that there's a new book published called Time Biases? [[00:16:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=960.0s)]
*  Have you managed to read that yet? [[00:16:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=965.48s)]
*  I've read about half of it. It's quite good. It's by Megan Sullivan. She's a philosopher at Notre Dame. [[00:16:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=967.08s)]
*  She spends a lot of time talking about a paradox I don't consider much, which is how much you should discount the past. [[00:16:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=972.52s)]
*  So like if someone told you, well, you have amnesia, but you had a very painful operation and it happened to you a month ago, how much should you care? [[00:16:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=979.64s)]
*  And then someone says, no, it wasn't a month ago. It was two months ago. It was more distant in time. Is that like better for you? Is that worse for you? [[00:16:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=987.68s)]
*  She explores the symmetry of paradoxes of discounting forward in time compared to those with discounting backward in time. [[00:16:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=994.3599999999999s)]
*  You then go on to point out that if we're very concerned about the long term and we have the option of creating economic growth, [[00:16:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1001.16s)]
*  this potentially allows us to kind of sidestep some of the aggregation puzzles that have really worried philosophers and economists. What's your argument there? [[00:16:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1007.76s)]
*  The classic aggregation puzzle in economics is simply there's a policy. Some people are better off. Some people are worse off. [[00:16:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1014.5999999999999s)]
*  How can you possibly judge if the policy is worth doing? [[00:17:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1021.16s)]
*  There are hardly any what we as economists call Pareto improvements, policy changes that make virtually everyone off. [[00:17:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1024.1599999999999s)]
*  But over a span of a few generations, if you have a higher rate of economic growth, [[00:17:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1030.28s)]
*  people today in today's wealthier world are really as a whole, obviously much better off than say people in the 18th century or even the 19th century. [[00:17:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1035.56s)]
*  That's an aggregation judgment we can make. I think it would be supported by people's demonstrated preferences as to where they want to migrate. [[00:17:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1045.3999999999999s)]
*  And there are some obvious moral facts that if a standard of living is, say, three to five times higher in one society rather than another, the wealthier society is better. [[00:17:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1053.0s)]
*  Yeah, OK. And you then go on to argue that against the things that some people have said, wealth actually does lead to happiness. [[00:17:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1061.72s)]
*  So we're not just creating wealth for its own sake, but actually it is going to increase welfare. What's the case for that? [[00:17:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1067.1200000000001s)]
*  If you look at the data within nations across classes of income or wealth, wealthier people are simply much happier than poorer people. [[00:17:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1072.3600000000001s)]
*  There is a partial paradox. When you look at data across nations, you find a lot of poorer countries where people report they're pretty happy. [[00:18:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1080.2s)]
*  But I think what's going on there often is they're just using words differently. [[00:18:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1088.6399999999999s)]
*  So, for instance, if you poll Kenyans, how happy are you with your health care? [[00:18:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1092.08s)]
*  Kenyans actually poll as being pretty happy with their health care. [[00:18:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1095.8799999999999s)]
*  It's not that Kenyan health care is so much better than we all think. They're just used to a lower standard. [[00:18:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1098.9199999999998s)]
*  So I think when you ask people about happiness across countries, there's still a positive slope on that relationship. [[00:18:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1103.9599999999998s)]
*  But you're understating just how good wealth is for people. Wealth also helps keep people alive. [[00:18:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1109.48s)]
*  So all these polls, you're only polling the living, not polling the dead. [[00:18:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1115.36s)]
*  If you could poll all the dead people who passed away because new medicines were not invented for them or they took a riskier job and they died in an accident, [[00:18:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1118.44s)]
*  put all those people into the poll. Again, wealth is going to do much, much better. [[00:18:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1125.8400000000001s)]
*  Yeah. So I'm not entirely sure how to interpret that while being literature. [[00:18:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1129.5600000000002s)]
*  It seems potentially still kind of an open question just how much wealth increases happiness today. [[00:18:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1132.6000000000001s)]
*  But I feel like you almost didn't make the strongest argument that you could make here, [[00:18:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1137.16s)]
*  which is that even if increasing GDP or wealth today doesn't make people happier now, [[00:18:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1139.8000000000002s)]
*  at some point in the future it will once we use that wealth and that greater knowledge to figure out new technologies that can turn our wealth into welfare. [[00:19:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1144.64s)]
*  Oh, of course. But also even wealthier countries today, even if you don't think the money makes us happier, we buy more exports from poorer countries. [[00:19:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1152.8000000000002s)]
*  So the growth of China, India, many parts of the world has relied on the wealthy countries having so much to spend and having technologies to transfer. [[00:19:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1161.3600000000001s)]
*  And people in those countries are clearly much better off because of the economic growth they've had lately. [[00:19:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1169.24s)]
*  Yeah, this is a slight aside, but many people, I think, have this intuition that rich countries are harming poor countries on balance, [[00:19:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1174.12s)]
*  perhaps by absorbing investment or the smartest people from them. [[00:19:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1182.08s)]
*  But I and I think you believe that poorer countries benefit a lot from having richer, richer countries on the earth with them. [[00:19:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1185.24s)]
*  Do you just want to make the case for that? [[00:19:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1191.1599999999999s)]
*  There's very strong evidence of positive complementarities, a lot of it coming from technology transfer, using medicines or electricity, [[00:19:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1192.6s)]
*  just general production techniques, management being transferred to poorer economies. [[00:20:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1200.6s)]
*  I do think for some small island economies, there is a brain drain. [[00:20:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1204.96s)]
*  They're still better off that say, you know, the West, Japan are wealthy rather than poor. [[00:20:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1208.44s)]
*  There's not a general brain drain that we see in the data. [[00:20:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1212.8799999999999s)]
*  But if you're a very small place and people just leave and don't come back, you can, through migration, be worse off. [[00:20:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1215.6s)]
*  It doesn't mean you're worse off because the West is wealthy. [[00:20:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1220.9199999999998s)]
*  So in the book, you also speak up in favour of rules over deciding how to act based on each individual, each individual situation. [[00:20:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1223.2s)]
*  What's your argument there? [[00:20:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1230.3999999999999s)]
*  This is a longstanding paradox in philosophy about rule utilitarianism versus act utilitarianism. [[00:20:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1231.6799999999998s)]
*  So if you follow a rule, when should you deviate from the rule? [[00:20:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1238.4399999999998s)]
*  And I just point out the rule of maximising sustainable economic growth. [[00:20:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1241.8799999999999s)]
*  They're just very high costs from deviating from that rule. [[00:20:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1245.7199999999998s)]
*  So if you simply adopt the attitude, we're not going to deviate from this rule. [[00:20:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1248.6399999999999s)]
*  We're going to stick with the rule. [[00:20:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1252.08s)]
*  You're better off. It's also the right thing to do. [[00:20:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1253.4399999999998s)]
*  There's a conciliance across deontological and utilitarian approaches. [[00:20:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1255.6s)]
*  And I think the case for rules is somewhat underrated in the literature. [[00:21:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1260.48s)]
*  They don't have to be bled away by a million different exceptions. [[00:21:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1263.6399999999999s)]
*  You're just better off following the rule. [[00:21:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1266.9199999999998s)]
*  Yeah, I don't quite understand that. [[00:21:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1268.7199999999998s)]
*  So is that just because if like you might make mistakes each time you're trying to reassess whether you want to follow the rule of maximising economic growth? [[00:21:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1269.6799999999998s)]
*  Or is there something more fundamental going on here? [[00:21:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1278.28s)]
*  Each time you deviate from the rule of maximising economic growth, [[00:21:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1281.6399999999999s)]
*  you're costing the more distant future really an enormous amount of resources. [[00:21:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1285.12s)]
*  So it's just a very high price. [[00:21:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1288.8s)]
*  My argument is just a way of making vivid how high is the cost of deviating from the rule. [[00:21:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1290.52s)]
*  But if it is so important for welfare to increase economic growth, won't act utilitarianism also endorse that same behaviour? [[00:21:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1295.8s)]
*  It may very well. So there may be this broader conciliance of act and rule utilitarianism. [[00:21:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1302.0s)]
*  But thinking of it in terms of a rule we're bound to follow. [[00:21:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1306.56s)]
*  Won't cost us much at all. [[00:21:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1309.9599999999998s)]
*  Right. Yeah. [[00:21:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1311.24s)]
*  Yeah, maybe the reverse. [[00:21:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1311.88s)]
*  OK, so I guess summarising the above, I think it's kind of my view is that I'd characterise you as kind of a total global objective list consequentialism plus respect for the non-aggression principle. [[00:21:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1313.52s)]
*  Do you think that's a decent summary? [[00:22:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1324.04s)]
*  That's very close. I would say respect for human rights. [[00:22:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1325.52s)]
*  The human rights may or may not always be defined by the non-aggression principle. [[00:22:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1328.0800000000002s)]
*  I think for the most part they are. [[00:22:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1332.2s)]
*  Yeah, we haven't talked about human rights yet. [[00:22:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1333.72s)]
*  What's your case in favour of human rights? [[00:22:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1335.4s)]
*  Almost all of the book is focused on the consequentialist arguments for growth and thinking about the more distant future. [[00:22:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1337.28s)]
*  But I add in a caveat, which I don't discuss at length, and that is I think there are some cases, some things you simply ought not to do, even if it would boost long term economic growth. [[00:22:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1343.9199999999998s)]
*  So if someone were asking you to slaughter some number of innocent babies after torturing them, that's simply wrong to do. [[00:22:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1353.1599999999999s)]
*  And that's more of a caveat in the argument. [[00:22:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1360.56s)]
*  It's not something I explore much in the book, but I think there are objective rights which people hold and we should respect them and we maximise growth within that framework. [[00:22:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1362.44s)]
*  Yeah. So what fundamentally is the philosophical argument in favour of human rights? [[00:22:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1373.1200000000001s)]
*  It's intuitionist, I think, that there are simply some acts that are so horrible, a person who doesn't see them as horrible, it would be hard to have further discourse with them. [[00:22:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1377.44s)]
*  But I don't think I have much to say about rights in this book. [[00:23:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1385.64s)]
*  That's just a kind of placeholder saying to people, look, if you believe in rights as I do, you don't have to run roughshod over humans to maximise growth in every instance. [[00:23:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1387.88s)]
*  You have this out, the door is open, take the out when you need to. [[00:23:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1398.0400000000002s)]
*  Yeah. So what are some occasions when your conception of human rights comes apart from the non-aggression principle? [[00:23:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1401.5600000000002s)]
*  Because most of the examples I think you give in the book are cases where you're using kind of violence against someone. [[00:23:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1407.0800000000002s)]
*  There might be cases where you're letting people die and by letting them die, you're not committing kind of formal libertarian aggression against them, but they might have a human right that you're in some way obliged to help them. [[00:23:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1411.6s)]
*  I leave that as an open question, but I don't think we should be restricted to formal libertarian aggression as our only conception of human rights. [[00:23:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1424.04s)]
*  Yeah, OK. You also talk about the extraordinary level of uncertainty about the future and how even quite trivial acts that we take could potentially change the entire course of history. [[00:23:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1431.36s)]
*  And indeed, it might be probable that they change the course of history. [[00:24:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1440.16s)]
*  George, do you want to explain the case there? [[00:24:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1443.1200000000001s)]
*  There's an old Ray Bradbury short story about backwards time travel. [[00:24:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1444.44s)]
*  You go back in time, you step on one butterfly and the whole later history of the world changes. [[00:24:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1448.16s)]
*  So every time you stop at a traffic light sooner than later, you remix timings of people's days when they start acts of intercourse. [[00:24:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1453.68s)]
*  You know, which children are conceived? [[00:24:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1461.52s)]
*  Does Hitler end up being born or someone else kind of a near Hitler, but who does not become Hitler? [[00:24:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1463.3600000000001s)]
*  So every single thing you do, including our discussion, remixes the future course of world history. [[00:24:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1468.2s)]
*  And if you're a consequentialist, you need to take that seriously. [[00:24:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1473.6399999999999s)]
*  You need to ask, does this simply make my entire doctrine incoherent? [[00:24:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1476.24s)]
*  And the stance I take in the book is if you're pursuing this truly large, significant, grand goal of making the future much, much better off in expected value terms, that will stand above the froth of the uncertainty you create by remixing things with every particular decision. [[00:24:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1480.8799999999999s)]
*  Yeah, so this this reminded me pretty strongly of the non identity problem from from Derek Parfit, who you wrote once wrote a paper with about discounting rates. [[00:24:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1497.72s)]
*  Do you want to describe that the non identity problem? [[00:25:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1506.6799999999998s)]
*  Derek Parfit in his 1984 book, Reasons and Persons, had an example that say you would bury nuclear waste and several generations from now, the waste would say kill millions of people. [[00:25:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1508.3999999999999s)]
*  But the fact that you buried the waste would change the timings of subsequent conceptions. [[00:25:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1519.6s)]
*  So the people who are being killed a million or say a thousand years from now, they wouldn't have been born otherwise unless you had buried the waste. [[00:25:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1524.0800000000002s)]
*  So you could argue, well, I haven't harmed anyone at all by burying the waste. [[00:25:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1531.0800000000002s)]
*  I caused them to be born. [[00:25:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1534.5600000000002s)]
*  They die of a terrible cancer when they're 27 years old. [[00:25:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1535.96s)]
*  But on net, this is still following the Pareto principle. [[00:25:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1538.76s)]
*  And I think I have an argument why that's wrong. [[00:25:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1541.72s)]
*  Namely the case where you don't commit the very harmful act. [[00:25:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1544.4s)]
*  You might have different identities of people, but you'll have a much greater aggregate of good in the more distant future. [[00:25:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1547.76s)]
*  And it's not about individual identities. [[00:25:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1553.4s)]
*  So there's something a little oddly collectivist about my argument, you might say. [[00:25:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1555.44s)]
*  Yeah. [[00:25:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1559.96s)]
*  So I guess many people have something like this intuition that if you change the identities of people in the future, such that you can't see any correspondence between them in the two different scenarios, then perhaps it doesn't matter exactly what you do, because there's no specific person who you can identify who's worse off. [[00:26:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1560.3600000000001s)]
*  Do you think this is a very strong counter argument to those views? [[00:26:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1574.16s)]
*  Here's a tension I think that we all have to face up to. [[00:26:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1577.52s)]
*  Parfit talks about something called the person affecting principle. [[00:26:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1580.28s)]
*  Like how does your action affect some particular person? [[00:26:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1583.3200000000002s)]
*  But if you're willing to make aggregate judgments and engage in an act of aggregation, saying some kinds of societies are better than others or some policies are better than others, there's something in the micro foundations of that judgment that's fairly non individualistic. [[00:26:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1586.64s)]
*  So people want to be consequentialists and they want to be pure individualists. [[00:26:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1600.8400000000001s)]
*  Sometimes it's not actually a fully happy marriage of views. [[00:26:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1604.2s)]
*  And the notion that once you jam together different measurements of well-being, you're making a collective judgment about the overall course of history, even slightly Hegelian. [[00:26:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1608.92s)]
*  You could also think of this book as like a Hegelian defense of liberty. [[00:26:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1619.12s)]
*  I think I slightly messed up the explanation of the person affecting issue there, because often what's going on is people want to say, well, if you change the number of people in the future, that can't necessarily be good or bad, because there's no specific individual in both cases who is worse off. [[00:27:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1623.2s)]
*  Or better off, because you've changed the people who exist in one scenario and not the other. [[00:27:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1638.36s)]
*  They're only there in one case. [[00:27:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1642.96s)]
*  You can't say that they have a higher welfare than a specific person in the other scenario. [[00:27:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1644.2s)]
*  But then when you point out that, well, almost everything you do is going to result in there being no correspondence between the list of people in one scenario and those people in the other scenario. [[00:27:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1648.36s)]
*  And so it doesn't matter whether you bury this nuclear waste that's going to going to greatly harm people in the future. [[00:27:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1656.2s)]
*  In one case, people tend not to like that conclusion. [[00:27:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1660.84s)]
*  It just seems that it seems very counterintuitive and wasn't really what they were aiming for. [[00:27:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1663.72s)]
*  I guess you're going to take kind of the total view here, where we just kind of sum up the consequences of our actions on lots of different people. [[00:27:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1668.44s)]
*  Subject to rights constraints, yes. [[00:27:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1675.56s)]
*  Yeah. [[00:27:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1677.32s)]
*  Do you think there's any plausible alternatives to doing that? [[00:27:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1677.84s)]
*  I think the most plausible alternative is simply to say the actual time horizon is not very long. [[00:28:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1680.0s)]
*  That may be an extreme case. [[00:28:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1686.0s)]
*  Either the world will end soon or history will start collapsing and run in reverse. [[00:28:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1687.8s)]
*  So there is no grand, glorious future that has a heavy weight in the calculation. [[00:28:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1692.0s)]
*  And thus, we're always dealing with the here and now a quite pessimistic view. [[00:28:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1697.52s)]
*  I think that's the main rival view to what I put out in the book. [[00:28:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1701.36s)]
*  I don't feel I refute that argument. [[00:28:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1704.76s)]
*  It's going to be true with some probability, right? [[00:28:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1707.44s)]
*  So if you do an expected value calculation, well, you know, retrogression is true with, say, probability 37 percent, progress with 63 percent and the expected value calculation. [[00:28:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1709.8s)]
*  Progress is still going to win. [[00:28:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1720.72s)]
*  It will have the dominant weight. [[00:28:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1722.16s)]
*  But we need to be very careful. [[00:28:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1724.0800000000002s)]
*  Don't assume progress is possible. [[00:28:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1725.4s)]
*  And the other pessimistic theory of history, you know, as say a lot of the ancient Greeks would have accepted may well be true. [[00:28:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1727.8400000000001s)]
*  And if that's true, then this vision is a kind of a large mistake. [[00:28:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1733.8s)]
*  But you cannot live with pessimism, right? [[00:28:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1739.88s)]
*  There's also a notion that more optimism is a partially self-fulfilling prophecy. [[00:29:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1742.3200000000002s)]
*  Believing pessimistic views might make them more likely to come about. [[00:29:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1747.44s)]
*  Yeah. In the seminar room, it seems like economists and sometimes philosophers are not willing to aggregate welfare across people. [[00:29:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1750.84s)]
*  So say, yeah, if like one person's worse off than someone else, you just won't be able to say which of these whether overall the situation is better. [[00:29:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1756.6s)]
*  But then it seems like in their everyday life, when they're making calls about, you know, what should a group of people do, they're always willing to aggregate. [[00:29:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1764.0s)]
*  Absolutely. [[00:29:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1769.52s)]
*  And that's the immediate argument that they'll always turn to. [[00:29:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1769.84s)]
*  What do you think's going on there? [[00:29:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1772.2s)]
*  We're always willing to choose a restaurant, right? [[00:29:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1773.48s)]
*  Even if it's not the first choice of all people. [[00:29:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1775.6000000000001s)]
*  And the aggregations we make when looking at economic growth are often quite large differences in income. [[00:29:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1778.2s)]
*  But I think there's a fear amongst a lot of philosophers that if you're too willing to aggregate, utilitarianism becomes too strong and they don't like all of the consequences of that decision. [[00:29:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1784.1200000000001s)]
*  And so they try to draw the line at aggregation. [[00:29:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1794.6000000000001s)]
*  But as you mentioned, I think that's grossly inconsistent with how we treat instrumental reason in our lives and our businesses and our nonprofits. [[00:29:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1796.72s)]
*  We aggregate all the time. [[00:30:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1803.92s)]
*  We're wrong a lot, but the judgments are not completely outside the bounds of reason either. [[00:30:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1805.52s)]
*  Yeah. [[00:30:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1810.08s)]
*  Something that's even even stranger about that argument to me is that if one person is made better off in a scenario and someone else is made worse off, it's not the case that it's forbidden to do the thing where one person was made worse off. [[00:30:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1810.4s)]
*  It simply makes it incrementable with the other scenario. [[00:30:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1822.04s)]
*  So you simply can't say whether it's better or worse, I think, on this view. [[00:30:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1824.44s)]
*  So it doesn't lead to the conclusion that I think people want, which is that you should be unwilling to harm one person to benefit a large number of people as where you simply can't say whether it's better or worse. [[00:30:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1827.92s)]
*  And so kind of all bets are off. [[00:30:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1836.32s)]
*  And indeed, it's in a sense permissible. [[00:30:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1837.4s)]
*  Has that argument occurred to you? [[00:30:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1840.44s)]
*  Sure. [[00:30:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1841.56s)]
*  It's always instructive to look at how people behave as parents or maybe how they vote in a department when they're dealing with their colleagues. [[00:30:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1841.84s)]
*  And there's some form of consequentialist in all those cases. [[00:30:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1849.72s)]
*  So if you take the intuitions they're using in these smaller decisions and just build them up onto a larger scale, I think the logic of consequentialism is very, very hard to escape. [[00:30:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1853.68s)]
*  And when people say, oh, I'm a deontologist, you know, Kant is my lodestar in ethics. [[00:31:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1865.76s)]
*  I don't know how they ever make decisions at the margin based on that. [[00:31:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1871.52s)]
*  It seems to me quite incoherent that deontology just says there's a bunch of things you can't do or maybe some things you're obliged to do. [[00:31:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1874.72s)]
*  But when it's about like more or less, well, how much money should we spend on the police force? [[00:31:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1881.6s)]
*  Try to get a Kantian to have a coherent framework for answering that question other than saying like crime is wrong or you're obliged to come to the help of victims of crime. [[00:31:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1885.76s)]
*  It can't be done. [[00:31:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1894.36s)]
*  Yeah. [[00:31:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1895.28s)]
*  It's a somewhat boring moral vision where we're just prohibited from doing a bunch of stuff and then doesn't really have much more to say. [[00:31:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1896.08s)]
*  That's right. [[00:31:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1900.08s)]
*  All right. [[00:31:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1900.8s)]
*  Let's let's move on a bit from the stuff where we see things basically the same to some areas where we have a somewhat different view. [[00:31:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1901.0s)]
*  You say early on in the book, if you're the kind of reader that I want, you'll feel I have not pushed hard enough on the tough questions, no matter how hard I push. [[00:31:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1907.08s)]
*  So I'm going to try to try to try to push you here and take that to heart. [[00:31:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1913.32s)]
*  So in the book, and I guess here so far, you've been focusing overwhelmingly on the importance of increasing economic growth. [[00:31:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1916.1599999999999s)]
*  So kind of getting to a better future faster. [[00:32:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1922.9599999999998s)]
*  I guess when we're talking about growth here, we might imagine kind of time on the x axis and kind of welfare being generated in the universe on the on the y axis. [[00:32:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1925.52s)]
*  And you kind of want to want to increase that faster. [[00:32:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1931.4399999999998s)]
*  Why focus on increasing the rate rather than making sure that that doesn't go to zero? [[00:32:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1933.6399999999999s)]
*  Well, keep in mind, the core recipe is the rate of sustainable economic growth. [[00:32:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1939.48s)]
*  So if it's going to go to zero, you're knocked out of the box. [[00:32:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1944.32s)]
*  So you're maximising across both of those dimensions. [[00:32:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1947.6s)]
*  And I think empirically, there are a large class of cases where more growth and more stability come together. [[00:32:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1951.2s)]
*  National defence is the easiest way to see that. [[00:32:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1957.6799999999998s)]
*  If your society stays poor, someone will take you over. [[00:32:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1960.08s)]
*  And those who take you over are probably nasty and will harm you. [[00:32:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1963.24s)]
*  It's not the only way in which growth and sustainability come together. [[00:32:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1966.52s)]
*  But at most margins, they do. [[00:32:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1969.8s)]
*  So there's a wide enough class of cases where we can do both things at the same time. [[00:32:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1971.44s)]
*  Yeah, I would note the earlier versions of this book. [[00:32:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1975.32s)]
*  You know, I worked on this for about 20 years. [[00:32:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1978.16s)]
*  The earlier versions had much, much more on existential risk. [[00:33:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1980.32s)]
*  And it took me years to cut those out. [[00:33:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1983.48s)]
*  I never repudiated any of the ideas. [[00:33:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1985.32s)]
*  They just came up in enough other books. [[00:33:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1987.44s)]
*  I felt I wanted to stick to my core notion of growth more than existential risk and stability. [[00:33:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1989.52s)]
*  OK, yes. So that's answering some of my questions. [[00:33:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1994.8s)]
*  Because in the book, you're right. [[00:33:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1996.6s)]
*  Kind of policies that prioritize growth at breakneck speed are frequently unstable. [[00:33:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=1997.84s)]
*  The average civilisation endured only 400 years, and this number appears to be declining. [[00:33:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2001.16s)]
*  Our path in the future requires a tightrope act, balancing progress and stability along the way. [[00:33:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2005.2s)]
*  And we should believe that the end of the world is a terrible event, even if that collapse comes in the very distant future. [[00:33:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2009.16s)]
*  Similarly, the continual persistence of civilisation 300 years from now is much better than having no further [[00:33:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2013.8s)]
*  civilization at that time. But then I guess so much of the book is dedicated to kind of economic policy and, you know, [[00:33:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2018.0s)]
*  how would we increase growth rather than focusing on this other word sustainability? [[00:33:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2022.8s)]
*  Like, what are the biggest threats to sustainability in the future? [[00:33:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2026.08s)]
*  And I guess you're just saying it's been done elsewhere. [[00:33:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2028.48s)]
*  So you wanted to focus on the growth. [[00:33:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2030.28s)]
*  Richard Posner was one of the first books on this. [[00:33:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2032.04s)]
*  And when Posner's book came out, I immediately started doing a lot of editing on mine. [[00:33:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2034.68s)]
*  But you and many other people in the Effective Altruism movement have written on existential risk. [[00:33:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2039.52s)]
*  And I endorse most of that. [[00:34:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2044.44s)]
*  But just at the margin, it seemed to me growth was underestimated. [[00:34:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2046.2s)]
*  I think that one of the main, if not quite existential risks, but it's a risk to ongoing growth is just environmental issues. [[00:34:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2050.16s)]
*  And I think there's plenty we could do for the environment that also boosts growth. [[00:34:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2057.16s)]
*  So cutting down on air pollution has made people healthier, more productive, easier to live in cities. [[00:34:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2061.2s)]
*  As China cuts down on air pollution, say in Beijing, it will make Chinese society more productive. [[00:34:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2066.44s)]
*  It would be more of a problem for the argument if you thought growth and stability were always at loggerheads. [[00:34:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2072.52s)]
*  But there are large numbers of societies that collapse because they don't grow enough. [[00:34:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2078.0s)]
*  They can't fend off, you know, say drought or weather problems or problems in their agriculture in world history or they're conquered by someone else. [[00:34:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2082.24s)]
*  Do you think that still applies today? [[00:34:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2090.2799999999997s)]
*  If the United States stopped growing, I feel a lot of free countries in the world would collapse or be taken over or they would become unfree. [[00:34:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2092.08s)]
*  If we grow at a very low rate, our budget will explode. [[00:34:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2099.6400000000003s)]
*  It will cut back on our discretionary spending, our ability to advance science, to protect the earth against an asteroid coming. [[00:35:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2103.04s)]
*  So, yes, I absolutely think it applies today. [[00:35:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2109.0s)]
*  Yeah, I think I agree that if the US stopped growing, that would be very bad, principally because of the kind of cultural and political effects that that would have and perhaps that we've started to see over the last five years. [[00:35:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2111.2000000000003s)]
*  But doesn't that kind of suggest that we want is kind of a kind of sufficiently high level of growth, one that kind of keeps people happy and looking forward to the future and, you know, being willing to [[00:35:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2121.6000000000004s)]
*  like accept some negative shocks because they know that things are going to get better in the future anyway. [[00:35:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2129.32s)]
*  And that we don't necessarily have to go from, you know, 4% GDP growth to 8% GDP growth. [[00:35:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2133.88s)]
*  That's not necessarily going to make things more stable. [[00:35:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2138.28s)]
*  Well, you're talking about going from 4 to 8%. [[00:35:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2140.6800000000003s)]
*  You may or may not think that's stabilizing. [[00:35:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2143.1600000000003s)]
*  But the actual reality is we're in the midst of one of our most wonderful labor market recoveries. [[00:35:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2145.52s)]
*  There's been a big fiscal stimulus. [[00:35:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2150.8s)]
*  And year on year, we're doing 2.7, which is very poor compared to our past performance. [[00:35:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2152.6000000000004s)]
*  You see a lot of recoveries where we grow at 4% or more to get just to get back to where we were. [[00:35:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2157.44s)]
*  So the growth engine has slowed down. [[00:36:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2162.7200000000003s)]
*  There's a lot of evidence, some of which I present in my other books, that technological progress has slowed down. [[00:36:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2164.6s)]
*  So it doesn't seem to me we're close to the margin of growth being so fast that we're thrown off the track. [[00:36:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2169.76s)]
*  We have high level of debt and deficits and we don't know how to pay it off. [[00:36:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2175.7200000000003s)]
*  And we're cutting into our future capabilities with infrastructure and military defense, many areas, science. [[00:36:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2180.08s)]
*  Yeah. [[00:36:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2185.3199999999997s)]
*  So inasmuch as you're focused on economic growth in order to increase sustainability, it seems like a slightly odd focus for at least an individual to take if they want to increase sustainability, because they're already such strong incentives that many people face to try to grow the economy because they earn money from it. [[00:36:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2186.12s)]
*  They earn like either labor income or they earn returns from starting businesses. [[00:36:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2201.52s)]
*  So if like a single person wanted to maximize kind of the sustainability of human civilization, would you recommend that they focus on economic growth? [[00:36:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2205.12s)]
*  Or do you think that there's other like more leveraged opportunities if they're willing to set aside making money? [[00:36:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2212.08s)]
*  It depends on the person and what kinds of talents they have. [[00:36:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2216.36s)]
*  But as I argued in my earlier book, The Complacent Class, there now seem to be so many people who are simply satisficers. [[00:36:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2219.48s)]
*  They're not very interested in innovating or even participating in a dynamic economy, and they just try to do well enough. [[00:37:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2225.92s)]
*  So I'm here making a moral argument that at the margin, many, many people should be less complacent and take more chances. [[00:37:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2232.72s)]
*  Personally, it will lower aggregate societal risk and do more to innovate, save more, work harder, in some way be more dynamic. [[00:37:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2239.24s)]
*  You can think of this and complacent class as two sides of the bigger picture. [[00:37:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2247.3199999999997s)]
*  Complacent classes like the sociology of what we're doing, and this is the moral side. [[00:37:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2251.68s)]
*  So it seems like another technology that you might be very interested in that could have big effects on the trajectory of human civilization and potentially avoid extinction, although it also could be very negative, would be the capacity to kind of [[00:37:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2256.4s)]
*  redesign human motivation and kind of our personalities through genetic engineering. [[00:37:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2266.64s)]
*  So we could potentially select our children such that they are, say, very pacifist, such they don't want to want to kill one another. [[00:37:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2270.7999999999997s)]
*  And if you could get a large take up of this technology, that could potentially lower existential risk and get it very close to zero and give us more brighter prospects of surviving for a long time. [[00:37:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2276.64s)]
*  On the other hand, the ability to kind of redesign human personalities such that we're so passive and we'll just accept dominance would potentially, again, facilitate totalitarianism and kind of a very stable, like bad or neutral state. [[00:38:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2285.72s)]
*  What do you think of that? [[00:38:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2296.0s)]
*  I don't think we know yet how genetic engineering will affect existential risk or even long term growth. [[00:38:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2296.84s)]
*  We don't at the moment, as you know, have the capabilities really to do that. [[00:38:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2302.48s)]
*  So as we develop them, if we do, we might have a better idea. [[00:38:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2305.84s)]
*  But I think most people should be deeply agnostic and also somewhat worried about genetic engineering. [[00:38:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2310.32s)]
*  If you think we're on an OK civilizational trajectory right now relative to the human past, and then we're going to have this other major event, possibly more important than nuclear weapons. [[00:38:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2315.6800000000003s)]
*  And our current trajectory is OK relative to the more distant past. [[00:38:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2326.0800000000004s)]
*  Probably we should be more worried than cheering. [[00:38:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2330.2400000000002s)]
*  Yeah, you might take. [[00:38:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2332.5600000000004s)]
*  But given that we don't have it in front of us, it's hard to say it might all work out wonderfully. [[00:38:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2333.6800000000003s)]
*  Yeah, I guess you would think that, like, as that technology gets closer, it would be important to have people think about how do you regulate that? [[00:38:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2337.6400000000003s)]
*  How do we make it applied well rather than badly? [[00:39:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2343.1600000000003s)]
*  That kind of thing? [[00:39:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2345.48s)]
*  Of course, we should think about that. [[00:39:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2346.28s)]
*  But I'm not sure we'll succeed in regulating it very well. [[00:39:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2347.5200000000004s)]
*  There are many countries parents, I think, are willing to go to other countries. [[00:39:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2350.28s)]
*  There'll be black market versions of the technologies. [[00:39:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2353.52s)]
*  The regulation might fall to a least common denominator standard. [[00:39:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2356.36s)]
*  Like whatever we can do, I suspect we'll end up doing one way or another. [[00:39:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2360.4s)]
*  So why wouldn't put too much faith in, oh, we'll regulate out the bad versions and be left with the good ones. [[00:39:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2364.0s)]
*  We're going to get some mix of like the very good and very bad. [[00:39:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2368.84s)]
*  Yeah. [[00:39:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2371.36s)]
*  I mean, you're always just pushing on the margin, trying to make it a bit more likely that we use it good ways and a bit less likely that we use it bad ways. [[00:39:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2371.96s)]
*  Yeah. [[00:39:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2376.48s)]
*  Are there any technologies that you can foresee over the next few hundred years that you think could end up being like very important or could put humanity on a different trajectory in the same way that perhaps like nuclear weapons could have done that during the 20th century? [[00:39:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2376.8799999999997s)]
*  I think changing the nature of human beings. [[00:39:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2387.24s)]
*  And you mentioned genetic engineering, but also just drugs. [[00:39:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2389.3199999999997s)]
*  I think the opioid epidemic has grown much more rapidly than almost anyone had expected. [[00:39:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2392.12s)]
*  We had long periods of time of kind of technological stagnation in drugs because many of them were illegal. [[00:39:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2397.3199999999997s)]
*  But that also means there's a kind of low hanging fruit. [[00:40:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2404.04s)]
*  And now there's more people can do in their own labs because of information technology. [[00:40:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2406.7999999999997s)]
*  So one of my worries is that bad drugs get too much better too quickly. [[00:40:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2410.64s)]
*  And we have many things like opioids that we can't control. [[00:40:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2414.9599999999996s)]
*  And that becomes a much bigger social problem. [[00:40:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2418.08s)]
*  Just the susceptibility of people to alcohol. [[00:40:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2420.3999999999996s)]
*  We take it for granted, but so many lives are lost each year. [[00:40:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2423.08s)]
*  So many careers ruined. [[00:40:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2425.7599999999998s)]
*  So much productivity lost. [[00:40:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2427.3599999999997s)]
*  One of my kind of personal crusades is just we should all be more critical of alcohol. [[00:40:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2429.6s)]
*  People will pull out a drink and drink in front of their children. [[00:40:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2433.9199999999996s)]
*  The same people would not dream of like pulling out a submachine gun and playing with it on the table in front of their kids. [[00:40:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2436.7999999999997s)]
*  But I think it's more or less the same thing. [[00:40:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2441.7999999999997s)]
*  And to a lot of liberals, like the drink is OK and the submachine gun is not. [[00:40:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2444.3999999999996s)]
*  I think if anything, it's the other way around. [[00:40:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2448.56s)]
*  And I encourage people to just completely voluntarily abstain from alcohol and make it a social norm. [[00:40:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2450.8399999999997s)]
*  I guess if we're able to design kind of better and better addicting substances, drugs or perhaps computer games or whatever else, [[00:40:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2455.7999999999997s)]
*  it's kind of the case that the Mormons will inherit the earth or whoever is like most resistant to those temptations. [[00:41:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2461.7599999999998s)]
*  And like still wants to like have children, even despite the fact that they can just shoot up on heroin. [[00:41:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2466.6s)]
*  That's right. So I try to encourage the productive people I know at the margin to be more Mormon. [[00:41:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2470.04s)]
*  Right. You mean have more children or like avoid drugs? [[00:41:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2474.6s)]
*  Avoid addictive substances of the wrong kind. [[00:41:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2478.7599999999998s)]
*  I mean, work too is an addictive substance. [[00:41:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2481.72s)]
*  Right. Yeah. It seems that there's a difficult tightrope here because we both want people to, you know, in the short run, focus on growth and like improving civilization and so on. [[00:41:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2483.48s)]
*  But then we don't want to lock in this value that is bad to experience pleasure. [[00:41:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2490.44s)]
*  That is like because ultimately we want to kind of cash it out in something which could involve kind of like using heroin or some like much better future form of heroin. [[00:41:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2493.24s)]
*  Do you think it's like going to be possible to like have a culture that supports that delicate balance? [[00:41:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2499.72s)]
*  If you could have better drugs, but they didn't destroy people and they became the new intermediate incentive, like innovate a new product, become a millionaire, and then you can afford to buy this truly wonderful drug. [[00:41:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2503.3599999999997s)]
*  That'll be great on Sundays and won't hurt your productivity. [[00:41:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2513.64s)]
*  That seems unlikely, but right. [[00:41:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2516.7999999999997s)]
*  Who knows? [[00:41:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2518.7599999999998s)]
*  Yeah. [[00:41:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2519.44s)]
*  What is kind of your vision of the long term future? [[00:42:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2520.6400000000003s)]
*  Do you think, do you see it as we're going to have growth and then some kind of plateau or kind of go up and down or will it just continue rising forever? [[00:42:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2523.0800000000004s)]
*  I don't think the rate of growth will rise forever. [[00:42:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2531.6000000000004s)]
*  My view of economic history is that growth comes in spurts. [[00:42:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2534.5600000000004s)]
*  It's not an evenly managed process, though it was for part of the post-World War II era, that you have a thing called general purpose technologies. [[00:42:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2537.7200000000003s)]
*  One of those being like fossil fuels plus machines, which became significant in the 19th century. [[00:42:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2546.68s)]
*  And then you have a big growth spurt. [[00:42:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2552.16s)]
*  You do everything you can say with fossil fuels and machines. [[00:42:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2553.56s)]
*  You get cars, you get planes, electricity, powerful factories. [[00:42:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2556.6s)]
*  But at some point your cars only get so much better. [[00:42:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2560.56s)]
*  And then you wait for the next big breakthrough. [[00:42:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2563.72s)]
*  The next set of big breakthroughs may well involve the internet, artificial intelligence, Internet of Things. [[00:42:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2565.96s)]
*  They are not quite here yet. [[00:42:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2570.52s)]
*  You see many signs of them. [[00:42:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2571.88s)]
*  They don't make the growth rate much higher again. [[00:42:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2573.6s)]
*  And then you will have a big period of explosive growth and then a slowing down again. [[00:42:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2576.68s)]
*  That's my basic model. [[00:43:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2580.96s)]
*  Yeah. So I was thinking perhaps less about growth and more thinking just the absolute level of the economy or welfare in the universe in the future. [[00:43:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2582.32s)]
*  Do you think at some point it's just going to level off because we'll have done everything we can. [[00:43:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2590.56s)]
*  We'll have grabbed all of the matter that we can access and we'll have figured out the best configuration for it to produce value. [[00:43:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2593.7599999999998s)]
*  And at that point, it's just a matter of milking it for as long as we can. [[00:43:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2598.88s)]
*  No, I think the world will end before that happens. [[00:43:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2602.12s)]
*  I think at some point there'll be a new phase where we can directly make people in some way happier or more fulfilled or be more the people they want to be by manipulating something inside the brain. [[00:43:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2604.8s)]
*  We do that in very crude ways today with antidepressants or even Viagra. [[00:43:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2616.0800000000004s)]
*  And it's not manipulating the brain, but it seems to make people happier. [[00:43:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2620.44s)]
*  And that will be an enormous breakthrough of sorts. [[00:43:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2625.04s)]
*  It's not right before us. [[00:43:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2627.84s)]
*  I don't even think it's the next breakthrough, but it seems at some point it will be possible. [[00:43:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2628.96s)]
*  And once we exploit that frontier, it seems to me the game will be about numbers, just having more very happy, very fulfilled people. [[00:43:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2634.7200000000003s)]
*  And we'll turn our attention to making higher numbers sustainable. [[00:44:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2643.92s)]
*  I don't see any obvious limit to that process. [[00:44:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2647.76s)]
*  I do think the world will end before we complete that process. [[00:44:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2650.6400000000003s)]
*  I don't think we'll ever leave the galaxy or maybe not even the solar system. [[00:44:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2654.1200000000003s)]
*  But at some point it will just become a numbers game. [[00:44:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2657.6400000000003s)]
*  OK, yeah. [[00:44:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2660.0800000000004s)]
*  Why do you think that we won't leave the galaxy? [[00:44:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2660.6000000000004s)]
*  And also, even if you think that that's improbable, just given the fact that almost all of the potential value that we could generate is outside of this galaxy, because that's where most of the matter of energy is. [[00:44:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2662.72s)]
*  Shouldn't we be pretty focused on that possible scenario where in fact we do leave the galaxy? [[00:44:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2670.9199999999996s)]
*  I see the recurrence of war in human history so frequently, and I'm not completely convinced by Steven Pinker. [[00:44:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2675.0s)]
*  So I agree with Steven Pinker that the chance of a very violent war indeed has gone down and is going down maybe every year. [[00:44:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2681.04s)]
*  But the tail risk is still there. [[00:44:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2688.4399999999996s)]
*  And if you let the clock, you know, tick out for a long enough period of time, at some point it will happen. [[00:44:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2689.96s)]
*  So powerful abilities to manipulate energy also mean powerful weapons, eventually powerful weapons in decentralized hands. [[00:44:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2695.52s)]
*  I don't think we know how stable that process is. [[00:45:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2702.6s)]
*  But again, let the clock tick out and you should be very worried. [[00:45:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2704.92s)]
*  Yeah. [[00:45:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2708.04s)]
*  OK, so what do you think is the probability that kind of neither humans nor some kind of successor species exists in like 100 years or 1000 years or 10,000 years? [[00:45:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2708.64s)]
*  100 years, I think it's extremely small. [[00:45:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2716.64s)]
*  It would be, you know, whatever is the small chance of some kind of galactic catastrophe, very small. [[00:45:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2719.04s)]
*  A thousand years, I think there's at least a 10% chance, not that every single human is dead, but that we've returned to some earlier, much poorer stage that's quite destructive. [[00:45:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2725.04s)]
*  And maybe, you know, the earth is ruled by roving bands which are violent, a kind of Mad Max scenario. [[00:45:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2735.8399999999997s)]
*  It seems to me the chance of that is reasonably high, way too high. [[00:45:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2741.2799999999997s)]
*  So if you're saying that there's a high probability that humans will still be around in 100 years, I guess that suggests that you think there's a very low annual risk of nuclear war. [[00:45:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2745.2000000000003s)]
*  Why is that? [[00:45:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2754.2000000000003s)]
*  I'm not sure what you mean by very low. [[00:45:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2755.28s)]
*  I think it's below 1%. [[00:45:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2757.76s)]
*  Yeah, I think so too. [[00:45:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2759.44s)]
*  I don't know if that counts as very low. [[00:46:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2760.76s)]
*  But again, it's going to happen sooner or later. [[00:46:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2762.6s)]
*  Yeah. [[00:46:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2764.76s)]
*  And how stable is it if you just trade like one nuke back and forth, two countries? [[00:46:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2765.48s)]
*  We don't know, right? [[00:46:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2770.1600000000003s)]
*  It's never happened. [[00:46:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2770.92s)]
*  So I think the chance that that happens within 30 years is easily, say, 5%. [[00:46:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2772.7200000000003s)]
*  How destabilizing it will be. [[00:46:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2778.36s)]
*  Do you have an immediate global financial crisis or do markets just kind of react like, yeah, yeah, yeah, some currencies go up, some go down. [[00:46:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2779.8s)]
*  It's a terrible tragedy. [[00:46:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2786.52s)]
*  But for most of the world, kind of sort of life goes on after these terrible tragic deaths. [[00:46:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2788.0s)]
*  We don't know. [[00:46:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2793.4s)]
*  Yeah. [[00:46:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2794.64s)]
*  So someone came to me and they were asking for advice, as they sometimes do, on what can they do to improve the long term future? [[00:46:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2794.92s)]
*  And they were deciding between increasing economic growth and, say, working to prevent a nuclear war or a great power war between the US and China. [[00:46:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2800.7599999999998s)]
*  I would almost always recommend that they work on the latter, because I feel like there's far fewer people who are working on that problem. [[00:46:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2808.04s)]
*  And so it's substantially more neglected. [[00:46:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2814.08s)]
*  What would you have to say to them? [[00:46:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2815.8799999999997s)]
*  I definitely recommend people working on lowering the risk of nuclear war. [[00:46:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2817.3199999999997s)]
*  One of my dissertation advisors was Thomas Schelling, who, of course, is the classic theorist of nuclear war. [[00:47:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2821.6s)]
*  Nuclear weapons to me are always the number one issue. [[00:47:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2827.2799999999997s)]
*  But that said, even if you sat down and said, I'm going to do my best to limit nuclear war, I don't know what that means operationally. [[00:47:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2830.28s)]
*  If you're a president or, you know, in a parliament or maybe if you had a particular nonprofit. [[00:47:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2837.56s)]
*  But I'm not sure disarmament is the answer, whereas to boost the rate of economic growth, there's plenty that most people can do in that direction. [[00:47:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2844.84s)]
*  So I wish we had more good avenues for lowering the risk of nuclear war. [[00:47:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2852.1600000000003s)]
*  I'd be very keen to hear about them. [[00:47:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2856.0s)]
*  We'd actually be keen to support them with Emergent Ventures Fund. [[00:47:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2857.84s)]
*  Yeah, it seems like, given what you're saying, that it's likely that humans will go extinct before we manage to escape from this galaxy or maybe even from the solar system. [[00:47:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2860.8s)]
*  And that the reason for this is primarily that we're going to be unable to coordinate between countries and individuals to prevent conflict that would destroy us. [[00:47:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2870.28s)]
*  That kind of your top priority would be figuring out ways to coordinate humans better. [[00:47:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2877.28s)]
*  And indeed, that is kind of a really high priority for people in the effective altruism community and many people who are working on [[00:48:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2881.64s)]
*  with this long termist framework elsewhere. [[00:48:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2886.96s)]
*  Do you think that you might want to write a book about how to improve coordination and international cooperation in future? [[00:48:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2889.44s)]
*  Maybe. That may not be an issue that's good for a book, of course. [[00:48:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2895.04s)]
*  Some issues you write about, but not necessarily in book form. [[00:48:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2899.0s)]
*  It still seems to me that education is a net positive for coordinating people and limiting their desire to slaughter each other. [[00:48:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2902.7200000000003s)]
*  I understand it's not always the case. [[00:48:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2909.6800000000003s)]
*  A lot of the Nazis were well educated and so on. [[00:48:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2911.44s)]
*  But still, on net, I think it's a positive force. [[00:48:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2913.6400000000003s)]
*  So growth and education tend to come together. [[00:48:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2917.04s)]
*  If we're growing more, we can afford more education. [[00:48:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2920.28s)]
*  We can do more to support education in poorer countries. [[00:48:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2923.1600000000003s)]
*  So I still think economic growth is at least a partial indirect means to some of those ends. [[00:48:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2926.1200000000003s)]
*  And again, it's something that's easy to concretize. [[00:48:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2931.7200000000003s)]
*  You can to some extent measure it. [[00:48:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2933.92s)]
*  You know, when you're failing and that makes it more useful than some other kinds of advice that maybe I still would truly fully support. [[00:48:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2935.44s)]
*  I guess I view the invention of nuclear weapons as kind of perhaps like the most important moment in human history. [[00:49:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2942.56s)]
*  Just looking around that time. [[00:49:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2948.32s)]
*  So I hope it ends up not being the most important moment in human history. [[00:49:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2949.2400000000002s)]
*  Fingers crossed. [[00:49:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2952.52s)]
*  But so around that time, say during the 30s and 40s and 50s, the Soviet Union under Stalin had had incredibly faster economic growth. [[00:49:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2953.92s)]
*  It was people were moving from farms to factories. [[00:49:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2963.7200000000003s)]
*  The Soviet Union was becoming substantially more powerful and a stronger military power and developing the ability to in future build nuclear weapons of its own. [[00:49:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2967.36s)]
*  Do you think watching that in the 30s and 40s, we should have been glad that the Soviet Union had a fast rate of economic growth or should it have on balance concerned us, both because it would potentially lead to more conflict between countries because you'd have more great powers and also because the person who was leading the Soviet Union was not a very nice guy? [[00:49:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2976.72s)]
*  Well, of course, it should have concerned us. [[00:49:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2992.36s)]
*  But on that, it was obviously a huge plus because the Soviets stopped the Nazis. [[00:49:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2994.04s)]
*  But keep in mind also, you know, my wife, daughter were born in the Soviet Union and grew up in a wealthier society. [[00:49:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=2998.8s)]
*  My father-in-law, who still lives with us, he was alive during the time of Stalin and his life was better. [[00:50:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3006.0s)]
*  He's still alive today because Soviets had a higher rate of economic growth. [[00:50:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3013.32s)]
*  Soviets urbanized probably more rapidly than China has done lately. [[00:50:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3017.92s)]
*  That's not a well-known fact. [[00:50:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3021.6s)]
*  The world discovered a lot of talent through that urbanization and people being brought into formal education. [[00:50:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3023.3199999999997s)]
*  So it had a lot of benefits and Stalin didn't wipe us out and he beat the Nazis. [[00:50:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3028.92s)]
*  So if you're looking for any case where a higher rate of growth had a big payoff, I think it's that one. [[00:50:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3034.24s)]
*  That's not the counterintuitive case. [[00:50:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3038.7599999999998s)]
*  Yeah. [[00:50:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3040.7999999999997s)]
*  OK. So I feel like ex post it. [[00:50:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3041.52s)]
*  It definitely looks good. [[00:50:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3043.4s)]
*  But at the point where the Soviet Union got nuclear weapons, I might have said looking back, you know, I kind of wish that [[00:50:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3044.36s)]
*  it had not become wealthy that quickly because now we have like a nuclear standoff. [[00:50:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3051.6s)]
*  And you know, the 1948 or 1949, you don't know how stable that situation is going to be. [[00:50:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3055.92s)]
*  So looking forward, you might think that there's like really a very substantial probability of humanity destroying itself during the Cold War. [[00:51:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3061.64s)]
*  Now looking back, we can say, well, it wasn't so severe. [[00:51:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3067.12s)]
*  But you might have thought actually it would be better if there was just one country, given that we have nuclear weapons. [[00:51:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3069.88s)]
*  What we really want is just like one country that's going to be a hegemon and dominate the world so that there won't be a nuclear war and we can have kind of permanent stability. [[00:51:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3073.68s)]
*  What do you think of that? [[00:51:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3080.8399999999997s)]
*  I don't think we understand stability in nuclear weapons very well. [[00:51:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3081.8399999999997s)]
*  Do keep in mind the two times they've actually been used is when only one country had them. [[00:51:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3085.16s)]
*  Doesn't mean we have a fully general theory there. [[00:51:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3089.96s)]
*  Nuclear weapons have spread actually at a slower rate than many people had expected. [[00:51:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3092.7999999999997s)]
*  And you read geopolitical theorists after the end of World War Two, a lot of them think like there's going to be another nuclear war really soon. [[00:51:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3097.4s)]
*  And we tend to dismiss them like, oh, those silly people, you know, they were just paranoid. [[00:51:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3103.68s)]
*  But maybe they were right and we got lucky. [[00:51:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3107.72s)]
*  And that's the true equilibrium. [[00:51:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3109.68s)]
*  I don't think we should reject that view. [[00:51:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3111.44s)]
*  That gets back to an underlying issue with a lot of claims in the book. [[00:51:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3113.8s)]
*  If you really think the chance civilized society might end or be defeated quite soon, you can't look to any kind of long term horizon to decide what is better. [[00:51:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3116.92s)]
*  And you're left with a kind of brute deontology for making choices. [[00:52:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3127.4s)]
*  And when that's the connect scenario, it's not about growth maximization. [[00:52:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3131.76s)]
*  So, I mean, I would accept that caveat. [[00:52:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3135.2400000000002s)]
*  Yeah, there's this interesting thing that if you think that the risk of extinction is extremely low, though non-zero, then you should place extremely high value on the future because it is an expectation is going to last a very long time and we have a high chance of colonizing a significant fraction of the universe. [[00:52:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3137.4s)]
*  So that is an argument for long termism. [[00:52:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3153.44s)]
*  On the other hand, if you think that the risk of extinction is actually quite high, so perhaps it's like 1% a year or something like that, then it's true that if we manage to avoid extinction this year, then the benefit that we get from that is not so great because there's still a good chance that we'll be able to survive. [[00:52:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3155.44s)]
*  We'll destroy ourselves in future. [[00:52:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3167.12s)]
*  But the risk is so high, like 1% every year, that there's probably a lot that could be done to lower that. [[00:52:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3168.3599999999997s)]
*  So it's like potentially a more tractable problem because it's a bigger problem to begin with. [[00:52:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3173.0s)]
*  Yeah. [[00:52:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3176.4s)]
*  Do you have any thoughts on that? [[00:52:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3176.6s)]
*  Well, let's imagine it were the case that somehow we actually knew that if we could construct hobbit society, but with people being taller, say, the world would not end. [[00:52:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3177.56s)]
*  And if we don't construct hobbit society, the world will end, say, through nuclear weapons. [[00:53:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3187.7599999999998s)]
*  Let's say we knew that or we thought 70% chance that's likely to be true. [[00:53:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3191.96s)]
*  I still don't think we actually are good at implementing the means to bring about hobbit society. [[00:53:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3196.6s)]
*  We would have to become brutal totalitarians. [[00:53:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3201.92s)]
*  If anything, we might accelerate the risk of this nuclear war. [[00:53:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3204.4s)]
*  So when you think of the feasible tools at our disposal, that's kind of outside our current feasible set, hobbit society. [[00:53:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3207.7200000000003s)]
*  We're on this path. [[00:53:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3213.96s)]
*  I think we have to manage it. [[00:53:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3215.16s)]
*  We can't just, you know, slam the brakes on the car. [[00:53:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3216.76s)]
*  It'll careen, you know, off the cliff. [[00:53:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3219.52s)]
*  And our best chance is to master and improve technologies to make nuclear weapons warning systems, second strike capabilities safer rather than riskier. [[00:53:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3222.0s)]
*  I just think that's the path we're on. [[00:53:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3230.2000000000003s)]
*  And the hobbits are not there for us. [[00:53:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3232.0s)]
*  Yeah. [[00:53:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3233.76s)]
*  Perhaps if I had to like summarize my overall worldview and just like one quote, it would be this phrase from E.O. [[00:53:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3234.28s)]
*  Wilson. [[00:53:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3238.12s)]
*  The real problem with humanity is the following. [[00:53:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3238.88s)]
*  We have paleolithic emotions, medieval institutions and godlike technology, and it's terrifically dangerous. [[00:54:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3241.48s)]
*  And perhaps this highlights kind of my concern with the idea that we ought to increase economic growth, which seems to push more perhaps on the godlike technology than improving the paleolithic emotions or the medieval institutions. [[00:54:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3246.6s)]
*  And I guess by focusing on improving technology, we're increasing the kind of disconnect between the improvement that we've had in our engineering and scientific and technological ability and the fact that just our personal moral values and our institutions for governing ourselves have not kept up with that. [[00:54:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3256.92s)]
*  And so I'd be perhaps more interested in seeing people focus on the emotions and the institutions here to get them to catch up with our godlike technology than increasing the technology itself. [[00:54:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3271.16s)]
*  What do you think of that? [[00:54:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3280.0s)]
*  I'm more optimistic than Wilson and perhaps you. [[00:54:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3280.92s)]
*  So he refers to medieval institutions. [[00:54:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3283.6800000000003s)]
*  But in most countries, institutions are much better than that. [[00:54:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3285.96s)]
*  Like, what are the good medieval institutions that stuck around like Parliament of Iceland, Oxford, where you've been, I suppose, Cambridge, you know, maybe a few other schools. [[00:54:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3288.52s)]
*  But we've built so much since then. [[00:54:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3298.08s)]
*  I don't mean technology. [[00:54:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3299.56s)]
*  I mean quality institutions with feedback and accountability. [[00:55:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3300.64s)]
*  If you look, say, at how Singapore is run, a lot of the Nordic countries, some parts of American life, by no means all, just to be clear, Canada, Australia, where you're from, you see remarkable institutions, unprecedented in human history. [[00:55:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3304.2s)]
*  I don't take those for granted. [[00:55:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3317.6s)]
*  They're not automatic. [[00:55:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3319.4s)]
*  But I think one has to revise the Wilson quote and be more optimistic. [[00:55:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3320.68s)]
*  Yeah. [[00:55:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3324.52s)]
*  So I agree. [[00:55:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3324.7999999999997s)]
*  Medieval institutions is perhaps an exaggeration. [[00:55:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3325.2799999999997s)]
*  But do you think it's a significant exaggeration, right? [[00:55:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3327.64s)]
*  Yeah. [[00:55:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3330.16s)]
*  OK, I agree. [[00:55:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3330.88s)]
*  I think it's the case that probably political institutions and our decision making capacity isn't improving as quickly as our technological capabilities. [[00:55:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3331.6s)]
*  And I think I wish it were like the other way around, that our kind of wisdom and prudence and ability to make like decisions that are not risky was like maybe moving faster than our than our technology. [[00:55:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3339.2799999999997s)]
*  But see, I see it the other way around. [[00:55:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3349.12s)]
*  If you look at data on economic growth, you see huge productivity improvements. [[00:55:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3350.6s)]
*  China, India, basically free riding on existing technologies, not usually making them better. [[00:55:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3354.44s)]
*  But just managing companies better, having better incentives and companies. [[00:56:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3360.12s)]
*  And if the world economy grew four point whatever percent last year, way more of that four point, say, eight percent is coming from better management, better institutions than it's coming from new technology. [[00:56:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3363.7599999999998s)]
*  Maybe like one percent of it's coming from new technology and the rest from better management and some in some cases growing population capital resources. [[00:56:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3376.04s)]
*  So institutions are way out racing technology right now. [[00:56:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3384.12s)]
*  Again, I'm not taking that for granted. [[00:56:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3387.2s)]
*  But I think people would be much more optimistic if they viewed it in that light. [[00:56:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3389.32s)]
*  So we're both big fans of Philip Tetlock and his work to improve forecasting. [[00:56:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3392.88s)]
*  I think it's like among among the most important work in social science and some of the most impressive and interesting work that's ever been done. [[00:56:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3396.84s)]
*  Do you think it would be valuable to get like much more effort going into improving decision making in that form rather than perhaps working on like science and technology otherwise? [[00:56:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3402.12s)]
*  Like do you think we under invest perhaps in social science relative to technical sciences? [[00:56:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3411.32s)]
*  I think we under invest in particular kinds of social science. [[00:56:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3415.2400000000002s)]
*  Too many social scientists are overly specialized. [[00:56:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3418.96s)]
*  They don't read outside their disciplines. [[00:57:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3421.88s)]
*  They don't have the incentives to do something the world as a whole will find useful. [[00:57:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3423.88s)]
*  Tetlock is a wonderful shining counter example to that. [[00:57:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3427.48s)]
*  So academic incentives are working less well than I think they did 20, 30 years ago, including in the social sciences. [[00:57:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3430.8s)]
*  And that we need to fix. [[00:57:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3438.1200000000003s)]
*  It will be very hard to do because existing structures are tightly locked in. [[00:57:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3439.6400000000003s)]
*  Let's take a step back in time back to 1900. [[00:57:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3443.24s)]
*  I imagine that if you were alive then you'd say that the risk of human extinction in the next hundred years would be fairly low. [[00:57:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3445.4s)]
*  But then in the 40s we had this shock where we developed nuclear weapons. [[00:57:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3450.48s)]
*  And suddenly I think we would both agree the risk of human extinction or the collapse of civilization went up quite substantially because kind of for the first time we had the ability for like one person or one country to basically wipe out most humans alive at the time. [[00:57:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3454.16s)]
*  What do you think of the chances that in the 21st century there'll be some new breakthrough that's kind of analogous to nuclear weapons that will again give a level shift in kind of the annual risk of human extinction? [[00:57:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3465.6s)]
*  The possibility that worries me the most is simply an equivalent amount of power being more portable. [[00:57:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3473.8799999999997s)]
*  I don't think it has to be a new technology. [[00:57:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3478.72s)]
*  It certainly might be, but simply the cost of a nuclear weapon or something like it being much cheaper. [[00:58:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3480.96s)]
*  Bioweapons are very hard to carry around and deploy. [[00:58:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3486.6s)]
*  But you could quite readily imagine that becoming easier. [[00:58:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3489.6s)]
*  It seems to me those are likely outcomes. [[00:58:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3492.3999999999996s)]
*  But terrorism in general, I don't think we understand well. [[00:58:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3494.9199999999996s)]
*  So after 9-11 people thought there would be many more attacks and you can ask questions. [[00:58:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3497.8799999999997s)]
*  Why don't they just send a few people over the Mexican border? [[00:58:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3502.3599999999997s)]
*  They get here, they buy sub machine guns, they show up like in a famous shopping mall and they take out 17 people. [[00:58:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3505.04s)]
*  They don't get any further than that. [[00:58:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3512.2s)]
*  But it's a massive publicity event and this just happens every two or three weeks. [[00:58:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3513.96s)]
*  Sort of a priori it almost sounds plausible, but nothing like that has happened. [[00:58:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3518.3199999999997s)]
*  If anyone has done that, it's our native white Americans who are not in the traditional sense terrorists. [[00:58:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3522.72s)]
*  So it's clearly possible, but they don't do it. [[00:58:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3529.24s)]
*  So when you ask how likely is someone to do something horrible with a pretty cheap, decentralized, highly destructive technology, [[00:58:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3532.44s)]
*  we don't even see them acting at the current frontier of destructiveness. [[00:58:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3539.84s)]
*  So what you need in terms of people who are competent enough, motivated enough, coherent enough, have a base to operate from, [[00:59:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3544.36s)]
*  how hard is it in the combinatorial sense for all those to come together? [[00:59:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3552.1600000000003s)]
*  We don't know, but I think thinking about it more, you become a little more optimistic rather than less. [[00:59:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3555.92s)]
*  I think that's fair, but it seems like over time as our technology gets better, [[00:59:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3561.36s)]
*  like the number of people and the amount of expertise and the amount of security that you'd need in order to pull off an operation like that is going down and down and down. [[00:59:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3564.2400000000002s)]
*  And eventually it could end up being a handful of people or even a single individual. [[00:59:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3571.7200000000003s)]
*  And perhaps breakthroughs in biology are the most likely cause of that. [[00:59:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3574.7200000000003s)]
*  Do you think that perhaps the risk, the annual risk of human extinction is going down or up? [[00:59:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3578.16s)]
*  There's kind of a link factors here. [[00:59:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3582.12s)]
*  And I guess like the improvement of technology in that sense is one thing that's pushing it up. [[00:59:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3583.88s)]
*  Though I suppose we could also invent technologies that might give us the ability to prevent that from ever happening. [[00:59:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3586.7599999999998s)]
*  I think it will go up over the next century. [[00:59:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3591.12s)]
*  I don't think it's going up right now. [[00:59:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3593.08s)]
*  I once asked some of my friends an interesting question. [[00:59:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3594.68s)]
*  If a single person by a sheer act of will that they had to sustain for only five minutes could destroy a city of their choice, [[00:59:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3597.56s)]
*  how much time would have to pass before one individual on earth would take the action to destroy that city? [[01:00:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3605.44s)]
*  Is it like it would occur in two seconds? [[01:00:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3611.52s)]
*  It would occur in 10 minutes. [[01:00:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3613.6800000000003s)]
*  It would occur within a year. [[01:00:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3614.8s)]
*  I don't think we know, but no one should be optimistic about that scenario. [[01:00:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3616.44s)]
*  Let's say that humans do continue for thousands, perhaps millions of years. [[01:00:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3620.32s)]
*  But for some reason, we decide just to never leave earth. [[01:00:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3623.8s)]
*  And so we don't use any of the resources that are available elsewhere. [[01:00:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3626.36s)]
*  Which would be my prediction, by the way. [[01:00:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3629.2400000000002s)]
*  I think space is overrated. [[01:00:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3630.76s)]
*  OK. It seems like on your view, that should be like a horrific tragedy that almost all the value that humanity could have created has been lost in that case. [[01:00:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3632.36s)]
*  Space is hard, right? [[01:00:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3639.96s)]
*  So it's far. [[01:00:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3641.96s)]
*  There are severe physical strains you're subject to while you're being transported. [[01:00:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3645.52s)]
*  Communication back and forth takes a very long time under plausible scenarios, limited by the speed of light. [[01:00:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3649.6800000000003s)]
*  And what's really out there? [[01:00:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3656.76s)]
*  Maybe there are exoplanets, but when you have to construct atmosphere, there's a risk diversification argument for doing it. [[01:00:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3658.44s)]
*  But simply being under the ocean or high up in the sky or distant corners of the earth, we're not about to run out of space or anything close to it. [[01:01:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3665.8s)]
*  So I don't really see what's the economic reason to have something completely external say to the solar system. [[01:01:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3674.84s)]
*  Yeah, so it seems like you're OK with the idea that we can turn just more matter and more energy into more value. [[01:01:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3681.1200000000003s)]
*  It seems like there's five times by ten to the 22 stars out there in the accessible universe at the moment. [[01:01:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3687.2400000000002s)]
*  Admittedly, as the galaxies recede, it's declining by about a millionth per year. [[01:01:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3693.52s)]
*  But if you're in favour of growth and creating more value, it just seems like almost all the value, no matter what you value, it has to be out there in all of that matter that we can reorganise. [[01:01:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3697.6800000000003s)]
*  Just given your desire for growth on Earth, I don't understand how it could be the case that you wouldn't be upset that we might just stop at the boundaries of the Earth's atmosphere. [[01:01:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3706.32s)]
*  Oh, I'm upset about it. I'm just not very optimistic. [[01:01:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3716.24s)]
*  So if you put me in the legislature, you know, I'll vote to increase funding for space exploration. [[01:02:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3720.0s)]
*  But just relative, especially in the Bay Area, relative to other people I speak to in this kind of fringe group of intellectuals who think about space, I'm more pessimistic than just about all of them. [[01:02:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3726.12s)]
*  But it's also that I'm more optimistic about the Earth. [[01:02:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3736.48s)]
*  The ocean, of course, is enormous. [[01:02:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3739.3199999999997s)]
*  It could be platforms. [[01:02:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3741.12s)]
*  It could be underwater. [[01:02:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3742.12s)]
*  Deserts, places that can be terraformed, cities in the sky. [[01:02:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3743.3999999999996s)]
*  So you do want diversification, protection against a big nuclear war. [[01:02:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3748.2s)]
*  Maybe for that you need other planets. [[01:02:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3751.7599999999998s)]
*  You know, there's the moon, there's Mars. [[01:02:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3753.64s)]
*  They're actually big enough to have diversification. [[01:02:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3755.44s)]
*  But it does seem like no matter how hard we go on Earth, at some point we'll just have found the best configuration we can make for kind of all of the matter and the energy that we can harvest here. [[01:02:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3759.6s)]
*  And then in order to continue growing, like, and to avoid a plateau, which is kind of terrible on your view. [[01:02:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3768.3199999999997s)]
*  That the only path is to go out. [[01:02:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3773.3199999999997s)]
*  And like, this is beautiful thing that once we go out into space and we start colonising, then we get cubic growth because we're like growing like a sphere. [[01:02:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3774.7599999999998s)]
*  I'm never going to vote no on that. [[01:03:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3780.2799999999997s)]
*  Just some cautionary notes. [[01:03:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3781.8399999999997s)]
*  There is a history of imperialism where mostly European societies have grown and taken over other parts of the globe, and they did not in every way do maximum good, to say the least. [[01:03:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3783.3999999999996s)]
*  And I worry about how we might treat societies we encounter. [[01:03:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3793.8799999999997s)]
*  We also may draw attention to ourselves as a target or a threat. [[01:03:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3797.44s)]
*  I'll still vote yes on the expenditures, but I don't view it as by any means this huge net positive. [[01:03:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3801.2s)]
*  It's something I also worry about a good deal. [[01:03:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3806.04s)]
*  And I also just think our corner of the galaxy will be wiped out before we get that far. [[01:03:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3808.12s)]
*  Yeah, it seems like to make this view stable. [[01:03:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3813.2s)]
*  It's so you have to think you're thinking that the probability of extinction is high such that like you're pretty confident we'll never go to space. [[01:03:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3814.9599999999996s)]
*  But it's not so high enough that like the overwhelming and the important thing is to work on extinction right now. [[01:03:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3821.9599999999996s)]
*  Or maybe you maybe do think that what we should do is lower the risk of a catastrophe. [[01:03:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3826.16s)]
*  But like the best way to do that is via increasing the growth rate. [[01:03:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3829.92s)]
*  Yes. And let's say your modal scenario is everything ends in 10,000 years. [[01:03:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3832.8399999999997s)]
*  That's still a long enough time horizon where the long term results of higher growth now are very significantly positive for billions of humans. [[01:03:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3837.8399999999997s)]
*  And that will play the dominant role in a moral calculus. [[01:04:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3846.08s)]
*  Yeah. [[01:04:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3849.04s)]
*  But the idea that somehow we're going to be sitting here three million years from now and I'll have my galaxy and you have yours and we're not even human anymore. [[01:04:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3849.28s)]
*  And it's not even recognizable as something from science fiction. [[01:04:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3856.6000000000004s)]
*  I would bet against that if we could arrange bets on it. [[01:04:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3860.1200000000003s)]
*  Yeah. [[01:04:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3862.8s)]
*  So why do you think that we couldn't develop kind of self replicating probes? [[01:04:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3863.0s)]
*  I like I agree that humans are not going to travel to other galaxies. [[01:04:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3866.4s)]
*  That's way too hard. [[01:04:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3868.7200000000003s)]
*  But at some point we should be able to create kind of intelligence that somewhat resembles humans or might even be better than humans in some form that is like easier to transport through space. [[01:04:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3869.84s)]
*  You know, on computers or whatever the future example of computers is. [[01:04:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3878.3599999999997s)]
*  And then that that kind of intelligence would have a much better shot at spreading to the stars. [[01:04:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3881.48s)]
*  It can travel much faster. [[01:04:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3886.56s)]
*  It's like much more resilient. [[01:04:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3887.72s)]
*  And then it arrives there and starts like creating more copies of itself. [[01:04:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3888.9199999999996s)]
*  We don't see self replicating probes from other parts of the universe. [[01:04:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3891.8799999999997s)]
*  And maybe we are those self replicating probes in some way, right? [[01:04:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3895.04s)]
*  We were seeded. [[01:04:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3898.52s)]
*  But the fact that we don't in an obvious way see them to me strengthens the case for pessimism. [[01:05:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3900.24s)]
*  Yeah, you probably have read this paper that came out of the Future of Humanity Institute. [[01:05:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3906.04s)]
*  Yeah, the Fermi paradox is not nearly as absolute as people used to think, but it's still an issue. [[01:05:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3909.92s)]
*  You still should update in Bayesian terms that you don't see the aliens, right? [[01:05:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3915.44s)]
*  Yeah, I agree. [[01:05:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3920.0s)]
*  That's worrying. [[01:05:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3920.92s)]
*  But because we have these alternative explanations that we might just be the one chance event where life began, I still kind of have to have some hope that we'll get there. [[01:05:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3921.4s)]
*  We'll be the first ones to colonize at least this part of the universe. [[01:05:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3928.2400000000002s)]
*  I'm going to vote with you. [[01:05:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3930.92s)]
*  That's all I can say for now. [[01:05:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3931.88s)]
*  Cool. [[01:05:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3933.72s)]
*  So you're in favor of markets and kind of liberal governance. [[01:05:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3934.3599999999997s)]
*  But I see kind of two arguments here that might justify an alternative approach. [[01:05:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3937.52s)]
*  So one is you're in favor of economic, faster economic growth. [[01:05:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3941.64s)]
*  And centrally planned economies in the past have been able to reinvest a much larger fraction of GDP and kind of future growth, just building more factories rather than producing consumer goods, then market economies have been able to. [[01:05:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3945.68s)]
*  So perhaps you might be interested in having some greater like central planning of the economy that would allow us to do much more investment through like science and technology, or perhaps physical capital. [[01:05:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3955.52s)]
*  That will allow us to increase the economic growth rate. [[01:06:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3964.2s)]
*  What do you think of that? [[01:06:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3966.2s)]
*  Well, we need to become more concrete. [[01:06:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3967.24s)]
*  But the wealthiest societies in today's world are, for the most part, the freest ones. [[01:06:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3969.08s)]
*  There's no guarantee that will always hold. [[01:06:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3974.04s)]
*  But I think that's an argument for some kind of liberal freedom. [[01:06:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3976.08s)]
*  But if you look at, say, China since 1979, yes, they grew because they became significantly freer. [[01:06:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3979.3199999999997s)]
*  But I suspect they also did better keeping some elements of Communist Party rule in place than if they had, say, followed the advice of Western reformers. [[01:06:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3986.8399999999997s)]
*  And I think they, you know, for the most part, not on every decision, but did the right thing. [[01:06:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3995.68s)]
*  So I think we need to recognize that. [[01:06:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=3999.68s)]
*  Yeah. [[01:06:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4001.56s)]
*  But that's not a centrally planned economy either. [[01:06:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4001.7599999999998s)]
*  It's because they gave up central planning. [[01:06:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4003.8399999999997s)]
*  Yeah. [[01:06:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4005.96s)]
*  But nonetheless, they spent very heavily on infrastructure and still do. [[01:06:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4006.68s)]
*  And that in large part comes from the government. [[01:06:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4010.96s)]
*  Yeah. [[01:06:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4013.4399999999996s)]
*  And so I guess we don't want to give up the benefits of markets, absolutely. [[01:06:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4013.96s)]
*  But I guess you'd be fairly happy if the United States just spent quite a lot more on supporting science and technology research and like perhaps the government built lots more infrastructure. [[01:06:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4016.92s)]
*  I would spend much more on science and technology. [[01:07:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4024.6800000000003s)]
*  When you say infrastructure, I want to disaggregate. [[01:07:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4026.88s)]
*  But there are certainly plenty of things I'd be willing to spend more. [[01:07:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4029.5200000000004s)]
*  But the idea that you just throw a trillion dollar bill at infrastructure and what ends up happening is the senators from Wyoming have their say and you just build a lot more roads and actually make climate change worse. [[01:07:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4032.84s)]
*  And you don't upgrade your power grid or do things very smart. [[01:07:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4043.08s)]
*  I don't want to just uncritically endorse infrastructure. [[01:07:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4046.12s)]
*  That's to me can be a negative. [[01:07:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4048.4399999999996s)]
*  Yeah, I'm with you. [[01:07:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4050.64s)]
*  So that perhaps another argument for lower liberalism would be you're saying that basically you think there's a high chance that humans are going to drive themselves to extinction. [[01:07:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4051.8799999999997s)]
*  The reason is a lack of coordination and conflict. [[01:07:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4059.3599999999997s)]
*  One possible cheap energy. [[01:07:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4061.52s)]
*  Right. [[01:07:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4063.08s)]
*  Okay. [[01:07:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4063.2799999999997s)]
*  And cheap energy. [[01:07:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4063.4399999999996s)]
*  Too much power, too much power in the hands of people and the ability to destroy one another. [[01:07:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4063.9599999999996s)]
*  This is like a very severe problem. [[01:07:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4067.9199999999996s)]
*  Perhaps in order to solve that problem, we should be willing to have a world government kind of run towards a singleton, as Nick Bostrom calls it, which would be like having one decision making process that is able to control everyone else, prevent conflicts. [[01:07:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4069.3199999999997s)]
*  Even if it doesn't produce the optimal decisions, at least we won't have extinction. [[01:08:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4081.3199999999997s)]
*  We'll get like some we have to survive for a lot longer and generate some more value, even if the singleton doesn't make the absolute best decisions that we might think of from a liberal point of view. [[01:08:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4084.3999999999996s)]
*  What do you think of that argument? [[01:08:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4093.6s)]
*  Well, it's hard enough to get the European Union to stay together. [[01:08:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4094.8s)]
*  And those countries have so much commonality of interest. [[01:08:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4098.0s)]
*  I expect some further nations after Brexit to peel off over time. [[01:08:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4100.88s)]
*  Try to get Southeast Asia to agree even to like a local, you know, ASEAN being much stronger, being an EU like phenomenon, simply impossible. [[01:08:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4105.68s)]
*  So it's a recipe for creating conflict. [[01:08:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4113.56s)]
*  I understand the appeal of the vision. [[01:08:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4115.8s)]
*  You know, I'm all for NAFTA. [[01:08:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4117.76s)]
*  I like multilateral institutions. [[01:08:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4118.92s)]
*  But I think it's the wrong way to go. [[01:08:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4121.68s)]
*  The UN is, you know, of some use, but in many ways an impotent bureaucracy. [[01:08:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4123.08s)]
*  You would not want it ruling over us. [[01:08:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4127.6s)]
*  You tend to recreate some of the worst aspects of national bureaucracies and then infuse them into a least common denominator sort of politically correct institution. [[01:08:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4129.64s)]
*  That's just not very effective. [[01:08:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4139.0s)]
*  So I think that's the wrong path overall. [[01:09:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4140.44s)]
*  Yeah. [[01:09:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4143.2s)]
*  So, but couldn't you imagine perhaps that we convinced like many people of this kind of long termist framework? [[01:09:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4143.48s)]
*  They share our belief that extinction is very possible and would be a terrible catastrophe. [[01:09:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4148.6s)]
*  And so they're willing to make many concessions perhaps. [[01:09:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4153.4s)]
*  If you could just get kind of China and the United States to, you know, are banned together to say, yeah, our top priority is avoiding extinction and war. [[01:09:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4155.64s)]
*  So we're going to like work together very closely, if not to control everything, just to control access to the kinds of technologies that would potentially produce human extinction. [[01:09:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4162.12s)]
*  Could you see like in the next 100, 500 years that kind of cooperation to make humanity more stable and civilization continue? [[01:09:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4169.92s)]
*  Well, there's already a great deal of international cooperation on nuclear weapons. [[01:09:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4178.4800000000005s)]
*  So right now we're trying to manage the North Korean situation. [[01:09:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4183.400000000001s)]
*  The cooperation is highly imperfect, but it's remarkable how much is there. [[01:09:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4186.92s)]
*  When the Soviet Union was collapsing and there were possibly loose nuclear weapons, there was a good deal of international cooperation to deal with that problem. [[01:09:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4191.04s)]
*  So we have, you know, very immediate successes near us. [[01:09:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4199.12s)]
*  And could we do better? [[01:10:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4202.839999999999s)]
*  Absolutely. [[01:10:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4203.879999999999s)]
*  But the idea of there being this general public movement where you get people to do the right thing by scaring them, I think that's the opposite of how politics usually works. [[01:10:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4205.36s)]
*  Voters like to live in denial. [[01:10:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4213.48s)]
*  And if you scare people too much with, say, climate change, they respond by thinking it's not actually all that significant. [[01:10:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4215.2s)]
*  And I think some kind of more positive vision, you're more likely to get people on the sustainability bandwagon. [[01:10:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4222.28s)]
*  And that's one of the kind of backstories to my book. [[01:10:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4228.12s)]
*  I'm trying to give a positive vision, emphasizing less, you know, scaring the heck out of people and more. [[01:10:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4230.4400000000005s)]
*  Here are the glories at the end of the road. [[01:10:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4236.12s)]
*  What you can do for your descendants and world history. [[01:10:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4238.320000000001s)]
*  And scaring people seems to backfire in politics. [[01:10:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4241.2s)]
*  Yeah. [[01:10:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4244.320000000001s)]
*  So we've been talking a lot about the possibility of a nuclear apocalypse here. [[01:10:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4244.52s)]
*  And that is like a somewhat tricky one to figure out how to solve. [[01:10:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4248.52s)]
*  But you bring up climate change where it seems like it's a lot more tractable. [[01:10:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4251.240000000001s)]
*  It's pretty clear what kinds of technologies you could work on in order to reduce the risk of really runaway climate change if we get unlucky. [[01:10:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4253.76s)]
*  Do you think it's particularly valuable for people to go and work on technologies that kind of differentially reduce the risk of catastrophes like climate change? [[01:11:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4260.16s)]
*  Oh, absolutely. [[01:11:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4266.88s)]
*  And I think the last few years, a lot of those technologies have made more rapid progress than I would have thought. [[01:11:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4268.04s)]
*  It's like electric cars, like fracking, just the interest in China in cutting back on their air pollution, solar, nuclear. [[01:11:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4273.280000000001s)]
*  Some of it's still on the drawing board, but I think they really intend to do it and probably will. [[01:11:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4279.919999999999s)]
*  So the progress in the fight against climate change, even in the last few years, is much higher than people think, even though we don't see the results yet in terms of measurements of carbon emissions. [[01:11:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4284.2s)]
*  I wouldn't quite say I'm an optimist, but there have been big gains in the immediate past. [[01:11:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4294.24s)]
*  Are there any other technologies that you're excited about because they kind of differentially improve civilizational stability? [[01:11:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4298.719999999999s)]
*  Well, everyone talks about batteries, but I often feel batteries are a mixed blessing. [[01:11:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4304.4s)]
*  So batteries, of course, would make it much easier to have green energy. [[01:11:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4309.32s)]
*  But batteries also ease the decentralized storage of power and carrying around of destructive power. [[01:11:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4312.76s)]
*  So if instead of like a gun, which is like awful, but it's hard to kill a thousand people just shooting a gun, right? [[01:11:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4319.4400000000005s)]
*  If you have some kind of pack on your back with a battery and then an energy creating weapon that you just walk around with and you have crazy people doing this the way they do now with guns, [[01:12:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4328.56s)]
*  that worries me. I still think on that, you know, better batteries are a plus, but it cuts both ways. [[01:12:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4339.24s)]
*  It seems like the most important technology from your point of view might be the ability to surveil people so that we can prevent any group from using really concentrated energy to end human civilization, [[01:12:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4344.400000000001s)]
*  but also kind of the social technology then to regulate that such that it doesn't lead to totalitarianism. [[01:12:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4357.6s)]
*  Do you think research into something like that could be very valuable? [[01:12:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4362.16s)]
*  I worry a great deal about surveillance, which, of course, has proceeded most rapidly in China. [[01:12:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4365.16s)]
*  If surveillance really would make us safer, that would be an argument for it. [[01:12:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4371.08s)]
*  But surveillance tends to corrupt your rulers and it tends to increase the returns to being in charge. [[01:12:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4376.24s)]
*  And I think over time, it increases the chances of, say, coup d'état or political instability in China. [[01:13:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4382.04s)]
*  Even though you have more stability at the ground level, you may have less stability at the top. [[01:13:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4388.56s)]
*  But I think this is one of the two or three biggest issues facing the world right now. [[01:13:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4393.76s)]
*  What are we going to do with surveillance and AI, facial and gait recognition? [[01:13:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4397.8s)]
*  I don't think we know what to do. [[01:13:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4401.64s)]
*  I would say I'm more worried about it than applaud it. [[01:13:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4403.280000000001s)]
*  Yeah, I think I'm with you. [[01:13:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4406.64s)]
*  I'm not sure whether more surveillance or less surveillance is better right now. [[01:13:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4407.68s)]
*  But I guess it seems like finding better ways to govern surveillance, given that we're probably going to have quite a lot of it, so that it doesn't lead to these negative political outcomes could be like an extremely important research question that more things should be looking into. [[01:13:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4410.96s)]
*  And it's quite possibly true that the gains in surveillance we've had so far are what have limited some of the potential sequel attacks to 9-11. [[01:13:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4421.44s)]
*  We can't know that for sure as outsiders, but many people suggest this is probably the case. [[01:13:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4429.8s)]
*  Yeah. So in terms of ways that humanity might end, we've got kind of nuclear war, just kind of a great power war between the US and China, even setting aside nuclear weapons. [[01:13:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4434.4s)]
*  We've got climate change. [[01:14:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4441.8s)]
*  And I guess we're both concerned about just like new technologies that would really concentrate energy, that would allow a lot of destructive power. [[01:14:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4442.759999999999s)]
*  What do you think about perhaps a fifth one on that list, which is that kind of a negative global totalitarianism because technology allows a negative political order to stabilise itself by monitoring people too much? [[01:14:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4449.88s)]
*  Well, that may happen in China. [[01:14:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4459.400000000001s)]
*  So one scenario is the Chinese government will simply clamp down on opposition through surveillance and that will be stable for a very long period of time. [[01:14:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4460.84s)]
*  That might make society in China worse, but I don't see why it's destabilising, even if it's undesirable. [[01:14:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4469.160000000001s)]
*  Oh, no, I mean, I don't think it would be destabilising. [[01:14:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4474.56s)]
*  The problem is, it would be very stable, but like bad, would still lose most of the value because perhaps we've locked in a bunch of negative or neutral moral values. [[01:14:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4476.12s)]
*  That's one of my big worries for the forthcoming future. [[01:14:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4483.56s)]
*  You mentioned climate change. [[01:14:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4486.2s)]
*  I don't think it's an existential risk. [[01:14:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4487.4s)]
*  I do think the expected costs are maybe higher than most people want to admit. [[01:14:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4489.28s)]
*  But the notion that it would wipe out human civilisation as we know it, you would need a very extreme scenario. [[01:14:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4494.36s)]
*  I don't think that's very likely. [[01:14:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4499.64s)]
*  I agree with you. [[01:15:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4501.04s)]
*  Yeah, I think it's unlikely that climate change could lead to extinction. [[01:15:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4501.88s)]
*  I mean, maybe it could lead to significant loss of life. [[01:15:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4504.879999999999s)]
*  I guess one possible way it could go is that it turns out to be like the temperature increases much more than we expect. [[01:15:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4507.36s)]
*  So we get like more like six to nine degrees of warming. [[01:15:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4511.92s)]
*  This like sets us back economically, which like sets up, you know, triggers a negative cascade of consequences. [[01:15:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4514.04s)]
*  The most worrisome scenario. [[01:15:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4518.24s)]
*  Keep in mind that regular air pollution, and I don't mean carbon based, just air pollution, right now it kills six to seven million people a year. [[01:15:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4520.04s)]
*  Obviously a large number. [[01:15:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4528.28s)]
*  Now, some of those are older people or frail people. [[01:15:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4529.88s)]
*  They might have died soon anyway, but still it's a number hardly anyone talks about. [[01:15:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4532.52s)]
*  Climate change right now is not killing six to seven million people a year. [[01:15:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4537.320000000001s)]
*  And this we just absorb and move on. [[01:15:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4540.88s)]
*  So as you indicated, a lot of the risk climate change is how it might set off other kinds of conflict. [[01:15:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4543.400000000001s)]
*  Yeah, or kind of just the tale that we've totally mismeasured how it's going to affect the climate. [[01:15:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4548.4400000000005s)]
*  I think this is like relatively unlikely, but perhaps is still worth having some people worry about. [[01:15:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4552.68s)]
*  Or we could do bad geoengineering and make the world too cold. [[01:15:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4557.76s)]
*  OK, let's move on to some other things in the book that I wasn't entirely convinced by. [[01:16:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4560.68s)]
*  You make the argument in one of the chapters that even though kind of our actions seem to have like very large and morally significant effects in the long run, that that doesn't necessarily mean that we have incredibly onerous moral duties that we don't necessarily have to set aside all of our projects in order to maximize the growth rate of GDP or improve, you know, civilizational stability. [[01:16:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4565.52s)]
*  What's your case there? [[01:16:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4583.88s)]
*  Well, I do think you have an obligation to act in accordance with maximizing the growth rate of GDP. [[01:16:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4585.08s)]
*  But given how human beings are built, that's mostly going to involve leading a pretty selfish life, trying to earn more, having a family, raising your children well. [[01:16:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4590.8s)]
*  It's close to in sync with common sense morality, which to me is a plus of my argument. [[01:16:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4601.52s)]
*  What it's telling you to do doesn't sound so crazy. [[01:16:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4606.360000000001s)]
*  You don't have to re-engineer human nature. [[01:16:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4609.320000000001s)]
*  So if someone for more of a Peter Singer direction says, well, all the doctors have to run off to Africa, like people won't do that. [[01:16:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4612.0s)]
*  We can't and shouldn't coerce them into doing that. [[01:16:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4618.48s)]
*  And the notion that by living a quote unquote good life, but making some improvements at the margin, that that's what you're obliged to do. [[01:17:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4621.08s)]
*  I find that very appealing. [[01:17:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4628.759999999999s)]
*  It's like change at the margin, small steps toward a much better world. [[01:17:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4630.0s)]
*  That's the subheader on marginal revolution. [[01:17:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4633.28s)]
*  It's also a more salable vision, but I think that it accords with longstanding moral intuitions, like shows it's on the right track. [[01:17:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4635.88s)]
*  Yeah, OK. So it seems like given your framework of long-termism, like the moral consequences of our actions are like much larger than what most people think when they're only thinking about the short-term effects of their actions. [[01:17:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4643.96s)]
*  So in that sense, the moral consequences are like should like bear on us more than they otherwise do. [[01:17:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4654.24s)]
*  Well, it's very tricky, though. [[01:17:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4659.4800000000005s)]
*  If you go around telling people everything you do is going to change the whole world. [[01:17:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4661.16s)]
*  They're going to get pissed off at you. [[01:17:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4664.92s)]
*  They're going to tune you out. [[01:17:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4667.12s)]
*  So this is a Straussian undercurrent in the book. [[01:17:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4668.360000000001s)]
*  Like the long term is really important, but people still need to focus to some extent on the short term to get to the long term. [[01:17:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4670.56s)]
*  They can only handle so much computationally. [[01:17:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4676.96s)]
*  So it's not that I think the right answer is for everyone to be like so attuned to the exact correct moral theory. [[01:17:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4679.56s)]
*  They're going to use rules of thumb. [[01:18:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4685.84s)]
*  We're going to rely on common sense morality, whether we like it or not, you know, even professional philosophers will. [[01:18:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4687.8s)]
*  And that's OK is one thing I'm saying. [[01:18:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4693.0s)]
*  Just always seek some improvement at the margin. [[01:18:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4695.36s)]
*  Yeah. So on the view that, you know, increasing GDP is like a very important thing for people to do, or like among the most valuable things that they could do. [[01:18:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4697.6s)]
*  Do you think that people who are taking holidays, for example, or people who just like aren't, you know, starting the business that would that would grow as much as possible, or perhaps, you know, people who could go work in think tanks and do economic reform that would increase GDP much more than what they're doing right now? [[01:18:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4705.64s)]
*  Would you at least and let's say that they do have some moral concerns. [[01:18:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4717.52s)]
*  So you're not so concerned about them like misreading your argument or getting angry and rejecting it. [[01:18:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4720.16s)]
*  Would you say to those people that they do kind of have a duty to do? [[01:18:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4724.5599999999995s)]
*  Absolutely. And I try to encourage them all the time. [[01:18:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4727.12s)]
*  I try to hire them, you know, into think tanks, research centers. [[01:18:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4729.5599999999995s)]
*  It's one of my goals and the more practical side of my life. [[01:18:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4733.599999999999s)]
*  So absolutely. [[01:18:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4736.36s)]
*  Yeah. So let's say it were the case that the best way to increase growth or to increase civilizational stability was to give a very large amounts of money from to give away most of the income that you had to like very poor people who could. [[01:18:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4737.8s)]
*  Earn like a greater rate of return. [[01:19:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4750.12s)]
*  Would you kind of advocate for people for people doing that? [[01:19:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4751.92s)]
*  Absolutely. I'm a big fan of private philanthropy. [[01:19:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4754.24s)]
*  There are quite a few very wealthy people who have pledged to give away most of their fortune. [[01:19:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4756.64s)]
*  I'm a big advocate of that. [[01:19:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4761.92s)]
*  I'm not sure they're all giving it away in the right manner. [[01:19:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4763.2s)]
*  And maybe, you know, they do have an obligation to think more critically about how they're giving it. [[01:19:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4766.08s)]
*  So, of course, but keep in mind, giving money to poor people does not always increase the rate of return. [[01:19:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4770.0s)]
*  Sometimes wealthier people can earn yet more with the money and give more away later. [[01:19:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4776.6s)]
*  So it's not that you should always redistribute now. [[01:19:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4781.2s)]
*  Yeah. So another argument you make is that you want you want to have like a strong grounding for human rights. [[01:19:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4783.68s)]
*  But it seems like on this long termist framework, it's possible that the consequences of actions could be so vast that it would kind of dominate any rights concerns. [[01:19:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4788.56s)]
*  Then, I guess, you make this argument that kind of uncertainty about the consequences of our actions kind of gives us a reason to like still respect human rights. [[01:19:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4797.08s)]
*  Do you want to put that argument? [[01:20:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4804.36s)]
*  Well, let's give a concrete example. [[01:20:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4805.96s)]
*  Right now in the northwestern part of China, the Chinese government is creating camps and detaining large numbers of people by some estimates up to a million. [[01:20:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4807.4800000000005s)]
*  Now, some people in the Chinese government say, well, this is going to help us in the longer run. [[01:20:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4816.8s)]
*  We'll be more stable. [[01:20:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4820.96s)]
*  You know, we'll grow more rapidly. [[01:20:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4822.04s)]
*  I'm very skeptical of that. [[01:20:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4823.72s)]
*  But, you know, you might say, well, there's some chance they're right. [[01:20:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4825.16s)]
*  I think it's unlikely. [[01:20:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4828.4800000000005s)]
*  But let's say you believe that there are gross violations of human rights when there's this deep uncertainty about the future. [[01:20:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4829.36s)]
*  You're not comparing directly while detaining all these people versus the brighter, richer future. [[01:20:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4836.88s)]
*  It's like a lottery ticket. [[01:20:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4842.32s)]
*  And the lottery ticket is so uncertain. [[01:20:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4843.6s)]
*  It's easier to respect the human rights. [[01:20:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4845.52s)]
*  You just say, well, look, these are gross violations of rights. [[01:20:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4847.76s)]
*  There's really not a guaranteed payoff at all. [[01:20:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4850.88s)]
*  It's highly uncertain at best. [[01:20:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4853.2s)]
*  It may even be destabilizing. [[01:20:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4854.96s)]
*  And then I'll just say, just don't do it. [[01:20:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4856.8s)]
*  And your consequentialist conscience, you know, is not knocking on the side of your skull so hard. [[01:20:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4858.88s)]
*  Yeah, but it seems like you've got like massive uncertainty kind of on both sides of the ledger here when you're comparing, you know, the [[01:21:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4863.44s)]
*  the thing where you violate human rights, but you get some massive GDP gain versus the case where you don't and you don't get the GDP gain. [[01:21:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4869.2s)]
*  It's true that there's like massive. [[01:21:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4875.44s)]
*  It's possible that both it's entirely plausible that both of those actions could be both very positive and very negative because the future is just so unforeseeable. [[01:21:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4876.88s)]
*  But I don't see why it kind of breaks in favor of the of the like human rights case rather than just like increasing GDP, because it's like better in expected value terms. [[01:21:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4883.44s)]
*  Again, if you think there's any case for deontology at all, there's not an argument deontology can wield to overturn the consequentialist conclusion in consequentialist terms. [[01:21:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4891.92s)]
*  You're just stuck with don't do it. [[01:21:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4902.44s)]
*  So nowhere in the book do I try to outline how far do those human rights extend. [[01:21:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4904.5599999999995s)]
*  It's partly beyond the sphere of my expertise. [[01:21:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4909.4s)]
*  Also, I'm genuinely uncertain, but it seems to me that their sphere is not zero, not so absolute that everything or even most things are about deontology. [[01:21:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4912.5599999999995s)]
*  Yeah, I wasn't sure whether to challenge you on this, because I think I actually like I think it is good to promote the idea of human rights and to and to lock those into law gets both for moral uncertainty reasons that it's possible that just like violating human rights is just absolutely wrong and no no number of consequences can compensate. [[01:22:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4921.04s)]
*  And also just because it seems like a better rule to follow that. [[01:22:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4934.88s)]
*  In fact, it will lead to a better future, like because GDP isn't everything to be like institutions matter a lot more and concern for welfare as well. [[01:22:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4937.04s)]
*  And I fully admit I punt on the human rights issue that the book is about growth. [[01:22:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4943.2s)]
*  I just want to reassure people. [[01:22:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4946.96s)]
*  You don't have to go crazy and become an evil person to maximize growth, but it would require another book, actually a much longer one. [[01:22:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4948.679999999999s)]
*  And a lot of books should be organized around just one idea, one key idea. [[01:22:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4954.719999999999s)]
*  In the book, you talk, you say that you're in favor of kind of moral pluralism. [[01:22:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4959.48s)]
*  So there's like many different things that are morally valuable and like trading off between them might be kind of hard. [[01:22:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4962.879999999999s)]
*  And one thing that you mentioned is that you think that like great art potentially has like intrinsic moral value, regardless of kind of the effects that it has on people's conscious states. [[01:22:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4967.28s)]
*  So I'm curious to know what would you think of a case where like say there was another universe where there was no life, there was no consciousness, but then by some like crazy natural phenomenon, it was a planet that ended up covered with kind of the great artistic artworks from Earth. [[01:22:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4976.4800000000005s)]
*  But like no one ever got to see them, but they just kind of arose naturally. [[01:23:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4988.4s)]
*  Would that be better than like the same universe, but without that artwork on that planet arising naturally? [[01:23:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4991.12s)]
*  It seems to me it would be better. [[01:23:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4995.96s)]
*  There's more intrinsic value of some kind. [[01:23:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4997.32s)]
*  But I would stress none of the arguments in the book depend on that. [[01:23:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=4999.52s)]
*  No, it's just another part of the bundle that might count as a positive. [[01:23:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5002.4800000000005s)]
*  I guess given that really all you can know is your unconscious states, how do you get this knowledge that kind of art is intrinsically valuable given that you kind of can't perceive the art directly? [[01:23:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5005.5199999999995s)]
*  It seems to me there's something valuable about humanity reaching its highest potential, say through the works of classical music or some of the greatest painters, that is not strictly reducible to the number of people paying money for it or enjoying it at any point in time. [[01:23:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5014.96s)]
*  And at some points in time, that number may be zero. [[01:23:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5029.48s)]
*  So simply having achieved certain kinds of semi-perfectionist peaks to me is part of the pluralist bundle. [[01:23:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5031.88s)]
*  But again, I think it's important that we have arguments robust to those who are skeptical that that should count at all. [[01:23:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5038.599999999999s)]
*  Yeah, I agree. [[01:24:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5043.92s)]
*  That's absolutely not decisive in the book in general. [[01:24:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5044.44s)]
*  I thought that you might say that the planet case is not so useful because it lacks the achievement aspect because it just arose through like erosion or something rather than through anyone actually accomplishing anything. [[01:24:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5046.679999999999s)]
*  And it's kind of the accomplishment that you're valuing. [[01:24:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5054.5599999999995s)]
*  Well, both. [[01:24:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5057.16s)]
*  But if there are beautiful natural structures, as there are, there may be intrinsic value to the natural beauty above and beyond who is able to see them at any point in time. [[01:24:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5057.64s)]
*  Do you worry that kind of this reliance on intuitions about the value of particular things or how we ought to respond to particular cases is kind of vulnerable to evolutionary debunking arguments that it's like we think that streams are particularly beautiful or fertile lands look particularly beautiful. [[01:24:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5065.8s)]
*  It seems like we don't really want to say that, like, in some fundamental objective sense, like all aliens, for example, ought to value, you know, the appearance of like streams or paintings of natural scenes. [[01:24:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5080.96s)]
*  That seems like a very kind of idiosyncratic human thing rather than a fundamental moral moral principle. [[01:24:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5088.96s)]
*  What do you make of that? [[01:24:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5093.4400000000005s)]
*  Philosophers often overuse ethical intuitionism. [[01:24:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5094.360000000001s)]
*  So sometimes I'll read a philosophy in public affairs piece. [[01:24:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5097.52s)]
*  And I'm always just wishing they would write down axioms and argue for or against the axioms. [[01:25:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5100.72s)]
*  But like, here's one comparison they make and then another. [[01:25:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5105.320000000001s)]
*  And you read through the piece, there are 17 different comparisons and you're all supposed to think about them a particular way because these intuitions are supposed to be obvious to us all. [[01:25:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5108.24s)]
*  And those intuitions evolve in a Darwinian sense. [[01:25:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5116.6s)]
*  And we should be skeptical about a lot of them. [[01:25:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5120.08s)]
*  If you're trying to find what's the intuition you should be least skeptical about, I would say it's lives that are like much richer, happier and full of these plural values to an extreme degree compared to other lives. [[01:25:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5122.72s)]
*  Even there, we can't be sure. [[01:25:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5134.12s)]
*  But that seems a kind of ground rock. [[01:25:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5135.679999999999s)]
*  If you won't accept that, I don't know how there's any discourse, but kind of who should get the kidney or different pieces on abortion or redistribution. [[01:25:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5137.36s)]
*  All these results, they seem to me quite sociologically class specific in a way the philosophers themselves are not willing to admit. [[01:25:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5146.88s)]
*  I guess there's a big trade off in philosophy between kind of having a simple theory, a parsimonious theory that only has a few pieces and then like being able to like match the common sense intuitions we have about kind of every case or about every claim. [[01:25:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5155.0s)]
*  I guess I'm like in the field of philosophy specifically, like in favor of parsimony and against kind of following common sense or like having very complicated theories in other domains. [[01:26:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5165.12s)]
*  I think like we need to use common sense and accept a loss of parsimony. [[01:26:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5174.08s)]
*  Where do you fall on that spectrum? [[01:26:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5177.4800000000005s)]
*  So I'm a little closer to common sense than you are. [[01:26:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5178.84s)]
*  So it may not have much metaphysical standing, morally speaking, but the world is ruled by common sense. [[01:26:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5181.88s)]
*  People behave in accord with common sense. [[01:26:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5187.24s)]
*  So it's probably counterproductive to stray too far from common sense. [[01:26:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5189.16s)]
*  So a good ethical theory, which has to has a practical component, it should be in accord with a lot of common sense, but revise other parts of it. [[01:26:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5192.679999999999s)]
*  And you need both. [[01:26:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5199.4s)]
*  And if the theory is either too much just matching the intuitions or totally overturning all of them, I get suspicious. [[01:26:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5200.8s)]
*  And again, this idea of revise at the margin, it seems to me how we make progress in science, in business. [[01:26:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5207.32s)]
*  So maybe it's how we should try to make progress in ethics, too. [[01:26:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5213.36s)]
*  It has a pretty good track record. [[01:26:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5216.04s)]
*  In this book, kind of the influence of the philosopher Derek Parfit is like clearly really vast. [[01:26:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5217.719999999999s)]
*  What do you think Parfit was most wrong about? [[01:27:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5222.799999999999s)]
*  And perhaps what do you think he was most right about that's unappreciated today? [[01:27:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5224.679999999999s)]
*  Not too long before he died, Parfit gave a talk. [[01:27:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5228.879999999999s)]
*  I think it's still on YouTube. [[01:27:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5231.48s)]
*  I think it was at Oxford. [[01:27:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5232.599999999999s)]
*  It was on Effective Altruism. [[01:27:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5233.599999999999s)]
*  And he spoke maybe for 90 minutes and he never once mentioned economic growth, never talked about gains in emerging economies, never mentioned China. [[01:27:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5235.2s)]
*  And I'm not sure he said anything in the talk that was wrong, but that omission strikes me as so badly wrong that the whole talk was misleading. [[01:27:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5243.84s)]
*  It was all about redistribution, which I think has a role. [[01:27:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5250.88s)]
*  But economic growth is much better when you can get it. [[01:27:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5254.28s)]
*  So not knowing enough about some of the social sciences and seeing the import of growth is where he was most wrong. [[01:27:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5257.52s)]
*  I think where he was most important is simply being the walking, living, breathing embodiment of the philosopher who is obsessively curious [[01:27:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5264.2s)]
*  and will plumb the depths of any argument to such an extreme degree like has never been seen before on planet Earth. [[01:27:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5272.48s)]
*  He was just remarkable. [[01:27:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5279.28s)]
*  And that's why he and his work have influenced so many people. [[01:28:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5280.92s)]
*  I'm not sure which of his conclusions stand up or even what his conclusions are. [[01:28:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5284.32s)]
*  He's not about conclusions. [[01:28:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5287.92s)]
*  He's about philosophising in the Socratic sense. [[01:28:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5289.12s)]
*  And for that, he was just such a marvel. [[01:28:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5292.28s)]
*  I wish more people could have like known and seen and heard him. [[01:28:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5294.679999999999s)]
*  Yeah, it was hugely influential to me and a lot of other people. [[01:28:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5298.12s)]
*  It's a real shame he's not with us anymore. [[01:28:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5301.64s)]
*  I guess who do you see as his kind of philosophical successors? [[01:28:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5303.4400000000005s)]
*  I guess because I think of kind of Nick Bostrom at the Future of Humanity Institute, perhaps Nick Beckstead, who wrote this great dissertation on the overwhelming importance of shaping the long term future. [[01:28:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5306.4800000000005s)]
*  Are there other people who you think like we should now look to in lieu of Parfit? [[01:28:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5317.84s)]
*  I'm big fans of the two Nicks you mentioned. [[01:28:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5321.400000000001s)]
*  I don't think of them as substitutes for Parfit. [[01:28:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5323.76s)]
*  I think they're doing something quite different. [[01:28:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5325.96s)]
*  Like Nick Bostrom has an engineering mentality to his work that Parfit never did. [[01:28:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5328.4s)]
*  Like, what can we do? [[01:28:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5333.2s)]
*  What should we do? [[01:28:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5334.16s)]
*  How do we apply resources? [[01:28:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5334.96s)]
*  Maybe it's like the next step. [[01:28:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5337.12s)]
*  But like who is the next Socrates? [[01:28:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5338.76s)]
*  We will see. [[01:29:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5340.96s)]
*  Probably it will be someone from quite an unexpected corner, perhaps. [[01:29:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5342.12s)]
*  You know, I would also mention two influential figures, Nozick and Rawls. [[01:29:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5346.12s)]
*  Rawls influenced a lot of people, but when you read Rawls on growth and the future, it's incoherent. [[01:29:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5350.12s)]
*  So Rawls is afraid of economic growth. [[01:29:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5354.88s)]
*  At times he seems to endorse a stationary state because like any savings makes the first generation worse off and they're the least well off people. [[01:29:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5357.28s)]
*  That to me is a reductio on Rawls' argument, the entire argument. [[01:29:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5364.88s)]
*  To me also. [[01:29:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5369.12s)]
*  And that should not have had as much influence as it has had, though it's a wonderful book. [[01:29:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5369.76s)]
*  You learn a lot from it. [[01:29:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5373.4800000000005s)]
*  And Rawls was a very impressive figure. [[01:29:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5374.88s)]
*  On Nozick, I think his actual views, which you see in his later works, involve a clear understanding that economic growth is good. [[01:29:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5377.28s)]
*  But in Anarchy State and Utopia, it's all about deontology. [[01:29:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5385.4s)]
*  And that doesn't work. [[01:29:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5388.48s)]
*  Like the actual intuition that drives the Wilt Chamberlain example. [[01:29:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5389.48s)]
*  Well, poor people spend money on Wilt Chamberlain. [[01:29:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5392.799999999999s)]
*  They enjoy it. Wilt earns money. [[01:29:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5394.759999999999s)]
*  Is that this is part of some broader process of growth that will elevate many, many people. [[01:29:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5396.5199999999995s)]
*  Not just that it's good if, you know, some poor youths can pay money to see Wilt play basketball. [[01:30:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5401.04s)]
*  So he never brought out what really was making his arguments tick. [[01:30:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5405.839999999999s)]
*  Yeah. [[01:30:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5409.08s)]
*  Hassani had, I think, a much better version of the veil of ignorance kind of argument that advocated in favor of something. [[01:30:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5409.5199999999995s)]
*  Like total utilitarianism. [[01:30:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5415.4s)]
*  And then I feel like it was ruined by Rawls. [[01:30:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5416.599999999999s)]
*  But that his Rawls' theory, it turned out, was like much more popular and got a lot more play. [[01:30:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5418.4s)]
*  What do you think's going on there? [[01:30:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5422.92s)]
*  And do you agree with me that people should go back to the original Hassani veil of ignorance? [[01:30:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5423.759999999999s)]
*  I agree. [[01:30:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5427.28s)]
*  I don't favor either veil of ignorance. [[01:30:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5427.799999999999s)]
*  But Rawls was at Harvard. [[01:30:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5429.839999999999s)]
*  Rawls was a professional philosopher. [[01:30:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5431.04s)]
*  He was connected in the right way. [[01:30:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5433.2s)]
*  His book came along at the right time when people wanted a rationale for a particular kind of social democracy. [[01:30:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5435.0s)]
*  The way in which Rawls in like the principles of liberty and then maxim in principle and like what can be good for everyone, the way all those interact, I tend to think is not coherent. [[01:30:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5441.0s)]
*  And there are many slights of hand in theory of justice, not just the problem with economic growth and future generations and savings rates. [[01:30:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5451.32s)]
*  And it's a brilliant book. [[01:30:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5458.5199999999995s)]
*  How well he disguised those. [[01:30:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5459.5599999999995s)]
*  It's a kind of master class in the philosophy of disguise is how I admire the book. [[01:31:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5461.16s)]
*  So what's the most likely way that the worldview that you're presenting in Southern Attachments would be fundamentally wrong? [[01:31:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5466.92s)]
*  If the pessimistic scenario is correct, history is cyclical. [[01:31:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5473.4400000000005s)]
*  We're going to undergo some kind of retrograde process like there will be some future. [[01:31:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5477.280000000001s)]
*  We're not all going to die. [[01:31:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5480.96s)]
*  But the amount of value in that future is not high enough for the option of continued growth through the future to be the dominant one deciding what it is we should do. [[01:31:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5482.52s)]
*  And there's a pretty good chance that's correct and I'm wrong. [[01:31:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5491.240000000001s)]
*  Yeah, let's work to make that false. [[01:31:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5493.76s)]
*  What would Tyrone have to say about the book? [[01:31:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5496.08s)]
*  Well, I think Tyrone would endorse the pessimistic view that the future is not so grand and glorious. [[01:31:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5497.8s)]
*  It doesn't have the power, the moral power I attribute to it, and that we just ought to have more of a kind of Nietzschean scramble for the here and now. [[01:31:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5503.360000000001s)]
*  And there is no final adjudicator of these clashing values. [[01:31:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5510.88s)]
*  And morality becomes not so much deontological, but for Tyrone, it would become relativistic and almost nihilistic. [[01:31:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5514.320000000001s)]
*  And that's what Tyrone said to me about this book. [[01:32:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5521.28s)]
*  And he bugs me all the time. [[01:32:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5524.4400000000005s)]
*  I try to shut him up, but I can't do it. [[01:32:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5525.68s)]
*  Yeah, maybe we can get him on the 80,000 Hours podcast sometime. [[01:32:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5528.6s)]
*  It seems like the argument is like really robust, though, because even if there's like a 10% chance that the future will be very big and glorious, that that should still like loom extremely large in our moral vision. [[01:32:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5530.92s)]
*  I agree, but let me make another argument against myself. [[01:32:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5540.56s)]
*  And that's the Pascal's wager argument. [[01:32:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5543.16s)]
*  So let's say like sustained growth has a value approaching infinity, but the chance we can ever get there, it's not 10%. [[01:32:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5545.48s)]
*  It's like 1%. [[01:32:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5551.76s)]
*  So if we're not persuaded by Pascal's wager, a small chance of a really large payoff in other contexts, like whether or not we should believe in the deity, maybe I'm offering the new version of Pascal's wager. [[01:32:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5553.08s)]
*  Like decay is really pretty likely. [[01:32:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5563.04s)]
*  The future doesn't extend that far. [[01:32:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5565.08s)]
*  There's like a 1% chance it does. [[01:32:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5567.0s)]
*  And I'm trying to religiously preach to people to believe in that future, make it self-fulfilling, get people to believe. [[01:32:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5569.2s)]
*  But I'm playing my own Pascal's wager game. [[01:32:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5574.599999999999s)]
*  And I'm not saying Pascal's wager is always wrong, but we know it's problematic. [[01:32:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5576.799999999999s)]
*  It's not convincing per se. [[01:33:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5580.5599999999995s)]
*  Yeah. [[01:33:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5582.0s)]
*  And if you're looking for problems in the book, maybe that's another one. [[01:33:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5582.4s)]
*  Yeah, I have an episode with the philosopher Amanda Askell where we talk about problems with infinite ethics and Pascal's wager, which perhaps we can stick up a link to. [[01:33:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5585.719999999999s)]
*  It's like it raises a lot of issues that we don't really have time for here. [[01:33:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5592.799999999999s)]
*  Okay, now in the middle of these discussions, there's usually a segment called overrated versus underrated. [[01:33:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5594.879999999999s)]
*  I'll toss out the names of some things. [[01:33:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5598.799999999999s)]
*  I'm not sure whether you're aware of this, but you're free to pass on any one of them. [[01:33:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5600.32s)]
*  How does it work? [[01:33:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5602.96s)]
*  Am I free to pass? [[01:33:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5605.04s)]
*  Yeah, I know I'm metaphysically free to pass, but won't it disgrace me to pass on one of them? [[01:33:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5606.72s)]
*  All right. [[01:33:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5612.2s)]
*  Chinese moral values. [[01:33:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5612.8s)]
*  Well, that's a big thing. [[01:33:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5614.12s)]
*  Chinese moral values. [[01:33:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5615.12s)]
*  If what you mean is like that China as a nation has invested a lot in infrastructure, that's gone very well for them. [[01:33:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5616.4800000000005s)]
*  If you mean the philosophy of Confucianism, I think it's given them some periods of high political instability and some other periods, Song dynasty today of great success. [[01:33:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5623.08s)]
*  And it has a very mixed record. [[01:33:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5633.2s)]
*  Confucianism probably has done best in Singapore. [[01:33:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5635.12s)]
*  So I'm not sure what I should take Chinese moral values to mean, but China has been the world's leading civilization for several thousand years. [[01:33:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5638.12s)]
*  And we should definitely respect that. [[01:34:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5645.56s)]
*  The deep state. [[01:34:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5647.96s)]
*  You mean how much it exists or how much I like it? [[01:34:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5649.32s)]
*  How good it is. [[01:34:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5652.28s)]
*  I don't believe in a conspiratorial notion of the deep state. [[01:34:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5653.52s)]
*  Now, is it true that there are people, say, in the Washington area who work for intelligence agencies who have outcomes they wish to come about and sometimes leak strategically to the media to help those outcomes come about? [[01:34:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5657.04s)]
*  Or they might even trade intelligence to other people to shift at the margin political maneuvering. [[01:34:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5668.280000000001s)]
*  I think there's some of that. [[01:34:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5673.96s)]
*  I don't think it's nearly the force that some people now are suggesting it is. [[01:34:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5675.280000000001s)]
*  So it's overrated by people to mention it, probably underrated by the majority of Americans who aren't even really aware of it at all. [[01:34:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5679.84s)]
*  But I would have a pretty modest sense of what the deep state is really about. [[01:34:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5686.5199999999995s)]
*  Tristan de Koonha. [[01:34:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5690.679999999999s)]
*  Who? [[01:34:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5692.08s)]
*  The island between South America and Africa. [[01:34:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5692.639999999999s)]
*  So I think it has the smallest permanent population of any island. [[01:34:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5695.16s)]
*  Since I didn't know about it, it must be underrated. [[01:35:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5700.12s)]
*  I've never been there, of course. [[01:35:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5704.759999999999s)]
*  Yeah. [[01:35:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5706.08s)]
*  NATO. [[01:35:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5706.96s)]
*  NATO has been underrated for a long time. [[01:35:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5707.92s)]
*  It's why it has frayed. [[01:35:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5710.32s)]
*  So Putin took deliberate pokes at NATO and indeed beat down NATO's credibility by seizing or disrupting various parts of territory that were not in NATO. [[01:35:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5712.36s)]
*  But NATO might have done more about. [[01:35:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5722.32s)]
*  And right now NATO is ailing. [[01:35:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5724.48s)]
*  Trump attacks NATO. [[01:35:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5726.0s)]
*  We would like to resurrect a feasible version of NATO. [[01:35:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5727.84s)]
*  I fear that maybe we can't. [[01:35:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5730.4s)]
*  But I view this as one of the great tragedies in the world today. [[01:35:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5732.08s)]
*  Americans don't seem to mind. [[01:35:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5734.84s)]
*  So I'll say definitely underrated. [[01:35:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5736.5199999999995s)]
*  Intersectionality. [[01:35:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5738.24s)]
*  Intersectionality is grossly underrated by people on the right. [[01:35:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5739.48s)]
*  So intersectionality, I take to be the notion that if you're a member of more than one, either minority group or group that's discriminated against your kind of multiple membership in discriminated groups creates problems for you in a potentially nonlinear fashion. [[01:35:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5742.72s)]
*  But the kind of social justice warriors on the left far overstate the problems of intersectionality. [[01:35:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5757.5199999999995s)]
*  So it's an idea that ought to be considered important. [[01:36:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5763.88s)]
*  It should be embraced by the middle and not attacked or, you know, celebrated on the two extremes. [[01:36:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5766.68s)]
*  So the idea is not where it should be. [[01:36:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5772.2s)]
*  It's become overly politicized. [[01:36:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5774.04s)]
*  We need to resurrect a more sensible version of it. [[01:36:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5775.84s)]
*  Guamanian cuisine. [[01:36:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5778.44s)]
*  I've never had Guamanian cuisine. [[01:36:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5780.04s)]
*  There's a restaurant in San Francisco closing, I'm told, in two weeks that serves Guamanian cuisine. [[01:36:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5781.96s)]
*  And I've never been to Guam. [[01:36:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5787.76s)]
*  It's not that high in my list of places to go. [[01:36:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5788.92s)]
*  So it's probably underrated, right? [[01:36:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5791.4800000000005s)]
*  Because most cuisine is pretty good if you get the right cook. [[01:36:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5793.28s)]
*  Gary Kearn. [[01:36:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5796.92s)]
*  You mean who is in the Trump administration? [[01:36:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5797.76s)]
*  Yeah. [[01:36:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5799.44s)]
*  I don't know. [[01:36:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5799.72s)]
*  In general, if you worked for the Trump administration early on, you might have had the notion you can do a lot to make things better. [[01:36:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5801.5199999999995s)]
*  And I respected that choice when people made it. [[01:36:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5810.2s)]
*  It seems to me now things are so chaotic and running in such strange, unpredictable and often destructive directions. [[01:36:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5812.8s)]
*  I tend to think most people should not be working in the Trump administration. [[01:37:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5820.879999999999s)]
*  He signed on at a time when maybe there was more promise. [[01:37:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5825.28s)]
*  So probably somewhat underrated. [[01:37:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5829.5199999999995s)]
*  But I don't think he was very effective. [[01:37:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5832.839999999999s)]
*  Choosing to pass on questions in overrated and underrated. [[01:37:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5834.719999999999s)]
*  More people should answer underrated, overrated rather than pass, because you're not expected to give a final answer. [[01:37:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5837.679999999999s)]
*  It's understood. [[01:37:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5846.24s)]
*  It's all about Bayesian updating. [[01:37:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5847.4s)]
*  And what small piece of wisdom can you bring to bear on what others know? [[01:37:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5849.48s)]
*  So the idea that you can't give some perfect answer or you only want to talk about your specialty, I think that's a cop out. [[01:37:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5853.76s)]
*  No one in real life behaves that way. [[01:37:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5859.4s)]
*  So just because you have this artificial distinction between academic knowledge and practical knowledge that you don't want to say something for fear, you'll look bad. [[01:37:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5861.599999999999s)]
*  I don't see why. [[01:37:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5869.44s)]
*  You know, give it a shot. [[01:37:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5870.28s)]
*  What's the harm? [[01:37:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5871.24s)]
*  I guess, yeah, I find overrated and underrated somewhat frustrating at times because I feel like most things are just appropriately rated. [[01:37:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5872.4400000000005s)]
*  Like the market is generally right. [[01:37:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5878.4400000000005s)]
*  And so but people very rarely really defer to that. [[01:38:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5880.0s)]
*  Then you get some was never say that things are appropriately rated. [[01:38:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5882.24s)]
*  Do you think we should at least say appropriately rated more often? [[01:38:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5885.4800000000005s)]
*  Once you consider diversity of opinion, arguably nothing is appropriately rated. [[01:38:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5887.64s)]
*  Right. [[01:38:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5892.08s)]
*  Someone rates it appropriately. [[01:38:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5892.4400000000005s)]
*  But it depends whether you're asking an objective or subjective question. [[01:38:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5894.320000000001s)]
*  It's ambiguous. [[01:38:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5896.64s)]
*  Right. [[01:38:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5897.360000000001s)]
*  But you always have the option of threading out who over rates and under rates it. [[01:38:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5897.64s)]
*  And I tried to do that in some of my answers. [[01:38:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5900.64s)]
*  You know, some things unemployment insurance is that appropriately rated. [[01:38:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5902.76s)]
*  Like maybe that is. [[01:38:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5907.0s)]
*  But for the most part, there's more you can say. [[01:38:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5908.56s)]
*  Yeah. [[01:38:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5910.56s)]
*  All right. [[01:38:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5911.120000000001s)]
*  Being an intellectual dilettante. [[01:38:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5911.360000000001s)]
*  It's begging the question to call it a dilettante. [[01:38:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5912.68s)]
*  I think academia is not producing enough generalists who produce information that a broader, well-educated, intelligent public can consume. [[01:38:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5914.8s)]
*  If someone wants to call them dilettantes, you know, fine. [[01:38:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5924.84s)]
*  But I would say underrated. [[01:38:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5927.56s)]
*  Okay. [[01:38:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5928.96s)]
*  So I guess being a generalist underrated. [[01:38:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5929.120000000001s)]
*  Underrated. [[01:38:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5931.0s)]
*  But of course I am a generalist, but a generalist is also a specialist. [[01:38:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5931.84s)]
*  I sometimes say I specialize in being a generalist and it's a specialty too. [[01:38:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5936.4400000000005s)]
*  It's not different from specializing. [[01:39:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5940.4400000000005s)]
*  You're just specializing in different things. [[01:39:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5942.080000000001s)]
*  Okay. [[01:39:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5944.120000000001s)]
*  Let's push on to substantive questions that aren't about the book. [[01:39:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5944.64s)]
*  What are one or two of the most important things that individuals could do to raise economic growth in your view? [[01:39:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5947.320000000001s)]
*  Listeners especially. [[01:39:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5952.52s)]
*  I think most people are actually pretty good at knowing their weaknesses. [[01:39:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5953.92s)]
*  They're often not very good at knowing their talents and strengths. [[01:39:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5956.84s)]
*  And I include highly successful people. [[01:39:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5960.400000000001s)]
*  You ask them to account for their success and they'll resort to a bunch of cliches, which are probably true, but not really getting at like exactly what they are good at. [[01:39:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5963.16s)]
*  So if I asked you like Robert Wiblin, what exactly are you good at? [[01:39:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5971.360000000001s)]
*  I suspect your answer isn't good enough. [[01:39:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5975.2s)]
*  So just figuring that out and investing more in kind of friends, support network, peers who can help you realize that vision. [[01:39:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5977.72s)]
*  People still don't do enough of that. [[01:39:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5985.36s)]
*  What are one or two things of the most impactful things that individuals listening might be able to do to improve civilizational stability and resilience and make humanity last for longer? [[01:39:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5987.28s)]
*  Other than other than increasing the growth rate. [[01:39:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5997.679999999999s)]
*  Well, they can vote wisely, of course, innovate more in their careers. [[01:39:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=5999.5599999999995s)]
*  Not an option for everyone, but for many people in terms of abusive substances. [[01:40:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6003.84s)]
*  Just stop doing them. [[01:40:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6008.679999999999s)]
*  Right. [[01:40:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6010.16s)]
*  Even if they know their own use is stable, to set an example for others, create a global norm and take common sense morality pretty seriously. [[01:40:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6011.240000000001s)]
*  So you think kind of alcoholism like increases the risk of human extinction materially? [[01:40:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6020.280000000001s)]
*  I would say it lowers our rate of economic growth, lowers the rate of innovation in the long run. [[01:40:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6024.52s)]
*  We're much worse off. [[01:40:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6030.360000000001s)]
*  So indirectly, that leads to a somewhat higher chance of the future collapsing. [[01:40:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6031.4400000000005s)]
*  I don't think directly it's going to have that effect. [[01:40:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6036.52s)]
*  Because given how much kind of conflict between China and the US looms as like an existential risk within the foreseeable future, what about doing things like increasing immigration between those countries? [[01:40:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6038.84s)]
*  So trying to bring lots of Chinese people into the United States to make it less likely that they'll fight or running scholarships to get the elite to move between these two countries so they're all friends and are less likely to want to go to war? [[01:40:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6047.08s)]
*  I favor both of those policies. [[01:40:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6056.68s)]
*  I'm not sure we know how they will affect existential risk or the risk of a conflict. [[01:40:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6058.6s)]
*  We've had many, many Chinese come to the United States. [[01:41:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6063.400000000001s)]
*  Many have gone back to China. [[01:41:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6066.36s)]
*  I'm not sure they advocate for on net policies that lower risk, maybe because they're more educated. [[01:41:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6068.8s)]
*  Some people in the United States are becoming paranoid about how many Chinese are educating. [[01:41:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6076.36s)]
*  I think on net, a wealthier China, even an unfree, undemocratic China is in the interests of the US. [[01:41:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6081.08s)]
*  I guess, yeah. So one option is that, you know, migrants come here and then they go back and they talk about how nice the United States is in some ways, or at least they like feel some relationship with it. [[01:41:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6087.84s)]
*  So it's not such a distant place. [[01:41:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6094.76s)]
*  Another option would just be, you know, having 10 million Chinese people living in the United States, such that the idea of like attacking the US or, you know, having conflict with the US seems like it's also harming Chinese citizens. [[01:41:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6096.2s)]
*  What would you think of that? [[01:41:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6105.08s)]
*  I don't think that would affect the calculus of the Chinese government very much. [[01:41:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6106.04s)]
*  If it came to a major war, I think they would be willing to make sacrifices like that. [[01:41:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6110.04s)]
*  But I don't think the Chinese government thinks at all about attacking the United States. [[01:41:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6115.280000000001s)]
*  The real chance of conflict would be something to do with North Korea or the South China Sea or even India or Japan, where there's a miscalculation. [[01:42:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6120.360000000001s)]
*  And it might lead to weapons of mass destruction being exchanged. [[01:42:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6129.4800000000005s)]
*  But not that the Chinese are going to wake up like now's the day we attack the United States. [[01:42:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6133.84s)]
*  Far more likely the US thinks that about China, if anything. [[01:42:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6137.68s)]
*  What about, you know, becoming a peace activist or something who advocates, you know, that the South China Sea is just not worth destroying the world over? [[01:42:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6140.96s)]
*  Advocates just being very reluctant to have any significant war with a major power. [[01:42:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6147.360000000001s)]
*  Well, the Chinese have already had their way in the South China Sea. [[01:42:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6152.360000000001s)]
*  We may have arrived at that outcome, whether we wanted it or not. [[01:42:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6155.4800000000005s)]
*  I don't know how influential peace activists are on many issues. [[01:42:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6159.72s)]
*  They were influential in getting us out of the Vietnam War. [[01:42:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6163.160000000001s)]
*  So there are clearly some cases of success. [[01:42:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6165.4800000000005s)]
*  But the emotions of voters run so high in foreign policy and the elites are so oriented toward other considerations. [[01:42:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6169.6s)]
*  I'm not sure a lot of peace activism really matters much. [[01:42:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6175.44s)]
*  Yeah. Do you think a lot of listeners should potentially go join Philip Tetlock's research agenda as a way of having more foresight about the problems we'll face and how we might solve them? [[01:42:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6178.5199999999995s)]
*  The people who have the talents where they can contribute to Tetlock's work. Absolutely. [[01:43:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6186.4s)]
*  Yeah. Speaking of Tetlock, are there any really important questions in economics or social science? [[01:43:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6190.5199999999995s)]
*  What would be your top three questions that you'd love to see get more attention? [[01:43:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6195.2s)]
*  Well, what's a single question is hard to say. [[01:43:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6198.599999999999s)]
*  But in general, the role of what is sometimes called culture. [[01:43:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6200.599999999999s)]
*  Like what is culture? How does environment matter? [[01:43:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6203.879999999999s)]
*  I'm sure you know the twin studies where you have identical twins separated at birth and they grow up in two separate environments and they seem to turn out more or less the same. [[01:43:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6206.639999999999s)]
*  That's suggesting some kinds of environmental differences don't matter. [[01:43:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6216.12s)]
*  But then if you simply look at different countries, people who grow up, say, in Croatia compared to people who grow up in Sweden, they have quite different norms, attitudes, practices. [[01:43:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6219.48s)]
*  So when you're controlling the environment that much, surrounding culture matters a great deal. [[01:43:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6229.08s)]
*  So what are the margins where it matters and doesn't? [[01:43:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6233.719999999999s)]
*  What are the mechanisms? [[01:43:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6236.639999999999s)]
*  That to me is one important question. [[01:43:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6238.28s)]
*  A question that will become increasingly important is why do face-to-face interactions matter? [[01:43:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6239.879999999999s)]
*  Why don't we only interact with people online? [[01:44:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6244.32s)]
*  Teach them online, have them work for us online. [[01:44:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6246.28s)]
*  Seems that doesn't work. [[01:44:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6249.28s)]
*  You need to meet people. [[01:44:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6250.2s)]
*  But what is it? [[01:44:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6251.48s)]
*  Is it the ability to kind of look them square in the eye and meet space? [[01:44:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6252.08s)]
*  Is it that you have your peripheral vision picking up other things they do? [[01:44:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6256.0s)]
*  Is it that subconsciously somehow you're smelling them or taking in some other kind of input? [[01:44:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6260.0s)]
*  Like what's really special about face-to-face? [[01:44:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6264.76s)]
*  How can we measure it? [[01:44:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6267.160000000001s)]
*  How can we try to recreate that through AR or VR? [[01:44:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6268.080000000001s)]
*  I think that's a big frontier question right now. [[01:44:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6271.64s)]
*  It would help us boost productivity a lot. [[01:44:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6273.64s)]
*  Those would be two examples of issues. [[01:44:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6276.360000000001s)]
*  I think about how to make philanthropy better. [[01:44:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6278.160000000001s)]
*  So everyone says measure results. [[01:44:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6281.200000000001s)]
*  I think it's become a cliche. [[01:44:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6283.040000000001s)]
*  It's trivial. [[01:44:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6284.400000000001s)]
*  It's begging the question. [[01:44:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6285.4s)]
*  Like what is it you're measuring? [[01:44:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6286.5599999999995s)]
*  What counts as good? [[01:44:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6287.5599999999995s)]
*  What counts as bad? [[01:44:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6288.32s)]
*  Might it not be the case a lot of initiatives will do better by not trying to measure results [[01:44:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6289.72s)]
*  and do better getting outliers rather than homogenising giving with everyone running after the same [[01:44:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6293.8s)]
*  easy to measure kinds of results. [[01:44:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6298.8s)]
*  So okay, if it's not measure results, what is it then? [[01:45:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6300.92s)]
*  We need more philanthropic experiments and to think about them critically. [[01:45:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6303.68s)]
*  Those to me are some of the frontier issues right now. [[01:45:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6307.0s)]
*  If the whole economics discipline came around to our view of having a deep concern for the long-term [[01:45:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6309.5599999999995s)]
*  future, like what neglective topics do you think they might spend a lot more time on? [[01:45:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6314.76s)]
*  I don't think economists are the main problem. [[01:45:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6318.12s)]
*  I would like to see more economists speak to the public. [[01:45:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6320.360000000001s)]
*  It's not really like a single issue, but just take what they know and present it more often in [[01:45:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6323.280000000001s)]
*  digestible form and take greater care to take in a broader set of inputs from others. [[01:45:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6327.88s)]
*  I do get that would involve them working harder, but we've already decided that's their moral [[01:45:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6333.72s)]
*  obligation. So I'm happy to lecture them about that. [[01:45:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6337.76s)]
*  I think economics is one of the healthiest disciplines. [[01:45:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6341.360000000001s)]
*  It's pretty scientific. [[01:45:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6343.68s)]
*  There's not that much fraud in it compared to most other parts of science or semi-science. [[01:45:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6345.6s)]
*  So overall, I'm not a huge critic of economics. [[01:45:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6351.240000000001s)]
*  It's working pretty well compared to most things. [[01:45:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6353.56s)]
*  What fraction of academics, if they were going to try to do as much good as possible, would [[01:45:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6356.12s)]
*  significantly change their research agenda? [[01:46:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6360.92s)]
*  Well, they all would change it. [[01:46:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6363.76s)]
*  Significantly is a tricky word. [[01:46:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6365.240000000001s)]
*  I think a lot of schools, people should not do research at all and should devote more [[01:46:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6367.400000000001s)]
*  attention to teaching. [[01:46:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6371.56s)]
*  That would probably be the single biggest change. [[01:46:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6372.72s)]
*  So they would significantly change their agenda by abolishing it. [[01:46:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6375.080000000001s)]
*  That has to be a significant change, right? [[01:46:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6378.360000000001s)]
*  Go from K to zero percentage terms. [[01:46:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6380.92s)]
*  It's a big change. [[01:46:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6383.120000000001s)]
*  How do you know if you're the kind of person who should do teaching or focus on teaching? [[01:46:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6384.400000000001s)]
*  I think most people actually already know that there are incentive structures where a [[01:46:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6388.400000000001s)]
*  lot of schools who should not be requiring publications for tenure are requiring it. [[01:46:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6393.080000000001s)]
*  And people trod through the motions of doing their dutiful, like seven publications in [[01:46:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6398.28s)]
*  lower tier journals. [[01:46:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6403.48s)]
*  And I think they know that system screwed up. [[01:46:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6404.839999999999s)]
*  So I don't think figuring it out is the problem. [[01:46:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6408.4s)]
*  It's fixing the incentives of the schools who want to try to like punch above their [[01:46:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6411.28s)]
*  weight. And it ends up being a zero or negative sum game. [[01:46:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6416.08s)]
*  How likely is it the case that the most important thing to track is not the global economic [[01:46:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6419.24s)]
*  growth rate, but rather the relative growth rate of countries that have the best moral [[01:47:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6423.68s)]
*  values versus those that have like relatively worse moral values? [[01:47:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6427.68s)]
*  That is kind of a more Manichaean vision of the future, where it's like the right people [[01:47:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6430.4400000000005s)]
*  have to have like power and influence. [[01:47:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6434.04s)]
*  It's a very good question. [[01:47:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6436.08s)]
*  I don't think we can say which countries have the best moral values. [[01:47:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6437.68s)]
*  A lot of people will tell you that's the United States. [[01:47:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6441.08s)]
*  But our longer run history is a pretty brutal one. [[01:47:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6443.56s)]
*  And we've treated a lot of disadvantaged groups very badly. [[01:47:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6446.56s)]
*  If you look at a lot of smaller countries, they've done a lot less wrongdoing, but they [[01:47:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6451.04s)]
*  also were not in a position to. [[01:47:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6455.8s)]
*  So to kind of glorify them as the model to copy, I think is begging the question, because [[01:47:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6458.08s)]
*  if they had more power, well, what would they have done? [[01:47:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6463.5199999999995s)]
*  We don't know. So I think of it more in terms of strands or tendencies we want to [[01:47:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6465.96s)]
*  encourage in all the countries and the so-called like bad, evil countries. [[01:47:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6471.76s)]
*  So many people can be so good or good at heart or maybe even partly because they're in a [[01:47:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6475.8s)]
*  bad country, like in the former Soviet Union, bonds of friendship often were stronger. [[01:48:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6480.12s)]
*  So I think we need to unpack the whole notion of like the better and worse countries and [[01:48:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6485.04s)]
*  mostly be a lot more self-critical about our own country, whichever one that may be. [[01:48:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6489.72s)]
*  Do you think that people overstate or understate kind of the differences, both like morally [[01:48:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6494.24s)]
*  and otherwise, between people in different countries? [[01:48:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6498.6s)]
*  I think they overstate the differences. [[01:48:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6500.96s)]
*  Most people are selfish in a wide variety of situations and their environments change. [[01:48:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6503.4400000000005s)]
*  They can be much better or much worse. [[01:48:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6508.4800000000005s)]
*  But to really say like these are the bad people, I'm pretty reluctant to do that. [[01:48:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6510.8s)]
*  So we should be more willing to kind of defer and just give free birth to other countries [[01:48:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6515.320000000001s)]
*  and less interested in conflict to contain them. [[01:48:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6520.84s)]
*  Well, I don't think that follows. [[01:48:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6524.280000000001s)]
*  I guess I agree with what you're saying. [[01:48:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6525.4800000000005s)]
*  But the mere fact that the ordinary citizens in some country might be better than it seems [[01:48:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6527.68s)]
*  doesn't itself mean we shouldn't intervene. [[01:48:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6533.5199999999995s)]
*  If you look at what NATO did in former Yugoslavia, it seems to me that was actually a good [[01:48:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6535.48s)]
*  intervention. It worked out well. [[01:49:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6540.36s)]
*  And you can think that was a good idea without thinking they were all evil people, which [[01:49:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6542.16s)]
*  I don't think at all. I've been to all of those countries, but Montenegro and like have [[01:49:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6546.24s)]
*  had a lot of fond connections with people who live there and were alive at the time. [[01:49:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6550.72s)]
*  So I'd say it's pretty separate questions. [[01:49:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6554.76s)]
*  Yeah. So looking back from today, people often say that one of the most important things [[01:49:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6557.16s)]
*  in the 21st century was that the United States developed nuclear weapons before the Nazis [[01:49:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6561.4400000000005s)]
*  did and that it was like it could be of like very great long term significance that the [[01:49:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6566.84s)]
*  US developed nuclear weapons first and then the Soviet Union next, rather than some other [[01:49:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6570.320000000001s)]
*  group of countries. Looking forward 500 years from now, how likely is it that we might look [[01:49:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6574.320000000001s)]
*  back and say, you know, the details of how some like really important technology developed, [[01:49:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6578.6s)]
*  like who got it first and how they applied it early on was kind of like the decisive [[01:49:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6582.12s)]
*  issue of how the 21st century went in the scheme of things. [[01:49:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6585.96s)]
*  There's a very good chance that matters. [[01:49:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6588.68s)]
*  And as you know, China and actually also Russia are experimenting pretty furiously with many [[01:49:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6590.44s)]
*  new kinds of weapons, cyber weapons. [[01:49:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6595.64s)]
*  United States is probably ahead of them in most cases. [[01:49:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6597.92s)]
*  I'm not even sure we always want the United States to be ahead. [[01:50:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6601.44s)]
*  Yeah, expand on that. [[01:50:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6604.88s)]
*  If you take, say, cyber weapons, we don't know how much damage they can do, but it could [[01:50:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6605.8s)]
*  be that some weaker but kind of quote unquote more evil countries having more powerful [[01:50:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6611.48s)]
*  cyber weapons could bring about a sense of balance. [[01:50:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6615.919999999999s)]
*  I think one of the big trends in the world today is that the super powerful countries [[01:50:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6618.919999999999s)]
*  are much weaker compared to kind of mid-level emerging economies than they were 30 years [[01:50:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6623.919999999999s)]
*  ago. So a place like Turkey or Saudi Arabia, kind of in total net military and geopolitical [[01:50:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6629.16s)]
*  terms, those countries have much more clout than they did not long ago. [[01:50:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6635.24s)]
*  And that makes the United States, China, also Russia, quite a bit weaker. [[01:50:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6640.08s)]
*  People don't talk about this much, but you have many more regional powers with a lot of [[01:50:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6643.8s)]
*  sway. Maybe that's stabilizing. [[01:50:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6647.72s)]
*  I don't know. [[01:50:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6650.0s)]
*  It seems more likely that it will be destabilizing to have a more multipolar world with lots [[01:50:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6650.88s)]
*  of different actors that, you know, because you're like any one conflict can be extremely [[01:50:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6655.0s)]
*  dangerous and you've got like more more connections between the different actors that [[01:50:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6658.4s)]
*  matter. [[01:51:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6661.72s)]
*  But you might be more robust. [[01:51:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6662.4s)]
*  So the old story is like two polarities of power versus many. [[01:51:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6663.72s)]
*  And then the two looks pretty stable, right? [[01:51:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6669.68s)]
*  Deterrence, USA, USSR. [[01:51:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6671.84s)]
*  But if it's three compared to a world with many centers of power, I don't know that three [[01:51:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6675.360000000001s)]
*  is very stable. Didn't Sartre say like three people is hell? [[01:51:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6680.0s)]
*  Or like seven. Is seven a stable number? [[01:51:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6683.92s)]
*  We don't know very much. [[01:51:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6686.56s)]
*  So it could just be once you get out of two party stability, you want a certain flattening [[01:51:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6687.64s)]
*  and maybe some parts of the world will have conflicts that are undesirable. [[01:51:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6692.8s)]
*  But nonetheless, by having the major powers keep their distance, that's better, maybe. [[01:51:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6696.6s)]
*  So the world seems more resilient today in that it's richer. [[01:51:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6702.72s)]
*  And so we have like we can like lose a lot of GDP without starving. [[01:51:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6706.360000000001s)]
*  On the other hand, it seems less stable, less resilient because we're all interconnected [[01:51:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6709.88s)]
*  such that a disaster anywhere like a disease can spread everywhere very quickly and there's [[01:51:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6714.04s)]
*  nowhere that's protected from it. [[01:51:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6717.8s)]
*  If we could potentially like bifurcate the world into two totally separate like halves [[01:51:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6719.4s)]
*  that barely had any contact with one another or you had to go through a quarantine in order [[01:52:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6723.28s)]
*  to get to the other half, would that hypothetically be a good idea in order to increase sustainability? [[01:52:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6726.72s)]
*  If you could start off with there being two separate planets operating independently and [[01:52:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6732.12s)]
*  half the population on each, that would be better. [[01:52:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6737.08s)]
*  But given where we're at, I don't think there's a way for that divorce to go amicably. [[01:52:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6740.16s)]
*  And even in a much earlier time. [[01:52:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6745.08s)]
*  So smallpox does spread to the new world. [[01:52:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6746.6s)]
*  It's true. It kind of spread slowly, but it still kills millions of people. [[01:52:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6748.64s)]
*  So prevention of pandemics also spreads more quickly. [[01:52:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6753.84s)]
*  And it's striking. We haven't, other than HIV, had a major pandemic of the flu or smallpox [[01:52:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6757.84s)]
*  kind in some time. [[01:52:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6763.76s)]
*  And maybe that's because a number of positive things have spread. [[01:52:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6766.12s)]
*  It may just be good luck. [[01:52:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6768.88s)]
*  Yeah, we've had a few near misses, but it does. [[01:52:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6770.76s)]
*  It's unclear whether the risk is greater or lower. [[01:52:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6772.400000000001s)]
*  Right. It might be lower. [[01:52:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6774.6s)]
*  So it could be. [[01:52:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6775.84s)]
*  How has the economics profession kind of directly and significantly improved the lives of [[01:52:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6776.96s)]
*  people on Earth over the last 75 years? [[01:53:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6780.92s)]
*  What are the most important breakthroughs? [[01:53:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6782.52s)]
*  Public health is the biggest breakthrough. [[01:53:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6784.240000000001s)]
*  By no means is it all or even mostly economists. [[01:53:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6786.0s)]
*  But economists and economic ways of thinking have played a big role in allocating resources. [[01:53:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6789.200000000001s)]
*  The general notion that economies should be relatively free and capitalistic. [[01:53:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6794.52s)]
*  Economists have been the major carrier of that notion. [[01:53:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6798.360000000001s)]
*  Maybe some sides of that have been overrated. [[01:53:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6801.52s)]
*  But on the whole, it's been a massively positive development that you've had a Hong Kong [[01:53:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6803.68s)]
*  and a Singapore and a Japan and a South Korea is because of the longer term influence of [[01:53:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6808.0s)]
*  economists. And in turn, those led to having a China. [[01:53:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6812.84s)]
*  Just the general level of expertise in emerging economies, again, by no means is it all or [[01:53:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6817.200000000001s)]
*  even mainly economists, much higher than it was a few decades ago. [[01:53:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6821.64s)]
*  And those are much better run places. [[01:53:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6825.160000000001s)]
*  Foreign aid is better allocated. [[01:53:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6826.92s)]
*  So general technocratic means of thinking, economics being a part of it, it's had a very, [[01:53:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6829.04s)]
*  very strong track record over the last century. [[01:53:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6834.52s)]
*  Yeah. You mentioned earlier the fact that particulate matter from coal and cars kills [[01:53:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6837.76s)]
*  way more people than we imagine or than most people think and causes like all kinds of [[01:54:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6842.04s)]
*  other health issues. And kind of my view is that, you know, the US should be like racing [[01:54:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6846.320000000001s)]
*  to eliminate coal, even setting aside climate change just because of the public health [[01:54:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6849.68s)]
*  gains. Why doesn't that happen? [[01:54:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6852.64s)]
*  Why are people shouting in the streets about this? [[01:54:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6854.0s)]
*  Most people don't care. [[01:54:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6856.240000000001s)]
*  Most people don't know about it. [[01:54:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6858.4400000000005s)]
*  It's not a politically divisive issue where there's one side motivated to do a great deal [[01:54:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6860.84s)]
*  for it. But also where most of the deaths come are in poorer economies. [[01:54:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6865.16s)]
*  And it's hard to substitute away from coal. [[01:54:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6869.96s)]
*  And a lot of it is indoor burning of fuels. [[01:54:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6872.96s)]
*  There is a great amount of low hanging fruit there limiting that. [[01:54:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6875.4400000000005s)]
*  But it's not easy for anyone to get their paws into manipulating those decisions. [[01:54:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6879.0s)]
*  So I don't think it's an easy problem. [[01:54:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6883.84s)]
*  If it were an easy problem, we would have a much stronger movement to fix it now. [[01:54:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6885.88s)]
*  The way you do with some of the public health issues, like let's stamp out malaria, polio. [[01:54:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6890.12s)]
*  Polio has gone further than malaria, but I think malaria will come about as well. [[01:54:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6895.0s)]
*  It's I wouldn't say it's an easy target, but it's easy to identify. [[01:54:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6898.68s)]
*  You more or less know what you have to do. [[01:55:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6901.76s)]
*  We're mostly doing it. [[01:55:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6903.72s)]
*  Yeah. Uber ran roughshod over laws all over the place, but in the process increased GDP [[01:55:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6905.12s)]
*  a lot. On balance, should we think that Uber is good or bad? [[01:55:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6910.08s)]
*  Of course it's good. [[01:55:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6912.92s)]
*  Right. [[01:55:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6913.96s)]
*  And we use it. [[01:55:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6914.64s)]
*  If Uber had had to ask permission, it might never have happened. [[01:55:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6915.6s)]
*  It might've been like, oh, you can do a thousand trial vehicles and 20 years later, [[01:55:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6919.04s)]
*  we'll revisit this. [[01:55:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6923.08s)]
*  But they just did it. [[01:55:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6924.52s)]
*  It was wonderful. [[01:55:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6925.28s)]
*  It was amazing. [[01:55:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6926.0s)]
*  It's the kind of behaviour I think we should have more of as I've argued in several [[01:55:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6927.12s)]
*  places. [[01:55:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6930.76s)]
*  And like you say, it maximises growth of GDP. [[01:55:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6932.0s)]
*  It fits my standard. [[01:55:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6935.04s)]
*  So of course I'm going to endorse it. [[01:55:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6936.24s)]
*  Don't you worry that there could be significant downsides for reducing respect for the [[01:55:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6937.72s)]
*  rule of law and that kind of institution? [[01:55:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6940.96s)]
*  Well, as I understand what Uber did in the United States, it was not against the law. [[01:55:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6943.4800000000005s)]
*  Simply no one had thought to write a law banning ride sharing because it hadn't [[01:55:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6947.52s)]
*  occurred to people. [[01:55:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6951.76s)]
*  So if there's a kind of empty legal space and you do something that's permitted, I [[01:55:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6952.96s)]
*  think that's fine. [[01:55:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6956.64s)]
*  Should you always have to ask permission for anything you do? [[01:55:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6957.68s)]
*  That would be a tyrannical regime. [[01:56:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6960.96s)]
*  So when local governments ban just ordinary economic activity, do you think people [[01:56:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6962.4800000000005s)]
*  have kind of any reason to follow those laws if they can get away with it? [[01:56:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6967.52s)]
*  Or are those laws just unjust and in fact they don't give us any reasons for action? [[01:56:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6971.08s)]
*  The laws are unjust, but I don't in general advocate people breaking the law. [[01:56:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6975.36s)]
*  I think they should work to change laws. [[01:56:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6979.08s)]
*  There are some laws where the rights infringement on individuals is so great. [[01:56:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6981.16s)]
*  You are justified in actually rebelling against the law. [[01:56:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6984.24s)]
*  But opening a taco truck isn't as severe as that. [[01:56:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6987.36s)]
*  Correct. [[01:56:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6990.04s)]
*  So if taco trucks are banned in a city and that's a bad law as it usually is, that [[01:56:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6990.44s)]
*  everyone goes rogue, I think has some negative long run consequences. [[01:56:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6995.56s)]
*  So I don't think that's the best strategy. [[01:56:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=6999.08s)]
*  Arguably immigration restrictions are the greatest human rights violation or among the [[01:56:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7001.36s)]
*  greatest human rights violations. [[01:56:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7004.5599999999995s)]
*  Should then people be willing to violate immigration law if they can get away with it? [[01:56:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7005.88s)]
*  Well, there's different layers of immigration law. [[01:56:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7009.68s)]
*  There's the law that's on the books and that's not the law which anyone intends. [[01:56:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7011.64s)]
*  So the laws put on the books with the understanding that there will be a certain level of [[01:56:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7016.8s)]
*  illegal immigration and this is desired and tolerated. [[01:57:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7020.6s)]
*  So I think you have to understand the law often as something richer and more complex [[01:57:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7023.84s)]
*  than what's written and the margins of illegal immigration we have had in the United [[01:57:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7027.8s)]
*  States, I do not in general object to. [[01:57:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7032.68s)]
*  There may be particular cases, you know, a murderer came to this country and so on. [[01:57:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7035.320000000001s)]
*  But you know, what the law says has some ambiguity to it. [[01:57:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7038.56s)]
*  All right. [[01:57:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7043.12s)]
*  Let's talk about animals for a moment. [[01:57:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7043.280000000001s)]
*  You almost certainly think it's wrong to cause animals to suffer. [[01:57:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7045.04s)]
*  No, I don't think suffering per se. [[01:57:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7048.240000000001s)]
*  All else equal? [[01:57:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7050.12s)]
*  I don't think all else can be equal. [[01:57:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7051.240000000001s)]
*  I think it's wrong to raise animals in factory farms and design large scale efficient [[01:57:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7053.08s)]
*  institutions to torture them. [[01:57:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7057.52s)]
*  I would say that's wrong. [[01:57:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7059.080000000001s)]
*  But animals live in a Malthusian world. [[01:57:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7060.6s)]
*  They don't have these cones of sustainable economic growth and a lot of their lives are [[01:57:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7062.52s)]
*  just suffering anyway. [[01:57:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7066.72s)]
*  And if we're kind of making them suffer in our preferred way at the margin, I don't think [[01:57:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7068.64s)]
*  that's necessarily wrong. [[01:57:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7072.68s)]
*  But you think that the suffering that we're causing animals systematically in farms is [[01:57:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7074.200000000001s)]
*  wrong? [[01:57:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7078.240000000001s)]
*  Absolutely. [[01:57:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7078.56s)]
*  So these intelligent animals. [[01:57:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7079.200000000001s)]
*  So in light of that, like it's abstaining from eating meat like a more moral diet all [[01:58:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7081.52s)]
*  else equal? [[01:58:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7084.84s)]
*  Sure. [[01:58:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7085.8s)]
*  Yeah. [[01:58:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7086.120000000001s)]
*  And it helps with climate change. [[01:58:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7086.679999999999s)]
*  If humanity continues for another thousand years, do you think we'll take significant [[01:58:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7088.08s)]
*  steps to improve the welfare of wild animals? [[01:58:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7091.44s)]
*  A thousand years is a hard time horizon for forecasting. [[01:58:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7094.0s)]
*  I don't see it on any horizon that I can imagine. [[01:58:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7096.96s)]
*  I think humans are programmed to kill and eat animals and they were programmed to see [[01:58:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7100.48s)]
*  that it's not that wrong. [[01:58:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7104.4s)]
*  And the sociological concentration of vegans and vegetarians is quite striking. [[01:58:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7105.84s)]
*  And even most of them actually eat meat no matter what they may claim. [[01:58:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7110.28s)]
*  So my best guess is it won't change for a very long time if ever. [[01:58:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7113.72s)]
*  Yeah. [[01:58:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7117.72s)]
*  Over that kind of time scale though, you know, if economic growth continues, we'll be [[01:58:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7118.08s)]
*  fabulously wealthy by that point in time. [[01:58:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7121.2s)]
*  So like we'll be able to afford doing even things that we have kind of weak inclinations [[01:58:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7123.0s)]
*  to do. [[01:58:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7126.32s)]
*  And we might also, you know, have become either much better at philosophy, ideas might [[01:58:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7126.8s)]
*  have changed, ideology might have changed. [[01:58:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7130.0s)]
*  We might also have the ability to kind of change our like inclinations, our everyday [[01:58:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7131.6s)]
*  inclinations to bring them more in line with our reflective moral values. [[01:58:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7135.0s)]
*  Does any of that cause you to kind of change your assessment of the probability? [[01:58:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7137.8s)]
*  No, I think people are programmed to enjoy meat and that biology is stronger than the [[01:59:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7141.16s)]
*  changes you mentioned. [[01:59:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7146.4s)]
*  Again, a long enough time horizon, all sorts of things can change. [[01:59:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7147.4s)]
*  If we simply invent something better than meat, right? [[01:59:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7150.64s)]
*  Yeah. [[01:59:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7152.68s)]
*  Of course people will change for selfish reasons. [[01:59:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7152.96s)]
*  And at some point that may well happen. [[01:59:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7155.5599999999995s)]
*  But I think you have to get to that point. [[01:59:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7157.5599999999995s)]
*  Yeah. [[01:59:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7159.2s)]
*  I mean, I'd be shocked for us to still be eating like animals the way that we produce [[01:59:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7159.5199999999995s)]
*  them now in a couple of hundred years, because I suspect that we'll produce like meat in [[01:59:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7163.32s)]
*  a much more efficient way that doesn't involve torturing animals. [[01:59:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7165.96s)]
*  That's certainly possibly true. [[01:59:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7168.5199999999995s)]
*  But the ventures I hear about going on now seem to be quite overrated and I don't think [[01:59:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7169.88s)]
*  they're really close to catching on. [[01:59:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7174.32s)]
*  But in the long run, you think there's a good chance they will. [[01:59:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7175.96s)]
*  Absolutely. Over some very long run. [[01:59:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7177.76s)]
*  Yes. [[01:59:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7179.400000000001s)]
*  Yeah. [[01:59:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7179.8s)]
*  But setting aside the meat thing, it seems like there's kind of two questions here. [[01:59:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7180.6s)]
*  Like one thing would be that, yes, we want to eat meat and we'll be eating meat in some [[01:59:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7183.84s)]
*  form regardless. [[01:59:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7187.2s)]
*  But nonetheless, we might think, oh, it's like it's terrible that all these animals in [[01:59:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7188.16s)]
*  the wild are suffering. [[01:59:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7190.88s)]
*  They're like dying because of parasites. [[01:59:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7192.28s)]
*  They have these horrible diseases or they're starving to death. [[01:59:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7194.2s)]
*  And so we might take kind of some action if we're incredibly wealthy to improve their [[01:59:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7196.64s)]
*  welfare. [[02:00:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7200.080000000001s)]
*  I don't think we will. [[02:00:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7200.88s)]
*  You know, we engineer nature somewhat right now. [[02:00:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7202.0s)]
*  So we manage deer populations. [[02:00:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7204.64s)]
*  You might keep coyotes out of a national park. [[02:00:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7206.56s)]
*  As we get richer, we'll do more of it. [[02:00:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7209.280000000001s)]
*  But again, I think we're largely indifferent to what I'm calling nature and maybe the [[02:00:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7211.68s)]
*  fundamental and indeed insoluble problem of philosophy is how to integrate the claims [[02:00:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7215.92s)]
*  of nature with the claims of culture. [[02:00:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7220.92s)]
*  And they're so there's such separate spheres, but they interact all the time. [[02:00:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7223.04s)]
*  And, you know, the final appendix B of my book, I talk about this problem. [[02:00:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7226.64s)]
*  Like, how do you weight the interests of humans versus animals or creatures that are [[02:00:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7230.240000000001s)]
*  very little to do with human beings? [[02:00:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7234.96s)]
*  And I think there's no answer to that. [[02:00:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7237.76s)]
*  The moral arguments of stubborn attachments, they're all within a kind of a cone of [[02:00:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7239.160000000001s)]
*  sustainable growth for some set of beings and comparing across beings. [[02:00:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7243.68s)]
*  I don't think anyone has good moral theories for that. [[02:00:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7248.360000000001s)]
*  But it seems like on your view, you should think that while we don't know what the [[02:00:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7251.240000000001s)]
*  correct moral tradeoff is between humans and animals, there is a correct moral [[02:00:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7254.4s)]
*  tradeoff. It's just very hard to figure out what it is. [[02:00:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7259.04s)]
*  I'm not sure what we would make reference to to make that tradeoff. [[02:01:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7261.44s)]
*  So there's some intuitionism, like gratuitous cruelty to animals, even not very [[02:01:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7264.48s)]
*  intelligent ones. People seem to think it's bad. [[02:01:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7268.96s)]
*  That's easy enough to buy into. [[02:01:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7271.5199999999995s)]
*  But you support interpersonal aggregation across humans. [[02:01:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7273.36s)]
*  And then it just seems like there should be a similar principle, though more [[02:01:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7276.96s)]
*  difficult to apply in practice, that would apply to a chimpanzee and a human. [[02:01:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7279.76s)]
*  We're very far from knowing what it is, but chimpanzees are pretty close to [[02:01:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7283.2s)]
*  humans. That strikes me as quite possible. [[02:01:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7286.16s)]
*  But if you're talking about bees and humans, you know, what if another billion [[02:01:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7289.6s)]
*  bees can exist, but one human has to have ongoing problems with migraine [[02:01:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7293.72s)]
*  headaches? My best guess is we will never have a way of really solving that [[02:01:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7297.76s)]
*  question using ethics. [[02:01:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7302.28s)]
*  Yeah, I agree that the practical problem gets very severe when you're comparing [[02:01:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7303.64s)]
*  humans and insects. But I think like in principle, the solution follows the [[02:01:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7306.28s)]
*  same kind of process as when you're comparing humans and other humans and [[02:01:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7310.24s)]
*  chimps. [[02:01:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7313.2s)]
*  I'm not sure the practical problem is different from the conceptual problem. [[02:01:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7313.72s)]
*  I think it's a conceptual problem, not a practical one. [[02:01:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7316.88s)]
*  We could hook up all the measurements to those bees we want. [[02:01:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7319.56s)]
*  And at the end of the day, whether a billion of them is worth a migraine [[02:02:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7322.24s)]
*  headache for a human. [[02:02:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7324.96s)]
*  But you say you're a moral realist section. [[02:02:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7326.08s)]
*  Shouldn't there be an answer then? [[02:02:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7327.6s)]
*  I don't think there's an answer to every question under moral realism. [[02:02:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7329.12s)]
*  Is it possible that murdering non-human animals might be morally prohibited in [[02:02:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7333.28s)]
*  the same way that like because of human rights, it's kind of morally prohibited [[02:02:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7336.6s)]
*  to murder another human. [[02:02:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7339.36s)]
*  Oh, of course. [[02:02:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7340.36s)]
*  Yeah. And even if that's kind of unlikely and sounds like you think it might not [[02:02:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7341.0s)]
*  be that unlikely, like just because of moral uncertainty, because it might be [[02:02:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7343.44s)]
*  morally prohibited and might just be really terrible. [[02:02:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7346.28s)]
*  We should abstain from murdering animals. [[02:02:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7348.04s)]
*  As much as we can. Yes. [[02:02:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7350.0s)]
*  Yeah. All right. Let's talk about discourse more broadly. [[02:02:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7351.36s)]
*  So in general, when writing your approach seems to be to kind of canvas like many [[02:02:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7353.72s)]
*  different considerations without feeling kind of a strong need to really like [[02:02:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7357.16s)]
*  settle any issue definitively or like take a really strong stance or, you know, [[02:02:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7360.12s)]
*  stick with one topic at great length. [[02:02:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7364.12s)]
*  Is that just kind of your comparative advantage in the scheme of things? [[02:02:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7365.96s)]
*  Or do you advocate that more people kind of tread lightly over topics like that? [[02:02:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7368.0s)]
*  It's my comparative advantage. [[02:02:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7370.96s)]
*  I guess if I'm saying more people should be generalists, more will be doing that. [[02:02:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7372.44s)]
*  But I would also stress, you know, the arguments in this book and my other books, [[02:02:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7376.04s)]
*  I typically address a lot of the points at greater length in journal articles or [[02:02:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7379.92s)]
*  subsequent blog posts or responses to reviews or even in podcasts like this one. [[02:03:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7383.2s)]
*  So knowledge is more distributed. [[02:03:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7388.72s)]
*  And the idea that some of your products are somewhat short and compact and reach a [[02:03:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7391.16s)]
*  larger audience and you fill out the points of details and other media. [[02:03:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7395.28s)]
*  I think that's often an efficient way to proceed. And that's what I try to do. [[02:03:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7399.84s)]
*  Yeah. When I interviewed Tetlock, he said that it's kind of good not to publicly [[02:03:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7403.0s)]
*  commit to kind of what your sincere views are, because then it makes you much more [[02:03:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7407.36s)]
*  flexible. You don't feel like there's any loss of face when you seem to change your [[02:03:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7410.8s)]
*  views. Do you think that that's something that you do? [[02:03:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7413.679999999999s)]
*  No, I try to put out a great number of views on the table, but be very willing to [[02:03:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7416.44s)]
*  revise them. So if I put forward a view, like it is a sincere view, [[02:03:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7421.12s)]
*  and then to show people later on, you're changing your mind is one of the valuable [[02:03:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7425.32s)]
*  things you can communicate, maybe more valuable than the view itself. [[02:03:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7429.04s)]
*  Yeah. Well, how much it seems like with perhaps like effective altruism and [[02:03:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7432.2s)]
*  cryptocurrency, in one case you were like positive about effective altruism, then [[02:03:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7435.24s)]
*  like became like more negative about it. Once perhaps other people had appreciated [[02:03:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7438.5599999999995s)]
*  its virtues. The important thing is to say now this is maybe overrated with [[02:04:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7441.4s)]
*  crypto. When people were talking about how great it was, you said it was bad and [[02:04:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7445.08s)]
*  then kind of vice versa. Do you kind of see that role where you want to push in [[02:04:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7447.44s)]
*  the direction that you think people's views ought to change? [[02:04:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7450.8s)]
*  Yes. And you see what people are saying and what points are missing, and that's [[02:04:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7453.12s)]
*  where you can add the most value. People sometimes will think you've changed your [[02:04:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7456.12s)]
*  mind more than you have, but you know. [[02:04:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7459.200000000001s)]
*  Yeah, just emphasising a different side of the same view. [[02:04:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7460.84s)]
*  Yeah. [[02:04:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7462.72s)]
*  Why do you allow comments on marginal revolution? It seems like you put in all [[02:04:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7463.200000000001s)]
*  of this effort into building up a huge audience and then kind of random people [[02:04:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7466.400000000001s)]
*  can hijack it and get very large numbers of your readers to read whatever random [[02:04:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7468.84s)]
*  thing they put in. [[02:04:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7471.88s)]
*  Well, anyone who reads the comments does so voluntarily. Some of the comments are [[02:04:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7472.92s)]
*  quite good. Many are bad, but the comments create context for the post. So I love [[02:04:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7477.4800000000005s)]
*  writing a post where I just tell the person where my mind is at and I really [[02:04:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7482.08s)]
*  don't give them any background. And a lot of people need the background and they [[02:04:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7486.08s)]
*  get that background from the comments, including the stupid ones. Even the [[02:04:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7490.24s)]
*  stupidest comments can indicate like who is offended, who should be offended, who [[02:04:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7494.04s)]
*  shouldn't be offended, and they're more valuable than they might look. [[02:04:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7498.04s)]
*  Yeah. [[02:05:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7501.16s)]
*  And if I didn't have the comments and I had to, well, here's the Wikipedia page [[02:05:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7501.6s)]
*  for this and be more didactic and lay out the whole argument. I would be a worse [[02:05:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7505.0s)]
*  writer. It would be a higher tax on me. So I think the comments are great. Even [[02:05:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7509.8s)]
*  like the bad comments are in a funny way underrated. The offensive ones, I really [[02:05:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7513.84s)]
*  do think are very bad. People shouldn't do that. They should be morally obliged, [[02:05:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7519.12s)]
*  like not to try to hurt others. That's like really very bad. And I, you know, you [[02:05:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7523.280000000001s)]
*  do what you can. [[02:05:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7527.84s)]
*  Yeah. I feel like that's kind of a self-control issue for me here where I [[02:05:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7528.64s)]
*  always read the comments, even though I feel like I'm being harmed while I'm [[02:05:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7532.280000000001s)]
*  doing it, or at least on reflection. [[02:05:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7534.68s)]
*  Maybe they are useful to you, right? [[02:05:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7536.64s)]
*  Maybe I'm just wrong about what I think I want. I want. [[02:05:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7538.599999999999s)]
*  If you have the self-control to work in a nonprofit, 80,000 hours that does all [[02:05:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7540.92s)]
*  this good, and you follow the obligation for your maximally do good in career, [[02:05:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7545.28s)]
*  probably your decision on reading the comments is also the right one. [[02:05:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7550.84s)]
*  It doesn't mean everyone should read the comments. Most people don't. [[02:05:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7554.2s)]
*  Yeah. The Atlantic had comments until I think six months ago, and then they shut [[02:05:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7556.92s)]
*  it down because they're saying these are too low quality. [[02:06:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7560.0s)]
*  But theirs were just worthless, right? I don't think it gave people any context. [[02:06:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7561.48s)]
*  And their articles, they're written like mainstream media articles. [[02:06:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7564.6s)]
*  They start off with an anecdote and they give you all this context. [[02:06:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7568.280000000001s)]
*  And readers like me are maybe bored till paragraph 17. [[02:06:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7571.68s)]
*  Ah, here's the part I didn't know. [[02:06:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7574.6s)]
*  And that's fine if they do that. That's their model. [[02:06:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7576.6s)]
*  I respect it. Atlantic is great, but it's not my model. [[02:06:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7578.4800000000005s)]
*  My model is jump right in with the new point, kind of screw the reader. [[02:06:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7581.4400000000005s)]
*  You have no idea what I'm talking about. [[02:06:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7584.6s)]
*  Cackle, haha. [[02:06:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7586.64s)]
*  Hope you enjoy it anyway. [[02:06:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7587.84s)]
*  Yeah, it was just odd that I would always read those comments even though I [[02:06:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7589.200000000001s)]
*  thought they're bad. And I was so glad when they took that option away from me. [[02:06:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7591.52s)]
*  So what topics do you most prefer to avoid discussing and why? [[02:06:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7594.6s)]
*  Well, I'm an employee of George Mason University. [[02:06:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7598.52s)]
*  So there are a lot of matters where my university like speaks for the university. [[02:06:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7600.96s)]
*  They do not in any way censor or limit what I say. [[02:06:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7605.56s)]
*  But it feels to me appropriate that I should let them be the spokesperson for all [[02:06:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7608.280000000001s)]
*  sorts of things that happen on campus. [[02:06:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7612.320000000001s)]
*  I'm an employer. So there's a lot of issues related to employment that I feel I [[02:06:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7614.92s)]
*  shouldn't comment on. And I don't. [[02:06:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7619.08s)]
*  Those are the two main areas. [[02:07:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7621.0s)]
*  And I think in both cases, I'm doing the right thing. [[02:07:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7622.4800000000005s)]
*  Do you ever shy away from kind of controversial topics, not like spend capital [[02:07:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7624.88s)]
*  that you want to reserve for other more important issues? [[02:07:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7628.4800000000005s)]
*  Sure. But usually, you know, those same topics, I'm kind of bored with them. [[02:07:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7630.64s)]
*  Or so there's a lot of like social justice issues people cover in great, great [[02:07:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7634.120000000001s)]
*  detail. Like how wrong or not wrong was the latest thing Trump did or said people [[02:07:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7638.88s)]
*  cover in great detail. [[02:07:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7643.56s)]
*  Like, obviously that's important. [[02:07:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7645.52s)]
*  He's president. I shy away from them. [[02:07:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7647.4400000000005s)]
*  You could say it's, you know, to preserve capital to some extent, but like mostly [[02:07:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7650.240000000001s)]
*  I'm sick of that discussion. [[02:07:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7654.48s)]
*  So it's kind of overdetermined why I don't do more on a lot of those issues. [[02:07:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7656.2s)]
*  Do you ever worry that you shy away from important topics, perhaps because they're [[02:07:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7661.48s)]
*  not intellectually challenging enough in that way? [[02:07:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7664.76s)]
*  Of course. I'm pretty selfish, but I do cover a lot of topics. [[02:07:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7666.88s)]
*  It's possible I've written about more topics like than any economist who's ever [[02:07:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7671.0s)]
*  lived. So if the charge against me is I'm not doing enough topics, like I might be [[02:07:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7674.44s)]
*  guilty, but surely there are better criticisms of me than that one, right? [[02:07:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7678.96s)]
*  Right. Yeah. So let's say that you were like a little bit more altruistic. [[02:08:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7683.799999999999s)]
*  So you're a bit more willing to sacrifice your welfare to do some more good. [[02:08:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7686.4s)]
*  What would be like one of the most efficient changes you could make in your life to do [[02:08:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7689.5599999999995s)]
*  that? [[02:08:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7692.08s)]
*  Well, one possibility we don't know what would be for me to take like one topic and [[02:08:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7692.719999999999s)]
*  devote my whole life to it. [[02:08:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7696.92s)]
*  Peter Singer is a version of that. [[02:08:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7698.5199999999995s)]
*  He's more than one topic, but it's kind of all in one direction. [[02:08:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7699.799999999999s)]
*  And he's had a lot of impact by repeating the same message over and over in different [[02:08:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7703.28s)]
*  forums, different ways. [[02:08:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7707.799999999999s)]
*  And that would bore me. [[02:08:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7710.08s)]
*  I don't think I'd be that productive, but if I were kind of, you know, more of a man, [[02:08:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7710.92s)]
*  I could summon up the will to do it and just suffer through. [[02:08:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7715.6s)]
*  But I can't. I don't want to. [[02:08:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7718.8s)]
*  I don't feel I'm about to try. [[02:08:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7720.4s)]
*  And that's selfish. [[02:08:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7722.2s)]
*  I've heard that some academics find it frustrating that you're so like very famous [[02:08:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7723.4400000000005s)]
*  and you've done that by addressing the public directly rather than going through kind [[02:08:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7727.4400000000005s)]
*  of papers in Econometrica. [[02:08:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7730.6s)]
*  Do you think that more people, more academics should should copy your example? [[02:08:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7732.32s)]
*  Well, there are different ways you can view what my example is. [[02:08:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7736.24s)]
*  So I spent more than 20 years of my career, almost all my energy publishing papers [[02:08:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7738.84s)]
*  and journals. I have, you know, five or six papers and like top three journals. [[02:09:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7743.56s)]
*  People may or may not agree with those papers, but I'm very glad I did that training [[02:09:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7747.68s)]
*  and have that background. [[02:09:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7752.0s)]
*  But it seems like you're like most of your fame kind of came later. [[02:09:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7753.360000000001s)]
*  Sure. It's a different kind of fame. [[02:09:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7755.92s)]
*  So I would say people who want to be public intellectuals to do some version of [[02:09:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7759.72s)]
*  something rigorous early on for quite a few years. [[02:09:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7764.8s)]
*  If you can, I recommend that. [[02:09:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7767.56s)]
*  I don't recommend that people try to avoid it, but situations will differ. [[02:09:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7769.240000000001s)]
*  Some people, they're just like bad at school. [[02:09:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7773.240000000001s)]
*  They don't even have a college degree. [[02:09:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7775.76s)]
*  They can be significant public intellectuals. [[02:09:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7778.080000000001s)]
*  Michelle Dawson, I interviewed her. [[02:09:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7780.040000000001s)]
*  She worked as a mail carrier, does not even have a BA. [[02:09:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7781.76s)]
*  Brilliant woman has had a phenomenal impact. [[02:09:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7785.56s)]
*  And like I should tell her, you know, she should have done something else. [[02:09:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7788.400000000001s)]
*  No way. So, you know, I'm all for diversity and credentials are overrated. [[02:09:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7790.96s)]
*  So, you know, rigor is important, but rigor and credentials are not the same thing. [[02:09:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7795.88s)]
*  Yeah. I think in terms of people who are extremely good at providing valuable [[02:10:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7800.839999999999s)]
*  links to read, I think there's like you and maybe Dennis Dutton, who did arts [[02:10:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7804.24s)]
*  and letters daily. Correct. [[02:10:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7807.4s)]
*  Yeah. Like who else do you, would you put on that list as like really good sources [[02:10:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7808.799999999999s)]
*  for good content for year after year after year? [[02:10:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7813.12s)]
*  Robert Cottrell, who runs the browser and he is the browser. [[02:10:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7815.28s)]
*  A lot of people love the browser. [[02:10:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7819.12s)]
*  I don't think as many people know it's this one person, Bob Cottrell, very, very [[02:10:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7820.44s)]
*  nice man, brilliant, widely read, deeply read, super underrated, I would say. [[02:10:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7824.88s)]
*  He's who comes to mind. [[02:10:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7830.2s)]
*  It seems like kind of standing at that nexus between what people read and kind of [[02:10:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7831.84s)]
*  what you want them to read, gives you actually like substantial influence. [[02:10:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7835.400000000001s)]
*  So like, why don't more people try to like, you know, get that, get that kind of [[02:10:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7838.6s)]
*  power by becoming someone who people refer to to figure out what to read. [[02:10:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7842.52s)]
*  I was just wondering this last night. [[02:10:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7845.68s)]
*  It seems to me there's market room for like very good. [[02:10:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7847.32s)]
*  They don't have to quite literally be blogs, but blog like entities, also [[02:10:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7852.6s)]
*  podcasts, some media companies are clearing out of the podcast space. [[02:10:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7856.0s)]
*  It may or may not make money, but it's a great way to reach people. [[02:11:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7860.88s)]
*  Maybe it's that the demands on those who do it are just really quite high. [[02:11:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7864.8s)]
*  And it's tough. [[02:11:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7868.5599999999995s)]
*  Independently wealthy or something to afford it. [[02:11:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7869.36s)]
*  And even if you're independently wealthy, you need to invest a lot of years of [[02:11:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7871.32s)]
*  compound learning and stick with it. [[02:11:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7875.4s)]
*  And then if you're talented, maybe you could earn more money doing something else. [[02:11:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7878.28s)]
*  But I'm surprised how few people do it. [[02:11:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7881.44s)]
*  Actually, I still can't figure this out. [[02:11:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7883.5199999999995s)]
*  There's a market gap. [[02:11:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7885.44s)]
*  Do you have a hypothesis? [[02:11:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7886.16s)]
*  No, I guess I, I did this to some extent. [[02:11:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7887.44s)]
*  So I'm not sure why there's no more competition, but please, please don't [[02:11:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7891.36s)]
*  join and compete with us. [[02:11:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7894.0s)]
*  So years ago, you wrote that in kind of, in order to like enforce a level of [[02:11:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7896.48s)]
*  epistemic humility on yourself, which you think is appropriate. [[02:11:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7900.4s)]
*  You try to be like extremely reluctant to move your credences out of the range of [[02:11:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7902.719999999999s)]
*  kind of 40% to 60% on like controversial issues at least. [[02:11:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7905.879999999999s)]
*  And I found that that really stuck in my head for like many years and kind of [[02:11:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7910.08s)]
*  became a bit of a rule of thumb to me that like, when I see like my credence is [[02:11:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7912.5599999999995s)]
*  moving out of the 40 to 60% range, and I have to like stop and really pause and [[02:11:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7915.32s)]
*  think about whether the evidence is strong enough. [[02:11:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7918.04s)]
*  Do you still like try to follow that principle and kind of, if so, how do you go about it? [[02:11:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7919.88s)]
*  I try all the more. [[02:12:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7923.28s)]
*  So I think the best way to go about keeping epistemic humility is to try to write out [[02:12:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7924.76s)]
*  the arguments of the side you disagree with. [[02:12:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7930.28s)]
*  And in part, I use marginal revolution as a vehicle for that. [[02:12:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7932.8s)]
*  It's like a selfish use for me. [[02:12:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7935.5199999999995s)]
*  And when you try to write out someone else's argument or even just present it [[02:12:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7937.679999999999s)]
*  orally, it's like your own ego forces you to produce the better version. [[02:12:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7940.84s)]
*  You don't want to sound or come across like an idiot, but as you produce the [[02:12:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7944.84s)]
*  better version, you become a bit invested in it and that's irrational that you're [[02:12:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7948.16s)]
*  invested in it, but it's countering your other irrationality of not liking it so [[02:12:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7952.04s)]
*  much and you're setting off like one passion against another to use Madisonian [[02:12:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7956.16s)]
*  language. [[02:12:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7961.2s)]
*  And I think that mostly works. [[02:12:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7962.16s)]
*  So always try, you know, steel manning, not straw manning, but put yourself in [[02:12:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7964.160000000001s)]
*  the position of having to pass the ideological Turing test. [[02:12:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7968.160000000001s)]
*  Can I express this as smartly as possible? [[02:12:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7971.400000000001s)]
*  Yeah. [[02:12:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7973.72s)]
*  I think from memory and super forecasting, that was perhaps the most important [[02:12:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7974.360000000001s)]
*  characteristic for making accurate forecasts was that you had gone through the [[02:12:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7977.4400000000005s)]
*  step of arguing actively for the other side from the one that you already believed. [[02:13:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7980.64s)]
*  Yeah. [[02:13:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7983.88s)]
*  Another post that you wrote in the past that really stuck with me to this day is [[02:13:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7984.6s)]
*  to say that people don't want to acknowledge the messiness of life and decision-making. [[02:13:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7988.400000000001s)]
*  That when they're asked a question like, you know, why are you doing what you're [[02:13:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7992.36s)]
*  doing today? [[02:13:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7994.759999999999s)]
*  They give this like kind of neat narrative where it's like, it seems inevitable that [[02:13:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7995.2s)]
*  they ended up where they are. [[02:13:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7998.08s)]
*  But in fact, it was just a total mess that like they were making all these decisions [[02:13:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=7998.799999999999s)]
*  and kind of by some random chance have ended up where they are. [[02:13:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8001.679999999999s)]
*  And to like to this day, when people ask me to like give a narrative like that, I [[02:13:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8003.799999999999s)]
*  just kind of reject it and like I refuse to do it because I don't believe the story [[02:13:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8006.96s)]
*  that I'm going to tell them. [[02:13:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8010.16s)]
*  Is that like as important a post to you as it was to me? [[02:13:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8011.12s)]
*  We're overly invested in narratives. [[02:13:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8014.44s)]
*  That's the theme of my Ted talk, but narratives are also impossible to avoid. [[02:13:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8016.16s)]
*  So we're always living with this contradiction. [[02:13:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8020.8s)]
*  And then economists have this dual problem. [[02:13:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8023.360000000001s)]
*  They have simple theories and the world's always more complex. [[02:13:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8025.6s)]
*  So kind of my personal program is to stay connected to the humanities, to remind me [[02:13:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8029.56s)]
*  of that complexity, to keep on reading fiction, take an interest in anthropological kinds [[02:13:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8034.240000000001s)]
*  of issues, the whole notion of culture, which no one is even sure what the word means, [[02:13:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8039.240000000001s)]
*  but it's reminding you all the time how much what matters is something that's hard to [[02:14:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8044.4800000000005s)]
*  pin down or have a simple theory about. [[02:14:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8048.400000000001s)]
*  So if you're both overly invested in narrative as a human and your main field is economics, [[02:14:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8050.8s)]
*  which has simple theories, you need to take these countervailing steps. [[02:14:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8055.400000000001s)]
*  If we received a message from aliens, what do you think are the chances that it would [[02:14:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8058.84s)]
*  be designed to kind of disable us as a competitive civilization in the race to colonize the [[02:14:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8062.84s)]
*  universe? [[02:14:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8067.240000000001s)]
*  I would assume that aliens have some kind of decentralized society and a lot of different [[02:14:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8068.12s)]
*  kinds of messages are being sent out, as indeed would be the case from planet Earth. [[02:14:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8072.96s)]
*  It seems like on your view that that actually shouldn't be the case because all of the [[02:14:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8076.88s)]
*  decentralized ones would destroy themselves. [[02:14:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8079.52s)]
*  I would think the decentralized ones would be more robust. [[02:14:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8081.52s)]
*  If you look at the most robust societies today, North Korea is highly centralized. [[02:14:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8084.040000000001s)]
*  I suspect it's not very robust. [[02:14:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8088.88s)]
*  So if the aliens have spread to other planets, if they're able to reach us with messages, [[02:14:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8091.280000000001s)]
*  they'll have some technology. [[02:14:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8095.4800000000005s)]
*  They'll have a lot of groups, people, institutions sending messages. [[02:14:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8097.92s)]
*  So what we're most likely to get is some kind of advertisement, I think, some kind of [[02:15:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8101.8s)]
*  semi-propaganda, maybe a religious message, exhortations. [[02:15:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8105.68s)]
*  I don't think it's likely to be that dangerous. [[02:15:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8109.24s)]
*  There may be some worms sent our way, but like what are most emails? [[02:15:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8112.0s)]
*  Right. [[02:15:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8116.96s)]
*  They're kind of crap. [[02:15:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8117.24s)]
*  Right. [[02:15:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8118.28s)]
*  Yeah. [[02:15:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8118.92s)]
*  Well, I suppose like in as much as they're like promoting their moral values to us, like [[02:15:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8119.4s)]
*  with much better technology than we have in a sense that is to disable us as a competitive [[02:15:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8122.48s)]
*  civilization, it's to get us on board with like their mission. [[02:15:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8125.72s)]
*  So we'll like go and do what they want because that'd be so persuasive. [[02:15:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8127.92s)]
*  But odds are the message is intended to raise the status of some group within alien society [[02:15:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8131.32s)]
*  and it will be pretty harmless. [[02:15:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8136.2s)]
*  You don't think that like even with like the fullness of like maturity of technology and [[02:15:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8137.839999999999s)]
*  you know, this these aliens hypothetically have like probably colonized a large part of [[02:15:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8142.12s)]
*  the universe that they'll still be playing status games that will still be like a big [[02:15:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8146.2s)]
*  part of their activity. [[02:15:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8148.96s)]
*  That's what motivates them to colonize the universe. [[02:15:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8150.24s)]
*  Right. [[02:15:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8152.48s)]
*  Something has to. [[02:15:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8152.759999999999s)]
*  What about just like moral values, ideology? [[02:15:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8153.96s)]
*  They want to like generate value by like, you know, getting madder and compiling it the [[02:15:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8155.679999999999s)]
*  way they think is best. [[02:15:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8159.44s)]
*  Well, it's over determined as it is with humans. [[02:16:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8160.4s)]
*  Right. [[02:16:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8162.44s)]
*  But incentives are always going to matter. [[02:16:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8163.16s)]
*  Status incentives are not the only one. [[02:16:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8164.839999999999s)]
*  But if you have decentralized incentives, you're going to have money and status and [[02:16:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8167.16s)]
*  just propagation of ideology mattering. [[02:16:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8171.4800000000005s)]
*  And then the broadcasters will tend to be those over invested in messages. [[02:16:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8173.8s)]
*  And maybe it's those who just show up with no message that we should be worried about. [[02:16:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8177.84s)]
*  Like they just zap us. [[02:16:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8181.88s)]
*  We never even know what hit us. [[02:16:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8183.0s)]
*  Yeah. [[02:16:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8184.4800000000005s)]
*  The message to me is slightly reassuring. [[02:16:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8185.52s)]
*  It's kind of like the knock on the door as opposed to, you know, the bullet in the back [[02:16:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8188.72s)]
*  of the head. [[02:16:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8192.32s)]
*  So it seems like you're pretty skeptical of world government appearing anytime soon. [[02:16:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8192.92s)]
*  Absolutely. [[02:16:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8196.4s)]
*  And absolutely so am I. [[02:16:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8196.72s)]
*  But it also seems like there's a long term trend, as Robin Hanson has pointed out, towards [[02:16:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8198.28s)]
*  like more greater and greater concentration that the units of governance are getting larger [[02:16:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8202.0s)]
*  progressively over time from, you know, like villages now to like enormous countries. [[02:16:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8205.2s)]
*  And do you think it's like possible that like gradually over hundreds of years we could [[02:16:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8208.72s)]
*  like converge on like having more of a world government, if not a full world government? [[02:16:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8212.92s)]
*  I think you're always going to have rival blocks of some kind, because the notion of [[02:16:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8217.36s)]
*  having unity and no enemy doesn't seem like a stable equilibrium to me. [[02:17:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8221.400000000001s)]
*  But I'm not even sure the trend toward larger units is continuing right now. [[02:17:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8225.720000000001s)]
*  So you have Brexit, a Scottish secession, it lost the referendum, but the movement really [[02:17:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8229.400000000001s)]
*  actually hasn't gone away. [[02:17:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8234.480000000001s)]
*  Catalonian secession, which to me, in logical terms, makes no sense. [[02:17:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8236.640000000001s)]
*  That hasn't gone away. [[02:17:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8241.04s)]
*  It may even happen. [[02:17:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8242.12s)]
*  So there's at least a chance there's some fragmenting of power at the margin. [[02:17:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8243.76s)]
*  Although both Scotland and Catalonia wanted to do that in part, because then they would [[02:17:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8247.48s)]
*  still be part of this like broader EU in their view that would like give them many of the [[02:17:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8251.199999999999s)]
*  benefits of being part of a large state. [[02:17:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8255.279999999999s)]
*  But the EU itself probably will become less powerful over the next 10 years, as you [[02:17:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8257.359999999999s)]
*  have, say, parts of Eastern Europe not following all the strictures and to keep itself [[02:17:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8262.68s)]
*  together, it'll be more of a thing on paper. [[02:17:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8266.439999999999s)]
*  I could see that going either way. [[02:17:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8268.96s)]
*  It seems like the long term. [[02:17:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8270.279999999999s)]
*  Either way, but to think there's some trend, it's just toward more and more centralisation. [[02:17:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8270.96s)]
*  Not necessarily. [[02:17:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8274.08s)]
*  Yeah, not necessarily. [[02:17:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8274.68s)]
*  But you think there's like some chance that we'll like end up with like the when or some [[02:17:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8275.44s)]
*  like successor group or like, you know, a hegemon of multiple different countries joining [[02:17:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8279.16s)]
*  together, like having a lot of power. [[02:18:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8282.640000000001s)]
*  That's a possible future. [[02:18:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8283.68s)]
*  Possible future, but it's not my modal prediction. [[02:18:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8284.84s)]
*  If the United States could double its rate of economic growth in exchange for adopting [[02:18:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8286.92s)]
*  wholesale kind of Chinese moral values, is that something that at all to do? [[02:18:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8291.04s)]
*  Well, again, what are Chinese moral values? [[02:18:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8294.68s)]
*  Most Chinese moral values are the same as American moral values. [[02:18:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8296.76s)]
*  So it sounds like yes is the answer. [[02:18:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8300.44s)]
*  So it sounds like yes is the answer. [[02:18:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8302.72s)]
*  Are there some ways in which they're making good decisions and we're not? [[02:18:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8304.279999999999s)]
*  Absolutely. [[02:18:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8308.08s)]
*  But we have a more responsive, flexible system. [[02:18:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8309.759999999998s)]
*  I don't want the Chinese system of government in the United States. [[02:18:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8312.08s)]
*  I think it would destroy us, even if it's doing okay for them. [[02:18:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8314.72s)]
*  So Chinese values lock, stock and barrel. [[02:18:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8318.32s)]
*  I say absolutely no, but mostly they're the same as our values. [[02:18:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8320.4s)]
*  Yes. [[02:18:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8324.08s)]
*  I mean, that seems like a really important point to me. [[02:18:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8324.279999999999s)]
*  I guess we're slightly returning to a conversation we were having earlier. [[02:18:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8325.839999999998s)]
*  But if it is just the case that most moral values are pretty similar, then there's [[02:18:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8328.6s)]
*  like no reason for countries to be fighting over resources. [[02:18:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8332.04s)]
*  They should just try to get along as peacefully as possible. [[02:18:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8334.960000000001s)]
*  That will prevent human extinction and the future will be about as good as it [[02:18:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8337.6s)]
*  plausibly can be. [[02:19:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8340.2s)]
*  Well, mostly they do, right? [[02:19:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8341.16s)]
*  But it's these unlikely events that can arise through miscalculations. [[02:19:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8342.880000000001s)]
*  So you still struggle over things at the margin, in part precisely because things [[02:19:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8347.800000000001s)]
*  are peaceful, you feel you can struggle at the margin. [[02:19:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8351.4s)]
*  Most of the time that goes fine, but you have miscalculations or you think [[02:19:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8353.640000000001s)]
*  missiles are coming in when they're not, or someone sends the wrong signal, or [[02:19:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8357.4s)]
*  you have an emotionally volatile leader. [[02:19:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8361.359999999999s)]
*  Again, let enough time pass. [[02:19:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8363.76s)]
*  These things are going to cash into some real conflict. [[02:19:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8365.4s)]
*  What do you think is more likely to destroy civilization? [[02:19:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8367.64s)]
*  Accidental use of nuclear weapons or deliberate use of nuclear weapons? [[02:19:30](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8370.48s)]
*  Where accidental means some kind of false alarm. [[02:19:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8373.64s)]
*  Some kind of false alarm. [[02:19:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8375.92s)]
*  It might even be partially justified, but not what you want to have happen. [[02:19:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8377.199999999999s)]
*  And second strike capability often means giving commanders some autonomy, and [[02:19:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8381.52s)]
*  that's dangerous. [[02:19:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8385.56s)]
*  They probably have substantial autonomy today in most of these countries. [[02:19:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8386.76s)]
*  And we're not even sure how much, right? [[02:19:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8388.76s)]
*  If only because of imperfect systems. [[02:19:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8390.28s)]
*  So autonomous commanders making risky decisions and maybe some are good, but [[02:19:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8392.480000000001s)]
*  some will turn out to be very bad. [[02:19:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8396.720000000001s)]
*  That to me seems a lot more likely than just kind of mad evil leaders pressing [[02:19:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8398.12s)]
*  buttons and screaming, you know, die, you enemy pigs. [[02:20:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8402.480000000001s)]
*  Yeah. [[02:20:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8406.04s)]
*  Do you have a favorite like nuclear near miss story? [[02:20:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8406.640000000001s)]
*  Well, there's the stories we know about, you know, that the Soviet commander who [[02:20:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8410.480000000001s)]
*  aborted the return launch and it turned out to be a mistake. [[02:20:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8414.12s)]
*  Cuban missile crisis, of course. [[02:20:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8417.84s)]
*  So we've come closer than we ought to have a few times. [[02:20:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8419.36s)]
*  And how much those systems are improved, I don't personally know, but I would take [[02:20:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8423.2s)]
*  such improvements to be a major priority. [[02:20:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8427.44s)]
*  So both of us agree that it's pretty unlikely that climate change is going to [[02:20:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8429.88s)]
*  lead to human extinction or even probably, you know, a collapse of civilization. [[02:20:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8433.32s)]
*  But we can imagine a very similar world where like the climate responsiveness to [[02:20:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8437.56s)]
*  greenhouse gases is say three or four or five times as large such that what we're [[02:20:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8441.76s)]
*  doing now would like lead to really radical changes in the climate that that [[02:20:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8445.560000000001s)]
*  would probably lead to, if not human extinction, at least like the collapse of [[02:20:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8448.960000000001s)]
*  civilization as we know it. [[02:20:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8452.4s)]
*  If we were in such a like severe and unfortunate world, do you think that [[02:20:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8453.92s)]
*  countries would be able to coordinate to stop it or would we just be screwed? [[02:20:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8457.24s)]
*  I think we'd be screwed. [[02:21:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8460.560000000001s)]
*  I think the greatest risk of climate change, even the less drastic scenarios is [[02:21:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8462.16s)]
*  our own response to it. [[02:21:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8465.880000000001s)]
*  So, you know, in the London report, I think they estimate three to 4% of global [[02:21:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8467.88s)]
*  GDP is lost through climate change and they are not denialists. [[02:21:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8471.8s)]
*  That strikes me as oddly low. [[02:21:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8475.28s)]
*  So if the global economy is growing at 4% a year, it just means you get to where [[02:21:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8477.84s)]
*  you're going a year later. [[02:21:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8482.68s)]
*  So that's a lot of lost resources, but in that context sounds entirely manageable, [[02:21:24](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8484.32s)]
*  but I think that's a misleading context. [[02:21:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8489.6s)]
*  If you look at how we've responded to say Chinese competition or certain immigration [[02:21:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8491.8s)]
*  problems, we way over respond or we panic or we take the wrong measures in response. [[02:21:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8496.32s)]
*  I believe the biggest costs of climate change will be the own stupidity of our [[02:21:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8501.84s)]
*  own responses to the real problems we have, but we'll make them much worse [[02:21:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8506.64s)]
*  because we're not always good at dealing with emergencies. [[02:21:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8511.0s)]
*  Do you think that in the next hundred years, there's any chance that we'll mine [[02:21:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8513.64s)]
*  asteroids and use their resources on earth? [[02:21:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8517.0s)]
*  I don't feel I have the expertise to answer that question, but I don't know of [[02:21:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8518.92s)]
*  any reason why we couldn't. [[02:22:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8522.36s)]
*  Interesting. [[02:22:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8524.0s)]
*  Okay. [[02:22:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8524.48s)]
*  It doesn't sound like a high value activity to me, but I don't know what's on the [[02:22:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8525.119999999999s)]
*  asteroids. [[02:22:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8529.16s)]
*  I'm not sure how much we know. [[02:22:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8529.72s)]
*  It's just an area I haven't read much about. [[02:22:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8530.72s)]
*  Yeah. [[02:22:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8532.599999999999s)]
*  So I've read several kind of engineering oriented papers that say that colonising, [[02:22:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8533.439999999999s)]
*  you know, other planets is like a relatively straightforward thing, technologically [[02:22:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8537.759999999998s)]
*  speaking, not right now, but like it's very foreseeable that we'll have the [[02:22:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8541.16s)]
*  technology to do that in future. [[02:22:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8543.56s)]
*  What do you think is the chances that those papers would convince you that we [[02:22:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8546.119999999999s)]
*  might go to space? [[02:22:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8548.72s)]
*  If the question is, will we have a colony on Mars? [[02:22:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8549.759999999998s)]
*  I would bet yes. [[02:22:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8553.24s)]
*  If the question is, will Mars become a, you know, a populated planet and [[02:22:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8554.96s)]
*  civilisation in some way akin to earth, I would bet no. [[02:22:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8559.8s)]
*  If we ever do develop a kind of machine intelligence that's like similar to [[02:22:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8562.439999999999s)]
*  humans, wouldn't that make it a lot easier to go to space and potentially [[02:22:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8565.88s)]
*  colonise places very far away? [[02:22:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8569.599999999999s)]
*  So the scenario is that we send AI and AI carries genetic material and terra [[02:22:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8571.32s)]
*  forms? [[02:22:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8577.279999999999s)]
*  No, no, there's no need to run a kind of reconstitute humans. [[02:22:58](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8578.119999999999s)]
*  It's just that like the life that travels there is like a technological one on [[02:23:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8581.0s)]
*  silicon or whatever is the future equivalent of silicon. [[02:23:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8584.4s)]
*  And so humans don't go, but like intelligence does leave the solar system. [[02:23:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8586.48s)]
*  I wouldn't think of that as life. [[02:23:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8590.119999999999s)]
*  So we could send really good cash registers to Jupiter and Saturn right now. [[02:23:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8591.44s)]
*  Actually we do sometimes. [[02:23:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8595.359999999999s)]
*  I'm fine with doing it, but I don't think it is necessarily self-aware. [[02:23:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8597.4s)]
*  Okay. [[02:23:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8602.6s)]
*  So you think it's like not possible for computers in some configuration to be [[02:23:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8602.8s)]
*  self-aware the way that they are? [[02:23:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8606.8s)]
*  No, it must be possible because you and I are computers, right? [[02:23:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8607.48s)]
*  And we're self-aware, but it seems to me very far away and the directions AI [[02:23:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8609.88s)]
*  is moving in where it's had a lot of success are their very powerful cash [[02:23:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8614.32s)]
*  registers, which is wonderful, but not self-aware. [[02:23:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8618.72s)]
*  Yeah. [[02:23:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8621.64s)]
*  So I agree that the current technology isn't going to produce self-awareness, [[02:23:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8621.88s)]
*  but it seems to me like there's some chance like in the next couple of hundred [[02:23:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8624.44s)]
*  years we'll have computers that are like both as smart as humans, maybe more so. [[02:23:47](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8627.08s)]
*  And that they will probably, that although we'll there's at least a good reason to [[02:23:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8631.64s)]
*  think that they might have conscious experiences the way that humans do. [[02:23:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8634.92s)]
*  And that ultimately like once we can make those like intelligences like quite small, [[02:23:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8637.6s)]
*  it would be possible to extend them to other solar systems and then they can [[02:24:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8642.28s)]
*  kind of take actions. [[02:24:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8645.0s)]
*  But if you think materials really matter, and I do, it could be that self-aware [[02:24:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8646.0s)]
*  entities have to be biological in some sense and that thus they're going to be [[02:24:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8650.400000000001s)]
*  relatively fragile. [[02:24:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8655.12s)]
*  So we know how to build more human beings, right? [[02:24:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8656.52s)]
*  It's even a pretty fun technology. [[02:24:18](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8658.560000000001s)]
*  Doesn't cost that much. [[02:24:20](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8660.720000000001s)]
*  So self-aware AI is always competing against that. [[02:24:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8662.240000000002s)]
*  The notion that you have human like beings augmented cyborgs, I think will [[02:24:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8666.12s)]
*  outcompete the notion of robots in the Isaac Asimov sense that they're like walk [[02:24:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8671.0s)]
*  like a robot, but they're self-aware and have all the smarts of AI. [[02:24:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8676.4s)]
*  I would be surprised by that. [[02:24:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8679.4s)]
*  But it seems like you were saying just a minute ago that like humans are conscious [[02:24:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8680.96s)]
*  because they're computers. [[02:24:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8685.119999999999s)]
*  So it seems like it should be in principle possible, but it's like in as much as we [[02:24:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8686.08s)]
*  can do computations like on some other system, like you don't think there's a good [[02:24:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8689.439999999999s)]
*  chance that they would feel something? [[02:24:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8693.16s)]
*  I just suspect the materials really matter and biological materials have some [[02:24:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8694.919999999998s)]
*  properties that silicon and metal don't. [[02:24:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8699.2s)]
*  And we have plenty of biological computers will do wonderful things, enhancing them [[02:25:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8701.800000000001s)]
*  like we've already done. [[02:25:05](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8705.640000000001s)]
*  But again, once it's biological, it becomes higher cost to send it elsewhere. [[02:25:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8707.0s)]
*  And maybe the model that you send genetic material and try to terraform and set up [[02:25:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8711.52s)]
*  colonies by setting processes of evolution in motion and try to skew them toward [[02:25:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8716.68s)]
*  producing vaguely humanoid like beings. [[02:25:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8721.960000000001s)]
*  That to me sounds more likely, though maybe still unlikely than what you're [[02:25:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8725.320000000002s)]
*  suggesting. [[02:25:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8728.56s)]
*  OK, yeah, some kind of panspermia. [[02:25:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8729.32s)]
*  Right. [[02:25:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8731.4s)]
*  What mood do we feel too little and what like stimulus could we use to induce it? [[02:25:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8731.76s)]
*  We feel too little tolerance and the fact that you can see what other people think on [[02:25:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8736.039999999999s)]
*  Twitter makes you downgrade the other side more than you ought to. [[02:25:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8739.48s)]
*  So we feel too much frustration and too much that, oh, now I see, you know, what's [[02:25:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8743.56s)]
*  really wrong with the other side. [[02:25:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8748.6s)]
*  That's the mood that's become a lot more common in the last five years and it's [[02:25:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8750.4s)]
*  dangerous. [[02:25:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8753.439999999999s)]
*  I agree. [[02:25:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8754.119999999999s)]
*  Yeah. [[02:25:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8754.4s)]
*  Which conspiracy theory is most likely to be true? [[02:25:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8755.16s)]
*  I think almost all of them are false. [[02:25:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8757.52s)]
*  I blogged once the notion that some major sporting events might be fixed for reasons [[02:25:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8759.28s)]
*  related to betting and corruption. [[02:26:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8763.76s)]
*  I don't know if that even counts as a conspiracy theory, but it's some kind of [[02:26:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8766.0s)]
*  conspiracy. [[02:26:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8768.84s)]
*  I would be surprised if that were not more true than we realise. [[02:26:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8770.12s)]
*  That's a pretty minor league, forgive the pun, conspiracy. [[02:26:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8773.28s)]
*  So you think there's many plural values. [[02:26:16](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8776.560000000001s)]
*  Is it nonetheless possible that the best future would involve just like maxing out [[02:26:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8779.160000000002s)]
*  on one of those values because it's more efficient to produce that value than the [[02:26:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8782.68s)]
*  other ones? [[02:26:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8785.960000000001s)]
*  You can get more bang for buck. [[02:26:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8786.32s)]
*  I think that's possible. [[02:26:28](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8788.32s)]
*  And that value would just be numbers. [[02:26:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8789.36s)]
*  So it could be, there are just limits on how much better we can make lives at some [[02:26:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8791.8s)]
*  margin. [[02:26:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8795.279999999999s)]
*  Like people can only get so happy even with some kind of biological genetic [[02:26:35](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8795.72s)]
*  engineering. [[02:26:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8800.24s)]
*  And then we just max out on lives. [[02:26:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8801.039999999999s)]
*  I think at some point that's how it will be. [[02:26:42](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8802.48s)]
*  Do you think that calling the repugnant conclusion, the repugnant conclusion kind [[02:26:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8805.68s)]
*  of begged the question and in fact, like it's maybe not as repugnant as people [[02:26:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8808.48s)]
*  think? [[02:26:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8811.32s)]
*  I don't think Parfit in naming it the repugnant conclusion was himself begging [[02:26:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8812.039999999999s)]
*  the question. [[02:26:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8815.88s)]
*  He was trying to draw people's attention to it with a vivid word. [[02:26:56](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8816.8s)]
*  I think he fully well understood it might not be repugnant. [[02:27:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8820.0s)]
*  But if you think about a life in the repugnant conclusion, well, you're alive [[02:27:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8823.599999999999s)]
*  for a few minutes, someone feeds you a potato, you hear some music and you pass [[02:27:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8826.88s)]
*  away. [[02:27:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8830.439999999999s)]
*  Well, isn't that better than nothing? [[02:27:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8831.039999999999s)]
*  In my view, those are not human lives as we understand the terms, even if they [[02:27:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8833.08s)]
*  look like humanoid beings. [[02:27:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8837.359999999999s)]
*  So it's getting back to the question of like comparing a billion bees to one [[02:27:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8839.119999999999s)]
*  person having a migraine headache, but I just don't think we can do it. [[02:27:23](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8843.8s)]
*  That moral realism can't handle utility comparisons across very different kinds [[02:27:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8847.759999999998s)]
*  of beings. [[02:27:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8853.0s)]
*  Yeah, I feel like a weakness of the repugnant conclusion kind of thought [[02:27:34](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8854.039999999999s)]
*  experiment is that it ties together multiple issues. [[02:27:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8856.439999999999s)]
*  So one thing that people don't like about it is the blandness or the stability of [[02:27:38](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8858.359999999999s)]
*  the welfare that people have in that world. [[02:27:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8861.439999999999s)]
*  If you imagine where we could be in a repugnant conclusion kind of world where [[02:27:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8863.0s)]
*  like humans, we like have ups and downs kind of on net though our lives may be [[02:27:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8865.84s)]
*  only weekly positive. [[02:27:50](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8870.279999999999s)]
*  But people don't say it's like terrible that there's like more people that have [[02:27:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8871.76s)]
*  lives of the kind that we do or that it's not worth not desirable for like [[02:27:54](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8874.2s)]
*  civilisation to continue just because like our lives could be much better in [[02:27:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8877.640000000001s)]
*  principle. [[02:28:00](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8880.720000000001s)]
*  We could imagine beings that have, you know, a hundred times the welfare that we [[02:28:01](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8881.08s)]
*  do over their lives. [[02:28:03](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8883.880000000001s)]
*  So by comparison to them, like this world is kind of the repugnant conclusion [[02:28:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8884.92s)]
*  basically. [[02:28:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8888.24s)]
*  That's right. [[02:28:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8889.08s)]
*  We have intuitions across a lot of different features of the utility [[02:28:09](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8889.480000000001s)]
*  distribution. [[02:28:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8892.52s)]
*  And some of them I suspect are implanted in us in a false way and not really [[02:28:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8893.68s)]
*  valid for moral theory. [[02:28:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8897.52s)]
*  Yeah, I suspect another problem there is that people worry whenever the welfare [[02:28:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8899.16s)]
*  is too close to zero because they feel that it's going to go negative and like [[02:28:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8902.52s)]
*  negatives way like a negative experiences way very heavily in people's minds. [[02:28:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8905.36s)]
*  If they were certain that it will be positive, maybe people's intuitions would [[02:28:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8909.24s)]
*  would go a bit differently. [[02:28:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8911.960000000001s)]
*  And even understanding what's the zero point that defines what's a positive or [[02:28:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8912.880000000001s)]
*  negative utility. [[02:28:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8916.0s)]
*  Thinking on that to me is very backward. [[02:28:37](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8917.68s)]
*  Yeah. [[02:28:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8919.48s)]
*  Do you think it will be possible to make a stable coin cryptocurrency? [[02:28:40](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8920.08s)]
*  Possible is always a tricky word. [[02:28:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8923.12s)]
*  Possible. [[02:28:44](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8924.52s)]
*  Yes. [[02:28:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8925.0s)]
*  Desirable. [[02:28:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8925.32s)]
*  No. [[02:28:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8925.92s)]
*  Speculative pegs tend to be broken. [[02:28:46](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8926.4s)]
*  I don't understand the value of a stable cryptocurrency. [[02:28:48](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8928.68s)]
*  Why not just use dollars? [[02:28:52](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8932.04s)]
*  And in general, crypto faces this problem. [[02:28:53](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8933.64s)]
*  You know, what problem is it trying to solve that we can't solve better through [[02:28:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8935.960000000001s)]
*  other means like more effective clearing houses, better use of dollars, use of [[02:28:59](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8939.92s)]
*  databases in Venezuela, maybe solve that use case. [[02:29:04](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8944.76s)]
*  It would be like a very valuable product in economies that are completely tanking. [[02:29:07](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8947.800000000001s)]
*  So that's not the best business model. [[02:29:10](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8950.880000000001s)]
*  But can't they just use dollars? [[02:29:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8952.12s)]
*  Ecuador, El Salvador and Panama use dollars. [[02:29:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8953.64s)]
*  It works fine for them. [[02:29:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8955.84s)]
*  Yeah. [[02:29:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8957.0s)]
*  It's like harder to track, I guess, would be the argument that like, you know, [[02:29:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8957.2s)]
*  that those countries often try to like prohibit dollarization. [[02:29:19](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8959.960000000001s)]
*  But it's all black market anyway in Venezuela. [[02:29:22](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8962.84s)]
*  Maybe some people are sent to jail for black market crimes. [[02:29:25](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8965.640000000001s)]
*  But I don't think using the dollar is, you know, the main political risk there. [[02:29:29](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8969.52s)]
*  All right. [[02:29:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8973.480000000001s)]
*  If you want to finish with perhaps like one like stirring message to people to go [[02:29:33](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8973.76s)]
*  out and improve the long term future, what would you say? [[02:29:36](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8976.76s)]
*  Don't look for stirring messages. [[02:29:39](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8979.320000000002s)]
*  Think about things more than once. [[02:29:41](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8981.52s)]
*  Thank you for listening to the podcast. [[02:29:43](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8983.400000000001s)]
*  And if I have a stirring message, it's, you know, continue to follow the career of [[02:29:45](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8985.52s)]
*  what Robert Wiblin. [[02:29:49](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8989.28s)]
*  I'm very grateful to him for all the time and energy he's put into being the [[02:29:51](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8991.24s)]
*  interviewer in conversations with Tyler. [[02:29:55](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8995.12s)]
*  Yeah. [[02:29:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8997.480000000001s)]
*  So the book is stubborn attachments, stubborn attachments published by Stripe Press. [[02:29:57](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=8997.800000000001s)]
*  The subtitle is a vision for a society of free, prosperous and responsible [[02:30:02](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9002.08s)]
*  individuals. [[02:30:06](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9006.880000000001s)]
*  It deals with the most important problems of our time in my view. [[02:30:08](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9008.0s)]
*  It is what I really think. [[02:30:11](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9011.08s)]
*  Absolutely. [[02:30:12](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9012.28s)]
*  People should go out and buy it. [[02:30:13](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9013.04s)]
*  Okay. [[02:30:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9014.12s)]
*  Thank you very much. [[02:30:14](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9014.44s)]
*  Thanks so much, Tyler. [[02:30:15](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9015.28s)]
*  Thanks for listening to conversations with Tyler. [[02:30:17](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9017.880000000001s)]
*  You can subscribe to the podcast in iTunes, Stitcher or your favorite podcast [[02:30:21](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9021.0s)]
*  app. [[02:30:26](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9026.0s)]
*  And if you like this podcast, please consider rating it on iTunes and leaving a [[02:30:27](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9027.04s)]
*  review. [[02:30:31](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9031.480000000001s)]
*  This helps other people find the show. [[02:30:32](https://www.youtube.com/watch?v=IpXYTHnj7iM&t=9032.52s)]
