---
Date Generated: May 30, 2025
Transcription Model: whisper medium 20231117
Length: 4860s
Video Keywords: ['peter diamandis', 'longevity', 'xprize', 'abundance']
Video Views: 205195
Video Rating: None
Video Description: In this episode, Peter and Emad discuss Emad's stepping down as CEO of StabilityAI, his next steps into decentralized AI, and why there is so much urgency to work on decentralization NOW. 

Emad Mostaque is the former CEO and Co-Founder of Stability AI, a company funding the development of open-source music- and image-generating systems such as Dance Diffusion, Stable Diffusion, and Stable Video 3D. 
Follow Emad’s journey on X: https://twitter.com/EMostaque
—******--
This episode is supported by exceptional companies:
Get started with Fountain Life and become the CEO of your health: https://fountainlife.com/peter/
AI-powered precision diagnosis you NEED for a healthy gut: https://www.viome.com/peter 
Learn more about Abundance360: https://www.abundance360.com/summit 
******************************************--
I send weekly emails with the latest insights and trends on today’s and tomorrow’s exponential technologies. Stay ahead of the curve, and sign up now: https://www.diamandis.com/subscribe
My new book with Salim Ismail, Exponential Organizations 2.0: The New Playbook for 10x Growth and Impact, is now available on Amazon: https://bit.ly/3P3j54J 
Get my new Longevity Practices book for free: https://www.diamandis.com/longevity

Connect with Peter:
Twitter: https://bit.ly/40JYQfK
Instagram: https://bit.ly/3x6UykS
Listen to the show:
Apple: https://apple.co/3wLXeV3
Spotify: https://spoti.fi/3DwLzgs
---

# Why I'm Leaving My Company Immediately (Stability AI) w/ Emad Mostaque | EP #93
**Moonshots - Peter Diamandis:** [March 29, 2024](https://www.youtube.com/watch?v=e1UgzSTicuY)
*  These organizations are telling you that they're building something that could kill you and something that could remove all our freedom and liberty [[00:00:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=0.0s)]
*  And they're saying it's a good thing you should back them because it's cool [[00:00:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=8.72s)]
*  They don't care about the revenue. They have the political power people are scared of them [[00:00:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=11.68s)]
*  Power should not be invested in any one individual if I can accelerate this over the next period [[00:00:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=16.88s)]
*  I don't have to make an impact. I should not have any power whereas again, you see everyone else trying to get more and more power [[00:00:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=21.8s)]
*  The only way that you can beat it to create the standard that represents humanity is [[00:00:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=30.16s)]
*  Decentralized intelligence its collective intelligence [[00:00:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=36.2s)]
*  The data sets of norms from that will be ones that help children that help people suffering [[00:00:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=39.36s)]
*  That reflects our moral upstanding and the best of us and gathers the best of us to do it [[00:00:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=45.8s)]
*  a [[00:00:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=51.92s)]
*  Week ago Imaad Mistak was on my stage at Abundance 360 talking about the future of open source AI [[00:00:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=55.800000000000004s)]
*  democratized decentralized AI [[00:01:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=63.0s)]
*  The day after a 360 he stepped down as CEO of stability now five days later [[00:01:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=65.04s)]
*  I've sat down with Imaad to talk about why he's stepping down what he's doing next the future of AI [[00:01:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=70.28s)]
*  He takes the gloves off. He talks about the dangers of centralized AI and [[00:01:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=76.56s)]
*  The potential for decentralized democratized AI to be the only avenue that truly uplifts all of humanity [[00:01:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=81.28s)]
*  All right, if you liked this episode, please subscribe [[00:01:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=88.28s)]
*  Let's jump in if you're a mood shot entrepreneur. This is an episode. You're not gonna want to miss [[00:01:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=92.28s)]
*  All right now on to Imaad. Good morning Imaad. Good to see you my friend. That's just always pizza [[00:01:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=97.68s)]
*  So you and I were on stage literally last week at the 2024 Abundance Summit [[00:01:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=104.0s)]
*  talking about [[00:01:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=110.82s)]
*  The whole open source AI movement you were beginning to talk about decentralized AI [[00:01:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=113.58s)]
*  you were talking about where stability was the speed of the development to the different products and [[00:01:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=119.34s)]
*  The day after the Abundance Summit was over [[00:02:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=126.02s)]
*  the news hit that you had stepped down as [[00:02:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=130.26s)]
*  CEO of stability and stepped off the board [[00:02:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=133.74s)]
*  So let's begin with the obvious question why what happened [[00:02:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=137.1s)]
*  And I I have huge respect for you and I know a lot of the issues in the past [[00:02:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=142.74s)]
*  But I'd like you to have a chance to share with entrepreneurs out there and folks interested in AI [[00:02:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=147.57999999999998s)]
*  Exactly your side of what's happening [[00:02:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=153.9s)]
*  Yeah, thanks, I think that Elon Musk once characterized being a CEO as [[00:02:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=157.42s)]
*  staring into the abyss and chewing glass [[00:02:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=163.18s)]
*  Because you are looking at a very uncertain future having to make decisions and the chewing glass is all the problems that come to you all the time [[00:02:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=165.58s)]
*  and it's required to steer the ship when things are incredibly uncertain and [[00:02:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=172.94s)]
*  Stability is a pretty unique company at a unique time like we hired our first developer and researcher two years ago [[00:02:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=179.26000000000002s)]
*  And then in those two years, we built the best models of almost every type except for large language [[00:03:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=186.14000000000001s)]
*  Image audio 3d etc and had over 300 million downloads of the various models we created and supported [[00:03:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=192.22s)]
*  Which was a bit crazy and then generative AI is crazy [[00:03:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=198.78s)]
*  In terms of usually in a startup, you don't have to deal with global leaders and policy debates about the future of humanity and [[00:03:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=202.38000000000002s)]
*  AGI [[00:03:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=210.54000000000002s)]
*  Everything else at the same time of building code. Yeah at the same time as building code. Yes [[00:03:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=212.54000000000002s)]
*  At the same time of building code, yeah at the same time as building code [[00:03:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=217.82000000000002s)]
*  Yes, and um, especially be a building code to take fraction [[00:03:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=221.34s)]
*  all the resources of our competitors [[00:03:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=225.9s)]
*  um, like we had [[00:03:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=228.70000000000002s)]
*  Certain teams will offer triple their entire packages to move to other companies. Yeah, I was grateful that only a couple of [[00:03:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=230.46s)]
*  Researchers before I couldn't announce internally I was gonna leave left for other companies [[00:03:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=238.76000000000002s)]
*  And that was just startups no one left for another big company, which I think is testament to that kind of loyalty in the mission [[00:04:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=243.73999999999998s)]
*  But you know what we've seen over the last year is or the last half year in particular is the question of governance in ai [[00:04:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=250.78s)]
*  It's something that's incredibly important [[00:04:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=256.86s)]
*  And [[00:04:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=260.3s)]
*  Who manages owns controls this technology and how is it distributed? [[00:04:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=261.58s)]
*  So we saw, you know everything from kind of open ai to congressional testimonies to other things [[00:04:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=266.78s)]
*  And as you know, one of my things has always been [[00:04:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=271.90000000000003s)]
*  How do we get this technology in the hands of people all around the world and then who governs it? [[00:04:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=274.54s)]
*  And how can we then take this technology to have an impact from education to health care to others? [[00:04:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=279.74s)]
*  So stability is a company that build great base models and we got to that point [[00:04:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=285.42s)]
*  The revenue is going up which is always nice, you know finding the business model and again, I think [[00:04:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=289.66s)]
*  It was always curious to see that as a deep tech company two years in [[00:04:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=295.74s)]
*  People were asking us, you know, why aren't we profitable and I was like it takes a bit of time and investment to get to profitability [[00:04:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=299.66s)]
*  Um, I think openly I I mean they took they're not there yet, but then they have eight years [[00:05:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=306.38s)]
*  I think all the comparisons are perhaps unfair [[00:05:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=311.98s)]
*  So reviewing everything and kind of looking at it. I was like, do I really want to be a ceo? I think the answer is no [[00:05:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=314.54s)]
*  I think there is a lot imbued in that in [[00:05:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=321.02000000000004s)]
*  tech [[00:05:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=324.06s)]
*  But it's a very interesting position [[00:05:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=325.02000000000004s)]
*  Just to dive into that a second, um, because we've had this conversation [[00:05:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=327.34s)]
*  Because it was there was a lot of pressure asking whether for you to step down as ceo [[00:05:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=333.18s)]
*  And I think founders [[00:05:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=340.46s)]
*  Typically want to see themselves or feel they need to be the ceo [[00:05:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=343.18s)]
*  And i've heard you say recently, you know that you view yourself more as a founder and strategist than the ceo. Is that a fair assessment? [[00:05:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=347.65999999999997s)]
*  Yeah, I think everyone's got their own skill sets, right? So i'm particularly great at taking creatives [[00:05:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=355.97999999999996s)]
*  Developers research of others and achieving their full potential and designing systems [[00:06:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=361.88s)]
*  But I should not be dealing with you know, hr and operations and business development and other elements [[00:06:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=366.78s)]
*  There are probably better people than me to do that [[00:06:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=373.09999999999997s)]
*  So now for example our most popular thing stable diffusion [[00:06:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=375.74s)]
*  And comfyui the system around it is the most widely used image software models in the world [[00:06:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=379.18s)]
*  There are great media ceos that can take that amplify that to make hundreds of millions of revenue. So they should come in and meet on that [[00:06:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=385.02s)]
*  So why now pal what is there anything that [[00:06:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=392.14s)]
*  specifically tipped for you [[00:06:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=395.71999999999997s)]
*  that has [[00:06:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=398.46s)]
*  I mean because [[00:06:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=399.97999999999996s)]
*  You know it has you know, you have done an extraordinary job. This has been your baby [[00:06:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=401.65999999999997s)]
*  I mean how you have to feel? [[00:06:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=407.74s)]
*  a a whole slew of emotional [[00:06:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=411.02s)]
*  Elements and you know, i've had to step down as ceo on two occasions over the 27 companies [[00:06:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=413.74s)]
*  I've had to sell a company for pennies on the dollar and [[00:07:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=420.3s)]
*  It takes an emotional [[00:07:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=424.14000000000004s)]
*  hardship on you [[00:07:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=427.08000000000004s)]
*  You know, i've had calls for me to step down this year since the [[00:07:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=429.1s)]
*  Well since 2022, you know [[00:07:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=433.98s)]
*  But I always thought you know, what's best for the company and the mission and when I look at the world right now [[00:07:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=437.02000000000004s)]
*  There's a few things a the company [[00:07:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=441.26s)]
*  Has momentum it has spread it's turning into a business like last year. I said, let's not enter into large revenue contracts [[00:07:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=443.58s)]
*  Because technology isn't mature yet and our processes aren't mature yet and you have to deliver [[00:07:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=450.94s)]
*  So we did a lot of experimental things we were setting up and again now it's ramping [[00:07:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=455.34s)]
*  On a business side on a technology side the technology is maturing [[00:07:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=459.26s)]
*  diffusion transformers [[00:07:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=463.02s)]
*  Such as stable diffusion 3 and saura are going to be the next big thing and again stability has got a great place there [[00:07:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=464.62s)]
*  But I think there's also the macro on this [[00:07:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=469.98s)]
*  So if you look at the open ai [[00:07:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=472.94s)]
*  ceo gaud thing [[00:07:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=475.58s)]
*  You know sam altman said the board can fire me anytime. This is the governance of open ai [[00:07:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=477.58s)]
*  And then they fired him and then he is back on [[00:08:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=482.21999999999997s)]
*  And he appoints himself back on the board [[00:08:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=486.38s)]
*  There's clearly no governance open ai. I mean, I respect the people on the board greatly. You know, I think there's some great individuals, but [[00:08:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=489.09999999999997s)]
*  Who should manage the technology that drives humanity and teaches every child and manages our government? [[00:08:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=495.5s)]
*  Who's really leading on that that can build these models and do those things? [[00:08:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=500.94s)]
*  As you know, I've always wanted to build the science models and the other health team's done that I want been doing the education work [[00:08:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=505.5s)]
*  And then my concept of a national model for every country owned by the people of the country [[00:08:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=512.46s)]
*  All tied together. I think it needs to be by a web3 [[00:08:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=517.8199999999999s)]
*  Not crypto or necessary token framework [[00:08:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=521.5s)]
*  That's something that's a brand new kind of challenge and one that I think there's only a window of a year or two to do [[00:08:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=524.7800000000001s)]
*  If you have highly capable models, let's put aside a gi for now, which you can discuss later [[00:08:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=531.26s)]
*  really accelerating [[00:08:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=536.3000000000001s)]
*  Then no one will be able to keep up with that unless you build in a decentralized manner and distributed manner [[00:08:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=538.3000000000001s)]
*  For data talent distribution standards and more so there's only a small window of time here to do that and realistically again [[00:09:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=544.22s)]
*  Successful companies and these things are all great [[00:09:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=552.0600000000001s)]
*  but [[00:09:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=554.7800000000001s)]
*  Genetify is a bit bigger than the classical norms [[00:09:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=555.6600000000001s)]
*  Just like the whole life cycle of the company was a lot faster than the classical norms [[00:09:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=558.38s)]
*  So that's why I felt you know now is the right time to make that change and hopefully play my part [[00:09:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=562.62s)]
*  In making sure this technology is distributed as widely as possible and governed properly [[00:09:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=568.7s)]
*  As pretty much I think i'm the only real independent agent that has built state-of-the-art models in the world right now [[00:09:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=574.22s)]
*  Yeah, we've seen [[00:09:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=581.1s)]
*  A lot of turbulence with open ai we just saw mustafa [[00:09:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=582.78s)]
*  From inflection become part of microsoft [[00:09:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=589.1s)]
*  And I am curious I mean you you had a now famous conversation with satya a couple of days after stepping down [[00:09:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=594.06s)]
*  Was that investigatory on your part or was that just a [[00:10:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=603.74s)]
*  touch base with an old friend [[00:10:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=607.42s)]
*  Oh, that's just chill trolling actually, you know like to let off some steam that picture was I think from [[00:10:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=609.5799999999999s)]
*  A year or two a year or so ago [[00:10:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=615.66s)]
*  But you know, I think satya is an amazing ceo and [[00:10:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=620.14s)]
*  You know, he responds again like the top ceo is incredibly quickly when you message [[00:10:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=624.14s)]
*  Um, he's got a great vision, but there is again this concern about consolidation in tech [[00:10:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=629.5s)]
*  We didn't take money from any trillion dollar companies at stability [[00:10:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=634.86s)]
*  You know, we remained and retained full independence [[00:10:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=639.02s)]
*  You know, um, and you know to the detriment of some of the elements that we've taken very big checks and other things [[00:10:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=642.8599999999999s)]
*  um [[00:10:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=649.9s)]
*  and even though you have good intentions you have to remember that companies are slight [[00:10:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=651.0999999999999s)]
*  Slow dumb ai's that over optimize for various things [[00:10:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=655.66s)]
*  And that's most certainly in the best interest of humanity when you have infrastructure [[00:10:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=659.02s)]
*  It's like this is the airports the railways the roads of the future ai isn't infrastructure [[00:11:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=663.6s)]
*  Which in fact is an infrastructure which should be [[00:11:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=669.6s)]
*  And should it be consolidated under the control of a few private companies with unclear objective functions again? [[00:11:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=672.24s)]
*  The people in the companies may be great. I don't think so and this is a key concern and part of that was that commentary [[00:11:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=678.8s)]
*  Again, he's doing an amazing job. He's consolidating a lot of power [[00:11:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=684.96s)]
*  For the good of the company and also he has a I think genuinely good heart of mission to bring technology to the world [[00:11:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=688.96s)]
*  But it is a bit concerning, right? [[00:11:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=695.84s)]
*  Especially with the new types of structure you're speaking of sam in this case [[00:11:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=698.0s)]
*  Satya here. Oh satya like I feel like like again, I think uh, the commentary was always interesting [[00:11:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=702.4s)]
*  It's like, you know satya playing 4d chess, you know assembling the ai avengers [[00:11:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=706.72s)]
*  I mean he is he's building an amazing mass of talent covering the bases and microsoft is doing incredibly well here, right? [[00:11:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=711.36s)]
*  If you asked who's doing best in general to their people would say microsoft [[00:11:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=718.08s)]
*  But there is has to be concerns about consolidation of talent and power and reach [[00:12:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=722.4s)]
*  Before I get to your vision going forward because it's so important and what you're doing next [[00:12:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=726.4s)]
*  um, I just [[00:12:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=731.6s)]
*  again as a [[00:12:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=733.92s)]
*  founder [[00:12:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=736.16s)]
*  As a ceo of a moonshot company. We have a lot of those [[00:12:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=737.2s)]
*  Listening here [[00:12:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=741.76s)]
*  Can I ask how are you feeling right now? [[00:12:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=743.44s)]
*  Because the decision to step down has to have huge emotional [[00:12:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=746.16s)]
*  Are you feeling relief? Are you feeling anxiety? [[00:12:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=750.3199999999999s)]
*  What's what's the feeling after making that momentous decision? [[00:12:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=754.88s)]
*  Uh [[00:12:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=760.0799999999999s)]
*  I was a big feeling of relief [[00:12:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=761.36s)]
*  um, you know because [[00:12:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=764.4s)]
*  There's the there's a japanese concept of ikigai. I know ikigai and I love it. Yes [[00:12:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=767.28s)]
*  Yeah, do what you go to do what you like and do where you believe you're adding value and other people do too [[00:12:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=772.8s)]
*  you know [[00:12:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=778.56s)]
*  like [[00:12:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=779.4399999999999s)]
*  Realistically again, I think I was an excellent research leader strategist other things [[00:13:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=780.62s)]
*  I didn't communicate properly or hire the right other leaders in certain other areas of the company and there are better people to do that [[00:13:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=785.4399999999999s)]
*  And so I wasn't doing what I was best at a lot or I could have the most measurable value [[00:13:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=791.6s)]
*  And it was tying down, you know, there's a lot of legacy [[00:13:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=796.88s)]
*  Technical organization or other debt, especially when you grow so so so fast [[00:13:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=800.2399999999999s)]
*  And you know, we were lucky that we had higher attention in the important areas and we could execute in spite of all of that [[00:13:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=804.9599999999999s)]
*  In spite of going the big company route [[00:13:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=810.88s)]
*  I think you know moonshot founders you have to do because you don't have the resources at the start and you have to guide the ship [[00:13:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=813.04s)]
*  You know as it goes out from port [[00:13:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=818.8s)]
*  But there does come that transition point there [[00:13:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=820.88s)]
*  And there is a competing thing where you typically take on vc money which has its own objective function [[00:13:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=823.5999999999999s)]
*  versus your overall mission [[00:13:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=829.52s)]
*  So again, if you look at the generative i world right now, how many credible? [[00:13:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=831.76s)]
*  Intelligent independent voices are there there they've had the ability to build models and design things and make an impact [[00:13:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=836.8000000000001s)]
*  You know, there's not many so I was like that's where I can add my most leverage and also [[00:14:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=844.5600000000001s)]
*  The design space is again is unprecedentedly huge because the entire market has just been created [[00:14:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=850.1600000000001s)]
*  So I was like where does gentrify not fit and where does it not touch? [[00:14:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=855.6800000000001s)]
*  And what needs to be built there? We need to actually have the agency to go and build that and so I felt [[00:14:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=859.52s)]
*  tired [[00:14:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=864.96s)]
*  relieved [[00:14:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=865.92s)]
*  I felt that now there's a million options [[00:14:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=866.96s)]
*  I want it rather than taking a long break get on with things [[00:14:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=870.32s)]
*  I've just done the first thing in kind of web 3 and i've got a whole bunch of other things we're going to discuss [[00:14:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=873.6s)]
*  kind of coming [[00:14:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=878.5600000000001s)]
*  And catalyze stuff that can make an exponential benefit [[00:14:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=879.84s)]
*  Exponential benefit [[00:14:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=883.52s)]
*  Because you know like massively transformed to purpose here is I want every kid to achieve their potential and give them the tools to do that [[00:14:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=885.36s)]
*  And and I love you for that [[00:14:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=892.64s)]
*  Because you've been true to that that vision and I know [[00:14:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=894.96s)]
*  on the heels of your announcement you've been reached out to by national leaders by corporate, you know by ceos and major [[00:14:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=898.24s)]
*  investment groups and [[00:15:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=906.0799999999999s)]
*  You have a lot of opportunity ahead of you. So [[00:15:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=908.16s)]
*  So let's talk about [[00:15:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=910.64s)]
*  Where you want to go next? [[00:15:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=913.76s)]
*  You mentioned publicly and you discussed on our abundant stage the idea of [[00:15:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=915.84s)]
*  democratized and decentralized ai [[00:15:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=921.58s)]
*  Let's define that first. What is that? Why is it important and what do you want to do there? [[00:15:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=925.44s)]
*  Yeah, I think that when I said i'm going [[00:15:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=930.96s)]
*  Move to do my part in decentralizing people like isn't that just open source you give the technology, right? [[00:15:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=934.32s)]
*  And then anyone can use it but it isn't a decentralizing ai has a few important components. One is availability and accessibility [[00:15:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=940.48s)]
*  Everyone should be able to access this technology for fruits of labor and there's some very interesting political and other elements around that [[00:15:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=948.0s)]
*  Number two is the governance of this technology [[00:15:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=955.9200000000001s)]
*  You have centralized governance because the models are the data. There's a recent data bricks thing [[00:15:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=959.04s)]
*  A model where they show that you have massive improvements from data. We all know that [[00:16:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=964.16s)]
*  You know who governs the data that teaches your child or manages your health or runs your government [[00:16:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=967.84s)]
*  That's an important question. I think too few are asking and we need data transparency and other things like that [[00:16:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=974.0s)]
*  so [[00:16:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=979.6s)]
*  accessibility, you know, you've got the [[00:16:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=980.86s)]
*  Governance aspect of that and then finally you have how does it all come together? [[00:16:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=983.6800000000001s)]
*  Is it a single package or is it a modernized infrastructure? [[00:16:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=989.2s)]
*  That people can build on and is available kind of everywhere [[00:16:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=994.0s)]
*  You know does it require monoliths and central servers where if it goes down and you have an outage on gbt4 [[00:16:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=997.6800000000001s)]
*  You're a bit messed up or someone can attack and co-opt it [[00:16:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1003.36s)]
*  I think that those are kind of the key elements that I was looking at when I was talking about decentralizing ai [[00:16:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1007.12s)]
*  And you know i've caught with an infrastructure to do that. I hope [[00:16:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1012.32s)]
*  as well [[00:16:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1017.12s)]
*  So if you don't mind, let's double click on it even further. So [[00:16:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1018.4s)]
*  You mentioned we don't have long to get there [[00:17:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1023.28s)]
*  If that's a true statement, why don't we have long to get there? [[00:17:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1026.96s)]
*  and then what does getting there look like if you had [[00:17:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1031.2s)]
*  All the capital available and if the right national leaders were hearing about this because a lot of this is supporting [[00:17:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1035.92s)]
*  um [[00:17:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1044.56s)]
*  supporting the populace of a nation [[00:17:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1045.52s)]
*  To have ai that serves them [[00:17:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1048.64s)]
*  versus [[00:17:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1051.52s)]
*  uh top down [[00:17:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1052.56s)]
*  What's it look like? [[00:17:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1054.56s)]
*  Two five ten years from now [[00:17:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1056.24s)]
*  Yeah, I think you'll have both proprietary and open source ai and they'll work in combination the practical example [[00:17:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1058.72s)]
*  I give is that this ai is like graduates right very talented slightly enthusiastic graduates [[00:17:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1065.84s)]
*  And you've got those and consultants [[00:17:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1071.04s)]
*  Um, but I really you know on stage with lat friedman last week at a360 when we're there [[00:17:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1073.44s)]
*  He said it's like we've discovered this new concept. What do you call it ai atlantis atlantis? Yes [[00:17:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1078.24s)]
*  Yes with 100 billion graduates that will work for free [[00:18:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1083.0400000000002s)]
*  Yes, I love that analogy. It was it was a brilliant analogy. Yeah, we used to figure out how to say atlantis [[00:18:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1086.0800000000002s)]
*  you know, um [[00:18:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1091.68s)]
*  But but there's a few things here. First of all is the defaults, you know, once a government [[00:18:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1093.3600000000001s)]
*  Embraces centralized technology. It's very difficult to decentralize it and every country needs an ai strategy a year ago [[00:18:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1097.8200000000002s)]
*  One year ago was gpt4 [[00:18:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1106.48s)]
*  Yeah crazy [[00:18:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1109.0400000000002s)]
*  How crazy is that you know at the ai safety summit, uh in [[00:18:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1110.64s)]
*  the uk [[00:18:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1115.3600000000001s)]
*  the king of england came on stage or came via video call and he said that [[00:18:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1116.48s)]
*  This is the biggest thing since fire, you know [[00:18:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1121.2800000000002s)]
*  And that was like what six seven months later. Where are we going to be in here? [[00:18:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1124.64s)]
*  Yeah, I think he took that from uh, uh [[00:18:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1128.48s)]
*  From uh, uh the founder the ceo of google. Um [[00:18:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1132.3200000000002s)]
*  ai is as powerful as fire and electricity [[00:18:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1136.5600000000002s)]
*  Yeah [[00:18:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1139.2s)]
*  Yeah, i've heard the same from like jeff bezos and a bunch of others, you know, not kindle fire proper fire, you know [[00:19:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1140.48s)]
*  Um, but then if you think about it [[00:19:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1146.88s)]
*  Norms are going to be set in this next period like, you know, i'm in california la at the moment if you don't set norms on [[00:19:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1149.76s)]
*  Rights for actors and the movie industry then you could have a massive disruption just occurring this full length [[00:19:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1156.32s)]
*  Hollywood features come in a year or two generated, you know [[00:19:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1162.32s)]
*  If you don't have norms around open models and ownership and governance by the people it'll be top-down governance because governments can't [[00:19:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1165.76s)]
*  Allow that to be out of control if they don't have a reasonable alternative [[00:19:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1173.6s)]
*  um, and [[00:19:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1177.1999999999998s)]
*  I think the window is only a year or two because every government must have a strategy by the end of the year [[00:19:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1178.6399999999999s)]
*  And so I think if you provide them a good solution that has this element of democratic governance and others that will be immensely beneficial [[00:19:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1183.28s)]
*  I think also [[00:19:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1190.8799999999999s)]
*  It's urgent because we have the ability to make a huge difference [[00:19:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1192.56s)]
*  You know as we kind of may probably discuss later having all the knowledge of cancer longevity autism at your fingertips [[00:19:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1196.48s)]
*  We have the technology for that right now [[00:20:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1202.72s)]
*  We have the technology that no one ever is ever alone again on those things or to give every child a superior education literally in a [[00:20:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1204.1599999999999s)]
*  couple of years [[00:20:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1211.28s)]
*  like [[00:20:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1212.8s)]
*  There is an urgency both from there's a small window but also from we must do this now [[00:20:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1213.6s)]
*  Because it can scale and make that impact we have dreamed of for so long the enabling technology is finally in it's finally good enough fast [[00:20:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1218.72s)]
*  Love and cheap enough everybody want to take a short break from our episode to talk about a company [[00:20:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1225.2s)]
*  That's very important to me [[00:20:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1229.2s)]
*  And could actually save your life or the life of someone that you love company is called fountain life [[00:20:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1231.28s)]
*  And it's a company I started years ago with tony robbins and a group of very talented physicians [[00:20:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1237.1200000000001s)]
*  You know most of us don't actually know what's going on inside our body. We're all [[00:20:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1242.72s)]
*  Optimists until that day where you have a pain in your side [[00:20:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1247.8200000000002s)]
*  You go to the physician in the emergency room and they say listen [[00:20:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1251.52s)]
*  I'm sorry to tell you this but you have [[00:20:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1254.0800000000002s)]
*  This stage three or four going on and you know, it didn't start that morning [[00:20:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1256.4s)]
*  It probably was a problem that's been going on for some time, but because we never look [[00:21:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1261.44s)]
*  We don't find out so what we built at fountain life was the world's most advanced diagnostic centers [[00:21:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1266.96s)]
*  We have four across the us today [[00:21:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1274.0s)]
*  And we're building 20 around the world these centers give you a full body mri a brain a brain vasculature [[00:21:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1276.3200000000002s)]
*  An ai-enabled coronary ct looking for soft plaque dexa scan a grail blood cancer test a full executive blood workup [[00:21:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1283.6000000000001s)]
*  It's the most advanced workup you'll ever receive [[00:21:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1292.0800000000002s)]
*  150 gigabytes of data that then go to our ai's and our physicians to find any disease at the very beginning [[00:21:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1295.74s)]
*  When it's solvable, you're going to find out eventually [[00:21:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1304.3200000000002s)]
*  Might as well find out when you can take action fountain life also has an entire side of therapeutics [[00:21:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1307.28s)]
*  We look around the world for the most advanced therapeutics that can add 10 20 healthy years to your life [[00:21:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1312.5600000000002s)]
*  And we provide them to you [[00:21:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1317.76s)]
*  At our centers. So if this is of interest to you [[00:22:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1320.24s)]
*  Please go and check it out go to fountain life.com [[00:22:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1323.8400000000001s)]
*  Backslash peter when tony and I wrote our new york times bestseller life force [[00:22:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1328.6200000000001s)]
*  We had 30 000 people reached out to us for fountain life memberships. If you go to fountain life.com [[00:22:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1334.16s)]
*  Peter will put you to the top of the list [[00:22:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1340.8000000000002s)]
*  Really? It's something that is [[00:22:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1344.24s)]
*  For me one of the most important things I offer my entire family the ceos of my companies my friends [[00:22:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1346.64s)]
*  It's a chance to really add decades onto our healthy lifespans [[00:22:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1353.04s)]
*  Go to fountain life.com [[00:22:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1358.4s)]
*  Peter it's one of the most important things I can offer to you as one of my listeners [[00:22:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1360.4s)]
*  All right, let's go back to our episode. So the let's talk about the objective function of democratized and decentralized ai [[00:22:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1364.96s)]
*  Is it that the compute is resonant? [[00:22:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1372.0s)]
*  In countries around the world. Is it that the models are owned by the citizens of the world? [[00:22:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1376.0800000000002s)]
*  Is it that data is owned? [[00:23:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1382.3200000000002s)]
*  And how do you get there from here? [[00:23:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1385.6000000000001s)]
*  I think that um, you can think of the supercomputers like universities [[00:23:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1387.9199999999998s)]
*  You don't need many universities, honestly if someone's building good quality models [[00:23:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1393.12s)]
*  That's one of the things as I said stability and we did the hard task. We could have just stuck with image [[00:23:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1396.56s)]
*  We said no, we're going to have the best 3d image audio [[00:23:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1401.04s)]
*  Biomedical all these models and no one else managed that apart from open ai to agree [[00:23:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1404.3799999999999s)]
*  In fact, I think we have more modalities than open ai [[00:23:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1409.36s)]
*  again kind of what I kind of describe this is accessibility and [[00:23:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1412.48s)]
*  Governance and a few of these other factors [[00:23:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1417.9199999999998s)]
*  So I think what it means is that this technology is available to everyone but you see now that [[00:23:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1420.24s)]
*  You don't assume you need giant supercomputers to even run it [[00:23:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1425.84s)]
*  You know, we showed you a language model running on the laptop stable lm2 will run on a gigabyte [[00:23:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1428.8799999999999s)]
*  On a mac macare faster than you can read, you know, we're writing some poems various things, you know [[00:23:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1434.7199999999998s)]
*  Um, we see stable diffusion now at 300 images a second or because you see the graphics card [[00:24:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1440.0s)]
*  Our video model was like five gigabytes of vrap [[00:24:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1446.08s)]
*  This really changes the equation because in web 2 all the intelligence was centralized on these giant servers and big data [[00:24:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1449.52s)]
*  Now you have big supercomputers. I think you'll need less with better data [[00:24:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1456.16s)]
*  Training these graduates that can go out and customize to each country, but they must reflect the culture of that country [[00:24:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1460.24s)]
*  Like the japanese stable diffusion model we had if you typed in [[00:24:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1466.08s)]
*  Valerie man, it gave you a very sad person versus the base model giving you a very happy person, right? [[00:24:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1469.44s)]
*  So you must have graduates that reflect the local culture and then reflect the local knowledge [[00:24:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1475.8400000000001s)]
*  and then global models again [[00:24:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1480.5600000000002s)]
*  That reflect our global knowledge and can be accessed by anyone [[00:24:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1484.0800000000002s)]
*  But who decides what goes in that? These are some very important questions [[00:24:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1489.5200000000002s)]
*  And who vouches for the quality as well? [[00:24:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1493.5200000000002s)]
*  What's your advice to a national leader because [[00:24:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1496.48s)]
*  You know, we're now starting to see ministers of ai in different nation states and what? [[00:25:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1500.0800000000002s)]
*  What's your advice to them? [[00:25:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1506.24s)]
*  right now in this area [[00:25:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1508.24s)]
*  I think my advice to them would be [[00:25:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1510.4s)]
*  To start collecting the data sets that they would teach [[00:25:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1512.72s)]
*  A graduate that was very smart through school and kind of other things. This is national broadcast data. This is [[00:25:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1516.96s)]
*  The curriculum this is their accounting legal and others and note that those data sets are infrastructure [[00:25:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1523.12s)]
*  They will enable the local populace and others to create these models because models are just data wrapped in algorithms with a bit of compute [[00:25:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1529.2s)]
*  That's the recipe [[00:25:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1536.8799999999999s)]
*  compute algorithms and data [[00:25:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1538.24s)]
*  and [[00:25:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1540.72s)]
*  It's not going to be as hard as you think to train these models, but you have to build them to get standards [[00:25:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1541.84s)]
*  So by the end of next year probably year after I would estimate that a [[00:25:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1546.3999999999999s)]
*  Llama 7 tb model or a stable diffusion model [[00:25:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1551.1200000000001s)]
*  So these are two leading models in image and language will cost about [[00:25:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1555.28s)]
*  Under ten thousand dollars probably even one thousand dollars to train [[00:26:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1560.16s)]
*  And then it comes all about the data and then it becomes about the standards [[00:26:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1564.32s)]
*  You know, it's it's it's interesting. Um, there is so much [[00:26:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1569.44s)]
*  knowledge [[00:26:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1573.92s)]
*  in the world that will [[00:26:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1575.04s)]
*  Vaporize sublimate over the decade ahead as people die [[00:26:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1578.0s)]
*  You know [[00:26:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1581.68s)]
*  Cultural data locked up in people's minds and stories and so forth that's never been recorded [[00:26:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1582.6399999999999s)]
*  It's an interesting time to actually capture that data and permanently store it into [[00:26:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1588.3999999999999s)]
*  uh the national models [[00:26:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1593.92s)]
*  Yeah, and again, I think people over focus on the models versus the data sets [[00:26:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1596.48s)]
*  I mean is data set. Yeah. Yeah with the exponential compute [[00:26:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1601.12s)]
*  You can recalibrate and improve the data as well [[00:26:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1604.56s)]
*  So right now a lot of the improvements and models are actually synthetically improving data and data quality [[00:26:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1607.4399999999998s)]
*  Um, as I said, there's so much that can be lost [[00:26:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1613.9199999999998s)]
*  But now we can actually capture this and the concepts and the other guidance and have cross checks like you can deconstruct laws [[00:26:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1616.32s)]
*  You know, you can translate between contexts [[00:27:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1624.3999999999999s)]
*  you can make [[00:27:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1626.96s)]
*  expert information available to everyone because again [[00:27:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1628.32s)]
*  You have this new continent of ai atlantis and all these graduates seem to be specialists [[00:27:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1631.44s)]
*  That are on your phone and that's incredibly democratizing [[00:27:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1636.8s)]
*  You know, uh [[00:27:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1641.28s)]
*  Because otherwise the knowledge is throughout history knowledge has always been gate kept always [[00:27:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1643.52s)]
*  I want to get to uh health and education next but before we go there [[00:27:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1649.44s)]
*  I know you were meeting with uh, a mutual friend. Uh, jules erbac the other day [[00:27:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1654.24s)]
*  um [[00:27:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1660.48s)]
*  And uh instability announced a deal with otoi endeavor and render network [[00:27:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1661.68s)]
*  Are you still an advisor to that venture? [[00:27:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1667.52s)]
*  Yeah, no, this is part of the whole thing. It's the first of many web three [[00:27:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1670.48s)]
*  Kind of elements there. I think web three is 95 percent. Let's say 90. I'll be generous [[00:27:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1674.96s)]
*  um speculative and rubbish [[00:28:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1681.26s)]
*  But there is that five ten percent of genuine people that have been thinking about questions of governance coordination and others [[00:28:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1684.24s)]
*  And have built things that are proper. So otoi is the bridge to the creative industry [[00:28:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1692.3200000000002s)]
*  You know, that's why we were with aria manuel and eric schmidt and others are on the board [[00:28:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1697.3600000000001s)]
*  Um, and the render network is a million gpus largely from creative professionals that are available [[00:28:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1701.92s)]
*  And so the first thing I announced there I was being the short 10 million gaps 250 million [[00:28:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1708.16s)]
*  Of distributed compute to create the best 3d datasets like stability [[00:28:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1714.24s)]
*  We funded and worked with alan institute and others on obj verse excel, which was 10 million high quality 3d assets. We're going to a billion [[00:28:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1720.4s)]
*  Distributed you don't need giant supercomputers [[00:28:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1727.5800000000002s)]
*  But then that is a community good that is owned by the people of the network and accessible to non-academic [[00:28:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1730.4s)]
*  Academic and others as well [[00:28:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1736.34s)]
*  Why because you need high quality assets to create better 3d models [[00:28:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1738.26s)]
*  We have any 3d model tripod that can generate a 3d image from a 2d image and not go five seconds [[00:29:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1741.78s)]
*  and that [[00:29:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1746.98s)]
*  3d model feeds into better 3d assets [[00:29:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1747.9399999999998s)]
*  And then what does that mean? It means we're heading towards the holodeck [[00:29:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1750.58s)]
*  Without the data, you're not going to get there [[00:29:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1753.86s)]
*  And that jewels jewels wants the holodeck for sure [[00:29:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1755.9399999999998s)]
*  And so, you know jewels and I are the same page of that, you know [[00:29:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1759.3s)]
*  And you're not going to get there without again a commons of data that can train the graduates that then become specialized with star trek or [[00:29:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1761.9399999999998s)]
*  You know star wars or any of these other ips and then also setting standards around [[00:29:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1770.82s)]
*  Monetization ip rights all sorts of other things [[00:29:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1777.36s)]
*  And so a network like render is really good for that [[00:29:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1780.74s)]
*  But you know, i've been talking to a lot of people in web 3 about the different elements of the stack [[00:29:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1783.54s)]
*  Uh, because what I basically see is that we have the opportunity to build almost a human operating system [[00:29:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1788.5s)]
*  models and data sets for every nation every sector coordinated through [[00:29:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1795.78s)]
*  Proper web 3 principles again, not speculative tokens or anything like that [[00:30:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1800.66s)]
*  You know making it so that every child in the world or adult can create anything they can imagine [[00:30:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1805.6200000000001s)]
*  They can be protected against the harms [[00:30:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1811.8600000000001s)]
*  And they have access to the right information at the right time to thrive [[00:30:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1814.42s)]
*  And again, that's infrastructure for everyone. It's a common good [[00:30:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1818.02s)]
*  Access to gpus has been sort of the limited fuel [[00:30:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1822.3400000000001s)]
*  Do you think decentralized gpu structures like render is part of that future is an important part of that future? [[00:30:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1827.22s)]
*  I think that right now [[00:30:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1834.98s)]
*  It's far more efficient to train models on these again big supercomputers the university but the rate of exponential growth there again is insane [[00:30:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1836.74s)]
*  Last year to train llama 2 cost 10 million dollars in a year. It'll cost 10 000 [[00:30:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1845.38s)]
*  It's a thousand times improvement from algorithms data super compute speeds [[00:30:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1851.54s)]
*  And that's crazy if you think about it, right? [[00:30:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1857.14s)]
*  Um, so I think this will be the limiting factor [[00:30:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1859.78s)]
*  I think the gpu overhang for language models probably lasts until the end of the year [[00:31:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1861.86s)]
*  But then there's plentiful supply because what you have is [[00:31:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1866.74s)]
*  Nvidia makes amazing gpus at 83 or 87 percent margin, right? [[00:31:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1870.18s)]
*  But the actual calculations aren't complicated like we took intel [[00:31:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1874.98s)]
*  Gpus and we ran the stable diffusion 3 diffusion transformer training [[00:31:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1878.64s)]
*  So this is the same technology that's used in saura and stable diffusion 3 is multimodal so it can train saura models with enough compute [[00:31:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1882.5800000000002s)]
*  And I think us and them are the only people kind of doing this. I think maybe pixart as well [[00:31:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1889.46s)]
*  um and then [[00:31:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1893.8600000000001s)]
*  It ran faster than the intel gpus than the nvidia gpus [[00:31:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1896.18s)]
*  But we know that it can run even faster because it's not optimized for either and it's still running fast [[00:31:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1900.66s)]
*  So what you'll see is a commoditization of the hardware [[00:31:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1906.02s)]
*  Once the architect just gets stabilized because gpd4 is just a research [[00:31:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1909.46s)]
*  Artifact still diffusion was just a research artifact. You're not getting engineering phase yet [[00:31:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1914.88s)]
*  And you've got to the point whereby this runs on macbooks it runs on other things [[00:31:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1919.78s)]
*  So I think it's a short-term phenomenon of the next year [[00:32:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1924.82s)]
*  Because people are taking a point in time [[00:32:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1928.5800000000002s)]
*  And extrapolating without taking into account efficiencies optimizations [[00:32:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1931.22s)]
*  And the fact that models that work on the edge and it can go to your private data will be more impactful than [[00:32:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1936.26s)]
*  Generalized intelligence everyone's over indexing on generalized intelligence and building ai god [[00:32:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1942.72s)]
*  versus amplified human intelligence, shall we say [[00:32:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1948.5s)]
*  Before we leave stability. It's now in the hands of uh, [[00:32:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1952.82s)]
*  the chair and your [[00:32:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1957.78s)]
*  Past cto what's what do you imagine the future of stability is going to be going forward? [[00:32:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1960.5800000000002s)]
*  I know that you're not involved anymore. It's under different leadership and there's a what's your advice to them? [[00:32:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1966.02s)]
*  Or where do you think they're going to go? [[00:32:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1972.1000000000001s)]
*  You know, I can do the very basic advice [[00:32:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1974.5800000000002s)]
*  I don't want any conflicts or anything because i'll be setting up lots of new companies and you know being a founder [[00:32:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1976.3400000000001s)]
*  And a shareholder and again stability. I'm a founder shareholder [[00:33:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1982.42s)]
*  In fact, you're still the majority shareholder. I think as of right now just about just about yeah [[00:33:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1986.44s)]
*  Um that will change i'm sure new money will come in like we still [[00:33:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1991.88s)]
*  Go here yesterday on I think [[00:33:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1995.64s)]
*  20 or 20 million of revenue run rate. They're raising it 5 billion money's plenty crazy. Yes [[00:33:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=1997.8000000000002s)]
*  Yeah with the right leadership, I think that um [[00:33:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2003.0800000000002s)]
*  It can again have an amazing part to play in media and that's what i've suggested to it [[00:33:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2006.5200000000002s)]
*  Um, and again, there's a great team that continues to ship great models [[00:33:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2011.3200000000002s)]
*  So last week there was an amazing code model next week amazing language audio and other models are coming out [[00:33:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2014.44s)]
*  So, you know you continue shipping and great products around that too [[00:33:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2019.88s)]
*  um [[00:33:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2023.64s)]
*  So that was kind of my advice to them. Let's focus on media and take that forward but [[00:33:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2025.0800000000002s)]
*  You know, i'm not the expert on the business side of things. I did the best I could [[00:33:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2030.1200000000001s)]
*  My expertise on setting this up i'm taking it 0 to 10 [[00:33:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2033.72s)]
*  And uh, yeah is zero zero one is is definitely um [[00:33:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2036.6s)]
*  a role that [[00:34:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2043.48s)]
*  That you played here and allow it allow someone else to take it the rest of the way [[00:34:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2045.08s)]
*  Uh, but the area that I know [[00:34:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2050.68s)]
*  If I could actually repeat this something I wanted to kind of discuss here. I think it's quite important [[00:34:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2053.4s)]
*  Please for again the founders listing and the moonshot companies [[00:34:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2057.96s)]
*  um [[00:34:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2061.8s)]
*  There is an imbalance of power when you have [[00:34:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2062.92s)]
*  Very visionary highly competent leaders there [[00:34:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2067.0800000000004s)]
*  Like what I found its stability is that everyone would be waiting for me [[00:34:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2071.48s)]
*  No matter how competent because I was the one that could see around the corners and I was a bit good at everything [[00:34:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2074.84s)]
*  Even if I hired people that built billion dollar startups or leaders and research at google or kind of whatever [[00:34:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2080.44s)]
*  Um, because you have the outsize things [[00:34:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2087.0800000000004s)]
*  So what kind of dress better says you have to speak last in some cases and some people in meetings [[00:34:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2088.84s)]
*  Otherwise, everyone just does everything you say and they also wait on you [[00:34:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2093.56s)]
*  Now what I find and what I tell the team is that you're flat as a power dynamic [[00:34:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2097.64s)]
*  You're all on the same page. You're all kind of relatively equal owners [[00:35:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2101.48s)]
*  And it'll be interesting to see how it evolves from that [[00:35:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2105.0s)]
*  Given that there's actually a business and again, I think this is something that you probably had a challenge within other founders here [[00:35:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2107.7999999999997s)]
*  whereby [[00:35:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2114.12s)]
*  They put more on your plate because you are so visionary and because you're like up there in the future [[00:35:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2115.56s)]
*  And they're always waiting on you. So you're always like well my schedule is completely packed my schedule now is actually quite free [[00:35:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2121.72s)]
*  Which is also quite nice [[00:35:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2126.68s)]
*  I've had a chance to speak with you every day for the last few days. So that's been a pleasure to have extra time on your [[00:35:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2128.52s)]
*  schedule [[00:35:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2133.0s)]
*  You know, so so we we do have a world of uh, visionary founder led [[00:35:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2134.2s)]
*  Ceo companies, right? So you've got musk and you've got bezos historically and you had steve jobs and you [[00:35:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2140.12s)]
*  and [[00:35:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2146.2799999999997s)]
*  And that's both powerful and dangerous the the power is the ability for that because we don't ever have a company [[00:35:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2147.08s)]
*  That is pre-existing a new ceo comes in and has the same [[00:35:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2154.84s)]
*  Both hutiba and and also the power of their of their vision [[00:36:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2162.04s)]
*  The danger there your concern you're saying is [[00:36:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2169.72s)]
*  Not not allowing your team to step up with their own vision [[00:36:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2173.7999999999997s)]
*  Or being over overly indexed on your on your vision [[00:36:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2178.7599999999998s)]
*  Yeah, I think that that can be the issue and that's why I wanted stability to again reach the point of spread [[00:36:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2182.12s)]
*  And revenue rate increase and other things before I did anything [[00:36:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2187.96s)]
*  um, I felt again this external pressure and that if nobody [[00:36:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2192.12s)]
*  Or there's very few people in the world actually thinking properly about governance and spread and others and a very small window [[00:36:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2196.52s)]
*  Given the pace of this to make a difference in the dent. I believed I had a reasonable approach to that [[00:36:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2201.72s)]
*  But I couldn't while remaining ceo of this company and again, it's a [[00:36:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2207.24s)]
*  pretty unique scenario because you've never seen a sector move this fast that has such wide-reaching human implications and [[00:36:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2211.24s)]
*  Regressively, there's too few people [[00:36:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2219.14s)]
*  I think with the right alignment and [[00:37:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2222.3599999999997s)]
*  Approach in this area. I've been very disappointed [[00:37:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2225.3999999999996s)]
*  Like usually what happens is you have power maximization equations and this is what we're seeing from the industry consolidation [[00:37:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2229.02s)]
*  how many people [[00:37:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2235.74s)]
*  Want to genuinely bring this technology to kids in nigeria? [[00:37:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2237.66s)]
*  or to the global south [[00:37:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2242.22s)]
*  Or to help those leaders build their own models, you know and believe also in a positive sum game [[00:37:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2244.38s)]
*  That was actually my biggest surprise from the discussions silicon valley [[00:37:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2249.34s)]
*  Almost entirely they all believe in [[00:37:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2252.7799999999997s)]
*  Uh flat or negative sum [[00:37:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2255.7400000000002s)]
*  You know zero sum or negative sum things where there has to be a winner. Everyone's a winner in this [[00:37:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2258.6200000000003s)]
*  And again, I was just very disappointed seeing that [[00:37:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2264.3s)]
*  I've been asking for you for a while to write and distribute your vision white paper [[00:37:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2267.42s)]
*  Because i've heard you describe it in detail and it's brilliant and I still hope that the world will see it soon enough [[00:37:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2272.86s)]
*  Everybody you want to take a break from our episode to tell you about an amazing company on a mission to prevent and reverse [[00:37:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2278.6200000000003s)]
*  chronic disease [[00:38:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2284.46s)]
*  By decoding your biology the company is called viome and they offer cutting-edge tests and personalized products that help you optimize [[00:38:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2285.82s)]
*  Your gut microbiome your oral microbiome and your cellular health as you probably know [[00:38:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2294.3s)]
*  Your microbiome is a collection of trillions of microbes that live in your gut and mouth [[00:38:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2299.6600000000003s)]
*  These microbiomes influence everything your digestion immunity mood weight and many other aspects of your health [[00:38:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2305.58s)]
*  But not all microbes are good for you [[00:38:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2312.86s)]
*  Some can cause inflammation toxins and actually lead to chronic diseases like diabetes heart disease obesity and even cancer [[00:38:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2315.5800000000004s)]
*  Viome uses advanced mrna technology and ai [[00:38:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2323.34s)]
*  To analyze your microbes and your cells and give you personalized nutrition recommendations [[00:38:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2327.6600000000003s)]
*  And products designed specifically for your genetics specifically for your biology [[00:38:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2333.26s)]
*  You can choose from different tests depending on your goals and needs [[00:38:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2338.7s)]
*  Ranging from improving your gut health your oral health cellular function or all of them [[00:39:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2342.46s)]
*  I've been using viome for the past three years. I can tell you that it has made a huge difference in my health [[00:39:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2347.42s)]
*  And because the data they collect and the ai engine they've built it gets better every single day [[00:39:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2353.5s)]
*  I love getting health scores and seeing how my diet and lifestyle affects my microbiome and my cells [[00:39:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2360.3s)]
*  And I love getting precision supplements and probiotics tailored for my specific needs [[00:39:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2366.2200000000003s)]
*  If you want to join me on this journey of discovery and improve your health from the inside out [[00:39:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2371.34s)]
*  Viome has a special offer for you for a limited time. You can get up to 40 off [[00:39:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2376.6200000000003s)]
*  Any viome test using the code moonshots just go to viome.com [[00:39:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2382.54s)]
*  Backslash moonshots and order your test today. Trust me. You won't regret it. All right, let's go back to our episode [[00:39:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2387.7200000000003s)]
*  Before we jump into into health and education, let's talk about governance a second because we've seen governance [[00:39:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2394.14s)]
*  Complicate this what is the right governance structure for this super powerful technology? [[00:40:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2402.2s)]
*  We have representative democracy that I think can be improved by this like I don't think democracy survives this technology at its current form [[00:40:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2407.3399999999997s)]
*  It will either improve or it'll end [[00:40:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2414.14s)]
*  I don't see anything else like yesterday [[00:40:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2416.7s)]
*  What does end what does end mean here a benign dictatorship a driven by an ai overlord [[00:40:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2419.9s)]
*  Yeah, like yesterday there was a announcement of an app called hume [[00:40:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2426.06s)]
*  Which had emotionally intelligent speech and they can understand your emotions and talk with emotion. You know, I have to discuss this [[00:40:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2430.94s)]
*  Yes, you know where that's going right? It's very powerful [[00:40:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2438.06s)]
*  It's incredibly powerful and governments have a tendency. I mean that official government [[00:40:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2441.66s)]
*  But say it say it here [[00:40:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2446.78s)]
*  it's important for you to state what what it means because we've discussed it but help people here under be ready for this and [[00:40:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2448.0600000000004s)]
*  Democracy is all about representation and you see the questions of deep fakes and things speech is one of the most impactful elements there [[00:40:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2456.44s)]
*  But now you can't believe anything you see here [[00:41:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2463.1800000000003s)]
*  everything [[00:41:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2466.0600000000004s)]
*  so one path that we have is a 1984 on steroids [[00:41:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2467.1800000000003s)]
*  Panoptical, you know [[00:41:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2472.78s)]
*  Where life is gamified and you listen to whatever the government says and they're incredibly convincing and you're happy [[00:41:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2474.62s)]
*  And you've always been happy and you've always been at war with eurasia, you know [[00:41:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2480.22s)]
*  propaganda on steroids [[00:41:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2483.8s)]
*  The other part that you have is things like citizen assemblies consultative democracy [[00:41:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2485.58s)]
*  the ability to take right now you can take any of the bills in congress and completely deconstruct them and find [[00:41:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2490.46s)]
*  What the motivations are you know, you can check laws against the constitution in a second seconds [[00:41:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2497.9s)]
*  This is incredibly powerful empowering technology from a democratic perspective. So I see two routes [[00:41:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2504.86s)]
*  Unfortunately, because I think that once the right thing goes it goes really fast [[00:41:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2510.04s)]
*  Centralized government control increasing because the governments want to protect themselves as an organization [[00:41:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2515.08s)]
*  And you know every party says the other party's crap [[00:42:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2520.3s)]
*  We've seen the increasing polarization in america already [[00:42:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2523.58s)]
*  And you know fundamentally come on you can do better than those two leaders that are currently competing [[00:42:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2526.8599999999997s)]
*  i'm saying this is [[00:42:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2531.5s)]
*  Clearly our system is sclerotic across this like democracy is the worst of all systems except for everyone else [[00:42:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2533.18s)]
*  You can have a better democracy [[00:42:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2538.7s)]
*  Where it's actually representative and empowers the people [[00:42:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2541.1s)]
*  or [[00:42:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2545.18s)]
*  We will have the end of democracy where it is in 1984 panoptical in my opinion [[00:42:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2546.14s)]
*  Because the momentum will go then of course you'll start using this technology you're already seeing it being used [[00:42:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2550.7s)]
*  But not at scale and not intelligently yet, which is scary [[00:42:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2556.3799999999997s)]
*  I think we finally have the technology for a direct [[00:42:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2560.8599999999997s)]
*  democracy versus a representative democracy, right where I can have my [[00:42:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2565.5s)]
*  my [[00:42:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2570.3799999999997s)]
*  desires directly represented on any specific law or [[00:42:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2571.42s)]
*  but I think the point you've made before is [[00:42:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2576.22s)]
*  that [[00:42:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2579.66s)]
*  speech [[00:43:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2580.7799999999997s)]
*  um if you look back to [[00:43:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2582.22s)]
*  Everybody from hitler to some of the most persuasive politicians [[00:43:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2585.3399999999997s)]
*  um is [[00:43:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2589.8199999999997s)]
*  Is a powerful tool and ai can become the most persuasive speaker out there [[00:43:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2591.74s)]
*  It can take anyone's speech and make it far more persuasive. Like I think my voice is a bit whiny [[00:43:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2598.22s)]
*  I can remove the wine, you know, I can go in a very polished british accent and other things like that, right? [[00:43:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2602.22s)]
*  You know must fight them on the hills and the areas or whatever [[00:43:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2607.8199999999997s)]
*  Public speaking needs to be different someone took hitler's speeches and put them through an ai and took them into english [[00:43:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2611.74s)]
*  Because when we're not in the german context and we listen to them, it sounds like he's shouting like what a crazy thing [[00:43:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2618.2999999999997s)]
*  You hear him in english. It is very different in his own voice [[00:43:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2624.38s)]
*  Just like someone took chavier millet's one in the united nations and put him into english again [[00:43:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2628.46s)]
*  He sounds a bit sharp how shouty but then he sounds very reasonable when it's in english [[00:43:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2633.66s)]
*  And you can take the phoenomes of obama's best speech and a bit of trumpianism and a bit of churchill [[00:43:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2638.78s)]
*  And you will have full modulation wave control over all of this [[00:44:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2644.54s)]
*  People are already using this technology [[00:44:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2647.7400000000002s)]
*  that everyone should have a passcode with their loved ones because people are getting calls from their mother [[00:44:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2650.3s)]
*  Saying help i'm in an emergency and you just send money right now [[00:44:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2656.86s)]
*  And you cannot tell it and it pulls at the emotional strings [[00:44:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2660.78s)]
*  If you look at something like u.s radio and you know one side of the political divide has taken over imagine if you're hearing [[00:44:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2664.3s)]
*  optimized speech every single day [[00:44:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2670.6800000000003s)]
*  That will have a huge impact and then they control the visuals and they control the other things [[00:44:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2674.0600000000004s)]
*  We're not set up for defenses. Yeah, if it's if it's optimized speech for you [[00:44:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2678.6200000000003s)]
*  Specifically for you right for the kids you have the age group they have where you live your historical background and so forth and n [[00:44:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2683.34s)]
*  Of one persuasive speech [[00:44:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2690.86s)]
*  Coming at you. Um [[00:44:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2693.42s)]
*  The brain is not set up for defenses [[00:44:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2695.5800000000004s)]
*  We're not and you know, we take this as an example of the youtube algorithm like youtube as an organization is not an evil organization [[00:44:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2698.46s)]
*  But it's an organization optimized for engagement which optimize for more extreme content [[00:45:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2706.2200000000003s)]
*  So there's some dark place in youtube which is an optimized for ices [[00:45:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2710.7000000000003s)]
*  The ices video spread [[00:45:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2714.1400000000003s)]
*  Viral, I don't know. Sometimes viral is good. Sometimes viral is bad. That one was bad [[00:45:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2716.3s)]
*  Because it was extreme [[00:45:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2720.6200000000003s)]
*  And they didn't understand why [[00:45:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2722.78s)]
*  And if you look at it, our two of our largest journal to be our companies are google [[00:45:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2725.1800000000003s)]
*  and meta [[00:45:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2730.3s)]
*  And their business is advertising their business is manipulation and they are both a moral companies [[00:45:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2731.7400000000002s)]
*  Because why would you expect a company to have morality? [[00:45:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2737.98s)]
*  Our governments are also amoral [[00:45:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2741.58s)]
*  And again, you can view these things as slow dumb ai's so you can see the way they will optimize unless we do something about it [[00:45:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2743.98s)]
*  And they will have full control like again you click on your vision pro headset [[00:45:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2750.78s)]
*  With your spatial audio [[00:45:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2754.78s)]
*  That is full sensory control [[00:45:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2757.1800000000003s)]
*  Not full, but you know what I mean a level that we've never seen full immersion full immersion full immersion [[00:45:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2759.9s)]
*  And so we have to be aware of this [[00:46:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2765.58s)]
*  And there's obviously other tools that can be used like in the wake of the arab spring, you know [[00:46:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2769.1s)]
*  Governments targeted everyone else on social media. We can do that on a hyper personalized basis [[00:46:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2773.34s)]
*  like [[00:46:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2778.78s)]
*  We need to set some defaults and standards here to protect [[00:46:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2780.2200000000003s)]
*  democracy [[00:46:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2784.44s)]
*  But again why democracy? [[00:46:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2785.66s)]
*  We're not really trying to protect democracy [[00:46:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2788.3s)]
*  You know again people have different definitions there [[00:46:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2790.3s)]
*  What we're trying to protect is individual liberty freedom and agency [[00:46:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2792.38s)]
*  Education should be about enhancing the education of every child. It's not you know, health care is sick care [[00:46:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2796.84s)]
*  Our government should uplift us, but how many people believe our governments do that rather than put us down? [[00:46:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2802.62s)]
*  Because they couldn't encapsulate and cater to [[00:46:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2807.98s)]
*  the brilliance of each individual [[00:46:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2811.6600000000003s)]
*  Because they didn't have the tools until now so that's why I said which way one man [[00:46:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2815.7400000000002s)]
*  Yes, which way agency or massive control these are the two ways do we control the technology or do these [[00:46:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2819.8199999999997s)]
*  organizations control the technology that controls us [[00:47:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2827.7999999999997s)]
*  You know when we were on the stage at at the abundant summit we talked about a future of digital super intelligence, right? [[00:47:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2831.02s)]
*  and a future in which we've got [[00:47:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2838.3799999999997s)]
*  ai a billion times more capable than a human which [[00:47:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2841.8199999999997s)]
*  Looking at it just from a ratio of neurons is the ratio of a hamster to a human. Um, yep [[00:47:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2845.5s)]
*  Do you believe that someday we could have a [[00:47:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2855.26s)]
*  a benign super intelligence that is supporting humanity? [[00:47:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2860.1400000000003s)]
*  Yes, and I believe that it should be a collective intelligence [[00:47:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2865.7400000000002s)]
*  that is made up of [[00:47:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2870.6200000000003s)]
*  Amplified human intelligence is amplifying all of us [[00:47:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2872.46s)]
*  Pilots that contain our collective knowledge and culture and the best of us [[00:47:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2875.7400000000002s)]
*  And data sets that are built from helping and augmenting us [[00:48:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2880.38s)]
*  Versus a collected intelligence an agi [[00:48:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2883.58s)]
*  That is top down and designed to effectively control us again [[00:48:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2886.78s)]
*  If you look at open ai's statements on the road to a gi they say this technology will end democracy [[00:48:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2890.38s)]
*  End capitalism and maybe kill us all [[00:48:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2895.6600000000003s)]
*  I don't like that. I remember I remember seeing that you you you texted me you said read this does this [[00:48:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2898.62s)]
*  Sound the same as it does to me [[00:48:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2904.7000000000003s)]
*  Yeah [[00:48:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2906.78s)]
*  So what i'd prefer instead is for this to be distributed like if you have data sets from nations that are built on enhancing the [[00:48:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2907.1800000000003s)]
*  Capability of the nation that reflect the local cultures and you push for data transparent certain models, which I believe we must have [[00:48:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2913.1600000000003s)]
*  You know, especially language models then you're more likely to have a positive thing [[00:48:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2919.98s)]
*  And again, the human collective can achieve anything from splitting the atom to go into space if we put our minds to it [[00:48:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2923.34s)]
*  But we have lacked in coordination mechanisms [[00:48:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2930.2200000000003s)]
*  They've not been good enough [[00:48:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2934.1400000000003s)]
*  So if you create the human colossus and every single person has an ai that's just looking out for them [[00:48:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2935.82s)]
*  To enhance their potential and coordination ai's [[00:49:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2941.26s)]
*  That is a far more positive view of the future [[00:49:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2944.86s)]
*  And that is the agi [[00:49:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2947.6600000000003s)]
*  That is a general intelligence that's the hive mind general intelligence not a borg style hive mind [[00:49:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2949.34s)]
*  But one that's really thinking again every child should achieve their potential [[00:49:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2954.3s)]
*  Versus this embodied concept of an agi that's a very western concept and you see that as well like you know [[00:49:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2958.54s)]
*  We look at the japanese concept of a robot [[00:49:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2963.42s)]
*  The robot is your equal and your helper you look at the western concept of the robot. It's terminator [[00:49:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2965.82s)]
*  And skynet and all of that and again, I think this is again where cultural norms become very interesting [[00:49:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2971.5s)]
*  And what do we want to build we want to build ai god? [[00:49:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2976.46s)]
*  Or do we want to build that ai helper that helps us and we help it, you know [[00:49:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2979.58s)]
*  Um those listening now, I mean you can see [[00:49:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2985.5s)]
*  Umad's brilliance and why i'm so enamored with the way you think about this because it's [[00:49:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2989.9s)]
*  There are very few individuals who are [[00:49:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2995.7400000000002s)]
*  Looking at this from an objective function of what's best for humanity. What's best for every nation state [[00:49:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=2998.46s)]
*  Uh out there let's talk about your going forward future [[00:50:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3004.6200000000003s)]
*  um, are you going to build something in the uh in the decentralized, um, [[00:50:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3009.6600000000003s)]
*  Uh side of of ai the democratized side of ai is there a company there or a fund in your future for that? [[00:50:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3015.02s)]
*  Yes, so, uh, you know doing the white paper finally getting there with a bit of help from ai [[00:50:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3023.02s)]
*  I can't I can't I can't wait to uh to help [[00:50:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3028.46s)]
*  Uh broadcast that white paper [[00:50:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3031.26s)]
*  Yeah, but look I think the basic thing is this what I want to do is set up a ai champion in every nation [[00:50:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3033.98s)]
*  With the brightest people of each nation working with the organization of each nation to help guide them through this next period [[00:50:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3040.38s)]
*  Because there will be massive job displacement from the graduates going [[00:50:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3046.6200000000003s)]
*  Massive uplifts and productivity from the technology being implemented and again that organization can help [[00:50:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3050.5400000000004s)]
*  govern [[00:50:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3056.28s)]
*  And create these data sets and these models that are so important and every nation should have that [[00:50:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3057.34s)]
*  But then I also believe that every sector [[00:51:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3062.86s)]
*  Should have a generative ai first infrastructure company that builds this and helps the healthcare companies finance companies and others through that [[00:51:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3065.1800000000003s)]
*  And to coordinate all of that you need to have a web 3 type protocol. What is the protocol for intelligence? [[00:51:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3072.54s)]
*  So what is a web what is a web 3 type protocol define that for folks listening? [[00:51:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3078.6200000000003s)]
*  Again people talk about web 3 it's not about the tokens or the meme coins or anything like that [[00:51:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3083.34s)]
*  What about three protocol is is that everyone should have like ai's first of all aren't going to have bank accounts [[00:51:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3088.6200000000003s)]
*  They're going to need some way to pay each other or exchange value [[00:51:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3095.42s)]
*  And again web 3 is still a lot of work in that [[00:51:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3099.26s)]
*  There needs to be some sort of identity attribution and other format because you'll have this mass influx of information [[00:51:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3101.82s)]
*  And so again web 3 concepts are very useful there there needs to be an identity concept because you have real and digital people [[00:51:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3108.14s)]
*  Web 3 concepts are very useful there. So data access station all these other things [[00:51:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3116.2999999999997s)]
*  Verifiability, so when I look at it if you've got sectorally my plan is to launch almost a company for every major sector [[00:52:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3121.48s)]
*  And we can talk about health and education and bring the smartest people in the world to solve that challenge of the infrastructure for the future [[00:52:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3128.14s)]
*  Every nation but you need to have some sort of coordinating protocol for all of that that becomes a standard [[00:52:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3134.06s)]
*  And that's the substrate for this amplified human collective intelligence [[00:52:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3139.66s)]
*  And and is that where you want to play and focus your energy next? [[00:52:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3144.86s)]
*  Yeah, it's setting up these organizations and bring the brightest smartest people that really want to make a difference there [[00:52:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3149.26s)]
*  Because there's massive network effects in doing this but again, I just need to be the founder and architect [[00:52:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3155.98s)]
*  I don't want to run the day-to-day of any of these things [[00:52:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3160.86s)]
*  um and then [[00:52:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3163.74s)]
*  Because the the most scarce talent that there's three types of capital as I view it. There's financial capital [[00:52:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3165.74s)]
*  human capital and political capital [[00:52:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3171.82s)]
*  And in order to effect a change in the world, you actually need all three [[00:52:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3174.7s)]
*  but the financial capital actually comes with the people capital and the political capital [[00:52:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3177.58s)]
*  And the smartest people in the world in every sector from health care to education to finance to agriculture [[00:53:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3182.3s)]
*  Almost all believe that gentrify is the biggest thing they've ever seen in the last year [[00:53:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3189.2s)]
*  Everyone's asking you all the smartest people peter. What's next? Right? And you know many of the smartest people in the world [[00:53:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3194.4799999999996s)]
*  So I want to create organizations that they can come [[00:53:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3199.4399999999996s)]
*  The chefs and the cooks the thinkers and the doers and think what is the future of finance? What's the future of education? [[00:53:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3202.72s)]
*  and then the national [[00:53:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3208.9599999999996s)]
*  Champions that should be owned by the people of each country become the distribution [[00:53:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3210.4599999999996s)]
*  for the amazing infrastructure that they built [[00:53:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3215.04s)]
*  And there's a vice a nice kind of vice versa, but then again, you need the coordination function [[00:53:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3217.9199999999996s)]
*  So i'm trying to bring together people in each of these and you know [[00:53:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3222.3999999999996s)]
*  There'll be public calls and things like that to build that infrastructure the future because as mentioned [[00:53:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3225.4399999999996s)]
*  AI is an infrastructure, but it should be I mean, maybe it's the rocket ship of the mind, right? [[00:53:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3230.64s)]
*  I love that. I love that analogy my friend. It it is the most important infrastructure [[00:53:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3236.0s)]
*  That humanity will have going forward across everything it does [[00:54:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3240.3999999999996s)]
*  And I look forward to helping you build it [[00:54:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3244.16s)]
*  Exciting right like again, I think one of the things I got I got lots of messages. They're like i'm so sorry for your loss [[00:54:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3246.24s)]
*  It was like my dog had died [[00:54:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3252.8799999999997s)]
*  after I left to see it [[00:54:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3254.8799999999997s)]
*  I was like [[00:54:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3256.64s)]
*  What is that? You know, they're like it's nice. It's nice that people care, right? [[00:54:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3258.0s)]
*  But i'm generally excited to kind of about what's next like, you know again [[00:54:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3262.48s)]
*  It was like staring into the abyss and chewing glass every single day [[00:54:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3266.0s)]
*  And that's not what i'm best at or where I could have the most impact [[00:54:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3270.3199999999997s)]
*  But I want it to be a point whereby if I can accelerate this over the next period [[00:54:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3274.2400000000002s)]
*  I don't have to make an impact. I should not have any power [[00:54:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3278.2400000000002s)]
*  on this [[00:54:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3282.1600000000003s)]
*  Whereas again, you see everyone else trying to get more and more power [[00:54:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3283.52s)]
*  I want to make sure it's set up properly, but I want to give it all away because [[00:54:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3286.56s)]
*  power is [[00:54:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3290.1600000000003s)]
*  Obligation it's dragging and again, it should not be invested in any one individual [[00:54:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3291.82s)]
*  We should not have to rely on anyone being nice or good [[00:54:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3296.0s)]
*  For this technology [[00:55:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3300.0s)]
*  I was talking to uh, michael sailor during the abundance summit that evening and you know talking about the fact that [[00:55:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3301.2s)]
*  because satoshi [[00:55:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3308.16s)]
*  When he set it up [[00:55:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3310.08s)]
*  Did not retain any power and did not trade on the founding blocks and so forth [[00:55:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3311.84s)]
*  That that's the reason it's been able to succeed [[00:55:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3317.36s)]
*  Because there wasn't that centralized power and you know bitcoin had been trying he said bitcoin had been tried many times before but [[00:55:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3320.4s)]
*  Because it didn't have that initial anonymity and and and the dissolution of founding power that that's the reason it didn't succeed [[00:55:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3327.92s)]
*  Yeah, I mean again, I think you need to have it accelerate and you see this with movements, right? [[00:55:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3337.92s)]
*  The movement starts but then it goes once you've got the dna and the story there, right? [[00:55:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3342.16s)]
*  You know, you see the prophets you see the leaders you see the others [[00:55:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3347.92s)]
*  But then it's about setting the framework correctly and reframing the concept [[00:55:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3351.44s)]
*  This technology is not beyond look stability is a company that started two years ago above a chicken shop in london, right? [[00:55:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3355.6s)]
*  You know my first 20 employees I went to the job center and I said bring me people that have overcome adversity [[00:56:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3363.04s)]
*  And I will train them young graduates and six of them are still at stability, you know [[00:56:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3368.8s)]
*  Like because it was a program and they're doing things from cyber security to run on supercomputers. We only had like 16 17 phd's [[00:56:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3374.08s)]
*  PhDs [[00:56:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3381.68s)]
*  Yet we built the state-of-the-art models in every modality. We built mind reading models like mindsight, you know [[00:56:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3382.88s)]
*  I remember that contributed to all these things [[00:56:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3388.4s)]
*  Yet you're told it's impossible to compete. We have shown it's not impossible to compete. That's a reframing [[00:56:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3392.0s)]
*  The reframing is data versus models. It's you don't need giant supercomputers for everyone. You just need to have [[00:56:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3397.84s)]
*  A trusted entity to build it, right? [[00:56:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3404.7200000000003s)]
*  Yeah, you know and so I hope to kind of convey this and then figure out this organizational structure that can proliferate [[00:56:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3407.52s)]
*  So I can take the holiday [[00:56:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3413.52s)]
*  So before we go further, let's talk about one area of your next chapter in life that we both have as a passion [[00:56:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3415.6s)]
*  Which is the use of generative ai and health. It's an area that you've given a huge amount of thought to [[00:57:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3423.3599999999997s)]
*  And I think you're excited about it. Can you share what your vision is there? [[00:57:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3428.7999999999997s)]
*  Yep, so I got into ai 13 years ago gosh [[00:57:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3433.12s)]
*  I was a programmer before for 23 years building large-scale systems as a hedge fund manager and other things [[00:57:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3437.04s)]
*  when my son was diagnosed with autism and then I built an lp team to analyze all the clinical literature and I looked at [[00:57:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3442.3999999999996s)]
*  Biomolecular pathway analysis of neurotransmitters gathering glue to make in the brain to repurpose drugs for him and went to mace your school [[00:57:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3449.52s)]
*  Which is great n equals one and then I was one of those lead architects on the one the covet ai project [[00:57:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3455.8399999999997s)]
*  So the united nations launched stanford and others and then because I didn't get the technology. I was like, oh we got to build it ourselves [[00:57:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3461.6s)]
*  but [[00:57:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3468.64s)]
*  What is health? You know again, I think we have this discussion a lot health care is sick care [[00:57:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3469.8399999999997s)]
*  We don't have all the information that we should have at our fingertips health assumes ergodicity [[00:57:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3475.36s)]
*  A thousand tosses of the coin is same as a coin tossed a thousand times, but we are all individual [[00:58:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3480.24s)]
*  And across the world there are amazing data sets [[00:58:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3486.08s)]
*  That could be better because when you write down a clinical trial or your own [[00:58:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3489.1200000000003s)]
*  Kind of experiences you lose so much information at the same time [[00:58:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3493.6800000000003s)]
*  You don't have all the information on cancer or autism multiple sclerosis at your fingertips and the comprans are authoritative in upstate way [[00:58:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3498.32s)]
*  So when I look at the health operating system [[00:58:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3505.2000000000003s)]
*  We're going to build a gpt4 open for cancer [[00:58:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3508.32s)]
*  And it's going to mean that nobody is alone again on that journey and loses that agency because they know [[00:58:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3512.3199999999997s)]
*  comprehensive authority to upstate all the knowledge [[00:58:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3519.3399999999997s)]
*  but [[00:58:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3521.8399999999997s)]
*  AI models today already outperform human doctors and empathy. So they're not going to be alone on that anymore [[00:58:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3522.72s)]
*  Yeah, can I just double click on what you just said because it's really important [[00:58:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3528.56s)]
*  I've had so many people because of my role as chairman of fountain life who reach out and say [[00:58:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3532.0s)]
*  I just got diagnosed with this cancer or my brother or my sister or my wife [[00:58:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3537.2s)]
*  and and [[00:59:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3541.6s)]
*  There is they're left with this decimating news and they're left googling [[00:59:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3543.44s)]
*  But a model that's able to have the [[00:59:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3550.64s)]
*  Most cutting-edge information and then incorporate all their medical data and give them advice in empathic fashion [[00:59:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3554.56s)]
*  How far is that? [[00:59:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3560.96s)]
*  See a couple of years if we focus maybe even like next year and that's amazing because for all of these topics [[00:59:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3563.04s)]
*  That again, we will have diagnosis that is superior [[00:59:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3570.32s)]
*  We will have research augmentation because again even researchers don't have all that knowledge at their fingertips [[00:59:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3573.44s)]
*  And again, this is public infrastructure and a public good [[00:59:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3578.5600000000004s)]
*  You know from primary care all the way through to that. What is the open infrastructure of the future? [[00:59:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3582.2400000000002s)]
*  Where this technology can come again to your own data as well. You have [[00:59:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3587.1200000000003s)]
*  Things like melody and other things around homomorphic encryption federated learning that they're trying to figure out how to preserve privacy [[00:59:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3591.28s)]
*  We can run a language model on a smartphone right now [[00:59:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3598.4s)]
*  That can analyze all your data and then just feed back stuff to a global collective, but people are people [[01:00:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3601.92s)]
*  So when I look at health care, I see amazing data sets that we can activate by taking the models to the data [[01:00:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3607.44s)]
*  An infrastructure that we can build like we had checks agent with stanford the top x-ray radio radiology model [[01:00:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3613.2s)]
*  To build good standard things across the entire gamut of health care [[01:00:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3620.24s)]
*  So we can actually get to health care versus sick care so we can make it so that everyone is empowered [[01:00:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3624.48s)]
*  To make the best decisions either as experts or individuals and make it so nobody is alone again as well as increasing with data quality [[01:00:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3629.2000000000003s)]
*  That will then feed better models that will then save lives [[01:00:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3637.04s)]
*  Save suffering [[01:00:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3640.7200000000003s)]
*  And again increase our potential like you've got a long job. Don't you put behind you, right? [[01:00:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3642.2400000000002s)]
*  Why don't you have all the latest knowledge of longevity at your fingertips at a gpt4 level right now? [[01:00:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3646.88s)]
*  That will happen over the next year. We will launch stable health or whatever decide to call it [[01:00:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3654.08s)]
*  And there will be the smartest people in each of these areas working on that [[01:00:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3658.48s)]
*  So again, you're never like doesn't matter if you're hot if you're with 100 billion dollars and your kid has autism [[01:01:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3662.08s)]
*  asd [[01:01:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3667.2000000000003s)]
*  There's no cure. There's no treatment. There's nothing [[01:01:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3669.36s)]
*  Doesn't matter how rich you are yet with just a little bit of effort right now [[01:01:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3671.76s)]
*  We can build it as an open infrastructure for the 5% of people in the world that know someone with autism the 50% [[01:01:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3676.2400000000002s)]
*  Of people in the world [[01:01:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3682.8s)]
*  That receive a cancer diagnosis of them or someone they love [[01:01:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3684.48s)]
*  And they feel that loss of agency. So we're going to return agency to humanity that way [[01:01:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3687.92s)]
*  And again, it needs to be an open infrastructure that they can then access private data sets and compensate them appropriately [[01:01:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3692.48s)]
*  So everyone is incentivized we need that fast [[01:01:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3698.8s)]
*  Yeah, and and that's a beautiful vision. It is again infrastructure [[01:01:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3702.32s)]
*  And one of the things that's so beautiful about it is guess what all eight billion people [[01:01:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3707.36s)]
*  We're all human. We're all running the same software and the the the breakthroughs and the knowledge accumulated in [[01:01:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3712.32s)]
*  You know in kazakhstan is going to be as useful in kansas [[01:02:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3720.56s)]
*  Yeah [[01:02:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3724.32s)]
*  Yeah, but this is the thing operating system. This is the biggest upgrade to the human operating system. We can imagine [[01:02:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3725.52s)]
*  Because we're going from analog to digital text is black and white whereas this these models only understand context [[01:02:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3730.56s)]
*  You know daniel kahneman just passed, you know amazing kind of guy [[01:02:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3738.8s)]
*  But you know, he did have this concept of type one type two thinking [[01:02:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3743.28s)]
*  And so we had one which is these big data things that can only extrapolate [[01:02:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3746.96s)]
*  But now we have these models that understand context [[01:02:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3750.6400000000003s)]
*  And so we have the missing parts of the brain and that will allow us to extrapolate allows to have all rainbows [[01:02:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3753.2000000000003s)]
*  You know have the context of each individual push intelligence to the edge [[01:02:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3758.96s)]
*  And that's why again there is this imperative to do this now because there's a window on the freedom agency democracy side [[01:02:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3762.7200000000003s)]
*  but the other imperative is [[01:02:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3769.84s)]
*  No one should have to suffer as they're suffering now [[01:02:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3771.92s)]
*  Amazing and how much does actually need doesn't need that much which is the really amazing stuff [[01:02:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3775.44s)]
*  This the total amount spent in genitive a I think I said at the conference is less than [[01:03:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3780.56s)]
*  The total amount spent on the los angeles san francisco railway [[01:03:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3785.28s)]
*  Which hasn't even started yet and and in building stable health again if that's what it's called [[01:03:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3790.0s)]
*  I mean the amount of capital required to build that is de minimis [[01:03:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3795.36s)]
*  Compared to what's spent on a single human trial of any any drug [[01:03:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3799.84s)]
*  Yeah, it is but then you know you build it and you get to that 80 20 incredibly quickly that will change [[01:03:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3804.2400000000002s)]
*  Hundreds of millions of lives and that will attract the smartest people in each of these areas thinking about what is the open infrastructure? [[01:03:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3811.0400000000004s)]
*  of multiple sclerosis of longevity of cancer and more [[01:03:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3815.92s)]
*  But then you can amp that because the value is so so huge [[01:03:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3820.0s)]
*  And you I hope to build a trusted organization as part of this whole human operating system upgrade [[01:03:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3824.96s)]
*  You know, that's why I want to build I want to build human os or at least catalyze it again [[01:03:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3830.64s)]
*  I don't want to run or control or own anything [[01:03:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3834.4s)]
*  I want to figure out how to give back that control because who should decide what cancer knowledge goes in there [[01:03:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3837.2s)]
*  Who should decide what education etc? [[01:04:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3842.32s)]
*  Let's talk about the second half of your of your vision which is how we originally met [[01:04:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3845.76s)]
*  When you were one of the winners of the global learning x prize that ilan and tony [[01:04:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3851.7599999999998s)]
*  robbins had had co-funded [[01:04:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3858.16s)]
*  Your your vision around education [[01:04:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3860.56s)]
*  Speak to us about that [[01:04:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3864.24s)]
*  Yeah, you know say we're deploying it. Um kind of the winners are kind of separate but [[01:04:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3866.0s)]
*  Every child right my entire operating system is like [[01:04:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3870.7999999999997s)]
*  If you think about things in terms of the rights of trials and today they have no agency and so we must [[01:04:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3874.56s)]
*  Respect their rights climate everything becomes a lot simpler [[01:04:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3879.76s)]
*  Now that we have language models on a laptop like I said, you can go to lm studio.ai [[01:04:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3883.36s)]
*  Download stable lm [[01:04:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3888.7200000000003s)]
*  And it will run on your macbook faster than you can read [[01:04:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3890.7200000000003s)]
*  It's crazy [[01:04:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3895.04s)]
*  We can have a gpt4 level ai from us or someone else on a smartphone or a tablet by next year [[01:04:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3896.16s)]
*  One laptop per child was too early [[01:05:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3901.84s)]
*  You know now we have this transformative technology you have an ai that teaches a child learns from a child [[01:05:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3904.8s)]
*  Are you visual auditory dyslexic? That's the best data in the world for a national model, but also to teach these models how to [[01:05:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3909.76s)]
*  be [[01:05:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3917.44s)]
*  Optimistic how to this really is this really is uh, the young ladies illustrator primer [[01:05:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3918.8s)]
*  This really is neil stevenson's vision in that regard [[01:05:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3925.2000000000003s)]
*  Yeah, but nel shouldn't have had to find the primer [[01:05:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3929.04s)]
*  He should have had it from day one [[01:05:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3933.3599999999997s)]
*  as a human right [[01:05:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3935.7599999999998s)]
*  As a human right, yes [[01:05:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3937.3599999999997s)]
*  Our schools education system our child care mixed with the social status game makes the petri dish [[01:05:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3939.7599999999998s)]
*  You know, they teach our kids not to have agency [[01:05:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3945.8399999999997s)]
*  Yes, whereas they should be telling the kids. Yeah. Yeah, they should be teaching this. It's a [[01:05:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3950.0s)]
*  Relic of the industrial age where everyone had to be counted and you can't measure what you can't manage [[01:05:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3954.56s)]
*  So you manage the creativity and belief out of people [[01:05:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3959.12s)]
*  Everyone in the world can do anything [[01:06:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3963.2799999999997s)]
*  Why because even if you don't have that talent you can convince someone else who does have that talent? [[01:06:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3965.6s)]
*  But they don't believe it so they can't do it. So what happens if we have an entire nation [[01:06:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3971.52s)]
*  of children [[01:06:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3976.16s)]
*  That have this helper that brings the right information the right time and tells them they can always believe that supports them [[01:06:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3977.52s)]
*  entire world [[01:06:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3983.36s)]
*  What can't you do? [[01:06:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3985.44s)]
*  You know then they have all of the cancer knowledge at their fingertips and all of the engineering knowledge at their fingertips [[01:06:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3986.96s)]
*  And it's a constantly learning adaptive and improving system [[01:06:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3992.8s)]
*  Again right now almost the entire a gi and ai debate is about these machine gods [[01:06:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=3996.56s)]
*  Train on giant supercomputers that bestow their beneficence down or may kill us or whatever [[01:06:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4002.96s)]
*  What about that human operating system upgrades that is a decentralized intelligence where that kid in mongolia or malawi or wherever [[01:06:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4008.32s)]
*  Can make a real difference to humanity some of the contributors to our open code bases for our models are 15 years old [[01:06:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4015.04s)]
*  Yeah, they just taught themselves and just happen to be their wizards you don't know in this new age, right? [[01:07:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4022.3999999999996s)]
*  and again, they should contribute to the whole because once something goes into this model or this system [[01:07:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4027.7599999999998s)]
*  And again, it needs the verification and other things that can be dynamic. They can proliferate to everyone using that system [[01:07:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4033.2799999999997s)]
*  Do you think that once this capability is built it will run into [[01:07:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4040.08s)]
*  blocks in different nations [[01:07:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4045.92s)]
*  Or do you imagine that this will become a again a human right? [[01:07:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4048.32s)]
*  Uh, and not all I mean listen, there's no greater gift [[01:07:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4053.2s)]
*  And no greater asset you can give to a nation's populace than intelligence and education [[01:07:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4057.68s)]
*  But i'm, not sure every national leader wants to see that [[01:07:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4064.4s)]
*  And that's why I think again there is a gap here [[01:07:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4066.88s)]
*  There is a year maybe where you can go to any national leader and say [[01:07:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4069.6800000000003s)]
*  I will bring this technology to your people and I will empower the smart to do with people [[01:07:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4074.48s)]
*  I want it to be owned by the people and what option do they have? [[01:07:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4078.1600000000003s)]
*  This is positive for them. What happens is that a lot of the corruption in the world is because of local maxima [[01:08:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4081.6800000000003s)]
*  You know, actually it's weird because unpredictable corruption is the worst predictable corruption is a bit like tax [[01:08:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4087.6800000000003s)]
*  You know, there's a good book by a fusser a job move at harvard about this and then you have taxation kicking at 14 [[01:08:12](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4092.96s)]
*  If you can show them something bigger and this is clearly big they will embrace this technology and set new norms [[01:08:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4101.76s)]
*  And if you create the same across all these countries with talented individuals in each of those groups [[01:08:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4106.56s)]
*  And talented individuals in each of those sectors with a shared mission, even though they're separate organizations [[01:08:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4111.6s)]
*  That's how you set amazing standards. That's how you build a network effect [[01:08:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4117.12s)]
*  And if you tie them all together with a intelligent protocol and they go and talk about tokens or speculation or ramps or anything like that [[01:08:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4121.36s)]
*  But taking the best of thinking around coordination [[01:08:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4128.16s)]
*  That can work that can break this open [[01:08:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4131.76s)]
*  you know, um [[01:08:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4134.4800000000005s)]
*  But it's not going to be everywhere [[01:08:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4136.56s)]
*  And also when you look at the current debate the current debate is for example [[01:08:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4138.4800000000005s)]
*  We can't let china have this technology [[01:09:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4142.56s)]
*  And you're like what about the kids in china? [[01:09:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4146.08s)]
*  Right, well, you know, it's dangerous they can have a gi so under what circumstance would china ever have this technology never [[01:09:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4148.64s)]
*  You know pakistan, which they have the tech never [[01:09:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4155.36s)]
*  That's really what they're kind of saying [[01:09:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4158.4s)]
*  It's also self-defeating because china has 100 million people they can use to create data sets and two x of lots of computers [[01:09:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4159.68s)]
*  Let's put that to the side [[01:09:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4165.12s)]
*  Again, it's a very western oriented debate. Whereas actually if you go to these countries and you talk to [[01:09:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4166.64s)]
*  The leaders and the family offices that have power and the people they will leapfrog in the global south [[01:09:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4171.92s)]
*  to [[01:09:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4178.32s)]
*  Intelligence augmentation like they let prog to mobile they want to embrace this technology [[01:09:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4179.36s)]
*  And again, you can set norms now versus what's going to happen is you know, they will get a centralized solution. They'll adopt that instead [[01:09:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4184.16s)]
*  If you don't right now for hundreds of millions billions of people [[01:09:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4191.84s)]
*  That's why I think again, it's a crossroads [[01:09:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4196.64s)]
*  Um, is there anybody else working towards the solution that you know of [[01:10:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4200.4s)]
*  No in the in the large ai panel [[01:10:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4204.72s)]
*  No, certainly no one credibility and again, that's why I had to build these models, you know, and I had to kind of do this [[01:10:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4207.68s)]
*  Everyone's working on tiny parts of this but they're expecting emergence build it and somehow it will spread and again [[01:10:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4214.08s)]
*  This is why I found it fascinating the web3 community [[01:10:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4220.16s)]
*  There are good people in there and I hope to be able to unite them just like hope to unite the people in health and others [[01:10:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4222.64s)]
*  Again peter you've seen people working on tiny parts of this [[01:10:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4228.0s)]
*  But this isn't a manhattan project where we're facing an enemy [[01:10:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4231.52s)]
*  And that's the enemies ourselves, you know, but this does require [[01:10:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4235.120000000001s)]
*  This big global coordinated push and that's why I've tried to design this system [[01:10:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4238.64s)]
*  That I believe will work because it's all about the talent and it is multiplicative [[01:10:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4243.4400000000005s)]
*  Is the race against? [[01:10:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4248.080000000001s)]
*  Over really powerful centralized ai systems that achieve some version of a gi is that what we're racing against? [[01:10:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4252.160000000001s)]
*  Yeah, again, we're racing against ourselves like um [[01:10:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4259.36s)]
*  Humans can scale through stories you have organizations, you know, come and join abundance come and go to oxford come and do this [[01:11:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4263.759999999999s)]
*  But then [[01:11:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4266.32s)]
*  When we scaled through text text was a lossy information format and there's this poem by ginsberg howl about this carthaginian demon of disorder molloc that comes in [[01:11:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4268.32s)]
*  Molloc comes in through the data loss our organizations are slow dumb ai's [[01:11:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4273.92s)]
*  And they're not going to be able to do that [[01:11:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4278.639999999999s)]
*  So I believe the competition here is against those organizations consolidating too much power and creating norms that are almost impossible to break [[01:11:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4281.320000000001s)]
*  So we're mistake vegetables, be transparent about the small and 원�anate things that we are씨 [[01:11:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4285.84s)]
*  Kaneh it applies here [[01:11:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4290.08s)]
*  The second point is supply, supply and demand [[01:11:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4295.12s)]
*  And talk about ourselvesbrush has been at Monitor market and Sh zeitokay and you've listened to people being Shai here [[01:11:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4300.400000000001s)]
*  So we're talking about they listen to small and medium screams [[01:11:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4306.56s)]
*  So we're almost competing against ourselves. [[01:11:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4309.68s)]
*  And again, the question is this, do you believe in amplified human intelligence or do you [[01:11:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4312.9800000000005s)]
*  believe in artificial general intelligence? [[01:11:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4316.92s)]
*  Do you believe in collective intelligence or do you believe in collected intelligence? [[01:11:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4318.96s)]
*  Who decides? [[01:12:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4323.52s)]
*  Is this infrastructure or is this a product? [[01:12:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4325.34s)]
*  Like so it's not like a Manhattan project against, you know, the Soviets or anything [[01:12:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4328.64s)]
*  like that. [[01:12:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4335.08s)]
*  But this is require us all to come together or at least the smartest people in each of [[01:12:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4336.08s)]
*  these areas from coordination to government systems to healthcare to education with a [[01:12:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4342.4s)]
*  blank slate of how do we upgrade the human operating system? [[01:12:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4347.92s)]
*  The time is now. [[01:12:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4350.88s)]
*  It's our last chance to do it. [[01:12:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4352.3s)]
*  And I love you for it because I think you're right. [[01:12:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4354.68s)]
*  You were there when Elon beamed in on X video over Starlink and from his airplane, which [[01:12:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4358.92s)]
*  was a fun moment. [[01:12:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4367.28s)]
*  And we were talking about the rate of growth and his statement because Rick Kurzweil was [[01:12:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4369.2s)]
*  there talking about his still his prediction of AGI by 2029 and Elon saying we'll have [[01:12:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4376.36s)]
*  AGI whatever that means by next year and the intelligence of the entire human race by 2029. [[01:13:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4383.96s)]
*  So I am curious what just to close out what you think about that those timelines and that [[01:13:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4391.36s)]
*  potential for a super intelligent AI system that is centralized because that's the people [[01:13:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4400.76s)]
*  who are building that level of power are building centralized systems. [[01:13:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4408.12s)]
*  They're building centralized single systems that again take our collective intelligence [[01:13:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4412.92s)]
*  like all of YouTube in the case of open AI clearly and other things and they package [[01:13:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4417.52s)]
*  it up, sell it back to us, but they don't care. [[01:13:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4422.36s)]
*  These organizations are trying to build a system that will take away our freedom, liberty [[01:13:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4426.88s)]
*  and potentially kill us all. [[01:13:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4430.52s)]
*  Let's be quite fair about that. [[01:13:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4431.72s)]
*  And sell it to us on an incremental basis. [[01:13:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4433.76s)]
*  The selling to us is a complete canard. [[01:13:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4437.28s)]
*  They don't care about the revenue of this. [[01:13:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4439.76s)]
*  Again let's call it a spade a spade. [[01:14:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4442.76s)]
*  They are telling you that they're building something that could kill you and something [[01:14:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4444.92s)]
*  that could remove all our freedom and liberty and they're saying it's a good thing you should [[01:14:09](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4449.24s)]
*  back them because it's cool. [[01:14:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4453.7s)]
*  It's not. [[01:14:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4455.12s)]
*  It's actually shameful if you think about it and we should not stand for it anymore. [[01:14:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4456.12s)]
*  And again this is another reason I want to step aside to say yeah because you can't say [[01:14:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4459.8s)]
*  things like that. [[01:14:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4462.12s)]
*  I've got canceled Silicon Valley so many times, but realistically it's ridiculous and it should [[01:14:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4463.12s)]
*  But they're going to do it anyway because they have the political power. [[01:14:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4468.6s)]
*  People are scared of them. [[01:14:33](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4473.280000000001s)]
*  So there has to be an alternative and the alternative has to be distributed intelligence. [[01:14:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4476.0s)]
*  When I resigned I said you can't beat centralized intelligence and centralized intelligence. [[01:14:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4480.4400000000005s)]
*  You're not going to beat it with a stability. [[01:14:44](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4484.72s)]
*  The least is a great organization. [[01:14:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4486.64s)]
*  It's going to do well. [[01:14:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4487.64s)]
*  The only way that you can beat it to create the standard that represents humanity is decentralized [[01:14:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4489.1s)]
*  intelligence. [[01:14:55](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4495.240000000001s)]
*  It's collective intelligence and the data sets and norms from that will be ones that [[01:14:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4496.24s)]
*  help children, that help people suffering, that reflect our moral upstanding and the [[01:15:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4501.639999999999s)]
*  best of us and gathers the best of us to do it because if you work in health care, if [[01:15:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4507.92s)]
*  you work in education, if you work in finance, if you work in any of these things, there's [[01:15:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4513.719999999999s)]
*  no organization for you to come and join or partner with on this. [[01:15:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4517.719999999999s)]
*  There's no kind of centralized mission. [[01:15:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4522.04s)]
*  I have looked. [[01:15:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4524.2s)]
*  I've wanted to help other people. [[01:15:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4525.2s)]
*  I don't want to do this myself. [[01:15:27](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4527.16s)]
*  I don't want it to be about me very, very quickly. [[01:15:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4528.16s)]
*  I'm kind of getting out there now. [[01:15:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4529.639999999999s)]
*  I hope that I can capitalize something that then people will take forward. [[01:15:31](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4531.32s)]
*  Time is now for that because AGI, when it comes, if it comes, again, there's various [[01:15:36](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4536.12s)]
*  definitions of this. [[01:15:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4539.599999999999s)]
*  Why on earth do you need any knowledge workers? [[01:15:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4540.599999999999s)]
*  Anything that can be done via a laptop doesn't need humans. [[01:15:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4543.599999999999s)]
*  So you have concepts of UBI here. [[01:15:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4548.639999999999s)]
*  You have concept. [[01:15:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4551.36s)]
*  When AGI comes, you don't need money. [[01:15:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4552.36s)]
*  Money is a common story, is a common good. [[01:15:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4554.56s)]
*  We hid her to post-capitalist society. [[01:15:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4556.76s)]
*  I think the example I think you said was Star Trek versus Mad Max. [[01:15:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4559.360000000001s)]
*  I'm like Star Trek versus Star Wars, I think is a better one. [[01:16:04](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4564.56s)]
*  And so you've got the Sith Lords and all of that. [[01:16:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4570.96s)]
*  But again, if you kind of look at this, I don't think we need money. [[01:16:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4574.160000000001s)]
*  It's cross contextual bartering with our AI systems representing us. [[01:16:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4577.88s)]
*  You don't need money because you're told what to do. [[01:16:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4582.6s)]
*  Again, our governments, the definition of a government is the entity with monopoly on [[01:16:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4586.200000000001s)]
*  political violence and an AGI can overtake any government that they can control the people. [[01:16:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4590.4400000000005s)]
*  Because again, listen to it whispering, look at the kind of human thing. [[01:16:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4597.200000000001s)]
*  So we have this opportunity to set norms right now. [[01:16:40](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4600.0s)]
*  The way that the big labs are going to AGI is likely to kill us all. [[01:16:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4602.84s)]
*  Elon and I signed that six month pause letter because even though people like MAD, you're [[01:16:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4608.280000000001s)]
*  an accelerationist, you put all this open source AI out, you have to think about the [[01:16:51](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4611.52s)]
*  other side and who's involved in that discussion. [[01:16:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4614.84s)]
*  And again, if we built an AGI as a centralized thing, is Windows or Linux safer as infrastructure? [[01:16:57](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4617.4400000000005s)]
*  Our entire Internet infrastructure is built on open. [[01:17:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4625.56s)]
*  Open can be challenged, open can be augmented. [[01:17:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4628.96s)]
*  A monolith is likely to be crazy. [[01:17:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4631.8s)]
*  And the way that I put this is we all like both know so many geniuses. [[01:17:14](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4634.4800000000005s)]
*  You know, side effect of genius is insanity. [[01:17:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4639.8s)]
*  Honestly, we're not meant, geniuses are not mentally stable. [[01:17:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4642.16s)]
*  Why would you expect an AGI to be so? [[01:17:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4646.84s)]
*  And you're putting all your ends in one basket versus creating a complex hierarchical system [[01:17:28](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4648.96s)]
*  that is a hive mind that's intelligence that represents us all. [[01:17:34](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4654.8s)]
*  We should be working towards building that, bring it safer, it's better, it achieves all [[01:17:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4658.8s)]
*  the benefits that people are talking about. [[01:17:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4662.84s)]
*  And it's possible today. [[01:17:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4665.2s)]
*  Do you think Elon shares in this vision of a decentralized AI? [[01:17:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4666.84s)]
*  Do you think he would play in that area? [[01:17:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4669.84s)]
*  And do you think any of the national leaders that you've been speaking to would support [[01:17:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4672.0s)]
*  that kind of a vision as well? [[01:17:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4676.400000000001s)]
*  I can't speak for Elon. [[01:17:58](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4678.2s)]
*  I'll speak to him and see what he thinks. [[01:18:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4680.8s)]
*  Then I'll get back to you. [[01:18:02](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4682.4400000000005s)]
*  You know, he always says what he thinks. [[01:18:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4683.72s)]
*  But you know, he's immensely concerned. [[01:18:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4685.8s)]
*  He was one of the leaders in this area saying, originally, why Google? [[01:18:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4688.0s)]
*  You know, now why Microsoft OpenAI? [[01:18:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4691.320000000001s)]
*  Like, it can't be centralized. [[01:18:13](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4693.320000000001s)]
*  But it's difficult. [[01:18:15](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4695.04s)]
*  It's a difficult question. [[01:18:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4696.04s)]
*  How many people have a feasible solution? [[01:18:17](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4697.5199999999995s)]
*  Or have you even thought about this properly? [[01:18:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4699.08s)]
*  You and I both know just not many. [[01:18:20](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4700.96s)]
*  And that's very sad. [[01:18:22](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4702.56s)]
*  It should be everyone thinking about this. [[01:18:23](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4703.56s)]
*  On the leader side, all the leaders I've met are super happy. [[01:18:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4705.8s)]
*  You know, because they, again, leaders want power, they want control and all of this. [[01:18:29](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4709.04s)]
*  But generally, like, they want to see abundance. [[01:18:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4715.16s)]
*  They're not happy with where their countries are. [[01:18:39](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4719.96s)]
*  And embracing this technology, they know that they can leap ahead. [[01:18:41](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4721.84s)]
*  You know, they will still have a say in all of this. [[01:18:45](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4725.639999999999s)]
*  It's not like it's kicking them out or removing them. [[01:18:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4727.2s)]
*  There are still various kind of mechanisms there. [[01:18:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4730.48s)]
*  And ultimately, improving the health, education and capability of your people is not a bad thing. [[01:18:54](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4734.08s)]
*  I mean, like, obviously, I haven't talked to the completely oppressive leaders, you know. [[01:19:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4740.12s)]
*  Maybe that'll be an interesting thing. [[01:19:03](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4743.96s)]
*  But honestly, I don't want to even be talking to leaders. [[01:19:05](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4745.28s)]
*  I want to create, again, a system where the people of the country coming together with [[01:19:07](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4747.96s)]
*  the franchise system can then build this technology for the good of their people in the open [[01:19:11](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4751.76s)]
*  and not be reliant on anyone politically or any other kind of thing like that. [[01:19:16](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4756.400000000001s)]
*  So we don't need giant supercomputers for where we're going. [[01:19:19](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4759.92s)]
*  We need coordination. [[01:19:21](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4761.8s)]
*  Need a few giant supercomputers, yeah. [[01:19:24](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4764.0s)]
*  What's your timeline for putting out this white paper? [[01:19:26](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4766.8s)]
*  I'm working as hard as I can, you know, putting it together. [[01:19:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4770.0s)]
*  I've held you to this a number of times. [[01:19:32](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4772.52s)]
*  I've said, get the vision out there. [[01:19:35](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4775.52s)]
*  It's getting there. [[01:19:37](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4777.8s)]
*  We're about to go off the school to a four-hour session to dictate all the various bits and [[01:19:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4778.84s)]
*  pieces. [[01:19:42](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4782.76s)]
*  And again, it was impossible when I was a CEO of Stability. [[01:19:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4783.76s)]
*  There was always another fire. [[01:19:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4786.24s)]
*  There was always another thing. [[01:19:47](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4787.24s)]
*  I didn't have time to think, you know. [[01:19:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4788.24s)]
*  And I hope people can take that white paper and make it better. [[01:19:50](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4790.72s)]
*  I don't have all the answers. [[01:19:52](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4792.76s)]
*  I'm just trying to capitalize something, man. [[01:19:53](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4793.76s)]
*  I think after I heard you step down, I wrote you a text saying congratulations. [[01:19:56](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4796.24s)]
*  Yeah, exactly. [[01:19:59](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4799.76s)]
*  Not commiserations. [[01:20:00](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4800.76s)]
*  Time to feel unleashed. [[01:20:01](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4801.76s)]
*  Yeah. [[01:20:06](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4806.76s)]
*  Emad, thank you, my friend. [[01:20:08](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4808.72s)]
*  Thank you for sharing where you are, what led up to this, where you're going next, and [[01:20:10](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4810.84s)]
*  really pulling the gloves off on discussing the idea of centralized, closed AI systems [[01:20:18](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4818.360000000001s)]
*  and their dangers and the importance of the vision that you portrayed. [[01:20:25](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4825.0s)]
*  I'm fully supportive and fully believe that what you've laid out is probably one of the [[01:20:30](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4830.56s)]
*  most sane visions of AI in the future that I've heard. [[01:20:38](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4838.84s)]
*  I hope other people agree, you know, and they can take it forward. [[01:20:43](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4843.4400000000005s)]
*  They're the real heroes. [[01:20:46](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4846.400000000001s)]
*  Thank you. [[01:20:48](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4848.0s)]
*  Thank you, pal. [[01:20:49](https://www.youtube.com/watch?v=e1UgzSTicuY&t=4849.0s)]
