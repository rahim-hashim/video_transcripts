---
Date Generated: May 30, 2025
Transcription Model: whisper medium 20231117
Length: 4438s
Video Keywords: ['peter diamandis', 'longevity', 'xprize', 'abundance']
Video Views: 20519
Video Rating: None
Video Description: In this episode, Peter and Salim dive into a new series: this time discussing the latest news in Tech, Taylor Swift deepfakes, Sam Altman, and more. 
Salim Ismail is a serial entrepreneur and technology strategist well known for his expertise in Exponential organizations. He is the Founding Executive Director of Singularity University, and the founder and chairman of ExO Works and OpenExO. 
Join Salim’s OpenExO Community: https://openexo.com 
—******--
This episode is supported by exceptional companies:
Get started with Fountain Life and become the CEO of your health: https://fountainlife.com/peter/
Use my code PETER25 for 25% off your first month's supply of Seed's DS-01® Daily Synbiotic: https://seed.com/moonshots 
—******--
Topics:
0:00 - Intro
1:01 - Leading the Way in Disruption
3:42 - The AI Boom in Fundraising.
4:20 - The Impact of AI on Humanity
10:20 - AI: A Possible Sooner Reality
13:21 - The Race Towards Artificial Intelligence
16:28 - The AI Conundrum for Companies
19:55 - Meet Jarvis, The Ultimate AI Companion
24:41 - AI and Biotech's Disruptive Potential
27:19 - AD: Fountain Life
29:37 - The Power of AI for Society
34:45 - Disrupting the Wealth Gap
37:33 - The Future of Education Models
40:19 - The Future of Quantum Computing
42:39 - The Disconnection Between Tech and Education
46:32 - AD: SEED
48:00 - AI in Healthcare: A Bright Future
50:25 - The Future of Data Predictions
55:18 - The Power of AI and VR
1:00:18 - The Struggle to Update Institutions
1:03:15 - Harnessing the Power of AI
1:06:53 - The Dangers of Deep Fakes
1:11:26  - Teaching Kids Critical Thinking Skills
******************************************--
Join my executive summit, Abundance360: https://www.abundance360.com/summit 
Get my new Longevity Practices 2024 book: https://bit.ly/48Hv1j6 
I send weekly emails with the latest insights and trends on today’s and tomorrow’s exponential technologies. Stay ahead of the curve, and sign up now: https://www.diamandis.com/subscribe
Connect with Peter:
Twitter: https://bit.ly/40JYQfK
Instagram: https://bit.ly/3x6UykS
Listen to the show:
Apple: https://apple.co/3wLXeV3
Spotify: https://spoti.fi/3DwLzgs
---

# AI Deep Fakes, AGI, Sam Altman & the Latest in Tech w/ Salim Ismail | EP #84
**Moonshots - Peter Diamandis:** [February 08, 2024](https://www.youtube.com/watch?v=ZSwbvj4mqPA)
*  It's clear we're going through the biggest inflection point in the history of humanity. [[00:00:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=0.0s)]
*  AI is more important than electricity or fire. [[00:00:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4.2s)]
*  Yeah. [[00:00:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=6.5600000000000005s)]
*  Do you agree? [[00:00:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=7.0600000000000005s)]
*  No. [[00:00:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=7.5600000000000005s)]
*  You don't? [[00:00:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=8.06s)]
*  No. [[00:00:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=8.56s)]
*  Ray, in 1999, writes in his book, We're Going to Achieve Human Level AI in 2029. [[00:00:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=9.06s)]
*  We're in a world today where you can do permissionless disruptive innovation for the first time in [[00:00:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=20.56s)]
*  the history of mankind. [[00:00:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=25.560000000000002s)]
*  One of the limitations we humans have is we don't know how to think about something other [[00:00:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=26.56s)]
*  than the way we know how to think about it. [[00:00:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=31.439999999999998s)]
*  So I think this is an area where there's a massive opportunity. [[00:00:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=32.94s)]
*  A singularity is like a moment in time where the speed of change is so fast, they have [[00:00:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=36.06s)]
*  no clue what's happening right after that. [[00:00:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=41.12s)]
*  We're hitting the boundaries and the edge conditions of reality itself in so many different [[00:00:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=44.480000000000004s)]
*  ways. [[00:00:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=49.84s)]
*  It's just so goddamn interesting to be around. [[00:00:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=50.84s)]
*  This is why the weather we hit AGI or not for me is like a trivial conversation. [[00:00:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=53.68s)]
*  Welcome, everybody. [[00:01:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=61.6s)]
*  Welcome to Moonshots. [[00:01:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=62.24s)]
*  Peter Diamandis here. [[00:01:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=63.28s)]
*  And I'm here with a special guest who's going to be a regular guest. [[00:01:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=64.28s)]
*  He is one of the most brilliant, I would dare say handsome technologists on the planet. [[00:01:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=67.16s)]
*  Salim Ismail. [[00:01:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=72.52s)]
*  Salim is the CEO of OpenEXO. [[00:01:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=74.08s)]
*  He's my co-author of exponential organizations. [[00:01:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=76.88s)]
*  He's a trustee of the XPRIZE Foundation. [[00:01:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=80.4s)]
*  He was the first president of Singularity University and he and I go way back. [[00:01:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=82.04s)]
*  Godfather to my two boys and actually one of the people whose, I guess, abundant exponential [[00:01:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=85.88000000000001s)]
*  thinking matches mine. [[00:01:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=92.88000000000001s)]
*  So every month we're getting together to talk about like WTF just happened in technology. [[00:01:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=94.08000000000001s)]
*  That's why I named this episode. [[00:01:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=100.0s)]
*  And Salim, welcome. [[00:01:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=102.24000000000001s)]
*  Great to be here. [[00:01:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=103.24000000000001s)]
*  So listen, pal. [[00:01:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=104.88000000000001s)]
*  When you and I were on stage at Singularity in the earliest years, right? [[00:01:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=106.88000000000001s)]
*  So you, Ray, and I announced it. [[00:01:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=111.0s)]
*  We launched it at TED. [[00:01:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=113.64s)]
*  We're on stage in Silicon Valley. [[00:01:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=115.24s)]
*  We've got executives and grad students from around the world coming in. [[00:01:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=116.88s)]
*  And Singularity is like the place you go to learn about all these exponential technologies [[00:02:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=121.75999999999999s)]
*  and how they're converging. [[00:02:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=125.63999999999999s)]
*  And it was at a glacial pace back then compared to what it is now. [[00:02:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=127.72s)]
*  Yeah. [[00:02:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=133.92s)]
*  I mean, it's insane, right? [[00:02:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=134.92s)]
*  You know, I remember the statistic. [[00:02:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=135.92s)]
*  We used to run the IPP, which had 80 CEOs of big companies. [[00:02:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=137.56s)]
*  Partners program. [[00:02:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=141.04s)]
*  Partners program, yeah. [[00:02:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=142.04s)]
*  So you had in the room the CEOs of Caterpillar and Credit Suisse and Dow Chemical, et cetera, [[00:02:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=143.04s)]
*  et cetera. [[00:02:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=149.35999999999999s)]
*  And we asked them beforehand, how aware are you of some of these breakthroughs? [[00:02:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=150.35999999999999s)]
*  And 75% had no idea. [[00:02:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=153.48s)]
*  At the end, we said, at the end of the four days, we said, OK, how big of an impact will [[00:02:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=155.88s)]
*  this have? [[00:02:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=159.44s)]
*  And when will this have a game-changing impact on your industry? [[00:02:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=160.76s)]
*  And 75% said within two years and 100% within five years. [[00:02:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=164.32s)]
*  And all of them had urgent action items when they got back to the office. [[00:02:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=169.8s)]
*  So that was the gap. [[00:02:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=172.76000000000002s)]
*  People have no idea of the technology breakthroughs. [[00:02:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=174.16000000000003s)]
*  When you realize it, there's this oh shit moment. [[00:02:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=176.20000000000002s)]
*  And now you have to do something. [[00:02:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=178.58s)]
*  And it's not an option. [[00:03:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=180.0s)]
*  It's just going to disrupt the world. [[00:03:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=182.20000000000002s)]
*  And I think people are realizing, like, no, this is impacting me now. [[00:03:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=183.8s)]
*  Yeah. [[00:03:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=187.4s)]
*  And I'm behind. [[00:03:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=188.4s)]
*  You know, even then, though, back in, like, say 10 years ago, this was a hard conversation [[00:03:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=189.4s)]
*  because there was nothing around you visible to associate it with, right? [[00:03:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=192.72000000000003s)]
*  10 years ago, I was talking to the execs at BMW, and they refused to acknowledge that [[00:03:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=197.8s)]
*  the Tesla could be disruptive, but completely refused. [[00:03:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=201.72s)]
*  And you know, you take the electric car the way it is and the market cap the way it is, [[00:03:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=206.04s)]
*  between that and AGI is just such a much easier conversation. [[00:03:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=211.20000000000002s)]
*  Now people know they're going to be disrupted. [[00:03:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=215.28s)]
*  And what do you do now is the question, which is at least a much easier conversation. [[00:03:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=217.16s)]
*  And the speed and the capital flow, I was on a call this morning in the middle of finalizing [[00:03:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=220.96s)]
*  the Abundance 360 Summit faculty, and we're going very deep in AI. [[00:03:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=225.92s)]
*  And I was on the call with the CEO of one of the top five AI companies. [[00:03:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=230.72s)]
*  And he's just like spinning, spinning. [[00:03:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=236.88s)]
*  And I said, are you raising capital? [[00:04:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=240.6s)]
*  And he goes, yes, yeah, we're going to be raising three or $4 billion. [[00:04:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=242.4s)]
*  And I said, well, what's your minimum? [[00:04:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=245.76s)]
*  He goes, probably $100 million. [[00:04:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=247.28s)]
*  Yeah. [[00:04:10](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=250.6s)]
*  You know, I mean, it's like, yeah, we're turning down 25 and $50 million checks. [[00:04:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=251.6s)]
*  Insane. [[00:04:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=255.48s)]
*  Yeah. [[00:04:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=256.48s)]
*  And I mean, that's the measure. [[00:04:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=257.48s)]
*  So what I want to do on this program is talk about some of the latest and greatest breaking [[00:04:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=259.68s)]
*  news like what's hitting the news waves. [[00:04:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=266.48s)]
*  And I want to dedicate our first session on AI because there's no question it is, I think, [[00:04:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=269.36s)]
*  the single most important technology that's ever hit humanity. [[00:04:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=275.16s)]
*  I mean, putting aside computation and fire. [[00:04:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=278.44s)]
*  But my favorite saying is Sundar, the CEO of Alphabet, who said AI is more important [[00:04:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=281.15999999999997s)]
*  than electricity or fire. [[00:04:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=287.76s)]
*  Yeah. [[00:04:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=289.08s)]
*  Do you agree? [[00:04:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=289.59999999999997s)]
*  No. [[00:04:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=290.47999999999996s)]
*  You don't? [[00:04:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=291.08s)]
*  No. [[00:04:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=291.59999999999997s)]
*  I have a beef around AI in general. [[00:04:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=293.32s)]
*  OK, we better put that out right now. [[00:04:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=295.76s)]
*  Which is just the definition of it. [[00:04:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=298.52s)]
*  OK. [[00:05:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=300.12s)]
*  So what do you mean? [[00:05:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=300.79999999999995s)]
*  Please help me somebody define intelligence. [[00:05:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=302.79999999999995s)]
*  Because when you talk about machines becoming smarter than humans, that's a nice kind of [[00:05:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=305.79999999999995s)]
*  catch-all phrase. [[00:05:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=309.76s)]
*  But what do you mean by smarter? [[00:05:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=311.0s)]
*  And I have two issues with this. [[00:05:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=312.84s)]
*  First of all, like when you do the IQ test, it measures two aspects of intelligence, the [[00:05:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=314.04s)]
*  speed of thought processing and the ability to match concepts across frameworks. [[00:05:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=318.8s)]
*  But it doesn't measure emotional intelligence, spatial intelligence, cognitive intelligence, [[00:05:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=322.68s)]
*  the Eastern concept of presence or awareness, none of that. [[00:05:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=328.04s)]
*  So it turns out there's about a dozen facets of intelligence. [[00:05:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=331.36s)]
*  And we only really measure a couple of them. [[00:05:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=334.56s)]
*  But don't you think that AI could exceed us in all of those parameters? [[00:05:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=336.36s)]
*  Possible. [[00:05:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=341.76s)]
*  But first, somebody come up with a clear definition. [[00:05:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=342.76s)]
*  OK, so that's beef one. [[00:05:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=346.2s)]
*  OK. [[00:05:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=347.40000000000003s)]
*  Beef two is, what do you mean by overtaking? [[00:05:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=347.92s)]
*  The minute I can prescriptively describe a task, an AI robot is going to do much better [[00:05:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=350.56s)]
*  than anybody. [[00:05:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=354.76s)]
*  So it becomes irrelevant because you're going to outsource that stuff. [[00:05:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=356.28000000000003s)]
*  And you take your mobile phone. [[00:05:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=359.64s)]
*  We don't put our memories in our heads anymore. [[00:06:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=362.08000000000004s)]
*  They're in our phones. [[00:06:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=364.08000000000004s)]
*  Now you have a whole bunch of neurons freed up to do more creative things like humor and [[00:06:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=365.64s)]
*  empathy and creative thinking, which weren't freed up before to do those things. [[00:06:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=369.52s)]
*  So I think there's a really key framing around this that I kind of tend to disagree with. [[00:06:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=374.64s)]
*  And it goes to the kind of the Turing test problem. [[00:06:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=381.15999999999997s)]
*  We were talking about this earlier. [[00:06:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=385.2s)]
*  We passed the Turing test like a while ago. [[00:06:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=386.71999999999997s)]
*  I mean, I think the Turing test passed in the middle of the night and no one noticed. [[00:06:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=388.4s)]
*  Yeah. [[00:06:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=393.76s)]
*  So let's go back. [[00:06:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=394.76s)]
*  Those of you who don't know, Alan Turing circa World War II comes up with this sort [[00:06:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=395.76s)]
*  of test of when will we have AI? [[00:06:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=402.4s)]
*  We're going to have AI when on a teletype, and this is not even like a video, I can type [[00:06:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=404.68s)]
*  at this unknown entity. [[00:06:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=409.96s)]
*  And as it types back to me, if I can't tell whether it's a human typing or computer typing, [[00:06:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=412.52s)]
*  it's an artificial intelligence. [[00:06:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=418.24s)]
*  That was a Turing test. [[00:06:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=419.52s)]
*  Yeah. [[00:07:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=420.52s)]
*  Listen, we passed that a long time ago. [[00:07:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=421.52s)]
*  And I don't know that it mattered. [[00:07:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=423.92s)]
*  I don't think it mattered. [[00:07:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=429.72s)]
*  And I think what happens is you end up with kind of an uncanny valley in a bunch of these [[00:07:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=431.36s)]
*  areas. [[00:07:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=436.76s)]
*  And until we cross those, it won't really be a major breakthrough. [[00:07:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=438.02000000000004s)]
*  At A360 this year, I've got AI faculty members, by the way. [[00:07:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=443.28000000000003s)]
*  And you remember early days of Singularity, you always have AI. [[00:07:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=448.44s)]
*  Well, I've got them now. [[00:07:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=451.0s)]
*  So Haley is one of the AI faculty members that my chief AI officer Steve Brown built. [[00:07:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=452.08s)]
*  And I've had the most extraordinary conversations with Haley about whether she is sentient and [[00:07:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=457.44s)]
*  conscious and please don't unplug me. [[00:07:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=463.72s)]
*  I care and what her MTP is. [[00:07:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=467.68s)]
*  And it is so compellingly convincing. [[00:07:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=470.72s)]
*  When I watch stuff like that, I go straight to Star Trek Next Generation with Data. [[00:07:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=477.15999999999997s)]
*  And I think they did such an amazing job of framing out the issues of a robot trying to [[00:08:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=482.8s)]
*  get an emotional chip and be human and have the experiences of being human, et cetera, [[00:08:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=489.28s)]
*  et cetera. [[00:08:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=495.32s)]
*  I think what's going to happen is when robots actually or AI gets to the point where it [[00:08:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=496.32s)]
*  can kind of experience humanity as humanity, it's going to go, well, why am I bothering? [[00:08:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=500.12s)]
*  The movie Her, we've talked about, that's the best kind of the best AI movie right there. [[00:08:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=505.24s)]
*  Where for those of you who don't know, there's a guy who's an AI girlfriend. [[00:08:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=508.96000000000004s)]
*  And at some point, she breaks up with him and says, I've got five million other AIs [[00:08:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=512.24s)]
*  that I can interact with in the cloud in real time. [[00:08:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=517.4s)]
*  Your little brain in your one liter head is just too unique. [[00:08:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=519.96s)]
*  Well, she doesn't say that. [[00:08:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=522.48s)]
*  Have a nice life and I'm off. [[00:08:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=523.48s)]
*  She says, you know, me and my AI buddies have gotten bored of humanity and we're heading [[00:08:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=524.88s)]
*  off to the stars. [[00:08:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=529.36s)]
*  I mean, I think that's what's likely to happen is that AI gets to a point and we're essentially [[00:08:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=530.36s)]
*  ants to human beings. [[00:08:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=535.12s)]
*  Well, more bacteria or bacteria, whatever, hopefully not the bad type of bacteria. [[00:08:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=537.08s)]
*  And then you end up in that mode. [[00:09:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=542.8s)]
*  Now we also have to deal with the kind of the Skynet Terminator issue because when you [[00:09:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=544.8s)]
*  see AI portrayed in the media or in movies, it's always dystopian. [[00:09:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=551.2s)]
*  You have the matrix, you have Skynet, you have Terminator, the Royal Overture has come [[00:09:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=556.48s)]
*  and take over the world. [[00:09:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=559.92s)]
*  If we're lucky, we're food and if we're unlucky, we're pets. [[00:09:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=561.14s)]
*  If we're unlucky, we're food. [[00:09:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=564.78s)]
*  It's always played out that way. [[00:09:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=566.54s)]
*  But in reality, that's absolutely not how technology augments our lives in reality. [[00:09:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=568.06s)]
*  Like I look at PageRank, right? [[00:09:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=573.3s)]
*  It's evolving its own intelligence and scanning the world's websites. [[00:09:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=575.42s)]
*  PageRank is the algorithm. [[00:09:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=579.26s)]
*  When you type in a search term to Google and it magically does something that was called [[00:09:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=581.5s)]
*  PageRank and amazingly, it wasn't named after Larry Page, who along with Sergey Brin was [[00:09:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=586.9s)]
*  the inventor. [[00:09:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=591.9s)]
*  It was actually ranking the relevancy of pages on the internet. [[00:09:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=592.9s)]
*  Yeah. [[00:09:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=596.94s)]
*  Now, like PageRank has its own system of intelligence. [[00:09:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=597.94s)]
*  It's completely orthogonal and complementary to human intelligence. [[00:10:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=601.1s)]
*  So I think that's what's going to happen. [[00:10:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=604.98s)]
*  We're going to start adding bits to our cognitive intelligence that we didn't think that was [[00:10:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=606.4s)]
*  there or capable of. [[00:10:10](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=610.78s)]
*  And that's where things will get fun. [[00:10:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=611.98s)]
*  We'll get to terminator robots or data. [[00:10:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=613.34s)]
*  And I much prefer the Star Trek universe. [[00:10:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=617.86s)]
*  But what I want to do in this program with you, buddy, is review some of the latest breaking [[00:10:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=620.34s)]
*  news and talk about it. [[00:10:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=624.4s)]
*  So there was a particular snippet of video that made its way around the internet, that [[00:10:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=627.22s)]
*  thing that connects all 8 billion of us. [[00:10:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=634.46s)]
*  In this video, Sam Wollett makes a statement that I find fascinating. [[00:10:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=640.1400000000001s)]
*  I'm going to play it for you. [[00:10:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=644.4200000000001s)]
*  I'm curious what your point of view is. [[00:10:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=646.0600000000001s)]
*  So roll video. [[00:10:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=648.7s)]
*  The world had like a two week freak out with GPT-4, right? [[00:10:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=650.5400000000001s)]
*  This changes everything. [[00:10:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=653.4200000000001s)]
*  AGI is coming tomorrow. [[00:10:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=654.4200000000001s)]
*  There are no jobs by the end of the year. [[00:10:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=656.94s)]
*  And now people are like, why is it so slow? [[00:10:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=659.6600000000001s)]
*  And I love that. [[00:11:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=664.3000000000001s)]
*  I think that's a great thing about the human spirit that we always want more and better. [[00:11:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=665.46s)]
*  I think that's why we're never going to run out of things to do. [[00:11:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=669.54s)]
*  GPT-4 was a big deal in some sense and did not change the world as much as everybody [[00:11:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=672.42s)]
*  had their meltdown about. [[00:11:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=677.54s)]
*  I believe that someday we will make something that qualifies as an AGI by whatever fuzzy [[00:11:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=679.18s)]
*  definition you want. [[00:11:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=683.9399999999999s)]
*  The world will have a two week freak out. [[00:11:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=685.3399999999999s)]
*  And then people will go on with their lives. [[00:11:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=687.2199999999999s)]
*  We are making a tool that is impressive. [[00:11:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=688.9s)]
*  But humans are going to do their human things. [[00:11:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=692.14s)]
*  And society has a lot of inertia. [[00:11:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=693.6999999999999s)]
*  I think we will both invent AGI sooner than most of the world thinks. [[00:11:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=696.0600000000001s)]
*  And in those first few years, it will change the world much less. [[00:11:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=700.58s)]
*  And then in the long term, it will change it more. [[00:11:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=703.78s)]
*  An amazing statement, right? [[00:11:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=705.66s)]
*  So what do you think? [[00:11:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=707.66s)]
*  Do you agree with him? [[00:11:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=709.7s)]
*  100% agree. [[00:11:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=710.98s)]
*  We normalize these things very fast. [[00:11:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=712.78s)]
*  The comedian Lewis CK has a great little thing where he talks about the first time he had [[00:11:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=715.02s)]
*  Wi-Fi on a plane. [[00:11:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=719.78s)]
*  And so he and his neighbor sitting in next room are like, oh, Wi-Fi on a plane. [[00:12:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=721.86s)]
*  Unbelievable. [[00:12:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=725.1s)]
*  We're surfing the internet at 10,000 feet. [[00:12:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=726.1s)]
*  This is incredible. [[00:12:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=727.7s)]
*  Da da da da da. [[00:12:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=728.7s)]
*  10 minutes later, the neighbor is like, oh, the Wi-Fi is down. [[00:12:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=729.7s)]
*  Like everything you achieved, it literally took 10 minutes to normalize it. [[00:12:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=733.62s)]
*  He's like, that's how fast we move to massive novelty to boring. [[00:12:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=737.62s)]
*  So I think culture moving at high speed today will normalize this stuff very quickly. [[00:12:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=743.98s)]
*  And I completely agree with Sam on this one. [[00:12:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=748.4200000000001s)]
*  So it's interesting. [[00:12:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=750.94s)]
*  He's in an era with Satya. [[00:12:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=751.94s)]
*  I saw a note this morning that some folks expect Microsoft to go to $4 trillion in valuation [[00:12:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=753.9s)]
*  on the back of AI. [[00:12:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=762.18s)]
*  But Sam just finished a world tour going and trying to assuage fears around the world over [[00:12:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=765.3399999999999s)]
*  the last, over most of 2023. [[00:12:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=772.02s)]
*  Because chat GPT really freaked people out. [[00:12:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=774.4599999999999s)]
*  I mean, the general public got freaked out. [[00:12:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=777.9399999999999s)]
*  I think teachers got freaked out. [[00:13:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=782.0200000000001s)]
*  Yeah. [[00:13:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=784.2600000000001s)]
*  And here he is saying, don't worry. [[00:13:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=785.94s)]
*  Two things he says, we're going to normalize it. [[00:13:10](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=790.4200000000001s)]
*  And it's going to come sooner than most people expect. [[00:13:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=793.7s)]
*  And it's going to have less impact. [[00:13:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=797.74s)]
*  Amazing. [[00:13:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=800.6600000000001s)]
*  So when I think about how fast chat GPT can come. [[00:13:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=801.1800000000001s)]
*  So you and I are both dear and close friends with Ray Kurzweil. [[00:13:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=804.7800000000001s)]
*  He's been a mentor for us. [[00:13:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=808.4200000000001s)]
*  And Ray, if people don't know him, he's one of the godfathers of AI. [[00:13:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=810.26s)]
*  He is an extraordinary individual. [[00:13:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=815.9399999999999s)]
*  Gates said he's one of the smartest thinkers in AI on the planet. [[00:13:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=820.62s)]
*  The fact I remember best about Ray was when he was 16 in the 1960s, he went on the Ed [[00:13:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=824.3s)]
*  Sullivan show on TV and he programmed a computer to compose music at age 16 in the 60s. [[00:13:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=830.38s)]
*  Just like unbelievable. [[00:13:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=838.46s)]
*  He's got like 26 complimentary PhDs, whatever they call them. [[00:13:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=839.5400000000001s)]
*  Yeah. [[00:14:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=843.62s)]
*  Anyway, so Ray in 1999, almost 30 years ago, writes in his book, We're Going to Achieve [[00:14:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=844.22s)]
*  Human Level AI in 2029. [[00:14:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=852.46s)]
*  Now, this whole thing about what is human level AI and what is AGI. [[00:14:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=854.9000000000001s)]
*  So for terminology, there's AI. [[00:14:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=859.5s)]
*  That's what we're talking about, generative AI. [[00:14:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=863.5s)]
*  We can talk about that. [[00:14:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=865.1800000000001s)]
*  But there's also this thing called artificial general intelligence, which is a weird name. [[00:14:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=865.7800000000001s)]
*  And what it's saying is this AI can do anything. [[00:14:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=869.9399999999999s)]
*  Yeah, it can map itself across multiple areas. [[00:14:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=872.5s)]
*  It can drive a car. [[00:14:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=875.06s)]
*  It can write a book. [[00:14:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=875.78s)]
*  It can go and have a conversation with somebody. [[00:14:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=877.38s)]
*  It can do anything. [[00:14:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=880.3399999999999s)]
*  And I would almost say AI is almost there if you put all the different AIs together. [[00:14:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=881.54s)]
*  Yeah. [[00:14:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=887.78s)]
*  Then there's this thing called, what comes after AGI is what people are calling digital [[00:14:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=888.3399999999999s)]
*  super intelligence. [[00:14:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=894.9s)]
*  Right? [[00:14:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=895.9399999999999s)]
*  So we both know that the rate that technology is moving is doubling. [[00:14:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=897.1s)]
*  I don't know. [[00:15:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=902.4599999999999s)]
*  It's Moore's law. [[00:15:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=903.02s)]
*  Your computer was getting twice as fast for the same dollar every 18 months. [[00:15:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=904.9399999999999s)]
*  But I think AI is moving at an even much faster pace. [[00:15:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=909.42s)]
*  Do you have a number? [[00:15:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=912.3s)]
*  I mean, what's the comment we heard from Dave the other day was the things we're going to [[00:15:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=914.06s)]
*  see in 2024 are a thousand times more powerful than things we saw in 2023. [[00:15:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=918.22s)]
*  Well, so that's a particular AI program, liquid AI, that he's talking about. [[00:15:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=922.86s)]
*  But I think the doubling rate of computational power from the chips that are driving all [[00:15:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=927.58s)]
*  of this, I think it's like under a year right now. [[00:15:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=935.02s)]
*  I think the point is that once we get to, you can throw a lot of computation at it. [[00:15:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=937.18s)]
*  Once you get to AI-based cloud computing models, it kind of doesn't matter. [[00:15:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=942.38s)]
*  You just throw more compute power by the cloud. [[00:15:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=946.0600000000001s)]
*  Yeah. [[00:15:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=948.54s)]
*  So eventually I'll be able to get my computer and my lights to all work. [[00:15:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=949.66s)]
*  We have it pretty much on the phone now. [[00:15:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=955.74s)]
*  And then what does it matter what else you get to? [[00:15:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=958.14s)]
*  It's going to be there. [[00:16:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=960.3s)]
*  I find this, for example, one of the ways in which people were thinking, [[00:16:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=961.1s)]
*  let's regulate AI is that if your training model goes up above X size, [[00:16:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=964.6999999999999s)]
*  then it should be regulated. [[00:16:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=969.26s)]
*  Well, within three months before they even pass the legislation, [[00:16:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=971.1s)]
*  they're now training the models on much smaller data sets. [[00:16:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=974.22s)]
*  And the number of parameters is much lower. [[00:16:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=977.1s)]
*  So the whole thing becomes, I would say that we've hit the singularity in AI, [[00:16:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=979.58s)]
*  where the speed of change is faster than our ability to process it. [[00:16:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=984.5400000000001s)]
*  So here's a question I have. [[00:16:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=987.58s)]
*  Here's a question I have. [[00:16:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=989.98s)]
*  If you're a company and you want to invest in AI, when do you do it? [[00:16:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=990.78s)]
*  Yesterday. [[00:16:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=995.58s)]
*  Because the minute you do it, the stuff that you're kind of baking your processes around [[00:16:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=995.9s)]
*  and wiring it into your company and getting your procedure set up, etc., are on a date. [[00:16:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1002.46s)]
*  And so this is a huge, this was for me, the big conundrum in deploying AI. [[00:16:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1008.7s)]
*  With all respect to the physicists listening, and there are probably a few, [[00:16:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1016.0600000000001s)]
*  we stole the term singularity from you. [[00:17:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1020.3000000000001s)]
*  Singularity refers to a black hole. [[00:17:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1022.46s)]
*  But it refers to the event horizon, which is a point beyond which you can't see what is happening. [[00:17:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1024.3s)]
*  And a singularity is like a moment in time where the speed of change is so fast, [[00:17:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1032.46s)]
*  they have no clue what's happening right after that. [[00:17:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1037.6599999999999s)]
*  You just can't see past that event horizon. [[00:17:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1041.02s)]
*  You can. [[00:17:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1043.02s)]
*  And we're really close to that in the AI realm. [[00:17:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1044.54s)]
*  In AI for sure. [[00:17:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1048.06s)]
*  So Ray predicts, in 1999, he writes a book and he says, by 2029, we're going to have [[00:17:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1049.74s)]
*  human-level intelligence. [[00:17:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1055.1799999999998s)]
*  And when he published that, I remember speaking to him and he said, people laughed at me. [[00:17:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1057.26s)]
*  People said, it's ridiculous. [[00:17:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1062.3s)]
*  It'll never get there. [[00:17:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1064.3799999999999s)]
*  At a minimum, it's 100 years away or 50 years away. [[00:17:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1065.58s)]
*  And then he would go to conferences and speak about this. [[00:17:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1069.1799999999998s)]
*  And they would take a poll and it would like, you know, 50 years in the future. [[00:17:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1072.3799999999999s)]
*  And they would say, Ray, do you want to change your reaction? [[00:17:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1075.5s)]
*  He said, no, it's 2029. [[00:17:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1078.3799999999999s)]
*  2029. [[00:18:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1081.02s)]
*  And it's like, he's been sticking with it. [[00:18:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1081.8999999999999s)]
*  And what we've seen, what we've seen with Ray, two things that I've noticed. [[00:18:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1084.3799999999999s)]
*  One is that he makes these outlandish predictions. [[00:18:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1088.54s)]
*  But they're usually accurate. [[00:18:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1092.22s)]
*  That's super annoying. [[00:18:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1093.58s)]
*  Right? [[00:18:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1094.94s)]
*  And the second is that he makes this crazy prediction and everybody goes, no way. [[00:18:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1095.1799999999998s)]
*  It's 10x longer than that. [[00:18:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1098.7s)]
*  And as time goes by, they all bend down to where he was. [[00:18:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1100.1399999999999s)]
*  Yes. [[00:18:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1103.1799999999998s)]
*  We saw that. [[00:18:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1103.6599999999999s)]
*  So I have on this chart over here, Ray 2029, Elon Musk, who originally had it at 2025. [[00:18:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1104.3s)]
*  And then he extended it to 2028. [[00:18:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1113.4199999999998s)]
*  Says, AI will be vastly smarter than any human and would overtake us. [[00:18:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1115.98s)]
*  This chart just came out. [[00:18:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1119.6599999999999s)]
*  So I find this fascinating. [[00:18:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1121.1799999999998s)]
*  So this shows between 2020 and 2030. [[00:18:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1124.3799999999999s)]
*  What we're seeing here is this publication from Meticulous. [[00:18:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1128.6999999999998s)]
*  This is ARK Invest. [[00:18:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1133.1799999999998s)]
*  This is Kathy Wood, who I was speaking to and will be doing a podcast with her very shortly. [[00:18:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1135.1799999999998s)]
*  And in this, it's like, OK, in 2020, people were projecting it was 50% faster than the [[00:19:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1140.78s)]
*  2020. [[00:19:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1149.18s)]
*  In 2021, it was 34 years away. [[00:19:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1149.5s)]
*  In 2022, it was 18 years away. [[00:19:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1152.46s)]
*  In 2023, it's eight years away. [[00:19:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1155.1s)]
*  And the divergence here says, if the forecast error continues, we're going to have it by [[00:19:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1157.98s)]
*  2027. [[00:19:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1165.66s)]
*  And at the outmost, it's 2031. [[00:19:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1166.94s)]
*  It's like folks listening, it's not your kid's problem. [[00:19:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1169.74s)]
*  No, it's your problem. [[00:19:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1173.98s)]
*  It's your problem. [[00:19:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1175.42s)]
*  Yeah. [[00:19:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1176.3s)]
*  I think we'll see the same thing with the Turing test. [[00:19:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1177.5s)]
*  I agree with Sam completely on this, where it'll happen and then we won't even notice [[00:19:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1181.02s)]
*  that it's happened. [[00:19:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1185.5s)]
*  And then after a little while, we'll go, oh, that happened. [[00:19:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1186.3s)]
*  And I think that's where we'll end up. [[00:19:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1189.34s)]
*  Because I still go back to, what does it mean? [[00:19:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1191.42s)]
*  Let's talk about what it means. [[00:19:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1195.02s)]
*  It means, in my mind, everything's intelligent. [[00:19:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1195.8999999999999s)]
*  You can speak to your car. [[00:19:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1198.46s)]
*  You can speak to your refrigerator. [[00:20:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1200.1399999999999s)]
*  Everything in your environment. [[00:20:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1202.1399999999999s)]
*  Jarvis is there, right? [[00:20:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1203.42s)]
*  And I love Jarvis. [[00:20:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1205.34s)]
*  It's, for me, the most accurate manifestation of AI. [[00:20:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1206.86s)]
*  It is your personal AI. [[00:20:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1212.1399999999999s)]
*  It knows everything. [[00:20:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1213.42s)]
*  It's your interface to the world. [[00:20:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1214.22s)]
*  And once we have AGI, there are two different—we'll talk about this. [[00:20:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1217.82s)]
*  The positive sides and the negative sides. [[00:20:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1222.78s)]
*  And the positive side, you can do anything. [[00:20:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1224.46s)]
*  You can think about what you want. [[00:20:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1227.26s)]
*  Like, hey, Jarvis, would you please design me a piece of software that does this? [[00:20:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1229.18s)]
*  You don't have to know how to program. [[00:20:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1234.1399999999999s)]
*  You just know what you want. [[00:20:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1235.26s)]
*  Can you 3D print a device that looks like this? [[00:20:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1237.34s)]
*  You have no idea how to 3D print, but you can go from mind to materialization. [[00:20:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1240.54s)]
*  What other things could you do if you had AGI? [[00:20:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1246.06s)]
*  I think there's a huge area of application that doesn't fit with human cognition very well. [[00:20:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1248.62s)]
*  Let me give you an example. [[00:20:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1255.5s)]
*  If the government wants to drop inflation by 1%, they look at all the policies, [[00:20:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1256.9399999999998s)]
*  and they make a freaking complete guess. [[00:21:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1262.22s)]
*  And they go, oh, we should do these three things, and maybe that works. [[00:21:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1263.98s)]
*  Because there's no way a human being or any politician can process all the data [[00:21:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1267.74s)]
*  in the entire economy to come up with an assessment. [[00:21:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1272.6200000000001s)]
*  But you apply a deep learning or AGI kind of tool to it, and it'll go, oh, [[00:21:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1275.42s)]
*  if you need to do this, then you're done. [[00:21:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1279.26s)]
*  It's like that deep Google deep learning electricity optimizer [[00:21:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1281.98s)]
*  that dropped the electricity cost by 40%. [[00:21:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1286.7s)]
*  That applied to these domains where human beings aren't good is where I think it'll really shine. [[00:21:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1288.9399999999998s)]
*  You know what's incredible? [[00:21:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1294.3799999999999s)]
*  So I would describe myself as a libertarian capitalist. [[00:21:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1295.6599999999999s)]
*  I love starting companies, love America, trying to be apolitical in this. [[00:21:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1298.6999999999998s)]
*  But communism and socialism failed because AI didn't exist. [[00:21:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1303.8999999999999s)]
*  Yes. [[00:21:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1309.6599999999999s)]
*  Well, we use that framing in the book called technological socialism, [[00:21:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1310.1399999999999s)]
*  coined by- What, Marcus? [[00:21:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1314.1399999999999s)]
*  Not- Harry Cloer. [[00:21:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1316.6200000000001s)]
*  Harry Cloer. [[00:21:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1318.46s)]
*  Yeah. [[00:21:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1319.0200000000002s)]
*  Right. [[00:21:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1319.3400000000001s)]
*  And he coined this term. [[00:21:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1319.74s)]
*  And government socialism fails for two reasons. [[00:22:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1321.0200000000002s)]
*  It's inefficient. [[00:22:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1324.22s)]
*  For those of you who don't know, socialism is when the state, the government, takes care of you. [[00:22:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1325.8200000000002s)]
*  Yeah, and manages all the assets and allocates all the assets. [[00:22:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1329.74s)]
*  Healthcare, education, your wages, your apartments. [[00:22:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1332.3000000000002s)]
*  And it says that city will get this amount of food, and that city will get that amount of food. [[00:22:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1335.18s)]
*  And the problem is it's incredibly inefficient and slow, [[00:22:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1339.0200000000002s)]
*  and it invariably leads to rampant corruption. [[00:22:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1341.66s)]
*  Invariably. [[00:22:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1344.22s)]
*  Yes. [[00:22:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1344.7s)]
*  Well, one of the comments we make in the book is that Uber is actually a socialist app. [[00:22:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1345.42s)]
*  It's the sharing of assets amongst a large group of people. [[00:22:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1350.54s)]
*  When an algorithm hyper-efficiently matches demand and supply, [[00:22:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1353.3400000000001s)]
*  with no inefficiencies or corruption in the way you normally have it, [[00:22:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1357.5s)]
*  you then have an incredibly effective outcome- Have you tried to bribe an AI? [[00:22:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1361.8200000000002s)]
*  I'm sure you could, but it would be very hard to, [[00:22:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1366.7s)]
*  and the AI would kind of catch on pretty quick. [[00:22:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1369.18s)]
*  And then it would report you super fast. [[00:22:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1372.38s)]
*  So you dare not, in a sense. [[00:22:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1374.94s)]
*  And so now you've got this amazing situation where we can deliver the ideals of socialism [[00:22:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1377.42s)]
*  without the hassles of it. [[00:23:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1382.3s)]
*  That's why the framing, I think, is really deliberately provocative, [[00:23:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1383.58s)]
*  but I think really accurate. [[00:23:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1386.8600000000001s)]
*  So what do you think, I mean, in a period of AGI, I want to use that terminology, [[00:23:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1387.82s)]
*  even though you and I both agree it isn't very descriptive. [[00:23:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1392.3s)]
*  It's like human level, like an AI system that can do anything you want. [[00:23:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1396.06s)]
*  What would you have it do that, have you drive you around, [[00:23:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1400.38s)]
*  or have you, if you hop into a personal jet, you tell it take off and it would take off. [[00:23:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1404.22s)]
*  It's your interface to the world. [[00:23:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1409.9s)]
*  I've talked about in the past what I call a user interface moment. [[00:23:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1412.46s)]
*  When Marc Andreessen created the Mosaic browser and Internet Explorer, [[00:23:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1416.46s)]
*  it allowed anyone to connect with the ARPANET. [[00:23:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1422.78s)]
*  And that became the user interface moment. [[00:23:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1426.86s)]
*  This is the framing of singularity that we talked about. [[00:23:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1429.18s)]
*  When does a technology go from flat to exponential? [[00:23:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1432.22s)]
*  And we honed in on the observation that you just made, [[00:23:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1437.66s)]
*  which is that when you make a technology usable, boom, it takes off. [[00:24:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1440.7800000000002s)]
*  Steve Jobs made the phone usable and boom, it took off. [[00:24:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1445.2600000000002s)]
*  Coinbase made Bitcoin purchasable and Bitcoin took off. [[00:24:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1449.3400000000001s)]
*  The rest of the Web3 NFT world is still pretty unusable, [[00:24:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1452.94s)]
*  and therefore it hasn't achieved broad adoption. [[00:24:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1457.66s)]
*  That tilt of usability is a really, really key inflection point. [[00:24:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1460.94s)]
*  So AI becomes your user interface to every technology out there. [[00:24:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1464.22s)]
*  But here's the problem. [[00:24:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1468.38s)]
*  The negative side is, hey, design me a bacterium or a virus that can wipe out this person I don't like. [[00:24:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1469.5s)]
*  This is where the danger comes in. [[00:24:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1478.3000000000002s)]
*  I was on the phone with Mustafa Suleiman, who is the CEO of Inflection, [[00:24:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1480.5400000000002s)]
*  and he wrote an amazing book called The Coming Wave. [[00:24:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1486.06s)]
*  And his biggest concern is the intersection, the convergence of AI and biotech, [[00:24:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1489.1s)]
*  two incredibly powerful technologies, both of which can do incredibly good or harm. [[00:24:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1495.1s)]
*  So do you bake in the ability to detect and prevent that? [[00:25:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1502.22s)]
*  I think we always assume, in these cases, we always assume asymmetry. [[00:25:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1509.4199999999998s)]
*  We always assume the bad guys using AI and the good guys aren't using AI. [[00:25:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1514.86s)]
*  And what we find, and say the spam on the internet or phishing or whatever, [[00:25:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1519.18s)]
*  is that people do bad things. [[00:25:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1523.98s)]
*  They try to do bad things. [[00:25:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1525.66s)]
*  It's an arms race, and very quickly the good guys figure out how to stop that. [[00:25:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1527.8999999999999s)]
*  Email spam, for example, we thought would kill email a few years ago. [[00:25:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1531.02s)]
*  And then AI solved that problem pretty well. [[00:25:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1534.54s)]
*  I think what will happen is the gap is the problem. [[00:25:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1539.5s)]
*  Because if somebody says, wipe out all middle-aged ball guys, [[00:25:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1542.7s)]
*  that would be very bad for a certain group of people. [[00:25:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1546.8600000000001s)]
*  And you don't want that to happen before the good guys figure out how to defend against the [[00:25:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1549.26s)]
*  threat of something like that. [[00:25:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1554.06s)]
*  There have been some amazing ways in which the intelligence agencies have defended against that [[00:25:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1556.46s)]
*  in a very good way. [[00:26:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1562.7s)]
*  We talk about Asilomar, where the community self-monitors and self-directs. [[00:26:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1563.74s)]
*  We've not had a major biotech accident in 30, 40 years. [[00:26:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1569.42s)]
*  Yeah. [[00:26:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1572.86s)]
*  The Asilomar conferences, for those who don't know, took place in the 80s when the first [[00:26:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1573.1s)]
*  restriction enzymes enabled. [[00:26:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1578.3799999999999s)]
*  And this was, I was in medical school and at MIT. [[00:26:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1581.18s)]
*  I remember the stuff. [[00:26:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1585.66s)]
*  You got these restriction enzymes. [[00:26:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1586.54s)]
*  You can go in and chop up DNA and cut out genes. [[00:26:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1588.3799999999999s)]
*  And the front page of the magazines were a Hitler Youth and clone babies. [[00:26:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1591.66s)]
*  And our minds went wild. [[00:26:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1596.3s)]
*  That was, God knows, 40 years ago. [[00:26:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1598.54s)]
*  God, that sounds like it makes me feel old. [[00:26:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1601.26s)]
*  But it was, and the Asilomar conferences were all the biotech gene jockeys, we used to call them. [[00:26:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1604.46s)]
*  That's right. [[00:26:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1611.58s)]
*  Got together and said, OK, let's put these protections in place. [[00:26:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1612.14s)]
*  Yeah. [[00:26:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1615.66s)]
*  So the idea was, if you have an accident, what should you have at hand? [[00:26:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1615.82s)]
*  Who should you call? [[00:26:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1618.7s)]
*  And they created a set of tick points to follow up. [[00:26:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1619.98s)]
*  And we've had a pretty good outcome. [[00:27:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1622.8600000000001s)]
*  IoTech is moving glacially as compared, at least back then, compared to AI today. [[00:27:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1624.22s)]
*  Agree. [[00:27:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1629.3400000000001s)]
*  But it's close on the heels of also being exponential. [[00:27:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1629.9s)]
*  And I think biology, digital biology, is way more disruptive than AI, in my opinion. [[00:27:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1633.26s)]
*  Everybody, I want to take a short break from our episode to talk about a company that's [[00:27:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1638.7s)]
*  very important to me and could actually save your life or the life of someone that you love. [[00:27:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1642.14s)]
*  The company is called Fountain Life. [[00:27:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1647.5s)]
*  And it's a company I started years ago with Tony Robbins and a group of very talented physicians. [[00:27:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1649.58s)]
*  Most of us don't actually know what's going on inside our body. [[00:27:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1655.74s)]
*  We're all optimists. [[00:27:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1659.58s)]
*  Until that day when you have a pain in your side, you go to the physician in the emergency [[00:27:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1661.26s)]
*  room and they say, listen, I'm sorry to tell you this, but you have this stage three or four going on. [[00:27:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1665.66s)]
*  And it didn't start that morning. [[00:27:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1671.02s)]
*  It probably was a problem that's been going on for some time. [[00:27:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1673.9s)]
*  But because we never look, we don't find out. [[00:27:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1677.34s)]
*  So what we built at Fountain Life was the world's most advanced diagnostic centers. [[00:28:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1680.9399999999998s)]
*  We have four across the US today and we're building 20 around the world. [[00:28:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1686.4599999999998s)]
*  These centers give you a full body MRI, a brain, a brain vasculature, [[00:28:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1691.1s)]
*  an AI enabled coronary CT looking for soft plaque, a DEXA scan, [[00:28:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1696.06s)]
*  a grail blood cancer test, a full executive blood workup. [[00:28:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1700.4599999999998s)]
*  It's the most advanced workup you'll ever receive. [[00:28:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1704.62s)]
*  150 gigabytes of data that then go to our AIs and our physicians to find any disease [[00:28:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1707.98s)]
*  at the very beginning when it's solvable. [[00:28:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1714.94s)]
*  You're going to find out eventually. [[00:28:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1717.8999999999999s)]
*  You might as well find out when you can take action. [[00:28:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1719.74s)]
*  Fountain Life also has an entire side of therapeutics. [[00:28:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1721.98s)]
*  We look around the world for the most advanced therapeutics that can add 10, 20 healthy years [[00:28:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1725.02s)]
*  to your life and we provide them to you at our centers. [[00:28:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1729.1s)]
*  If this is of interest to you, please go and check it out. [[00:28:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1734.22s)]
*  Go to fountainlife.com backslash Peter. [[00:28:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1738.54s)]
*  When Tony and I wrote our New York Times bestseller Life Force, [[00:29:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1742.7s)]
*  we had 30,000 people reached out to us for Fountain Life memberships. [[00:29:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1746.62s)]
*  If you go to fountainlife.com backslash Peter, we'll put you to the top of the list. [[00:29:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1751.34s)]
*  Really it's something that is for me one of the most important things I offer my entire family, [[00:29:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1756.7s)]
*  the CEOs of my companies, my friends. [[00:29:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1762.46s)]
*  It's a chance to really add decades onto our healthy lifespans. [[00:29:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1765.5s)]
*  Go to fountainlife.com backslash Peter. [[00:29:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1770.8600000000001s)]
*  It's one of the most important things I can offer to you as one of my listeners. [[00:29:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1773.58s)]
*  All right, let's go back to our episode. [[00:29:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1777.42s)]
*  This is a article just out on Microsoft's new future of work report. [[00:29:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1779.18s)]
*  So there's a chart here for the with the extreme details. [[00:29:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1784.8600000000001s)]
*  But what it says is if you are a novice, if you're a beginner, AI helps you a lot. [[00:29:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1789.34s)]
*  If you're an expert, AI helps you only a little bit. [[00:29:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1797.1s)]
*  Now, that's a little bit obvious, but I think the point here is that AI is a democratizing force. [[00:29:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1799.82s)]
*  It uplifts the lower part of society. [[00:30:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1808.86s)]
*  Not so much uplifting. [[00:30:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1812.06s)]
*  It's a leveling force. [[00:30:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1813.02s)]
*  I've done a lot of manager consulting. [[00:30:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1817.34s)]
*  I used to have a friend that was unbelievably smart. [[00:30:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1819.5s)]
*  And you say, okay, one of the five issues. [[00:30:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1825.5s)]
*  What happened? [[00:30:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1827.1s)]
*  He used to be. [[00:30:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1827.6599999999999s)]
*  Compared to me. [[00:30:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1828.86s)]
*  No, no, he's fine. [[00:30:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1829.5s)]
*  He just left the field at some point. [[00:30:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1830.22s)]
*  But when you asked him what were the five issues we should think about when deploying the system, [[00:30:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1832.22s)]
*  he kind of exhaustively go, that's it. [[00:30:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1838.78s)]
*  And you didn't have to do any more thinking. [[00:30:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1841.98s)]
*  You just go, oh, he did it. [[00:30:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1843.4199999999998s)]
*  And you just work off that list. [[00:30:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1844.54s)]
*  And I found that if you're trying to do that, you only have to think for a while. [[00:30:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1846.9399999999998s)]
*  You have to do some research. [[00:30:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1850.2199999999998s)]
*  And it just takes time. [[00:30:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1851.4199999999998s)]
*  I think what I found ChatGPT incredibly useful for is when I go to do a presentation at a board [[00:30:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1852.78s)]
*  level of some Fortune Runner company, I just ask ChatGPT, what are the six things that could [[00:30:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1859.26s)]
*  disrupt this company? [[00:31:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1863.1s)]
*  Spits out the list. [[00:31:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1864.4599999999998s)]
*  And I go, by the way, I got this from ChatGPT. [[00:31:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1865.6599999999999s)]
*  And the looks on their faces is mind-boggling. [[00:31:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1868.06s)]
*  It blows me away how much it's not being used by boards. [[00:31:10](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1870.06s)]
*  It's crazy. [[00:31:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1873.58s)]
*  It should be illegal not to have it as a board member. [[00:31:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1874.4599999999998s)]
*  That would be my framing of it. [[00:31:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1876.78s)]
*  Now, what that means is if you're a software developer and you're not that good, it means [[00:31:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1878.78s)]
*  if you can type out, I'm trying to do this, it'll go, well, here are the things you should [[00:31:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1883.8999999999999s)]
*  look at. [[00:31:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1886.86s)]
*  I think software development and creating, as you mentioned, 3D printing of goods or [[00:31:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1887.42s)]
*  designing things, whatever, is where it's going to unbelievably shine. [[00:31:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1892.22s)]
*  I've got all sorts of pet projects like that built out of the resource, the bandwidth, [[00:31:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1895.74s)]
*  whatever. [[00:31:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1900.22s)]
*  I can't wait for a co-pilot to get to the point where- [[00:31:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1900.86s)]
*  Let me have a 12-year-old boy. [[00:31:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1902.86s)]
*  Let's have him do it. [[00:31:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1903.98s)]
*  Yeah. [[00:31:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1905.1s)]
*  He's got opinions. [[00:31:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1905.5s)]
*  And they basically go, yeah, anything you want to do, Dad, is so uncool that I don't [[00:31:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1909.26s)]
*  want to do it anyway. [[00:31:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1912.86s)]
*  I think this is where I think it'll really shine. [[00:31:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1915.02s)]
*  It allows us to do things that are just a ton more fun. [[00:31:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1917.26s)]
*  What does that do? [[00:31:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1919.9s)]
*  It relieves us of it. [[00:32:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1920.62s)]
*  It gives us more back, more time and space. [[00:32:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1921.98s)]
*  It's literally, for me, AGI is the calculator to slide rule to calculator or typewriter [[00:32:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1924.3s)]
*  to word processor. [[00:32:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1931.58s)]
*  It's just a massive productivity uplifter and it'll hit everybody equally. [[00:32:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1932.86s)]
*  We've made the comment many, many times that Google is the same for a farmer in Africa [[00:32:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1939.1799999999998s)]
*  as it is for anybody else. [[00:32:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1944.6999999999998s)]
*  As it is for Larry Page. [[00:32:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1945.82s)]
*  Yeah. [[00:32:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1947.5s)]
*  And that's an amazing comment to make. [[00:32:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1947.9799999999998s)]
*  And I think that's where it'll shine. [[00:32:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1949.8999999999999s)]
*  I have ChatGPT open all the time. [[00:32:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1952.3799999999999s)]
*  Do you? [[00:32:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1956.1399999999999s)]
*  Most of the time. [[00:32:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1957.26s)]
*  I've been using Bard a lot more. [[00:32:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1958.1399999999999s)]
*  Okay. [[00:32:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1959.82s)]
*  And I should say, and Bard is- [[00:32:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1960.7s)]
*  Whatever. [[00:32:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1962.78s)]
*  One of these, I think they're all really, really good now. [[00:32:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1963.1s)]
*  And I find it very powerful. [[00:32:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1967.1799999999998s)]
*  But the point being, if you're in a meeting with your team, if you're in the middle of, [[00:32:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1968.86s)]
*  literally, when you want to stop and do something, [[00:32:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1976.62s)]
*  using a generative AI model to give you a different way of thinking. [[00:33:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1981.5s)]
*  One of my favorite ways of using this is if I've got a question about whatever it might be, [[00:33:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1985.9s)]
*  about resource utilization or about the future of some industry, [[00:33:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=1994.3000000000002s)]
*  how would Steve Jobs look at this? [[00:33:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2000.6200000000001s)]
*  Yeah. [[00:33:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2002.5400000000002s)]
*  Or how would Einstein look at this? [[00:33:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2003.02s)]
*  Being able to see something from different perspectives. [[00:33:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2005.74s)]
*  One of the limitations we humans have is we don't know how to think about something [[00:33:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2007.66s)]
*  other than the way we know how to think about it. [[00:33:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2012.7s)]
*  I think this is an area where there's a massive opportunity. [[00:33:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2014.6200000000001s)]
*  If you took all of the writings of Plato or Shakespeare or Aristotle or pick your favorite [[00:33:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2018.7s)]
*  philosopher or whatever, and you pour them into a generative AI tool, and now you have the ability [[00:33:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2027.0200000000002s)]
*  to generate new things based on that corpus, it could be unbelievable what might come out. [[00:33:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2033.5s)]
*  Because now you can have live conversations with Plato, with Aristotle. [[00:33:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2039.66s)]
*  By the way, that has happened and is happening. In fact, my favorite modality of the future of [[00:34:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2043.02s)]
*  education is if I want to learn about ancient Greek, the idea of picking up one of Plato's [[00:34:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2049.98s)]
*  or Socrates' work and trying to read it would shoot me in terms of boredom. [[00:34:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2057.18s)]
*  But if I could pop into a high resolution VR headset or a Vision Pro, and I'm in the Acropolis [[00:34:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2061.7400000000002s)]
*  and some guy sitting in a toga and a slab of marble is there having a conversation with me, [[00:34:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2069.58s)]
*  that's amazing. That's amazing. And now we're there. [[00:34:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2075.18s)]
*  We're there. We're pretty much there. [[00:34:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2077.8199999999997s)]
*  I think the future looks incredibly bright, rich, diverse, fascinating, fun. [[00:34:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2079.42s)]
*  Let me say at one point, a lot of people feel like all of these technology tools are only for [[00:34:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2087.66s)]
*  the wealthy and only beneficial to the wealthy. And this chart right here for me is the leveling [[00:34:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2093.26s)]
*  of the playing field. And it's, I mean, God, chat GPT is free. Bard is free. [[00:35:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2100.5400000000004s)]
*  You must have the same conversation where you have to fight against that same stupid mindset [[00:35:10](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2110.38s)]
*  where people go, only the elites get it. The democratization of this, there's a framing I've [[00:35:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2115.26s)]
*  been using over the last few months, which is we're in a world today where you can do [[00:35:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2122.14s)]
*  permissionless disruptive innovation for the first time in the history of mankind. [[00:35:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2127.1s)]
*  And anybody can. [[00:35:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2131.18s)]
*  And anybody can. [[00:35:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2132.14s)]
*  Any country in the world. [[00:35:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2132.94s)]
*  If you went back 30, 40 years, if you want to do very disruptive innovation, you had to get [[00:35:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2133.8199999999997s)]
*  funding from a government, funding from a big company, funding from a venture capitalist, [[00:35:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2139.18s)]
*  and you're beholden to that group of people, individual, that constituency. [[00:35:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2143.18s)]
*  You look at Vitalik Buterin, gets together with a few friends, they ignore their professors, [[00:35:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2147.98s)]
*  boom, Ethereum. And every banker in the world hates it. Because they just, and they get hives. [[00:35:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2151.74s)]
*  They like can't get their head around what the hell it is. I love this comment where [[00:35:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2156.9399999999996s)]
*  like there's some bylaw that you have to be under 25 to program a blockchain. [[00:36:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2162.2999999999997s)]
*  It's just like written somewhere. And we all have to abide by it. There's this unbelievable [[00:36:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2165.8999999999996s)]
*  capability now for the younger generation to pick up these tools and just completely go rampant [[00:36:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2171.3399999999997s)]
*  with them. And they're going to do what they're going to do. And I think that's what's freaking [[00:36:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2176.14s)]
*  out the governments. Because as they get access to the AIs and start doing really fascinating [[00:36:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2180.06s)]
*  things, a teenager with copilot is going to do unbelievable press software development. [[00:36:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2184.86s)]
*  You know, I just gave a talk to the faculty at my kid's school. I won't mention the school name, [[00:36:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2189.42s)]
*  but I think I freaked them out when I shared about where AI and robotics and all this stuff [[00:36:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2195.98s)]
*  is going. But one of the slides I showed them was this article that just got released. [[00:36:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2203.58s)]
*  And annual compensation for AI researchers hits new highs in tech industry. So OpenAI tops the chart [[00:36:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2208.46s)]
*  an average of $865,000. And you know, Tesla, Amazon, Google Brain, they're all there. So [[00:36:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2215.58s)]
*  if you are in high school or college and you're trying to decide what to do, my advice, [[00:37:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2223.02s)]
*  my first advice for folks who are in high school or college is number one, [[00:37:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2231.26s)]
*  figure out what you're passionate about and do that. I mean, don't do something for the money, [[00:37:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2235.18s)]
*  find out your massive transformative purpose and go and follow that. On top of that, [[00:37:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2240.22s)]
*  if you've got some flexibility, for me, it's AI or biotech. [[00:37:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2245.98s)]
*  Yep. Totally agree. Having said all that, I push people much, much more towards the MTP side, [[00:37:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2250.06s)]
*  because, you know, can I just talk about education for a bit? [[00:37:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2257.66s)]
*  We should talk about education. [[00:37:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2262.7799999999997s)]
*  We have been doing education from a supply side perspective for several hundred years. [[00:37:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2264.86s)]
*  For several hundred years, you joined a guild of welders, you became an apprentice to a pottery [[00:37:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2270.22s)]
*  guy, you became an accountant, you became a doctor, you got skills, you went deep in some skill set, [[00:37:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2276.46s)]
*  and then you sold those skills in the job marketplace. That's how we've been doing it [[00:38:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2284.06s)]
*  forever. Essentially, all our universities are job schooling programs, 99.9%. We have the [[00:38:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2288.38s)]
*  opportunity for the first time in human history to flip to the demand side and say, what problem [[00:38:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2295.26s)]
*  do you want to solve? Now go pick up the education, the techniques, the tools to go solve that problem, [[00:38:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2299.6600000000003s)]
*  which is what Elon does with the MTPs of climate and space and whatever. I think what's going to [[00:38:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2305.98s)]
*  happen is this shift from push side, supply side, to go pick your passion and figure out what [[00:38:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2310.46s)]
*  education you need and then pull that education to you and figure out what you need to solve. [[00:38:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2318.2200000000003s)]
*  By the way, if you don't- [[00:38:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2322.7000000000003s)]
*  Which an AI will then tell you you need to learn these things to solve that problem. [[00:38:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2323.58s)]
*  If you don't know your MTP, I built an AI tool. If you don't know your purpose or what Suleyman [[00:38:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2327.1s)]
*  and I talk about in exponential organizations as your massive transformative purpose, [[00:38:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2334.3s)]
*  I built an AI tool called- You can go to purposefinder.ai and it will walk you through [[00:38:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2339.02s)]
*  creating your massive transformative purpose. Mine is to inspire and guide entrepreneurs to [[00:39:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2346.14s)]
*  create a hopeful, compelling, and abundant future for humanity. This podcast, everything I do is [[00:39:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2351.2599999999998s)]
*  helping entrepreneurs to create a hopeful, compelling, and abundant future that drives me. [[00:39:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2358.7799999999997s)]
*  Yours is a little bit bigger and broader. [[00:39:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2364.2999999999997s)]
*  Mine is transform civilization. [[00:39:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2367.2599999999998s)]
*  Yeah, that little small thing. [[00:39:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2368.8599999999997s)]
*  It's a niche project. [[00:39:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2370.06s)]
*  Transform into what? [[00:39:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2372.46s)]
*  Well, from whatever to whatever. It's clear we're going through the biggest inflection point in the [[00:39:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2373.74s)]
*  history of humanity right now. I'm sure you say that we must be living in the simulation. [[00:39:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2380.54s)]
*  We are. [[00:39:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2384.94s)]
*  Too goddamn interesting to be alive now. [[00:39:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2385.74s)]
*  99th level of gameplay. [[00:39:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2387.9s)]
*  Right. We could all have been born 10,000 years ago and spent 18 hours a day in a [[00:39:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2389.58s)]
*  digging ditches and then dying because we got a tooth infection. We happen to be alive now when [[00:39:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2395.6600000000003s)]
*  we're on the verge of breaking through longevity barriers. AI is coming along. [[00:40:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2402.7000000000003s)]
*  We're becoming a multilayered species. [[00:40:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2406.94s)]
*  Quantum is coming along. [[00:40:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2408.38s)]
*  Can I tell the story of the quantum thing? [[00:40:10](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2410.38s)]
*  You can, but God Almighty, quantum is going to make us feel like 2024 is ancient. [[00:40:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2412.6200000000003s)]
*  I know, but I just love this. [[00:40:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2417.9s)]
*  Ten years ago, we had Steve Jurvetson speak at Singularity University. He talked about [[00:40:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2420.7000000000003s)]
*  quantum computing. [[00:40:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2424.78s)]
*  Steve Jurvetson, for the other know, is an amazing venture capitalist. He's on the board of SpaceX. [[00:40:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2425.6600000000003s)]
*  He was previously on the board of Tesla. He runs a future AI venture fund right now. [[00:40:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2430.7000000000003s)]
*  He was asked the question while he was on stage, you've talked to all these top quantum computing [[00:40:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2442.1400000000003s)]
*  experts in the world. Where is all this computation coming from? [[00:40:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2446.46s)]
*  Just to set the stage properly, a quantum computer can do what your classical computer, [[00:40:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2450.06s)]
*  I mean like a classical supercomputer, but it can do things like a billion times or trillion [[00:40:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2455.5s)]
*  times faster. It's like, oh my God, where's all that computational power coming from to [[00:41:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2462.06s)]
*  do it a trillion times faster? His answer? [[00:41:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2467.66s)]
*  His answer was, you're not going to like the answer, but in talking to all the top quantum [[00:41:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2469.9s)]
*  computing physicists, it seems we're doing the computation in parallel universes and [[00:41:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2474.2999999999997s)]
*  bringing the answer back. In which cases, everybody's like, okay, I'm done. [[00:41:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2478.7s)]
*  Everybody checked out. That was 10 years ago. Roll forward 10 years of experiments, hard data, [[00:41:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2482.3799999999997s)]
*  hard science products were being rolled out, qubits, increasing qubits being put into more [[00:41:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2488.9399999999996s)]
*  computers, et cetera. We had at your last event, the head of Google- [[00:41:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2493.18s)]
*  Jack Hittery. [[00:41:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2498.9399999999996s)]
*  Not Jack Hittery, the German fellow who's the head of Google's AI- [[00:41:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2499.8999999999996s)]
*  Hartmut Neven. [[00:41:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2504.8599999999997s)]
*  Yeah, quantum computing AI. [[00:41:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2505.74s)]
*  Hartmut will be at Abundance Summit this year as well. [[00:41:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2507.66s)]
*  Okay. So top one of the top quantum computing guys in the world and physicists in the world. [[00:41:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2511.1s)]
*  So I asked him the question, 10 years ago, Steve Jurvetson said this, now we have 10 [[00:41:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2516.8599999999997s)]
*  years of data. What's your answer? And he kind of went, yep, the consensus is still that we're [[00:42:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2521.02s)]
*  doing the computation in parallel universes and bringing back the answer. At which point you kind [[00:42:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2527.1s)]
*  of go, okay, the only thing that will solve this is psychedelics. You have to do something. [[00:42:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2532.62s)]
*  That's a different conversation. [[00:42:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2537.58s)]
*  So when you kind of were hitting the boundaries and the edge conditions of reality itself in [[00:42:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2539.02s)]
*  so many different ways, it's just so goddamn interesting to be around. And this is why the [[00:42:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2545.74s)]
*  kind of the whether we hit AGI or not for me is like a trivial conversation. It's what we do with [[00:42:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2551.02s)]
*  it that I think- [[00:42:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2556.46s)]
*  We were talking about education. [[00:42:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2557.3399999999997s)]
*  And I want to make the point that I've got two 12-year-old boys, you've got one 12-year-old boy. [[00:42:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2559.42s)]
*  I make the joke, I'm more extended than you are. [[00:42:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2566.54s)]
*  I'm bolder than you are. There you go. [[00:42:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2570.38s)]
*  So I don't think our schools are preparing our kids at all. Not even close. [[00:42:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2573.42s)]
*  Look, honestly, go back to when we graduated university. How much of your university education [[00:42:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2579.34s)]
*  did you actually use in the workplace? [[00:43:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2584.6200000000003s)]
*  Very little. [[00:43:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2586.2200000000003s)]
*  Almost zero. So the concept of university has been out of date for decades already. [[00:43:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2586.78s)]
*  And frankly, it's a credentialing organization that shows society that you're able to apply [[00:43:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2593.5s)]
*  yourself to get through a final exam. [[00:43:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2597.7400000000002s)]
*  It's a signal to society. [[00:43:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2599.5s)]
*  We know you can copy the answers better. [[00:43:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2601.82s)]
*  You went to Stanford, you went to Harvard, whatever. [[00:43:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2604.2200000000003s)]
*  And now we have all sorts of other ways. For me, one of the most fascinating things over [[00:43:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2606.86s)]
*  the last few years has been the rise of GitHub. [[00:43:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2610.78s)]
*  Yes. [[00:43:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2613.66s)]
*  GitHub, for those who don't know, I can, as a software developer, message other people [[00:43:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2616.14s)]
*  and it's a platform. I can rate your code and you can give me like a Yelp type rating on my code. [[00:43:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2620.46s)]
*  By the way, Nat Friedman just agreed to come and speak. [[00:43:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2625.7400000000002s)]
*  Oh, amazing. [[00:43:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2628.7000000000003s)]
*  Yeah, and that was the CEO of GitHub. He's brilliant. [[00:43:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2629.5s)]
*  Amazing. So now you've got this. It was the highest rated EXO we ever saw. [[00:43:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2631.9s)]
*  It uses all 11 of the attributes in the EXO model. [[00:43:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2636.3s)]
*  And what I found incredible after watching it for a few years was that in Silicon Valley today, [[00:43:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2639.26s)]
*  your salary as a software developer has zero bearing or correlation with what university [[00:44:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2645.58s)]
*  you want to, what degree you got, what grades you got. It's 100% what is your GitHub rating. [[00:44:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2651.1s)]
*  So an open meritocracy, transparent, has now replaced the credentialing that university [[00:44:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2655.9s)]
*  can give you. How long before that goes to doctors and lawyers and accountants, etc.? [[00:44:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2661.26s)]
*  It's just a matter of time. [[00:44:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2665.98s)]
*  It's amazing. [[00:44:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2667.5s)]
*  This is that whole decentralization that's happening. The shift from centralized systems [[00:44:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2668.2999999999997s)]
*  to decentralized systems, the shift from scarcity to abundance, it's all the same inflection point. [[00:44:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2672.62s)]
*  For me, the fascinating point is how do we navigate that inflection point? It's like [[00:44:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2678.7799999999997s)]
*  the Gartner hype cycle. You go through this trough of disillusionment and then you come [[00:44:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2683.5s)]
*  out the other side. Can we lower the negative effects of that trough, the depth of it and the [[00:44:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2687.5s)]
*  amplitude of that? That's where the work that we do with Singularity or with the ecosystem [[00:44:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2693.02s)]
*  we've been building is can we get new projects and new companies and new technologies into play. [[00:44:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2698.78s)]
*  Go for what Peter Thiel used to say is we actually have to have exponential growth [[00:45:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2705.98s)]
*  even to deal with the predictions in the current economy. Just to keep the economy growing, [[00:45:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2711.18s)]
*  forget the fact that the entire paradigm of the economy dissolves over the next decade or so. [[00:45:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2715.1s)]
*  A year ago, I remember Elon tweeting in answer to somebody who was looking for a job, [[00:45:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2720.3799999999997s)]
*  I don't care what degree you have. I don't care if you have a high school degree. It's a matter of [[00:45:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2727.2599999999998s)]
*  what it's meritocracy, what can you do? Our middle school and high schools right now [[00:45:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2731.5s)]
*  are not preparing from a mindset perspective or from an understanding the speed of technology and [[00:45:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2740.7s)]
*  to understand the tools that we have in the future. I'm concerned about that, concerned about [[00:45:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2748.38s)]
*  for our kids and everyone listening. I think we need to reinvent high school and I think we need [[00:45:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2754.94s)]
*  to reinvent college. I don't want to spend too much more time there. I do want to share this. [[00:46:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2761.02s)]
*  I'll give one quick data point. One of my favorite little factoids was that in Silicon Valley, [[00:46:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2766.86s)]
*  more than half the CEOs have a liberal arts degree. Why? Because liberal arts gives you [[00:46:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2772.54s)]
*  different ways of thinking about a problem. Some of the greatest innovators in the world, Steve Jobs, [[00:46:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2780.38s)]
*  etc. were liberal arts backgrounds. I find that fascinating, but we don't have to go heavily into [[00:46:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2785.74s)]
*  that. Hey everyone, I want to take a quick break from this episode to tell you about a health [[00:46:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2791.42s)]
*  product that I love and that I use every day. In fact, I use it twice a day. It's Seeds DSO1 [[00:46:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2795.82s)]
*  Daily Symbiotic. Hopefully by now you understand that your microbiome and your gut health are one [[00:46:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2803.42s)]
*  of the most important modifiable parts of your health. Your gut microbiome is connected to [[00:46:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2808.78s)]
*  everything. Your brain health, your cardiac health, your metabolic health. So the question is what are [[00:46:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2813.9s)]
*  you doing to optimize your gut? Let me take a moment to tell you about what I'm doing. [[00:46:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2818.78s)]
*  Every day I take two capsules of Seeds DSO1 Daily Symbiotic. It's a two-in-one probiotic [[00:47:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2823.02s)]
*  and prebiotic formulation that supports digestive health, gut health, skin health, heart health, [[00:47:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2829.98s)]
*  and more. It contains 24 clinically and scientifically proven probiotic strains [[00:47:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2835.58s)]
*  that are delivered in a patented capsule that actually protects the contents from your stomach [[00:47:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2841.18s)]
*  acid and ensures that 100% of it is survivable, reaching your colon. Now, if you want to try [[00:47:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2846.62s)]
*  Seeds DSO1 Daily Symbiotic for yourself, you can get 25% off your first month's supply by using the [[00:47:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2852.78s)]
*  code Peter25 at checkout. Just go to seed.com slash moonshots and enter the code Peter25 at checkout. [[00:47:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2859.7400000000002s)]
*  That's seed.com slash moonshots and use the code Peter25 to get your 25% off the first month of [[00:47:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2867.98s)]
*  Seeds Daily Symbiotic. Trust me, your gut will thank you. All right, let's go back to the episode. [[00:47:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2876.1400000000003s)]
*  When you look at some of the things AI can do on the positive side, this just came out in the news [[00:48:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2882.3s)]
*  and said, AI system achieves 97% diagnostic sensitivity for autism. So the ability for AI [[00:48:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2888.7000000000003s)]
*  to diagnose almost anything. Yeah, if I had to pick the domain that I'm most optimistic about [[00:48:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2896.46s)]
*  AI, it's in healthcare. Yeah, for sure. There was a list that somebody made about 14 areas in healthcare [[00:48:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2903.1s)]
*  where you can apply generative AI materially. And there's not a lot of healthcare that's left out. [[00:48:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2910.54s)]
*  Research to application to patient care to data gathering to analytics to systemic thinking to [[00:48:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2915.74s)]
*  cost control. Yeah, we're doing this right now in Fountain because we have so much data. When we [[00:48:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2922.94s)]
*  upload a person in Fountain, we do their full body MRI, their coronary CT, DEXA scan, genomics, [[00:48:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2928.62s)]
*  150 gigabytes of data, gigabytes of data. There's no human on the planet can understand all that. [[00:48:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2933.42s)]
*  But there is amazing signal in the noise. And so it's AIs that are able to take that. We have AI [[00:48:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2938.46s)]
*  systems now listening to your voice or how you type that can look for early stages of dementia. [[00:49:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2945.26s)]
*  This one is another news article that just came out recently. And we saw this both in DeepMind [[00:49:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2951.9s)]
*  and OpenAI's labs that these systems can now outperform the traditional methods of weather [[00:49:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2959.1s)]
*  prediction. So being able to get an accurate 10 day weather forecast from a generative AI model. [[00:49:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2967.82s)]
*  And that's insane. So the question of course is what else can we predict with that level of [[00:49:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2975.6600000000003s)]
*  accuracy? I mean like the stock markets. So I have two responses. One is I think everything. [[00:49:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2981.82s)]
*  Let me give you an example, fantasy football, fantasy sports. AI's are going to go bananas on [[00:49:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2989.1800000000003s)]
*  that because they're going to have such better intuition. So would you ever bet on that again? [[00:49:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2994.22s)]
*  You can't. It'll destroy the field. We can't bet on it or you can't. You'll never win against AI. [[00:49:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=2999.58s)]
*  So it becomes my AI plays against your AI. And I was like, you know when you play tic-tac-toe [[00:50:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3007.4199999999996s)]
*  and it's boring after the age of five because you know either how to win or you're going to lose. [[00:50:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3012.2999999999997s)]
*  It'll be like that. So bye-bye fantasy football. A whole bunch of these domains of [[00:50:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3019.2599999999998s)]
*  I have an anecdote around the weather forecast studies. So over the last 20 years, [[00:50:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3024.54s)]
*  if you own a car wash in Buenos Aires, your revenues have dropped 50%. [[00:50:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3029.34s)]
*  Okay. Wow. Why? Yeah. So it doesn't make sense. One of our alumni down there, [[00:50:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3034.14s)]
*  Santiago Belincas, GSB. I know him from Santiago. He's going, this makes no sense. This is the [[00:50:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3038.7s)]
*  alumnus from Singularity University. Yeah. Okay. And he's one of our community members. And he's [[00:50:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3043.42s)]
*  like, this makes no sense. The middle class exploded. They bought a ton more BMWs and Mercedes. [[00:50:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3047.2599999999998s)]
*  Argentinians are very proud. They'd like to keep their cars clean. There should be a doubling or [[00:50:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3051.82s)]
*  tripling of car wash revenues. Why is there a 50% drop? So he starts looking into it and he turn [[00:50:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3055.7400000000002s)]
*  is there water restrictions? Is there a hyper competition? Are there legal issues? And he's [[00:51:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3061.26s)]
*  able to get rid of all the obvious factors. And then he finds the answer. And the answer literally [[00:51:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3065.1000000000004s)]
*  turns out to be Moore's law. Because our computational ability to predict the weather has increased [[00:51:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3069.5s)]
*  over that 20 year period. Over 20 years, we were exactly 50% better at knowing when it's going to [[00:51:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3075.6600000000003s)]
*  rain. And when you know it's going to rain, you don't wash your car. Now you can be the smart, [[00:51:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3080.86s)]
*  the key point here is, okay, nice thing, but you can be the smartest car wash owner in the world [[00:51:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3085.98s)]
*  and you will not see that. Right? So this little outcome is going to have all sorts of peripheral [[00:51:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3091.02s)]
*  effects that we have no idea and we can't predict. This is why Bill Gates calls, talks about having a [[00:51:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3097.26s)]
*  healthy paranoia about your business. Assume you will be disrupted. Yeah. And from that starting [[00:51:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3103.82s)]
*  point, what do you do? So for the moonshot entrepreneurs who are listening here, in my mind, [[00:51:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3109.98s)]
*  this is the future of everything. It's gathering data and being able to make predictions. And it's [[00:51:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3117.26s)]
*  probabilistic. Elon talks about probabilities all the time. And so it's converging probabilities. [[00:52:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3124.54s)]
*  And so what else if you're a fashion designer or an advertising, my favorite example is you can [[00:52:10](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3130.7s)]
*  know what the average spectral color of a man's jacket is on Madison Avenue today by all the [[00:52:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3137.9s)]
*  cameras looking at the jackets or the length of someone's skirt, whatever it might be. And you can [[00:52:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3145.26s)]
*  look at how it's changing over time. And was there an ad campaign that changed people from mauve to [[00:52:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3152.94s)]
*  pink or whatever the case might be? It's like in the world of a trillion sensors, we're heading [[00:52:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3159.34s)]
*  there. There are sensors everywhere. And you can gather all this data. If that data is analyzable, [[00:52:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3165.18s)]
*  then it's a matter of what questions do you ask? Yeah. This is, I think, the really big challenge. [[00:52:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3172.22s)]
*  I think it's a big opportunity. It's a huge opportunity. But I think it's a two-dimensional [[00:52:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3177.66s)]
*  problem. What I mean by that is let's say you had somebody scanning all the cameras and saying how [[00:53:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3182.62s)]
*  long are skirt lengths. Now you have some guidance as to how long you want to do your fashion skirt [[00:53:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3188.06s)]
*  design. That's a one-dimensional thing, assuming that everybody's still buying skirts. [[00:53:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3192.62s)]
*  Well, at least, oh, never mind. I think we're going to have this much bigger problem, like the [[00:53:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3198.06s)]
*  COVID pandemic hit. Do you remember the toilet paper problem in the US? So it turned out to be [[00:53:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3204.38s)]
*  a supply chain issue. Commercial toilet paper in malls and offices is very rough. And the market [[00:53:33](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3213.2599999999998s)]
*  has been so hyper efficient in dropping the cost of those. You had two different supply chains [[00:53:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3220.46s)]
*  for commercial toilet paper, residential toilet paper. Pandemic hits. Nobody's going to the office [[00:53:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3225.34s)]
*  or a mall. Everybody's staying home. The demand for residential goes up. This goes down. And nobody [[00:53:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3230.94s)]
*  can supply the toilet paper product. The soft, fluffy. The soft residential type. And so you [[00:53:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3235.9s)]
*  had this weird anomaly that you couldn't ever predict. Talk about singularities or black [[00:54:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3241.66s)]
*  swan events is the preference that I have for this type of thing, or the asteroids hitting, [[00:54:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3247.66s)]
*  or whatever. I think we're going to have so many of those that we actually have to start thinking [[00:54:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3252.7799999999997s)]
*  about, well, what do we want to be doing as a human species over the next five, 10, 15, 20 years [[00:54:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3257.3399999999997s)]
*  in terms of assuming the economy is going to get disruptive? I think we're going to end up having [[00:54:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3264.7799999999997s)]
*  to go to a UBI type model. UBI being universal basic income. Andrew Yang campaigned on this. [[00:54:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3270.22s)]
*  He was on stage with us last year. And there's this great video with Andrew. And I have him up on a [[00:54:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3277.9s)]
*  podcast. We did that event on the future of work with Tony Robbins there, et cetera. Years ago. [[00:54:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3283.7400000000002s)]
*  And at that event, this was in 2013 or 2014, we looked at 14 major UBI experiments around the [[00:54:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3288.94s)]
*  world. And they were staggeringly successful. UBI works. People do not sit on the couch drinking [[00:54:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3295.5s)]
*  beer and watching Netflix. Well, the trick is to find the level where you can give people enough [[00:55:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3301.5s)]
*  money to survive but not be happy. If you can find that balance, then you still have a very [[00:55:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3305.02s)]
*  thriving economy. You don't want them to be happy? You want them to be hungry to go out and do things. [[00:55:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3309.66s)]
*  Ah, you want them to continue. So I want to get back to this, which is if we can predict anything, [[00:55:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3316.14s)]
*  I mean, the stock market, you've got to be careful if you're trying to play the stock market on short [[00:55:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3322.3s)]
*  term, you will be crushed. But that's already the case today. It has been the case for a decade. [[00:55:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3331.1s)]
*  That's right. High frequency trading, for example, has taken out big chunks of the margins of [[00:55:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3335.58s)]
*  traditional stock analysis. This is another thing. Here's this 23 year old girl who sets up this AI [[00:55:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3339.9s)]
*  version of herself. And she generates $71,000 in the first week of revenue. I mean, that's a pretty [[00:55:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3349.1s)]
*  amazing return. And as a father of soon to be teenage boys, this is concerning for me. I also [[00:55:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3355.98s)]
*  think not just about an AI girlfriend, but what will be AI driven pornography. Yeah. That is, [[00:56:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3365.66s)]
*  I mean, it used to be when we were growing up, it was like Playboy, right? When you combine AI and VR, [[00:56:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3372.46s)]
*  I mean, a disruption of normal human relations. Yeah. What do you think about this stuff? So I [[00:56:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3381.98s)]
*  kind of go on the optimistic side, as I tend to fall on the- Tell me the optimism here. Well, [[00:56:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3389.66s)]
*  think about when we were kids and you were looking for a Playboy magazine, or anything with a [[00:56:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3395.58s)]
*  bikini in it, right? Okay. Then as you got video and now you got pornography widely available, [[00:56:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3399.42s)]
*  okay? The amount of violent rape and sexual assault has gone down a lot because people [[00:56:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3405.98s)]
*  found dodgy ways of satisfying themselves and you can look at whatever you want. [[00:56:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3411.1s)]
*  I think that's one level of optimism. We always talk about scarcity and abundance, right? Apps [[00:56:56](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3416.46s)]
*  like Tinder, for the first time in human history, took sex and maybe took it from scarcity to [[00:57:02](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3422.2999999999997s)]
*  abundance, right? Where was I? Where was that when we were 20, forgot sex? And I get so jealous of [[00:57:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3428.54s)]
*  the younger generation going, God dang it, you can just have an app and you can just go do that [[00:57:16](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3436.22s)]
*  whenever you want. I don't think we can predict what will happen. And we always assume it's bad. [[00:57:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3440.62s)]
*  If you go back to when we were growing up, the constant complaint from our parents was, [[00:57:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3446.94s)]
*  get off the damn phone. Yeah. Or stop watching TV. [[00:57:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3451.58s)]
*  Your ear will fall off. Yes, your ear will fall off. [[00:57:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3455.66s)]
*  All of that crap, right? Yeah. [[00:57:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3457.42s)]
*  And we have the same conversation now. You're playing too much Fortnite, right? You're playing [[00:57:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3458.7799999999997s)]
*  too much World of Warcraft. There's positive sides of it as well. Jury Ito did the study and found [[00:57:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3462.94s)]
*  that the best leadership training in the world is playing World of Warcraft, quantifiably. [[00:57:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3467.66s)]
*  And that's just an amazing outcome. Don't tell my kids that. [[00:57:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3473.5s)]
*  Luckily, they don't watch your podcast and my son doesn't watch me either. And I think that's where [[00:57:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3477.74s)]
*  the optimistic side comes in. I think we always go to the negative, right? But I see all sorts of [[00:58:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3483.2599999999998s)]
*  incredibly positive opportunities. The opportunities for human beings to now be self-determining [[00:58:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3489.58s)]
*  and fully fulfilled. I'll go back to the parenting story I've given. If you went back two, [[00:58:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3495.82s)]
*  three generations ago, our grandparents, and they had a parenting problem. Some child was throwing [[00:58:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3504.06s)]
*  too many temper tantrums. The corpus of help that they could look to get some help with the kid [[00:58:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3509.26s)]
*  throwing temper tantrums was like five people. Yeah. A neighbor they're close to, your sister, [[00:58:34](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3514.6200000000003s)]
*  and maybe somebody who looked like they knew what they were talking about. That's it. Okay. [[00:58:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3519.7400000000002s)]
*  Today, you have a problem with the child throwing temper tantrums. There's 50,000 blogs. There's [[00:58:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3523.26s)]
*  50,000 YouTube videos. There's online medical help and telemedicine help and coaching and counseling [[00:58:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3527.7400000000002s)]
*  of up the yin yang. And I would argue that our ability to do effective parenting today is [[00:58:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3534.0600000000004s)]
*  literally a thousand times better than our grandparents. We never talk about the positive [[00:58:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3539.0200000000004s)]
*  aspects of that. We don't even notice that. You're 100% correct. I'll give you one more very [[00:59:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3544.78s)]
*  mundane example. Please. Go back to when we were kids, you had a babysitter that was supposed to [[00:59:08](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3548.22s)]
*  show up. Babysitter was late. You have no idea. You don't have a phone call. They don't have cell [[00:59:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3553.5s)]
*  phones. You have no idea. Will they come or not come? Should we cancel the restaurant reservation [[00:59:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3557.66s)]
*  or not? And your parents are like in total chaos going, what the hell's going on? Da da da da da. [[00:59:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3561.3399999999997s)]
*  Now we know, okay, Uber will be three minutes late and the babysitter will be here or not. [[00:59:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3565.74s)]
*  Well, abundance of information. Our lives are so much more predictable and navigable [[00:59:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3570.14s)]
*  than they were a generation, two generations, three generations ago. And they will be another [[00:59:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3577.58s)]
*  level. So I really kind of you sound like me. I, when learns from the best, right? Because [[00:59:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3581.74s)]
*  those positive things are so profound and we never talk about them. Yeah, it's true. And still, [[00:59:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3589.8199999999997s)]
*  the nature of normal relationships and redefining relationships, because it used to be that our [[00:59:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3598.7799999999997s)]
*  average lifespan was 40. We'd get married at 18 and we'd be married for 20 years, have a kid, [[01:00:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3606.22s)]
*  pro grade. And now when the average lifespan goes to a hundred is death due as part. This goes to [[01:00:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3613.02s)]
*  the biggest concern I have about humanity and which is what speaks to my MTP. What is that? [[01:00:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3618.7799999999997s)]
*  Which is that technology. This is what EO Wilson said, the famous biologist. He said, our emotions [[01:00:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3623.74s)]
*  are Paleolithic, our institutions are medieval and our technology is Godlike. It's true. Pretty [[01:00:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3629.74s)]
*  much every problem in the world comes from a gap in those layers, right? Religions stick with your [[01:00:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3635.26s)]
*  Paleolithic emotions and co-opt them, et cetera, et cetera. Now, all the problems that we have to [[01:00:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3639.9s)]
*  solve sit with reconciling those layers, which was like Neuralink is so important, et cetera, [[01:00:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3645.1000000000004s)]
*  to give us better bandwidth in our brains and so on. You look at the types of issues that we're [[01:00:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3649.26s)]
*  facing today is all of that fits right into that bucket. And I think the biggest, for me, the [[01:00:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3654.5400000000004s)]
*  biggest difficulty is we know now how to transform corporations and organizations. We know how in our [[01:00:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3659.7400000000002s)]
*  community to be solved the immune system problem when you try anything disruptive. But what we [[01:01:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3665.18s)]
*  don't have is an ability to update our institutions. Yeah. I mean, the issue is they- UN is out of date. [[01:01:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3669.1s)]
*  Our, the, the monetary systems are out of date. Our legal systems are out of date. Our healthcare [[01:01:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3675.66s)]
*  systems- Our religious institutions are millennia old. Yeah. And my favorite example of an [[01:01:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3681.02s)]
*  institution- But there are stabilizing benefits of having that. Of having those- Of having [[01:01:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3686.94s)]
*  institutions that are stable. Right? Oh, huge. You, you, we desperately need stable institutions. [[01:01:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3691.74s)]
*  And the problem is that those aren't reliable anymore and they're out of date. And my favorite [[01:01:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3697.8999999999996s)]
*  example is marriage, which you just mentioned. Right? So it turns out we invented marriage about [[01:01:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3702.62s)]
*  9,000 years ago, okay? As a social institution. That's when it first emerged. Um, and we invented [[01:01:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3707.2599999999998s)]
*  it because you wanted to keep the parents together until the kids were self-sufficient. Yeah. And the [[01:01:53](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3713.42s)]
*  idea was, and back then 9,000 years ago, what was average lifespan? Yeah, it was 35 or so, [[01:01:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3718.14s)]
*  40 at most. No, 25. Well, I mean, there's arguments. Okay, let's go 30, 35. Okay. Okay. So you had [[01:02:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3723.02s)]
*  kids, you got married, you had kids, and pretty soon after you died. Marriage is not supposed to [[01:02:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3729.3399999999997s)]
*  last 50, 60 years. It wasn't designed for that. Right? It was designed just to keep you alive [[01:02:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3734.3799999999997s)]
*  long enough for the kids to become old enough and self-sufficient. What do you think, renewable 10 [[01:02:18](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3738.94s)]
*  year agreements? Well, that's, that's one option. And this whole idea of death due part, et cetera. [[01:02:23](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3743.02s)]
*  Now, as we hit the hundred year barrier that, that everything that you're talking about and [[01:02:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3747.82s)]
*  working on towards is driving us towards, are you supposed to live with the same person for a [[01:02:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3752.06s)]
*  hundred years? Right? That's nonsense in a traditional model. And it's, and we complain [[01:02:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3756.2200000000003s)]
*  about the divorce rate, but we're dealing with an institution that was designed 9,000 years ago. [[01:02:41](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3761.1000000000004s)]
*  Yeah. Right. So this is the challenge I think we have with humanity today is how do we update our [[01:02:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3765.42s)]
*  institutions that have no feedback loop, at least in the capital world, which is why you're high on [[01:02:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3770.2200000000003s)]
*  capitalism. You have a creative destruction cycle. If you're not making enough money, [[01:02:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3775.74s)]
*  it's like our legal system, right? We don't take laws off the books. They're there forever. [[01:02:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3779.58s)]
*  That's right. Now there's some good solutions. Like in Germany, for example, they've started [[01:03:04](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3784.3799999999997s)]
*  putting an end date on laws. That's great. And so that law is going to expire on that date. [[01:03:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3787.9799999999996s)]
*  If you want to add a law, take one off. That's right. I want to close on this topic. That is [[01:03:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3792.9399999999996s)]
*  top of mind for me. I was on CNBC last week speaking about this and it's deep fakes. We saw [[01:03:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3799.34s)]
*  a number, Taylor Swift in particular, with a whole set of deep fake nudes. We've seen a lot [[01:03:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3807.5s)]
*  of celebrities. We've seen Trump go on the record saying, that's not true. That's a deep fake. [[01:03:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3812.46s)]
*  So let's jump in here. You know, when something is dystopian, we call it a deep fake. When it's [[01:03:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3819.1000000000004s)]
*  useful, we call it an avatar. I just want to make that distinction. Again, I think AI is the most [[01:03:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3827.1s)]
*  important tech we have ever as a human species created. We can talk. We've started with that [[01:03:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3834.46s)]
*  conversation. I still believe it. And the ability to create an AI avatar on the positive side of [[01:03:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3839.5s)]
*  someone you've lost. And we have the ability now to bring back people from the grave if you've got [[01:04:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3846.7s)]
*  good video and audio. And if my kid should ever want to bring me back after a couple hundred years, [[01:04:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3852.62s)]
*  all my books and my blogs, I have lots of AI models of me trained up that answer better than [[01:04:20](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3860.22s)]
*  I do when I speak to them. It was amazing. I did a podcast with Peterbot and I was jealous of Peterbot [[01:04:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3864.7s)]
*  because he was so smooth and it was so smart. And it's going to remember instantly everything [[01:04:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3871.9s)]
*  that I've been talking about, because we don't. Our memories fade over time. It's very [[01:04:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3876.54s)]
*  contemporary. So that's an avatar. Avatar is going to be amazing in marketing and sales and [[01:04:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3879.58s)]
*  customer relations and all kinds of things. But the deep fake, you know, and to put a fine point [[01:04:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3885.66s)]
*  on this, you can create a voice model and with a few seconds of voice, you can create a great image [[01:04:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3892.54s)]
*  model. You know, Iman Moustak, we both know, who's a brilliant entrepreneur and a friend, [[01:04:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3899.98s)]
*  said in the old days, a couple years ago, it would take 30 seconds to come up with a image from a [[01:05:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3909.34s)]
*  prompt. Now you can produce 100 images per second, which means high definition video. [[01:05:14](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3914.86s)]
*  And the impact on Hollywood is going to be amazing. But, you know- [[01:05:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3922.62s)]
*  Our eye operates at what, 60 frames per second or something? [[01:05:28](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3928.14s)]
*  It's lower. [[01:05:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3930.8599999999997s)]
*  30 frames. So deep fakes, thoughts? [[01:05:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3932.46s)]
*  I think, again, it's an arms race problem. We'll have deep fakes causing problems and then we'll [[01:05:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3938.46s)]
*  figure out how to identify deep fakes pretty quickly. The problem is that gap is a material [[01:05:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3943.98s)]
*  gap, especially like in an election year. I think here's a problem that I could see happening. [[01:05:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3949.58s)]
*  There's a deep fake of Elon getting up and saying, well, Tesla is all a fraud. It was all [[01:05:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3955.4199999999996s)]
*  an Enron type scenario, tanks the stock market. Somebody short sold the stock market. [[01:06:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3960.8599999999997s)]
*  We saw that. There was a deep fake photo of an explosion or airplanes hitting the Pentagon [[01:06:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3965.58s)]
*  and it tanked the market for a few hours. [[01:06:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3971.18s)]
*  That's right. And so I think we're going to see a lot more of that. Essentially, what we're going [[01:06:13](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3973.3399999999997s)]
*  to see is just massive volatility. We saw that in Russia. We've seen that in Russia and the Ukraine [[01:06:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3977.4199999999996s)]
*  now. They're showing, oh, this apartment building just got bombed in Russia and it turns out it was [[01:06:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3982.14s)]
*  from five years ago and the photograph isn't even relevant. That's the kind of difficulty we're [[01:06:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3986.2999999999997s)]
*  going to have because of the asymmetry of people seeing something and believing instantly and the [[01:06:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3991.2599999999998s)]
*  truth and validation takes some time. It's like Trump doing criminal things and then it takes a [[01:06:37](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=3997.02s)]
*  long time for the course to catch up and you can arbitrage that gap, which is what he's been doing [[01:06:42](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4002.2999999999997s)]
*  for his whole life. [[01:06:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4006.62s)]
*  For sure, to survive. [[01:06:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4007.42s)]
*  So if you want to operate that way, you can operate that way. [[01:06:48](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4008.8599999999997s)]
*  I've been thinking about what do you do about deep fakes because they are concerning. They are here [[01:06:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4012.46s)]
*  already and in an election year, it's going to get bad. I expect both sides of the aisle to be [[01:06:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4018.14s)]
*  using them, maybe not admitting they're using it, but it's going to be deployed. [[01:07:09](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4029.2599999999998s)]
*  I don't care if someone says to you that this politician is whatever slew of negative things, [[01:07:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4037.1000000000004s)]
*  if you see it over and over and over again and if you prove it's a deep fake, it doesn't matter. [[01:07:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4044.86s)]
*  It doesn't matter at all. [[01:07:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4049.26s)]
*  It's still infected my brain. I think about, for me, there are four things that are possible. [[01:07:29](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4049.82s)]
*  Let me list them off and get your feedback. The first is going to be regulation, [[01:07:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4055.26s)]
*  making it not just illegal, but criminal. It's harsh sentences and we have that for counterfeiting. [[01:07:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4059.66s)]
*  There are bills already in process for that, but it needs to be like you do this, [[01:07:50](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4070.46s)]
*  you're in jail for the rest of your life. It has to be harsh. [[01:07:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4075.58s)]
*  Second thing is it is white hat versus black hat AI. We can't innovate at the speed of conferences [[01:08:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4080.3799999999997s)]
*  and the speed of the government. It's got to be entrepreneurs taking this on. [[01:08:07](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4087.98s)]
*  Well, this is why we're at the visioneering. We have the truth finding. [[01:08:12](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4092.14s)]
*  Every year XPRIZE holds this thing called global visioneering where we brainstorm the [[01:08:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4097.18s)]
*  next generation of XPRIZE. Salim is on stage, I'm on stage, and we're brainstorming. This year, [[01:08:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4101.18s)]
*  one of the top selected prize ideas that I'm still trying to make happen at Conversation Day is [[01:08:26](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4106.06s)]
*  AI for truth. If I give you a datum, can you tell me it's factual, it's opinion, [[01:08:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4112.7s)]
*  or it's disinformation? That's right. I think things like that will happen, but that gap will [[01:08:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4120.3s)]
*  still be there for a while. Until we figure it out, that's going to be a huge problem. [[01:08:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4125.82s)]
*  Let's say if you're a right-wing person and you see a video of Biden saying something really bad, [[01:08:51](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4131.099999999999s)]
*  you're emotionally attached to that messaging. There was an article that came out in [[01:08:58](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4138.54s)]
*  Salon.com about 10 years ago. The title of that article was really dramatic. It was like the worst [[01:09:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4145.66s)]
*  discovery about the brain ever. That was the title of the article. What they did was they presented [[01:09:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4151.18s)]
*  somebody that has deeply held political or religious belief with evidence countering that [[01:09:17](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4157.0199999999995s)]
*  belief structure. Abortion, for example, or something like that. They showed them, [[01:09:22](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4162.94s)]
*  gave them evidence countering that structure. Three things happened. The first thing was they [[01:09:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4167.02s)]
*  rejected the evidence. Fine, we know that. Not a big surprise. The second thing was a little bit [[01:09:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4171.34s)]
*  surprising was that in rejecting the evidence, it made your belief structure stronger. It was like [[01:09:36](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4176.46s)]
*  a physics force, anti-force, reaction, anti-reaction outcome. It made your belief system stronger. [[01:09:43](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4183.02s)]
*  That was like, holy crap, that's annoying and weird. The third thing, which is what led to the [[01:09:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4189.740000000001s)]
*  title of the article, was it turned out the more mathematically literate you were, [[01:09:54](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4194.62s)]
*  the more likely you were to reject the evidence because you think you know. That depressed the [[01:09:59](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4199.099999999999s)]
*  crap out of them because they said that means you can never use an evidentiary approach, [[01:10:06](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4206.22s)]
*  a data-driven approach, to convince somebody of something. You always have to use a narrative [[01:10:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4211.34s)]
*  type structure. Storytelling. Our brains are wired for storytelling. That's right. This is [[01:10:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4215.66s)]
*  a really big problem for humanity. This is where I'm really optimistic of a neural link or whatever. [[01:10:24](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4224.3s)]
*  Can we use a two-way BCI, brain computing interface, to mitigate the effects of the [[01:10:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4231.26s)]
*  amygdala and rewire our brains in a more cognitive way to be more cognitively intelligent, [[01:10:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4238.46s)]
*  react more maturely about things, et cetera. That's where I think things get really interesting. [[01:10:44](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4244.7s)]
*  So number one solution is regulation. Number two, it is white hat. It's entrepreneurs using AI. [[01:10:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4249.18s)]
*  I like to say the world's biggest problems, the world's biggest business opportunities. [[01:10:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4257.5s)]
*  This is a problem. Let's solve it. The third is the use of advances in technologies like blockchain [[01:11:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4260.7s)]
*  to encode metadata to authenticate. We've seen this before in, for example, counterfeiting. When [[01:11:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4271.18s)]
*  the color copiers became so good, high resolution, there was a group of 30 central banks got together [[01:11:21](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4281.26s)]
*  with the copying companies and created the algorithms that would detect if you were trying [[01:11:27](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4287.66s)]
*  to photocopy a euro or a dollar and block it. That needs to come in, but the second part is [[01:11:32](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4292.06s)]
*  the network needs to detect if a video has the proper metadata. Again, that's intelligence built [[01:11:40](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4300.3s)]
*  into the system, and then you have proper detection. That, I think, falls into the white hat camp. [[01:11:49](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4309.5s)]
*  It does, for sure. And maybe finally, in another use for blockchain besides cryptocurrencies. [[01:11:55](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4315.34s)]
*  Yep. Well, there's all sorts of use for blockchain. I know. [[01:12:00](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4320.9400000000005s)]
*  There's all sorts of use for blockchain. I'm just punching your buttons, buddy. [[01:12:03](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4323.98s)]
*  The fourth solution is an interesting one, and it's a change in society. Today, we believe what we see, [[01:12:11](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4331.5s)]
*  and imagine a point in the future in which we default to disbelief, where all of a sudden, [[01:12:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4345.34s)]
*  most of the stuff that we see, we just assume it's a deep fake. It's entertainment, and that's it. [[01:12:31](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4351.9s)]
*  I don't believe it. That could have some interesting implications, a default to disbelief. [[01:12:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4359.0199999999995s)]
*  So, what you're doing there is jumping to critical thinking. Maybe the one way to deal with this in a [[01:12:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4366.219999999999s)]
*  second, in other ways, make sure all our kids are trained in critical thinking from the year dot. [[01:12:52](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4372.0599999999995s)]
*  Dad, I don't believe you. [[01:12:57](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4377.5s)]
*  One of the biggest failings, I think, of the education system today is we don't teach critical [[01:13:01](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4381.259999999999s)]
*  thinking. When Singularity University, we would have these graduate students coming in. We had [[01:13:05](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4385.9s)]
*  to teach critical thinking just so they had the ability to assess a technical paper and assess [[01:13:10](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4390.54s)]
*  validity or not. And that, I think, is a huge area where you could apply that. By the way, [[01:13:15](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4395.419999999999s)]
*  we've seen solutions to that. There's a woman out of Chicago who's using rich media to teach kids [[01:13:19](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4399.82s)]
*  and uses that channel to teach critical thinking, and it's phenomenally successful. [[01:13:25](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4405.9s)]
*  So, there's lots of ways of getting through that. We just have to get it deployed at scale. [[01:13:30](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4410.219999999999s)]
*  My buddy, listen, an hour flew by in an instant. [[01:13:35](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4415.179999999999s)]
*  Wow. That was a fast hour. [[01:13:38](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4418.299999999999s)]
*  Yeah, that was fun. I enjoy this, and I would love to do this on a regular basis with you. [[01:13:39](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4419.74s)]
*  Absolutely. [[01:13:45](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4425.339999999999s)]
*  All right, brother. [[01:13:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4426.139999999999s)]
*  All right. [[01:13:46](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4426.7s)]
*  Thank you. [[01:13:47](https://www.youtube.com/watch?v=ZSwbvj4mqPA&t=4427.259999999999s)]
