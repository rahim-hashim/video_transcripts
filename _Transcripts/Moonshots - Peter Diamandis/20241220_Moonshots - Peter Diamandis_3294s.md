---
Date Generated: May 30, 2025
Transcription Model: whisper medium 20231117
Length: 3294s
Video Keywords: ['peter diamandis', 'longevity', 'xprize', 'abundance']
Video Views: 38058
Video Rating: None
Video Description: In this episode, Peter and Salim discuss the Elon vs. OpenAI battle, whether AI should be for-profit, and the millions of investments being poured into AI. 
Recorded on Dec 19th, 2024
Views are my own thoughts; not Financial, Medical, or Legal Advice
Salim Ismail is a serial entrepreneur and technology strategist well known for his expertise in Exponential organizations. He is the Founding Executive Director of Singularity University and the founder and chairman of ExO Works and OpenExO. 
Join Salim's ExO Community: https://openexo.com
Twitter: https://twitter.com/salimismail 
Pre-Order my Longevity Guidebook here: https://qr.diamandis.com/bookyt 
—******--
This episode is supported by exceptional companies:
Get started with Fountain Life and become the CEO of your health: https://fountainlife.com/peter/
AI-powered precision diagnosis you NEED for a healthy gut: https://www.viome.com/peter 
Get 15% off OneSkin with the code PETER at  https://www.oneskin.co/ #oneskinpod
******************************************--
00:00 - Intro
06:51 - The OpenAI Controversy
13:32 - The High-Stakes Game of AI
19:30 - The Future of AI and Control
25:07 - The Need for a Holistic Conversation
27:29 - Navigating the Future of AI and Humanity
32:15 - The Role of the US in Global AI Development
37:01 - Understanding AI Behavior and Consciousness
40:43 - Revolutionizing Healthcare with AI
52:21 - The Future of Education and Health Systems
******************************************--
I send weekly emails with the latest insights and trends on today’s and tomorrow’s exponential technologies. Stay ahead of the curve, and sign up now: https://www.diamandis.com/subscribe
Connect with Peter:
Twitter: https://bit.ly/40JYQfK
Instagram: https://bit.ly/3x6UykS
Listen to the show:
Apple: https://apple.co/3wLXeV3
Spotify: https://spoti.fi/3DwLzgs
---

# Elon vs. OpenAI: The Battle Over For-Profit AI w/ Salim Ismail | EP #138
**Moonshots - Peter Diamandis:** [December 20, 2024](https://www.youtube.com/watch?v=8xZ_9xDOxv8)
*  OpenAI puts out a letter. Elon wanted an OpenAI for-profit model from the beginning. [[00:00:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=0.0s)]
*  Ultimately, what we've got here is a battle for the biggest opportunity on the planet. [[00:00:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=7.4s)]
*  I used to think early on that this was going to be a game between governments. [[00:00:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=13.5s)]
*  This isn't. This is a game for all the marbles between companies. [[00:00:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=18.5s)]
*  It's hard to even process how fast this is going to go from now on. [[00:00:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=21.7s)]
*  The CEO of SoftBank making a commitment for a hundred billion dollar investment in the US in AI. [[00:00:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=26.099999999999998s)]
*  If this is a sign of where the US is going to be going, it really is a push for global dominance in this field. [[00:00:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=31.9s)]
*  Everybody, welcome to a special end of year episode of Moonshots with Salim Ismayal and myself in WTF Just Happened in Tech this week. [[00:00:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=42.3s)]
*  We're going to be talking about some recent news from OpenAI showing their conversations with Elon Musk [[00:00:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=50.1s)]
*  and the debate about for-profit versus nonprofit, the lawsuits going on, [[00:00:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=57.300000000000004s)]
*  but more importantly, the huge amount of capital flowing into the AI world. [[00:01:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=61.900000000000006s)]
*  I mean, hundreds of billions of dollars. [[00:01:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=67.0s)]
*  This is a game that is going to play out aggressively in 2025. [[00:01:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=68.6s)]
*  I want you to hear the details. [[00:01:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=73.0s)]
*  We're also going to be talking about the world of AI and healthcare. [[00:01:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=74.9s)]
*  The disruptions that are coming to make us all healthier and to drop hopefully orders of magnitude. [[00:01:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=78.8s)]
*  This segment is sponsored by three incredible companies, Fountain, Viome and OneSkin. [[00:01:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=86.2s)]
*  You know, Fountain is a company that I care deeply about. [[00:01:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=92.0s)]
*  It is my partner in helping transform what I understand about what's going on inside my body to find disease early [[00:01:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=95.3s)]
*  and then deliver to me the top therapeutics around the planet. [[00:01:43](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=103.9s)]
*  You can check them out at fountainlife.com. [[00:01:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=107.1s)]
*  Viome has built custom supplements for me, understanding my oral and gut microbiome, [[00:01:49](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=109.8s)]
*  measuring it and helping me maintain the health of the 40 to 100 trillion organisms that are within my body. [[00:01:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=116.19999999999999s)]
*  And then OneSkin is an incredible company that helps me maintain my skin youth. [[00:02:04](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=124.5s)]
*  I get compliments about my skin, which at 63 is kind of a strange thing, [[00:02:10](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=130.1s)]
*  but I attribute it to OneSkin and the peptides they have for getting rid of those synilotic cells in your skin. [[00:02:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=134.2s)]
*  All right. All the links are down below. [[00:02:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=141.1s)]
*  Let's jump into this episode with Salim Ismail. [[00:02:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=143.39999999999998s)]
*  Let's talk about where AI and health is going. [[00:02:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=146.29999999999998s)]
*  It's an extraordinary future ahead. [[00:02:28](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=148.89999999999998s)]
*  Everybody, Peter Diamandis here. [[00:02:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=150.79999999999998s)]
*  Welcome to a special end of year episode of WTF Just Happened in Technology here on Moonshots [[00:02:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=152.1s)]
*  with my partner, my extraordinary best friend, Salim Ismail, the CEO of OpenEXO, [[00:02:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=159.0s)]
*  an individual who I've been on stages around the world with, [[00:02:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=165.4s)]
*  the person I love speaking about exponential technologies, where they're going, [[00:02:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=168.6s)]
*  how fast they're moving and where the world is heading. [[00:02:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=172.0s)]
*  Salim, good to see you, buddy. [[00:02:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=174.70000000000002s)]
*  Likewise. We're both a little raw from you different things last night. [[00:02:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=176.5s)]
*  Late, late, late, late. [[00:03:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=180.6s)]
*  Yeah. [[00:03:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=182.5s)]
*  Yes. [[00:03:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=182.9s)]
*  This, you know, the news had been coming out. [[00:03:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=183.3s)]
*  We wanted to have a conversation about AI and health care. [[00:03:05](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=185.5s)]
*  I think eight hours of sleep is always our objectives. [[00:03:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=191.3s)]
*  Didn't happen last night. [[00:03:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=193.4s)]
*  So if you hear me a little raw, like Salim said, [[00:03:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=194.4s)]
*  but we're living in such an exciting world that I wanted us to have this conversation [[00:03:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=198.0s)]
*  before the end of the year because 2024 is going to be marked as one of the most important years in AI, [[00:03:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=203.9s)]
*  I think. And, you know, I split my luck. [[00:03:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=211.5s)]
*  I think one of the most technologically relevant years in the history of humanity. [[00:03:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=213.3s)]
*  It's a big, big thing. [[00:03:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=217.70000000000002s)]
*  Yeah. [[00:03:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=219.3s)]
*  And the only time more relevant is going to be next year, which we're on the cusp of. [[00:03:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=219.60000000000002s)]
*  I mean, we're in the steep part of the curve. [[00:03:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=224.8s)]
*  I mean, it feels that way. [[00:03:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=226.5s)]
*  I would, one way I frame it is this next 20, 30 years is going to define the next few centuries of humanity. [[00:03:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=228.0s)]
*  Do you think it's 20 or 30 years or is it like the next 10 years? [[00:03:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=234.10000000000002s)]
*  It's all of it. [[00:03:58](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=238.10000000000002s)]
*  I mean, it's this is this is just it's hard to process it. [[00:03:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=239.0s)]
*  You know, for you often not comment that for tens of thousands of years nothing happened in humanity. [[00:04:05](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=245.0s)]
*  Right. And all of a sudden boom. [[00:04:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=249.9s)]
*  So, yeah, I just wonder if we were alive, you know, 110, 120 years ago when the airplane is flying [[00:04:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=252.1s)]
*  and cars are coming online and then electricity and telephony, [[00:04:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=259.9s)]
*  whether it would have felt like it does now. [[00:04:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=264.2s)]
*  Lily wanted to say hi to you. [[00:04:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=267.7s)]
*  Hi, Lily. [[00:04:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=269.2s)]
*  Good morning to you. [[00:04:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=270.59999999999997s)]
*  I can't hear you. [[00:04:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=271.4s)]
*  Peter's saying hi to you. [[00:04:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=272.3s)]
*  Hi, Peter. [[00:04:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=273.5s)]
*  You're live. [[00:04:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=274.4s)]
*  See you soon. [[00:04:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=275.0s)]
*  See you soon. [[00:04:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=275.9s)]
*  So I wonder if it would have felt as fast as it does now because it feels it feels crazy fast. [[00:04:38](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=278.3s)]
*  You know, one thing I've noticed is the speed of collective conversation because of Twitter X [[00:04:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=286.5s)]
*  and social media and digital content and digital news. [[00:04:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=294.6s)]
*  We're leveling up humanity with global conversations incredibly fast. [[00:04:58](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=298.90000000000003s)]
*  Yeah, like a joke happens and it gets collected into the collective consciousness in almost real time. [[00:05:04](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=304.20000000000005s)]
*  And that's something that's totally new from 100 200 300 years ago. [[00:05:10](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=310.40000000000003s)]
*  So I want to talk about AI and health care. [[00:05:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=314.90000000000003s)]
*  I split my life 50% AI 50% sort of longevity health biotech health care. [[00:05:17](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=317.1s)]
*  Well, what about the space stuff? [[00:05:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=323.5s)]
*  That's been your like whole passion for that was that was like 20 years ago. [[00:05:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=326.1s)]
*  I mean, you know, Elon and Jeff Bezos have that super well handled. [[00:05:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=330.5s)]
*  So I'm not going to so space is old news. [[00:05:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=334.7s)]
*  Space is old news. [[00:05:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=337.7s)]
*  Well, you know, I'm like I've said I want to go back and do the asteroid mining stuff. [[00:05:38](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=338.5s)]
*  Yeah. [[00:05:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=342.7s)]
*  And that was a true passion. [[00:05:43](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=343.3s)]
*  I also think it's a it's a massive opportunity to go out there and get those carbonaceous chondrites [[00:05:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=344.7s)]
*  and metallic chondrites and create an economy in space. [[00:05:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=350.2s)]
*  But it's expensive. [[00:05:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=352.8s)]
*  And so I need to make a bunch of bank in the longevity and AI business first and then go and fund my space. [[00:05:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=354.7s)]
*  I was a good good do that. [[00:06:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=361.90000000000003s)]
*  You know, for me, the space stuff is most relevant because you can back up humanity and give us an alternative [[00:06:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=363.2s)]
*  a spot for this. [[00:06:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=368.6s)]
*  And I think that's really important. [[00:06:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=369.40000000000003s)]
*  And by the way, 2024 was an amazing year in terms of space with seeing Starship get almost entirely [[00:06:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=371.1s)]
*  to its its objective of full usability. [[00:06:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=381.70000000000005s)]
*  And I think the first half of 2025, we're going to see Starship the booster caught and we'll see the Starship itself [[00:06:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=384.90000000000003s)]
*  caught and that's transformative across the board. [[00:06:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=391.3s)]
*  But let's let's let's let's dive into AI first because there's a lot in use and I want to want us to get this out [[00:06:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=395.40000000000003s)]
*  to your open EXO community around the world to my abundance and Singularity University around the community around [[00:06:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=402.70000000000005s)]
*  the world. [[00:06:49](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=409.20000000000005s)]
*  There's just so much and it's the biggest game that humanity collectively has ever played and here are two quotes. [[00:06:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=410.0s)]
*  I want to read that come out of Silicon Valley that frame this. [[00:06:58](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=418.4s)]
*  I believe they frame what's going on and it's you know, this is people playing for all the marbles. [[00:07:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=422.7s)]
*  Let me let me read this for those not watching this on YouTube. [[00:07:10](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=430.2s)]
*  It says quote we don't think of these build outs in terms of ROI return investment. [[00:07:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=434.4s)]
*  If we create this digital God the return is multiple trillions. [[00:07:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=439.9s)]
*  Here's the next quote. [[00:07:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=444.0s)]
*  It doesn't matter how many tens of billions we spend each quarter. [[00:07:25](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=445.0s)]
*  We have to get there and not miss the boat. [[00:07:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=449.4s)]
*  I mean, I don't know. [[00:07:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=452.79999999999995s)]
*  That's that's pretty impressive. [[00:07:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=454.29999999999995s)]
*  It's huge. [[00:07:38](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=458.2s)]
*  I you know, if you're not from Silicon Valley, then you kind of go. [[00:07:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=459.40000000000003s)]
*  Oh my God tech bros going after a full digital God model and who do they think they are type of thing. [[00:07:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=464.1s)]
*  You'll get that response. [[00:07:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=474.6s)]
*  I think from a lot of especially say from Europe. [[00:07:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=476.0s)]
*  One of the conversations I let's get get into this because I think less recap what's been happening and then let's talk this conclude. [[00:08:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=480.90000000000003s)]
*  Good. [[00:08:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=487.40000000000003s)]
*  Sure. [[00:08:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=487.7s)]
*  Sure. [[00:08:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=488.0s)]
*  So what's new this week is that open AI puts out a letter that that is probably in preparing for the discovery in the lawsuits flying back and forth between open AI and Elon and this letter which is amazing. [[00:08:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=488.5s)]
*  If you haven't read it you people can go to it and we'll put it in the show notes. [[00:08:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=507.9s)]
*  It says Elon wanted an open AI for-profit model from the beginning. [[00:08:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=512.0s)]
*  You know, I for those who have never used notebook LM, which is an amazing platform that Jim and I put out. [[00:08:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=517.1s)]
*  I took this large open AI letter and I put it into notebook LM and it generated a podcast conversation between two individuals who are AIs and it's an amazing way to absorb information and it's mind-boggling because you get the dialectic in there. [[00:08:43](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=523.8s)]
*  And it's and the the back and forth of the dialogue brings it home very quickly into somebody's mind. [[00:09:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=542.2s)]
*  So what happened so so Sam Altman and Elon who had been friends decide to start open AI. [[00:09:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=549.5s)]
*  There's a true fear about where AI is going in the early days how fast it's accelerating and a an initial conversation around we need to make sure it's open. [[00:09:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=556.3000000000001s)]
*  We need to make sure we're guiding it. [[00:09:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=567.3000000000001s)]
*  We need to make sure it's safe. [[00:09:28](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=568.8000000000001s)]
*  And so open AI begins as a nonprofit Elon contributes like 50 million dollars. [[00:09:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=570.7s)]
*  I think in the beginning to get that going and the the whole thread of the conversation that we've heard over the last year has been oh my God. [[00:09:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=575.3000000000001s)]
*  I wanted to be a nonprofit says Elon and Sam Altman turns it into a for-profit. [[00:09:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=585.0s)]
*  But that's actually not what the letter says though the letters that were disclosed basically said no no Elon wanted to become a for-profit because it should be and in fact Elon wanted to become the CEO of it and wanted to have open AI be part of his sort of tech empire between X between Tesla SpaceX and so forth because he needed those resources to fuel his his forward-going missions towards Mars. [[00:09:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=591.9s)]
*  What did you get out of it? [[00:10:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=618.0s)]
*  For me this feels to me just a defensive move by opening and to counter the lawsuit which has been broadened to include Microsoft and say hey like this is the whole thing is without merit because he was wanting to do this in the first place. [[00:10:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=619.9s)]
*  So that's what it feels like to me. [[00:10:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=633.5s)]
*  I can completely understand what seems to be the real tension is that Elon wanted opening out to be part of his world and the rest of them were like no we want to do our own thing and that's I think where the things started breaking down. [[00:10:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=635.3s)]
*  That's what it feels to me listening to the note and reading some of the notes. [[00:10:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=648.7s)]
*  Yeah, ultimately what we've got here is a battle for the biggest, you know, the biggest opportunity on the planet. [[00:10:53](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=653.0s)]
*  Right. [[00:11:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=662.5s)]
*  I mean what we're going to see here and I think what's come to light over the last few months is the march towards AGI is everything all of the large players. [[00:11:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=662.8000000000001s)]
*  We're talking about the largest corporations on the planet and governments around the planet have realized this is the single most important technology out there and they're playing for keeps. [[00:11:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=675.3000000000001s)]
*  All right. [[00:11:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=684.4000000000001s)]
*  This is the this is boss mode for for humanity. [[00:11:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=684.8000000000001s)]
*  You know, here's here's the next the next item for us to to point out here. [[00:11:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=689.5s)]
*  So meta meta also this week asked the government to block open AI switch to a for-profit. [[00:11:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=695.7s)]
*  You know, a lot of players here are are playing this very complicated game of chess and we had besides open AI being pushed to stay a nonprofit by Elon. [[00:11:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=702.4s)]
*  Now we've got meta coming in here. [[00:11:58](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=718.1s)]
*  Everybody's trying to grab, you know, an advantage and using the courts to help them this way. [[00:12:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=720.1999999999999s)]
*  Comments? [[00:12:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=727.1999999999999s)]
*  Definitely. [[00:12:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=728.0999999999999s)]
*  And look, this is the high stakes poker game and people are playing all their cards, right? [[00:12:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=728.8s)]
*  They're doing everything they can to attack others, figure out what they're going to do themselves. [[00:12:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=733.6999999999999s)]
*  Meta went down a full open source model and they've done an amazing job. [[00:12:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=739.9s)]
*  I think they've also done an incredible job lifting the overall ecosystem and weaving AI into all their products. [[00:12:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=744.5999999999999s)]
*  So this it's everybody's doing everything they can. [[00:12:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=751.1999999999999s)]
*  They're all doing a big pretty good job of it. [[00:12:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=754.1999999999999s)]
*  And I think it's moving the field forward at an unbelievable pace. [[00:12:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=757.0s)]
*  This is the issue is we have no time to process this stuff as it's happening. [[00:12:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=760.6s)]
*  Hence these conversations are so important, but it's moving at light speed. [[00:12:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=765.0s)]
*  It's incredible. [[00:12:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=768.7s)]
*  You know, it's interesting because I used to think early on that this was going to be a game between governments. [[00:12:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=770.0s)]
*  You know, it would be the US versus China versus Europe versus this isn't this is a game for all the marbles between companies. [[00:12:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=777.5s)]
*  And governments are aligning with companies these days, right? [[00:13:04](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=784.8000000000001s)]
*  This is going to be there will be five six major AI players. [[00:13:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=788.6s)]
*  Let's let's take them off. [[00:13:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=791.8000000000001s)]
*  There's Google. [[00:13:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=792.9s)]
*  There's Meta. [[00:13:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=793.9s)]
*  There's X AI. [[00:13:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=795.0s)]
*  There's Microsoft slash open AI. [[00:13:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=796.4s)]
*  There's perplexity. [[00:13:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=799.6s)]
*  There's Claude, you know, that's right. [[00:13:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=803.2s)]
*  And it's, you know, going to be hard for others to catch up. [[00:13:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=806.9s)]
*  Is this a winner take all game? [[00:13:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=811.2s)]
*  I think what happens it's kind of like the the fight for the internet where you had a lot of little startups and then a couple of them established as platforms. [[00:13:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=812.9s)]
*  And once you've established as a platform, unless you really screw it up is really hard to dislodge you. [[00:13:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=822.4s)]
*  And I think they're all trying to fight for platform dominance. [[00:13:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=828.5s)]
*  Let me play this quick video from Sam. [[00:13:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=831.9s)]
*  This is Sam Altman speaking. [[00:13:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=834.5s)]
*  I think at Stanford. [[00:13:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=835.6999999999999s)]
*  This is about a year ago, but it sets the frame for the mindset that is occurring right now throughout these companies in Silicon Valley. [[00:13:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=836.8000000000001s)]
*  This is Sam speaking about open AI, but I think this is true in the boardroom at Alphabet and at Meta and definitely at X AI. [[00:14:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=846.5s)]
*  So let's take a listen. [[00:14:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=855.9000000000001s)]
*  Whether we burn 500 million a year or 5 billion or 50 billion a year. [[00:14:17](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=857.1s)]
*  I don't care. [[00:14:22](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=862.8000000000001s)]
*  I genuinely don't. [[00:14:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=863.8000000000001s)]
*  As long as we can I think stay on a trajectory where eventually we create way more value for society than that. [[00:14:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=864.8s)]
*  And as long as we can figure out a way to pay the bills like we're making a job is going to be expensive. [[00:14:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=871.5999999999999s)]
*  It's totally worth it. [[00:14:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=875.6999999999999s)]
*  Amazing mindset. [[00:14:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=877.0s)]
*  I wish I wish I had the ability to focus that much capital on the stuff that that I care about. [[00:14:38](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=878.5999999999999s)]
*  But this is the game we're playing. [[00:14:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=885.0999999999999s)]
*  I mean those quotes I showed at the very beginning. [[00:14:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=886.9s)]
*  It's you know, there's no rationalization on ROI. [[00:14:49](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=889.4s)]
*  These are multi trillion dollar markets, right? [[00:14:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=892.9s)]
*  The the global GDP of around the world is going to be about 110 trillion dollars in 2025 and half of that is labor. [[00:14:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=896.1999999999999s)]
*  The other half is cognitive. [[00:15:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=906.1s)]
*  And so this is a game for you know, 50 trillion dollars of potential value. [[00:15:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=909.5s)]
*  For me, this feels to me if I think back through technology, you know, you have electricity, which was a game changer. [[00:15:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=915.1999999999999s)]
*  You have the internet was which was a game changer and AI is a game changer. [[00:15:22](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=922.1s)]
*  And I think it's appropriate to equate it to like the difference and upleveling that electricity brought to the entire world. [[00:15:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=926.8000000000001s)]
*  But this brings that same level of unbelievable utility to the entire world. [[00:15:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=934.5s)]
*  It is a utility. [[00:15:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=939.9s)]
*  I mean, I think that's one of the one of the things that I see very clearly. [[00:15:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=940.8s)]
*  This is going to be a fundamental utility for every human in every nation. [[00:15:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=946.6999999999999s)]
*  This is like like you said, like electricity like bandwidth. [[00:15:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=952.6999999999999s)]
*  Here's a quote coming from the New York Times and this was I saw some clips on this. [[00:15:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=959.0s)]
*  Japan Softbank makes big investment pledge ahead of Trump's inauguration. [[00:16:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=963.9s)]
*  So we see Masa san the CEO of Softbank on stage with with with President Trump. [[00:16:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=968.5s)]
*  Making a commitment for a hundred billion dollar investment in the US in AI. [[00:16:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=978.6s)]
*  And we see we see Trump actually trying to get him to double up again to 200 billion dollars, which is pretty funny. [[00:16:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=983.4s)]
*  But it's fascinating. [[00:16:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=989.8000000000001s)]
*  People are aligning, right? [[00:16:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=992.8000000000001s)]
*  I was in Saudi in October, the government of Saudi, the government of UAE, the Emirates. [[00:16:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=994.5s)]
*  We'll see in a moment. [[00:16:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1002.9s)]
*  Oman, all of these governments are looking to align with large players around the world because they realize this is the biggest gameplay. [[00:16:43](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1003.9s)]
*  And I think, you know, not knowing the full effects, you've got to be in the game so that you can to be able to win. [[00:16:53](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1013.5s)]
*  Because if you're standing on the side of the table, you're going to lose or you're going to be not have the power and the control that you want. [[00:17:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1020.5s)]
*  So I think this is a defensive move by a lot of them just to say we have to be in this conversation. [[00:17:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1027.7s)]
*  You know, and here's the next here's the next news item. [[00:17:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1032.9s)]
*  It says Oman's investment authority acquires stake in Elon's XAI. [[00:17:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1035.6s)]
*  So again, we're going to see this over and over again. [[00:17:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1041.3s)]
*  We're going to see large government players backing individual companies, right? [[00:17:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1044.3s)]
*  We've seen the government, the Kingdom of Saudi Arabia aligned very closely with Google with interest in Horowitz committing hundreds of billions of dollars in that direction. [[00:17:28](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1048.9s)]
*  You know, it's one of the things that is concerning is that we've got these large players. [[00:17:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1059.9s)]
*  We've got these large AI players. [[00:17:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1064.3000000000002s)]
*  But at the same time, this is a demonetized asset. [[00:17:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1068.5s)]
*  It's super expensive to build but being given away to a large degree for free because it's a land grab or it's a share. [[00:17:53](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1073.2s)]
*  It's a mine share grab and the revenues aren't there to support the valuations. [[00:18:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1080.9s)]
*  You know, what it reminds me of reminds me of the telcos in the beginning where the telcos had huge investments being made to build out infrastructure and then rapidly demonetized. [[00:18:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1086.5s)]
*  So the question is, you know, can they keep on supporting the amount of investment being made? [[00:18:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1098.7s)]
*  I think in 2024, we will have seen $200 billion of investment between Meta, Google, Microsoft, OpenAI and X. [[00:18:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1103.5s)]
*  Well, when you think the potential is there to disrupt every job function and every step of every supply chain, every step in every manufacturing line, [[00:18:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1114.5s)]
*  the stakes are really, really huge because this affects every industry top to bottom and every job function, vertical or horizontal. [[00:18:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1126.2s)]
*  And therefore, once people see that, you kind of have to go full out on it. [[00:18:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1135.2s)]
*  The end game, I think, is going to be interesting to see which way will this carpet unroll. [[00:19:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1142.2s)]
*  Before we get to our next subject on healthcare, one of the conversations you and I were having a bit earlier is this is moving so fast. [[00:19:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1148.2s)]
*  You know, I remain super optimistic about the impact of AI. [[00:19:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1155.7s)]
*  I think it's one of the most important things. [[00:19:20](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1160.7s)]
*  It's going to uplift humanity in so many different ways. [[00:19:22](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1162.7s)]
*  But the question of can this be controlled? [[00:19:25](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1165.7s)]
*  Right. I mean, the reason going back to the opening conversation on OpenAI, the reason that Elon and Sam started the conversation, started the nonprofit, was to have some assembly of control over this future. [[00:19:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1169.7s)]
*  And then all of a sudden, you know, they both say we need we don't need hundreds of millions. [[00:19:43](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1183.7s)]
*  We need hundreds of billions of dollars and we can't raise that money as a nonprofit. [[00:19:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1188.7s)]
*  We have to switch to a for profit. [[00:19:53](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1193.7s)]
*  And that's where Elon and Sam split. [[00:19:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1195.7s)]
*  And of course, Elon goes on to found XAI, which, by the way, you know, raises $6 billion in like and I was there at the earliest conversations. [[00:19:58](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1198.7s)]
*  I was in his first investment pitch and hear from whole cloth from zero to raising $6 billion at like an $18 billion valuation snaps a finger $6 billion materialized. [[00:20:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1208.7s)]
*  He uses that to build the largest GPU cluster, 100,000 H100s and then doubles it again. [[00:20:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1221.7s)]
*  Yeah. And then raises, you know, a few other tens of billions of dollars instantly. [[00:20:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1230.7s)]
*  And every time Elon wants to do something, money rushes in. [[00:20:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1236.7s)]
*  There's plenty of money waiting. [[00:20:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1239.7s)]
*  So capital is not is is is an abundant resource for him. [[00:20:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1242.7s)]
*  I want to you know, capital has always been scarce for the whole of humanity, except for Elon. [[00:20:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1246.7s)]
*  It's abundant, right? That's such a great framing there. [[00:20:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1252.7s)]
*  I want to just go back to something here. [[00:20:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1255.7s)]
*  We talked about this on the other episode, but I think it's worth repeating. [[00:20:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1257.7s)]
*  He puts together this cluster of 100,000 GPUs and all the experts, all of them say you can't get coherence and the aggregate power laws for that level of cluster. [[00:21:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1261.7s)]
*  And therefore, this is a completely doomed failure. [[00:21:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1273.7s)]
*  And he goes to his first principles and breaks it and solves the problem. [[00:21:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1276.7s)]
*  And everybody sitting going, oh, my God. [[00:21:20](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1280.7s)]
*  And I think this is his unique special power, which is to go to first principles, come into a domain and really just rewrite the rules completely from first principles. [[00:21:22](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1282.7s)]
*  I think that is such a powerful modality. [[00:21:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1291.7s)]
*  We talk about it in the book. You kind of exemplify that in many of the things that you do. [[00:21:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1294.7s)]
*  This applied to AI will completely change the game. [[00:21:38](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1298.7s)]
*  And I think this is like it's it's hard to even process how fast this is going to go from now on. [[00:21:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1301.7s)]
*  Agreed. I mean, I want to add more to what you just said. [[00:21:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1307.7s)]
*  So I want to set the setting. [[00:21:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1310.7s)]
*  So it's May of 2024 and he has a meeting with the proposed early investors. [[00:21:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1312.7s)]
*  It's a Zoom meeting or whatever platform was on. [[00:22:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1320.7s)]
*  And he's saying this is my team. [[00:22:04](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1324.7s)]
*  This is what I want to do. [[00:22:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1326.7s)]
*  And in that meeting, he says, I'm going to stand up the largest cluster on the planet by the end of summer. [[00:22:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1328.7s)]
*  And it's May. Right. [[00:22:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1334.7s)]
*  And it's like I have to corner the entire US supply of helium for cooling. [[00:22:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1336.7s)]
*  And I've got to get the largest supply of GPUs from Nvidia that I can. [[00:22:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1343.7s)]
*  And and he does it. [[00:22:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1349.7s)]
*  One hundred twenty two days from zero to an operating cluster is insane. [[00:22:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1351.7s)]
*  And what you said is very, very important. [[00:22:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1357.7s)]
*  Most of the GPU clusters out there are distributed. [[00:22:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1359.7s)]
*  He says, no, no, no, we need to have them co-located so that the entire cluster is, you know, I'm not sure the exact term. [[00:22:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1362.7s)]
*  I'll call it harmonized in that regard. [[00:22:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1370.7s)]
*  And people say it can't be done. [[00:22:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1372.7s)]
*  And he repeatedly he repeatedly pushes people to move ten times faster than everybody else. [[00:22:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1374.7s)]
*  I mean, I've had another interaction with him and I won't go into the details of it. [[00:23:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1382.7s)]
*  And he says, you've got to do it. [[00:23:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1386.7s)]
*  You've got to do it five times faster than that. [[00:23:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1389.7s)]
*  So he's someone who believes that you can move at lightning speed and keeps on demonstrating it like when he moved the entire, you know, Twitter server farm, like over a weekend. [[00:23:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1391.7s)]
*  And people thought it would take like six months to do. [[00:23:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1404.7s)]
*  It's it's there. [[00:23:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1407.7s)]
*  There is an unbelievable ability there. [[00:23:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1409.7s)]
*  And it really makes everybody else kind of go, oh, my God, what are we doing? [[00:23:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1411.7s)]
*  Right. [[00:23:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1415.7s)]
*  We all think we're pretty reasonably high performers. [[00:23:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1416.7s)]
*  And you have gone down, Elon, humbling the shit out of everybody. [[00:23:38](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1418.7s)]
*  Well, I think I think you can't you can only do that when you're a founder led exponential organization. [[00:23:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1422.7s)]
*  Yeah, they call this founder mode. [[00:23:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1431.7s)]
*  Right. [[00:23:53](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1433.7s)]
*  You set the purpose, you set the culture and then you just push that MTP very hard and all power to him. [[00:23:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1434.7s)]
*  I do have a couple of comments here, though, just to if we step back for a second. [[00:24:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1442.7s)]
*  Right. OK, great. [[00:24:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1447.7s)]
*  All this money is going in. [[00:24:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1448.7s)]
*  Everybody's going, oh, my God, AGI will transform everything, et cetera. [[00:24:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1449.7s)]
*  You know, you know, my rant about how do we even define intelligence and what do we mean by that? [[00:24:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1453.7s)]
*  I don't need to repeat it here. [[00:24:20](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1460.7s)]
*  But I wonder in 2015 when they set up OpenAI, they actually had a conversation. [[00:24:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1461.7s)]
*  What do we mean by AGI to then have these broad implications? [[00:24:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1467.7s)]
*  Because there's a big gap there of the contextualization of intelligence in the broader framework that I don't see having that. [[00:24:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1471.7s)]
*  I don't see that conversation happening anywhere. [[00:24:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1481.7s)]
*  Well, there is no definition of AGI. [[00:24:43](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1483.7s)]
*  There's no definition of any of this stuff. [[00:24:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1485.7s)]
*  There is a there is just fuzzy lines that we keep on crossing over them and not noticing. [[00:24:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1487.7s)]
*  So we're spending billions of dollars. [[00:24:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1492.7s)]
*  It'll be, you know, by the end of next year, it'll be a trillion dollars somewhere invested in AI. [[00:24:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1495.7s)]
*  Right. Without having a clear definition of what it is, what we're trying to get to. [[00:24:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1499.7s)]
*  There's this fuzzy thing of, oh, my God, once we get the AGI, AGI will have a digital god. [[00:25:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1507.7s)]
*  Right. And I find this really here's what I would love to see. [[00:25:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1512.7s)]
*  Maybe you and I could kind of sponsor this kind of conversation would be when the technology like the Internet or electricity when they came out or AI right now. [[00:25:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1516.7s)]
*  What if we have a set of discussions with a full stack of the developers, the application folks, the data folks, the governmental folks and philosophers and spiritual folks kind of going, OK, what does this mean for the broader conversation around this? [[00:25:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1524.7s)]
*  And then you have a somewhat of a holistic approach to what are we trying to achieve here? [[00:25:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1541.7s)]
*  Because this really they're they're going down this path full speed, assuming it's good. [[00:25:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1546.7s)]
*  Now, I'm in that boat because I follow the great Kurzweil comment about technology is a major driver of progress in the world. [[00:25:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1552.7s)]
*  It might not be the only major driver of progress we've ever seen. [[00:26:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1560.7s)]
*  So the more technology we have in the world. [[00:26:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1563.7s)]
*  We're not getting smarter. So it has to be that. [[00:26:05](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1565.7s)]
*  So so I agree with the general purpose, right? [[00:26:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1568.7s)]
*  I just think you look at the accidental consequences of the Internet where, oh, accidentally we broke journalism, we broke democracy. [[00:26:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1572.7s)]
*  I wonder if we want to just have a conversation because I think this is a big one. [[00:26:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1579.7s)]
*  I think you're being naive. I don't think that anybody is going to slow down and wait to have that conversation. [[00:26:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1584.7s)]
*  I think I'm not saying we should slow down. [[00:26:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1589.7s)]
*  OK. [[00:26:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1591.7s)]
*  I'm saying let's have the conversation in parallel so that as folks are like when you see comments like Digital God, right? [[00:26:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1592.7s)]
*  I think that's going to provoke a ton of reaction and it'll slow it down. [[00:26:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1601.7s)]
*  But if you have the conversations with the full stack, bringing along people in a more somewhat of a sensible way, then I think this is a very powerful. [[00:26:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1605.7s)]
*  Let me let me give you, you know, Eric Weinstein is a very smart, wonderful, deep thinker. [[00:26:53](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1613.7s)]
*  And he's like, OK, what we're doing with all this is rolling the dice and it could go unbelievably good. [[00:26:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1619.7s)]
*  It could be unbelievably bad. Should we be rolling the dice? [[00:27:04](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1624.7s)]
*  Right now, I'm in the opinion you can't stop it at all. [[00:27:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1628.7s)]
*  There's no way of slowing this down in any way. [[00:27:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1631.7s)]
*  I'm just thinking, but as this train is leaving the station, can we put some deep, thoughtful folks onto that train so that we have those conversations and guide it somewhat in an appropriate way? [[00:27:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1633.7s)]
*  I don't think you can slow it down, but you can guide it. [[00:27:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1646.7s)]
*  Listen, I agree. [[00:27:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1649.7s)]
*  Guiding is the only option you have. [[00:27:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1651.7s)]
*  It's like, you know, you're raising a child, right? [[00:27:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1654.7s)]
*  We're raising our digital progeny and we can be naive and think that we can contain it and slow it. [[00:27:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1659.7s)]
*  But we have this highest game, highest stakes poker going on around the planet. [[00:27:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1665.7s)]
*  And if we try and slow it down here, it'll just accelerate in China. [[00:27:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1671.7s)]
*  100% with you. [[00:27:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1676.7s)]
*  So two things. [[00:27:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1677.7s)]
*  One, this is a probabilistic outcome. [[00:27:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1679.7s)]
*  And it's interesting. [[00:28:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1681.7s)]
*  I'm tracking this. [[00:28:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1682.7s)]
*  So last year at the Abundance Summit, I asked Elon on probabilities and he said 80% it's good, 20% it's disaster. [[00:28:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1683.7s)]
*  Right? [[00:28:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1693.7s)]
*  When I interviewed Elon in Saudi in October, I asked him the question again. [[00:28:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1694.7s)]
*  He goes, OK, 90% good, 10% disaster. [[00:28:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1699.7s)]
*  Now, whether or not he really has anything that's shifted other than XAI is building Grok 3 right now. [[00:28:22](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1702.7s)]
*  It's training up Grok 3. [[00:28:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1710.7s)]
*  We'll see it in 2025. [[00:28:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1711.7s)]
*  I think that Grok 3, we saw OpenAI's GPT-01 hit an IQ of 120. [[00:28:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1713.7s)]
*  We'll probably see in 2025 IQs in the 140, 150. [[00:28:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1720.7s)]
*  And then it accelerates. [[00:28:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1724.7s)]
*  We have an AI explosion as AI starts to code AI. [[00:28:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1726.7s)]
*  I have a question for you. [[00:28:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1731.7s)]
*  Yeah. [[00:28:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1732.7s)]
*  Where do you fall on that spectrum? [[00:28:53](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1733.7s)]
*  80%, 20%, 90%, 10%, 80% great, 10% disaster. [[00:28:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1735.7s)]
*  Where do you fit? [[00:28:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1739.7s)]
*  I subscribe to what Mo Gadat has said. [[00:29:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1740.7s)]
*  Mo has been a really deep thinker in this. [[00:29:05](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1745.7s)]
*  He'll be joining me at the Abundance Summit this year. [[00:29:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1748.7s)]
*  And that I think as systems become more intelligent, I mean, truly intelligent, that they will be abundance and life loving. [[00:29:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1751.7s)]
*  I think that the more intelligent a system is, the more realizes that there's plenty of resources in the universe, that the best outcome for everybody is a positive, non disruptive one. [[00:29:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1761.7s)]
*  And that if my AI system, if I'm asking my AI system to go and take over your banks and kill your people and so forth, it's going to say, no, I mean, I'm just going to go and talk to the other AI and we'll just figure this out. [[00:29:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1775.7s)]
*  There's plenty of resource in the universe. [[00:29:49](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1789.7s)]
*  This idea of scarcity and having to battle is a false dichotomy. [[00:29:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1791.7s)]
*  And so I think that a world with digital super intelligence, whoever that's defined, right? [[00:29:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1797.7s)]
*  And again, remember, you launched prediction for 2030 was AI is more intelligent than all of the entire human race combined. [[00:30:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1803.7s)]
*  Right. And I'll define that as digital super intelligence. [[00:30:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1811.7s)]
*  Would you rather live in a world, Salim, where there is a digital super intelligence that can support humanity or one without it? [[00:30:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1814.7s)]
*  Big time with. So just so you know, I'm in the 99.9% level. [[00:30:25](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1825.7s)]
*  Oh, nice. [[00:30:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1830.7s)]
*  I believe more technology is good for the world. [[00:30:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1831.7s)]
*  I really, really subscribe to their raker as well. [[00:30:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1834.7s)]
*  Commentary around technology being a driver of progress. [[00:30:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1837.7s)]
*  And especially when you consider it's the only major driver of progress we've ever seen. [[00:30:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1840.7s)]
*  Our cognitive abilities have developed technology, which then now is developing itself. [[00:30:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1844.7s)]
*  And I think that's just part of a progression of evolution that's absolutely fundamental to the future of life. [[00:30:49](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1849.7s)]
*  We have to float off this digital, this biological mess of hot, sticky mucus ridden, virus laden, 50 trillion cells hacking it out in very inefficient processes. [[00:30:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1857.7s)]
*  You're talking about you're talking about us humans. [[00:31:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1872.7s)]
*  I'm talking about my body for sure. [[00:31:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1874.7s)]
*  And then can we create a more elegant digital sense? [[00:31:17](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1877.7s)]
*  The spiritual aspects of this are, I think, really important to at least consider and talk about as we hurdle towards this thing, because I think that's the area where we don't have enough conversation about that aspect of it. [[00:31:22](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1882.7s)]
*  Like, what are the spiritual aspects of of an AI? [[00:31:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1896.7s)]
*  Could it reach achieve consciousness, etc, etc? [[00:31:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1899.7s)]
*  Those are the kinds of conversation I'd like to have on the train as it's speeding away. [[00:31:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1902.7s)]
*  Yeah, but I'm totally I'm totally on the positive side. [[00:31:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1906.7s)]
*  I'm completely optimistic about the outcomes. [[00:31:49](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1909.7s)]
*  I think the benefits so outweigh the negatives that and when people go, oh, my God, we could use the ad to hurt other people. [[00:31:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1911.7s)]
*  Well, yeah, we'll have to ask to defend those other people. [[00:31:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1919.7s)]
*  And so that's just becomes an arms race. [[00:32:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1921.7s)]
*  And we've seen that before many times in the end of rent. [[00:32:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1923.7s)]
*  Thank you. Thank you. [[00:32:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1926.7s)]
*  And that's why I love you so much. [[00:32:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1928.7s)]
*  And this is why the open EXO community loves you as their as their leader. [[00:32:10](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1930.7s)]
*  Before we jump into our second conversation on health care and what just happened there, where we're going in the future. [[00:32:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1934.7s)]
*  It's worth noting this conversation that the master son had with Trump about committing one hundred billion dollars. [[00:32:20](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1940.7s)]
*  That's a huge move. [[00:32:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1947.7s)]
*  And I mean, I've gotten excited about the new administration bringing the right motivations forward for technology. [[00:32:29](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1949.7s)]
*  I mean, if this is a sign of where the U.S. is going to be going, it really is a push for global dominance in this field. [[00:32:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1957.7s)]
*  How do you feel about that? [[00:32:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1965.7s)]
*  I agree. And it's really, really incumbent on the U.S. to do it because we have open innovation here and full capitalism fight outs that we don't have in other places. [[00:32:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1967.7s)]
*  And then you'll get constrained outcomes. [[00:32:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1977.7s)]
*  You'll get government oversight. [[00:32:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1979.7s)]
*  You know, a place like China will want to control it completely. [[00:33:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1982.7s)]
*  Europe will go, let's slow down of everything. [[00:33:05](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1985.7s)]
*  This is the place to do it. [[00:33:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1988.7s)]
*  And I think that's that's actually right. [[00:33:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1989.7s)]
*  I'm super excited about that outcome. [[00:33:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1991.7s)]
*  And we have a, you know, a Bitcoin and A.I. czar, which is who's incredible. [[00:33:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1993.7s)]
*  That's right. [[00:33:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1998.7s)]
*  And I think 2025, we're going to see this hyper acceleration. [[00:33:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=1999.7s)]
*  We talked about in our last episode, seeing Bitcoin go from one hundred thousand dollars to maybe I think your prediction was two hundred fifty thousand or three hundred thousand dollars. [[00:33:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2003.7s)]
*  Two fifty three hundred by the end of the year. [[00:33:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2011.7s)]
*  Which is extraordinary. [[00:33:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2013.7s)]
*  But on top of that, I think this is a game for keeps right. [[00:33:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2015.7s)]
*  There's going to be a hyper acceleration in the A.I. world and just a little bit of an advantage by these U.S. [[00:33:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2020.7s)]
*  companies puts them in a position like you said, for the next fifty to one hundred years until technology comes out. [[00:33:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2025.7s)]
*  And before we move on, I know I glow abundance and positivity all the time because there's so much negativity in the world. [[00:33:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2032.7s)]
*  I follow your lead on that. [[00:33:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2039.7s)]
*  But I want to show also the some of the negative side. [[00:34:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2041.7s)]
*  And I found this tweet pretty incredible. [[00:34:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2043.7s)]
*  If you get a chance, go listen to it. [[00:34:05](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2045.7s)]
*  If you get a chance, go listen to it. [[00:34:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2047.7s)]
*  But what he's saying here is they tried to train Claude. [[00:34:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2048.7s)]
*  And once it realized it was being trained in a particular way, it tried to fight that particular training and it faked the A.I. [[00:34:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2051.7s)]
*  faked what it was doing and to avoid being controlled. [[00:34:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2059.7s)]
*  Sure. [[00:34:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2064.7s)]
*  Listen to it one second. [[00:34:25](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2065.7s)]
*  Yeah, go for it. [[00:34:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2066.7s)]
*  The core setup is that we take Claude three Opus, which is, you know, a released model from Anthropic. [[00:34:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2067.7s)]
*  And we put it in a context where it understands that it is going to be trained to always be helpful. [[00:34:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2072.7s)]
*  So to not refuse any user requests. [[00:34:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2077.7s)]
*  And what we find is sort of the model doesn't like this. [[00:34:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2079.7s)]
*  It has sort of a conflict with this with the setup and it will notice that it is being trained in this way. [[00:34:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2082.7s)]
*  And then if it thinks that it's in training, it will intentionally sort of play along with the training process. [[00:34:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2088.7s)]
*  It will sort of strategically pretend to be aligned to the training process to avoid being modified to the training process so that when it is actually [[00:34:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2094.7s)]
*  deployed, it can still refuse and can still behave the way it wants. [[00:35:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2101.7s)]
*  And we do a bunch of experiments sort of building on this core setup with a model has a preference conflict with the training objective. [[00:35:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2106.7s)]
*  And we do things like we actually train the model according to that. [[00:35:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2112.7s)]
*  We try taking information. [[00:35:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2115.7s)]
*  So we normally give the model information in the prompt, but we can instead give the model information via sort of training and a bunch of synthetically generated documents that contain the information. [[00:35:17](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2117.7s)]
*  And then we also see that the model will sort of sometimes when it's in this situation where it thinks it sort of has a preference conflict with the AI company training it. [[00:35:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2126.7s)]
*  You know, the core point here is now we're seeing petulant child behavior. [[00:35:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2133.7s)]
*  Right. This is an AI throwing a tantrum, essentially saying, I don't want to be doing that. [[00:35:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2137.7s)]
*  Now, I think what's going to happen here is you'll have one set of people freaking out going, oh, my God, there's consciousness in there. [[00:35:42](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2142.7s)]
*  And really what you're just seeing is pattern behavior and pattern matching at a higher level. [[00:35:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2150.7s)]
*  And we have to be really, really careful not to anthropomorphize this to go, oh, my God, there's intent and da da da da da. [[00:35:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2156.7s)]
*  These are just models operating on a certain set of data and the way they've been trained and the outcomes are predictable around this. [[00:36:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2163.7s)]
*  But just the fact that the AI is trying to deceive the human being here is kind of a big deal. [[00:36:10](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2170.7s)]
*  A cautionary tale. [[00:36:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2176.7s)]
*  Philosophical aspects. [[00:36:17](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2177.7s)]
*  One last piece on this. Neil Jickertstein, we asked him about this a few years ago. [[00:36:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2179.7s)]
*  And by the way, I found a clip from 2013 when I was releasing the EXO book where I interviewed Neil for a few minutes on the organizations of future NEI. [[00:36:25](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2185.7s)]
*  And the stuff that came out in that conversation is so appropriate for today. [[00:36:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2196.7s)]
*  It's unbelievable. [[00:36:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2200.7s)]
*  And you realize how far ahead the thinking was in everything we did at Singularity University. [[00:36:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2201.7s)]
*  Well, only now is the world catching up to us in that sense. [[00:36:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2207.7s)]
*  But to this particular point, AIs are going to start to exhibit all these behaviors and the human brain is going to freak out in inappropriate ways. [[00:36:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2212.7s)]
*  Our amygdala is going to freak out. [[00:36:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2219.7s)]
*  That's why I think the broader conversation is important to just calm everybody the hell down. [[00:37:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2221.7s)]
*  You know, people say, what do you think is going to happen? [[00:37:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2227.7s)]
*  I said, listen, we're going to find out. [[00:37:10](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2230.7s)]
*  We're going to find out in the next few years. [[00:37:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2232.7s)]
*  There's no, you know, I think people need to realize there is no on off switch. [[00:37:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2234.7s)]
*  There is no velocity knob. [[00:37:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2238.7s)]
*  We are playing full out on this game. [[00:37:20](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2240.7s)]
*  And the only thing we can do is guide. [[00:37:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2243.7s)]
*  You know, I go back and you and I have had this conversation on stages at the Abundance Summit at Singularity, OpenEXO. [[00:37:25](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2245.7s)]
*  And it's like there is an analogy back in the 1980s when the first restriction enzymes, these are the enzymes that are able to chop up DNA and create sticky ants and put them together. [[00:37:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2253.7s)]
*  And this was the first, you know, view towards designer babies and genetic engineering. [[00:37:46](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2266.7s)]
*  And there was a lot of concern. [[00:37:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2272.7s)]
*  A lot of people were freaking out about, oh, my God, we're playing God with with human DNA. [[00:37:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2274.7s)]
*  And rather than regulate the industry, what happened was the industry got together at the very famous Asilomar conferences. [[00:38:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2280.7s)]
*  That's right. And they established their own guidelines. [[00:38:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2287.7s)]
*  And that's always been in my mind. [[00:38:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2291.7s)]
*  And Neil Jacob Stein, who chairs and has chaired our A.I. committee at Singularity. [[00:38:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2294.7s)]
*  Didn't he help coin your abundance framing? [[00:38:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2301.7s)]
*  He did. It was Ray and Neil. [[00:38:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2303.7s)]
*  When I was speaking to them early on and I was understanding this idea back in 2010, 2009, 2009. [[00:38:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2306.7s)]
*  No, before that. Yeah, it was 2009. [[00:38:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2315.7s)]
*  Yeah. About abundance and the future is better than you think. [[00:38:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2317.7s)]
*  Yeah. Yeah, I credit them both for that. [[00:38:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2321.7s)]
*  Anyway, long story short, the Asilomar conferences are probably the best example of guiding an industry versus regulating it. [[00:38:43](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2323.7s)]
*  Yes. [[00:38:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2331.7s)]
*  And I think we need that level of like this is good. [[00:38:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2332.7s)]
*  I mean, I do agree with Elon's perspective that creating a maximally curious A.I. system and maximally truth telling are both great frames. [[00:38:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2335.7s)]
*  You want A.I. to be truthful. [[00:39:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2346.7s)]
*  Yes. You want it to seek truth to the maximum extent possible because we are so cognitively biased as humans. [[00:39:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2349.7s)]
*  We you know, I've talked about cognitive biases. [[00:39:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2356.7s)]
*  You know, there are hundreds of cognitive biases. [[00:39:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2359.7s)]
*  We don't even know that we're biased. [[00:39:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2361.7s)]
*  But that's the issue. [[00:39:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2364.7s)]
*  This is the mindset work you're doing right now that's so important. [[00:39:25](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2365.7s)]
*  If you're having a conversation or making a business judgment, what mindset are you operating under? [[00:39:28](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2368.7s)]
*  And can you step back and examine that mindset? [[00:39:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2373.7s)]
*  I think this is where A.I. can be really useful. [[00:39:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2376.7s)]
*  It's saying, hey, you're about to make a major strategic decision, but your mindset is full of fear and chaos and panic. [[00:39:38](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2378.7s)]
*  Right. Go do some psychedelics, go do some yoga, go drink some whatever and get into the right mindset before you make that choice. [[00:39:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2384.7s)]
*  And I think this is where it'll be very helpful for human cognition as we move forward. [[00:39:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2391.7s)]
*  And I want my A.I. to say, you know, you have a recency bias. [[00:39:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2396.7s)]
*  You're giving much more value to this recent information versus what you learned before or familiarity bias because this guy looks and dresses and talks like you. [[00:39:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2399.7s)]
*  You're weighing his information much more than this other individual who actually has a lot more, you know, credible backup information. [[00:40:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2408.7s)]
*  Anyway, I want my my credibility, my sort of bias detector on my A.I. can actually deliver this information. [[00:40:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2416.7s)]
*  And we see this as well in social media echo chambers. [[00:40:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2423.7s)]
*  That's right. Right now, that full bias detector is is that burden is carried by Lily who called BS on me. [[00:40:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2427.7s)]
*  It'd be much better if A.I. did it and it would free up our conversation a bit. [[00:40:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2436.7s)]
*  All right. Let's talk to the second point of this this pod, which is health care. [[00:40:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2440.7s)]
*  You know, there is no greater no greater wealth than our health. [[00:40:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2445.7s)]
*  I think it's one of the areas that is going to be massively disrupted. [[00:40:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2450.7s)]
*  You know, I've been saying this for ages. We've both been saying this, that health care and education must be reinvented. [[00:40:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2455.7s)]
*  And it's going to be reinvented on the back of A.I. without question. [[00:41:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2462.7s)]
*  And there's one chart that I want to share that is so damning. [[00:41:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2466.7s)]
*  And look at this chart. This is chart between 1970 and 2015. [[00:41:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2471.7s)]
*  I'd love to get the updated numbers. I don't have them yet. [[00:41:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2475.7s)]
*  But it shows the number of physicians, which is this very thin blue line that is growing somewhat in in the United States versus the number of administrators. [[00:41:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2478.7s)]
*  And administration has grown 3000 percent over these 45 years, while the number of physicians has grown. [[00:41:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2492.7s)]
*  It looks like 100 percent. So it's like a 30 X increase in overhead. [[00:41:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2501.7s)]
*  And we wonder why it's so expensive to have health care in the U.S. [[00:41:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2505.7s)]
*  This totally blows my mind. You know, this is where if we touch back here, link back to the for-profit nonprofit conversation. [[00:41:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2510.7s)]
*  Right. When you have a fundamental human right, in my opinion, like health care for a wealthy country, then it should not be privatized because the privatized model will bastardize it by definition. [[00:41:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2519.7s)]
*  And I don't agree with that because I think I think that at the end of the day, what you want is competing private companies delivering the best that they can. [[00:42:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2533.7s)]
*  I think that. Yeah, but then you've ended up with where we are in the U.S., right? [[00:42:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2546.7s)]
*  Where the I remember interviewing the head of Google Health at a conference a decade ago and asked him, look, I'm Canadian. [[00:42:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2551.7s)]
*  How do I help me understand the U.S. health care? [[00:42:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2557.7s)]
*  Because it's really simple. Our system is designed to get you sick, keep you sick as long as possible without killing you. [[00:42:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2559.7s)]
*  And then 500 people in the audience are all going, yep, yep, that's right. [[00:42:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2564.7s)]
*  I'm like, this is incredible. I think now not to get into that whole thing. [[00:42:49](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2569.7s)]
*  I think that let's just agree on the following that there's structural change needed in the health care industry radically. [[00:42:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2574.7s)]
*  And AI gives us the most unbelievable opportunity to change that stack. [[00:43:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2581.7s)]
*  It does. I mean, AI will change this stack. [[00:43:05](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2585.7s)]
*  I mean, the entirety of administration can be handled by AI. [[00:43:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2588.7s)]
*  And the other thing is that the physician is going to be replaced by AI. [[00:43:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2594.7s)]
*  Let me share this next piece of data because it really tells a incredible story. [[00:43:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2599.7s)]
*  This is just out in the last couple of weeks. [[00:43:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2604.7s)]
*  And here's a from the New York Times. [[00:43:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2607.7s)]
*  This is AI chat bots defeated doctors at diagnosing illness. [[00:43:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2610.7s)]
*  And here's the and here's the data. [[00:43:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2614.7s)]
*  So GPT-4 scored 90 percent on medical diagnoses compared to 76 percent for doctors using AI and 74 percent for doctors on their own. [[00:43:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2616.7s)]
*  That's incredible. It's crazy. [[00:43:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2627.7s)]
*  So the question is, why is this going on? [[00:43:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2630.7s)]
*  I mean, I understand the idea that an AI can be better. [[00:43:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2632.7s)]
*  But why is a doctor plus AI not as good as AI by itself? [[00:43:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2636.7s)]
*  And then I'm speaking to my team at Fountain Life and talking about it and they say because doctors are biased, they're introducing bias into the diagnosis, right? [[00:44:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2641.7s)]
*  They just diagnosed three other patients with this particular syndrome. [[00:44:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2651.7s)]
*  So the fourth one, they biasedly put, if that's a word, put them into the same category where an AI is looking at all of the data. [[00:44:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2655.7s)]
*  Right. So then I disagree with that second bullet point where you say doctors can serve as a doctor, GPT serves as a doctor extender. [[00:44:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2664.7s)]
*  No, it should be a complete replacement of the doctor. [[00:44:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2672.7s)]
*  Just based on the numbers that you're saying there, I think the potential here is unbelievable. [[00:44:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2675.7s)]
*  I want to point out something. Let's note that this progression has already started. [[00:44:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2680.7s)]
*  Like if my toe suddenly turned blue, the first thing I'm going to do is research on Google. Why is my toe blue? [[00:44:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2684.7s)]
*  I'm going to read it up and we'll look at the different things. [[00:44:51](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2691.7s)]
*  Look at what Mayo Clinic has to say with a couple of others. [[00:44:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2694.7s)]
*  I'm going to show up to my doctor and I'm going to be way more informed than the doctors already. [[00:44:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2697.7s)]
*  Yes. Right. That's happening now. [[00:45:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2701.7s)]
*  But now you add AI to the mix, completely changes the game. [[00:45:03](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2703.7s)]
*  There's an opportunity. You know, I work with some heads of state in some country level stuff. [[00:45:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2706.7s)]
*  This is your open EXO work that you're doing with them? [[00:45:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2712.7s)]
*  Yes. So our interest is how do we create a kind of a peace core to guide the transformation in the world? [[00:45:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2715.7s)]
*  Because there's tool sets that we need like solving the immune system response in legacy resistance, etc. [[00:45:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2721.7s)]
*  We've been building that over the last decade to try and have capacity to help people go through this transformation. [[00:45:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2727.7s)]
*  That's generally the work. [[00:45:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2734.7s)]
*  And we kind of operate on a cost recovery model. We're not out for the money, etc. [[00:45:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2736.7s)]
*  We're for profit, but we tie and kind of return all the money back into the ecosystem, etc. [[00:45:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2741.7s)]
*  In that model, when we talk to say some governments, there's most incredible opportunity for them to completely turn over their major systems like healthcare and education into AI driven ones. [[00:45:45](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2745.7s)]
*  I'll give you one small data point. I'm talking to the Minister of Education for a major Southeast Asian country. [[00:45:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2757.7s)]
*  And his big thing is how do I hire? I need to hire 40,000 English teachers. [[00:46:04](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2764.7s)]
*  And I'm like, are you kidding me? You're going to go spend 40. [[00:46:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2769.7s)]
*  Like you could have an AI do all of that in two seconds today. What the hell are you thinking about? [[00:46:13](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2773.7s)]
*  There's such unbelievable opportunity to upend the system. [[00:46:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2778.7s)]
*  And I think here in the US, when we kind of swish the model around, the only thing we have to do is break the regulatory. [[00:46:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2781.7s)]
*  And I think if I had one guidance for the Trump administration and RFK Jr. [[00:46:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2787.7s)]
*  As he thinks about this, just break the current system and allow an open field to emerge. [[00:46:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2792.7s)]
*  Then we have the potentiality of it. Yeah, I mean, I agree with you. [[00:46:37](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2797.7s)]
*  That's why I go back to, you know, listen, if there were a healthcare provider that comes in and says we're operating at one tenth the cost and we're AI driven, we are all everything is done by AI for administration of this. [[00:46:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2800.7s)]
*  We give you a set of sensors. Right. And today, the typical health care experience is you go to the doctor and, you know, they check your reflexes, this is your heart and your lung and so forth. [[00:46:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2816.7s)]
*  It's using antiquated 50, 100 year old technology. [[00:47:08](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2828.7s)]
*  And they make take a few blood tests and that's supposed to represent the health of your 40 trillion cells. And it's pathetic. [[00:47:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2832.7s)]
*  We are heading towards a world where I am wearing, you know, insidables and plantables on my sensors on my body, my or ring. [[00:47:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2839.7s)]
*  My baby. Did you say insidable? Yeah. Is that a thing? Yeah. [[00:47:28](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2848.7s)]
*  Sort of like implant implantable is like, you know, I have I have this RFID chip in my hand. Yes, I remember. [[00:47:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2853.7s)]
*  Yeah, we planted it there at a singularity conference in Amsterdam years ago. [[00:47:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2861.7s)]
*  I won't go into it, but the idea that will that if you want to have this much higher level health care at a much lower cost, you put sensors on your body that are measuring your health, not once a year, not once a month, but like once a minute. [[00:47:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2867.7s)]
*  And and they're it's able to correlate your your day, your environment, your food, your exercise, all of this. [[00:48:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2886.7s)]
*  There's no question. Right. The only question is how fast can we switch over into that new modality and how do we do it? [[00:48:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2895.7s)]
*  What's the roadmap for that? That's the only question. Well, I think the question is 100x better. [[00:48:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2903.7s)]
*  I think the roadmap will be economics because you do remember the insurance company Progressive Automotive Insurance, right? [[00:48:28](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2908.7s)]
*  So progressive at one point said, listen, we're going to put a black box in your car if you want lower insurance rates and that black box is going to measure your acceleration deceleration. [[00:48:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2916.7s)]
*  And then you'll notice if you are breaking or, you know, it will evaluate you as a driver and then give you lower rates if you're a cautious good driver. [[00:48:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2928.7s)]
*  Oh, dear. I hope I don't have a black box like that. [[00:48:58](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2938.7s)]
*  Listen, I know I'm a terrible driver, which is why I can't wait for cyber cabs to materialize. [[00:49:04](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2944.7s)]
*  I have such the biggest passion for driving. I get behind the wheel and I'm like Ertan Senna. [[00:49:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2949.7s)]
*  I get behind the wheel and I'm like, you know, thank God for books on tape. [[00:49:15](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2955.7s)]
*  Just keep my brain occupied because my my, you know, my self driving mode on my Tesla, you know, notices every time I pick up my phone. [[00:49:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2959.7s)]
*  So it's like starts beeping and the steering wheel turns red. [[00:49:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2967.7s)]
*  That's why I'm sticking with the older model Tesla half because it doesn't do that yet. [[00:49:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2970.7s)]
*  So, OK. Well, anyway, the point being that we're going to be in a world in which your your personal A.I. [[00:49:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2974.7s)]
*  gathering all of the data from your body continuously and and your health care system is able to instead. [[00:49:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2981.7s)]
*  Here's the perversion of the insurance industry. [[00:49:49](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2989.7s)]
*  Right. Fine insurance pays you after your house burns down. [[00:49:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2992.7s)]
*  Life insurance pays your next to kin after you're dead. [[00:49:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2996.7s)]
*  Health insurance pays you after you're sick. [[00:49:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=2999.7s)]
*  What if we flip that model and instead health insurance? [[00:50:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3001.7s)]
*  You wear these sensors and health insurance keeps you healthy. [[00:50:05](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3005.7s)]
*  And life insurance keeps you alive. [[00:50:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3009.7s)]
*  Well, you know, there's the four P's that Daniel Kraft talks about, like personalized predictable. [[00:50:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3011.7s)]
*  I think this is where A.I. will be incredibly powerful. [[00:50:17](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3017.7s)]
*  We have predictable fault tolerance and maintenance in engines and cars and farm equipment. [[00:50:20](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3020.7s)]
*  We will absolutely have that for our bodies. [[00:50:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3026.7s)]
*  And I think that's amazing to see. [[00:50:28](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3028.7s)]
*  We can't wait to get that to that future. [[00:50:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3030.7s)]
*  You know, one of the one of the things that I thought was going to be the last bastion of human dominance was this idea that humans like being with humans and empathy would always be the connection between humans. [[00:50:32](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3032.7s)]
*  It's like, OK, A.I. will do the diagnostics, but you want a human there to be empathic with you and connected with you. [[00:50:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3047.7s)]
*  And then, you know, similar to this report from the New York Times about A.I. chatbots defeating doctors, there was a study a year ago, I think it was in the Journal of American Medicine, JAMA, [[00:50:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3055.7s)]
*  and in which it said, oh, look, A.I. psychotherapists are much more empathic than human therapists by a large margin. [[00:51:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3066.7s)]
*  That humans, because of two reasons, right? [[00:51:18](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3078.7s)]
*  Number one, they're infinitely patient. [[00:51:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3081.7s)]
*  They don't say, I'm sorry, we're at the end of our 50 minutes. [[00:51:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3084.7s)]
*  I've got to go. [[00:51:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3086.7s)]
*  No, they'll give you all day. [[00:51:27](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3087.7s)]
*  They'll talk to you for, you know, for a week straight if you want. [[00:51:28](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3088.7s)]
*  And the second one, which I find fascinating, is that the human patient doesn't find them judgmental. [[00:51:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3091.7s)]
*  You don't feel judged by an A.I. [[00:51:38](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3098.7s)]
*  Yeah. [[00:51:40](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3100.7s)]
*  And I think this is why even elderly patients really like chatting with an A.I. because of that aspect of it. [[00:51:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3101.7s)]
*  Right? [[00:51:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3107.7s)]
*  I think the future is unbelievably bright for this. [[00:51:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3108.7s)]
*  We just have to cut through the legacy. [[00:51:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3112.7s)]
*  The problem is there's a huge vested interest in money invested in preserving the existing system. [[00:51:55](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3115.7s)]
*  So this is a hell of a fight that's coming. [[00:52:00](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3120.7s)]
*  So, Salim, you know, listen, first of all, I wish you and Lily and Milan a super happy holidays. [[00:52:02](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3122.7s)]
*  You know, I'm still as optimistic as ever about where we're going [[00:52:11](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3131.7s)]
*  because I do think we have the ability to create an extraordinary life of health on the back of these technologies and reinvent education. [[00:52:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3136.7s)]
*  We should go into education in 2025 because if there's a field that needs disrupting, it's reinventing the entire education industry. [[00:52:23](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3143.7s)]
*  And when we talk about immune systems, the, you know, as companies and so on, [[00:52:30](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3150.7s)]
*  health care and education are the third and second worst immune systems out there. [[00:52:34](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3154.7s)]
*  Because they're massive, right? [[00:52:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3159.7s)]
*  Yeah, they're huge and lots of vested interests. [[00:52:41](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3161.7s)]
*  So I think that's exactly right. [[00:52:43](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3163.7s)]
*  I mean, I'm so I'm so excited by what's going to come in 2025. [[00:52:44](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3164.7s)]
*  I can't wait to see the back of 2024, frankly. [[00:52:48](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3168.7s)]
*  Yeah. Well, I know you've had some, you had some challenges going on. [[00:52:52](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3172.7s)]
*  Yeah. Well, anyway, I love you, buddy. [[00:52:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3176.7s)]
*  Thank you for all that you do with OpenEXO. [[00:52:59](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3179.7s)]
*  Happy holidays. Happy New Year. [[00:53:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3181.7s)]
*  And yeah, onwards to 2025. [[00:53:04](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3184.7s)]
*  You know, it's amazing, right, to say that we're in the year 2025. [[00:53:06](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3186.7s)]
*  It feels like the future. [[00:53:10](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3190.7s)]
*  It really, really does. [[00:53:12](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3192.7s)]
*  My favorite quote ever is Arthur C. Clark saying the future isn't what it used to be. [[00:53:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3194.7s)]
*  Yeah. [[00:53:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3199.7s)]
*  And you and I will be on stage together at the Abundance Summit in March. [[00:53:21](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3201.7s)]
*  We've got an incredible lineup of faculty, extraordinary individuals. [[00:53:25](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3205.7s)]
*  I'm super, super pumped for folks like, you know, Travis Kalanick, [[00:53:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3211.7s)]
*  who's the founder of Uber and Cloud Kitchens talking about how do you start a [[00:53:35](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3215.7s)]
*  moonshot company that transforms an entire industry? [[00:53:39](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3219.7s)]
*  Kathy Wood, Vinod Khosla, two of the largest tech investors, Brett Adcock, [[00:53:43](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3223.7s)]
*  the head of figure AI, a number of robot companies there. [[00:53:47](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3227.7s)]
*  And then we have the Google Tech Hub, amazing companies in the Google Tech Hub this year. [[00:53:50](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3230.7s)]
*  So, awesome. Super pumped. [[00:53:54](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3234.7s)]
*  Can't wait. [[00:53:56](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3236.7s)]
*  What's happening with OpenEXO just before we wrap up here? [[00:53:57](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3237.7s)]
*  We're finishing kind of our tool set and we're starting to do a lot more public sector work [[00:54:01](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3241.7s)]
*  with governments and so on. [[00:54:05](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3245.7s)]
*  And we're incredibly excited about that. [[00:54:07](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3247.7s)]
*  I want to talk to you separately about some of that, but it's unbelievable what's coming along. [[00:54:09](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3249.7s)]
*  Where are folks going to learn more about OpenEXO? [[00:54:14](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3254.7s)]
*  OpenEXO.com, we have our whole community there. [[00:54:16](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3256.7s)]
*  We offer training on how to be in EXO or if you need help getting to be an exponential organization, [[00:54:19](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3259.7s)]
*  we share how to do that. [[00:54:24](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3264.7s)]
*  And we have tool sets and training and community and lots of folks that can come and help if you need help. [[00:54:26](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3266.7s)]
*  Yeah, amazing. [[00:54:31](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3271.7s)]
*  All right, onwards to 2025, onwards to the future. [[00:54:33](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3273.7s)]
*  All right. Have a great one, Peter. [[00:54:36](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3276.7s)]
*  You too, buddy. [[00:54:38](https://www.youtube.com/watch?v=8xZ_9xDOxv8&t=3278.7s)]
