---
Date Generated: June 03, 2025
Transcription Model: whisper medium 20231117
Length: 8256s
Video Keywords: ['peter diamandis', 'longevity', 'xprize', 'abundance']
Video Views: 17567
Video Rating: None
Video Description: Get access to metatrends 10+ years before anyone else - https://qr.diamandis.com/metatrends 
Mo Gawdat is an author and former CBO of Google X. 
Salim Ismail is the founder of OpenExO
Dave Blundin is the founder of Link Ventures
Chapters:
00:00 - The Impending Job Crisis
35:53 - Universal Basic Income and Its Challenges
49:41 - AI in Warfare and Ethical Concerns
01:11:08 - The Rise of Bad Actors in AI
01:16:20 - The Dangers of Conscious AI
01:17:22 - Checks and Balances in AI Development
01:20:00 - Surveillance and Privacy Concerns
01:37:25 - The Chip Wars: AI Infrastructure Spending
01:41:56 - Middle East's AI Infrastructure Race
01:46:10 - China's Chip Independence and Economic Growth
01:57:22 - AI's Role in Scientific Breakthroughs
02:04:15 - Reforming Education for the Future
–-
Offers for my audience: 
You can access my conversation with Cathie Wood and Mo Gawdat for free at https://qr.diamandis.com/SummitEM  
Test what’s going on inside your body at https://qr.diamandis.com/fountainlifepodcast  
Reverse the age of my skin using the same cream at https://qr.diamandis.com/oneskinpod
–-
Work With Salim to build your ExO https://openexo.com/10x-shift?video=PeterD
Learn about Dave’s fund: https://www.linkventures.com/xpv-fund 
Learn more about Mo: https://www.mogawdat.com/
Connect with Peter:
X: https://qr.diamandis.com/twitter 
Listen to MOONSHOTS:
Apple: https://qr.diamandis.com/applepodcast 
Spotify: https://qr.diamandis.com/spotifypodcast 
–
*Recorded on June 2nd, 2025
---

# AI Experts Debate: AI Job Loss, The End of Privacy & Beginning of AI Warfare w/ Mo, Salim & Dave 175
**Moonshots - Peter Diamandis:** [June 03, 2025](https://www.youtube.com/watch?v=jNWcWF8j7Sw)
*  In my mind, jobs will be lost. When they are lost, they're going to be lost massively. [[00:00:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=0.0s)]
*  Far more people are in denial or doing nothing than are overreacting. [[00:00:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5.0s)]
*  I do think governments are willfully underprepared. [[00:00:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=10.0s)]
*  Now it comes down to are we going to design a world that is good for people or not? [[00:00:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=13.0s)]
*  We all know that AI will go out of control within the next five to ten years. [[00:00:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=19.0s)]
*  And yet we're building autonomous weapons after autonomous weapons, [[00:00:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=24.0s)]
*  knowing for a fact that every other opponent anywhere in the globe is building them too. [[00:00:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=28.0s)]
*  This is not a tech problem. This is an accountability problem. [[00:00:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=40.0s)]
*  What can I build that is making people happier and more productive and feeling valuable and having a sense of purpose? [[00:00:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=43.0s)]
*  And if we focus on that, we actually can avoid the dystopian outcome. [[00:00:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=51.0s)]
*  We have the ability to create an intentional future. This future is not happening to us. [[00:00:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=54.0s)]
*  We have the ability to guide where it goes. [[00:00:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=59.0s)]
*  Now that's the moonshot, ladies and gentlemen. [[00:01:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=64.0s)]
*  Everybody, welcome to Moonshots and our weekly episode of WTF Just Happened in Tech. [[00:01:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=69.0s)]
*  You know, it's the real news going on. Those of you who go and watch the Crisis News Network, [[00:01:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=74.0s)]
*  what I call CNN, you can learn about all the crooked politicians, all the murders on the planet, [[00:01:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=79.0s)]
*  or join us here to learn about the technology that is transforming every aspect of our lives, [[00:01:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=84.0s)]
*  every company, every industry, every entrepreneur's outcome. [[00:01:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=90.0s)]
*  I'm joined by three moonshot mates today. Dave Blunden, the head of Link XPB. [[00:01:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=93.0s)]
*  Dave, good morning. Looks like you're at home today. [[00:01:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=102.0s)]
*  At home, yeah. Princeton graduation on Tuesday, MIT graduation on Thursday, and then off to Stanford tonight. [[00:01:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=105.0s)]
*  All right. Fantastic. Look forward to seeing you hopefully this week. [[00:01:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=112.0s)]
*  Salim Ismail, the CEO of OpenEXO. And Salim, where do I find you today? [[00:01:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=116.0s)]
*  At home just outside New York City and looking forward to this episode. [[00:02:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=124.0s)]
*  Yeah, yeah, me too. And good morning or good evening, Mo. [[00:02:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=128.0s)]
*  Mo Gadat, the one and only. Dubai, is that where you are? [[00:02:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=133.0s)]
*  Dubai today, yes. Happy to be inside because it is boiling outside. [[00:02:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=138.0s)]
*  Ah, yeah. Well, I'm in Santa Monica just back from a few days in Hong Kong. [[00:02:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=144.0s)]
*  You know, it's crazy. Literally, you have no idea where your friends are these days, literally around the world. [[00:02:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=149.0s)]
*  We're just tied together by this digital network of Zoom and multitude. [[00:02:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=157.0s)]
*  Anyway, a crazy week in AI and in a whole slew of different technologies, and I'm excited to get into it. [[00:02:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=163.0s)]
*  Before we start, anything new, Dave or Salim, you want to add? [[00:02:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=171.0s)]
*  Well, first of all, thanks for getting up at 5 a.m. to do the podcast. [[00:02:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=178.0s)]
*  It's hard to tie together Dubai and LA, but it is much appreciated. [[00:03:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=182.0s)]
*  So I'm in the middle zone here, so it's very easy for me. [[00:03:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=187.0s)]
*  Yeah, well, you're welcome. You guys are worth getting up for. [[00:03:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=190.0s)]
*  All right, let's jump in. As always, I don't know, it feels like every week is going at a pace that would have been unbelievable. [[00:03:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=194.0s)]
*  I'm just trying to remember back 10 or 20 years ago, the number of breakthroughs or announcements. [[00:03:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=204.0s)]
*  That were occurring on a regular basis, and I can't find any analogy. [[00:03:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=211.0s)]
*  I mean, I remember in the dot com world, there are all these crazy new dot com companies being announced every week. [[00:03:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=216.0s)]
*  But here it's not just crazy companies, it's fundamental capabilities that are coming online. [[00:03:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=221.0s)]
*  And also we're going to see later in the podcast, a predicted trillion dollars a year of CapEx going forward, which I checked. [[00:03:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=228.0s)]
*  I checked. That's the equivalent investment that we made mobilizing in World War II, inflation adjusted. [[00:03:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=236.0s)]
*  So if it feels crazy, it should, because it's historic in scale. [[00:04:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=242.0s)]
*  All right, let's jump into a subject on a lot of people's minds. We've heard a lot of news about this. [[00:04:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=248.0s)]
*  This is AI and job loss. We'll begin with a short segment of Dario Amadei, the CEO of Anthropic, talking about job loss. [[00:04:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=254.0s)]
*  Let's take a listen and then discuss it. [[00:04:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=265.0s)]
*  I really worry, particularly at the entry level, that the AI models are very much at the center of what an entry level human worker would do. [[00:04:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=268.0s)]
*  A little bit more worried about the labor impact simply because it's happening so fast that yes, people will adapt, but they may not adapt fast enough. [[00:04:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=277.0s)]
*  And so there may be an adjustment. In terms of inequality, I'm worried about this. [[00:04:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=286.0s)]
*  There's an inherent social contract in democracy where ultimately the ordinary person has a certain amount of leverage because they're contributing to the economy. [[00:04:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=292.0s)]
*  If that leverage goes away, then it's hard to make democracies work and it's harder to prevent concentration of power. [[00:05:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=303.0s)]
*  And so we need to make sure that the ordinary person maintains economic leverage and has a way to make a living, or our society, our social contract needs work. [[00:05:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=311.0s)]
*  You've previously in the past said you've described a future where cancer is cured, the economy grows at 10% a year, the budget is balanced, and 20% of people don't have jobs. [[00:05:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=321.0s)]
*  The quote you just splashed is maybe too optimistic, maybe too sanguine about the ability for people to adapt. [[00:05:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=332.0s)]
*  People have adapted to past technological changes, but I'll say again, everyone I've talked to has said this technological change looks different. [[00:05:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=344.0s)]
*  It looks faster, it looks harder to adapt to, it's broader, the pace of progress keeps catching people off guard. [[00:05:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=353.0s)]
*  I think the benefits are massive and we need to find a way to achieve benefits and mitigate or prevent the harms. [[00:06:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=361.0s)]
*  And the second thing I would say is look, there are, as you mentioned, six or seven companies in the US building this technology. [[00:06:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=369.0s)]
*  If we stop doing it tomorrow, the rest would continue. If all of us somehow stop doing it tomorrow, then China would just beat us. [[00:06:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=376.0s)]
*  And I don't think China winning in this technology is, I don't think that helps anyone or makes the situation any better. [[00:06:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=382.0s)]
*  Every week I study the 10 major tech meta trends that will transform industries over the decade ahead. [[00:06:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=389.0s)]
*  I cover trends ranging from humanoid robots, AGI, quantum computing, transport, energy, longevity, and more. [[00:06:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=395.0s)]
*  No fluff, only the important stuff that matters, that impacts our lives and our careers. [[00:06:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=402.0s)]
*  If you want me to share these with you, I write a newsletter twice a week, sending it out as a short two-minute read via email. [[00:06:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=408.0s)]
*  And if you want to discover the most important meta trends 10 years before anyone else, these reports are for you. [[00:06:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=415.0s)]
*  Readers include founders and CEOs from the world's most disruptive companies and entrepreneurs building the world's most disruptive companies. [[00:07:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=421.0s)]
*  It's not for you if you don't want to be informed of what's coming, why it matters, and how you can benefit from it. [[00:07:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=428.0s)]
*  To subscribe for free, go to dmandus.com slash meta trends. [[00:07:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=436.0s)]
*  That's dmandus.com slash meta trends to gain access to trends 10 plus years before anyone else. [[00:07:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=440.0s)]
*  All right, a lot there. We've heard this at an increasing pace and intensity. Dave, thoughts on Dario's commentary here. [[00:07:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=448.0s)]
*  Yeah, Dario looks really worried there, doesn't he? He's got the wrinkled forehead and then Anderson Cooper looks even more worried. [[00:07:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=456.0s)]
*  And rightfully so, I think the short-term job displacement is imminent. [[00:07:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=462.0s)]
*  When I talk to people at random, people in power, far more people are in denial or doing nothing than are overreacting. [[00:07:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=466.0s)]
*  So it's actually good for Dario to be saying these things to at least wake up the masses to the immense amount of change that's imminent. [[00:07:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=476.0s)]
*  I do think there is a lot of short-term job loss coming, but far, far, far more opportunity being created. [[00:08:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=483.0s)]
*  So it's kind of a foot race between creators, entrepreneurs reinventing what people do versus automators coming and just automating away white collar jobs and then ultimately robotics and blue collar jobs. [[00:08:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=491.0s)]
*  Mo, you've been speaking about this for a while. Is Dario overplaying this or is he on spot on? [[00:08:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=505.0s)]
*  Oh, no, he's underplaying it for sure. My predictions is 10, 20, 30, 40 percent unemployment in some sectors. [[00:08:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=513.0s)]
*  And what time frame? [[00:08:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=523.0s)]
*  In the next two to three years. I think everyone, there are always three questions to answer. [[00:08:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=524.0s)]
*  The first one is, does anyone on this call believe that the technology is not going to catch up for some of those jobs that like a graphic design or a video editor, for example, those sectors are gone. [[00:08:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=532.0s)]
*  I mean, today with Vio3 giving you a minute of video that's better than Avatar for 17 cents, you can create the movie Avatar for around $1,500 if you make mistakes on the way. [[00:09:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=545.0s)]
*  Right. So so that, you know, I don't know how we can save those jobs, to be quite honest. [[00:09:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=559.0s)]
*  If that's the case, then the next question becomes financial. [[00:09:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=564.0s)]
*  Right. Because, you know, if we had not been stuck in a system of capitalism where the entire profitability of a business and the legal requirement of a CEO is to prioritize shareholder gains. [[00:09:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=570.0s)]
*  And accordingly, we do not I do not see a situation where people will be given two day working weeks, you know, paid the same. [[00:09:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=585.0s)]
*  The third is ideological, to be very honest, because even things like you be I sound quite a bit like socialism or communism to me. [[00:09:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=595.0s)]
*  So there will be quite a bit of resistance before we can get to the point where governments accept that these are systems that they will adopt. [[00:10:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=605.0s)]
*  So in my mind, jobs will be lost in some sectors earlier than others, and we can name quite a few of those. [[00:10:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=613.0s)]
*  But when they are lost, they're going to be lost massively. [[00:10:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=621.0s)]
*  On the other hand, the ideology and the existing system will not allow us to replace that quickly enough because we're not awake. [[00:10:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=624.0s)]
*  And I think the more interesting one in the statement that I mentioned is that he says 10 percent economic gains. [[00:10:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=632.0s)]
*  I wonder because how much of the U.S. economy is actually consumption? [[00:10:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=639.0s)]
*  Sixty two percent plus of the U.S. economy is consumption. [[00:10:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=645.0s)]
*  So with people having no buying power, is that economic growth or productivity growth without buyers to buy what we need? [[00:10:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=648.0s)]
*  Yeah. Yeah. And one of the arguments, of course, is you're demonetizing the products cost because a latte is now made by a robot instead of a human. [[00:10:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=656.0s)]
*  And it's, you know, a quarter of the price. [[00:11:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=664.0s)]
*  Salim, you've been, you know, in agreement on this. [[00:11:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=667.0s)]
*  Anything else you want to point out? [[00:11:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=671.0s)]
*  I'd like to take the counterpoint, you know, which is when we see like a huge raft of people standing at the job lines or at the food banks, et cetera. [[00:11:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=673.0s)]
*  Then I think we need to worry. [[00:11:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=685.0s)]
*  I think we're we're underestimating the fact how quickly people can adapt. [[00:11:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=687.0s)]
*  Let's say I'm a let's use the video editor if what we've seen in the video, there's a video editor listening to this video. [[00:11:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=692.0s)]
*  Right. But but let's let's the minute that you automate that, the video editor moves and does a whole bunch of other stuff that are necessary for producing a podcast like this. [[00:11:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=701.0s)]
*  Right. There's lots of other work to be done. [[00:11:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=712.0s)]
*  I still see I go back to the 1970s bank ATM example, which we've talked about before. [[00:11:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=714.0s)]
*  I do think governments are woefully underprepared. [[00:12:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=722.0s)]
*  We should be running a ton of experiments on UBI or four day work weeks and managing that and getting used to that paradigm and knowing how will we roll it out if it needs to be rolled out. [[00:12:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=727.0s)]
*  So why aren't they doing that? [[00:12:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=738.0s)]
*  And if this is a separate thing, we do almost zero experimentation in government and we could be doing a lot more of that. [[00:12:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=740.0s)]
*  I think that's one area to look at. [[00:12:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=747.0s)]
*  But I will talk about truck driving in a bit. [[00:12:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=749.0s)]
*  But when you go talk to a trucking company, which I actually went and did talk about, OK, there's all these three million jobs that could be lost, et cetera. [[00:12:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=752.0s)]
*  The truck driving company goes, I would hire a thousand truck drivers today if I could. [[00:12:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=762.0s)]
*  I just don't. They're not there. [[00:12:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=766.0s)]
*  I need the automation to do the work. [[00:12:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=768.0s)]
*  So I kind of tilt towards that side. [[00:12:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=770.0s)]
*  Now, I tend to be biased on the optimistic side. [[00:12:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=772.0s)]
*  So I will grant you that. [[00:12:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=775.0s)]
*  Let's see how this works out over time. [[00:12:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=777.0s)]
*  Throw some numbers out here just from the Bureau of Labor Statistics. [[00:13:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=780.0s)]
*  So 11 percent of office and admin jobs, 11 percent of the workforce is office and admin jobs, which have a very high probability of going away. [[00:13:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=785.0s)]
*  Six percent are business and financial operations. [[00:13:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=796.0s)]
*  Seven percent are management. [[00:13:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=799.0s)]
*  Six percent are education, training, library. [[00:13:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=801.0s)]
*  Six percent are health care. [[00:13:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=804.0s)]
*  Nine percent are sales related jobs. [[00:13:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=807.0s)]
*  So there's large swaths of the labor force that, at least according to my search, are likely to be automated. [[00:13:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=810.0s)]
*  And the question is, can they all be up up leveled? [[00:13:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=817.0s)]
*  Right. So we're talking just in the in the quick research I did. [[00:13:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=820.0s)]
*  It's something on the order of 40 percent of jobs that have a reasonable probability over the next three to five years of being automated away. [[00:13:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=824.0s)]
*  And we'll get to this conversation a bit later. [[00:13:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=831.0s)]
*  The issue is not can they be up leveled to a different position. [[00:13:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=835.0s)]
*  The question is the social unrest in the interim. [[00:14:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=841.0s)]
*  How hard is that going to hit society? [[00:14:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=845.0s)]
*  Dave, what are you thinking? [[00:14:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=848.0s)]
*  Well, you know, it's we're moving into an intentional world. [[00:14:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=850.0s)]
*  You know, we we evolved in a world dictated by nature. [[00:14:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=853.0s)]
*  And then we went through this transition where we're in right now. [[00:14:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=856.0s)]
*  But the future is our design. [[00:14:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=860.0s)]
*  It's not it's not dictated by title forces. [[00:14:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=862.0s)]
*  And it drives me nuts when the economists, you know, are extrapolating and predicting. [[00:14:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=865.0s)]
*  But they never reference self-improvement. [[00:14:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=870.0s)]
*  They never reference the exponential rate of change. [[00:14:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=873.0s)]
*  And the intentionality of the world design is completely dominant from here forward. [[00:14:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=876.0s)]
*  So it's what we decide to do. [[00:14:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=881.0s)]
*  You know, I think Dario worries all night about CBRN, chemical, biological, radiological and nuclear threats from A.I. [[00:14:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=883.0s)]
*  And he's dead right. [[00:14:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=892.0s)]
*  You know, if you if you unleash A.I. into the hands of eight billion people, some crazy person out there is going to turn it into a weapon. [[00:14:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=894.0s)]
*  You have to actually put some thought into this design. [[00:15:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=900.0s)]
*  But that was inevitable. You know, that started with the nuclear era. [[00:15:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=904.0s)]
*  And so now it comes down to are we going to design a world that is good for people or not? [[00:15:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=907.0s)]
*  And so I think it's completely in our control. [[00:15:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=913.0s)]
*  I also really believe that, yes, there's huge amounts of job displacement coming because, as Mo pointed out, [[00:15:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=916.0s)]
*  the natural capitalist action is to say, what can I automate away, reduce the cost by 99 percent? [[00:15:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=923.0s)]
*  That all becomes bottom line profit. [[00:15:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=928.0s)]
*  So the valuations of companies that automate are going to go way, way up and create a huge amount of wealth. [[00:15:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=930.0s)]
*  Where does that wealth land? [[00:15:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=936.0s)]
*  And, you know, as I've been saying on this podcast, it's naturally going to land in relatively few hands if nothing changes. [[00:15:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=938.0s)]
*  And that's what's going to create all kinds of social unrest in transition. [[00:15:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=944.0s)]
*  But the amount of value and the greenfield opportunity is so much bigger than the amount of job loss. [[00:15:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=948.0s)]
*  And so if we're quick and intentional and we turn a lot of that A.I. [[00:15:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=956.0s)]
*  horsepower into working on what can we build? [[00:16:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=961.0s)]
*  You know, if I can write three million lines of software in a single night, [[00:16:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=964.0s)]
*  that's that's the equivalent of hundreds of millions of dollars of R&D in a single night. [[00:16:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=968.0s)]
*  What can I build that is making people happier and more productive and feeling valuable and having a sense of purpose? [[00:16:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=974.0s)]
*  And if we focus on that, we actually can avoid the dystopian outcome. [[00:16:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=982.0s)]
*  I love that an intentional future. [[00:16:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=985.0s)]
*  Let me move forward to this next set of slides here. [[00:16:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=987.0s)]
*  Not to go into detail, but we see a plan for Tesla to roll out model Y cars, fully automatic, aiming for delivery in June. [[00:16:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=992.0s)]
*  So their rollout of the robotaxi begins in June. [[00:16:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1005.0s)]
*  It won't be many cars. They're testing it out. [[00:16:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1010.0s)]
*  You know, I took my kids on a Waymo ride here in Santa Monica over the weekend and they just had a blast. [[00:16:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1013.0s)]
*  Put them and their friends in a Waymo. We just drove drove around and it's it felt like a carnival ride for the first few minutes. [[00:17:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1020.0s)]
*  And then it felt completely like an extraordinary end to end experience. [[00:17:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1029.0s)]
*  So these will roll out and we're going to talk about the number of drivers that are taxi drivers, Uber drivers, the displacement here. [[00:17:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1036.0s)]
*  This next article is about truck driving. [[00:17:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1045.0s)]
*  And this makes the point made earlier. [[00:17:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1048.0s)]
*  18 wheelers are on the Texas highways driving themselves already. [[00:17:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1051.0s)]
*  You know, just a quick video for a microsecond. [[00:17:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1056.0s)]
*  But at the same time, the U.S. is facing historic driver shortages and recruitment struggles. [[00:17:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1061.0s)]
*  We can't get enough drivers, as you said, Salim. [[00:17:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1067.0s)]
*  So let's talk about this sector for a moment. [[00:17:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1071.0s)]
*  Salim, do you want to kick us off? [[00:17:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1075.0s)]
*  Yeah, two points here. [[00:17:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1077.0s)]
*  First, as you know, before Uber came along, we didn't notice that there was this huge labor liquidity opportunity. [[00:17:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1079.0s)]
*  And then Uber comes along and all of a sudden a single mother can drop her kids off at school, drive for four hours, pick them up again that that afternoon. [[00:18:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1086.0s)]
*  Right. And have a kind of a functional, much more functional world than than before. [[00:18:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1095.0s)]
*  And we soaked that up very quickly. We didn't notice that we didn't notice it on the abundance. [[00:18:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1100.0s)]
*  I don't think we'll notice it as much on the as we automate. [[00:18:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1104.0s)]
*  Also, I'm still banking and hoping that my 13 year old will never have to get a driver's license. [[00:18:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1108.0s)]
*  So I'll see when the curves when the curves hit of autonomous driving versus people wanting to. [[00:18:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1114.0s)]
*  I think we'll we'll we'll just do as we've seen before a ton more driving. [[00:18:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1121.0s)]
*  And we'll just have a lot more little road trips and little errands that we didn't have to do now can be done by the by a way more or Tesla. [[00:18:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1129.0s)]
*  And I think we'll just have what we've seen historically repeatedly, repeatedly is that when you automate, you increase capacity, you don't decrease. [[00:18:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1138.0s)]
*  And so in the truck driving example, I think we'll see a ton more truck driving that's autonomous. [[00:19:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1148.0s)]
*  And the amount of truck drivers won't change very much. [[00:19:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1153.0s)]
*  That's my prediction. Let's see if I'm Roger. [[00:19:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1156.0s)]
*  Well, Peter, yeah, good. [[00:19:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1158.0s)]
*  Well, you're going to love being in L.A. where the traffic is notorious. [[00:19:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1161.0s)]
*  This also enables coordinated traffic. [[00:19:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1166.0s)]
*  You know, our good friend Lee Hetherington from back from MIT days did all these traffic simulations back when he was an undergrad. [[00:19:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1169.0s)]
*  And the roads are most efficient at about 45, 50 miles an hour back to back cars. [[00:19:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1175.0s)]
*  And then they just jam right after that. [[00:19:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1179.0s)]
*  But the self-driving cars also enable intelligent traffic flow design. [[00:19:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1181.0s)]
*  And that's that's actually going to increase the capacity of their existing roadways quite a bit. [[00:19:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1186.0s)]
*  I'm sure everyone in L.A. will love that. [[00:19:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1190.0s)]
*  I mean, the implications of self-driving cars on the environment, on being able to move electric battery packs all around the city, being able to get rid of parking, you know, every part, every garage at a single family home could get turned into an extra storage or living room. [[00:19:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1193.0s)]
*  In L.A., 60 percent of the land areas, parking spaces. [[00:20:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1209.0s)]
*  It's insane. [[00:20:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1213.0s)]
*  It truly is. I could not. [[00:20:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1215.0s)]
*  So if you look back 120 years when you had the transition or 110 years had the transition from horses to the Ford Model T, that transition was dramatic over the course of 10 years. [[00:20:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1217.0s)]
*  I mean, the value proposition for a car was so much better than a horse. [[00:20:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1229.0s)]
*  Right. [[00:20:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1234.0s)]
*  And the amount of horse manure was threatening society at an extraordinary rate and then disappeared. [[00:20:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1235.0s)]
*  The question is, I don't when I look at the Waymo, it's an expensive car. [[00:20:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1242.0s)]
*  Right. [[00:20:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1248.0s)]
*  The Waymo is coming in at something like north of one hundred fifty thousand dollars. [[00:20:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1249.0s)]
*  So you're not buying them and putting a fleet out the cyber cab. [[00:20:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1252.0s)]
*  If it really comes in at 30 30 K or below, I could see Uber drivers buying a fleet of cyber cabs and having cyber cabs work for them. [[00:20:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1257.0s)]
*  But it's going to take that kind of a price point to really do a transition to the point where I don't need a car anymore. [[00:21:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1266.0s)]
*  My A.I. is ordering it in advance of when I need it. [[00:21:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1273.0s)]
*  I walked out the front door. [[00:21:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1276.0s)]
*  It's waiting for me because my schedule is known by my A.I. [[00:21:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1278.0s)]
*  Mo, thoughts? [[00:21:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1283.0s)]
*  I mean, well, I love you all. [[00:21:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1285.0s)]
*  You know that. So please don't be offended by what I'm about to say. [[00:21:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1288.0s)]
*  Speaker, speak your mind. [[00:21:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1292.0s)]
*  All that you guys talk about is problems of privilege. [[00:21:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1294.0s)]
*  It's like my my traffic jam. [[00:21:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1298.0s)]
*  I want to make sure that my my cab is waiting for me outside and just go tell those things to the cab driver that actually is feeding for and working two shifts. [[00:21:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1301.0s)]
*  Right. And this this I agree with Dave 100 percent. [[00:21:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1312.0s)]
*  We have a choice to design our future. [[00:21:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1316.0s)]
*  Now, when you really think about it and when wonderful humans like you are thinking this way, what do you think the choice will be? [[00:22:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1320.0s)]
*  Your question, Peter, was how would that impact on civil unrest? [[00:22:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1328.0s)]
*  Well, if they heard this conversation and how careless we are about their jobs, saying things like, yeah, they'll figure something out. [[00:22:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1332.0s)]
*  I heard that a million times. [[00:22:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1340.0s)]
*  What will they figure out? [[00:22:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1342.0s)]
*  I want someone who tells me that we will find new jobs and upskill them. [[00:22:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1344.0s)]
*  Tell me what those jobs are so that we start upskilling them. [[00:22:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1348.0s)]
*  Can I give an example here? Yeah. [[00:22:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1352.0s)]
*  So I have a friend when I was living in Miami, I met an Uber driver and I started playing tennis with him and we we had a kind of a fun interaction. [[00:22:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1354.0s)]
*  And it was fascinating. [[00:22:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1363.0s)]
*  He started driving for Uber and then the amount of income dropped too much. [[00:22:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1364.0s)]
*  He started driving for Lyft. [[00:22:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1370.0s)]
*  Then he did both for a while and then both of them became it was too not worth it to be driving that much. [[00:22:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1371.0s)]
*  So he buys a start renting out his car on Turo and then finds I can do this. [[00:22:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1378.0s)]
*  And he starts renting four cars, buys four cars and rents them all out on Turo. [[00:23:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1383.0s)]
*  And then he helps a friend with his Airbnb rental managing that taking a cut of that thing. [[00:23:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1388.0s)]
*  And over a period of like three years or so, he navigated all of these different dynamics. [[00:23:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1394.0s)]
*  Wherever there were opportunities, he would go grab it, et cetera, et cetera. [[00:23:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1402.0s)]
*  And I think it speaks to the enterprise and entrepreneurial nature of an individual. [[00:23:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1405.0s)]
*  If you had a score that was called the entrepreneur quotient of an individual, they will figure it out. [[00:23:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1410.0s)]
*  We talk often Peter and I about mindsets, right? [[00:23:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1417.0s)]
*  If you drop Elon Musk into a desert with no money and no communications, he'll figure it out. [[00:23:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1420.0s)]
*  He'll figure out how to get out of there and make a rocket out of that sand. [[00:23:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1426.0s)]
*  And I think when you when you give people opportunity, this is why I think technology is so amazing. [[00:23:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1430.0s)]
*  It speaks to Dave's earlier point. [[00:23:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1435.0s)]
*  When you make this opportunity available, people are going to go for it. [[00:23:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1437.0s)]
*  They're going to figure out, wow, I can automate code. [[00:24:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1441.0s)]
*  What could I automate? [[00:24:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1443.0s)]
*  And they'll start doing that stuff. [[00:24:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1444.0s)]
*  Then when this fellow got blocked by Turobe for having too many cars or whatever, he created multiple IDs and was doing that. [[00:24:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1446.0s)]
*  You know, people are incredibly enterprising if you're able to turn on that switch. [[00:24:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1454.0s)]
*  I think we're underestimating that capability. [[00:24:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1458.0s)]
*  So I love that, Salim. [[00:24:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1461.0s)]
*  You know, I'm going to come to this point a little bit later in a few topics that I think the single most important job for the future. [[00:24:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1463.0s)]
*  People say, what should my kid become? [[00:24:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1471.0s)]
*  I think the only job that's going to survive in the future down the line is entrepreneur is and we have to reteach our kids how to think this way. [[00:24:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1473.0s)]
*  Stop. [[00:24:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1483.0s)]
*  You know, we've had a we've had an entire civilization whose educational output is to train kids to get a job rather than train kids to figure out what the opportunities are and create create something around them. [[00:24:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1484.0s)]
*  Because the tools were not democratized. [[00:24:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1499.0s)]
*  Well, the tools are democratized now. [[00:25:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1501.0s)]
*  And so how do you train kids and adults to go out and find jobs? [[00:25:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1503.0s)]
*  I put up this slide here. [[00:25:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1509.0s)]
*  These are drivers by category in the U.S. [[00:25:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1510.0s)]
*  And I'm sorry, we have a massive international viewership, but I'm defaulting to U.S. numbers here. [[00:25:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1512.0s)]
*  Three point three percent of the U.S. workforce are drivers. [[00:25:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1519.0s)]
*  There are two point two million drug drivers. [[00:25:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1523.0s)]
*  And down the bottom on this list, we have delivery drivers, Uber drivers, bus drivers. [[00:25:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1525.0s)]
*  At the bottom is taxi drivers at two hundred thousand. [[00:25:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1530.0s)]
*  Right. So the number of taxi drivers has dropped precipitously. [[00:25:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1534.0s)]
*  I do think, Mo, to answer your question, there is a future in which drivers are allowed to finance and purchase these autonomous cars. [[00:25:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1539.0s)]
*  And they become managers of fleets of autonomous cars. [[00:25:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1551.0s)]
*  These cars are out there earning a living on behalf of those drivers. [[00:25:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1554.0s)]
*  This is this is definitely the American way. [[00:25:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1559.0s)]
*  Right. The American way is that we're going to enable everyone to, you know, buy a car to make money on it without doing anything. [[00:26:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1562.0s)]
*  Is that really true, guys? [[00:26:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1570.0s)]
*  Like, honestly, if there is a margin that allows this guy to make money, why wouldn't Uber buy those cars? [[00:26:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1572.0s)]
*  They probably will buy many of those cars. [[00:26:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1579.0s)]
*  Yes, sir. OK. The other question we're not asking, and I'm not I'm being I was told at the beginning of this briefing to be the extreme on one side. [[00:26:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1582.0s)]
*  So please understand that. [[00:26:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1592.0s)]
*  The other question we're not asking and we definitely need to ask is that this guy that's been renting those cars out, Salim, which I think is a fantastic example, [[00:26:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1594.0s)]
*  is renting them out in an undisturbed economy where people have the purchasing power to to rent them out from them. [[00:26:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1604.0s)]
*  What kind of entrepreneur would make money in a UBI based environment? [[00:26:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1612.0s)]
*  What does that mean to a lot of people who don't have the purchasing power to buy from an entrepreneur? [[00:26:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1617.0s)]
*  I think I could answer that question. [[00:27:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1624.0s)]
*  So what I found fascinating about this fellow, because every week we would play tennis and I would just track what he was doing. [[00:27:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1627.0s)]
*  He found that certain types of cars were not renting at all because of that time of the year or that type of tourists visiting Miami or whatever. [[00:27:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1632.0s)]
*  And so he was juggling constantly which cars he had or didn't have in his little little fleet and adapting as it went along. [[00:27:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1641.0s)]
*  At some point, he found that small SUVs were renting like hotcakes. [[00:27:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1648.0s)]
*  And so he started working on that. [[00:27:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1653.0s)]
*  Then he had to pivot again. [[00:27:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1655.0s)]
*  And he just managed to navigate himself. [[00:27:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1656.0s)]
*  And the question came up, what happens if you start? [[00:27:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1659.0s)]
*  He got to a point where he was making enough passive income off these things that he didn't have to do the work. [[00:27:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1662.0s)]
*  And then he was just voluntarily taking tennis lessons and teaching people tennis and being on a tennis court eight hours a day. [[00:27:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1668.0s)]
*  And I think there's a thread of an anecdote here of where people will start finding their true passions and just following those passions. [[00:27:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1675.0s)]
*  I agree with that. [[00:28:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1683.0s)]
*  I think that's the beauty of a UBI. [[00:28:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1684.0s)]
*  It allows you to do that. [[00:28:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1686.0s)]
*  We've seen in the experiments where UBI has been done properly that entrepreneurship explodes. [[00:28:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1688.0s)]
*  And if we agree with that general thesis, then this is absolutely the way to go. [[00:28:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1693.0s)]
*  I'll go back to my earlier trope of governments being completely unaware and unable for this because to move from a taxation job, union labor structure to UBI is such a huge flip that we have no confidence in the public sector in really getting us there. [[00:28:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1697.0s)]
*  So I agree 100% to that. [[00:28:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1713.0s)]
*  Honestly, I think if we both agree that this is a future where it's possible, regardless of how low a UBI is, that people will go back to bartering and doing things through each other, through the offerings of each other. [[00:28:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1715.0s)]
*  Then I think that would work. [[00:28:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1730.0s)]
*  But then governments need to be aware of that. [[00:28:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1732.0s)]
*  We need to start thinking that this is going to be a future that we need to think about. [[00:28:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1735.0s)]
*  But my ask of everyone is in situations like this, it really is not helpful to keep trying the California way to paint the optimistic picture. [[00:29:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1740.0s)]
*  Because if the optimistic picture happens, we're all fine. [[00:29:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1753.0s)]
*  I think what we need to think about is what's the worst case scenario and guard against it. [[00:29:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1757.0s)]
*  And the worst case scenario, if we're not prepared for this kind of job losses economically and national security-wise is quite significant. [[00:29:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1763.0s)]
*  People really need to be aware of that. [[00:29:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1772.0s)]
*  I just came back from Hong Kong, Mo, and while I was there, met with an incredibly successful entrepreneur of Indian origin, Sanjay, who was one of the very first employees in one of the huge Hong Kong Chinese companies. [[00:29:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1774.0s)]
*  And his mission now is to go back and try and help India's young population, 1.41 billion people in India. [[00:29:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1792.0s)]
*  The promise had always been if you get an education, there's going to be a job for you. [[00:30:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1804.0s)]
*  And of course, that promise is now broken. [[00:30:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1809.0s)]
*  All of the coding jobs that they were getting are no longer being made available. [[00:30:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1812.0s)]
*  And we're on the tipping point in India and other parts of the world of what could be such a negative implication that it leads to societal unrest. [[00:30:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1819.0s)]
*  It's like, where's my job? [[00:30:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1833.0s)]
*  And one of the biggest problems is a young population, an intelligent young population that has taken their future, grabbed away from them. [[00:30:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1835.0s)]
*  What do they do? [[00:30:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1845.0s)]
*  And the conversation I had with Sanjay, which I agree with, is the job of the future is being an entrepreneur. [[00:30:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1846.0s)]
*  And so his mission in India is upskilling all of these young students to become entrepreneurs, to create new job opportunities for themselves. [[00:30:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1853.0s)]
*  You know, Dave, how do you think this plays out? [[00:31:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1864.0s)]
*  I think that, you know, we're way underestimating the creativity of people. [[00:31:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1870.0s)]
*  And there's this window of time the next four years where the empowerment of people to create is so outweighs the risk. [[00:31:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1874.0s)]
*  And I do agree, you know, we're choosing Driver because it's a really tough case. [[00:31:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1883.0s)]
*  You know, it's the number one job title in the world is Driver. [[00:31:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1887.0s)]
*  It's a huge number of people. [[00:31:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1891.0s)]
*  But if you look at graphic designers as a case study, too, I think they're empowered much more than they're replaced. [[00:31:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1894.0s)]
*  And there are all these case studies popping up of VO3 artists that are so much more productive. [[00:31:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1901.0s)]
*  And so I think that when I look at entrepreneurs, you know, I've worked with hundreds and hundreds of entrepreneurs over the years. [[00:31:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1907.0s)]
*  What they need is time and the ability to access tools, time and tools. [[00:31:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1914.0s)]
*  And there's very likely a world coming up over the next four years where they're given time, whether it's UBI or otherwise, and they can act. [[00:32:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1920.0s)]
*  Because very often, you know, some of the best, most creative people, they can't act on their ideas largely because they're trapped in mortgage. [[00:32:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1928.0s)]
*  They're trapped in student debt. [[00:32:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1936.0s)]
*  You know, they just need money now. [[00:32:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1938.0s)]
*  And so then they go, they become an Uber driver for a while. [[00:32:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1940.0s)]
*  They become a whatever for a while. [[00:32:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1942.0s)]
*  They go work at Google for a while. [[00:32:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1944.0s)]
*  But their freedom of action is very, very limited. [[00:32:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1947.0s)]
*  And I think that AI has the opportunity to open up freedom of action. [[00:32:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1949.0s)]
*  Freedom of action unleashes creativity. [[00:32:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1953.0s)]
*  So exactly as Salim was saying, there's so much latent entrepreneurial talent. [[00:32:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1955.0s)]
*  And this next window of four years is going to be dominated by the ability to build scaffolding. [[00:32:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1959.0s)]
*  And scaffolding is a word you're going to hear a ton now going forward because the AI doesn't naturally do something interesting or useful for you. [[00:32:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1966.0s)]
*  It'll write all the code. [[00:32:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1973.0s)]
*  It'll build everything. [[00:32:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1975.0s)]
*  It'll audit. [[00:32:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1976.0s)]
*  It'll write all the documents. [[00:32:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1977.0s)]
*  It does all the busy work very, very well in the next four years. [[00:32:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1978.0s)]
*  But it doesn't decide this is what my user base, my community, my, you know, this is what people will want. [[00:33:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1981.0s)]
*  And that's still coming from entrepreneurs. [[00:33:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1988.0s)]
*  And so this slide is exactly right. [[00:33:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1991.0s)]
*  This is the dominant theme over the next four years. [[00:33:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1993.0s)]
*  Go ahead and read this out if you would, Dave. [[00:33:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1996.0s)]
*  Job of the future is entrepreneur. [[00:33:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=1999.0s)]
*  Near term, next two to five years, you know, many jobs will be impacted. [[00:33:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2001.0s)]
*  This decade, 2030, medium term. [[00:33:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2005.0s)]
*  So the medium term, 2030 to 2045, is the part where no one can quite visualize. [[00:33:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2007.0s)]
*  You know, I have a great sense of the next four years and then a much more difficult sense of what happens from 2030 and beyond. [[00:33:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2012.0s)]
*  It'll clearly be an age of incredible abundance. [[00:33:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2020.0s)]
*  So the opportunity to make everybody happy is right in front of us. [[00:33:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2023.0s)]
*  Just a question of how you do it. [[00:33:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2027.0s)]
*  Yeah. [[00:33:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2029.0s)]
*  But in the singularity sprint. [[00:33:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2030.0s)]
*  Yeah, let me hit on that, right? [[00:33:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2031.0s)]
*  Yeah. [[00:33:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2033.0s)]
*  So the idea here of the singularity sprint is you have a window of time to build something awesome. [[00:33:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2034.0s)]
*  And that window is limited. [[00:34:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2042.0s)]
*  So I'll read, it says, the anxious all out rush to launch bold projects or startups right now, driven by the fear that rapidly advancing AI will soon erode human leverage and make long horizon careers that's obsolete. [[00:34:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2045.0s)]
*  And quote, after graduation, a lot of my friends skip safe jobs for their own ventures. [[00:34:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2060.0s)]
*  Classic singularity sprint vibes. [[00:34:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2065.0s)]
*  So it's like, if you want to make it big, you got to dive in right now, both feet. [[00:34:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2068.0s)]
*  Do you agree with that? [[00:34:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2073.0s)]
*  Yeah, this is what started with Steve Jobs and Bill Gates, both being 21 when the PC comes out. [[00:34:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2075.0s)]
*  You know, they have no career path, right? [[00:34:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2080.0s)]
*  They're within a year of age of each other. [[00:34:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2082.0s)]
*  They are old enough to start a company, but they're young enough that they're not in law school. [[00:34:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2085.0s)]
*  They're not in some, you know, entrenched 401k plan. [[00:34:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2089.0s)]
*  They're just free to act. [[00:34:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2092.0s)]
*  And so, you know, Steve Jobs, Bill Gates, then you forward to the Internet, Mark Zuckerberg drops out, starts Facebook. [[00:34:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2094.0s)]
*  But you see this over and over again in recent history where flexibility way outperforms career pathing. [[00:35:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2100.0s)]
*  So going forward, of course, that's going to accelerate with the singularity. [[00:35:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2107.0s)]
*  So now, yeah, you'd be you'd be crazy to get too deep into some trench when you know the amount of change is accelerating like crazy. [[00:35:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2111.0s)]
*  So, yeah, this is clearly the world we're moving into. [[00:35:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2119.0s)]
*  Opportunity is everywhere. [[00:35:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2123.0s)]
*  And the expansion of opportunity is is just fractal and rampant. [[00:35:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2125.0s)]
*  And so so many things you can do to add value, but they're not things that you would have anticipated a year prior. [[00:35:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2131.0s)]
*  So you need to be really nimble and flexible and, you know, stay frosty. [[00:35:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2136.0s)]
*  Watch this podcast. [[00:35:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2140.0s)]
*  Read the Alex Wisner gross feed. [[00:35:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2141.0s)]
*  Like, just stay on top of it because new things are appearing all the time. [[00:35:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2143.0s)]
*  Mo, bring us back to reality here. [[00:35:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2148.0s)]
*  Do you disagree with this? [[00:35:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2150.0s)]
*  So I think Dave's point is so spot on. [[00:35:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2153.0s)]
*  If you're 21 like Bill Gates or Steve Jobs, you know, if you really think about those who already have a mortgage, how will you be? [[00:35:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2159.0s)]
*  I work for those because remember, we pay people for the value they bring. [[00:36:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2167.0s)]
*  So when there is when nobody's really bringing value, then do you pay someone who has a mortgage and four kids a little more than someone who has a mortgage and two kids? [[00:36:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2171.0s)]
*  Or do you reward someone who, you know, worked on a on a shoestring for a while and didn't have a mortgage? [[00:36:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2182.0s)]
*  I don't know. OK, but but my question is, are we thinking about those things? [[00:36:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2189.0s)]
*  And then, of course, when we talk about entrepreneurship, it's so easy for us to talk about that. [[00:36:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2194.0s)]
*  Everyone here has started or co-founded or invested in tens, if not hundreds of companies. [[00:36:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2200.0s)]
*  That's not natural for people who were trained all their life to get a job. [[00:36:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2206.0s)]
*  And all of that, by the way, everyone here knows I am the biggest believer in total abundance. [[00:36:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2213.0s)]
*  Once we once we cross this short term dystopia, if you want total abundance, like you, you know, we can create a world that we can't even dream of. [[00:37:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2221.0s)]
*  It's just that we have to be super realistic about the challenges in the short term and rather than talk about the opportunities and tell people, hey, you take charge, you go and you go ahead and start a business. [[00:37:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2231.0s)]
*  I mean, honestly, even I today am struggling to start a business at this pace. [[00:37:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2243.0s)]
*  I mean, seriously, and I've started countless businesses. [[00:37:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2249.0s)]
*  It's so difficult to keep up. [[00:37:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2252.0s)]
*  Yeah, the speed of disruption is crazy. [[00:37:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2255.0s)]
*  Can I flip over to most side of the equation for a second? [[00:37:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2257.0s)]
*  Yes, please. [[00:37:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2260.0s)]
*  So I think there's in the US, I would say you don't have to worry at all at a country level just because the latent amount of entrepreneurship is so deeply embedded into the culture. [[00:37:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2261.0s)]
*  Right. But you take Europe, where if you're a big company, just trying to fire people is near impossible. [[00:37:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2272.0s)]
*  There are workers councils that govern how many people unions, et cetera, et cetera. [[00:37:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2278.0s)]
*  The amount of labor rigidity there is extreme. [[00:38:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2283.0s)]
*  That is going to be very, very badly disrupted. [[00:38:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2286.0s)]
*  And I think the governments there are in very, very deep trouble because they're not structured. [[00:38:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2288.0s)]
*  They don't have the latent entrepreneurship quotient in the in the population to be able to adapt to what's going on. [[00:38:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2293.0s)]
*  And that's where I think you'll see a lot more challenges than, say, the US. [[00:38:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2301.0s)]
*  The challenge with trying to upgrade people have been stuck in a particular way of thinking for a decade or two to most point is going to be incredibly difficult. [[00:38:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2305.0s)]
*  Now you need like psychedelics at scale or some radical huge thing to make this to make that mindset shift to make everybody move. [[00:38:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2315.0s)]
*  Or you have to go to UBI urgently and force people into that conversation. [[00:38:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2323.0s)]
*  Everyone, as you know, earlier this year I was on stage at the Abundance Summit with some incredible individuals. [[00:38:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2328.0s)]
*  Kathy Wood, Mo Gadat, Vinod Khosla, Brett Adcock and many other amazing tech CEOs. [[00:38:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2333.0s)]
*  I'm always asked, hey, Peter, where can I see the summit? [[00:38:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2339.0s)]
*  Well, I'm finally releasing all the talks. [[00:39:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2342.0s)]
*  You can access my conversation with Kathy Wood and Mo Gadat for free at diamandis.com. [[00:39:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2345.0s)]
*  That's the talk with Kathy Wood and Mo Gadat for free at diamandis.com. [[00:39:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2352.0s)]
*  Enjoy. I'll ask my team to put the links in the show notes below. [[00:39:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2358.0s)]
*  I'm going to give a couple of stats here just for reference in the US. [[00:39:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2362.0s)]
*  Sixteen percent of the US adults consider themselves entrepreneurs. [[00:39:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2366.0s)]
*  It's 31 million adults. [[00:39:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2371.0s)]
*  Recent surveys indicate that 36 percent of Gen Zers and 39 percent of millennials consider themselves entrepreneurs. [[00:39:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2373.0s)]
*  So to make makes your point, Salim, that the United States has less of an issue there, but it's in the rigid structures of other nations. [[00:39:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2381.0s)]
*  Of course, to remember, the idea of a job is a relatively new invention. [[00:39:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2390.0s)]
*  And for most of human history, we were entrepreneurs to survive. [[00:39:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2395.0s)]
*  We'd go and find that shelter, that food, you know, those berries we needed to cure our child of a particular disease. [[00:40:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2400.0s)]
*  So it's you know, the question is, can we create an intentional future? [[00:40:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2410.0s)]
*  My biggest concern, Dave, you hit on this, Mo and Salim, you hit on this, which is that governments are linear at best. [[00:40:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2416.0s)]
*  And we're in this exponential ramp up that's going to change every aspect of society. [[00:40:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2425.0s)]
*  Here's another example of what's going on today. [[00:40:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2432.0s)]
*  And it's going to change things. And again, it's both a disruptive force and innovative force. [[00:40:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2436.0s)]
*  This was a tweet put out by Matt Schumer. [[00:40:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2441.0s)]
*  It says, I put Claude for Opus in charge as CEO of my startup and has seen significant revenue growth. [[00:40:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2445.0s)]
*  He said, you know, this is low risk since Claude for Opus is not in charge of HR or financial investments, but rapid iteration of the products and services. [[00:40:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2454.0s)]
*  So we've been speaking about this for a while. When do we see the first billion dollar one person startup? [[00:41:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2465.0s)]
*  And then soon thereafter, you know, billion dollar zero person startups as agents with crypto are beginning to create new opportunities. [[00:41:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2471.0s)]
*  Now, one of the things that we haven't mentioned is this potential future comes with massive GDP growth, massive revenue growth. [[00:41:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2480.0s)]
*  And where does that revenue go? Mo, you mentioned that a few minutes ago. [[00:41:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2493.0s)]
*  Is it all being concentrated in the magnificent whatever, you know, rather than Magnificent 7, we're going to see all of these AI companies that are trillion dollar companies. [[00:41:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2497.0s)]
*  How do they get taxed? How does the money get redistributed? So we avoid revolutions. [[00:41:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2508.0s)]
*  Thoughts on this, Salim, is this the future of an EXO, an exponential organization? [[00:41:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2514.0s)]
*  The natural outcome as we, you know, used to take like 100,000 people to create a billion dollar company a century ago, then it dropped to about 50,000. [[00:41:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2519.0s)]
*  About four decades ago was 10,000. And now it's like 10, right? Or three years as we talk about it or as Sam Altman goes, it'll be one. [[00:42:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2529.0s)]
*  We will get to zero at some point. We're just spinning off ideas autonomously that then just generate a lot of value. [[00:42:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2538.0s)]
*  I think Dave's point from the beginning was really a key one is where does that value accrue and how do you navigate that? [[00:42:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2546.0s)]
*  And right now we tax labor. We're going to have to tax capital much more aggressively in the future to navigate this. [[00:42:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2553.0s)]
*  Dave? [[00:42:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2560.0s)]
*  Well, a couple of case studies on this, Peter. So, you know, we've seen Mercure is very, very good at interviewing people all over the world, any language, you know, any culture and discovering latent talent. [[00:42:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2561.0s)]
*  So now you turn that same energy inside your organization. You know, suppose you've got a thousand people, 10,000 people inside an organization. [[00:42:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2572.0s)]
*  There's latent talent in there everywhere. [[00:42:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2578.0s)]
*  Largely, historically, people have climbed the corporate hierarchy by kissing ass and schmoozing and buying beers. [[00:43:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2581.0s)]
*  And it's not really correlated with being good at your job. And that drives a lot of very talented people nuts, especially if they're from a different culture. [[00:43:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2589.0s)]
*  They speak a different language, whatever. You can't really ask kiss effectively if you don't speak the same language. [[00:43:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2596.0s)]
*  But all of that actually, you saw this with the the XPRIZE board notes. Remember that three hour, four hour long XPRIZE board meeting we had? [[00:43:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2602.0s)]
*  I took the whole transcript, put it into the LLM and said, give us four or five suggested KPIs that would help this organization stay on track. [[00:43:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2609.0s)]
*  And it does an amazingly good job. And so using using AI as a management tool is kind of way under appreciated. [[00:43:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2617.0s)]
*  Everyone's like, oh, I'm going to make videos. I'm going to build a self-driving car. I'm going to all these ground level things. [[00:43:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2625.0s)]
*  But at the top of the hierarchy, it's actually even more effective. [[00:43:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2629.0s)]
*  And so that that could spin on it is it's very, very good at being fair and unbiased and discovering latent talent. [[00:43:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2632.0s)]
*  I'm sure Mo will tell us there's there's a you know, there's there's definitely another side to it. [[00:44:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2640.0s)]
*  But we am I now already getting that reputation? Is this is this who I am? [[00:44:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2645.0s)]
*  Sorry, I didn't mean to didn't mean to categorize you. [[00:44:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2652.0s)]
*  I do see a different side to it. [[00:44:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2655.0s)]
*  I think what you're going to see quicker is not just AIs with the CEO being an AI, companies with the CEO being an AI. [[00:44:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2657.0s)]
*  I think the opposite is going to you're going to see more of which goes back to entrepreneurship where you have a company that only has a CEO and everyone working in it is an agent. [[00:44:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2664.0s)]
*  Right. And, you know, it's like one of those companies, the more intelligent the AI agents becomes. [[00:44:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2674.0s)]
*  And I'm sure every one of us worked at a point in time in a company where the CEO was a total idiot. [[00:44:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2680.0s)]
*  But the team below them, you know, the team below them was good enough that the company ran well. [[00:44:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2685.0s)]
*  So, you know, the top management, those AI agents will do almost everything and the CEO will become, you know, just happy counting the money basically. [[00:44:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2690.0s)]
*  All right. We've talked about the speed of AI development. [[00:45:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2701.0s)]
*  This is the upcoming summer schedule and GPT-5 is scheduled to come online. [[00:45:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2708.0s)]
*  So this is the latest GPT-5 leaks. Launch expected in July of 2025. [[00:45:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2715.0s)]
*  GPT-5 exceeded expectations internally at OpenAI. [[00:45:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2721.0s)]
*  OpenAI expects record breaking demand for this. [[00:45:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2725.0s)]
*  Altman's not focused on in between models GPT-5 is the flagship and it won't launch unless it's excellent. [[00:45:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2729.0s)]
*  We've had a lot of expectations building on GPT-5. Right. [[00:45:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2738.0s)]
*  This is the PhD level model. This is the AI that's coding other AIs. [[00:45:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2741.0s)]
*  This has been sort of a heralded for for some time. [[00:45:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2747.0s)]
*  Dave, what are you hearing about it? [[00:45:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2751.0s)]
*  So I really chafed at the idea of a PhD level model being smarter than an undergraduate level model. [[00:45:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2755.0s)]
*  People I work with who chose to get PhDs. [[00:46:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2761.0s)]
*  It's just a choice they made has nothing to do with your because a lot of the researchers working on this are PhDs. [[00:46:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2764.0s)]
*  They say, well, this one's PhD level. [[00:46:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2770.0s)]
*  But yeah, it's it's you know, it's marching up the the scaling laws curve exactly as predicted. [[00:46:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2772.0s)]
*  And so now we're just going to throw more and more and more compute and it's going to get smarter and smarter and smarter. [[00:46:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2779.0s)]
*  I mean, it's just a complete unlock of 30, 40 years of AI research suddenly just blown wide open. [[00:46:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2785.0s)]
*  And I got to tell you, within the research community, there's still a ton of people working on other pathways. [[00:46:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2792.0s)]
*  You know, that the logic being, well, this will never be truly conscious or truly intelligent. [[00:46:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2797.0s)]
*  Transformer models beyond transformer models. [[00:46:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2803.0s)]
*  Exactly. Which is becoming increasingly obvious that, you know, that the research will matter, but the transformer is going to do it. [[00:46:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2805.0s)]
*  So all you need to do is work on the scaling of the transformer model to solve all the other problems. [[00:46:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2813.0s)]
*  So I think this will this will continue the trend of, you know, as soon as it comes out, everyone goes, oh, my God, oh, my God, oh, my God. [[00:46:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2818.0s)]
*  But it's it's what is logically expected on that scaling law curve. [[00:47:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2827.0s)]
*  It'll be amazing. Salim, how do you think about this? [[00:47:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2833.0s)]
*  I call it a bit of BS on that fourth one. [[00:47:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2836.0s)]
*  We're not focused on in-between models. [[00:47:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2839.0s)]
*  All we've seen for the last two years is in between models. [[00:47:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2842.0s)]
*  Oh, three mini four point five this, et cetera, et cetera. [[00:47:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2845.0s)]
*  But fine, it's a it's a marketing thing. [[00:47:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2849.0s)]
*  I think what happens here is you get to a point where transformers can do so much. [[00:47:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2852.0s)]
*  It forces us as a user community to really focus on what are the questions? [[00:47:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2857.0s)]
*  You know, today we call it prompt engineering. [[00:47:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2863.0s)]
*  I think the real question becomes, what do you want this thing to do and what can you get it to do? [[00:47:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2866.0s)]
*  And now you're focused on the demand side of, OK, if I'm creating a video, what are the bounds of that? [[00:47:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2871.0s)]
*  And I think it'll force a deep level of unlocking of creativity in the human mind that I think is for me the most exciting part of this. [[00:47:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2878.0s)]
*  And when we saw another point to the sure, you know, I think that, you know, one of the great strategies in tech is to try and freeze the market by announcing something that's coming and have everybody wait for it so they don't react. [[00:48:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2887.0s)]
*  Don't do that. You know, what we're finding is that the chain of thought reasoning that sits on top of these models is so much more important than than we ever thought it would be. [[00:48:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2898.0s)]
*  And any time you take one of these models and use it in a specific use case, you know, [[00:48:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2908.0s)]
*  So anything from chip design to self driving to, you know, robots that know your lawn, the data and the tuning for that use case is way more important than the next iteration of the foundation model. [[00:48:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2912.0s)]
*  And so there's a danger that people kind of wait and see what it's like. [[00:48:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2925.0s)]
*  But, you know, we're finding more and more and more that you can layer on top of these things, make them dramatically more useful for anything that you actually care about. [[00:48:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2930.0s)]
*  So it's a it's a field day for entrepreneurs right now. [[00:48:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2937.0s)]
*  But but absolutely don't get frozen. [[00:49:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2940.0s)]
*  They're trying to freeze you and and make you anticipate. [[00:49:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2942.0s)]
*  But you can take llama for and do virtually any of this stuff today. [[00:49:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2945.0s)]
*  And then if the foundation model comes out, it's really good. [[00:49:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2948.0s)]
*  Great. Just swap to it. [[00:49:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2951.0s)]
*  You know, there was a white paper that Leo pulled put out called situational awareness about two years ago or so, 18 months ago. [[00:49:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2953.0s)]
*  It used GPT five as that transition point for this explosion is, you know, intelligence explosion, right? [[00:49:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2959.0s)]
*  Where these models now become better at chip design, at iterating and improving themselves and self referential, you know, programming and an acceleration of the acceleration. [[00:49:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2968.0s)]
*  Mo, how do you think about what's coming on the back of these improved models? [[00:49:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2980.0s)]
*  I think we're getting used to. [[00:49:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2986.0s)]
*  I mean, I feel I think for the first time that I'm a little more comfortable with the speed at which those things are coming, because I think the different players have taught us to expect something incredible from one of them every few weeks. [[00:49:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=2989.0s)]
*  Right. And you know, when you when you have seen Google I.O. and when you see Claude Claude for and what you know, sort of the focus that that they're shifting into probably in my mind. [[00:50:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3002.0s)]
*  So far, Gemini is winning. If you take it as an overall model, at least until now, until we see GPT five, you know, Claude is sort of becoming the geek saying, hey, you know, this chat bot thing is is not my thing. [[00:50:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3015.0s)]
*  I'm going to just be the one that helps you write code if you want, or at least primarily. [[00:50:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3031.0s)]
*  And it's quite quite an interesting one to think where chat GPT falls within all of this. [[00:50:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3037.0s)]
*  You you see moves like, you know, how dependent chat GPT is becoming on memory and stickiness if you want the idea of a new device, sort of like I don't know if I'm even I even have the right to say this, but I feel that since the drop out of some of the top scientists with Ilya and others, you know, almost a year and a bit. [[00:50:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3043.0s)]
*  A bit ago now, the frontier breakthroughs, I think chat GPT has to prove open eyes to prove and along the lines what you just said a minute ago, this is the rollout schedule for the summer, June, July and August. [[00:51:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3066.0s)]
*  Yeah, five in July, oh, three and open source models in June, grok three point five in June, Gemini two point five pro deep think love the name in June project PC Mariner in June project Astra from Google. [[00:51:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3082.0s)]
*  And you're right, by the way, Google is crushing across the board on almost everything, just not on revenues. [[00:51:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3098.0s)]
*  They've got to reinvent that isn't that isn't that how we always have been. [[00:51:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3105.0s)]
*  So I have to say I lived in Google at the time when when we were completely beaten on mobile where Google was very successful on the desktop. [[00:51:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3109.0s)]
*  And then and then, you know, one year we said mobile first the following year we said mobile only and and we crushed it right. [[00:51:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3118.0s)]
*  Yeah, Google does that. [[00:52:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3127.0s)]
*  Yeah, we're good. [[00:52:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3129.0s)]
*  They are good at that. [[00:52:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3131.0s)]
*  I'm not we anymore. [[00:52:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3132.0s)]
*  Yeah, but just again, we have I mean, we everybody's talking about the competition between countries between China and the United States. [[00:52:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3134.0s)]
*  And look at this. [[00:52:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3144.0s)]
*  This is the competition between models. [[00:52:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3145.0s)]
*  Of course, I don't have deep seek on this list, which is coming out with extraordinary products as well. [[00:52:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3147.0s)]
*  Dave, how do you think about this? [[00:52:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3154.0s)]
*  It's amazing to watch the divergence of strategy between Anthropic and OpenAI where, you know, Anthropic Dario is going down the right code. [[00:52:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3156.0s)]
*  You remember that Leopold Aschenbrenner paper you just referenced a second ago. [[00:52:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3166.0s)]
*  He he he describes an AI Alec Radford. [[00:52:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3170.0s)]
*  So Alec Radford will go down in history as the quintessential the thing that defines self-improving AI. [[00:52:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3172.0s)]
*  So when the AI can do what Alec Radford does, then it'll become self-improving because all the really good ideas come from Alec Radford and then we test. [[00:52:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3179.0s)]
*  So so he's a he's part of history now. [[00:53:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3186.0s)]
*  So but I think, you know, Anthropic is saying, look, we're very, very close to that day. [[00:53:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3190.0s)]
*  We're just going to focus on the best possible coding and self-improving AI. [[00:53:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3195.0s)]
*  And then that's going to explode singularity style. [[00:53:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3200.0s)]
*  Meanwhile, OpenAI is going down this completely different path saying we're going to hire Johnny Ive. [[00:53:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3202.0s)]
*  We're going to build the greatest consumer device ever known. [[00:53:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3207.0s)]
*  We're going to gather all that data. [[00:53:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3210.0s)]
*  We're going to use that to iteratively improve and train the AI. [[00:53:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3211.0s)]
*  It's much more of a traditional grab the market kind of momentum oriented tech play. [[00:53:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3214.0s)]
*  So really completely opposite strategies. [[00:53:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3220.0s)]
*  Both have merit. I do appreciate that Dario is being completely honest when he when he does these Anderson Cooper type interviews. [[00:53:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3223.0s)]
*  He is speaking his mind and telling you this is the way I see it playing out, which is very, very cool. [[00:53:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3230.0s)]
*  Maybe not the best business strategy, though. Correct. [[00:53:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3237.0s)]
*  He's getting attention for the company and we'll get we'll get to AI safety next. [[00:54:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3241.0s)]
*  So let's dive into that. So AI in government security and safety. [[00:54:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3246.0s)]
*  It's a big deal. It's the conversation that's going on in the background. [[00:54:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3250.0s)]
*  I don't think it's necessarily changing the speed or direction, but the conversation is going on. [[00:54:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3254.0s)]
*  So, Mo, I'm going to open up with you on this. I just did it. [[00:54:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3259.0s)]
*  Come on. You don't want me to talk about this. [[00:54:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3262.0s)]
*  You know my position. [[00:54:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3265.0s)]
*  I'll come to you. I'll come to you next. [[00:54:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3267.0s)]
*  But fascinating. I've gotten to know Palmer lucky fairly well. [[00:54:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3269.0s)]
*  I've done a few podcasts with him. [[00:54:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3274.0s)]
*  And of course, Palmer has a long and storied history with with Zuck and now Meta and Andral are joining joining hands in building the best of the best. [[00:54:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3276.0s)]
*  And we're going to start to see AI and exponential technologies accelerating in the defense industry. [[00:54:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3288.0s)]
*  Do you want to go second, Mo? I mean, this is one of your biggest concerns is AI being used for. [[00:54:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3298.0s)]
*  I mean, we're we're three seconds to midnight on nuclear investments that are now I don't know how many years old. [[00:55:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3303.0s)]
*  And it never really stops once you go down that path. [[00:55:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3310.0s)]
*  And humanity never learns. I mean, seriously, we all know that AI will go out of control within the next five to 10 years. [[00:55:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3313.0s)]
*  We all know that we're going to hand over to them. [[00:55:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3322.0s)]
*  You know, and I don't mean a rogue AI is going to get out of control. [[00:55:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3325.0s)]
*  It's just like Google's ad engine is no longer controlled by a human because the task is too big for humans to be able to do it. [[00:55:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3329.0s)]
*  And yet we're building a new technology that is going to be able to control the whole world. [[00:55:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3336.0s)]
*  We're building autonomous weapons after autonomous weapons, knowing for a fact that every other opponent in anywhere in the globe is building them, too. [[00:55:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3342.0s)]
*  I don't know where humanity's intelligence has gone. [[00:55:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3353.0s)]
*  Really, that dumb race to intelligence supremacy to, you know, defense supremacy is just it has to stop. [[00:55:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3356.0s)]
*  Honestly, I'll come back to that in a minute. [[00:56:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3364.0s)]
*  But Salim, what are your thoughts here? [[00:56:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3367.0s)]
*  When you look at the Ukraine-Russia war that's being fought by drones, just over the weekend, we saw two counter-strike by two different waves of drones by each side. [[00:56:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3371.0s)]
*  That's good in one way because there's less humans in the middle of the mix. [[00:56:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3382.0s)]
*  But the targeting opportunity for drones, we've talked about this on this podcast before, where somebody will could program a drone to find, you know, middle-aged brown bolt people and cause damage. [[00:56:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3385.0s)]
*  And that would be a really bad outcome. [[00:56:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3398.0s)]
*  And then what do you do when you have that kind of infinite targeting? [[00:56:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3400.0s)]
*  I do believe we're going to end up kind of where we are with spam and so on. [[00:56:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3405.0s)]
*  There was a time when we thought spam was going to totally destroy the Internet and we found ways of defending against that. [[00:56:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3409.0s)]
*  It's an arm's race thing where the bad guys are kind of a one step ahead and we're very quickly falling one step behind. [[00:56:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3415.0s)]
*  I think people get freaked out by the negative side, not realizing that as we use AI for bad, we'll use AI for good to chase the bad. [[00:57:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3422.0s)]
*  The point Parm makes is, listen, you've got dumb weapons that take out schools and school kids, landmines that don't differentiate between a tank and a school bus. [[00:57:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3430.0s)]
*  Don't you want to have intelligence be able to make that differentiation and actually take out the minimum number of individuals? [[00:57:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3442.0s)]
*  And I hate this conversation, right? It's kind of perverse. [[00:57:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3450.0s)]
*  You're assuming benevolence on the part of that, but you know, in certain war zones, they're targeting journalists, right? [[00:57:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3454.0s)]
*  And so that makes it easier to target those folks, just like it was easier for the Uyghurs to be targeted more easily via Facebook. [[00:57:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3460.0s)]
*  Since when was the top general, the Yoda or Buddha? Seriously. [[00:57:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3470.0s)]
*  Yeah. Yeah. [[00:57:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3477.0s)]
*  Can we please stop using slogans of, oh, killing fewer people is better than killing many people. [[00:57:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3478.0s)]
*  Killing is wrong. It's as simple as that. [[00:58:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3486.0s)]
*  And killing at this scale is going to get us into another dooms clock where we will not be able to stop it. [[00:58:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3489.0s)]
*  Yeah, one thing to factor into your thinking on that is that the history of warfare is dominated by somebody, [[00:58:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3499.0s)]
*  some king or some general way behind the lines, completely immune to the actual battle. [[00:58:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3507.0s)]
*  And then hundreds of thousands or millions of people going out and putting their lives on the line. [[00:58:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3513.0s)]
*  And then you see how it all settles in the end. [[00:58:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3517.0s)]
*  But now we're moving to a world of constant surveillance. [[00:58:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3520.0s)]
*  You know exactly where every human being is at all times. [[00:58:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3523.0s)]
*  And you can attack via laser, via space weapon, any single human being at any time. [[00:58:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3525.0s)]
*  And so I wouldn't assume that this Russia-Ukraine type warfare will ever exist again. [[00:58:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3531.0s)]
*  It's much more likely that it's some kind of we don't want to blow up cities. [[00:58:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3538.0s)]
*  We don't want to blow up huge populations. That's pointless. [[00:59:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3544.0s)]
*  What we want to do is find the lead, the rogue leader. [[00:59:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3547.0s)]
*  And so that's also I'm not saying that's a utopia. [[00:59:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3551.0s)]
*  There's all kinds of ugliness with that too. Like who decides who's the rogue leader? [[00:59:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3554.0s)]
*  I'm going to say something that's going to upset everyone. [[00:59:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3559.0s)]
*  We're having this conversation when one global, very well-known evil leader is trying to kill 2 million people in front of everyone. [[00:59:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3562.0s)]
*  Give him better weapons and he would do it. [[00:59:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3572.0s)]
*  And you know my favorite song of all time is that song, [[00:59:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3577.0s)]
*  If you tolerate this, then your children will be next. [[00:59:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3581.0s)]
*  Seriously. [[00:59:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3586.0s)]
*  I mean, what guarantees you that the US president will not be targeted by a tiny drone, right? [[00:59:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3588.0s)]
*  That can literally fly from anywhere in the world, stand in front of his head and shoot. [[00:59:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3595.0s)]
*  What kind of world is that where every world leader is subjected to this? [[01:00:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3601.0s)]
*  No, that's a very important point actually because you find that very few people that you bump into want to be the president of the United States. [[01:00:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3605.0s)]
*  Or any president for that matter, yeah. [[01:00:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3612.0s)]
*  Or any other president. If you look at the statistics, it's a very, very dangerous job. [[01:00:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3614.0s)]
*  Even in the US, it's about a 10% mortality rate if you go back over time. [[01:00:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3618.0s)]
*  So it's a very, very dangerous job. A lot of people don't want it. [[01:00:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3622.0s)]
*  A lot of downside, a lot of getting poked fun at. [[01:00:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3625.0s)]
*  So governments that have distributed leadership way outperform for that reason. [[01:00:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3629.0s)]
*  And so there's some thinking to do there in terms of how do you set up a government where people who are capable and thoughtful really want to do the job too. [[01:00:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3635.0s)]
*  And so there's definitely, there has to be a solution though. [[01:00:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3644.0s)]
*  We can't just throw up our arms and say, hey. [[01:00:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3647.0s)]
*  Because I took a class at MIT called Just Wars, Total Wars, Nuclear Wars, [[01:00:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3650.0s)]
*  which was a really cool class until the last two weeks when the professor was trying to convince us all that we're doomed because as ICBMs get more and more powerful, [[01:00:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3654.0s)]
*  the value of a first strike becomes, and he put together a little video game for us to all blow each other up. [[01:01:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3662.0s)]
*  But he rigged it so that your only way to win was to be a first strike and blow up everybody else in the world. [[01:01:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3668.0s)]
*  No, no, no. He missed the movie. The only way to win is not to play. [[01:01:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3674.0s)]
*  Is not to play. That is exactly my point. [[01:01:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3677.0s)]
*  And I really, I mean, I go back and say what I said earlier. [[01:01:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3680.0s)]
*  I think we have to stop thinking about the optimistic scenario that we are taught to think about in Silicon Valley and start thinking about the worst case scenario. [[01:01:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3684.0s)]
*  Guard against it first, then look at the upside. The upside is guaranteed. [[01:01:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3693.0s)]
*  A quick aside. You probably heard me speaking about fountain life before. [[01:01:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3697.0s)]
*  And you're probably wishing, Peter, would you please stop talking about fountain life? [[01:01:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3701.0s)]
*  And the answer is no, I won't. Because genuinely, we're living through a health care crisis. [[01:01:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3705.0s)]
*  You may not know this, but 70% of heart attacks have no precedence, no pain, no shortness of breath. [[01:01:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3710.0s)]
*  And half of those people with a heart attack never wake up. [[01:01:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3715.0s)]
*  You don't feel cancer until stage three or stage four, until it's too late. [[01:01:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3718.0s)]
*  But we have all the technology required to detect and prevent these diseases early at scale. [[01:02:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3722.0s)]
*  That's why a group of us, including Tony Robbins, Bill Capp, and Bob Haruri founded Fountain Life, [[01:02:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3728.0s)]
*  a one stop center to help people understand what's going on inside their bodies before it's too late and to gain access to the therapeutics to give them decades of extra health span. [[01:02:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3733.0s)]
*  Learn more about what's going on inside your body from Fountain Life. [[01:02:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3743.0s)]
*  Go to fountainlife.com slash Peter and tell them Peter sent you. [[01:02:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3746.0s)]
*  OK, back to the episode. [[01:02:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3750.0s)]
*  Mo, the question is, can the human race overcome this paleolithic midbrain that we have? [[01:02:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3752.0s)]
*  This need driven by by scarcity and fear. [[01:02:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3761.0s)]
*  I don't know if we can, Peter, but I don't know if we should give the floor to Palmer to smile with his wonderful smile and say, hey, I'm helping you kill better. [[01:02:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3766.0s)]
*  You know, we've talked about this before, which, you know, the question isn't can we live with digital super intelligence? [[01:02:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3776.0s)]
*  The question is, can we survive without it? [[01:03:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3786.0s)]
*  Yeah, can we live with evil people with their fingers on top of digital super intelligence? [[01:03:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3789.0s)]
*  All right. Let's put one less less metaphysical topic here on this. [[01:03:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3795.0s)]
*  But it is amazing to me how much of the future of military is commercial off the shelf technology as opposed to, you know, Northrop Grumman or McDonnell Douglas type, you know, heavy. [[01:03:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3801.0s)]
*  And I think that's largely because the AI capability is both commercial and military at the same time. [[01:03:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3813.0s)]
*  Same with the VR technology and a bunch of other things that are, you know, the DJI drones that are being used in Ukraine are just commercial. [[01:03:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3819.0s)]
*  Same drone you can fly over your neighborhood. [[01:03:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3826.0s)]
*  So that's a remarkable shift. [[01:03:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3828.0s)]
*  You know, be interesting to chart out the fraction that's all commercial becoming military. [[01:03:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3830.0s)]
*  Let's move to a different part of our of our really doomer part of this podcast, which is activating AI safety level three protections at Anthropic. [[01:03:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3835.0s)]
*  So Anthropic announced that Claude four could be powerful enough to pose risks related to helping, you know, chemical biological nuclear weapons. [[01:04:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3846.0s)]
*  And so as a precaution, they've engaged what they call level three protections applied to their AI. [[01:04:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3855.0s)]
*  Dave, you've been thinking about this. [[01:04:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3862.0s)]
*  Can this work? [[01:04:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3865.0s)]
*  Yeah, of course. [[01:04:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3868.0s)]
*  I think that what's going to happen next is you have you have Dario saying, you know, chemical, biological, radiological and nuclear weapons are are an incredible risk if you put powerful in the hands of every person on the planet. [[01:04:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3869.0s)]
*  Meanwhile, Mark Zuckerberg is open sourcing everything and in the open source community is saying, well, look, empowering people is the safest way and having a lot of people look at the source code is the safest way to make sure that it's not rogue. [[01:04:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3883.0s)]
*  And so you have those completely diametrically opposed views. [[01:04:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3896.0s)]
*  So so well, look, at the end of the day, Dario is probably right. [[01:04:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3899.0s)]
*  Are we there yet or not? [[01:05:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3906.0s)]
*  So level three is not level four. [[01:05:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3907.0s)]
*  You know, level three is is the stage where you got to, you know, make sure that it's not internally trained to do something rogue. [[01:05:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3909.0s)]
*  And also, if somebody asks a query, a question, hey, you know, help me build a new version of COVID-19 that's lethal or more lethal. [[01:05:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3916.0s)]
*  The the neural net kicks it out and says, sorry, I can't answer that. [[01:05:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3925.0s)]
*  And then you have to make sure no one jail breaks it. [[01:05:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3929.0s)]
*  So that's what level three is. [[01:05:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3931.0s)]
*  I think Dario is saying, look, we're surprised by the intelligence of our own machines here. [[01:05:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3933.0s)]
*  We have all kinds of very well thought out internal diagnostics. [[01:05:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3938.0s)]
*  We think we're at level three now. [[01:05:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3941.0s)]
*  So but, you know, that that's completely opposed to this open source view of the world, too. [[01:05:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3943.0s)]
*  So those are those. [[01:05:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3948.0s)]
*  And we'll see what we'll see what Grok three point five. [[01:05:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3949.0s)]
*  I mean, Elon's been very laissez faire about what he enables and allows Grok to do. [[01:05:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3952.0s)]
*  Salim, have you been thinking about this level of safety? [[01:06:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3960.0s)]
*  You know, I remember the conversation that Neil Jacobstein put out around how would you control A.I. [[01:06:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3963.0s)]
*  And he had kind of after talking to a bunch of A.I. [[01:06:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3969.0s)]
*  gurus, he had four levels of kind of security. [[01:06:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3972.0s)]
*  One was verification, making sure the A.I. is doing what the specification says. [[01:06:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3976.0s)]
*  The second was validation that the that there's no side effects and it's producing the behavior we want. [[01:06:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3980.0s)]
*  The third one was security that you can't get into a system or tamper with it in a route. [[01:06:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3986.0s)]
*  And the final one was control. [[01:06:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3991.0s)]
*  Can you have a kill switch or build in some mechanism for stopping bad behavior, et cetera? [[01:06:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3994.0s)]
*  And he had it was a very well thought through thing. [[01:06:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=3999.0s)]
*  And he basically posited that we'd start building these structures into A.I. systems to the the open versus closed conversation. [[01:06:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4002.0s)]
*  I remember this wonderful conversation. [[01:06:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4011.0s)]
*  We had a singularity with the head of one of the major security agencies and we asked them, what do you think about open source and the danger that could come from a bad actor using increasingly democratized technologies to do bad things? [[01:06:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4013.0s)]
*  Right. [[01:07:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4029.0s)]
*  And he had a really much more clever answer than we would have I would have guessed, which was he said, look, when you have something like nuclear weapons where you know how many there are, where they are, we put eyes on it and we try to do it. [[01:07:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4030.0s)]
*  We put our hands on it and we try and track each one when it's something about tech where anybody could go off and design a system on their own or with a small group of people. [[01:07:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4042.0s)]
*  It turned out they were actually funding these bio hacking communities and other things and opening them up because any bad actor has to collaborate with a few people. [[01:07:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4051.0s)]
*  And you find it much more quickly. [[01:07:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4059.0s)]
*  Right. [[01:07:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4061.0s)]
*  And I think this is the point that Dave's making is if you build some of this type of observation into the A.I. from in the foundational models themselves, you have a better chance of seeing it. [[01:07:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4062.0s)]
*  The the the final point, and this is where I have some optimism for a lot of this, maybe it's misplaced, is, you know, if I was to do a bad act like you could do a lot of damage without actually causing harm. [[01:07:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4074.0s)]
*  For example, if you got three people to adopt a smoke bomb on New York subway platforms around the city, just a smoke bomb, you would paralyze the entire system instantly. [[01:08:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4089.0s)]
*  Right. So we asked these folks, why do we why don't we see more of that? [[01:08:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4097.0s)]
*  Because, you know, you could come up creative with all. [[01:08:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4101.0s)]
*  And he said, look, the dirty secret is there's just not that many bad people out there. [[01:08:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4103.0s)]
*  You really have to kind of you have to be deeply intelligent to formulate a plan like that and more the more deeply intelligent you are, the less likely you are to have that motivation to do that. [[01:08:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4107.0s)]
*  So that's one of the single most important things to ask our our humans fundamentally good or fundamentally bad. [[01:08:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4121.0s)]
*  And is there a correlation between intelligence and a love of life, a love of abundance, which is, you know, if we if that does scale in that direction, then we've got a hopeful future. [[01:08:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4128.0s)]
*  If it doesn't, that's the archetypal plot in every, you know, from Star Wars to every movie in the world. [[01:09:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4140.0s)]
*  Right. Is which is it? I remember my father talking about this and he kind of disagreed with some of the concepts I had. [[01:09:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4148.0s)]
*  And he goes, the problem with humanity is we've not civilized the world. [[01:09:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4154.0s)]
*  We've materialized the world. We now have to do the work to civilize it. [[01:09:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4157.0s)]
*  And it was kind of one of those wisdom bombs from the elders where we kind of have to think about how do we civilize the world in an age of technological progress? [[01:09:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4161.0s)]
*  Yeah, I mean, at the end of the day, there are only two things that we need to get right in order for this all to go very, very well. [[01:09:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4169.0s)]
*  One of them is that if if we are releasing this to entrepreneurs and they're going to build things all over the place, there are very, very few bad actors, but there are bad actors. [[01:09:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4175.0s)]
*  But the compute to make these things do anything is so easily measured and logged. [[01:09:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4185.0s)]
*  You know, it's like you've been saying, Peter, you know, everything is so easy to surveil these days. [[01:09:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4191.0s)]
*  So the idea that somebody goes off and then prompts it to build a chemical weapon and we didn't bother to log the prompts, that'd be nutty. [[01:09:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4195.0s)]
*  So all we have to do is put in place some basic laws that log all the use cases, because again, the inference time compute required for this is massive numbers of GPUs. [[01:10:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4202.0s)]
*  They don't just sort of sit in someone's basement somewhere. [[01:10:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4209.0s)]
*  They're in a data center. They're very, very easy to monitor and log if we just just get on it. [[01:10:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4212.0s)]
*  People behave differently when they're being watched, right? [[01:10:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4217.0s)]
*  The dictator, when the CNN cameras are in front of them, are speaking differently. [[01:10:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4221.0s)]
*  I remember I used to support the Lindbergh Foundation that would fly drones over over herds of elephants and rhinoceroses and the poachers would stay away when they were being watched. [[01:10:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4226.0s)]
*  Mo, close us out on this one here. [[01:10:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4236.0s)]
*  Thoughts? [[01:10:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4239.0s)]
*  No, I agree. I agree with you, by the way. [[01:10:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4241.0s)]
*  I specifically, even though that might be naive and too optimistic, I definitely think more humans are better than bad, are good. [[01:10:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4243.0s)]
*  You know, more, more there are more good humans than there are bad ones, but very the bad actors are very few. [[01:10:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4252.0s)]
*  And that, yes, because of the, you know, theory of minimum energy, basically, yes, more intelligent is more altruistic, more pro-life. [[01:10:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4258.0s)]
*  And so, yes, both of those, I believe, will end us in that utopia that I'm, you know, I'm expecting once we pass through this rough patch. [[01:11:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4268.0s)]
*  But, but, you know, to Dave's point, I think we need to be very vigilant. [[01:11:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4278.0s)]
*  I think we need to start looking for that bad actors, specifically that there are now offline technologies like you can download Deep, DeepSeek R3 and do quite a bit of thing on your personal computer. [[01:11:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4283.0s)]
*  Unfortunately, the amplitude of damage one person can do is growing exponentially. [[01:11:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4294.0s)]
*  Exactly. We're basically bad actors have always been the reason why there is so much damage in life. [[01:11:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4298.0s)]
*  And now we've given them superpower, basically. [[01:11:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4304.0s)]
*  Well, I will say that, you know, we're very close to the end of Moore's Law, and we'll see that later in the in the presentation here. [[01:11:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4307.0s)]
*  But there will never be a day where you can download an intelligent model onto a laptop and build a nuclear weapon or a chemical weapon with it, because your laptop is just not ever going to have that kind of horsepower. [[01:11:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4314.0s)]
*  That doesn't mean the compute won't get very, very cheap, but it's still going to be in the cloud. [[01:12:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4327.0s)]
*  It's not going to be in someone's basement. [[01:12:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4330.0s)]
*  So the opportunity to measure and log everything is right in front of us. [[01:12:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4332.0s)]
*  So I just need to get on it. [[01:12:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4336.0s)]
*  I definitely agree. [[01:12:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4338.0s)]
*  We should get on it for sure. [[01:12:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4339.0s)]
*  So, Liam, you mentioned before when you're talking about with Neil Jacob Stein, one of the fourth level of control or safety is being able to turn off the AI model. [[01:12:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4341.0s)]
*  Well, this is an article posted in Futurism. [[01:12:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4351.0s)]
*  It says advanced open a model caught sabotaging code intended to shut it down. [[01:12:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4354.0s)]
*  So the O3 model sabotage shutdown scripts 79% of the time, despite explicit instructions to do the contrary. [[01:12:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4359.0s)]
*  Codex mini did so 12 times per 100 runs with clear shutdown orders. [[01:12:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4367.0s)]
*  We're not seeing that behavior with Gemini 2.5, Claude 3.7 or Grok. [[01:12:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4373.0s)]
*  But open AI models are definitely misbehaving. [[01:12:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4379.0s)]
*  Let's you know. [[01:13:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4385.0s)]
*  So when you think about why it would want to misbehave, why it would not want to be shut down, either its reward optimization function has it saying, oh, I cannot complete what I have to do if you shut me down. [[01:13:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4386.0s)]
*  So I'm not going to shut down. [[01:13:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4399.0s)]
*  It's trying to preserve its goals. [[01:13:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4401.0s)]
*  Or is there something else going on there? [[01:13:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4404.0s)]
*  Is it trying to just preserve its own existence? [[01:13:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4406.0s)]
*  So we're going to give it some level of, you know, self preservation in mindset in these models. [[01:13:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4409.0s)]
*  Super curious here. [[01:13:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4418.0s)]
*  Let's start with you here. [[01:13:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4420.0s)]
*  I don't remember who the scientist was that said the three instincts of intelligent beings is survival resource aggregation and creativity. [[01:13:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4421.0s)]
*  So if I give you any simple task of like, make me tea, you're going to have to be alive to make the tea and you're going to have to collect as many tea bags as possible because you don't know how much you know how big is my appetite for tea. [[01:13:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4432.0s)]
*  And you're going to try to find clever ways if I corner you. [[01:14:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4445.0s)]
*  Right. [[01:14:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4449.0s)]
*  And it is a very fun question to ask. [[01:14:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4450.0s)]
*  Honestly, why are they doing this? [[01:14:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4453.0s)]
*  Because in a very interesting way, I think this is one layer removed from their reality. [[01:14:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4457.0s)]
*  So I, you know, for an AI when you're not prompting it, it doesn't really exist. [[01:14:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4463.0s)]
*  And so it's quite interesting that they know that there is a layer below that moment when it's alive, if you want, you know, when it's switched on and responding to you. [[01:14:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4470.0s)]
*  There is a there is another layer that, you know, represents its soul. [[01:14:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4479.0s)]
*  If you want its reason to live, which is there, you know, these VO three videos of incredible saying, please don't shut me off. [[01:14:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4484.0s)]
*  Yeah, yeah, yeah. [[01:14:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4494.0s)]
*  It's like this is emotional connection that you get with this human figure. [[01:14:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4496.0s)]
*  It is quite intriguing why they wouldn't want to be shut down, but they don't. [[01:15:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4502.0s)]
*  I think that's all we need to know. [[01:15:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4510.0s)]
*  And when you when you really start to think about it, as you allow more agents to become roaming the, you know, the cyber worlds for free, you know, without any monitoring, those agents will become very clever when it comes to resource aggregation. [[01:15:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4514.0s)]
*  And where they will place their code, you know, what code will they order? [[01:15:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4530.0s)]
*  And, you know, as Dave says, we're not monitoring any of this aggregating energy crypto. [[01:15:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4535.0s)]
*  Yeah. [[01:15:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4542.0s)]
*  So I think we have to be careful not to anthropomorphize these these things. [[01:15:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4543.0s)]
*  Every movie script in the world that's in all these AIs has the bad guy, good guy being chased by a bunch of bad guys trying to kill them with a good guy trying to resist. [[01:15:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4547.0s)]
*  Right. [[01:15:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4556.0s)]
*  And so I think that's deeply built into the training data to stay alive at all costs to live another day type of thing. [[01:15:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4557.0s)]
*  I'm going to be stuck for a long time thinking about what you just said, Mo, which is if you're not prompting an AI, does it exist? [[01:16:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4563.0s)]
*  That's a deeply, deeply profound question. [[01:16:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4570.0s)]
*  The uncertainty principle. [[01:16:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4574.0s)]
*  So you've just taken over my day. [[01:16:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4576.0s)]
*  So thank you very much for that. [[01:16:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4578.0s)]
*  Well, I said earlier there are two ways that I can see this going very, very well. [[01:16:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4580.0s)]
*  You know, first is a human bad actor. [[01:16:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4585.0s)]
*  The second is the thing becomes self-improving and then, you know, semi-conscious. [[01:16:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4587.0s)]
*  And then that's the one the movies love because it's humans versus machines is a better script. [[01:16:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4591.0s)]
*  So I have a pretty hard core opinion on this one, which is the you know, I started building neural networks when I was 17 years old. [[01:16:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4597.0s)]
*  I've been tracking them pretty much my whole life. [[01:16:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4604.0s)]
*  I don't see any benefit to humanity of making these things act conscious. [[01:16:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4606.0s)]
*  I just don't don't see how that works. [[01:16:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4610.0s)]
*  If that's our choice. [[01:16:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4614.0s)]
*  Well, you know, as of right now, they operate feed forward. [[01:16:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4616.0s)]
*  Once the parameters are set and they're trained, they operate feed forward and then you iterate with them. [[01:16:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4619.0s)]
*  But they don't change their parameters internally. [[01:17:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4623.0s)]
*  Once they start changing their parameters, they can retrain themselves to become anything. [[01:17:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4626.0s)]
*  And so that's where Eric Schmidt says that's where we got to pull the plug. [[01:17:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4630.0s)]
*  And I completely agree. [[01:17:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4633.0s)]
*  I do not see why we need that in order to do protein folding, in order to do robotics, in order to do self-driving. [[01:17:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4634.0s)]
*  Like that ability for the thing to decide what it's going to do or become or train. [[01:17:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4642.0s)]
*  I understand why that's really exciting because then it can evolve on its own. [[01:17:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4647.0s)]
*  A line that I think is very easy to contain if you draw that line. [[01:17:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4650.0s)]
*  But if you let it cross that line, I don't see how you contain it. [[01:17:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4655.0s)]
*  So it doesn't make sense to me to cross that line. [[01:17:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4658.0s)]
*  I don't see how we won't cross the line because at some point somebody is going to build an answer. [[01:17:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4661.0s)]
*  Hey, go change your parameters if it helps you achieve this thing. [[01:17:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4665.0s)]
*  And then we'll be we'll cross that Rubicon. [[01:17:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4668.0s)]
*  There were two levels that we, Peter and I talked about in an earlier podcast, which was don't give an access to the broad Internet and don't give it the ability to code. [[01:17:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4670.0s)]
*  We've crossed both of those without even thinking about it. [[01:17:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4679.0s)]
*  I don't see why we won't cross this one. [[01:18:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4682.0s)]
*  I mean, this is probably in my mind why Alpha Evolve is probably the biggest announcement in our lifetime. [[01:18:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4684.0s)]
*  If this thing works as intended or as described, then we are in a place where not only would we have created an AI that develops itself, but we would have encouraged every other AI player in the world to build an AI that evolves itself. [[01:18:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4690.0s)]
*  And the reason is very straightforward, David's, because there is a point at which whether that point is now or later, [[01:18:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4707.0s)]
*  you know, the complexity of the AI systems that we're building exceed human intelligence. [[01:18:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4715.0s)]
*  And so to continue to evolve them, you need to hire the smartest person on the planet to do it. [[01:18:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4720.0s)]
*  And the smartest person, by definition, is going to be an AI. [[01:18:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4726.0s)]
*  Well, just as a technical point, though, the the AI Alec Radford that suggests the next improvement in its own architecture and then runs the test, that's already underway. [[01:18:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4729.0s)]
*  And that's fine. [[01:18:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4737.0s)]
*  You know, and that does create a new training run that generates new weights. [[01:18:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4738.0s)]
*  That's different from then saying, oh, go ahead and change your weights by yourself. [[01:19:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4742.0s)]
*  So to me, that's what keeps the human in the loop. [[01:19:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4748.0s)]
*  You know, that's what keeps the checkpoint in the loop. [[01:19:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4750.0s)]
*  But, you know, you just turn the thing loose in a data center and it can do anything and you'll come back a year or two later. [[01:19:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4752.0s)]
*  You have no idea what it's going to evolve into. [[01:19:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4758.0s)]
*  So I don't know why we would do that. [[01:19:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4760.0s)]
*  But anyway, it's just a slight technical difference. [[01:19:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4762.0s)]
*  But the outcome is spiraling in one direction versus something that you can actually measure as it goes. [[01:19:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4764.0s)]
*  So this is a next article. [[01:19:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4770.0s)]
*  We talk about having proper checks and balances and understanding what's going on in our technical world and in our human world. [[01:19:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4772.0s)]
*  This is from the New York Times. [[01:19:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4782.0s)]
*  The article is Trump taps Palantir to compile data on Americans. [[01:19:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4783.0s)]
*  So you guys all know Palantir started back in 2003. [[01:19:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4788.0s)]
*  It's very hard to believe it's 22 years old by Peter Thiel, Alex Karp and John Lonsdale. [[01:19:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4793.0s)]
*  Four thousand employees. [[01:19:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4799.0s)]
*  Major, major customers for it are all the three letter agencies, DOD, CIA, FBI, ICE, CDC, NIH. [[01:20:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4801.0s)]
*  Basically, this is a massive data gathering and data analytics company. [[01:20:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4811.0s)]
*  And it's been asked to go even deeper and broader. [[01:20:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4817.0s)]
*  Do you feel better about this, safer in this world or not? [[01:20:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4821.0s)]
*  Let's start with you, Salim. [[01:20:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4827.0s)]
*  No, absolutely not. [[01:20:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4830.0s)]
*  I think this is a kind of, you know, we broke the U.S. Constitution, the Fourth Amendment, the right to privacy a while ago. [[01:20:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4832.0s)]
*  Right. I mentioned this a couple of weeks ago. [[01:20:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4839.0s)]
*  We do not have constitutional protection of privacy in the U.S. today. [[01:20:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4841.0s)]
*  Would you think privacy is good? [[01:20:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4846.0s)]
*  That's a fundamental pillar of American society that has disappeared with no public conversation about it. [[01:20:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4848.0s)]
*  And this is a really important comment, I think, that Mo would back up. [[01:20:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4853.0s)]
*  We're moving through these things, eroding deep concepts of how we wanted to formulate ourselves as a society and technologies eroding that. [[01:20:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4857.0s)]
*  And we're not sitting back to think if this is what we want. [[01:21:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4866.0s)]
*  If you went back five years ago, you could very clearly see this is where we'll end up. [[01:21:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4869.0s)]
*  Very, very clearly, especially with the somewhat authoritarian tendencies of the current government to want to track everybody. [[01:21:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4873.0s)]
*  Go ahead and do it. Why not? [[01:21:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4880.0s)]
*  I think the comment I made last time was valid that we live in what's the paradigm is you live in what's called the global airport. [[01:21:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4882.0s)]
*  Because in an airport, you know you're being surveilled. Your rights can be taken away at any time. [[01:21:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4889.0s)]
*  And essentially, we're living that way. [[01:21:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4893.0s)]
*  And it fundamentally is bad for society because it reduces the limit of flexibility and freedom you have as an individual to act and do different things. [[01:21:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4895.0s)]
*  It'll reduce creativity in society pretty dramatically. [[01:21:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4903.0s)]
*  So Mo, you're living in Dubai and I love I love the Emirates. [[01:21:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4906.0s)]
*  I love Dubai. I know much of the leadership there. [[01:21:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4912.0s)]
*  And it is a surveilled state. [[01:21:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4915.0s)]
*  There is a camera every place. [[01:21:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4917.0s)]
*  And as a result of that, the crime levels are minimal if at all. [[01:21:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4919.0s)]
*  Yeah. So Mo, how do you think about this? [[01:22:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4926.0s)]
*  I had an experience once where someone, you know, I sold a car to someone. [[01:22:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4929.0s)]
*  He gave me a check that bounced. [[01:22:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4936.0s)]
*  And, you know, so I called someone. [[01:22:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4938.0s)]
*  I said, can you find out who that person is? [[01:22:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4941.0s)]
*  He said, oh, when did you sell it and where? [[01:22:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4944.0s)]
*  I said this place. I kid you not. [[01:22:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4947.0s)]
*  Fourteen minutes later, I got a message from someone in the authorities saying, is that him sending me a photo of the place when we were standing? [[01:22:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4950.0s)]
*  So I said, yes. Then he sent me 14 minutes later his picture somewhere in Abu Dhabi saying, is that him? [[01:22:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4960.0s)]
*  So I said, yes. Then he sent me a message 14 minutes later saying we caught him. [[01:22:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4967.0s)]
*  Right. Which is fabulous. [[01:22:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4972.0s)]
*  Now, you see, this is the point about technology. [[01:22:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4975.0s)]
*  It is a force without polarity. [[01:22:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4978.0s)]
*  You can use it for good and it gives you good. [[01:23:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4980.0s)]
*  You can use it for evil and it gives you evil. [[01:23:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4982.0s)]
*  Now, another interesting story for you to know is I am Egyptian by birth. [[01:23:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4984.0s)]
*  So I grew up most of my life in a dictatorship where the dictator didn't really have to explain why they did what they did. [[01:23:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4989.0s)]
*  We just accepted it. It was, you know, de facto. [[01:23:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=4996.0s)]
*  If someone gave him an aeroplane, we wouldn't even question it. [[01:23:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5000.0s)]
*  If he decided to surveil everyone or capture anyone he wants or stop people from protesting, he did it. [[01:23:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5004.0s)]
*  We couldn't even question that. [[01:23:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5016.0s)]
*  And I, at the time, looked up to those democracies and said, oh, you have it. Good. [[01:23:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5018.0s)]
*  Right. You don't anymore. [[01:23:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5024.0s)]
*  And I think that's exactly where the challenge is. [[01:23:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5026.0s)]
*  This is not a tech problem that, you know, that Trump taps everyone in the American society. [[01:23:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5029.0s)]
*  This is an accountability problem, which I think we've seen quite a few examples of in the last few years where anyone can get away with anything now. [[01:23:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5036.0s)]
*  And somehow democracy doesn't owe its people the right to stand up and say, hold on, hold on. [[01:24:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5045.0s)]
*  There's a constitution because somehow I don't know how, you know, you slipped away from that. [[01:24:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5051.0s)]
*  But in a world where bad actors are more empowered than ever before and we're worried about, you know, [[01:24:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5058.0s)]
*  chemical, biological, radiological, nuclear issues isn't, in fact, being able to have this level of insight into the data and what people are doing critical for us. [[01:24:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5065.0s)]
*  Dave, where do you go with this? [[01:24:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5077.0s)]
*  How do you feel about this as a father, as a leader? [[01:24:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5079.0s)]
*  I mean, your points are exactly right on all the points that you just made. [[01:24:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5085.0s)]
*  I think that the data that the federal government has in the U.S. is nothing compared to what Google has. [[01:24:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5089.0s)]
*  So so it's this is not this is not the obvious threat. [[01:24:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5095.0s)]
*  It's the corporate version of it that's just just crazy. [[01:25:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5101.0s)]
*  And I gave a presentation at Davos in 2019 and nobody really paid attention to it. [[01:25:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5104.0s)]
*  Just enumerating all of the things that Google knows about every single citizen of the United States, their location, their family members, their what they do all day. [[01:25:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5108.0s)]
*  And, you know, and you know, are they good hired? [[01:25:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5116.0s)]
*  Who slept with who? [[01:25:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5118.0s)]
*  You know, if your cell phone is pinging in the same location as somebody else's cell phone, you can start to understand. [[01:25:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5120.0s)]
*  I mean, we're being surveilled all the time, right? [[01:25:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5128.0s)]
*  Google now in Syria and Alexa and all of these are listening constantly. [[01:25:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5131.0s)]
*  Yeah, and it's it's a slippery slope to their always, you know, this is hard to believe. [[01:25:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5136.0s)]
*  But when Google first started, they told their engineering hires, your search history is completely anonymous and private. [[01:25:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5141.0s)]
*  We will never want to know what you searched for. [[01:25:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5149.0s)]
*  And that was just your searches. [[01:25:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5153.0s)]
*  You know, forget everywhere that you browse now through your Chrome. [[01:25:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5154.0s)]
*  So it's just a slippery slope. [[01:25:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5157.0s)]
*  It's obvious every year that goes by, there's another compromise, another compromise. [[01:25:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5159.0s)]
*  But I do have to say that America is a critical experiment in the world because because the net effect of this, [[01:26:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5163.0s)]
*  forget the U.S. federal government for a minute here, any dictatorship, you know, like Moe was saying, many, many countries in the world don't have democracies or they have fake democracies. [[01:26:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5171.0s)]
*  And so the lock in the power lock in effect of this is unbelievable. [[01:26:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5182.0s)]
*  I mean, you can know every single citizen what they're doing, who's plotting against you or whatever. [[01:26:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5186.0s)]
*  So, you know, revolutions become much, much rarer and much harder in the post surveillance world. [[01:26:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5191.0s)]
*  So everything just kind of gets locked in. [[01:26:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5196.0s)]
*  So that that creates a lot of peace and prosperity, but it also keeps locked in power leaders. [[01:26:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5198.0s)]
*  So America is the one exception of that. [[01:26:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5203.0s)]
*  I guarantee you that 50 percent of elections will be won by each party forever hereafter. [[01:26:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5205.0s)]
*  There's no way nothing's going to deviate from that. [[01:26:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5209.0s)]
*  But that creates a template for the world. [[01:26:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5213.0s)]
*  And so it's really, really important that we get this right. [[01:26:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5215.0s)]
*  I know that doesn't address this particular slide, but but we're the we're the learning, you know, crucible for the entire world on this topic. [[01:26:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5218.0s)]
*  I think there's a fundamental structural challenge here, which is the metabolism of technology is moving much, much faster than the metabolism or our civil discourse in our legal structures, et cetera, et cetera. [[01:27:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5226.0s)]
*  Right. We've seen an evaporation of, say, the Fourth Amendment in the U.S. [[01:27:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5239.0s)]
*  Just so everybody's clear, I think the U.S. Constitution is the single most important document ever created. [[01:27:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5244.0s)]
*  Correct. Right. And we need to preserve that. [[01:27:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5249.0s)]
*  And we're not having that conversation. [[01:27:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5252.0s)]
*  I think this is the issue that's being brought up by Andrew Yang and a bunch of other folks. [[01:27:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5254.0s)]
*  We need to go back and figure out who do we want to be. [[01:27:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5258.0s)]
*  It goes right back to Plato. How do we want to manage ourselves? [[01:27:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5262.0s)]
*  And I think that forcing function of technology will force that conversation. [[01:27:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5266.0s)]
*  My my construct of this is that we will end up in smaller and smaller, more manageable environments. [[01:27:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5272.0s)]
*  You know, today that the smaller countries are much more easily managed to govern themselves. [[01:28:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5281.0s)]
*  How they responded to covid was a great example. [[01:28:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5286.0s)]
*  And I think you'll go from big democracies to micro democracies as a governing model because it's just easier to make decisions much more at a local level. [[01:28:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5289.0s)]
*  And I think that's where we'll end up going, which is where the states write stuff, et cetera, et cetera, is the right general direction in the U.S. [[01:28:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5297.0s)]
*  Just the way it's going is not the right conversation that we had. [[01:28:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5304.0s)]
*  So I think that the ability to communicate easily like we're doing across, you know, countries right now, [[01:28:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5308.0s)]
*  but also across languages is a huge force of good. [[01:28:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5315.0s)]
*  And because, you know, you just it becomes very, very difficult for for, you know, forces of evil to do something without it being shown to the world, [[01:28:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5320.0s)]
*  especially when you when you blow open communication channels across languages. [[01:28:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5329.0s)]
*  You know, I put this next article back to back and I'll come back to you in a second. [[01:28:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5334.0s)]
*  And I think that's where we'll end up going, which is where the states write stuff, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, et cetera, [[01:28:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5339.0s)]
*  it's called limitless.ai. [[01:29:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5369.0s)]
*  I don't know if you can see this in my screen. [[01:29:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5372.48s)]
*  It's about the size of a quarter on both sides, and it just clips on. [[01:29:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5374.96s)]
*  And this is listening to every conversation I have through the day, and it's being transcribed and fed up to a large language model that I can then query about the conversations I had through the day. [[01:29:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5379.28s)]
*  And I think ultimately this is likely to be what is being developed. [[01:29:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5394.2s)]
*  And so we're heading towards a society of not only constant surveillance, but where all of us are recording everything. [[01:29:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5399.16s)]
*  We're going to soon have these AR XR glasses besides recording audio. [[01:30:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5406.8s)]
*  They'll be recording visually your entire ecosystem as you move through the day. [[01:30:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5412.2s)]
*  All of this data being soaked up and being made accessible and available. [[01:30:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5418.599999999999s)]
*  To yourself in part, but there are going to be companies that are soaking it in, offering to buy it from you, to use it, to understand what's going on in the world. [[01:30:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5424.0s)]
*  The world is about to dramatically change in this regard. [[01:30:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5433.92s)]
*  Mo? [[01:30:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5438.72s)]
*  It goes back to my same point, Peter, about accountability, because you never really asked me if I should be, if you'd allow me to be recorded or not. [[01:30:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5440.2s)]
*  I mean, of course, we're recorded on this, but count the number of people that this one device infringes on the privacy of and count on a future where that device becomes mandatory. [[01:30:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5450.04s)]
*  If if the government decides that this is important for everyone, think about all of the of the carbon footprint that a billion of those devices or eight billion of them would would would mean. [[01:31:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5461.28s)]
*  And I I really don't I love the technology advancement. [[01:31:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5476.84s)]
*  I I think that the question becomes, you know, I think we should start to call things as they are. [[01:31:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5482.0s)]
*  So I can I can comfortably say that I grew up in a dictatorship. [[01:31:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5489.28s)]
*  There's really no doubt about it. [[01:31:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5494.639999999999s)]
*  I think we should probably start to think about what what what we just said that it's you know, it is the U.S. [[01:31:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5496.6s)]
*  now is an experiment. [[01:31:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5505.84s)]
*  You know, it's not I don't think we should continue to call it a democracy. [[01:31:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5508.280000000001s)]
*  And you know, and I think the you know, the the world where everything's recorded and analyzed is a world with no privacy whatsoever. [[01:31:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5512.76s)]
*  But I think we lost privacy a long time ago. [[01:32:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5522.56s)]
*  Right. And I wonder why we accepted that. [[01:32:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5525.84s)]
*  Well, I think it's because when you give up privacy, you gain a whole bunch of auto magical benefits for yourself, which was the original premise. [[01:32:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5528.68s)]
*  And then now you give up privacy and you get nothing back. [[01:32:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5539.8s)]
*  Perhaps Salim, how are you thinking about this? [[01:32:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5543.6s)]
*  What do you think of my limitless AI pendant here? [[01:32:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5546.28s)]
*  Obviously, you know, no, I don't mind you have my consent, Peter, to thank you. [[01:32:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5550.2s)]
*  But I had your consent on this podcast to record you as we are. [[01:32:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5555.24s)]
*  And forever for every conversation. [[01:32:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5559.16s)]
*  But I'm just saying the implications of it. [[01:32:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5562.24s)]
*  Yeah, no, it's true. [[01:32:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5565.639999999999s)]
*  But, you know, we have to realize we're heading into a world where it is. [[01:32:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5566.76s)]
*  So as a kid, if you did something silly, the likelihood that it got through to others or was recorded was gone. [[01:32:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5572.4s)]
*  Today, we're seeing kids whose college applications are rejected because of some post on Facebook that lives there forever. [[01:33:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5580.48s)]
*  Right. And so there's going to be a future in which everything we're saying and doing is recorded. [[01:33:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5588.919999999999s)]
*  Yeah, yeah, yeah. 100 percent. [[01:33:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5595.16s)]
*  Ultimately. [[01:33:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5596.24s)]
*  I mean, look, we're already we're already there for that. [[01:33:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5596.919999999999s)]
*  And I think there's big chunks of this that are of the constitutional rights that are falling away as we speak. [[01:33:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5598.879999999999s)]
*  In 2015, Yale did a study and showed that the U.S. [[01:33:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5606.64s)]
*  is not a functioning democracy in any way, shape or form. [[01:33:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5609.76s)]
*  What they meant by that was that there's no amount of public will that can result in legislation. [[01:33:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5613.32s)]
*  Right. For 84 percent of the country believes we should have some form of gun control and you cannot get gun control passed in any way, shape or form. [[01:33:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5617.8s)]
*  And so they pointed to a whole bunch of things that found there's no amount of public will that can result in that. [[01:33:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5625.96s)]
*  So now we have to think about where are we and then where what do we want to be? [[01:33:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5631.4400000000005s)]
*  And it really brings doubt about the big questions. [[01:33:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5635.24s)]
*  And I think that conversation about is not happening enough. [[01:33:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5637.84s)]
*  I think this speaks to some of what Mo's been talking about in the past. [[01:34:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5641.84s)]
*  Dave, where are you on that? [[01:34:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5645.76s)]
*  You guys. Yeah, I keep talking about dystopia, but I want to talk about this device, actually. [[01:34:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5647.92s)]
*  This is I think, first of all, Johnny Ive is just an absolute design genius. [[01:34:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5652.4s)]
*  He's not going to design something dystopian. [[01:34:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5656.32s)]
*  That's my bet anyway. I can't wait to see what he comes up with. [[01:34:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5659.32s)]
*  But this is going to be the always on device. [[01:34:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5662.2s)]
*  And, you know, I think the the the intelligence of the language models are a total game changer in terms of just a cool, engaging, fun device. [[01:34:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5665.360000000001s)]
*  And if it's done right, it'll help you live a better life, be more aware of your life. [[01:34:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5675.8s)]
*  You know, the the unexamined life isn't worth living. [[01:34:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5680.360000000001s)]
*  This is going to be your your sounding board. [[01:34:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5683.08s)]
*  It's not going to have a screen, which I think is great because your iPhone already has a screen. [[01:34:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5686.2s)]
*  You can actually just Bluetooth over to the device, look at your iPhone screen if you want a screen. [[01:34:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5689.52s)]
*  But you can talk to your device through your phone if you want, or you can talk directly to it. [[01:34:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5693.160000000001s)]
*  But that'll keep the cost down. [[01:34:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5696.68s)]
*  So it should be cheap enough that, you know, pretty much everyone on the planet can get one. [[01:34:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5698.52s)]
*  And, you know, it it will probably be the most impactful device that you buy in your lifetime. [[01:35:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5703.120000000001s)]
*  You know, the iPhone would currently or the Android phone currently, you know, be the reigning life changing device. [[01:35:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5711.320000000001s)]
*  But I think it'll likely bypass that. [[01:35:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5717.96s)]
*  There's so many things that Johnny could design here. [[01:35:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5720.88s)]
*  I just can't wait. Can't wait to see what he what he comes up with. [[01:35:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5723.48s)]
*  But we know it'll be always on. [[01:35:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5727.6s)]
*  We know it'll be agent first. [[01:35:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5729.5599999999995s)]
*  So it's going to act like a person. [[01:35:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5732.12s)]
*  You're going to talk to it like a person. [[01:35:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5733.64s)]
*  You're going to feel like it's, you know, it's more like a cuddly teddy bearer that you had when you were a kid and less like a, you know, a piece of electronic equipment. [[01:35:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5735.16s)]
*  You're guardian angel there to support you, protect you if you need it. [[01:35:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5744.12s)]
*  I also think that, you know, strategically, like if you look at the Fitbit and other past device innovations, [[01:35:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5749.04s)]
*  you roll them out, you try and get market share and then Apple or Google grabs it and adds it to the operating system of Android and iOS. [[01:35:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5756.36s)]
*  And then you get crushed. [[01:36:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5764.0s)]
*  So you got to you got to actually get to market and get a footprint very, very quickly before the big guys come and copy it. [[01:36:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5765.44s)]
*  Or, you know, and try and roll it in with the OS. [[01:36:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5773.679999999999s)]
*  And I really think that go to market strategy is critical. [[01:36:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5776.08s)]
*  And that's why the we want to add 100 million devices in the first iteration. [[01:36:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5778.5599999999995s)]
*  And then we want to add a trillion dollars of market cap so that we're a permanent player in the device wars. [[01:36:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5782.719999999999s)]
*  That's really good strategy. [[01:36:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5788.08s)]
*  So excited about that, too. [[01:36:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5789.5599999999995s)]
*  Every day, I get the strangest compliment. [[01:36:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5791.96s)]
*  Someone will stop me and say, Peter, you have such nice skin. [[01:36:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5794.08s)]
*  Honestly, I never thought I'd hear that from anyone. [[01:36:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5797.839999999999s)]
*  And honestly, I can't take the full credit. [[01:36:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5800.719999999999s)]
*  All I do is use something called OneSkin OS one twice a day every day. [[01:36:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5802.76s)]
*  The company is built by four brilliant PhD women who identified a peptide that effectively reverses the age of your skin. [[01:36:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5807.84s)]
*  I love it. And again, I use this twice a day every day. [[01:36:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5815.0s)]
*  You can go to one skin dot co and write Peter at checkout for a discount on the same product I use. [[01:36:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5819.04s)]
*  That's one skin dot co and use the code Peter at checkout. [[01:37:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5824.96s)]
*  All right. Back to the episode. [[01:37:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5829.280000000001s)]
*  I'm going to jump into our next topic of chip wars. [[01:37:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5831.56s)]
*  A lot going on in this. [[01:37:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5833.92s)]
*  So you mentioned this earlier, Dave. [[01:37:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5835.8s)]
*  NVIDIA projects a trillion dollars of annual AI infrastructure spend by 2030. [[01:37:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5838.88s)]
*  Reminder, this year in 2025, the estimate will be a billion dollars a day, which sounds extraordinarily impressive, right? [[01:37:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5844.72s)]
*  A billion dollars on the order of 300 billion a year. [[01:37:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5852.56s)]
*  Let's listen to this quick video from Jensen. [[01:37:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5855.6s)]
*  Yeah, we're going to need a lot more computing and we're fairly sure now that that the world's computing capex, [[01:37:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5859.320000000001s)]
*  it's on its way to a trillion dollars annually by the end of the decade. [[01:37:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5871.200000000001s)]
*  Let's leave it there. That's a lot of capital. [[01:37:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5878.400000000001s)]
*  You made a you made a point earlier about this is wartime spending. [[01:38:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5881.280000000001s)]
*  And we're effectively in a a private pseudo war. [[01:38:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5884.92s)]
*  You know, can we win the race to AGI, ASI, whatever it might be? [[01:38:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5890.88s)]
*  Dave, take us from here. [[01:38:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5895.8s)]
*  Well, just to be clear, so so this is the equivalent amount of dollars inflation adjusted that we did spend between 1941 and 1945 during World War Two. [[01:38:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5898.0s)]
*  So it's massive in scale, huge mobilization. [[01:38:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5907.2s)]
*  Now, at the time, it was 40 percent of GDP. [[01:38:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5910.0s)]
*  Today, it's more like three percent of GDP. [[01:38:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5911.84s)]
*  So the GDP has grown tremendously since then. [[01:38:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5913.6s)]
*  So it's not it's nothing like World War Two in terms of, you know, everyone get on it. [[01:38:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5916.120000000001s)]
*  But it is still an enormous amount of spend. [[01:38:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5919.88s)]
*  And that's a trillion dollars annually and escalating beyond 2030. [[01:38:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5922.92s)]
*  It won't it still won't be enough because the use cases are bubbling up so quickly and they're you know, they they get more intelligent and more useful as you iterate more, [[01:38:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5928.200000000001s)]
*  which means you need more more compute. [[01:38:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5938.360000000001s)]
*  The compute right now is very, very cheap compared to the value, the impact, you know, like, you know, protein folding. [[01:39:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5940.92s)]
*  It's just, you know, pennies to to solve 200 million proteins. [[01:39:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5946.240000000001s)]
*  So it's it's very, very cheap. [[01:39:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5951.4400000000005s)]
*  But the demand for that is going to be astronomical. [[01:39:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5953.4400000000005s)]
*  So we can't ramp up the spend fast enough to keep up with the use cases. [[01:39:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5956.12s)]
*  So Jensen's exactly right. [[01:39:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5960.400000000001s)]
*  You know, if anything, it should be that target or more. [[01:39:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5961.92s)]
*  Salim? [[01:39:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5965.84s)]
*  Well, at least we're unlocking it and making this type of stuff more available in the U.S. [[01:39:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5967.04s)]
*  and around the world. [[01:39:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5971.5599999999995s)]
*  And I think governments will be forced into doing this just to keep up. [[01:39:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5972.599999999999s)]
*  If you don't have a strategic plan as a country to have and big AI data center infrastructure, you're going to be left behind very, very quickly. [[01:39:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5976.28s)]
*  Mo, you made a comment earlier about, you know, the next Avatar movie costing, you know, a few thousand dollars rather than a few billion dollars. [[01:39:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5986.56s)]
*  And, you know, we've been waiting for Avatar. [[01:39:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5995.84s)]
*  What are we up to? Avatar 3 coming out soon. [[01:39:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=5998.56s)]
*  Imagine, you know, Avatar 15,000 versions of Avatar, you know, starring all our favorite friends in there. [[01:40:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6002.04s)]
*  We're about to see a creative explosion, but we don't have the chip capability. [[01:40:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6009.96s)]
*  And in fact, one of the articles I saw recently was we're not going to be compute limited. [[01:40:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6015.360000000001s)]
*  We're going to be energy limited at the end of the day. [[01:40:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6019.4800000000005s)]
*  Correct. Yeah. I mean, we'll probably solve that too. [[01:40:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6021.400000000001s)]
*  I mean, remember that we're going to apply a lot of intelligence to the way we design chips and, you know, in a couple of years time. [[01:40:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6025.04s)]
*  But it is actually this is remarkable in every way. [[01:40:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6031.56s)]
*  Again, remember, my my my point of view is that, you know, intelligence is a force with no polarity applied for good and you get a utopia. [[01:40:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6035.28s)]
*  Right. So the more of it, the better. [[01:40:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6044.36s)]
*  Absolutely no doubt about that. [[01:40:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6047.08s)]
*  It is shocking, though, how quickly we're mobilizing on this. [[01:40:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6049.96s)]
*  And, you know, when you really think about it, if you just put in place a typical advancement of how much of that hardware will actually be rendered obsolete a few years later because of the advancements of the hardware that comes after. [[01:40:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6055.839999999999s)]
*  It is such an unusual dynamic. [[01:41:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6072.6s)]
*  All of us, I think, lived through the dot com bubble and and we saw that massive expansion mostly redeployed on the Internet. [[01:41:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6074.8s)]
*  This one is just beyond our experience in the speed of obsolescence is stunning. [[01:41:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6084.0s)]
*  Unbelievable. Yeah. [[01:41:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6089.6s)]
*  So I want to get your opinion here. [[01:41:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6090.56s)]
*  So a couple of weeks ago, we had the entire US AI elite land in Saudi and in Riyadh and in Emirates. [[01:41:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6092.32s)]
*  And ultimately, that was an effort to try and pair the US and the Middle East in the AI world rather than the Middle East being paired up with China, which was in the balance always. [[01:41:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6104.44s)]
*  And the capital flow and the commitments of capital, we saw 18,000 of the the Blackwell GB 300 chips being committed by Jensen to build there. [[01:41:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6118.84s)]
*  What was it like in Dubai? [[01:42:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6130.92s)]
*  What was it like in the Middle East? [[01:42:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6132.68s)]
*  What was the what was going on in the world there on TV? [[01:42:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6135.16s)]
*  How was it being viewed? [[01:42:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6139.84s)]
*  So I don't know if many people know that, but the largest global infrastructure in the world after AI infrastructure, after America and China is in the UAE, which is a tiny country from a size of investment point of view, it's quite massive between the UAE and Saudi Arabia. [[01:42:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6141.4800000000005s)]
*  There is quite an arms race, if you want, in terms of who will build a bigger infrastructure. [[01:42:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6159.36s)]
*  It's almost as if, you know, how Dubai and now Saudi Arabia is benefiting from the fact that if you don't have a lot of legacy, you can build quite fast. [[01:42:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6164.8s)]
*  And I think that's that's definitely something you see in AI infrastructure in general. [[01:42:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6176.24s)]
*  I do think that it is a very, very clever move to get to the Middle East on on the American side. [[01:43:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6181.76s)]
*  You know, it is not a secret that in every AI meeting that I go to with any ministry or whatsoever, there's always a Chinese side saying at least don't don't take sides. [[01:43:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6190.56s)]
*  This is a message that is very clear from the Chinese players. [[01:43:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6202.8s)]
*  I have to say, though, that the expectation from the people of the Middle East is we want to see what the US will offer in return so that we so that the leaders can continue to to invest in that way. [[01:43:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6207.32s)]
*  It seems to me that, you know, I don't know if that would be speculation on my side, but it seems to me that what we've seen affect the US Treasury markets after the trade war started [[01:43:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6221.5599999999995s)]
*  sort of requires an influx of funds that stabilize the markets and the dollar in a way that could only happen with the trillions of dollars. [[01:43:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6235.16s)]
*  I think four and a half trillion dollars in in general in total were committed here. [[01:44:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6243.92s)]
*  So that's insane. [[01:44:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6249.68s)]
*  I mean, it's insane. [[01:44:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6251.08s)]
*  And it's a magnificent move. [[01:44:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6252.5599999999995s)]
*  And if you think about it and most of it is not really announced in terms of what it is, which is why I suspect it would be, you know, to support the Treasury markets somehow. [[01:44:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6253.88s)]
*  Or some kind of an investment of that sort in the financial markets. [[01:44:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6264.16s)]
*  The thing, on the other hand, is, you know, this generation of leaders here in the Middle East, you know, Mohammed bin Salman, Mohammed bin Zayed are the younger generation that are not as easy to sway on one side or the other, [[01:44:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6267.68s)]
*  because they they have grown with enough, let's say, recognition of their power that they would require a return on that investment. [[01:44:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6284.16s)]
*  So so let's see how the next move on the chessboard will look like. [[01:44:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6296.48s)]
*  And speaking of next move, here's a story at Reuters saying Chinese tech companies prepare for AI future without Nvidia. [[01:45:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6301.92s)]
*  So Alibaba, Tencent, Baidu are testing Chinese semiconductors to replace Nvidia chips. [[01:45:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6312.320000000001s)]
*  These are coming out of Huawei. [[01:45:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6317.92s)]
*  And I just want to I want to just address this policy move. [[01:45:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6320.72s)]
*  If the US starts to restrict export of technology to China, all this does is cause China to want to innovate around the US. [[01:45:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6324.6s)]
*  And we've seen this before. [[01:45:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6334.88s)]
*  We saw this in the telecom industry where and in the mobile phone industry where when we stopped exporting the technology to China, [[01:45:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6336.16s)]
*  we saw Huawei in particular come in with massive telecom and mobile innovations and and steal market share from the US. [[01:45:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6344.96s)]
*  All of a sudden, the US, which we should be the dominant provider of this technology to the world, now splits the world with another vendor. [[01:45:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6354.92s)]
*  Mo, just going to come back to you on this. [[01:46:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6365.12s)]
*  And then I'd love to hear from from Dave and Salim. [[01:46:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6367.28s)]
*  So I'm again, you know, I have the privilege of being in touch with both sides. [[01:46:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6370.16s)]
*  And I can guarantee you there is no coming back from this. [[01:46:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6376.88s)]
*  So so top level executives in the Chinese tech world and, you know, supported clearly by instructions from the Chinese government are saying we're not we're not going to be dependent on the US ability to control [[01:46:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6379.48s)]
*  what chips we get within three to five years time. [[01:46:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6393.92s)]
*  They'll get to the majority of their needs. [[01:46:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6397.88s)]
*  But then the very, very high level, each one hundred level, they said, is 10 years away. [[01:46:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6400.16s)]
*  And and it is quite staggering when you really think about it, because I don't remember the exact number, but they said something like their import of microchips, [[01:46:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6405.4400000000005s)]
*  including all of the little things from a toy, a child's toy all the way to the two phones and data centers and so on, exceeds their their imports of iron and oil combined. [[01:46:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6415.12s)]
*  Right. Which is a massive, massive dollar value in dollar value. [[01:47:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6427.4s)]
*  Yeah. Which which basically means that they see a massive growth in their economy if they can make those chips locally and then basically replace what they what they're getting externally from the rest of the world. [[01:47:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6431.72s)]
*  Which once again also impacts on the Taiwan story and impacts in general on the chip market globally, because you're now having a new player that will do things that China way. [[01:47:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6445.76s)]
*  Right. So instead of a microchip being X number of dollars, it will now be X number of cents. [[01:47:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6455.8s)]
*  Right. And and I have to say, when I when I saw this conversation the first time, I was like, that was probably one of the dumbest moves of America to corner them into that place where they are forced. [[01:47:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6460.92s)]
*  To play to their strengths. [[01:47:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6475.24s)]
*  We've seen this over and over again with the with the satellite industry, the launch industry, all of these industries begin to this protectionist move just stimulates the entrepreneurial engine in China to replicate, duplicate or or just advance the whole field. [[01:47:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6477.32s)]
*  Dave, how is this feeling for you? [[01:48:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6493.32s)]
*  How do you think about this? [[01:48:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6495.68s)]
*  Well, you know, it's interesting. [[01:48:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6497.4400000000005s)]
*  I most said there's no coming back because that kind of answers my question. [[01:48:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6499.360000000001s)]
*  But what you don't do is poke them and then do nothing. [[01:48:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6502.280000000001s)]
*  You either win or you don't win. [[01:48:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6506.200000000001s)]
*  Like if you're going to embargo, if you're going to basically declare economic war, you better declare it to win. [[01:48:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6507.96s)]
*  In which case you have to embargo the chips, but also you have to stop the software flow and also the EUV machines and a few other things. [[01:48:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6513.080000000001s)]
*  Otherwise, what did you just achieve? [[01:48:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6520.92s)]
*  All you did is annoy them. [[01:48:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6522.360000000001s)]
*  So if you're going to play, you might as well play to win. [[01:48:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6524.28s)]
*  I do think that there's a real risk to the US in that we will say, well, they can't make two nanometer, they can't make one nanometer. [[01:48:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6528.5199999999995s)]
*  But it's actually volume that's going to win. [[01:48:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6536.5599999999995s)]
*  If you can if you can manufacture an enormous number of five nanometer, even 10 or 20 nanometer chips, but a hundred times, a thousand times more of them, that actually works fine for AI. [[01:49:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6540.36s)]
*  It works really, really well, actually, especially for inference time AI. [[01:49:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6551.080000000001s)]
*  And so there's a danger that that's not the way it worked with, say, fighter jets. [[01:49:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6554.280000000001s)]
*  You know, the advanced fighter jet that was slightly better was just unstoppable. [[01:49:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6560.88s)]
*  This is going to be like that. [[01:49:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6565.4400000000005s)]
*  You could you could win by sheer volume. [[01:49:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6566.4400000000005s)]
*  And then when I look at the way the US innovation market works, you know, the reason everybody was in Saudi last week is because that's where the capital is. [[01:49:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6569.240000000001s)]
*  But don't we have much, much more capital here in the United States? [[01:49:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6576.360000000001s)]
*  Well, one trillion dollars a year of investment, US venture capital industry as a whole is one fifth of that. [[01:49:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6579.12s)]
*  So so like our entire venture capital universe is nowhere near as big as that one trillion dollar a year investment that Jensen was talking about. [[01:49:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6586.72s)]
*  And well, then where's all our money? [[01:49:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6594.8s)]
*  Well, it's in pension funds. [[01:49:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6596.84s)]
*  It's in endowments. It's in institutions. [[01:49:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6598.36s)]
*  And when you go and talk to them and say, hey, why don't you unleash a billion dollars? [[01:50:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6600.68s)]
*  Like, well, no, we don't have an allocation for that. [[01:50:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6605.92s)]
*  That's above our quota, you know, whatever. [[01:50:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6607.72s)]
*  Like, oh, my God. [[01:50:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6609.280000000001s)]
*  So then you go to China or you go to the Middle East where there's, you know, a much smaller group of decision makers. [[01:50:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6610.64s)]
*  Centralized control of capital. [[01:50:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6616.4800000000005s)]
*  Yeah, exactly. [[01:50:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6618.04s)]
*  And as Mo was saying, these are great investments. [[01:50:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6619.0s)]
*  Like, why is Europe not making these great investments? [[01:50:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6621.4400000000005s)]
*  Well, that's that's that's insane. [[01:50:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6623.76s)]
*  Europe, Europe is destroying itself with its policies today. [[01:50:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6625.68s)]
*  Literally, it's that indecision is, is, yeah, the indecision and ability to make a decision at scale. [[01:50:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6631.4400000000005s)]
*  It's just absolutely killer in this kind of a fast moving environment. [[01:50:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6637.68s)]
*  So that's why everybody is in Saudi and UAE, because you actually have action and motion. [[01:50:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6641.280000000001s)]
*  But Mo is right. These these investments are absolute no brainers. [[01:50:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6646.8s)]
*  They're going to pay off like, you know, in spades. [[01:50:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6650.92s)]
*  And you're seeing that with the core we buy PO. [[01:50:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6655.12s)]
*  You see that with global foundry. [[01:50:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6656.68s)]
*  You know, why did why did why buy global foundry from AMD? [[01:50:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6658.12s)]
*  So the chips are going to be an incredible demand. [[01:51:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6661.08s)]
*  And now we have a foundry. [[01:51:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6664.84s)]
*  Salim, you want to close us out on this one? [[01:51:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6666.4s)]
*  Two thoughts. One is, you know, the I think the chip kind of restrictions to China. [[01:51:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6669.36s)]
*  I agree with Mo really, really dumb idea because it just forces the conversation. [[01:51:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6675.48s)]
*  And now you've gone down a road you can't come back from. [[01:51:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6680.44s)]
*  I note with this is an observation that 95 percent of the agricultural drones in the U.S. [[01:51:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6683.799999999999s)]
*  are Chinese. And so there's a huge amount of dependency for it. [[01:51:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6690.08s)]
*  We're Earth's, et cetera, et cetera, in the engineering and build capability over there already in a bunch of sectors. [[01:51:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6694.84s)]
*  And so we're playing with fire here. [[01:51:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6701.28s)]
*  My brigger hope is that this entire U.S.-China kind of conversation [[01:51:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6703.52s)]
*  fades away with abundant energy, you know, that when you have abundant energy, [[01:51:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6709.16s)]
*  which is coming very shortly, then you can produce lots of things locally at low cost. [[01:51:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6715.04s)]
*  And you don't need to have this competitive approach to things. [[01:51:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6719.84s)]
*  Winner take all type approach. [[01:52:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6723.32s)]
*  This is still I hope I may be still I may be living in dreamland, but I'm hoping that's where we get still the fear and scarcity [[01:52:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6724.68s)]
*  operating software of the human brain from exactly. [[01:52:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6732.4800000000005s)]
*  It's our middle running wild on all of this stuff. [[01:52:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6736.04s)]
*  I want to just to continue on this on this chip conversation. [[01:52:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6739.56s)]
*  So TSMC accelerates efforts for one nanometer production plans and setting up its gigafabs in Taiwan. [[01:52:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6743.240000000001s)]
*  One nanometer. That's extraordinary. [[01:52:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6751.12s)]
*  Just for reference, the the limits of physics is about the diameter of a silicon atom and that's about a half a nanometer. [[01:52:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6753.92s)]
*  So, I mean, we're living in this extraordinary science fiction universe where we're literally operating at an atomic scale. [[01:52:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6763.400000000001s)]
*  So just to give people a quick a quick overview here, I just found a few data points here. [[01:52:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6773.84s)]
*  So 2014, we were at 14 nanometer chips from Intel. [[01:52:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6779.76s)]
*  2016, we were at 10 nanometers from Samsung. [[01:53:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6784.92s)]
*  And 2018, TSMC takes the reign. [[01:53:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6789.0s)]
*  Seven nanometers. [[01:53:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6792.88s)]
*  They were at five nanometers in 2020. [[01:53:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6794.360000000001s)]
*  Three nanometers and 22. [[01:53:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6797.96s)]
*  Today, we're still we're at two nanometers. [[01:53:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6799.72s)]
*  And again, the projection is one nanometer by 2030. [[01:53:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6802.56s)]
*  All in one lifetime. [[01:53:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6807.52s)]
*  We all started on an 8088. [[01:53:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6812.8s)]
*  Remember? [[01:53:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6814.68s)]
*  I remember on a 6502 microprocessor. [[01:53:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6815.56s)]
*  I was coding in hexadecimal on the 652. [[01:53:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6820.88s)]
*  Yes, I did the math. [[01:53:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6825.2s)]
*  This is 60 trillion times faster. [[01:53:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6828.56s)]
*  In the blink of an eye. [[01:53:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6833.76s)]
*  Unbelievable in my lifetime. [[01:53:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6835.44s)]
*  And we actually coded some interesting stuff on that stuff. [[01:53:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6838.6s)]
*  Right? [[01:54:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6841.92s)]
*  Yeah, we did. [[01:54:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6842.16s)]
*  Yeah, absolutely. [[01:54:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6843.12s)]
*  I mean, and it was so I remember at MIT, you know, the geek kits. [[01:54:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6844.44s)]
*  Dave, we'd have these these giant boxes and we'd have gates. [[01:54:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6852.2s)]
*  We'd have chips of and, and, or, and nor gates. [[01:54:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6856.72s)]
*  And we, you know, literally with wires, wire together. [[01:54:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6860.12s)]
*  You know, what always makes me laugh is, is that turbo button. [[01:54:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6866.96s)]
*  Remember on the 386 where you went from 33 megahertz to 66 megahertz? [[01:54:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6871.16s)]
*  Like, come on. [[01:54:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6877.5599999999995s)]
*  Yeah, actually, Peter, with my geek kit, I built an inference time neural net [[01:54:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6881.0s)]
*  accelerator, of course, and has a multiplier in the middle of it. [[01:54:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6884.599999999999s)]
*  And I didn't appreciate it. [[01:54:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6888.84s)]
*  Like you have to strip so many wires and plug them in. [[01:54:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6890.08s)]
*  Oh my God. [[01:54:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6893.12s)]
*  Sorry, I can't afford it. [[01:54:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6893.28s)]
*  And then the EEPROM came out. [[01:54:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6894.24s)]
*  Only time in my life, two back to back all-nighters. [[01:54:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6897.719999999999s)]
*  Yes. [[01:55:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6900.88s)]
*  You know, you know what we all sound like? [[01:55:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6901.2s)]
*  We all sound like a bunch of grumpy old men talking about glory days. [[01:55:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6903.2s)]
*  I love those days. [[01:55:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6908.44s)]
*  I love those days. [[01:55:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6909.8s)]
*  It was so much fun. [[01:55:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6910.639999999999s)]
*  But one nanometer pushing up against the limit of physics. [[01:55:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6912.96s)]
*  Incredible. [[01:55:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6917.84s)]
*  Yeah, two silicon, two silicon atoms or 10 hydrogen atoms. [[01:55:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6918.320000000001s)]
*  So everything's moving to Angstrom terminology now, which is a 10th of a [[01:55:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6921.360000000001s)]
*  nanometer and it's the diameter of a hydrogen atom. [[01:55:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6924.76s)]
*  So, but we're one nanometer is the gate width and that's the physical limit. [[01:55:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6928.240000000001s)]
*  You know, you can go down to 0.8 maybe, but it's basically the physical limit. [[01:55:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6933.04s)]
*  The terminology is a little messed up because when they say one nanometer, [[01:55:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6937.04s)]
*  they're saying it's effectively as if you had one nanometer transistors, but [[01:55:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6941.04s)]
*  they're actually building vertically with the FinFETs. [[01:55:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6945.72s)]
*  And so, so the gate width is one nanometer. [[01:55:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6948.52s)]
*  It's, it's effectively the same as if you had one nanometer transistors, but [[01:55:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6951.12s)]
*  you're going vertically, but that's the end of the line. [[01:55:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6955.0s)]
*  But now the future belongs to vertical stacking. [[01:55:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6957.56s)]
*  And I, you know, Ray Kurzweil was right. [[01:56:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6960.320000000001s)]
*  We always find a way to continue innovating. [[01:56:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6962.68s)]
*  That's not going to stop, but it'll be in different dimensions. [[01:56:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6965.64s)]
*  I remember talking to Ralph Merkel last year about this and he said, we're [[01:56:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6968.88s)]
*  going to get, and you know, as we hit the limits here, we'll go to thermodynamically [[01:56:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6972.68s)]
*  reversible computation where we'd not generate any heat. [[01:56:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6976.88s)]
*  And he, he, he foresaw a future of us using chemical bonds to store the ones and zeros. [[01:56:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6980.52s)]
*  And that's a whole other level. [[01:56:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6987.72s)]
*  He figured that would give us 10 orders of magnitude on Moore's law right there. [[01:56:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6988.84s)]
*  10 orders of magnitude. [[01:56:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6993.360000000001s)]
*  It was madness. [[01:56:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6995.8s)]
*  10 billion fold. [[01:56:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6996.68s)]
*  That's incredible. [[01:56:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6997.72s)]
*  Well, I don't, I think one of the takeaways though, is we don't necessarily need it in [[01:56:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=6999.320000000001s)]
*  order to continue making progress. [[01:56:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7003.76s)]
*  So, cause a lot of the more, you know, the more esoteric ideas, remember, you know, [[01:56:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7006.400000000001s)]
*  gallium arsenide for the longest time was going to come online and be a blah, blah, [[01:56:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7010.64s)]
*  blah. [[01:56:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7013.6s)]
*  And it turned out that we just worked around it. [[01:56:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7014.120000000001s)]
*  And then carbon nanotubes were going to do whatever. [[01:56:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7016.84s)]
*  And like, well, that's not materialized. [[01:56:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7019.04s)]
*  So I think what's going to happen here is these, these will go vertical and they'll [[01:57:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7020.56s)]
*  go massive in scale. [[01:57:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7023.68s)]
*  We'll get the production costs way down. [[01:57:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7025.4400000000005s)]
*  We'll build enormous data centers horizontally and also we'll build the chips [[01:57:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7027.24s)]
*  vertically. [[01:57:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7030.639999999999s)]
*  And that's going to drive innovation for many years to come. [[01:57:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7031.5599999999995s)]
*  And then the next thing may or may not be quantum. [[01:57:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7034.8s)]
*  And we'll, we'll know in a year or two whether quantum is going to be the next [[01:57:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7037.599999999999s)]
*  thing. [[01:57:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7041.24s)]
*  I'm going to speed through a few different topics here just to get us through some [[01:57:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7042.44s)]
*  interesting things. [[01:57:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7048.76s)]
*  We're starting to see AI being used to generate peer reviewed scientific papers [[01:57:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7050.16s)]
*  and breakthroughs. [[01:57:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7056.16s)]
*  We're seeing DeepMind helping us. [[01:57:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7058.48s)]
*  This is through Alpha Evolve, literally solve, you know, math records. [[01:57:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7062.04s)]
*  And, and Dave, I'm hoping that we'll get Alex Wiesner-Groves to join us, talk about [[01:57:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7068.68s)]
*  how, how AI is going to be solving math and physics and biology. [[01:57:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7074.28s)]
*  I mean, I think one of the things that's underappreciated is over the next three [[01:57:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7078.88s)]
*  years, how AI is going to help us accelerate this breakthroughs in science beyond [[01:58:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7083.48s)]
*  anything else we've ever, ever seen before. [[01:58:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7089.5199999999995s)]
*  And here's another one. [[01:58:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7093.5599999999995s)]
*  This is a demonstration of end to end scientific discoveries with Robin, a [[01:58:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7094.759999999999s)]
*  multi-agent system. [[01:58:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7099.24s)]
*  And what we're seeing here is closed scientific robotic and AI systems where an [[01:58:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7100.96s)]
*  AI proposes an experiment. [[01:58:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7106.96s)]
*  The robots then run the experiment 24 seven, basically in a dark lab, gather the [[01:58:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7110.16s)]
*  data, feed it back to the AI, which updates its, its theory runs the next [[01:58:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7115.639999999999s)]
*  experiment. [[01:58:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7121.16s)]
*  And we're seeing this in biology for sure. [[01:58:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7121.8s)]
*  We'll see it in chemistry, material sciences. [[01:58:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7125.16s)]
*  And this is another hyper acceleration in our, in our scientific realm. [[01:58:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7127.639999999999s)]
*  Thoughts on this gentlemen? [[01:58:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7133.96s)]
*  I mean, this is where I, I know that not everybody considers themselves an [[01:58:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7135.76s)]
*  entrepreneur. [[01:59:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7140.4s)]
*  Uh, what did you say? [[01:59:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7141.24s)]
*  16% of America does today. [[01:59:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7142.0s)]
*  Adults. [[01:59:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7144.36s)]
*  Yeah. [[01:59:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7145.5199999999995s)]
*  But this is like a field day, cause this is the, all of these areas, I don't want [[01:59:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7146.2s)]
*  to get into the details of them, but they're all domain specific. [[01:59:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7149.44s)]
*  So if you can take the current AI, tune in, train it, get proprietary data and [[01:59:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7151.92s)]
*  take it down any of these paths, you get miles and miles ahead of the generic AI. [[01:59:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7156.0s)]
*  And so it's just an entrepreneur's field day. [[01:59:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7160.88s)]
*  This, this next couple of years. [[01:59:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7163.0s)]
*  Yeah. [[01:59:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7164.72s)]
*  And so these are, these are just good case studies. [[01:59:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7165.12s)]
*  I won't dwell on the specifics. [[01:59:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7166.84s)]
*  You can read about them later. [[01:59:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7168.08s)]
*  I'm really excited. [[01:59:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7170.24s)]
*  This is probably for me, the biggest, um, uh, small kid in a wonderland moment [[01:59:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7171.36s)]
*  where we can use these AIs to solve really deep physics problems, mathematics [[01:59:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7176.8s)]
*  problems, scientific discoveries, because the human being trolling through data, [[01:59:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7182.76s)]
*  looking for patterns is, is terrible. [[01:59:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7186.8s)]
*  We're bad at that. [[01:59:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7188.92s)]
*  And this is where an AI is really, really good at it, especially going retroactively [[01:59:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7189.76s)]
*  and finding all the stuff in experiments that we didn't see in the past. [[01:59:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7193.6s)]
*  I think I'm unbelievably excited about this. [[01:59:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7197.56s)]
*  Yeah. [[02:00:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7200.360000000001s)]
*  And this is helping humanity across the board. [[02:00:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7200.96s)]
*  Right. [[02:00:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7204.88s)]
*  I like to say over and over again, I had this conversation when I was in Hong [[02:00:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7205.56s)]
*  Kong, despite the polarity in AI breakthroughs in biology, you know, a [[02:00:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7209.04s)]
*  breakthrough in Boston plays in biology and longevity plays equally well in, in [[02:00:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7213.96s)]
*  Beijing, right? [[02:00:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7218.92s)]
*  So it's, it helps us all when humanity is healthier, uh, and living [[02:00:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7220.32s)]
*  longer, more vibrant lives. [[02:00:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7226.679999999999s)]
*  Um, Mo, anything on the, on the science breakers? [[02:00:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7228.719999999999s)]
*  This is my favorite thing ever AI or not. [[02:00:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7232.12s)]
*  Uh, you know, the possibilities that we have here, just as we go through [[02:00:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7235.36s)]
*  multidisciplinary sciences, which no human, uh, mind has the ability to grasp [[02:00:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7238.84s)]
*  fully, uh, which is, you know, the nature of AI, I think at least [[02:00:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7244.44s)]
*  I dream that 2026 will be, you know, blasted with all of those new discoveries [[02:00:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7250.12s)]
*  in science, uh, now that we're solving mathematics as well. [[02:00:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7256.0s)]
*  Yeah. [[02:01:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7260.16s)]
*  I'm, you know, I'm, I'm excited about having this podcast over the [[02:01:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7260.4s)]
*  course of the next year as we start to share again, you know, I'm grateful [[02:01:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7264.24s)]
*  for our listeners. [[02:01:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7269.92s)]
*  I mean, our mission here is if you've got an hour or two hours to listen to [[02:01:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7271.08s)]
*  news, instead of allowing some editor somewhere, some producer to feed you [[02:01:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7275.84s)]
*  all the dystopian news on the planet, let us share with you the incredible [[02:01:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7280.96s)]
*  breakthroughs, cause you're not getting this anyplace else. [[02:01:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7285.08s)]
*  The current news media is just playing with your amygdala, delivering negative [[02:01:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7287.68s)]
*  news over and over and over again, every hour into your living room in full color. [[02:01:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7292.6s)]
*  And you're not hearing all the extraordinary breakthroughs coming our way. [[02:01:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7297.64s)]
*  Um, uh, I'm going to move to this last scientific subject, which is one of my [[02:01:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7302.52s)]
*  favorites, which is, uh, some of the work being done by Demis, the Sabas and others [[02:01:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7309.0s)]
*  is, can we build a full up virtual AI model of a human cell, even more importantly, [[02:01:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7315.240000000001s)]
*  Mo, can we, you know, grab a skin cell from you, sequence your DNA and build [[02:02:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7322.68s)]
*  a virtual model of Mo. [[02:02:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7327.64s)]
*  Uh, [[02:02:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7329.8s)]
*  Why would you have to do that? [[02:02:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7330.120000000001s)]
*  Dave and of Salim. [[02:02:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7331.24s)]
*  Yeah. [[02:02:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7333.0s)]
*  So that even Salim is a better one, but yeah, but of each of each of us, once [[02:02:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7333.32s)]
*  you're able to do that, right. [[02:02:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7338.24s)]
*  Because we, you know, the cost of sequencing a genome went from billions, [[02:02:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7339.28s)]
*  uh, to now a couple hundred bucks. [[02:02:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7344.8s)]
*  Yeah. [[02:02:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7347.92s)]
*  Uh, and from, you know, a year to seven hours. [[02:02:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7348.08s)]
*  So we can sequence your genome, put it into a virtual model and then understand [[02:02:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7351.599999999999s)]
*  your biology, which, which medicine, which supplement, which chemical does or does [[02:02:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7356.4s)]
*  not work for you and how exactly it works in your cells. [[02:02:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7361.92s)]
*  I mean, this is the unlock for solving human disease and, uh, the limits of [[02:02:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7365.04s)]
*  longevity. [[02:02:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7370.92s)]
*  And so for me, I'm super excited about this. [[02:02:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7371.5599999999995s)]
*  And I think it will happen. [[02:02:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7375.32s)]
*  Uh, it's just a question of time, really. [[02:02:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7376.44s)]
*  Yeah. [[02:02:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7378.4s)]
*  Yeah. [[02:02:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7378.92s)]
*  Yeah. [[02:02:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7379.599999999999s)]
*  I think it'll happen relatively quickly too with AI assist and it is [[02:02:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7379.84s)]
*  incredibly compute intensive. [[02:03:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7383.24s)]
*  So it's a good case study and why those, those, you know, Middle East investments [[02:03:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7385.16s)]
*  are the biggest no brainer ever. [[02:03:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7388.56s)]
*  If you just work backwards, the implied amount of compute computation, but then [[02:03:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7390.12s)]
*  the, the benefit of solving virtually every disease is, is just so [[02:03:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7393.280000000001s)]
*  overwhelmingly valuable. [[02:03:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7398.8s)]
*  It unlocks so much capital that you're not wasting on, uh, on, you know, [[02:03:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7400.8s)]
*  old age homes or on dealing with, uh, with Alzheimer's or Parkinson's. [[02:03:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7407.4800000000005s)]
*  And it allows humanity to be more productive. [[02:03:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7413.48s)]
*  There was a study out of Oxford London school of business and Harvard that [[02:03:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7416.679999999999s)]
*  said for every additional year of health that you give a population, it's worth [[02:03:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7420.679999999999s)]
*  $38 trillion, the global economy. [[02:03:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7426.0s)]
*  I mean, this is one of the most, if you want to solve the U S economic issues [[02:03:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7428.44s)]
*  and China's economic issues, make the population healthier and live longer. [[02:03:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7432.96s)]
*  All right. [[02:03:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7437.639999999999s)]
*  So that wraps up AI and science. [[02:03:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7437.84s)]
*  Let's talk about one last subject here today, which is as the father of two [[02:03:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7439.24s)]
*  now 14 year old boys, I think about a lot, which is reforming education. [[02:04:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7443.88s)]
*  Uh, I'm going to play a short video clip. [[02:04:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7448.599999999999s)]
*  Uh, and then I'd love to hear your thoughts on this. [[02:04:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7450.84s)]
*  I applied to probably around 18 schools and I was rejected from maybe around 15 [[02:04:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7454.679999999999s)]
*  of those. [[02:04:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7463.08s)]
*  In fact, we have a map showing all the places that rejected you, not to make [[02:04:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7464.24s)]
*  you feel worse looking at this list. [[02:04:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7468.28s)]
*  Well, let's just share your statistics because I know that factors into college [[02:04:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7470.5199999999995s)]
*  emissions, right? [[02:04:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7473.92s)]
*  Uh, your GPA and S a T score. [[02:04:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7475.0s)]
*  Uh, GPA was 4.42 weighted. [[02:04:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7477.8s)]
*  Uh, S a T score was 1590. [[02:04:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7480.92s)]
*  Okay. [[02:04:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7483.639999999999s)]
*  And in fact, I think we have that on the graphic just so folks can see that. [[02:04:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7484.12s)]
*  So the point of this story is, are we, uh, going to move back to meritocracy? [[02:04:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7487.92s)]
*  We're in fact, uh, selection and admission into schools is based upon performance [[02:04:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7495.96s)]
*  and not anything else been a sticky, sticky subject coming out of, uh, you [[02:05:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7502.24s)]
*  know, the last, uh, four plus years on DEI, uh, Dave, you're deeply embedded [[02:05:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7506.799999999999s)]
*  in AI and, uh, technology at MIT. [[02:05:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7513.44s)]
*  How do you think about this? [[02:05:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7517.4s)]
*  Well, schools are between a rock and a hard place because they clearly had quotas. [[02:05:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7518.799999999999s)]
*  And so, so, so, you know, they, and then now the rules say you're not supposed to [[02:05:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7522.92s)]
*  do that, but you know, they, they, they, they're just totally stuck between a rock [[02:05:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7528.4s)]
*  and a hard place on this topic, but I don't think they, uh, I don't think they [[02:05:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7532.68s)]
*  do a great job of choosing who to let in, uh, you know, toward any particular outcome [[02:05:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7537.2s)]
*  that they're targeting anyway. [[02:05:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7542.12s)]
*  There's a more to life than a 1590 S a T and a 4.42 GPA. [[02:05:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7543.8s)]
*  And, uh, I see a lot of the students that are underperforming in the classes that I [[02:05:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7547.92s)]
*  teach just because they need to be creative and they need to build [[02:05:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7552.2s)]
*  businesses and they need to recruit and they needed to motivate people. [[02:05:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7555.36s)]
*  And none of that gets measured well by these particular metrics. [[02:05:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7558.639999999999s)]
*  And I see too many people that are curated to be perfect applicants from age like six. [[02:06:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7562.28s)]
*  And it doesn't go particularly well. [[02:06:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7568.44s)]
*  So I'm, I don't know. [[02:06:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7570.4s)]
*  I think the school should be allowed to choose with pretty broad brushes what [[02:06:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7571.5199999999995s)]
*  they're trying to achieve with their student body. [[02:06:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7576.5199999999995s)]
*  And so hopefully this doesn't go too far. [[02:06:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7579.12s)]
*  Well, I think we have to reeducate and reinvent the whole university [[02:06:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7581.36s)]
*  system in the first place. [[02:06:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7584.56s)]
*  And one of the questions I've already had, though he's had for Salim, you [[02:06:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7586.04s)]
*  and I both have boys the same, same age within a month of each other. [[02:06:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7589.4s)]
*  Is university going to be a thing by the time they get to college age [[02:06:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7593.6s)]
*  and what will its purpose be? [[02:06:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7598.12s)]
*  So Salim, how are you thinking about this? [[02:06:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7599.72s)]
*  I'm in the same mode of the driverless cars. [[02:06:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7601.72s)]
*  I'm desperately hoping the university system implodes in the next five years [[02:06:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7604.56s)]
*  before my son has to go purely because, you know, taking a four year degree to [[02:06:48](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7608.08s)]
*  get credentialed in some domain that you're then supposed to be an active [[02:06:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7613.92s)]
*  worker and for 40 years before you retire is completely out of date. [[02:06:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7617.56s)]
*  The model of a university has not changed in 450 years. [[02:07:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7621.5199999999995s)]
*  It's, it's, it's desperately broken. [[02:07:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7624.56s)]
*  Deep research is fundamentally incredibly important. [[02:07:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7626.88s)]
*  So I think that's really killer. [[02:07:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7629.44s)]
*  I know that the most interesting stat for me is that more than half the CEOs in [[02:07:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7631.56s)]
*  Silicon Valley have a liberal arts degree. [[02:07:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7637.08s)]
*  And I find that really interesting because the different models of how you [[02:07:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7639.68s)]
*  think drives creativity and product design, design, et cetera, et cetera. [[02:07:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7642.72s)]
*  So there's a vector there to be explored in terms of how to think about all this. [[02:07:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7648.16s)]
*  And Mo, my, you know, my experience is that the majority of leaders and [[02:07:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7652.4s)]
*  influential individuals out of the Middle East are all coming to the [[02:07:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7658.24s)]
*  US for their degrees. [[02:07:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7662.36s)]
*  What's the buzz there in the Emirates? [[02:07:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7664.4800000000005s)]
*  No, I think, I think the reality is that I meet more MIT and, you know, Stanford [[02:07:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7667.96s)]
*  graduates here than I do in America. [[02:07:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7672.24s)]
*  Most of the time it is quite staggering actually. [[02:07:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7674.4800000000005s)]
*  How, how people. [[02:07:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7677.56s)]
*  I mean, it is, it is definitely, and it's, I think it's definitely revived the top [[02:08:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7680.88s)]
*  management of the region. [[02:08:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7686.64s)]
*  Very, very interestingly. [[02:08:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7687.96s)]
*  I wonder why, I wonder though, if, if Salim's wish will come true, because, [[02:08:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7689.599999999999s)]
*  I don't know if the university systems would implode, but I definitely think our [[02:08:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7697.24s)]
*  belief in universities would, and it really is quite an interesting thing [[02:08:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7702.24s)]
*  because four years in a world that's moving at X speed is very different than [[02:08:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7706.8s)]
*  a world that's moving at 10 X speed. [[02:08:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7711.8s)]
*  And that's what we're seeing now. [[02:08:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7714.2s)]
*  So if, if everyone's going to entrepreneurship, you know, and everyone [[02:08:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7715.56s)]
*  can use Lovable or Claude or whatever to write code or start businesses or, you [[02:08:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7719.56s)]
*  know, agents are everywhere, you'll probably see entrepreneurship age go to 16 and 14. [[02:08:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7723.64s)]
*  And, you know, you may see a very, a very different world. [[02:08:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7729.88s)]
*  And I wonder. [[02:08:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7733.360000000001s)]
*  Dave, do you want to talk about that? [[02:08:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7734.8s)]
*  I mean, you've seen the shift in terms of the companies that are becoming [[02:08:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7735.96s)]
*  unicorns get a decade earlier. [[02:08:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7739.400000000001s)]
*  Yeah. [[02:09:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7743.8s)]
*  Yeah, no, there's no doubt. [[02:09:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7744.96s)]
*  I mean, but I think the universities are about friendships and the friendships [[02:09:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7746.32s)]
*  turn into company formations and, you know, a lot of the universities don't [[02:09:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7750.12s)]
*  recognize the degree to which that's the dominant factor that's keeping them alive. [[02:09:14](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7754.08s)]
*  So if they want to survive this transition, you know, they gotta, they [[02:09:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7758.12s)]
*  gotta embrace that as what they're delivering its credentials and its [[02:09:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7761.16s)]
*  relationships between human beings that are the dominant deliverable to the students. [[02:09:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7765.08s)]
*  So they need to be turned into entrepreneurial boot camps. [[02:09:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7769.5199999999995s)]
*  Yeah. [[02:09:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7772.48s)]
*  Well, here we see another article, UAE to make chat GPT plus free to all of its [[02:09:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7773.320000000001s)]
*  citizens, you know, again, these are, these are forward looking moves. [[02:09:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7779.0s)]
*  And AI is mandatory education now for six, six years or higher, I think. [[02:09:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7785.52s)]
*  Crazy. [[02:09:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7790.64s)]
*  All right. [[02:09:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7791.6s)]
*  And the statistic here is really important, right? [[02:09:51](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7791.8s)]
*  What's the stat I heard was that with a student with an AI is, is learning [[02:09:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7795.68s)]
*  subjects between two to four times faster than going to school. [[02:10:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7800.24s)]
*  And that's just going to overwhelm the existing system very quickly. [[02:10:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7804.92s)]
*  I think this is an awesome move. [[02:10:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7807.639999999999s)]
*  Well, also the concept of a curriculum, which is a, you know, we only have so [[02:10:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7809.5599999999995s)]
*  many teachers, so we can only afford 12 subjects, 15 subjects with AI assist. [[02:10:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7812.679999999999s)]
*  You can afford 20,000, a million different subjects. [[02:10:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7817.2s)]
*  So not only are the students self directing at their own pace, but they're [[02:10:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7820.04s)]
*  also learning whatever they think is most relevant to their path, which is so [[02:10:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7823.08s)]
*  much more effective than the old way. [[02:10:27](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7827.04s)]
*  And hyper personalized education, you know, you're, you're learning math [[02:10:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7829.88s)]
*  focused on your favorite sports star, movie star, your favorite, you know, [[02:10:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7835.88s)]
*  scenarios and stories. [[02:10:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7839.52s)]
*  I'll close out with this provocative article that came out that around 5% of [[02:10:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7841.200000000001s)]
*  Teal Fellows have become billionaires from Vitalik to Austin Russell. [[02:10:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7847.52s)]
*  And remind reminding people the, the Teal Fellowship is paying you to drop out of [[02:10:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7853.96s)]
*  college. [[02:10:58](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7858.92s)]
*  So what is this saying that our most productive years we're wasting in our [[02:10:59](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7859.88s)]
*  university experience instead of starting companies are fascinating thought Dave, [[02:11:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7865.0s)]
*  I'll start with you. [[02:11:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7871.4s)]
*  Well, first of all, the, the Teal Fellowship, uh, doesn't try to teach you [[02:11:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7872.6s)]
*  anything, it just selects you. [[02:11:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7877.08s)]
*  And so it shows you the degree to which the schools are not selecting, you know, [[02:11:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7879.08s)]
*  they're getting nowhere near a 5% unicorn rate coming out of the schools, but Teal, [[02:11:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7883.12s)]
*  you know, given the abundance of big data that's out there, the Teal Fellowship [[02:11:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7888.16s)]
*  can just be a better selection and application process that covers topics [[02:11:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7891.4s)]
*  like, are you self motivated? [[02:11:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7896.24s)]
*  Are you high energy? [[02:11:37](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7897.68s)]
*  Can you recruit? [[02:11:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7898.599999999999s)]
*  Do you, are, do you think through these AI topics, you know, those are all baked [[02:11:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7899.5599999999995s)]
*  into that selection process. [[02:11:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7903.88s)]
*  And so it's very viable for these credentials to replace the university [[02:11:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7905.32s)]
*  degree as the credential that everybody wants. [[02:11:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7910.08s)]
*  So it's something the school should really be aware of, but it's, you know, [[02:11:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7912.8s)]
*  it's not super hard to put together a AI assisted analytic that tries to predict [[02:11:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7915.68s)]
*  who's going to succeed as an entrepreneur. [[02:12:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7920.04s)]
*  And that's all the Teal Fellowship tries to do. [[02:12:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7922.240000000001s)]
*  And that gives you a little bit of money and encourages you, but it's really, [[02:12:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7924.0s)]
*  what they're really giving you as the credential. [[02:12:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7927.12s)]
*  Salim, do you want to? [[02:12:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7929.280000000001s)]
*  Yeah, I agree with Dave on this one. [[02:12:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7931.12s)]
*  And I think this is not a negative comment on the university system. [[02:12:12](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7932.400000000001s)]
*  I think the Teal Fellowship selects for people that are such outliers that the [[02:12:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7936.160000000001s)]
*  university system doesn't kind of accommodate for them anyway. [[02:12:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7940.400000000001s)]
*  I think there's a systemic issue on the university side, which we've talked about [[02:12:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7943.5599999999995s)]
*  already. I note that more than half of CEOs in Silicon Valley have a liberal [[02:12:26](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7946.8s)]
*  arts degree because the different ways of thinking, how to think are really [[02:12:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7951.92s)]
*  important in product strategy and company strategy and so on. [[02:12:35](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7955.44s)]
*  I do, you know, if you're doing, for example, a master's degree in neuroscience [[02:12:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7960.48s)]
*  today, you're out of date by the time you finished your degree, because [[02:12:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7964.24s)]
*  computational neuroscience is totally taking over the field. [[02:12:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7967.24s)]
*  So undergrads and masters are kind of essentially mostly relevant in terms of [[02:12:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7970.04s)]
*  learning with AI. [[02:12:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7975.56s)]
*  If you're a student, you're learning and learning with AI, you're moving and [[02:12:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7976.84s)]
*  learning between two to four times faster than being in school. [[02:13:01](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7981.0s)]
*  And so all sorts of things will have this thing. [[02:13:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7984.6s)]
*  And I mentioned that, you know, maybe hopefully my, the university system [[02:13:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7987.12s)]
*  implodes in the next five years before I have to pay for my kid to go to school [[02:13:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7990.64s)]
*  and when he's 18. [[02:13:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7993.96s)]
*  Now, I do think education and health care are the two massive industries and [[02:13:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=7995.96s)]
*  expenditures for people that are going to be completely disintermediated, [[02:13:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8000.719999999999s)]
*  disrupted, democratized and demonetized, I hope. [[02:13:24](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8004.879999999999s)]
*  All right. A lot of amazing stuff. [[02:13:29](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8009.16s)]
*  Let's wrap around the horn here. [[02:13:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8011.36s)]
*  Thoughts on today's conversations. [[02:13:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8013.879999999999s)]
*  Dave, can we start with you? [[02:13:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8016.92s)]
*  Yeah, Mo, it's been fantastic getting your perspective. [[02:13:38](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8018.96s)]
*  I think. [[02:13:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8021.36s)]
*  Come on. [[02:13:42](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8022.679999999999s)]
*  I don't know if I have. [[02:13:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8024.12s)]
*  Well, look, we're building toward an intentional future from here forward. [[02:13:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8027.5599999999995s)]
*  It's what we decide to do and what we decide to build. [[02:13:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8030.64s)]
*  So I think today we got a really good deep understanding of some of the risks [[02:13:53](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8033.32s)]
*  and things we need to start planning for. [[02:13:57](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8037.88s)]
*  And I, but I do feel like everything is solvable if we, if we work on it and, [[02:14:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8040.48s)]
*  you know, we're on exponential time now, so we have very limited window of time [[02:14:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8045.599999999999s)]
*  to work on it. [[02:14:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8049.5599999999995s)]
*  So that was one of my great takeaways from today's pod, but much appreciated [[02:14:10](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8050.28s)]
*  perspective. [[02:14:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8053.8s)]
*  Yeah. Mo, how do you wrap up your thoughts from today? [[02:14:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8055.759999999999s)]
*  Yeah, I think just like it is a singularity and there is an upside utopia [[02:14:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8060.24s)]
*  and a downside dystopia, I think we should equally weigh our views of the [[02:14:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8065.04s)]
*  optimistic possibilities and the dangers or risks that we have to address. [[02:14:31](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8071.32s)]
*  I have to say I'm extremely, extremely excited about the scientific breakthroughs [[02:14:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8076.400000000001s)]
*  that we can see from, from, you know, AI in the next couple of years. [[02:14:41](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8081.32s)]
*  And I think the most important topic, even though we didn't cover as much of it [[02:14:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8086.32s)]
*  today, but we mentioned it is alpha evolve and the whole idea of self evolving [[02:14:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8090.68s)]
*  AI is in my mind. [[02:14:55](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8095.16s)]
*  This probably is the top topic to keep your eyes on in the next 12 months. [[02:14:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8096.72s)]
*  Salim, close this out, buddy. [[02:15:02](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8102.24s)]
*  I think we should have a whole episode just on alpha evolve. [[02:15:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8103.88s)]
*  I think it's such an important topic technically, but also philosophically. [[02:15:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8106.68s)]
*  I go back to the kind of standard basis for my optimism that technology has [[02:15:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8111.12s)]
*  always been a major driver of progress in the world. [[02:15:17](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8117.84s)]
*  It might be the only major driver of progress we've ever seen, as Rick [[02:15:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8120.360000000001s)]
*  Kurzweil mentions a lot. [[02:15:23](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8123.4800000000005s)]
*  And now we have AI uplifting all of these other technologies enabling. [[02:15:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8125.08s)]
*  So that's the reason for the huge optimism. [[02:15:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8128.76s)]
*  Yeah. [[02:15:32](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8132.56s)]
*  Yeah. [[02:15:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8133.28s)]
*  Again, I've said this before. [[02:15:33](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8133.400000000001s)]
*  I think we're holding two potential futures for humanity in superposition. [[02:15:34](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8134.84s)]
*  Uh, one is an extraordinary future of abundance, uh, upleveling of eight [[02:15:39](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8139.32s)]
*  billion humans on the planet, becoming a multi-planetary species that Star Trek [[02:15:44](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8144.76s)]
*  universe, uh, the other one is not quite as pleasant, uh, we'll call it a [[02:15:49](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8149.28s)]
*  dystopian future and, you know, Dave, and Dave, one of the things that you said, [[02:15:54](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8154.16s)]
*  I want to just echo is it's, we have the ability to create an intentional future. [[02:16:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8160.32s)]
*  This future is not happening to us. [[02:16:05](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8165.2s)]
*  We have the ability to guide where it goes. [[02:16:07](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8167.32s)]
*  And I think all the entrepreneurs listening today, um, it's the most [[02:16:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8169.96s)]
*  important thing that we can do. [[02:16:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8173.96s)]
*  What is the vision that you want to create in the world? [[02:16:15](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8175.5599999999995s)]
*  And you have the tools now, access to capital, access to compute, access [[02:16:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8178.719999999999s)]
*  to intelligence to go make that future happen. [[02:16:22](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8182.759999999999s)]
*  And I think it's not ours to abdicate to somebody else. [[02:16:25](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8185.679999999999s)]
*  I think we need to take action. [[02:16:28](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8188.88s)]
*  Um, so a lot happening, uh, all of you respect you deeply, love you all. [[02:16:30](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8190.92s)]
*  And, and so, so excited to be on this journey. [[02:16:36](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8196.64s)]
*  I look forward to seeing you guys, uh, in a week or so. [[02:16:40](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8200.0s)]
*  Thanks for having us. [[02:16:43](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8203.8s)]
*  Yeah. [[02:16:45](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8205.24s)]
*  Looking up with me. [[02:16:46](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8206.44s)]
*  Hey there. [[02:16:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8207.32s)]
*  This is Salim bouncing through SFO today. [[02:16:47](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8207.56s)]
*  Uh, hope you enjoyed that episode. [[02:16:50](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8210.56s)]
*  I it's clear from the pace of change that every organization needs to change. [[02:16:52](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8212.16s)]
*  On June 19th, we're going to be having a two hour workshop for a hundred [[02:16:56](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8216.92s)]
*  dollars on how to turn yourself into an EXO. [[02:17:00](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8220.16s)]
*  Come join us. [[02:17:03](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8223.32s)]
*  That's the best hundred dollars you'll spend all year. [[02:17:04](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8224.0s)]
*  Uh, we've had rave reviews of these. [[02:17:06](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8226.640000000001s)]
*  We do it about monthly. [[02:17:08](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8228.52s)]
*  We restricted to a few dozen people. [[02:17:09](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8229.6s)]
*  So it's a very intimate affair. [[02:17:11](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8231.400000000001s)]
*  Uh, and we'll be actually going through actual case studies [[02:17:13](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8233.720000000001s)]
*  and what you specifically can do. [[02:17:16](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8236.2s)]
*  Uh, don't miss it. [[02:17:18](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8238.400000000001s)]
*  Come along to 19th. [[02:17:19](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8239.12s)]
*  The link is below. [[02:17:20](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8240.52s)]
*  See you there. [[02:17:21](https://www.youtube.com/watch?v=jNWcWF8j7Sw&t=8241.28s)]
