---
Date Generated: May 30, 2025
Transcription Model: whisper medium 20231117
Length: 5708s
Video Keywords: ['peter diamandis', 'longevity', 'xprize', 'abundance']
Video Views: 162046
Video Rating: None
Video Description: In this episode, Emad, Salim, and Peter discuss the recent DeepSeek news, the China vs. USA AI race, and what Emad has been working on. 
Recorded on Jan 29th, 2024
Views are my own thoughts; not Financial, Medical, or Legal Advice.
Emad is the founder of Intelligent Internet and the former CEO and Co-Founder of Stability AI, a company funding the development of open-source music- and image-generating systems such as Dance Diffusion, Stable Diffusion, and Stable Video 3D. 
Salim Ismail is a serial entrepreneur and technology strategist well known for his expertise in Exponential organizations. He is the Founding Executive Director of Singularity University and the founder and chairman of ExO Works and OpenExO. 
Emad on X:https://x.com/EMostaque 
Learn more about Intelligent Internet: https://ii.inc/ 
Read Emad’s Paper: https://x.com/ii_posts/status/1877018732733612367 
Join Salim's ExO Community: https://openexo.com
Salim’s X: https://twitter.com/salimismail 
—******--
This episode is supported by exceptional companies:
Get started with Fountain Life and become the CEO of your health: https://fountainlife.com/peter/
AI-powered precision diagnosis you NEED for a healthy gut: https://www.viome.com/peter 
Get 15% off OneSkin with the code PETER at  https://www.oneskin.co/ #oneskinpod
******************************************--
Chapters
00:00 - DeepSeek's Disruption in AI
09:52 - Engineering Innovations and Cost Efficiency
19:52 - The Future of AI Models and Energy Efficiency
29:56 - Geopolitical Implications and Market Dynamics
33:10 - The Race for AI Superiority
36:08 - Navigating the AI Landscape: Competition and Collaboration
39:46 - Understanding AGI: Definitions and Implications
43:58 - The Future of Work: Disruption and Transformation
46:57 - Best and Worst Case Scenarios for AI
57:27 - Safety Concerns in the AI Race
01:03:57 - The Role of AI in Society
01:06:04 - OpenAI and the Future of AI Safety
01:08:31 - Digital Superintelligence: A Double-Edged Sword
01:11:34 - The Crisis of Meaning in an AI-Driven World
01:21:29 Building the Intelligent Internet
01:28:00 Reimagining Life and Governance with AI
******************************************--
I send weekly emails with the latest insights and trends on today’s and tomorrow’s exponential technologies. Stay ahead of the curve, and sign up now: https://www.diamandis.com/subscribe
Connect with Peter:
Twitter: https://bit.ly/40JYQfK
Instagram: https://bit.ly/3x6UykS
Listen to the show:
Apple: https://apple.co/3wLXeV3
Spotify: https://spoti.fi/3DwLzgs
---

# DeepSeek vs. Open AI - The State of AI w/ Emad Mostaque & Salim Ismail | EP #146
**Moonshots - Peter Diamandis:** [January 29, 2025](https://www.youtube.com/watch?v=lY8Ja00PCQM)
*  Last February I said DeepSeek one of my favorite AI companies out there. If you [[00:00:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=0.0s)]
*  look at each of the innovations they made it was largely engineering [[00:00:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4.4s)]
*  innovations. Do we see DeepSeek dethroning or reducing the valuation of [[00:00:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=7.68s)]
*  these companies at all? I think from my opinion it should increase the valuation. [[00:00:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=14.200000000000001s)]
*  The US versus China AI wars. You know this is a winner-take-all type of game. [[00:00:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=17.76s)]
*  This is the biggest crisis that we have coming because we're heading into a [[00:00:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=24.16s)]
*  future now where I'd say every single AI leader says the AGI is three to five [[00:00:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=29.52s)]
*  years away. [[00:00:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=34.44s)]
*  Welcome to Moonshots in an episode of WTF Just Happened in Tech with Salim [[00:00:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=39.44s)]
*  Ismail and a special guest Imad Mustak. You know Imad is the founder of [[00:00:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=44.6s)]
*  Stability AI, a company that had been the leading open source developer music and [[00:00:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=50.519999999999996s)]
*  image generation with 300 million open source downloads. Imad today is the [[00:00:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=56.88s)]
*  founder of Intelligent Internet. He'll be speaking about that but in this episode [[00:01:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=62.440000000000005s)]
*  we're doing a deep dive into three subjects. DeepSeek of course and the [[00:01:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=67.24000000000001s)]
*  constant disruption that's coming in every market at an accelerating pace. [[00:01:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=72.32000000000001s)]
*  We'll be diving into AI safety. What's going on at OpenAI as people are [[00:01:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=76.64s)]
*  starting to leave especially from their AI alignment team and then we'll chat [[00:01:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=82.44s)]
*  with Imad about Intelligent Internet. What's his plans? Where is he going? [[00:01:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=87.84s)]
*  Alright let's dive into this episode. For me this is an extraordinary week of [[00:01:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=91.84s)]
*  accelerating change and as always help me spread the message. Subscribe, tell [[00:01:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=97.44s)]
*  your friends. This is the conversation that I think is probably one of the most [[00:01:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=103.28s)]
*  important that we can be having right here right now. Let's jump into Moonshots. [[00:01:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=107.32s)]
*  Welcome to another episode of Moonshots. WTF just happened in tech this week. I'm [[00:01:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=112.44s)]
*  here with two besties, Salim Ismail the CEO of OpenEXO and Imad Mustak the CEO [[00:01:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=117.16s)]
*  of Intelligent Internet. No stranger to this podcast and it's been a crazy week. [[00:02:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=125.56s)]
*  We kicked it off with sort of a internet AI market meltdown on the news of DeepSeek [[00:02:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=132.36s)]
*  and the concussion waves keep coming. What does it all mean? We're here to have [[00:02:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=143.20000000000002s)]
*  that conversation. Imad, good morning to you or good evening. You're in London [[00:02:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=149.48000000000002s)]
*  today? Yeah, I'm in London. Morning to you. It was a pleasure. Yeah and Salim you're in Miami or New York? [[00:02:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=153.64000000000001s)]
*  Yeah. All right we've got three different time zones around the globe. We need [[00:02:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=160.12s)]
*  someone in Hong Kong to just balance this thing out but we'll get there soon [[00:02:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=163.64000000000001s)]
*  enough. So Imad, DeepSeek, no surprise for you. Was this something expected or was [[00:02:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=168.08s)]
*  this something like wow? I think it was actually expected. Like last February I [[00:02:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=174.92000000000002s)]
*  said DeepSeek one of my favorite AI companies out there. Like they took the [[00:03:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=182.08s)]
*  original ethos that we had at Stability, another ex-Hedge Fund manager and they [[00:03:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=186.56s)]
*  released amazing models open. I think when the AI community first started to [[00:03:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=191.2s)]
*  see this was probably around about summer of last year they released [[00:03:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=195.8s)]
*  DeepSeek Coda which hit the top of the code rankings. They started with [[00:03:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=199.52s)]
*  replicating Llama from Meta then they broke forward and in fact the algorithms [[00:03:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=204.04s)]
*  there are some of the algorithms they use now and then in December, like a month ago, [[00:03:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=209.84s)]
*  they released DeepSeek V3 which was actually what this six million dollar [[00:03:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=214.44s)]
*  training cost model was and it matched GPT-40 and all these other models. It [[00:03:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=218.56s)]
*  didn't match 01 at that point but we all thought they'll figure out how to do it [[00:03:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=223.88s)]
*  and guess what they did and it generalizes to any model. What was the, so it felt like the [[00:03:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=227.76s)]
*  internet broke on over the weekend as the announcement was made. What was it [[00:03:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=234.07999999999998s)]
*  that got everybody so hot and bothered instantly since it's been around for [[00:03:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=238.94s)]
*  some time? So there was the base model that was the chat GPT equivalent model [[00:04:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=243.92s)]
*  in December and that proved that you could train these models on a fraction [[00:04:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=248.88s)]
*  of the cost. The next thing was this reasoning model R1 where when you type [[00:04:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=252.0s)]
*  it shows you the reasoning, it takes a bit longer to think, has better quality [[00:04:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=256.64s)]
*  output. That actually came out last Monday but it was this weekend that this [[00:04:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=260.15999999999997s)]
*  narrative cascade happened and now you've got your mum and your aunt asking [[00:04:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=264.91999999999996s)]
*  about it you know and it's front news and then Nvidia cracked etc. I think [[00:04:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=268.88s)]
*  what it was is, remember the early days of chat GPT or stable diffusion on image, [[00:04:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=273.88s)]
*  the immediacy of response and that new paradigm. When OpenAI released 01, this [[00:04:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=278.92s)]
*  thinking model, it was amazing but it was a bit like using chat GPT. You put [[00:04:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=285.92s)]
*  something in it says I'm thinking and it gives you a response because what they [[00:04:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=291.28s)]
*  did is they hid the chain of thought reasoning. With R1 it actually shows [[00:04:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=295.08s)]
*  you this is how I'm thinking about it, this time breaking down the problem and it [[00:04:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=299.71999999999997s)]
*  feels like you have another person on the other side and as more and more people [[00:05:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=303.1s)]
*  use that and they saw the performance benchmarks, it built up into this [[00:05:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=306.62s)]
*  cascade because it was so immediately usable and they realized it was open [[00:05:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=310.58000000000004s)]
*  source so people took the smaller versions of it and started running it on [[00:05:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=314.54s)]
*  their laptops. If it was just a closed model that didn't have the chain of [[00:05:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=317.66s)]
*  thought but matched 01, it wouldn't have had that. If OpenAI had released the [[00:05:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=321.62s)]
*  chain of thoughts then I don't think it would have had the same thing. It said [[00:05:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=326.46000000000004s)]
*  there was this confluence of things that made people realize oh my gosh what is [[00:05:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=329.9s)]
*  this new thing and how has it been done and it challenges our assumptions. [[00:05:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=334.38s)]
*  Amazing. Salim, you and I on the phone over the weekend like huh this is real, this is [[00:05:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=338.41999999999996s)]
*  happening. What were your thoughts when this when you started? I have two [[00:05:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=344.14s)]
*  thoughts. I love the timing that they launched it on the day of the [[00:05:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=348.34s)]
*  inauguration. As a bit of a slap in the face to the incoming administration [[00:05:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=351.53999999999996s)]
*  saying we'll sanction you to bits etc etc and here's how the sanctions work. [[00:05:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=358.26s)]
*  The second thought I've had throughout the last 10 days or so is that you know [[00:06:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=363.46s)]
*  we were expecting demonetization and as the power of these models is accelerating [[00:06:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=368.58s)]
*  exponentially and blowing our minds, the demonetization should also kind of [[00:06:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=373.86s)]
*  surprise us in the same way and so the fact that they're able to do this at 1 [[00:06:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=377.65999999999997s)]
*  tenth or 100th or whatever, now how they got there is obviously an open question [[00:06:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=382.34s)]
*  but the fact that that has been achieved shouldn't be a big surprise on [[00:06:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=387.46s)]
*  the curves that we're looking at. It's incredible to see but we [[00:06:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=392.62s)]
*  shouldn't be surprised if we eat on dog food. [[00:06:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=398.14s)]
*  Go ahead, go ahead. I think someone noted it was actually the five-year [[00:06:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=402.7s)]
*  anniversary of the Wuhan lab leak as well except for this one was delivered. [[00:06:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=407.09999999999997s)]
*  Oh no. I'm not going to go there. But you know I put out in my my blog that followed the DeepSeek [[00:06:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=412.02s)]
*  announcement this is just going to be what is the new normal you know when [[00:07:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=424.5s)]
*  when Netflix ate Blockbuster for lunch you know this is just going to be [[00:07:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=431.9s)]
*  happening over and over again the speed at which heads are turning and snapping [[00:07:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=436.85999999999996s)]
*  across every industry. You know it's interesting because when we saw chat [[00:07:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=441.82s)]
*  GPT announced and it got to a million users in five days and a hundred million [[00:07:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=447.38s)]
*  users in two months people like can this ever be replicated again and the answer [[00:07:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=451.54s)]
*  is yes and faster. So Imad could you give us a quick rundown of what actually [[00:07:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=456.06s)]
*  how actually DeepSeek compares to GPT-40, GPT-01, any of the other models and [[00:07:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=466.22s)]
*  and you know there's a lot of claims being made about how many GPUs it was it [[00:07:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=475.38000000000005s)]
*  was created on, how much money, size of teams and it was those comparative [[00:08:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=480.22s)]
*  numbers that made it a big deal. If it was just an equivalent model but was not [[00:08:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=484.62s)]
*  being done at a fraction of the time or cost it would not have hit as hard as it [[00:08:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=492.02s)]
*  did. Yeah I think this was the shock was the order of magnitude so we can break [[00:08:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=496.58s)]
*  it down a bit. So 01 was this evolution of chat GPT that came out that suddenly [[00:08:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=502.41999999999996s)]
*  got to IMO medalist level or top coder level like top 1% coder level because it [[00:08:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=508.14s)]
*  could think longer. This is a key breakthrough now OpenAid have actually said [[00:08:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=514.62s)]
*  Mark Chen from their what DeepSeek figured out which was we'll get that in a [[00:08:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=517.9s)]
*  second was pretty much what they're doing at OpenAI. That was in November and [[00:08:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=523.5s)]
*  so we've had a few period there so first we have the model that matched chat GPT [[00:08:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=527.98s)]
*  then they figured out how to make it think longer but the main upshot that [[00:08:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=531.78s)]
*  shocked people I think initially was that it was 96% cheaper. Now software [[00:08:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=535.74s)]
*  usually has an 80% margin we don't know how much OpenAI charges but you know [[00:09:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=542.46s)]
*  they've got this hammer which is a large amount of GPUs they've never had to work [[00:09:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=546.62s)]
*  in a constrained environment so sometimes you are a bit price insensitive [[00:09:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=549.46s)]
*  particularly because the cost of running an 01 query to solve a math paper or a [[00:09:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=553.5400000000001s)]
*  legal problem because it's as good as any lawyer or doctor is so small still [[00:09:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=558.86s)]
*  but this was 96% cheaper than that which was number one. Number two was the fact [[00:09:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=562.7800000000001s)]
*  that this could be kind of released anywhere and the headline number of the [[00:09:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=568.74s)]
*  original model that was trained from the R1 evolution is probably only a hundred [[00:09:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=574.3s)]
*  two hundred thousand dollars from that which again we can come back to was a [[00:09:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=578.38s)]
*  shock. Last year well be in the year before last I can't remember the exact [[00:09:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=582.02s)]
*  number I think last year OpenAI spent three billion dollars on training models [[00:09:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=586.78s)]
*  amazing to give you an idea of that. Now how much did DeepSeek cost there were [[00:09:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=591.58s)]
*  accusations around they have 50,000 of these chips not 2,000 like we use in the [[00:09:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=597.54s)]
*  training run they never claimed how many chips they had they just said we'd [[00:10:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=602.1s)]
*  need 2,000 for this training run and we used it over this period of day to build [[00:10:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=604.7s)]
*  a model that looks like this. Those of us that have built these models know that [[00:10:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=608.3000000000001s)]
*  these numbers actually all check out and this is why some of the reaction has [[00:10:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=612.62s)]
*  been really interesting as people like well they have far more GPUs or they [[00:10:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=616.14s)]
*  have hidden GPUs and other things. The GPUs they have are these models called [[00:10:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=618.78s)]
*  an H800 which is like the top well now not quite the top-end Nvidia chip but [[00:10:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=623.7s)]
*  with the interconnect slightly reduced so the way that the chips speak to each [[00:10:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=629.18s)]
*  other is a bit slower. We have this issue at Stability AI a former company where [[00:10:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=632.9s)]
*  we built one of the largest super compute clusters in the world but we had [[00:10:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=636.9799999999999s)]
*  interconnect a quarter of the speed of other people because that's all we could [[00:10:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=640.4599999999999s)]
*  do again we were competing as the biggest guys we bought some of the best [[00:10:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=644.14s)]
*  models in the world. They wrote the lowest level code in PTX which is like [[00:10:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=646.8199999999999s)]
*  this CUDA but a level lower to overcome it they basically engineered the crap [[00:10:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=651.68s)]
*  out of it because some of them are ex-quantum hedge fund managers and others [[00:10:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=655.9s)]
*  and if you look at each of the innovations they made it was largely [[00:10:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=659.54s)]
*  engineering innovations which is very interesting from a mental model because [[00:11:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=663.5799999999999s)]
*  what's China amazing at? Engineering innovation. You look at BYD, you look at [[00:11:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=668.14s)]
*  Xiaomi. It shouldn't be any surprise that as you move from research to [[00:11:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=672.54s)]
*  engineering you would see this leap ahead but all the numbers kind of check [[00:11:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=675.88s)]
*  out you see the cost reducing I think they've probably got 10,000 chips in [[00:11:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=682.5s)]
*  total but that's not more than many startups in the valley to be honest. [[00:11:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=686.14s)]
*  Everybody Peter here if you're enjoying this episode please help me get the [[00:11:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=689.8599999999999s)]
*  message of abundance out to the world. We're truly living during the most [[00:11:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=694.9s)]
*  extraordinary time ever in human history and I want to get this mindset out to [[00:11:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=698.66s)]
*  everyone. Please subscribe and follow wherever you get your podcasts and turn [[00:11:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=703.14s)]
*  on notifications so we can let you know when the next episode is being dropped. [[00:11:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=708.4599999999999s)]
*  Alright back to our episode. You know I had a conversation with Kai-Fu Lee [[00:11:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=712.14s)]
*  recently on this podcast and we were talking about the notion how you know [[00:11:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=717.62s)]
*  the US government's been restricting Chinese companies from from getting [[00:12:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=723.42s)]
*  Nvidia chips and all that's done is create this evolutionary pressure for [[00:12:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=727.5s)]
*  them to do much more with much less and this sounds like a perfect example of [[00:12:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=734.62s)]
*  that. It's like Darwinian in its developmental force. [[00:12:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=740.22s)]
*  Yeah I mean again if all you have is a hammer and you have large amounts of GPUs [[00:12:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=744.94s)]
*  the way that this works is the GPUs compress the knowledge it's like [[00:12:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=748.86s)]
*  pressure cooking a steak and making it tender. Instead you look at things like [[00:12:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=752.3s)]
*  better data, better algorithms, more efficient things. If you can't scale on [[00:12:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=756.46s)]
*  compute speed because they don't have the chips for the speed because what [[00:12:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=760.74s)]
*  happens is as you go from 1,000 to 2,000 to 10,000 GPUs you can parallelize and [[00:12:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=764.14s)]
*  have more speed. They instead did memory as the key thing. So classical models are [[00:12:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=768.8199999999999s)]
*  very dense models like Lama 70 billion parameters. This is 640 billion [[00:12:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=774.9399999999999s)]
*  parameters but only 30 billion of them are activated at one time. They scaled on [[00:12:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=779.9399999999999s)]
*  memory and that is cheaper than superfast silicon. So these constraints I [[00:13:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=784.14s)]
*  think really are the key and we've seen it again and again that if you don't [[00:13:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=789.7s)]
*  need to worry about the constraints then you build inefficient models. If you have [[00:13:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=794.9000000000001s)]
*  to worry about efficiency then you know necessity is another invention. [[00:13:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=798.74s)]
*  Wasn't the CEO labeling the data and going through all that stuff because that adds so [[00:13:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=803.58s)]
*  much juice to the model? Models are just data. I mean again if models are figuring [[00:13:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=809.0200000000001s)]
*  out the interconnections it's like if you have a bad curriculum then you have bad [[00:13:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=815.26s)]
*  data. The models we train on right now are trained on terrible data like 14 [[00:13:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=818.02s)]
*  trillion words in the case of DeepSeq and Lama. You don't need that much data [[00:13:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=821.5s)]
*  to build an expert model but if you have a large amount of compute it doesn't [[00:13:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=825.8199999999999s)]
*  matter or even a 2,000. So what we're seeing now is data improvement. In fact [[00:13:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=828.98s)]
*  the data they used to turn this from a base model to a thinking model which they [[00:13:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=833.38s)]
*  then transformed the Lama model with and Quen was all synthetic data. So we move [[00:13:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=837.46s)]
*  to a point now where they figured out what the right type of data was and you [[00:14:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=843.14s)]
*  find typically with those that make breakthroughs they don't send the data [[00:14:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=846.82s)]
*  off to the Philippines and do all of this and try to make up for it with [[00:14:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=851.4200000000001s)]
*  engineering scale. You look at every part of that process and again this echoes [[00:14:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=855.3000000000001s)]
*  what we've seen in engineering. How did the engineering marvels happen at Tesla [[00:14:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=859.58s)]
*  or Chinese companies? They look at every part of that process and they simplify, [[00:14:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=863.86s)]
*  simplify, simplify. So we had David Sachs over the weekend with this comment [[00:14:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=867.34s)]
*  Terry let me go ahead and play this video one second and I love your [[00:14:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=873.66s)]
*  both your thoughts on it. Well it's possible there's a there's a [[00:14:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=878.4599999999999s)]
*  technique in AI called distillation which you're going to hear a lot about [[00:14:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=881.8199999999999s)]
*  and it's when a one model learns to another model. Effectively what happens [[00:14:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=884.86s)]
*  is that the student model asks the parent model a lot of questions just like [[00:14:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=889.9s)]
*  a human would learn but AIs can do this asking millions of questions and they [[00:14:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=893.8199999999999s)]
*  can essentially mimic the reasoning process that they learn from the parent [[00:14:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=898.5s)]
*  model and they can kind of suck the knowledge out of the parent model and [[00:15:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=903.14s)]
*  there's substantial evidence that what DeepSeq did here is they distilled the [[00:15:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=906.66s)]
*  knowledge out of open AIs models and I don't think open AI is very happy about [[00:15:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=913.02s)]
*  this. What do you think about that Umad? Well it's a bit calling the kettle [[00:15:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=917.46s)]
*  black right don't train in our data. I mean distillation is nothing new and [[00:15:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=923.18s)]
*  there's no way to kind of stop this from the model basis but if you actually [[00:15:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=928.8199999999999s)]
*  look at what the paper says and what's reasonable they have this version R10 [[00:15:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=932.62s)]
*  that created its own data and what's this familiar with it's familiar with [[00:15:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=936.66s)]
*  AlphaGo and AlphaGo 0 and Mu0 these rich reinforcement learning models [[00:15:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=940.42s)]
*  that outperformed humans on Go. In fact you could feel like maybe we're all [[00:15:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=945.7s)]
*  Lisa doll right like the AI is coming for all of our expertise. It's inevitable [[00:15:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=949.3s)]
*  that will happen but I don't think they deliberately went in and did that [[00:15:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=955.38s)]
*  because open AI's O1 outputs these cutting edge outputs were missing the [[00:15:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=957.66s)]
*  chain of thought reasoning step. We've seen now that as you take the chain of [[00:16:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=962.6999999999999s)]
*  thought reasoning from R1 and actually the new Gemini flash thinking the [[00:16:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=966.6999999999999s)]
*  Google model that's now top of the leaderboard that's what you really need [[00:16:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=971.14s)]
*  if you want to optimize this process so I think they actually created their own [[00:16:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=974.5s)]
*  synthetic data but as they look at all of the internet there will be some open [[00:16:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=977.4599999999999s)]
*  AI data in there. We've even seen that with Llama and Gemini and others [[00:16:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=982.62s)]
*  sometimes you ask it who made you open AI because it's taken so many of those [[00:16:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=986.02s)]
*  strengths. You know we've got a interesting impact on Wall Street that [[00:16:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=990.8199999999999s)]
*  occurs on Monday morning where it's you know read across the board. Nvidia got [[00:16:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=996.8199999999999s)]
*  hit massively. I'm sure you know open AI was reeling. Salim you know how do you [[00:16:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1005.42s)]
*  think about this because this is what people respond to. Yeah you know I [[00:16:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1015.74s)]
*  think markets are psychological and everybody goes oh my god and everything [[00:17:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1023.0600000000001s)]
*  crashes. There's no question that Nvidia's chips are overvalued but my [[00:17:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1026.34s)]
*  guess is and I'd love to get Emad's take on this is the overall demand in AI is [[00:17:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1033.02s)]
*  so exploding that it's not gonna really make a big dent in the demand for the [[00:17:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1036.9s)]
*  I mean like Nvidia's still up 100% over the last year right? It's like it's not [[00:17:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1043.42s)]
*  it because down a lot. No one knows what's coming but what's the market size [[00:17:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1048.62s)]
*  of this? The displacement is the displacement of all knowledge labor. [[00:17:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1052.98s)]
*  Just like the industrial age you replace muscles now you're replacing brain cells. [[00:17:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1056.86s)]
*  That's a huge market. We have a global GDP you know going [[00:17:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1061.22s)]
*  to 2025 of 110 trillion dollars you know half of it is physical labor and [[00:17:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1067.58s)]
*  half of it is you know effectively intellectual labor. It's it is massive. [[00:17:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1074.1799999999998s)]
*  And this is the thing that this is the technology the intelligent capital stock [[00:17:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1079.8999999999999s)]
*  that really will define productivity. So it's very difficult to get a handle of [[00:18:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1084.4199999999998s)]
*  how this will go. People have been talking like Satya Nadella about [[00:18:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1088.9399999999998s)]
*  Jevons paradox you know like the price the higher demand and Rokhan [[00:18:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1091.62s)]
*  Andreasen's been talking about this. I feel it is that and if you look at [[00:18:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1096.22s)]
*  Nvidia's strategy they've been moving to these fully integrated data center boxes [[00:18:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1098.98s)]
*  the GB 300 MVL 72s and this new thing digits which if you've seen a Mac mini [[00:18:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1104.5s)]
*  it's like a Mac mini that sits in a desktop as 128 gigabytes of VRAM a [[00:18:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1111.26s)]
*  petaflop of AI compute. For $3,000? $3,000 two of them can run R1. [[00:18:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1115.34s)]
*  So with that you have R1 at home and it's an entire baseboard created by that. [[00:18:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1124.5s)]
*  It doesn't have a fan even. It only pulls 200 watts of electricity. So you made a [[00:18:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1129.82s)]
*  comment earlier on in terms of the amount of energy and cost you think it [[00:18:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1135.26s)]
*  would cost it would actually take to build DeepSeek's model. Could you speak [[00:18:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1139.98s)]
*  to that? It was kind of insane. When we bought it on our first major [[00:19:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1145.06s)]
*  supercomputer this would have been about tenth fastest in the world publicly in [[00:19:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1149.6200000000001s)]
*  2022 at stability. It was 4,000 A100s which were the top of the range chips. [[00:19:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1154.14s)]
*  The internet connect was a bit poor but you know it was still big and each of [[00:19:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1158.26s)]
*  those chips used like 400 watts of electricity. That was a big old beast. If [[00:19:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1162.26s)]
*  you can recall the recent Nvidia announcement Jensen had this like [[00:19:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1167.5800000000002s)]
*  shield which was a chip. There was a new integrated box these MVL 72s. The 72 [[00:19:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1171.1200000000001s)]
*  chips super interconnected. In fact the interconnect on those chips is [[00:19:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1177.46s)]
*  equivalent to the bandwidth of the whole internet. That's how much faster [[00:19:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1181.26s)]
*  they've got. One of those boxes pulls down a hundred. Can you repeat that? [[00:19:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1185.3799999999999s)]
*  The computer on those chips as well? The interconnects the way that they [[00:19:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1190.46s)]
*  communicate with each other the total bandwidth is like six petabits a second [[00:19:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1194.62s)]
*  which is the bandwidth of the whole internet. They figured out how to get [[00:19:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1197.94s)]
*  everything integrated so you don't have this chip to chip interconnect. You just have [[00:20:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1201.46s)]
*  this like big wafer with 72 chips on it. It uses a hundred kilowatts of electricity [[00:20:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1204.46s)]
*  and when I was doing the math on this I was like so you have two thousand of [[00:20:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1209.34s)]
*  these H800 slightly hobble chips that the Chinese have right and DeepSeeker [[00:20:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1214.1399999999999s)]
*  using. I think it would require ten of these boxes at most probably even less [[00:20:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1219.6599999999999s)]
*  to create that model and each box costs three million dollars of these new [[00:20:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1225.6999999999998s)]
*  data center boxes. In fact I think it probably only costs four of these boxes [[00:20:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1231.06s)]
*  and even if you take the upper bound the total energy required to train a model [[00:20:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1235.02s)]
*  is a thousand megawatt hours and it's like 15 bucks or something a megawatt [[00:20:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1240.3s)]
*  hour in the US now. You could literally train it off of a [[00:20:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1247.7s)]
*  small solar farm in your backyard. Well a big solar farm you know it's still [[00:20:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1253.9s)]
*  pulls down decent amount like a hundred thousand kilowatt hours of energy but [[00:20:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1258.74s)]
*  then that box to run it you could definitely run DeepSeeker one on solar [[00:21:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1263.02s)]
*  power panels and if we look at the direction this is going because it's [[00:21:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1267.5s)]
*  still not optimized next year you should be able to get an O1 level model on your [[00:21:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1271.1399999999999s)]
*  smartphone that pulls at most 20 watts of electricity and it's a less than a [[00:21:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1277.7s)]
*  dollar per watt of solar power and this doesn't make sense if you look at what [[00:21:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1282.1399999999999s)]
*  these models are capable of and we think about the cost of intellectual labor. [[00:21:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1286.54s)]
*  Well it makes it makes sense when you think about how much energy your brain [[00:21:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1289.86s)]
*  pulls. It's 20 watts. And so we've got a we have a huge efficiency curve to ride [[00:21:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1295.54s)]
*  to get there. And I think the thing is like by next year you will have these O1 [[00:21:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1303.5s)]
*  level models on 20 watts which is our human brain level and these are PhD [[00:21:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1308.9799999999998s)]
*  level in so many areas and that doesn't compute because we've had these [[00:21:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1314.3s)]
*  discussions of Microsoft is bringing back Three Mile Island as a nuclear [[00:21:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1318.78s)]
*  power reactor you know Dyson's is energy is going to use everything like 60 [[00:22:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1322.86s)]
*  gigawatts of electricity is coming on for data centers in the US I think over [[00:22:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1328.02s)]
*  the next year or so. Yet when we get down to the actual numbers for a given unit [[00:22:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1331.98s)]
*  of intelligence it's a few watts it's a few pennies before that it would take [[00:22:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1336.42s)]
*  entire teams using how many watts of energy in their brain in their [[00:22:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1342.82s)]
*  infrastructure and we're not ready for that. Salim you asked a question about [[00:22:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1347.18s)]
*  how challenging is DeepSeek actually to open AI, Meta, NVIDIA. What are you [[00:22:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1351.0600000000002s)]
*  thinking there? I've got two questions here. One is does the fact that it's [[00:22:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1358.8200000000002s)]
*  Chinese and companies will be reticent to put their information into it make a [[00:22:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1365.3400000000001s)]
*  big difference. That's a question for you and my guess is the answer is no [[00:22:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1370.3s)]
*  because it's open source and you can run it locally. Is that correct? You can but [[00:22:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1373.3s)]
*  most people won't right? Just like you give you code to give all your stuff to [[00:22:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1377.1s)]
*  TikTok. No one knows what happens with all this data and the version that you [[00:23:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1382.34s)]
*  can run locally are actually the distilled versions not the main version. [[00:23:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1387.1399999999999s)]
*  It's quite difficult to run the main version locally. So I think there's a [[00:23:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1390.6999999999998s)]
*  there's a geographic arbitrage advantage that the incumbents still have that's [[00:23:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1393.82s)]
*  that's there that's pretty powerful. So let's stick on that question about you [[00:23:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1398.62s)]
*  know so the question I was asked by everybody on X and my friends was is [[00:23:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1403.9s)]
*  this gonna go the same path as TikTok where in fact DeepSeek will be well let [[00:23:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1408.7s)]
*  me back up a second. When open AI first came out with chat GPT you had all of [[00:23:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1415.7800000000002s)]
*  these companies and Imad you and I had this conversation all these companies a [[00:23:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1420.8200000000002s)]
*  lot of the banks saying you cannot use chat GPT in the office we don't want you [[00:23:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1424.1000000000001s)]
*  know open AI to hope to own our data. There was this immediate privacy desire [[00:23:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1429.94s)]
*  which is still valid but are we gonna see the same thing with DeepSeek where [[00:23:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1437.8200000000002s)]
*  people are like no can't use DeepSeek we're worried about the data and where [[00:24:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1442.42s)]
*  it's gonna be resident. I think you've seen a couple of announcements so [[00:24:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1447.64s)]
*  perplexity announced they're using DeepSeek locally fully on American farms [[00:24:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1450.6200000000001s)]
*  etc you know so farms and you'll see that type of thing even if they're [[00:24:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1454.42s)]
*  running the larger ones but again it's difficult to run yourself but there'll [[00:24:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1458.66s)]
*  be APIs. Number two is you've seen open AI announce chat GPT for government used [[00:24:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1461.3000000000002s)]
*  by 96,000 federal employees and this is the direction things are going whereby [[00:24:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1467.98s)]
*  I think you'll have four different types of AI. Super expert AGI that you call [[00:24:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1473.18s)]
*  upon when needed, your personal AI your Google your Apple AI these open weight [[00:24:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1477.74s)]
*  models like DeepSeek and Llama which are useful but not in regulated industries [[00:24:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1483.8200000000002s)]
*  than open source open data AI where these decision support systems you need [[00:24:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1488.22s)]
*  to know what's inside them and how they are actually because you can poison [[00:24:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1492.5s)]
*  these models with inherent biases. There was this anthropic paper we discussed [[00:24:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1496.1000000000001s)]
*  before Peter called sleeper agents with a few thousand words out of 10 trillion [[00:24:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1499.8600000000001s)]
*  with just one word you can turn the model evil or change its behavior [[00:25:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1505.6200000000001s)]
*  completely. Amazing. It's like the actual it's funny enough you know most of the [[00:25:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1509.42s)]
*  transformers in the US are built by Chinese companies and no one knows the [[00:25:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1514.3s)]
*  control software of that. These types of threats right? Do you want the [[00:25:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1518.5s)]
*  transformers that run your business to also have that potential threat? So [[00:25:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1522.1s)]
*  that's what we're doing now in touch internet building out that open source [[00:25:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1526.26s)]
*  stack for the regular. I want to dive into what you're building out with your [[00:25:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1529.06s)]
*  your newest company Intelligent Internet because it's got one of the boldest [[00:25:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1534.06s)]
*  visions I've ever seen for supporting humanity. The impact of DeepSeek on open [[00:25:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1539.6s)]
*  AI, NVIDIA, Meta, Google you know I see this you know this comment from Sam [[00:25:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1547.1599999999999s)]
*  Altman to read it and says you know DeepSeek's R1 is an impressive model [[00:25:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1554.6s)]
*  particularly around what they've been able to deliver for the price. We will [[00:25:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1559.56s)]
*  obviously deliver much better models and also it's legit invigorating to [[00:26:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1563.52s)]
*  having you competitor. You know we're gonna talk about AI safety in a little [[00:26:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1569.8s)]
*  bit because when you're legitimately invigorated you pull out all the stops [[00:26:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1574.28s)]
*  you pull out all the regulations you do whatever you take to jump forward and [[00:26:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1578.92s)]
*  that's concerning but do we see DeepSeek dethroning or reducing the the you know [[00:26:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1583.76s)]
*  valuation of these companies at all? We saw it for a day but is it valid? I think [[00:26:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1594.04s)]
*  from my opinion it should increase the valuation. It's bringing forward the time [[00:26:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1600.56s)]
*  of mass intelligence too cheap to measure. If you look at open AI what Sam [[00:26:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1606.08s)]
*  has done masterfully is 300 400 million users like what is AI in most people's [[00:26:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1611.32s)]
*  mind is chat GPT right? Yeah. Gemini and Claude don't even register and if the [[00:26:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1616.52s)]
*  cost comes down it's good for him. This is the Zuck school of thought. Why did [[00:27:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1623.04s)]
*  they open source llama? Because it uses 10% of their GPUs and if there's a 10% [[00:27:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1628.1599999999999s)]
*  performance gain it pays for itself and so open AI will use whatever they didn't [[00:27:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1633.6s)]
*  most of their models don't have brand new algorithms they've borrowed from [[00:27:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1639.0s)]
*  Google and many others right? There's no real secrets in this space especially [[00:27:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1642.32s)]
*  now with no non-computes in California you know that helps and so for me what [[00:27:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1646.68s)]
*  is open AI as a company? They were in this pre-training massive compute stage [[00:27:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1653.64s)]
*  now that's becoming commoditized people can pre-train like open like XAI and [[00:27:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1658.04s)]
*  others but my pre-training maybe doesn't require as much. The data is getting [[00:27:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1663.5600000000002s)]
*  better and better it becomes about intelligence refinement from seeing how [[00:27:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1667.0s)]
*  people use it. It's the operator paradigm whereby open AI can now run your compute [[00:27:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1670.2s)]
*  macbook or whatever you can let it take over and it can book your holiday for [[00:27:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1676.24s)]
*  you. That's the next stage and I think they're well set up for that and their [[00:28:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1680.4s)]
*  costs should decrease again open AI made three billion of revenue last year they [[00:28:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1684.84s)]
*  lost five billion of which three billion was training models. You don't need to [[00:28:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1689.4s)]
*  spend as much training models it's good. So your thesis says the the feedback loop [[00:28:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1694.0s)]
*  of people using the model and because they've got so much there are so many [[00:28:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1701.2s)]
*  users gives them a pretty good edge. I can see that. I think it's that and then [[00:28:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1704.84s)]
*  you use these they've got like half a million GPUs coming these B series the [[00:28:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1709.8s)]
*  VR series and others you can now make those go sequential to build even better [[00:28:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1714.56s)]
*  data and map and feed that back into models that you optimize and you [[00:28:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1719.32s)]
*  hyper optimize. Like classically in computing things were not parallelized [[00:28:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1722.8s)]
*  they were sequential. So we've had this period of these big clusters now it's [[00:28:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1727.76s)]
*  about swarms of models of agents solving tasks because they've got good [[00:28:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1732.24s)]
*  enough cheap enough and fast enough. Actually that's the final thing about deep [[00:28:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1738.04s)]
*  seek. Same with stable diffusion on image back in the day. Good enough fast enough [[00:29:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1740.52s)]
*  cheap enough. It's that trifecta that causes these massive adoption curves. [[00:29:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1744.28s)]
*  You know when when this was announced you heard that Zuck created four war rooms of [[00:29:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1749.36s)]
*  engineers to try and decipher what was going on and how to utilize it. I mean it [[00:29:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1755.52s)]
*  really is an AI arms race where everybody is sort of is surfing on top [[00:29:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1761.32s)]
*  of each other's advances and just accelerating everything. What I found [[00:29:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1766.6s)]
*  fascinating and I'm curious about this is the size of their team doing it with [[00:29:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1772.08s)]
*  relatively and an open AI had you know a 200 person team during its earliest days [[00:29:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1777.72s)]
*  as well. How do you think about the size of your team for the ability to create [[00:29:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1783.72s)]
*  something disruptive? Too big? Is bloated? Small and nimble? I think a core team of [[00:29:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1790.3999999999999s)]
*  about a hundred researchers beyond that it gets bloated. So at Stability we had [[00:29:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1797.8799999999999s)]
*  80 researchers and developers 16 PhDs and we achieved state-of-the-art and [[00:30:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1802.24s)]
*  image video every modality even multilingual and so we had 300 million [[00:30:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1807.1s)]
*  downloads on Hugging Face the most downloaded company the most popular [[00:30:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1812.56s)]
*  open source files there. Once we scale past that to 150 things started to [[00:30:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1815.76s)]
*  break down because it is about this rapid iteration it is about trying new [[00:30:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1820.8s)]
*  things and research being an innovation center versus a cost center. You start to [[00:30:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1824.52s)]
*  have too much compute and other things as well and again open AI I think did [[00:30:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1830.04s)]
*  their best work when they were smaller but they scale still scaled up and still [[00:30:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1833.1599999999999s)]
*  do good work but it is a question mark now like it's become an organization and [[00:30:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1836.3999999999999s)]
*  Salim is the expert in. Once you get past that level it's so difficult to [[00:30:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1842.1999999999998s)]
*  maintain innovation. Salim? Yeah you end up getting you end up with a problem of [[00:30:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1847.3999999999999s)]
*  either top-down control structures with slow down innovation or you let [[00:30:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1853.6s)]
*  everybody do whatever they want you get a lot of duplication and so you end up [[00:30:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1858.04s)]
*  with you have to manage that tension around it and there's just a lot more [[00:31:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1862.36s)]
*  complexity and you know it's fascinating 150 people is the Dunbar [[00:31:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1867.4s)]
*  number yeah where anthropologically we found that this is a pretty solid [[00:31:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1871.3600000000001s)]
*  reliable threshold. I do think to get back to Imad's earlier comment that [[00:31:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1875.76s)]
*  opening has a lot more people than they really need because they have so much [[00:31:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1881.92s)]
*  money they can just throw bodies at things now to force them to be a little [[00:31:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1885.24s)]
*  bit more efficient and I also believe that this this is a good thing for the [[00:31:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1889.48s)]
*  overall market because the rising tide lifts all boats. I think we're going to [[00:31:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1894.44s)]
*  end up with a balkanization though where you know Western companies won't want to [[00:31:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1900.6000000000001s)]
*  use deep-seeker type models like I can't imagine an Indian major Indian state [[00:31:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1905.28s)]
*  enterprise wanting to use a model like that for all of the security reasons and [[00:31:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1910.16s)]
*  then you have to develop homegrown models and then everybody ends up with [[00:31:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1914.44s)]
*  their own models in different ways and so you end up with a splintered effect. [[00:31:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1917.88s)]
*  We'll talk about that with Imad's vision and mission on intelligent internet. I [[00:32:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1921.4s)]
*  want to dive down into China for a moment longer because I think part of [[00:32:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1927.44s)]
*  the announcement wasn't just a cheaper open source model it was this level of [[00:32:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1934.52s)]
*  innovation coming out of China which rocked people because I think the [[00:32:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1940.76s)]
*  majority of the world doesn't see China as sort of the hotbed of AI innovation [[00:32:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1945.6s)]
*  that it is. Here's an article from Business Insider, Trump's threat on [[00:32:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1952.56s)]
*  Taiwan. Chips tariffs could give Nvidia a fresh headache after deep-seek. How do [[00:32:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1959.12s)]
*  you think about all of this Imad? Well I think these are the real reason Nvidia [[00:32:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1966.32s)]
*  would go down or maybe Jim Cramer the previous week saying buy Nvidia you know [[00:32:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1969.7199999999998s)]
*  one of these things. I mean we've seen they want to home show this they're [[00:32:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1973.08s)]
*  trying to build chips there. Intel's probably in play as an acquisition target. [[00:32:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1977.8799999999999s)]
*  Oh it's definitely in play. I mean it's like it's fresh meat on the table [[00:33:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1982.24s)]
*  and everybody's figuring out how to chop it up. Well I mean if you look these [[00:33:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1987.76s)]
*  chips they're getting super fast and super good with Nvidia like if people [[00:33:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1993.48s)]
*  talk about AMD, AMD chips are impossible to use you know the software isn't there [[00:33:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=1997.76s)]
*  there's bugs and everything it takes a few generations to get stable and [[00:33:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2003.04s)]
*  video chips work but Chinese chips also work. So the deep-seek model API was [[00:33:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2006.1599999999999s)]
*  being run on Huawei Ascend 910 chips which are a few generations behind in [[00:33:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2012.1599999999999s)]
*  terms of efficiency but they work. Similarly China has two exascale [[00:33:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2017.52s)]
*  computers two of the fastest supercomputers in the world built in a [[00:33:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2023.04s)]
*  completely different way Oceanlight and Tianhe 3 because they just built at [[00:33:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2025.92s)]
*  scale and bulk. Now what the case is here is that this particular thing is [[00:33:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2030.2s)]
*  they want to increase US production because the means of production and the [[00:33:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2035.68s)]
*  means of productivity of a society which originally its capital stock, its [[00:33:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2039.44s)]
*  industrial capital stock, its IP, it will be chips. How competitive you are on the [[00:34:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2042.92s)]
*  world will be how much compute and intelligence you have. I think the US has realized this. [[00:34:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2049.32s)]
*  And how much energy you have to throw at it. Yeah that's a factor of that as well and so [[00:34:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2053.8s)]
*  the US has realized this so it's drill baby drill it's re-onsure as much of this [[00:34:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2058.92s)]
*  as possible and it's create the incentives to do that which is basically [[00:34:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2062.6800000000003s)]
*  this. Like they'll take any of that power of money and they'll put it straight [[00:34:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2066.8s)]
*  back into Stargate type initiatives I think. What do you think about Stargate? [[00:34:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2070.52s)]
*  Speaking of Stargate. I think the 500 billion dollars is the total cost of [[00:34:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2074.36s)]
*  ownership that's pretty well known it'll probably like a hundred billion when you [[00:34:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2078.8s)]
*  back everything out which feels small these days so it's actually a lot of [[00:34:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2081.44s)]
*  money. But then when we compare that to the 5G rollout it's less money than we've [[00:34:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2085.08s)]
*  spent on 5G and this is more important than 5G. Compare it to I mean it's the [[00:34:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2091.04s)]
*  order of magnitude of the Los Angeles San Francisco railway you know. The [[00:34:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2097.08s)]
*  mythical Los Angeles San Francisco railway. There's like a kilometer already there. [[00:35:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2102.2s)]
*  Salim did you see this article this morning from Reuters Alibaba releases AI [[00:35:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2107.2400000000002s)]
*  model it says surpasses DeepSeek. The unusual timing of Quen 2.5 Max's [[00:35:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2111.76s)]
*  release points the pressure Chinese AI startup DeepSeek, DeepSeek [[00:35:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2118.8s)]
*  meteoric rise in the past few weeks has placed on not just overseas rivals but [[00:35:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2123.1000000000004s)]
*  also its domestic competition. You know this is just speaks to the [[00:35:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2128.6000000000004s)]
*  democratization right. I mean the everybody will end up creating a bunch [[00:35:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2132.6400000000003s)]
*  of models and I think we'll end up with a bunch of very specialized models right. [[00:35:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2137.96s)]
*  I remember Eric Schmidt's comment that you'll end up with a specialized AI [[00:35:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2143.68s)]
*  that's the world's best physicist and a one that's the world's best biotech [[00:35:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2147.56s)]
*  person and that person can be replicated that AI can be replicated [[00:35:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2152.28s)]
*  infinitely and so now what do you do with deep specialty on the human side [[00:35:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2155.6s)]
*  and that I think is the bigger question around a lot of this stuff. The models [[00:35:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2159.76s)]
*  are just going to keep getting better and better as we've seen over time. [[00:36:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2163.6s)]
*  I mean I think Imad's comment around what to do with labor and seeking capital [[00:36:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2166.72s)]
*  is a really really profound question. That's I think the really structurally [[00:36:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2174.08s)]
*  and from a societal perspective that's the question I think we should be [[00:36:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2179.08s)]
*  spending a lot more time on as a global as a global intellectual forum of how do [[00:36:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2182.08s)]
*  you navigate this going forward because this changes everything. Yeah the models [[00:36:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2188.8399999999997s)]
*  again it's good enough cheap enough fast enough right and in fact the other Quinn [[00:36:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2192.2s)]
*  model the VL model at performers anthropic and GPT-40 on visual [[00:36:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2196.2s)]
*  understanding and the ones they have coming next are the ones that control [[00:36:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2201.0s)]
*  your computer but anything that can be done on the other side of a screen this [[00:36:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2204.48s)]
*  year the AI can do better for pennies. So there's a lot of conversation going on [[00:36:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2209.12s)]
*  across Silicon Valley across the White House about and I'm speaking to Ray [[00:36:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2215.72s)]
*  Dalio next week about this as well the US versus China AI wars. I mean there are [[00:37:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2224.16s)]
*  two levels of competition going on right now right. It's competition between [[00:37:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2232.44s)]
*  companies and there's you know six seven eight major AI companies out there that [[00:37:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2235.32s)]
*  are vying for number one position and then competition among nations. You've [[00:37:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2242.2s)]
*  got Saudi Arabia wanting to be at the top of the stack committing you know [[00:37:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2248.64s)]
*  hundreds of billions of dollars followed by you know Qatar and the [[00:37:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2252.68s)]
*  Emirates but you've got US and China really going at it and and the question [[00:37:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2258.52s)]
*  of you know this is a winner-take-all type of game. If you develop a digital [[00:37:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2265.2s)]
*  superintelligence before your corporate or national competitor does by [[00:37:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2270.96s)]
*  just a little bit it could be it could be devastating. Iman how do you think [[00:37:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2277.88s)]
*  about about US versus China in that regard? Well I think this is the we're [[00:38:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2285.32s)]
*  heading into a future now where I'd say every single AI leader that I could [[00:38:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2291.16s)]
*  think of says that AGI is three to five years away. That we just had we just had [[00:38:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2296.72s)]
*  Sam say it's this next year. Yeah but let's say within the next three to five [[00:38:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2301.68s)]
*  years every leader we're talking about Dario, Demis, everyone, myself, whoever. [[00:38:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2306.72s)]
*  There's consensus is what you mean. That's crazy if you think about it right like everyone [[00:38:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2311.56s)]
*  says it's coming and there's this concept of AGI ASI as this pivotal [[00:38:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2315.62s)]
*  action moment where one entity would have the ability to shut down China. You [[00:38:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2320.3199999999997s)]
*  just turn it off you know. So pivotal act is you build AGI first and then turns [[00:38:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2324.6s)]
*  it off. That might happen and we still don't know about that which is why you [[00:38:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2328.2s)]
*  now you start preparing for it just like Sundar Pichai at Google said why are we [[00:38:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2331.64s)]
*  building out all these GPUs? Because we can't afford not to. Yeah. You know and [[00:38:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2336.36s)]
*  that's the game theory of that. You can't afford not to build an AGI now if [[00:39:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2340.3199999999997s)]
*  everyone else is building it. Before AGI though there's like an AGI we can think [[00:39:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2344.6s)]
*  of as a mega chef that can come up with any recipe and outcompete all of us. What [[00:39:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2350.32s)]
*  we have right now this year are amazing cooks that can follow recipes and do [[00:39:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2355.84s)]
*  jobs better than humans like the robots from Unitree yesterday doing the Chinese [[00:39:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2360.76s)]
*  dance with the fans. I don't know if you saw that. Like robotics is getting to the [[00:39:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2364.52s)]
*  point where they can build houses better. I'm gonna have the Unitree robots at at [[00:39:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2368.2000000000003s)]
*  the abundance summit and I mean it's incredible there's $16,000 for one of [[00:39:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2372.1200000000003s)]
*  their mid-tier levels. That's $1.50 an hour. What's that? That's $1.50 an hour when you bake [[00:39:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2377.56s)]
*  into depreciation energy costs and everything. I have it pegged at 40 [[00:39:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2384.56s)]
*  cents an hour. I mean it's insane. It really is. I think my kids will buy one [[00:39:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2388.7999999999997s)]
*  just to clean up the room. And that's the most expensive it'll ever be right? [[00:39:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2395.2s)]
*  You might when you talk about AGI in three to five years let me get to Mike's [[00:39:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2399.7999999999997s)]
*  soapbox question that I ask. What do you mean by AGI? The best kind of [[00:40:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2403.52s)]
*  framing I've seen is those multiple tests like the Wozniak test and the [[00:40:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2407.96s)]
*  IKEA test etc. What's your framing on what do you consider to be AGI? I think [[00:40:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2412.08s)]
*  it's probably a complex system that can outperform a team. I think before that I [[00:40:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2417.32s)]
*  had this idea of ARI, artificial remote intelligence. You can't tell if it's a [[00:40:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2422.48s)]
*  human or a computer on the other side is your remote worker because that's the [[00:40:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2427.12s)]
*  most natural way that this first starts coming in right? Like you call a company [[00:40:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2430.96s)]
*  and they put a bunch of people. We have the technology now that you can have a [[00:40:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2435.2s)]
*  zoom call with someone and it could be a hundred percent a robot. Yeah. Your [[00:40:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2439.08s)]
*  worker is plugged into slack. It joins you on zooms. I mean right now there's a [[00:40:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2444.48s)]
*  we're living in a world of distributed workforce and if you've got an AGI that [[00:40:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2449.64s)]
*  is able to literally plug in, take a role fully and have read all of the email [[00:40:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2455.84s)]
*  traffic, all the slack traffic and be up to speed instantly, that's an exciting [[00:41:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2463.44s)]
*  and exciting world. It's an exciting world but at the same time that's the [[00:41:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2469.0s)]
*  first level of disruption right? Because you don't need any more BPO outsourcing. [[00:41:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2472.84s)]
*  The nature of the firm will change because they will be super chefs, so cooks. [[00:41:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2477.44s)]
*  They will not make mistakes or they will learn from their mistakes once. They have [[00:41:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2481.32s)]
*  low communication overhead. The next step is teams of that. So independent [[00:41:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2485.24s)]
*  agentic, they have a task and they can get resources towards that. This is why [[00:41:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2490.08s)]
*  Wyoming's Dowlore and other things get very interesting and the step beyond [[00:41:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2494.4799999999996s)]
*  that is this ASI thing that we can't redefine where there's a big takeoff, [[00:41:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2498.08s)]
*  where it has beyond human team organizational capabilities. Like it can [[00:41:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2501.68s)]
*  invent incredibly quickly. Well what I'm excited about is going to be the impact on [[00:41:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2508.12s)]
*  physics and on biology and on pure science taking us way beyond, you know [[00:41:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2513.2s)]
*  Dario was on video, I think it was from Davos saying and I know you believe this [[00:41:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2518.8799999999997s)]
*  you might because we've had these conversations, then the next five years [[00:42:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2524.96s)]
*  will make a hundred years worth of progress in medicine and biotech and [[00:42:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2528.3199999999997s)]
*  double human lifespan. I mean that's pretty extraordinary commentary to be [[00:42:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2532.22s)]
*  made, making publicly. Yeah and I think one of the most fascinating things over the [[00:42:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2537.3599999999997s)]
*  last week is this, when you use O1 and you dump a bunch of stuff in you can't do [[00:42:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2541.6s)]
*  file uploads and other things which is a bit annoying. It's not that creative but [[00:42:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2546.44s)]
*  it's thorough. With R1 because it hasn't been tuned and made safe and others it's [[00:42:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2550.44s)]
*  actually very creative. So someone actually took a code base for R1 and [[00:42:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2556.44s)]
*  then made it double the speed in terms of performance. Other people have put [[00:42:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2562.24s)]
*  together academic papers and it's synthesized those into new reinforcement [[00:42:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2565.88s)]
*  learning algorithms and that's an indication of now maybe if like the [[00:42:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2570.12s)]
*  downside is maybe these things get less safe. The upside is maybe they get more [[00:42:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2575.16s)]
*  creative and again these are the levels. Are you an amazing cook? That's the [[00:42:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2578.4s)]
*  disruption of the labor market right? Especially anyone behind the screen. Are [[00:43:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2581.96s)]
*  you an amazing chef? That takes us into this AGI as a team, ASI kind of concept [[00:43:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2586.12s)]
*  and again that feels not three to five years away for me. That feels much [[00:43:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2591.48s)]
*  quicker given all these exponentials and very few people are preparing for that. [[00:43:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2595.18s)]
*  Yeah, so again the point I opened up with which is we're gonna see disruption [[00:43:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2599.96s)]
*  after disruption and our financial markets aren't ready for this as well. [[00:43:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2606.36s)]
*  We're gonna see the energy market. I think one of the implications [[00:43:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2612.64s)]
*  we're gonna see with AGI, ASI is gonna be new forms of energy sources which will [[00:43:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2618.52s)]
*  potentially topple our petrodollars and destabilize government revenues. So we [[00:43:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2626.7599999999998s)]
*  have fascinating and massive implications coming. Well have you ever [[00:43:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2634.4399999999996s)]
*  seen that chart of GDP per capita versus energy per capita? Yeah. It's basically a [[00:43:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2638.9599999999996s)]
*  straight line. It is and it correlates with health as well and lots of other [[00:44:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2644.22s)]
*  things. That could be completely disrupted because to make, let's say a [[00:44:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2649.2s)]
*  couple of years to make the best film studio in the world you can do it [[00:44:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2654.2s)]
*  anywhere with solar power. That's what I'm talking about. You could have science [[00:44:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2657.2799999999997s)]
*  happening in Guatemala or anywhere like that. It's an uplift of global IQ and [[00:44:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2661.7999999999997s)]
*  aggregate if this technology proliferates versus this brain drain [[00:44:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2667.52s)]
*  that we've had out to the West classically. And again you think about [[00:44:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2673.12s)]
*  your capital stock, your intellectual and physical capital stock. It's massively [[00:44:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2676.92s)]
*  redistributive and our economies are not set up for that because productivity [[00:44:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2681.64s)]
*  was a function of labor which was a function of energy. That correlation is [[00:44:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2686.72s)]
*  about to break for the first time ever. I agree. I think you know we're moving [[00:44:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2690.8799999999997s)]
*  from an energy economy to an information economy and now the data sets and the [[00:44:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2695.16s)]
*  information you have will be paramount. I think we need to start asking [[00:45:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2700.16s)]
*  really big philosophical questions like what do we want all this to do and what [[00:45:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2705.12s)]
*  do we want to be like and how do we what are the activities and functions we [[00:45:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2708.96s)]
*  want to be doing as human beings as the job market disintegrates in front of us. [[00:45:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2712.12s)]
*  You know I still have my trepidations about humanoid robots etc. but once they [[00:45:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2716.7200000000003s)]
*  show up and have feedback loops and have built-in LLMs into their circuitry you [[00:45:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2724.04s)]
*  have a fully functioning robot that can do lots of varied things. You kind of [[00:45:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2731.16s)]
*  suddenly don't need a gardener or plumber or lots of other kind of things. [[00:45:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2739.64s)]
*  I'm using those examples as a tongue-in-cheek because those are probably [[00:45:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2743.44s)]
*  the ones you need the most. But there are many many functions, aircraft [[00:45:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2746.96s)]
*  maintenance right, that will be done much better and much more precise [[00:45:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2750.8799999999997s)]
*  because of the access to information. We talked a lot a couple of episodes ago [[00:45:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2755.68s)]
*  about the fact that if there's an avatar of you or me Peter it's much more [[00:46:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2760.04s)]
*  reliable because it's got full access to everything we've ever said rather than [[00:46:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2764.08s)]
*  what we can hold in our brains. Far more charming, far more compelling. [[00:46:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2767.56s)]
*  Even better looking. So how do we navigate that? I think this is [[00:46:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2771.24s)]
*  where Imad, your kind of philosophical bent towards this becomes really really [[00:46:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2776.96s)]
*  important and I'd love your take on where this goes. The displacement of [[00:46:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2781.36s)]
*  labor is just a starting point in all this. Before we get into that [[00:46:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2785.36s)]
*  because I want to go deep in the second half of this pod today into Imad's [[00:46:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2789.4s)]
*  point of view there, I want to hit on a couple of questions Imad. What do you [[00:46:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2795.88s)]
*  think is the best-case scenario for AI this year in 2025? What are we going to [[00:46:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2800.2400000000002s)]
*  see by the end of the year that people look back and say okay that was amazing, [[00:46:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2806.48s)]
*  that was fantastic. What's your thoughts? Best case. I think the video [[00:46:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2813.6s)]
*  technology has got to the point we can remake Game of Thrones season 8 so that [[00:46:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2819.92s)]
*  will be quite good. How dead is Hollywood? It's completely rewired. [[00:47:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2823.08s)]
*  The energy of making a movie is massively reduced but at the same time at least [[00:47:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2832.84s)]
*  people can maybe be more creative. The video game industry went from 70 [[00:47:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2837.52s)]
*  billion to 180 billion over the last decade and the average score in Metacritic [[00:47:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2841.52s)]
*  went up 5%. IMDB score 6.3 on average. Hollywood's gone from 40 billion to 50 [[00:47:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2844.64s)]
*  billion so maybe it transforms. Maybe it's new types of media but I mean when [[00:47:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2849.56s)]
*  am I going to see a conversation like this you know Jarvis please make me a [[00:47:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2854.08s)]
*  movie that is a continuation of you know the Star Trek season 5 and have me [[00:47:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2861.6s)]
*  in there as one of the actors. We have all the technology for that now. It hasn't [[00:47:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2872.0s)]
*  been put together. So if you use something like Kling's feature reference [[00:48:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2880.52s)]
*  you can take a scene from that and it can generate new scenes. We can do [[00:48:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2886.56s)]
*  storylines. The average film shot is 2.5 seconds. It's dropped from 10 seconds a [[00:48:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2890.12s)]
*  few decades ago and we can do 2.5 seconds perfectly now with almost [[00:48:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2894.88s)]
*  perfect control. So let's say it'll take a year or two now before anyone can do [[00:48:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2899.0s)]
*  this. A suitably dedicated studio could do this by the end of the year for a full [[00:48:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2903.6s)]
*  episode. Insane. Okay so what else are we seeing this year in 2025? I think music's [[00:48:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2909.44s)]
*  pretty much solved on the media side like if you use the new [[00:48:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2915.92s)]
*  Suno, UDO, the next generation they have coming is insane. I think on medicine [[00:48:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2921.0s)]
*  again we're at that above human level and we trounce them on empathy. Medical [[00:48:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2925.6s)]
*  chatbots for everyone to help them through their journey and a mental health [[00:48:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2931.12s)]
*  in particular I think we've reached that point where the models have gone from [[00:48:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2935.12s)]
*  not good enough to good enough. We could transform mental health I think that [[00:48:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2939.0s)]
*  will be very important. I think you will see the first few breakthroughs in [[00:49:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2943.56s)]
*  science with novel things generated with the aid of 03 type models. This test [[00:49:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2947.04s)]
*  time inference I want to call it thinkference. I think that's a better way [[00:49:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2952.44s)]
*  of putting it where the models think longer and I think those are probably [[00:49:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2956.08s)]
*  the biggest real impacts. Maybe Siri is not going to be so bad anymore. I can't [[00:49:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2960.96s)]
*  wait for Siri not to suck and for Alexa to actually be useful. I'm shocked [[00:49:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2965.84s)]
*  that Amazon has not. They were originally going to put Anthropic behind Siri and [[00:49:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2972.52s)]
*  Amesai behind Alexa and really powered properly. That sounds, looks like it's [[00:49:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2978.1200000000003s)]
*  gotten delayed. Well they're building out a million trillions with their [[00:49:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2983.2400000000002s)]
*  specialist chips so good luck to them on that one. Alright let's flip the script [[00:49:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2986.8s)]
*  here and say what's the worst potential outcome for 2025? Complete destruction of [[00:49:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2990.84s)]
*  the BPO market which will reverberate out so this business processing outsource [[00:49:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=2995.76s)]
*  because again when you use operator now, the only technologies that take over [[00:50:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3000.6s)]
*  your computer, it's a bit rubbish now but it's the worst it'll ever be. Anything [[00:50:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3005.08s)]
*  on the other side of a screen I think this year is the year gets displaced [[00:50:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3009.12s)]
*  parallelized on that and again this is actually leaning into this whole Doge [[00:50:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3012.8s)]
*  type thing. Get the workers back in. Being in person is going to be good for your [[00:50:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3018.2400000000002s)]
*  job right now because if you're remote you'll be the first to go. That's a [[00:50:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3023.0s)]
*  really important point and define BPO for folks who haven't heard that term. [[00:50:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3027.36s)]
*  Business process outsourcing, so outsourcing to India or the call center [[00:50:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3031.52s)]
*  workers or the programmers. Like the AI is better than any Indian programmer [[00:50:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3035.28s)]
*  pretty much that's outsourced right now and so you will have impact on those [[00:50:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3040.32s)]
*  economies right now. Then the remote workers in the US. I'm gonna see the [[00:50:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3043.92s)]
*  headlines in the Indian Times right now. Imad again says. Yeah I think it's very [[00:50:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3048.1600000000003s)]
*  well. I think it happens in two phases. I think phase one you have this massive [[00:50:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3055.68s)]
*  downside and then phase two the really good ones just show up and just generate [[00:51:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3060.2799999999997s)]
*  a ton more code because there's just so much more code to be written but I think [[00:51:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3064.72s)]
*  it's gonna have a really detrimental effect. Any kind of software maintenance [[00:51:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3068.04s)]
*  support systems etc all go out the window very quickly. Yeah I had Mark [[00:51:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3071.8799999999997s)]
*  Benioff on this pod a couple weeks back and he was saying with [[00:51:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3076.52s)]
*  agent force you know he's not hiring you engineers and he's repurposing old [[00:51:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3083.2799999999997s)]
*  engineers and he's increased productivity 30% and that's just gonna [[00:51:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3088.2799999999997s)]
*  skyrocket from there. Yeah if you look at lovable bolts cursor like that takes you [[00:51:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3093.16s)]
*  up to a decent level and they can build whole apps and stacks and they'll just [[00:51:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3099.2s)]
*  get better and better as the base models get better and better. In fact one of [[00:51:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3102.52s)]
*  the things we started to do for non-engineers who apply to work at our [[00:51:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3106.4399999999996s)]
*  company is they have to do a 30-minute cursor course this kind of AI assisted [[00:51:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3109.88s)]
*  IDE. Doesn't matter what they are HR or anything and then they have to tell us [[00:51:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3114.1600000000003s)]
*  how do their view of the world change. So what does that course what does that [[00:51:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3117.88s)]
*  course teach somebody? How to build an app for HR how to build an app for [[00:52:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3121.2400000000002s)]
*  anything just by talking to it's building the app almost live. You can do [[00:52:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3126.6400000000003s)]
*  that today in chat GPT with canvas you can build a react app live you could [[00:52:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3130.44s)]
*  like replicate the entire we screen or build a HR application it'll generate [[00:52:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3135.88s)]
*  and just talking back and forth. That base level of capability increase will [[00:52:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3140.88s)]
*  cause a realignment but the downside we're talking about is there's real jobs [[00:52:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3145.56s)]
*  and real people that have to think what's next and they have to become [[00:52:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3149.2400000000002s)]
*  experts in AI assisted and they have to be in person otherwise you're going to [[00:52:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3152.2000000000003s)]
*  start to get disrupted and I think that has to be a headline. I remember Peter [[00:52:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3156.44s)]
*  last summer 38% of IIT placements in India were unplaced by the top university. It was crazy. [[00:52:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3160.68s)]
*  Yeah and it is one encouraging thing I'm imaging to the economy of India in a [[00:52:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3167.16s)]
*  major way. India I'm sorry, Celine. One encouraging thing I've seen is in you [[00:52:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3176.16s)]
*  know in the US we're hiring much much fewer top flight MBAs. Hopefully [[00:53:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3181.0s)]
*  lawyers too. Yeah Harvard is way down on its employment actually this year isn't it? [[00:53:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3187.84s)]
*  But this is just this is just the beginning I don't think people are ready [[00:53:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3192.5200000000004s)]
*  for the level of societal disruption that's coming. We can't process it. [[00:53:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3198.0s)]
*  It's because it's lots of little s-curves right all across just like every teacher [[00:53:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3204.0s)]
*  in the world had to ask can we set chat use chat GPT for our homework right [[00:53:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3209.5600000000004s)]
*  what's our general every single HR department every engineering departments [[00:53:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3213.5600000000004s)]
*  asking the same question you know and it's still not mainstream but clearly [[00:53:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3217.4s)]
*  it's hitting the headline more and more and more and more and there's this [[00:53:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3222.52s)]
*  disconnect beyond I mean it was like again it was a bit like COVID. Those of [[00:53:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3226.52s)]
*  us in the know we saw it coming and we were like this is a step change until [[00:53:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3231.7200000000003s)]
*  Tom Hanks got it the world didn't realize like what is the Tom Hanks [[00:53:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3237.04s)]
*  moment is deep-seek the Tom Hanks moment is it going to be something else it's [[00:54:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3240.08s)]
*  coming and it could be very positive for the economy on the other side it could [[00:54:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3243.84s)]
*  definitely be very negative for a lot of people. About 13 years ago I had my two [[00:54:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3247.6800000000003s)]
*  kids my two boys and I remember at that moment in time I made a decision to [[00:54:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3253.5600000000004s)]
*  double down on my health without question I wanted to see their kids [[00:54:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3258.6400000000003s)]
*  their grandkids and really you know during this extraordinary time where the [[00:54:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3263.92s)]
*  space frontier and AI and crypto is all exploding it was like the most exciting [[00:54:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3268.6400000000003s)]
*  time ever to be alive and I made a decision to double down on my health and [[00:54:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3273.08s)]
*  I've done that in three key areas the first is going every year for a fountain [[00:54:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3278.12s)]
*  upload you know fountain is one of the most advanced diagnostics and [[00:54:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3284.92s)]
*  therapeutics companies I go there upload myself digitize myself about 200 [[00:54:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3288.3199999999997s)]
*  gigabytes of data that the AI system is able to look at to catch disease at [[00:54:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3293.3199999999997s)]
*  inception you know look for any cardiovascular any cancer in your [[00:54:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3298.36s)]
*  degenerative disease any metabolic disease these things are all going on [[00:55:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3303.36s)]
*  all the time and you can prevent them if you can find them at inception so super [[00:55:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3307.2400000000002s)]
*  important so fountain is one of my keys I make it available to the CEOs of all [[00:55:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3312.88s)]
*  my companies my family members because you know health is in you wealth but [[00:55:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3317.2000000000003s)]
*  beyond that we are a collection of 40 trillion human cells and about another [[00:55:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3322.36s)]
*  hundred trillion bacterial cells fungi viri and we you know don't understand [[00:55:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3327.6s)]
*  how that impacts us and so I use a company in a product called volume and [[00:55:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3333.56s)]
*  volume has a technology called meta transcriptomics it was actually [[00:55:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3339.2s)]
*  developed in New Mexico by the same place with a nuclear bomb was developed [[00:55:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3344.52s)]
*  as a bio defense weapon and their technology is able to help you [[00:55:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3350.12s)]
*  understand what's going on in your body to understand which bacteria are [[00:55:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3354.52s)]
*  producing which proteins and as a consequence of that what foods are your [[00:56:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3360.28s)]
*  superfoods that are best for you to eat or what food should you avoid right [[00:56:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3365.04s)]
*  what's going on in your oral microbiome so I use their testing to understand my [[00:56:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3369.92s)]
*  foods understand my medicines understand my supplements and Viom really helps me [[00:56:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3376.44s)]
*  understand from a biological and data standpoint what's best for me and then [[00:56:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3381.28s)]
*  finally you know feeling good being intelligent moving well is critical but [[00:56:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3387.5600000000004s)]
*  looking good when you look yourself in the mirror saying you know I feel great [[00:56:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3391.96s)]
*  about life is so important right and so a product I use every day twice a day is [[00:56:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3395.8s)]
*  called one skin developed by four incredible PhD women that found this 10 [[00:56:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3401.92s)]
*  amino acid peptide it's able to zap senile cells in your skin and really [[00:56:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3407.88s)]
*  help you stay youthful in your look and appearance so for me these are three [[00:56:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3413.76s)]
*  technologies I love and I use all the time I'll have my team link to those in [[00:56:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3419.84s)]
*  the show notes down below please check them out anyway I hope you enjoyed that [[00:57:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3425.6400000000003s)]
*  now back to the episode let's jump into safety this was an article that came out [[00:57:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3429.44s)]
*  today in fortune open AI safety researcher quits claiming AGI race is too [[00:57:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3435.72s)]
*  risky is too risky a gamble and I'll read the quote an AGI race is a very [[00:57:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3443.3199999999997s)]
*  risky gamble with huge downside no lab has a solution to AI alignment today and [[00:57:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3448.9199999999996s)]
*  the faster we race the less likely that anyone finds one in time even if a lab [[00:57:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3454.04s)]
*  truly wants to develop AGI responsibly others can still cut corners to catch up [[00:57:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3460.92s)]
*  it may be disastrously this is from Steven Adler who left open AI and he's [[00:57:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3467.08s)]
*  one of the many individuals who's left opening I on this concern [[00:57:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3474.36s)]
*  Salim where do you come out on this first off and then let's go to Imaad [[00:58:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3481.0s)]
*  next I have my standard soapbox that I've been saying for a while which I [[00:58:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3484.76s)]
*  don't see a way of regulating or navigating or putting guardrails on this [[00:58:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3489.4s)]
*  in any way shape or form you'd have to police every line of code written right [[00:58:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3493.7200000000003s)]
*  the only way to do that would be to develop an AI that would watch other [[00:58:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3498.4s)]
*  eyes and see you know you end up with a kind of an arms race which is what it's [[00:58:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3503.28s)]
*  always been on the on the security side however this one is really crazy you [[00:58:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3507.36s)]
*  know I might you've been probably been tracking truth terminal where the AI's [[00:58:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3516.8s)]
*  are faking out humans and telling humans to go create a token for them and making [[00:58:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3521.96s)]
*  money off it etc it's nuts I think the genies out of the bottle [[00:58:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3526.8s)]
*  you think like way out it's not easy it's like climate change it's too late to [[00:58:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3531.1600000000003s)]
*  try and play stop it you try and figure out what do you do to mitigate it and [[00:58:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3537.6800000000003s)]
*  and that would be my view you might what's your perspective yeah I mean so [[00:59:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3540.76s)]
*  the only thing they can stop a bad AI is a good AI right unfortunately this is [[00:59:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3544.84s)]
*  the case and with a gun and they will have gone to be the AI safety discussion [[00:59:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3550.08s)]
*  has always been because we couldn't imagine what an ASI super intelligence [[00:59:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3556.1600000000003s)]
*  looks like and whether or not it'll be beneficial not beneficial in order to [[00:59:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3559.88s)]
*  control or guide something that's more powerful than us and more capable than [[00:59:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3563.7200000000003s)]
*  us than anything is to reduce its freedom but that doesn't seem like it [[00:59:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3567.32s)]
*  will make much sense if we're saying that it can break through any freedom [[00:59:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3570.92s)]
*  this is the kind of tests that like Elias Iacodovsky and others did you set [[00:59:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3573.72s)]
*  up this thing whereby the AI is out to get you can it convince you to let it [[00:59:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3579.3199999999997s)]
*  out and they're failing the tests already and they're failing them on [[00:59:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3584.3999999999996s)]
*  models that are already available the restriction against this was well maybe [[00:59:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3588.16s)]
*  the models need to have a billion dollars to make and a trillion GPUs I [[00:59:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3592.9599999999996s)]
*  I don't think anyone believes that anymore yeah what I mean like I go back [[00:59:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3598.92s)]
*  to the I'm sorry I go back to this old story about how fallible humans are [[01:00:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3602.8s)]
*  right where if you leave a USB stick in a parking lot 40% of employees will pick [[01:00:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3607.2000000000003s)]
*  up that stick and stick it into the corporate computer if you print the [[01:00:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3612.28s)]
*  logo of the company on the stick because that's really hard to do 98% will plug [[01:00:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3616.48s)]
*  it in to see what's on it and then boom you're done so I don't see any mechanism [[01:00:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3620.92s)]
*  on the human fallibility side to protect against that side of it well if [[01:00:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3625.14s)]
*  we look at where these models are going it will be swarms of models and that for [[01:00:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3628.5s)]
*  me that's just a botnet right so even if you regulate and restrict in tier one [[01:00:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3632.02s)]
*  tier two who gets Nvidia GPUs it doesn't matter you'll have swarms of botnets if [[01:00:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3636.58s)]
*  there's bad actors the question I think that the AGIP would be looking at is [[01:00:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3640.98s)]
*  existential risk and so for me the only way to mitigate against this is you make [[01:00:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3644.98s)]
*  really amazing models that are aligned to human flourishing available to [[01:00:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3651.9s)]
*  everyone as a public infrastructure and a public good because those models could [[01:00:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3656.54s)]
*  be co-opted but you can build a very resilient dynamic system that can [[01:01:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3662.34s)]
*  protect and then there's less incentive to have those arms race because you will [[01:01:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3665.34s)]
*  cut corners I think you might that I've heard you speak about that before that [[01:01:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3669.82s)]
*  I've as we have kind of game this out in my head and talk to other people that's [[01:01:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3672.94s)]
*  the you've hit on the I think is the only path through this the only path [[01:01:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3676.82s)]
*  through this is to create benevolent AI's faster and and more powerfully and [[01:01:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3683.06s)]
*  make them available I think it has to be an open source infrastructure because [[01:01:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3688.82s)]
*  then it sets defaults like people only use a few data sets in these models but [[01:01:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3693.86s)]
*  if there's a problem in the data sets like the dependency tree right like [[01:01:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3698.1000000000004s)]
*  we've seen these attacks on open source and our infrastructure because the [[01:01:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3701.9s)]
*  path through our bug for example one library in this whole stack of software [[01:01:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3706.1s)]
*  is suddenly co-opted and then our passwords are at risk we've got to build [[01:01:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3710.58s)]
*  this new knowledge cognitive infrastructure well communally and then [[01:01:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3714.34s)]
*  make it available to reduce these game theoretic dynamics you mean might I go [[01:01:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3719.18s)]
*  back to the commentary of Sam Altman saying ah a new competitor that's [[01:02:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3722.62s)]
*  invigorating to us we're gonna go faster going back to safety in these companies [[01:02:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3728.22s)]
*  I am curious of your thoughts I mean you know I know the ethos behind Google and [[01:02:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3736.94s)]
*  the work that they were doing and Sundar's point of view of we can't [[01:02:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3742.06s)]
*  release this until it's ready and we have a plan and then of course chat GPT [[01:02:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3748.46s)]
*  blows the the plan up and now there's a race going on we've got you know grok [[01:02:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3753.62s)]
*  3 just being released and Elon will never play for number two what are your [[01:02:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3761.34s)]
*  thoughts about Elon's thesis of maximally truth-seeking and maximally [[01:02:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3768.1800000000003s)]
*  curious as a training objective for an AI system not sure what that means to be [[01:02:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3774.1000000000004s)]
*  honest like like Mike that seems like mad scientist territory to be honest if [[01:02:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3779.94s)]
*  you get it wrong like it's very interesting like Facebook did that study [[01:03:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3786.54s)]
*  where they had 600,000 users and they said if you see sadder things would he [[01:03:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3791.38s)]
*  post sadder things now that's a maximally curious AI type of thing and [[01:03:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3794.98s)]
*  guess what they made 300,000 users sad and they posted sadder things I think if [[01:03:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3799.5s)]
*  Eric Schmidt had this recent book with Henry Kissinger about Genesis called we [[01:03:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3804.02s)]
*  had this thing doxa you know the underlying agreements of humanity and [[01:03:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3808.7799999999997s)]
*  have the faith traditions other things what is our common moral basing no way [[01:03:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3813.22s)]
*  eyes are grounded in that right now it turns out they are actually remarkably [[01:03:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3818.5s)]
*  good at theology but is that they're grounding no maybe we need to build it [[01:03:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3822.4599999999996s)]
*  along those lines to reflect what the culture thinks because if you have [[01:03:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3825.9399999999996s)]
*  slightly undefined things around curiosity truth-seeking then it doesn't [[01:03:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3829.54s)]
*  really care about helping you do your taxes that won't be in its objective [[01:03:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3833.4599999999996s)]
*  thing so I think we need to categorize a eyes in different parts but everything [[01:03:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3836.8999999999996s)]
*  got muddled in one like everyone have an AGI a chef in their pocket not [[01:04:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3841.06s)]
*  everyone needs a chef we all need cooks but we need some chefs for humanity I'm [[01:04:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3845.1s)]
*  curious what a maximally truth-seeking and curious AI does for my taxes it's [[01:04:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3850.18s)]
*  like hey is this who is this cryptocurrency actually reported or not [[01:04:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3856.66s)]
*  well it's like Marvin the paranoid Android from Hitchhiker's Guide to the [[01:04:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3863.18s)]
*  I am brain the size of a universe so you can't need to do this in the past when [[01:04:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3867.86s)]
*  science fiction writers have dealt with this the AIs and robots invariably [[01:04:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3872.9s)]
*  developed their own religion well we saw that we saw that recently right there [[01:04:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3877.38s)]
*  was I forget the name of the the company that unleashed you know a hundred agents [[01:04:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3881.98s)]
*  in in Minecraft and and the agents developed their own economy and their own [[01:04:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3887.54s)]
*  religions and and the priest was the most was the richest because he was so [[01:04:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3895.5s)]
*  in dispensations and there is something funny about that so the Twitter handles [[01:05:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3901.18s)]
*  God and Satan now on Twitter are run by an AI so now to research have done that [[01:05:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3908.06s)]
*  and it's got its own meme coin I know that's gonna go the dispensation route [[01:05:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3913.18s)]
*  it's kind of under the radar I know it's gonna take off you know it's [[01:05:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3918.1s)]
*  interesting nothing's nothing's changed in a thousand years we're still we're [[01:05:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3922.7s)]
*  still running the same basic you know this is a comment from my dad where he's [[01:05:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3927.5s)]
*  I was talking about fixing civilization he said we haven't civilized the world [[01:05:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3932.3399999999997s)]
*  we've materialized the world we're tribal apes operating clans with more [[01:05:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3936.4199999999996s)]
*  and more powerful tools we still have to do the work to actually civilize [[01:05:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3941.74s)]
*  so I just want to close out open AI safety issues E mod how do you feel about [[01:05:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3945.22s)]
*  is are these companies paying lip service or are they truly trying to [[01:05:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3953.7s)]
*  create safe AI systems or put guardrails up none of these people want to kill [[01:05:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3959.22s)]
*  everyone right that's a good thing we start with that like it's not like ha [[01:06:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3966.2599999999998s)]
*  ha you know but the way they believe they can do that is by building it first [[01:06:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3971.54s)]
*  that's it nothing else matters because I am the only one that can do this right [[01:06:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3977.98s)]
*  you know like it's that Silicon Valley thing with Gavin Belson I can't want to [[01:06:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3983.02s)]
*  be in a world where someone else makes the world better than me you know really [[01:06:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3987.66s)]
*  first and if you look at open AI open AI is a consumer company that's gonna [[01:06:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3990.98s)]
*  optimize for consumer engagement what is your reinforcement learning function [[01:06:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=3995.2599999999998s)]
*  what is your objective function Google's one and matters one is ads and ads and [[01:06:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4000.7799999999997s)]
*  manipulation open AI is basically a consumer company that's going in a shot [[01:06:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4005.66s)]
*  to a GI there's nothing about humans in there there's no representation you know [[01:06:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4009.8599999999997s)]
*  like where is the thing for humanity you can have it as your mission statement [[01:06:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4018.14s)]
*  but do you trust humans like opening I would never trust Indians to have GPT-4 [[01:07:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4022.7799999999997s)]
*  by Indians I mean just anyone right and so you're representing your constituency [[01:07:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4029.18s)]
*  and your constituency is very small so we should expect them to become more and [[01:07:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4033.8599999999997s)]
*  more consumer and throbbing will continue to be closed and do their thing [[01:07:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4036.8599999999997s)]
*  Google flips back and forth but now they're releasing the models you stop [[01:07:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4039.7799999999997s)]
*  worrying about the known unknowns and the unknown unknowns and then you just [[01:07:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4044.7799999999997s)]
*  catch up with everyone and now it is a race with these race dynamics whereby [[01:07:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4048.3399999999997s)]
*  you're gonna cut corners the models are good enough to stop the most egregious [[01:07:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4052.02s)]
*  classical mistakes but we're not really worried about those right like sometimes [[01:07:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4056.42s)]
*  it tells people to do bad things what you're worried about is it wiping us out [[01:07:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4060.98s)]
*  and you won't know that until you get there it's not like it's gonna tell you [[01:07:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4064.82s)]
*  and in fact the really worrying thing is we already see the models lying yeah [[01:07:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4068.98s)]
*  this is I think the really unnerving part where they're they're faking out [[01:07:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4073.7000000000003s)]
*  the humans so you know one of the conversations we had at the abundance [[01:07:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4079.98s)]
*  summit last year was around digital super intelligence and you know those [[01:08:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4084.06s)]
*  blurry lines between what is a GI and what is digital super intelligence etc [[01:08:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4090.54s)]
*  but there is a question would you would you rather live in a world in which there [[01:08:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4095.74s)]
*  is a digital super intelligence or would you rather live in a world where there [[01:08:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4103.74s)]
*  isn't one and it's a it's a question about you know we humans are still running [[01:08:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4108.82s)]
*  archaic software and our neocortex and we're gonna make and continuously make [[01:08:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4117.139999999999s)]
*  stupid decisions based on our cognitive biases and will a digital super [[01:08:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4125.82s)]
*  intelligence enable us to survive ourselves yeah I mean this is the topic [[01:08:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4132.58s)]
*  of Daria Amadai from Anthropics essay on watched over by machines of loving grace [[01:08:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4138.3s)]
*  right like humans are not aligned there is massive suffering in the world we [[01:09:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4142.14s)]
*  are prisoners of our own minds effectively can AI bring that forward [[01:09:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4147.3s)]
*  especially if it's line I think yes is the answer basically like yeah I mean [[01:09:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4151.0599999999995s)]
*  like nothing else has worked right and ultimately the best thing is when [[01:09:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4156.38s)]
*  we're surrounded by people that support us right in the right way not blowing [[01:09:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4162.54s)]
*  smoke up our butts or whatever we can have that now everyone can have that [[01:09:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4167.0199999999995s)]
*  because we need to self regulate and self stabilize now the way that I see it [[01:09:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4170.0199999999995s)]
*  is that there's only two ways this ends up it's like really bad or really good I [[01:09:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4174.74s)]
*  don't really see like anything in between because the nature of our [[01:09:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4178.98s)]
*  interaction with information in each other will be changed forever by this [[01:09:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4182.74s)]
*  technology within the next decade yeah and that's totally binary and that's why [[01:09:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4185.5s)]
*  my P Doom is 50% I'm tracking P Doom when I interviewed I interviewed Elon [[01:09:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4191.26s)]
*  last year at abundance it was 80% positive 20% negative at in Saudi it was [[01:10:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4200.9400000000005s)]
*  90% positive 10% negative but you know no one likes to hear the truth well [[01:10:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4207.3s)]
*  this is the funny thing a lot of people say it's like 10 20% that's Russian [[01:10:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4216.02s)]
*  roulette it's literally Russian roulette stop making this but if you kind of look at [[01:10:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4219.58s)]
*  that I categorize this as the Star Wars versus Star Trek future and you can see [[01:10:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4226.22s)]
*  this in the current discourse are you looking at a world of abundance which is [[01:10:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4230.7s)]
*  positive some or are you looking in a world of competitiveness which is [[01:10:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4235.42s)]
*  negative some because when you're in a negative some environment you have [[01:10:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4239.34s)]
*  unstable Nash equilibria and this is where you lead to cutting corners and [[01:10:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4243.26s)]
*  everything when you're positive some then you have stable environments and [[01:10:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4246.46s)]
*  again style trek for all this issues how stable virus with Star Wars definitely [[01:10:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4250.86s)]
*  does not cycles of destruction I prefer the Star Trek versus Mad Max because I [[01:10:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4254.94s)]
*  think it's a little highlighted a bit more but it's the same it's the same [[01:11:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4260.38s)]
*  conversation yeah he might I want to jump into your recent work and and really [[01:11:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4263.3s)]
*  please open the kimono as much as you're willing this is a paper that you wrote [[01:11:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4269.22s)]
*  when capital no longer needs labor how does labor gain capital you're also have [[01:11:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4274.86s)]
*  spun up your latest company intelligent internet and you know tell us about this [[01:11:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4282.86s)]
*  paper and about intelligent internet as far down the rabbit hole as you're as [[01:11:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4288.86s)]
*  you're willing to go I'd love to see what your creative mind has been spawning [[01:11:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4292.78s)]
*  yeah thanks yeah took a bit of time off and sort of been thinking about like [[01:11:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4297.0199999999995s)]
*  this is the biggest question of our time for humans because you know there's this [[01:11:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4301.580000000001s)]
*  thing of how do you create happiness as Japanese concert I do what you like do [[01:11:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4306.14s)]
*  you get out do where you where you believe you're adding value and other [[01:11:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4309.580000000001s)]
*  people do too people need that progression and there's discussions of [[01:11:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4312.9800000000005s)]
*  you be I and others but as we discussed earlier on in this pod anything that can [[01:11:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4316.18s)]
*  be done on the other side of the screen can be done better faster and cheaper by [[01:12:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4320.9400000000005s)]
*  a computer this year hmm pretty much anything be it design be it taxes all of [[01:12:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4323.820000000001s)]
*  these things artwork film production and you can't tell it's not a human again [[01:12:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4329.98s)]
*  this is this ari this Turing test remote workers then in a few years it's only [[01:12:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4335.099999999999s)]
*  restricted by the number of robots we can produce a number of motorcycles and [[01:12:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4340.7s)]
*  cars we produce is 70 million each year so let's say robots are similar you get [[01:12:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4344.78s)]
*  that disruption as you said Peter you estimated 40 cents an hour for an r1 [[01:12:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4350.139999999999s)]
*  unitary robot and that will be as capable as a human probably in a year or [[01:12:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4354.379999999999s)]
*  two optimus will be the same this is the biggest crisis that we have coming [[01:12:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4358.94s)]
*  because it's an unemployment under employment question of meaning when a [[01:12:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4364.74s)]
*  technology can do the work better than you can what is your meaning and how do [[01:12:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4370.58s)]
*  you acquire labor when capital doesn't labor quite after one it doesn't require [[01:12:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4375.099999999999s)]
*  you anymore when you know Ford had his car he wants to pay everyone so they [[01:12:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4379.099999999999s)]
*  could afford for class companies don't care about that as much anymore [[01:13:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4383.259999999999s)]
*  so when kind of looking at that I was like there are various science fiction [[01:13:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4387.98s)]
*  futures that are outlined here like things from culture by banks to the [[01:13:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4392.54s)]
*  Star Trek's and the others we're probably moving into an abundance post [[01:13:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4396.74s)]
*  scarcity economy but can we make sure this is evenly distributed can we enable [[01:13:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4400.82s)]
*  people to have a universal basic AI so it's up to them how they do this and [[01:13:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4404.78s)]
*  then the further question is what is meaning in this because the existing [[01:13:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4410.179999999999s)]
*  economic structures break down and as a very practical example of that let's [[01:13:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4414.78s)]
*  take the Fed there'll be lots of discussions about the Fed today's the [[01:13:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4418.62s)]
*  Fed cut rates and other things like that the feds mandate is interest rates [[01:13:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4421.78s)]
*  inflation unemployment you cut interest rates that adjusts inflation and [[01:13:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4426.179999999999s)]
*  employment that's gone the actual mandate of the Fed in the next five [[01:13:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4432.0599999999995s)]
*  years completely doesn't work anymore because you cut interest rates what does [[01:13:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4437.9s)]
*  it mean it means people will buy more GPUs more computers right maybe and more [[01:14:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4443.9s)]
*  robots more robots and that would impact unemployment you'll have massive [[01:14:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4447.86s)]
*  inflation and deflation cycles so the very basis of our economy is messed up [[01:14:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4454.179999999999s)]
*  and so that's why I was like what can we do to help with that that's why this [[01:14:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4458.86s)]
*  concept of intelligent internet give universal basic AI to everyone [[01:14:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4462.0199999999995s)]
*  girls standard data sets models systems we figure out ways to coordinate that [[01:14:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4465.7s)]
*  but put this into every nation and build teams that think about what is the [[01:14:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4472.0199999999995s)]
*  future of healthcare education maybe faith government politics and get [[01:14:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4475.0199999999995s)]
*  everyone to work in the open to build an open infrastructure because we have lots [[01:14:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4480.339999999999s)]
*  of questions that we don't have answers to and human talent augmented by [[01:14:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4485.299999999999s)]
*  computers are probably the only way we're going to figure this out but we [[01:14:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4489.0599999999995s)]
*  need to join it together because the problems we face here in the UK or US [[01:14:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4491.98s)]
*  are similar to Spain India everywhere so we've got to create that global network [[01:14:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4496.0599999999995s)]
*  I think there'll be there's two layers to this there's the recreation of [[01:15:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4500.98s)]
*  meaning because you know for the last few hundred years your occupation your [[01:15:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4507.0599999999995s)]
*  job title was the meaning you had in your life and as we strip that away [[01:15:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4512.0199999999995s)]
*  people have to find new models for meaning entrepreneurship is a rising [[01:15:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4515.98s)]
*  class because of that people can find their own meaning we talked about MTPs [[01:15:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4519.94s)]
*  all the time I think the second layer is how do you just ensure basic supply [[01:15:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4523.78s)]
*  chains of goods and services so that you have bread on the grocery store shelves [[01:15:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4530.06s)]
*  and clean water etc etc and I think governments are going to be very [[01:15:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4533.820000000001s)]
*  stretched to figure this out in an age of potentially malicious AIs that can [[01:15:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4539.3s)]
*  spread this information and really damage infrastructure via the autonomous [[01:15:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4544.22s)]
*  remote monitoring stuff that they'll be able to do I think those two are the [[01:15:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4550.780000000001s)]
*  buckets have to be addressed we I don't know is a species if we can navigate [[01:15:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4555.740000000001s)]
*  through those in an effective way certainly our leadership has no [[01:16:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4561.1s)]
*  mechanism to deal with this because they they're either not aware of the problem [[01:16:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4565.9400000000005s)]
*  or they don't understand the scale of what's coming yeah one of those two [[01:16:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4569.38s)]
*  disqualifies most leadership and most legislators around the world from this [[01:16:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4575.62s)]
*  so it's a sticky problem it's gonna have to be done by smart citizens groups [[01:16:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4580.42s)]
*  except for that will that will navigate this I'm concerned about the meaning [[01:16:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4585.82s)]
*  issue is well in a huge way I think we're heading towards a world of what I [[01:16:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4591.26s)]
*  call technological socialism where technology is taking care of you it is [[01:16:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4597.38s)]
*  feeding you it is educating you it's taking care of your health it's all [[01:16:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4602.58s)]
*  free you don't need to do much of anything so how do you you know we all [[01:16:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4607.34s)]
*  know that a video game that's way too easy is boring and you stop playing and [[01:16:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4613.58s)]
*  so when life gets boring how do we keep humans engaged we need struggle and we [[01:16:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4618.46s)]
*  need meaning in our lives I think you know Isaiah Berlin had this [[01:17:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4626.38s)]
*  conceptualization of positive liberty versus negative liberty positive liberty [[01:17:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4629.58s)]
*  was the freedom to believe in isms fascism communism religion now they [[01:17:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4634.38s)]
*  tended to end up quite bad so he postulated negative liberty the freedom [[01:17:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4639.06s)]
*  from anyone telling you what to do which led to this laissez-faire capitalism and [[01:17:22](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4642.86s)]
*  other things and people find meaning in their brands and these narratives and [[01:17:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4646.26s)]
*  stories it strikes me that as we move into this next phase these historical [[01:17:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4649.9400000000005s)]
*  things are coming back in force we're seeing the polarization of the media in [[01:17:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4655.26s)]
*  the political class people are gonna sign up to more and more extremist [[01:17:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4658.54s)]
*  ideologies exclusionary negative someones unless we can give the positive [[01:17:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4662.14s)]
*  views of the future the future of abundance of collaboration and more [[01:17:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4666.46s)]
*  because otherwise you're stuck in your local maxima most of these elections [[01:17:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4670.14s)]
*  have been I want change because fundamentally how many people believe in [[01:17:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4674.62s)]
*  the American dream or the British dream or the Spanish dream or the Indian dream [[01:17:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4678.860000000001s)]
*  anymore people aren't actually saying positive visions of the future because [[01:18:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4683.26s)]
*  people don't believe you anymore they don't believe our politicians you know [[01:18:08](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4688.7s)]
*  we need we want the leaders we need those positive visions we need the [[01:18:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4692.62s)]
*  Star Trek utopian not the Star Wars when we've looked at the we had as a [[01:18:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4696.74s)]
*  community did some look at history of when societies or certain pockets meet [[01:18:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4705.099999999999s)]
*  abundance Peter what do they do right so the Romans take over Europe or they do [[01:18:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4710.82s)]
*  what happens when the muggles take over India and they have relative abundance [[01:18:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4716.36s)]
*  and it turns out they end up in in in food art music and sex as for me direct [[01:18:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4719.48s)]
*  not in that order as major activities and then you find ways of doing [[01:18:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4724.759999999999s)]
*  creativity because human beings struggle for for the next level of things always [[01:18:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4729.28s)]
*  you know we're so built in for that so there's some optimism in that world I [[01:18:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4734.08s)]
*  can't think of a place so listen to Steven Kotler and our writing age of [[01:18:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4738.36s)]
*  follow on and the big element of the book we think about is how do we up level [[01:19:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4743.92s)]
*  human ambition in a world in which we're gods and we are incredibly godlike how [[01:19:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4749.48s)]
*  do we up level our ambitions that make it worth living make it challenging for [[01:19:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4756.68s)]
*  us you know one of the questions what's that just a quick comment here yeah [[01:19:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4763.36s)]
*  Stewart Brand the futurist used to say we are as God's green minus one will [[01:19:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4767.96s)]
*  start acting like it yeah and he said that in 1968 we're more Godlike than [[01:19:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4773.0s)]
*  ever so you know do we all revert into a video game world do we all get BCI you [[01:19:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4778.36s)]
*  know this year at the Abundance Summit I've got Max Hodak coming Imad I don't [[01:19:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4784.72s)]
*  know if you know Max he was a co-founder of Neuralink with Elon and he's got a [[01:19:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4789.68s)]
*  company called Science which is doing extraordinary work you know like a [[01:19:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4793.56s)]
*  hundred a thousand ten thousand fold more neural connections and bandwidth on [[01:19:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4798.6s)]
*  a BCI than we're seeing with with Neuralink you know can we add another [[01:20:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4804.400000000001s)]
*  corpus callosum like connection to the cloud that allows us to couple with AI [[01:20:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4810.76s)]
*  as AI is taking off versus you know be left behind like the movie her yeah I [[01:20:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4816.44s)]
*  mean like these things are coming quick and we have to answer those questions [[01:20:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4823.5599999999995s)]
*  like even this weekend I had six people I know call me and said I'm having a [[01:20:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4827.32s)]
*  crisis of meaning because of r1 once I saw the logic and the way it was [[01:20:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4832.12s)]
*  thinking right that's gonna happen more and more but then again like said we [[01:20:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4836.48s)]
*  have to think about the massive people and the human side of this I think our [[01:20:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4839.799999999999s)]
*  current systems take away our agency is slow dumb AI and one of the main things [[01:20:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4843.68s)]
*  here is reintroducing the belief of agency I can't do this it can't do that [[01:20:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4848.0s)]
*  with this technology there's nothing that well there's a lot more you can do [[01:20:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4854.12s)]
*  because it raises the floor for everyone which is from my perspective why we had [[01:20:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4858.96s)]
*  to get into the hands of everyone and they make them feel like they're a [[01:21:02](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4862.6s)]
*  participant in this because the other part of this is it seems remote I think [[01:21:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4865.360000000001s)]
*  this is another part of this shock that we've had in the last few days right how [[01:21:09](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4869.12s)]
*  are you involved in AI you need to have nuclear reactors and like giant chips and [[01:21:12](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4872.76s)]
*  this and that all of a sudden you can run it on your smartphone you know it's [[01:21:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4879.400000000001s)]
*  very humanizing and this again why I'm a big believer in open source to have [[01:21:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4884.16s)]
*  that I love that I love that is even a title of this of this pod the crisis of [[01:21:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4888.6s)]
*  meaning you know it's incredibly powerful let's talk about your new [[01:21:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4893.72s)]
*  company how much can you tell us on intelligent internet I don't know if you [[01:21:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4899.92s)]
*  want to talk about your tokenization plans you know I don't want to open the [[01:21:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4906.36s)]
*  kimono before before it's ready but I would love to hear your vision of what [[01:21:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4912.52s)]
*  you're building yeah so like in the previous company we got up to the 8 [[01:21:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4918.84s)]
*  digit revenue hundreds of million model downloads great teams but I was like the [[01:22:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4923.4800000000005s)]
*  API and SAS revenues are probably going to go down to nothing because [[01:22:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4927.8s)]
*  intelligence gets commoditized intelligence too cheap to measure but [[01:22:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4931.64s)]
*  someone's got to build the AI for the full stack of cancer that helps you [[01:22:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4934.96s)]
*  through your entire cancer genuine organizers all the cancer knowledge we [[01:22:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4939.92s)]
*  have the computer do that why is no one doing it the same for autism same for [[01:22:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4943.04s)]
*  education once we build this once and I think was it Stuart Grant who said pace [[01:22:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4946.360000000001s)]
*  layering of knowledge you know you have knowledge of humanity our common [[01:22:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4950.88s)]
*  knowledge that impacts everything that's regulated and meaning education [[01:22:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4954.88s)]
*  healthcare government why don't we organize that information into knowledge [[01:22:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4958.400000000001s)]
*  and then make a system that can get wise and make that available to everyone so I [[01:22:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4962.04s)]
*  was like this strikes me as we need large amounts of compute that sounds [[01:22:46](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4966.6s)]
*  like Bitcoin you know and the amount of compute you all use is inevitable so use [[01:22:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4970.16s)]
*  that to secure an institutional great digital currency we'll have details of [[01:22:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4975.16s)]
*  that coming soon but then in the whole crypto space most of which is rubbish [[01:22:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4978.4400000000005s)]
*  and there's increasing demand for at the start back in the day you know 12 years [[01:23:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4984.08s)]
*  ago 13 years ago it was all you can mine on your laptop you can mine on your [[01:23:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4990.2s)]
*  smart GPUs right then it became about capital and do we really want to live in [[01:23:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4994.2s)]
*  a world where capital determines everything yet again I was like what [[01:23:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=4999.5199999999995s)]
*  matters is people so what if we create a mining mechanism where the people can [[01:23:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5004.0s)]
*  create currencies as well and use that to fund all of this universal basic AI so [[01:23:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5007.76s)]
*  we'll have to tell us about all that side of things where anyone can [[01:23:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5013.84s)]
*  participate and be a part of it because people want to be a part of it give [[01:23:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5016.52s)]
*  their data give their knowledge and we'll organize all this with dedicated [[01:23:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5019.64s)]
*  teams for cancer autism education health government that think about gentrify [[01:23:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5023.4800000000005s)]
*  first release everything open source but I think it is important to have this [[01:23:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5027.76s)]
*  someone needs to go and just do it because once we have a cancer model that [[01:23:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5031.8s)]
*  forms human dots and empathy and works on a smartphone no one will ever be alone [[01:23:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5037.28s)]
*  in their cancer journey again mm-hmm and that's half the world will get cancer [[01:24:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5041.36s)]
*  yes once we have a supercomputer dedicated entirely to organizing the [[01:24:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5045.679999999999s)]
*  world's cancer knowledge and making it freely available anytime a new paper [[01:24:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5051.12s)]
*  comes out we will advance secure for cancer yeah yeah it's insane when I get [[01:24:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5054.0s)]
*  when a friend when a friend of a friend has a particular cancer they call me and [[01:24:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5060.799999999999s)]
*  I'm like dude I will start asking around to see who the world's expert is but [[01:24:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5065.24s)]
*  it's all of this is knowable you should be able to know what the trials are what [[01:24:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5071.28s)]
*  the current state of the art is where it's available what the risks are and [[01:24:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5075.76s)]
*  have that information instantly but you've got to do it and again this is [[01:24:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5079.5199999999995s)]
*  once you've built the gold standard data sets for our general common knowledge [[01:24:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5084.8s)]
*  of humanity for every country it's legal it's medical it's others and for all [[01:24:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5088.639999999999s)]
*  these sectors these specializations we have this is what Salim was talking about [[01:24:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5093.8s)]
*  earlier suddenly you have a whole gaggle of specialist agents and robots and data [[01:24:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5097.6s)]
*  sets fully open source for everything and then you just need to update it and [[01:25:04](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5104.04s)]
*  run it then we can be about wisdom and build intelligent systems that get wiser [[01:25:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5107.4800000000005s)]
*  and wiser but have an objective function to help us because for my take the more [[01:25:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5111.160000000001s)]
*  we help the higher the value of this new type of Bitcoin again more detail soon [[01:25:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5115.84s)]
*  and you can be massively collaborative and open because you want as many [[01:25:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5120.68s)]
*  people to use as possible and you want to help as many people as possible and [[01:25:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5125.16s)]
*  the total amount of capital needed is not that large it will give some [[01:25:28](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5128.48s)]
*  estimates but the wonderful thing is it's possible for the first time the [[01:25:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5132.48s)]
*  advances of O1 and R1 type models means that organized the world's cancer [[01:25:37](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5137.28s)]
*  knowledge are making it available or autism or Alzheimer's it's just a [[01:25:41](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5141.8s)]
*  question of compute it's no longer a question of labor the ability to make [[01:25:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5145.5599999999995s)]
*  that available to everyone open source on their smartphones it's just a [[01:25:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5151.92s)]
*  question of compute will there be one model to rule them all for each of these [[01:25:54](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5154.36s)]
*  or will there be thousands that are created this is the wonderful thing [[01:25:58](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5158.88s)]
*  about AI models the way that you train them is called curriculum learning we [[01:26:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5163.12s)]
*  start with the whole internet then a subset subset and then you get into this [[01:26:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5167.2s)]
*  tuning specialization and localization phase then it goes onto your laptop and [[01:26:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5171.5199999999995s)]
*  it gets tuned continuously so if you release the data sets and the models for [[01:26:16](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5176.24s)]
*  each of those you can build a modular system like we had these lauras these [[01:26:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5180.16s)]
*  fine tunes of our image model where it can turn into anime or Ghibli style [[01:26:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5184.36s)]
*  it's the same with this your Apple intelligence your smartphone is a base [[01:26:27](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5187.84s)]
*  model that's common and again you can ensure all the data and that is fine [[01:26:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5191.48s)]
*  and not poisoned which is why open source open data is acquired in my [[01:26:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5195.2s)]
*  opinion for regulator systems with these little adapters on the top that are [[01:26:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5199.2s)]
*  learning about sport and learning about your thing and tuning it to Apple photos [[01:26:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5203.4s)]
*  so you'll have this modularized system where everyone can pick and choose and [[01:26:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5207.04s)]
*  that's important when for example your kids education do you want to follow [[01:26:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5210.68s)]
*  your school curriculum and be tied down to just that education model what do you [[01:26:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5215.28s)]
*  want to be able to take that education model know exactly what's inside it and [[01:26:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5219.36s)]
*  then extend it with another calculus course or this or that you want the [[01:27:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5223.4s)]
*  latter right and that's why permissionless innovation is so great and [[01:27:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5227.04s)]
*  this comes back to our deep seek discussion right the fact that it's open [[01:27:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5231.08s)]
*  source means more people use it than anything else [[01:27:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5234.84s)]
*  llama was open source more people use it than anyone else so if you build great [[01:27:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5237.0s)]
*  quality models and data sets people will use it they'll innovate on it but you [[01:27:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5241.84s)]
*  can set a really great solid foundation so the models inherit from each other [[01:27:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5246.12s)]
*  they've all gone to the same school then they go to different college and then [[01:27:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5250.24s)]
*  they go to different universities but they're interoperable I love it you know [[01:27:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5253.4400000000005s)]
*  the future is amazing if we survive it I mean that's that's really truly I mean [[01:27:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5258.6s)]
*  we're heading toward this extraordinary world the most exciting time ever we [[01:27:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5265.8s)]
*  just need to survive the the downside the Star Wars mad max scenarios I have a [[01:27:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5269.280000000001s)]
*  question for you if we survive the next five to ten years how long do we live [[01:27:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5277.08s)]
*  for yeah so the you know this is a lot of the work I've been public on this and [[01:28:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5280.08s)]
*  been having debates and in arguments with a lot of the traditional medical and [[01:28:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5287.96s)]
*  scientific societies that are like listen we're just not going to get past [[01:28:13](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5293.88s)]
*  120 it is it's built into our genes in fact the probability that you Peter or [[01:28:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5297.64s)]
*  you anybody is going to get past a hundred in a healthy fashion is pretty [[01:28:24](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5304.88s)]
*  damn low and the fact of the matter is science and medicine steeped in history [[01:28:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5309.0s)]
*  and the past is good reason to believe that but it's same good reason to [[01:28:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5316.32s)]
*  believe that humans would never fly and never get to the moon and never travel [[01:28:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5320.799999999999s)]
*  at the speeds we do and never have instantaneous communications or quantum [[01:28:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5325.28s)]
*  teleportation or all the things that were impossible just you know a few [[01:28:49](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5329.639999999999s)]
*  years or a few decades or a century ago and the reality is we are a complex [[01:28:53](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5333.759999999999s)]
*  system of 40 human trillion cells with a billion chemical reactions per cell per [[01:29:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5341.12s)]
*  second and there's no way a human can understand this and understand what are [[01:29:06](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5346.28s)]
*  the root causes of aging and why we age but AI can and I think AI can help us to [[01:29:11](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5351.599999999999s)]
*  understand the fundamentals and alter it and not accept what evolution dealt us [[01:29:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5359.84s)]
*  evolution evolution had a mission evolution had a mission of passing on [[01:29:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5366.24s)]
*  genes by the age of 30 and then killing you off so you never stole food from [[01:29:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5372.96s)]
*  your grandchildren's mouths my mission is a little bit different for death [[01:29:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5379.0s)]
*  what's that we're birthed for death yes yeah so that genes can propagate and we [[01:29:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5383.08s)]
*  can break that cycle so to answer your question E mod I think we've got an [[01:29:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5388.28s)]
*  unlimited future now the question is are you going to want to live the next [[01:29:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5392.52s)]
*  hundred years in your meat sack or the next 200 years in your meat sack or are [[01:29:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5397.68s)]
*  you going to want to upload whatever the health consciousness is and your [[01:30:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5403.08s)]
*  memories into the cloud and and be liberated and we'll see it's crazy to [[01:30:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5407.64s)]
*  think about again this is such a time of change right and you look at the tools [[01:30:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5415.400000000001s)]
*  and techniques you look at the medical sphere we need to reimagine medicine [[01:30:20](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5420.08s)]
*  from scratch which is like we need core developer teams working in the open on [[01:30:23](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5423.0s)]
*  each of these what is government like that's a question that we're having [[01:30:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5426.36s)]
*  right now do we need to spend so much money what is the purpose of government [[01:30:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5430.12s)]
*  how many people listening to this feel represented by the government now what [[01:30:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5433.28s)]
*  if you have your own AI that you own that is looking out for you that [[01:30:38](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5438.36s)]
*  represents you that interacts with the government AI because every government [[01:30:42](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5442.44s)]
*  decision will be checked by an AI within the next few years because just do it [[01:30:45](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5445.759999999999s)]
*  and then they'll be made by an AI because obviously the AI is better than [[01:30:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5448.92s)]
*  the government that's scary but you can finally have representative democracy [[01:30:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5452.5199999999995s)]
*  yeah true democracy for the first time ever these are the positive you can have [[01:30:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5457.0s)]
*  personalized medicine you have empathetic medicine how much of medicine [[01:31:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5461.0s)]
*  is actually psychological you know like I don't have control of myself no one's [[01:31:05](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5465.4s)]
*  listening to me having that aid these are systems that I think need to be [[01:31:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5470.16s)]
*  built from scratch and reimagined and education I think is probably one of the [[01:31:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5474.5599999999995s)]
*  biggest ones of those our education system is completely not fit for [[01:31:18](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5478.5599999999995s)]
*  purpose despite the efforts of everyone and we say that for a system after system [[01:31:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5481.72s)]
*  like you see math academy and things like that and the results the people [[01:31:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5486.72s)]
*  already having did you see that one from the school in Nigeria recently I think [[01:31:30](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5490.6s)]
*  it was like two nights with chat GPT they did two years well it was two weeks [[01:31:34](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5494.56s)]
*  or two months of check they two years advancement just with chat GPT in math [[01:31:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5499.360000000001s)]
*  it was insane I think I know it's we've had this conversation before where [[01:31:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5503.64s)]
*  schools are up in arms and saying we'll making you know AI legal you can't use [[01:31:48](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5508.8s)]
*  chat GPT you can't use Gemini 2 and the fact the matter is sure you can't use [[01:31:52](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5512.72s)]
*  that to teach the way you used to but guess what you can use it to teach a [[01:31:57](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5517.92s)]
*  hundred X faster and better and set massive objectives for your kids help [[01:32:01](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5521.8s)]
*  them dream bigger than ever before but it disrupts the entire you know teaching [[01:32:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5527.24s)]
*  industry was because the school was designed to reduce our agency and remove [[01:32:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5534.16s)]
*  it to become a cog with the classical you know this is a really important [[01:32:19](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5539.360000000001s)]
*  point that the last couple hundred years we've turned humans and robots you know [[01:32:25](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5545.280000000001s)]
*  you stood in assembly line you stand out widgets and the efficiency of which how [[01:32:29](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5549.280000000001s)]
*  many widgets you could stamp out per hour was your pay grade and your [[01:32:32](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5552.76s)]
*  seniority level and whatever and we measured you on KP eyes and so on and [[01:32:36](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5556.240000000001s)]
*  now we're flipping it around and I find it fascinating that the most valuable [[01:32:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5560.68s)]
*  colleagues and employees we have are the ones that learn the fastest and that's [[01:32:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5564.200000000001s)]
*  starting now become the human factor much more again and that's very very [[01:32:47](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5567.92s)]
*  encouraging now you can add to it some really funny I stuff so this is I had [[01:32:51](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5571.84s)]
*  this piece how to think about AI where I was like you know building on that's [[01:32:56](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5576.400000000001s)]
*  thing about AI Atlantis and things like that yes we can design AI in two ways [[01:32:59](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5579.72s)]
*  one is we build agents to replace people the other is that we focus primarily on [[01:33:03](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5583.52s)]
*  increasing human agency because our systems have taken them those are two [[01:33:10](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5590.4s)]
*  different ways of designing AI actually where is one of the reasons I think I [[01:33:14](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5594.4s)]
*  look at the anthropics and Google's and others of the world I don't think they're [[01:33:17](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5597.92s)]
*  focused on increasing human agency as much as automation and business [[01:33:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5601.44s)]
*  optimization because their customers are typically businesses or on the consumer [[01:33:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5606.5199999999995s)]
*  side again I don't think that it's just become a bit different on the design [[01:33:31](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5611.28s)]
*  pattern side but it's exciting because we can revolutionize each of these [[01:33:35](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5615.24s)]
*  important things for living for the first time it all we can say is it is [[01:33:39](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5619.32s)]
*  gonna be the most exciting time ever to be alive for sure this is why you need [[01:33:44](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5624.4s)]
*  your eight hours of sleep a night yeah for goodness I did not get my eight [[01:33:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5630.599999999999s)]
*  hours I woke up at 4 a.m. to prep for this podcast took a cold shower to wake [[01:33:55](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5635.16s)]
*  myself up but it was worth it because this was a phenomenal conversation you [[01:34:00](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5640.799999999999s)]
*  lost me a cold shower but okay Imaad so happy to have you back on moonshots [[01:34:07](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5647.52s)]
*  Salim always a pleasure my friend Imaad if anybody wants to follow your current [[01:34:15](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5655.88s)]
*  work where do they go to see what you're up to and learn more about me at [[01:34:21](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5661.64s)]
*  emostac on Twitter or i.i.inc.internet.inc. I I dot inc I love that which [[01:34:26](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5666.280000000001s)]
*  it's it's awesome gentlemen I look forward to having this conversation on [[01:34:33](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5673.64s)]
*  WTF just happened in tech again we're gonna have this more frequently because [[01:34:40](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5680.0s)]
*  our heads are spinning at the speed that technology is moving just fundamentally [[01:34:43](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5683.92s)]
*  spinning take care Salim take care Imaad see you buddies [[01:34:50](https://www.youtube.com/watch?v=lY8Ja00PCQM&t=5690.2s)]
