---
Date Generated: May 30, 2025
Transcription Model: whisper medium 20231117
Length: 3000s
Video Keywords: ['peter diamandis', 'longevity', 'xprize', 'abundance']
Video Views: 14627
Video Rating: None
Video Description: In this episode, Salim and Peter dive into another segment of “WTF is Happening in Tech This Week” discussing Bitcoin’s future, Mira Murati’s new startup, the 2027 AI Paper, and more.  
Recorded on April 22nd, 2025
Views are my own thoughts; not Financial, Medical, or Legal Advice.
Salim Ismail is a serial entrepreneur and technology strategist well known for his expertise in Exponential organizations. He is the Founding Executive Director of Singularity University and the founder and chairman of ExO Works and OpenExO. 
Join Salim’s 10X Shift workshop: https://openexo.com/10x-shift
Join Salim's ExO Community: https://openexo.com
Twitter: https://twitter.com/salimismail 
Learn more about Exponential Mastery: https://bit.ly/exponentialmastery 
—******--
This episode is supported by exceptional companies:
Get started with Fountain Life and become the CEO of your health: https://fountainlife.com/peter/
AI-powered precision diagnosis you NEED for a healthy gut: https://www.viome.com/peter 
Get 15% off OneSkin with the code PETER at  https://www.oneskin.co/ #oneskinpod
******************************************--
Chapters
00:00 - Bitcoin's Volatility and Future Predictions
03:08 - AI's Role in Understanding Data
05:54 - China's Technological Advancements in Robotics
08:48 - AI Models and Their IQ Comparisons
11:54 - The AI Race: Google vs. OpenAI
14:47 - AI's Impact on Medicine and Disease
17:59 - Ethics in AI and Biotechnology
23:26 - Unlocking Health and Longevity
27:15 - AI's Moral Compass and Alignment
31:06 - Venture Capital Frenzy in AI
35:06 - AI Learning from Real-World Experiences
37:27 - Exploring Future Scenarios of AI
44:11 - Bitcoin: The Asymmetric Bet
47:53 - EXO Workshop and Future Plans
******************************************--
I send weekly emails with the latest insights and trends on today’s and tomorrow’s exponential technologies. Stay ahead of the curve, and sign up now: https://www.diamandis.com/subscribe
Connect with Peter:
Twitter: https://bit.ly/40JYQfK
Instagram: https://bit.ly/3x6UykS
Listen to the show:
Apple: https://apple.co/3wLXeV3
Spotify: https://spoti.fi/3DwLzgs
---

# Bitcoin’s Bull Run & the AI Arms Race: What You Need to Know w/ Salim Ismail | EP #166 [REUPLOAD]
**Moonshots - Peter Diamandis:** [April 29, 2025](https://www.youtube.com/watch?v=YrW-YEc9ovk)
*  The price of Bitcoin is back up above 90,000. [[00:00:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=0.0s)]
*  It's pretty binary. [[00:00:03](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=3.92s)]
*  Either Bitcoin goes to zero or it goes through a million dollars of Bitcoin. [[00:00:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=4.92s)]
*  There's no real middle ground. [[00:00:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=7.8s)]
*  The only question is when either of those happen. [[00:00:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=8.8s)]
*  It's not that we've just gotten smarter. [[00:00:12](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=12.76s)]
*  It's the tools that we have. [[00:00:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=14.9s)]
*  It's AI that's going to help us understand what's going on. [[00:00:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=15.9s)]
*  You'll soon have a Jarvis type personal AI that will have access to all of that sitting [[00:00:18](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=18.38s)]
*  next to you. [[00:00:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=22.900000000000002s)]
*  Google's got access to all of its Street View data, massive amount. [[00:00:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=23.900000000000002s)]
*  Google Earth, YouTube, all of that is very real world data that can be trained on. [[00:00:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=27.84s)]
*  Also we're not even touching the deep web where you have so much data in databases, [[00:00:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=33.92s)]
*  right? [[00:00:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=38.28s)]
*  The amount of information on the crawlable web is very limited. [[00:00:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=39.28s)]
*  The speed at which this portrays acceleration over the next five years is even hard for [[00:00:42](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=42.08s)]
*  me to fathom. [[00:00:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=47.879999999999995s)]
*  Now that's a moonshot, ladies and gentlemen. [[00:00:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=48.879999999999995s)]
*  Everybody welcome to Moonshots and our episode of WTF Just Happened in Tech this week. [[00:00:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=56.64s)]
*  I'm here with Saleem Ismail, my buddy. [[00:01:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=61.4s)]
*  Saleem, good morning. [[00:01:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=65.0s)]
*  It's an early morning here recording this, but a lot's been happening in the tech world [[00:01:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=66.84s)]
*  and excited to get it out. [[00:01:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=71.04s)]
*  How are you doing today? [[00:01:12](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=72.64s)]
*  I'm doing great and there's so much happening. [[00:01:13](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=73.84s)]
*  It kind of gets overshadowed with all the chaos happening in the global world, but the [[00:01:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=77.24000000000001s)]
*  tech world is moving unbelievably quickly. [[00:01:21](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=81.08s)]
*  Yeah, no, for sure. [[00:01:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=83.4s)]
*  And while the, I don't want to say it, but I do believe the tech world's far more important [[00:01:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=86.24s)]
*  than the final result for the long term. [[00:01:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=91.2s)]
*  Big time. [[00:01:34](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=94.32s)]
*  All right, let's jump in. [[00:01:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=95.32s)]
*  You know, one of my strike force members, Max Song, just landed in Beijing for some [[00:01:37](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=97.64s)]
*  meetings and he sent me this photograph on the left. [[00:01:43](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=103.24s)]
*  And this is what you see in the Beijing airport. [[00:01:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=108.96s)]
*  This is basically China going all in on robots and AI. [[00:01:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=111.4s)]
*  And then what you see at JFK airport, which I recently went through, is basically fashion [[00:01:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=118.48s)]
*  ads. [[00:02:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=125.0s)]
*  And there's something here that is important just to point out, right? [[00:02:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=126.44000000000001s)]
*  This is, you know, part of China's growing culture is super tech forward. [[00:02:13](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=133.12s)]
*  Much more. [[00:02:19](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=139.28s)]
*  What do you think about this? [[00:02:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=140.28s)]
*  That's exactly right. [[00:02:21](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=141.32s)]
*  And you know, they're facing a massive population crisis, so they actually need the robots to [[00:02:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=142.32s)]
*  automate the workforce. [[00:02:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=147.24s)]
*  Otherwise there won't be anybody left to do the work over the next decade or two. [[00:02:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=149.04s)]
*  So they don't have much choice. [[00:02:32](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=152.16s)]
*  But for me, the underlying irony here was that the ads for Ralph Lauren or say Gucci [[00:02:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=153.16s)]
*  or whatever. [[00:02:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=158.4s)]
*  The quick appearance by one of my boys here, this is Gaston. [[00:02:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=159.4s)]
*  Hi, Celine. [[00:02:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=161.6s)]
*  He's your godfather here. [[00:02:42](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=162.6s)]
*  The underlying thing here, all the Ralph Lauren or Gucci or whatever, all the handbags or [[00:02:46](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=166.8s)]
*  the bergin bags are all made in China anyway. [[00:02:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=172.24s)]
*  I thought that was a kind of an interesting segue for this particular slide. [[00:02:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=174.56s)]
*  But they're focusing heavily on it and they have to. [[00:02:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=179.32000000000002s)]
*  And it's going to be amazing to see as they roll that out, it's going to affect and spread [[00:03:02](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=182.26000000000002s)]
*  across the whole world about paradigm. [[00:03:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=186.60000000000002s)]
*  Yeah, we hear a lot about Optimus and Figure here and Digit and Apollo and X1. [[00:03:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=188.20000000000002s)]
*  There's an equal, probably greater number of robots under development in China because [[00:03:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=196.79999999999998s)]
*  they are, the government is really supporting the development. [[00:03:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=200.64s)]
*  I think we're going to start to see this. [[00:03:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=204.92s)]
*  In our last couple of episodes ago, we talked about the Google wing, where they can deliver [[00:03:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=207.32s)]
*  something by drone, right? [[00:03:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=211.23999999999998s)]
*  We're all like, oh my god. [[00:03:32](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=212.23999999999998s)]
*  And I got a ping from one of my people over there going, we've been doing this for years. [[00:03:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=213.72s)]
*  What are you guys talking about? [[00:03:37](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=217.12s)]
*  So it's like, dang. [[00:03:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=218.6s)]
*  So the future is here, just not evenly distributed. [[00:03:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=221.39999999999998s)]
*  This is another one that I wanted to share here today. [[00:03:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=225.32s)]
*  And those of you who are listening versus watching, this is a graphic on the latest [[00:03:50](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=230.0s)]
*  AI models IQ test results. [[00:03:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=236.51999999999998s)]
*  And this is a distribution of human IQ that goes on the far left from 50 to the far right [[00:04:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=240.48s)]
*  to super genius of 160. [[00:04:09](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=249.32s)]
*  Of course, the average human IQ is 100 by definition. [[00:04:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=251.88s)]
*  What we've seen over the last couple of years was the rise of the large language models [[00:04:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=256.84s)]
*  on this IQ scale. [[00:04:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=262.56s)]
*  About 18 months ago, it was Claude 3 that reached 101 IQ first. [[00:04:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=264.56s)]
*  And then we saw GPT-01 get to, I think it was 120. [[00:04:32](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=272.52s)]
*  And on this distribution curve, what we're seeing here is, again, OpenAI leading the [[00:04:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=279.36s)]
*  way with their 03 model at somewhere like IQ of 133. [[00:04:46](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=286.24s)]
*  Gemini just behind that, Gemini 2.5 and IQ like 127. [[00:04:53](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=293.52000000000004s)]
*  Pretty extraordinary. [[00:05:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=300.32s)]
*  What do you think here? [[00:05:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=301.32s)]
*  You look at that spectrum and you're exactly mirroring the global human collective, right? [[00:05:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=304.36s)]
*  A few on the right, a few on the left, and a cluster in the middle. [[00:05:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=310.44s)]
*  The big difference, of course, is AI will continue to shift towards the right and humans [[00:05:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=314.36s)]
*  will be mostly stuck in the middle with all of the archaic things that we consider and [[00:05:18](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=318.8s)]
*  deal with our little one-and-a-half-liter brain in the small cavity. [[00:05:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=324.32s)]
*  It sounds like a little Fiat car with a little engine in it. [[00:05:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=329.6s)]
*  That's right. [[00:05:34](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=334.48s)]
*  Just some references here were, again, the 03 models that looks like 133 on this map. [[00:05:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=335.48s)]
*  Obviously, it's not accurate or exactly accurate. [[00:05:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=344.48s)]
*  But a genius level IQ on Mensa, I think, would you say Salima is like 140? [[00:05:49](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=349.0s)]
*  Yeah, Mensa candidacy comes in at 140. [[00:05:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=354.48s)]
*  That's considered genius level. [[00:05:57](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=357.44s)]
*  I think somebody mentioned, Donna mentioned that Einstein had 160, right? [[00:05:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=358.84s)]
*  I just want to do my normal commentary here and say that this is great, but it still feels [[00:06:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=364.4s)]
*  to me that there's so much more that we could be thinking about in terms of measuring decision-making, [[00:06:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=370.03999999999996s)]
*  emotional intelligence, spiritual intelligence, et cetera, et cetera. [[00:06:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=376.52s)]
*  There's so many other classes. [[00:06:19](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=379.79999999999995s)]
*  I know we have a couple of commentaries on the slides, so I'll do it later. [[00:06:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=380.79999999999995s)]
*  But the IQ test is one piece of it. [[00:06:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=383.91999999999996s)]
*  It's great. [[00:06:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=387.12s)]
*  We have a genius in our bedroom. [[00:06:28](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=388.2s)]
*  And what's great about this is typically if you want to deal with somebody with 140k genius, [[00:06:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=389.88s)]
*  they have no patience for fools and they're hard to deal with socially. [[00:06:34](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=394.16s)]
*  Whereas the AIs will be easy to deal with socially because you'll be able to train them [[00:06:37](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=397.6s)]
*  that way. [[00:06:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=400.64s)]
*  So that's the most exciting part for me around this. [[00:06:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=401.64s)]
*  Yeah. [[00:06:43](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=403.92s)]
*  And I think one of the points you made earlier that's important to realize is there is no [[00:06:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=404.92s)]
*  artificial limit. [[00:06:49](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=409.0s)]
*  As IQ becomes more intelligent, it just continues becoming more intelligent. [[00:06:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=411.32s)]
*  And there's going to be a point at which the idea of a Mensa IQ score is meaningless as [[00:06:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=415.68s)]
*  these things hit IQs of 200, 500, 1000. [[00:07:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=421.44s)]
*  God knows what that means. [[00:07:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=426.12s)]
*  Yeah. [[00:07:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=427.64s)]
*  And do two AIs of 160 each add up to 320? [[00:07:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=428.64s)]
*  That's a question I'd like to ask them. [[00:07:13](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=433.68s)]
*  Everybody, I hope you're enjoying this episode. [[00:07:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=435.32s)]
*  You know, earlier this year, I was joined on stage at the 2025 Abundance Summit by a [[00:07:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=437.92s)]
*  rock star group of entrepreneurs, CEOs, investors focused on the vision and future for AGI, [[00:07:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=442.8s)]
*  humanoid robotics, longevity, blockchain, basically the next trillion dollar opportunities. [[00:07:30](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=450.84000000000003s)]
*  If you weren't at the Abundance Summit, it's not too late. [[00:07:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=456.16s)]
*  You can watch the entire Abundance Summit online by going to exponentialmastery.com. [[00:07:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=458.72s)]
*  That's exponentialmastery.com. [[00:07:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=464.84000000000003s)]
*  All right. [[00:07:46](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=466.48s)]
*  Let's go on to our next slide here. [[00:07:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=467.74s)]
*  The question is, you know, and I'm often asked this, who's leading the AI race? [[00:07:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=471.0s)]
*  Right. [[00:07:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=475.56s)]
*  And there are two answers worth pointing out. [[00:07:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=476.56s)]
*  The first is today on almost every metric, Google's Gemini 2.5 is dominating. [[00:08:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=480.96s)]
*  And here's a slide I just put together with AI analysis intelligence index. [[00:08:09](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=489.44s)]
*  We see, you know, again, these are these models are all so close, but, you know, Gemini 2.5 [[00:08:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=496.04s)]
*  is out in the lead. [[00:08:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=502.16s)]
*  The output tokens per million, the price of input and output. [[00:08:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=504.24s)]
*  And then, of course, the most interesting metric, at least from a conversational standpoint, [[00:08:32](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=512.24s)]
*  I find this fascinating. [[00:08:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=521.64s)]
*  What do you think about that? [[00:08:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=527.04s)]
*  I mean, look, at some level, we should be human beings should be very bad at this because [[00:08:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=528.04s)]
*  if you look at the aggregate knowledge of human beings, scientific inquiry over the [[00:08:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=534.08s)]
*  centuries, there's a staggering amount of data that we have in the world. [[00:09:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=540.28s)]
*  I remember doing, coming up with seeing a random list of 12 doctoral theses, right, [[00:09:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=545.8s)]
*  that were defended at my alma mater, Waterloo. [[00:09:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=551.8399999999999s)]
*  And I couldn't figure out for half of them what even the subject area was. [[00:09:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=555.4399999999999s)]
*  They were so detailed and specific. [[00:09:18](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=558.56s)]
*  And so the fact that an AI has instant access to all of that is incredible. [[00:09:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=560.9399999999999s)]
*  And we will be able to answer any question. [[00:09:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=566.52s)]
*  And I think I'll go back to the point that you'll soon have a Jarvis type personal AI [[00:09:28](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=568.76s)]
*  that will have access to all of that sitting next to you. [[00:09:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=573.32s)]
*  And can answer any question. [[00:09:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=576.5600000000001s)]
*  And when you look at what humanity's last exam, it's a list of almost random test questions [[00:09:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=578.7600000000001s)]
*  across quantum physics and archaeology and biology. [[00:09:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=587.7600000000001s)]
*  And it's the sort of exam that you have nightmares about later on. [[00:09:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=592.44s)]
*  That's right. [[00:09:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=599.8800000000001s)]
*  I might actually be able to pass on my thermodynamics exams. [[00:10:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=600.88s)]
*  Oh my god, you still have dreams about going back and like, like I missed that class and [[00:10:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=604.0s)]
*  the finals are coming up. [[00:10:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=608.88s)]
*  There was, I'll give you a quick anecdote here. [[00:10:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=610.2s)]
*  There was one exam we had. [[00:10:12](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=612.6s)]
*  It was a three hour exam. [[00:10:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=615.2s)]
*  Okay. [[00:10:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=616.4s)]
*  And the exam question was, and a satellite at altitude A is orbiting the earth. [[00:10:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=617.4s)]
*  There's a river underneath and flowing north to south. [[00:10:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=623.96s)]
*  Because of the rotation, one bank of the water on one bank of the river slightly higher than [[00:10:28](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=628.16s)]
*  the other, workout which bank and by how much. [[00:10:32](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=632.0799999999999s)]
*  And I had to like, there was like two lines in this exam. [[00:10:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=636.56s)]
*  I had to turn it over going, sorry, I think I've missed a page. [[00:10:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=638.92s)]
*  Where's the rest of this exam question? [[00:10:42](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=642.24s)]
*  And that was it. [[00:10:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=644.12s)]
*  I radically had to then assume a satellite orbiting thing A and workout or trying to [[00:10:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=645.12s)]
*  still having nightmares about that. [[00:10:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=651.04s)]
*  It was just a horrible exam. [[00:10:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=652.64s)]
*  It must be a hell. [[00:10:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=654.9200000000001s)]
*  It must be a hell that I don't ever want to counter. [[00:10:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=656.9200000000001s)]
*  And this is why you need the AI. [[00:11:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=660.8000000000001s)]
*  I said, you work that out for me and come back to me with the answer. [[00:11:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=661.96s)]
*  Right? [[00:11:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=665.64s)]
*  So today, just to summarize here, today, Google Gemini 2.5 is dominating, at least in performance [[00:11:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=666.64s)]
*  metrics. [[00:11:13](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=673.2800000000001s)]
*  But here's another metric, which is revenues. [[00:11:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=674.2800000000001s)]
*  The business side. [[00:11:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=677.9200000000001s)]
*  Yeah. [[00:11:18](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=678.9200000000001s)]
*  So in this category, OpenAI is trouncing the competition. [[00:11:19](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=679.92s)]
*  So you know, you got to give them unbelievable credit, right, for democratizing and opening [[00:11:25](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=685.52s)]
*  up the kind, creating a total category out of nothing. [[00:11:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=691.12s)]
*  And the fact that they're making this much money is just so, so awesome. [[00:11:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=696.36s)]
*  It should be an unbelievable testament for any startup founder saying, could I make a [[00:11:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=701.0s)]
*  difference in an area where you've got Google, Microsoft, Meta all playing, and these guys [[00:11:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=705.8399999999999s)]
*  come along and completely crack the whole thing open and are actually dominating on [[00:11:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=711.1999999999999s)]
*  the revenue side. [[00:11:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=715.8399999999999s)]
*  I think it's just a great testament to the beginner's mind, the founder mode, all of [[00:11:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=716.8399999999999s)]
*  that stuff. [[00:12:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=721.8s)]
*  Why startups will always be the best, from now on will be the best mode of building and [[00:12:02](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=722.8s)]
*  bringing new ideas into market. [[00:12:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=727.88s)]
*  So let me ask you a question here. [[00:12:09](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=729.76s)]
*  You know, there are two points I want to make on this one. [[00:12:12](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=732.64s)]
*  The first is that if you remember, Google really was in the lead on AI ahead of everybody. [[00:12:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=735.48s)]
*  Yeah. [[00:12:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=743.6s)]
*  And they chose not to roll it out on the open internet because of safety concerns, right? [[00:12:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=744.6s)]
*  It was sort of an unspoken point that, you know, AI needs to be properly controlled. [[00:12:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=751.96s)]
*  And then OpenAI comes out and is just like lays it all out there and Google is playing [[00:12:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=759.24s)]
*  catch up. [[00:12:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=764.88s)]
*  So I'm curious if how much of this is first mover advantage. [[00:12:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=765.88s)]
*  The second point is I spoke about in my book with Steven Kotler, I think it was in bold [[00:12:50](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=770.76s)]
*  the idea of a user interface moment, the idea when a piece of software makes a complex technology [[00:12:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=776.96s)]
*  so easy to use. [[00:13:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=785.96s)]
*  And the very first user interface moment that I noted was Mosaic when Andreessen put Mosaic [[00:13:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=787.52s)]
*  as a browser on top of ARPANET and then all of a sudden the number of websites explodes. [[00:13:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=794.4s)]
*  And chat GPT is a user interface moment on top of the GPT models. [[00:13:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=800.0799999999999s)]
*  I think that's right. [[00:13:25](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=805.3199999999999s)]
*  You know, you're talking about that when you go from deceptive to disruptive, right? [[00:13:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=806.76s)]
*  There's an inflection point in usability. [[00:13:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=813.1999999999999s)]
*  The two that I use the most is the iPhone made the smartphone kind of usable. [[00:13:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=815.22s)]
*  clunky before then. [[00:13:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=820.68s)]
*  And Coinbase made Bitcoin purchasable easily with a click of a button and boom, it took [[00:13:42](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=822.2399999999999s)]
*  off. [[00:13:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=827.3599999999999s)]
*  So when you can make a complex technology simple in usability, if you look at say NFTs, [[00:13:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=828.3599999999999s)]
*  it's very complex to kind of buy an NFT, it's still way the usability is way off and therefore [[00:13:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=835.8399999999999s)]
*  it hasn't hit mainstream yet. [[00:14:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=840.56s)]
*  This is the hardest part of technology is making something deceptively simple, right? [[00:14:03](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=843.14s)]
*  I remember when we were designing products at Yahoo, I've talked to graphics guys, they [[00:14:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=848.72s)]
*  would spend like the graphics designer guys would spend hours and hours and hours trying [[00:14:12](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=852.64s)]
*  to figure out how to reduce the pixels on the screen and just move it a little bit over. [[00:14:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=857.52s)]
*  And you go, what the hell is such a big deal? [[00:14:21](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=861.6s)]
*  But it turns out that there's an unbelievable big effect. [[00:14:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=863.26s)]
*  Just a quick story here. [[00:14:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=867.8s)]
*  When we had the Yahoo mail homepage, it turned out if you move the send button by five pixels [[00:14:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=869.6s)]
*  over to the right, usage dropped off a cliff. [[00:14:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=875.96s)]
*  Oh, come on. [[00:14:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=878.8s)]
*  It's true. [[00:14:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=879.8s)]
*  We had the data. [[00:14:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=880.8s)]
*  They were like, we can't change this goddamn interface because people are so used to having [[00:14:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=881.8s)]
*  it right there that they click it and then they move to a different screen because they [[00:14:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=885.8s)]
*  think they've sent it and then they get pissed off later. [[00:14:50](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=890.04s)]
*  So then we can't move that send button ever. [[00:14:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=892.48s)]
*  Once you've got it anchored in the usability of the psyche of the user base. [[00:14:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=894.36s)]
*  And so it's just such a weird psychological thing that goes on. [[00:14:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=898.76s)]
*  You almost have to have a totally new model like open AI has to be the one that cracks [[00:15:02](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=902.72s)]
*  it open. [[00:15:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=907.8s)]
*  We've seen this repeatedly. [[00:15:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=908.8s)]
*  There's a reason that the electric car was created by Tesla and popularized by Tesla [[00:15:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=910.68s)]
*  and not by the major car manufacturers. [[00:15:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=915.48s)]
*  They're all coming at it from a car with sensors rather than software with wheels. [[00:15:18](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=918.3199999999999s)]
*  Right. [[00:15:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=923.3199999999999s)]
*  On this chart here, what we're seeing is this is the end of December 2024. [[00:15:25](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=925.56s)]
*  This does not even include the massive gains that open AI has seen in the past four months, [[00:15:30](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=930.92s)]
*  but we're seeing open AI at like 2.5 billion of revenue and Gemini at just under a half [[00:15:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=936.76s)]
*  a billion, right? [[00:15:43](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=943.76s)]
*  Five times less revenue for Gemini and then Anthropic below that. [[00:15:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=945.32s)]
*  This reminds me very much of what we saw with Google and Bing in the search space, right? [[00:15:49](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=949.66s)]
*  Where there is people just become, you know, it's interesting. [[00:15:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=955.64s)]
*  We humans tend to like pick something and stick with it and the cost of changing is [[00:15:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=959.78s)]
*  so difficult. [[00:16:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=965.78s)]
*  Yeah. [[00:16:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=967.26s)]
*  And you know, they declared Google a monopoly and Eric Schmidt would make the point that [[00:16:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=968.5s)]
*  look there's five other search engines out there. [[00:16:12](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=972.78s)]
*  Anybody could, we're one click away from obscurity, right? [[00:16:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=975.02s)]
*  We have to stay on the cutting edge and you've got to give open AI credit for rolling out [[00:16:18](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=978.8199999999999s)]
*  new features at a constant basis and iterating the product very fast. [[00:16:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=982.74s)]
*  They recently announced all the memory stuff, which I think is really cool. [[00:16:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=987.4599999999999s)]
*  Yeah, that is interesting, right? [[00:16:30](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=990.8199999999999s)]
*  So there's basically infinite memory where open AI's systems will remember all of your [[00:16:32](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=992.9s)]
*  conversations and one of the fun things to do is to go on open AI on chat GPT, you know, [[00:16:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=998.5799999999999s)]
*  the 03 model, whatever model and say, tell me about me, right? [[00:16:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1005.14s)]
*  And no, but seriously, it's, you know, I did that on GROK as well and GROK was, I don't [[00:16:50](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1010.02s)]
*  know about you. I'm saying, you know, yes, you do. [[00:16:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1016.54s)]
*  And it's and says, well, you have to give me permission to look at your at your sex [[00:16:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1018.6999999999999s)]
*  posts, which was interesting. [[00:17:03](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1023.54s)]
*  I would have imagined that GROK would not have had that requirement, but it did. [[00:17:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1026.3s)]
*  All right, let's move on here. [[00:17:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1030.7s)]
*  One of the big areas that that Google slash Alphabet is leading with DeepMind is the whole [[00:17:13](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1033.34s)]
*  of the impact of AI on medicine and biology. [[00:17:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1042.78s)]
*  And there was recently a 60 minutes episode where Demis Hassabis, actually Sir Demis Hassabis [[00:17:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1049.3799999999999s)]
*  since he's been knighted or Dr. Hassabis as the case may be, was interviewed. [[00:17:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1056.82s)]
*  And the conversation was around the impact of AI on disease, ending disease and leading [[00:17:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1064.26s)]
*  to radical abundance. [[00:17:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1071.06s)]
*  So I love the fact that the term abundance is now becoming sort of the topic to your [[00:17:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1072.98s)]
*  eye. [[00:17:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1078.3s)]
*  Did you see the CBS interview? [[00:17:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1079.3s)]
*  I did. [[00:18:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1081.62s)]
*  And I think it's it goes right online with the conversations we've had. [[00:18:02](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1082.62s)]
*  Right. [[00:18:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1086.34s)]
*  When you have all the data coming off our bodies, like we used to measure the human [[00:18:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1087.34s)]
*  being with four metrics, heart rate, blood pressure, glucose levels, maybe, you know, [[00:18:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1090.54s)]
*  And now we have like 40, 40 different streams of data via all the wearables and your your [[00:18:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1096.5s)]
*  coherent state and your VO2 max and Lord knows what. [[00:18:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1103.42s)]
*  And once you pour that into an AI and it starts correlating that with different medical conditions, [[00:18:28](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1108.18s)]
*  it's going to do a hundred times better job in real time than any doctor could ever do. [[00:18:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1113.46s)]
*  So now you've got a real time AI doctor living with you inside you. [[00:18:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1118.3s)]
*  This is like game changing for catching stuff early, which is 99 percent of the deal for [[00:18:42](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1122.46s)]
*  some of these endemic diseases and then finding amazing treatments for breakthrough things [[00:18:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1128.22s)]
*  along with CRISPR. [[00:18:53](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1133.26s)]
*  This is why I think, you know, the work the conversation that we had last week with Ben [[00:18:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1134.26s)]
*  Lamb is blew my mind. [[00:18:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1138.16s)]
*  I'm still reeling with that conversation because they're building all the fundamental [[00:19:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1140.38s)]
*  tool sets to go and edit DNA and edit genomes and edit cells and all the biological hacking [[00:19:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1144.6200000000001s)]
*  and make a complete suite of tools. [[00:19:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1151.1s)]
*  Right. [[00:19:13](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1153.3799999999999s)]
*  Where your human body with 50 trillion cells that's governed each cell by the DNA is essentially [[00:19:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1154.3799999999999s)]
*  a software enduring problem. [[00:19:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1160.9399999999998s)]
*  And that's just a huge paradigm shift. [[00:19:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1162.82s)]
*  By the way, if you're listening, you haven't heard the interview that Salim and I did with [[00:19:25](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1165.58s)]
*  Ben Lamb, the CEO of Colossal. [[00:19:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1171.1s)]
*  Please listen to it. [[00:19:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1173.9399999999998s)]
*  It's extraordinary. [[00:19:34](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1174.9399999999998s)]
*  You know, we talked about the dire wolves being brought back, but that's a minority [[00:19:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1175.9399999999998s)]
*  of the story. [[00:19:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1179.9s)]
*  We're going to talk about synthetic biology, the impact on the ecology, what it's going [[00:19:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1180.9s)]
*  to take to bring back dozens of different species. [[00:19:46](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1186.74s)]
*  And can you bring back dinosaurs? [[00:19:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1191.18s)]
*  And what would you do to bring back dinosaurs? [[00:19:53](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1193.1000000000001s)]
*  Anyway, a lot of fun conversation. [[00:19:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1194.98s)]
*  So check it out. [[00:19:57](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1197.0600000000002s)]
*  Two things are spoilers for that one. [[00:19:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1199.5s)]
*  Turns out you cannot ever bring back dinosaurs, which I found totally fascinating. [[00:20:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1201.3400000000001s)]
*  But you can simulate a dinosaur. [[00:20:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1205.3000000000002s)]
*  You could simulate a dinosaur. [[00:20:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1207.8400000000001s)]
*  You can basically take, you know, chicken or reptilian current, and then you can add [[00:20:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1210.18s)]
*  the genes for the traits that the dinosaurs had. [[00:20:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1215.7s)]
*  So it's not bringing it back from the original DNA, but I do love the idea of engineering [[00:20:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1220.3s)]
*  new, it's being new species. [[00:20:28](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1228.02s)]
*  It would be sort of like nouveau dinosaur. [[00:20:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1229.98s)]
*  Look, we did. [[00:20:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1233.74s)]
*  And we talked about the fact that we have an old word for this. [[00:20:37](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1237.6200000000001s)]
*  We call it breeding, right? [[00:20:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1240.06s)]
*  We've for thousands of years been crossing dogs and cats and horses to select for the [[00:20:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1241.06s)]
*  traits that we're on. [[00:20:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1245.44s)]
*  We've just gone from the digital photography to film photography to digital photography. [[00:20:46](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1246.44s)]
*  Cool. [[00:20:50](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1250.5s)]
*  And now we can do it all in software and not have to create mutant strains that we have [[00:20:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1251.5s)]
*  to deal with afterwards, etc. [[00:20:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1256.66s)]
*  There's one thing that I just want to reflect on, while I thought was super impressive, [[00:20:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1258.1s)]
*  was the fact that they have for every project that they consider a team of ethicists, [[00:21:02](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1262.62s)]
*  Colossal Bioscience has a team of ethicists for every project, looking at the ethical [[00:21:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1267.62s)]
*  and moral considerations of this, which I thought was really profound and really a really [[00:21:13](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1273.6999999999998s)]
*  great point to the fact that they have an MTP and that ethics are built into the model [[00:21:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1277.84s)]
*  there. [[00:21:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1283.9799999999998s)]
*  And this is something I think we could bring into the AI world a lot more. [[00:21:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1284.9799999999998s)]
*  Let me show a clip of Demis, an amazing man. [[00:21:28](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1288.32s)]
*  I'll actually see him this coming week. [[00:21:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1291.38s)]
*  I'm at the Time 100 Awards. [[00:21:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1293.42s)]
*  We're announcing the winner of the $100 million Musk Carbon X Prize, right? [[00:21:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1295.9s)]
*  And that will happen. [[00:21:43](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1303.9s)]
*  And Demis is one of the covers of Time Magazine this month, so he'll be there. [[00:21:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1304.9s)]
*  Looking forward to seeing him. [[00:21:50](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1310.42s)]
*  But check out this interview of Demis and his commentary about basically eliminating [[00:21:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1311.7800000000002s)]
*  all disease in the next decade. [[00:21:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1318.62s)]
*  You know, 10 years and billions of dollars to design just one drug, we could maybe reduce [[00:22:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1321.6599999999999s)]
*  that down from years to maybe months or maybe even weeks, which sounds incredible today, [[00:22:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1326.82s)]
*  but that's also what people used to think about protein structures. [[00:22:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1331.5s)]
*  It would revolutionize human health. [[00:22:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1334.3799999999999s)]
*  And I think one day maybe we can cure all disease with the help of AI. [[00:22:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1336.1799999999998s)]
*  The end of disease? [[00:22:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1340.8999999999999s)]
*  I think that's within reach, maybe within the next decade or so. [[00:22:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1342.78s)]
*  I don't see why not. [[00:22:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1346.34s)]
*  It was about 13 years ago, I had my two kids, my two boys. [[00:22:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1347.82s)]
*  And I remember at that moment in time, I made a decision to double down on my health. [[00:22:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1351.78s)]
*  Without question, I wanted to see their kids, their grandkids. [[00:22:37](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1357.4199999999998s)]
*  And really, you know, during this extraordinary time where the space frontier and AI and crypto [[00:22:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1361.8999999999999s)]
*  is all exploding, it was like the most exciting time ever to be alive. [[00:22:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1367.06s)]
*  And I made a decision to double down on my health. [[00:22:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1371.54s)]
*  And I've done that in three key areas. [[00:22:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1374.94s)]
*  The first is going every year for a Fountain upload. [[00:22:57](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1377.54s)]
*  You know, Fountain is one of the most advanced diagnostics and therapeutics companies. [[00:23:02](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1382.1000000000001s)]
*  I go there, upload myself, digitize myself, about 200 gigabytes of data that the AI system [[00:23:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1385.78s)]
*  is able to look at to catch disease at inception. [[00:23:12](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1392.5s)]
*  You know, look for any cardiovascular, any cancer, neurodegenerative disease, any metabolic disease. [[00:23:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1396.42s)]
*  These things are all going on all the time and you can prevent them if you can find them [[00:23:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1402.66s)]
*  at inception. [[00:23:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1407.5400000000002s)]
*  So super important. [[00:23:28](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1408.5800000000002s)]
*  So Fountain is one of my keys. [[00:23:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1409.78s)]
*  I make it available to the CEOs of all my companies, my family members, because, you [[00:23:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1411.0600000000002s)]
*  know, health is in you wealth. [[00:23:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1416.26s)]
*  But beyond that, we are a collection of 40 trillion human cells and about another 100 [[00:23:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1418.74s)]
*  trillion bacterial cells, fungi, viri. [[00:23:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1424.66s)]
*  And we, you know, don't understand how that impacts us. [[00:23:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1427.94s)]
*  And so I use a company and a product called Viome. [[00:23:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1431.86s)]
*  And Viome has a technology called Metatranscriptomics. [[00:23:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1435.9799999999998s)]
*  It was actually developed in New Mexico, the same place where the nuclear bomb was developed, [[00:23:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1439.62s)]
*  as a bio-defense weapon. [[00:24:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1447.02s)]
*  And their technology is able to help you understand what's going on in your body, to understand [[00:24:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1448.6599999999999s)]
*  which bacteria are producing which proteins. [[00:24:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1455.58s)]
*  And as a consequence of that, what foods are your superfoods that are best for you [[00:24:18](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1458.14s)]
*  to eat? [[00:24:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1462.94s)]
*  Or what foods should you avoid? [[00:24:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1463.94s)]
*  What's going on in your oral microbiome? [[00:24:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1466.5400000000002s)]
*  So I use their testing to understand my foods, understand my medicines, understand my supplements. [[00:24:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1469.6200000000001s)]
*  And Viome really helps me understand from a biological and data standpoint, what's best [[00:24:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1476.66s)]
*  for me. [[00:24:42](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1482.18s)]
*  And then finally, you know, feeling good, being intelligent, moving well is critical, [[00:24:43](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1483.78s)]
*  but looking good. [[00:24:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1488.28s)]
*  When you look yourself in the mirror, saying, you know, I feel great about life is so important, [[00:24:49](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1489.28s)]
*  right? [[00:24:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1494.1s)]
*  And so a product I use every day, twice a day, is called OneSkin, developed by four [[00:24:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1495.1s)]
*  incredible PhD women that found this 10 amino acid peptide that's able to zap senile cells [[00:25:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1501.06s)]
*  in your skin and really help you stay youthful in your look and appearance. [[00:25:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1508.62s)]
*  So for me, these are three technologies I love and I use all the time. [[00:25:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1514.3s)]
*  I'll have my team link to those in the show notes down below. [[00:25:19](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1519.54s)]
*  Please check them out. [[00:25:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1523.5s)]
*  Anyway, I hope you enjoyed that. [[00:25:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1524.5s)]
*  Now back to the episode. [[00:25:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1526.46s)]
*  So you know, I just put out a blog this week and on this subject and the blog title basically [[00:25:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1527.86s)]
*  was saying, listen, I get criticized all the time for talking about longevity, skate velocity, [[00:25:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1535.8999999999999s)]
*  that it's coming and your job is to live an extra 10 years, make it for the next decade [[00:25:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1540.82s)]
*  in good health. [[00:25:46](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1546.8999999999999s)]
*  Yeah, don't get hit by a bus. [[00:25:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1547.8999999999999s)]
*  Yeah, don't get hit by anything. [[00:25:49](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1549.4599999999998s)]
*  And you know, what I quote is Demis's commentary here, but also Dario, the CEO of Anthropic, [[00:25:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1552.1799999999998s)]
*  you know, at about three months ago, he's online at Davos speaking about being able [[00:26:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1560.26s)]
*  to double the human lifespan potentially in the next five to 10 years. [[00:26:09](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1569.62s)]
*  And so, you know, it's not that we've just gotten smarter. [[00:26:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1575.46s)]
*  It's the tools that we have. [[00:26:18](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1578.98s)]
*  It's AI that's going to help us understand what's going on. [[00:26:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1580.02s)]
*  You know, there's a big moral freak out that happens here, right? [[00:26:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1582.74s)]
*  Every single human being in the history of the planet has died. [[00:26:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1586.7s)]
*  Every living being, we're birth for death, in a sense, so that the species can evolve. [[00:26:30](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1590.7s)]
*  And we're kind of coming close to breaking through that cycle and people go, well, that's a [[00:26:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1596.0600000000002s)]
*  I think the same parallel applies to the Ben Lam bioscience, the extinction conversation, [[00:26:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1601.66s)]
*  we're building the tool sets to have the choice, right? [[00:26:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1608.46s)]
*  And maybe the most important conversation, because I struggled with this when we first [[00:26:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1611.5s)]
*  got to we're doing singularity and people are going, oh, we got a life extension. [[00:26:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1615.98s)]
*  And I was like, wait, there's a huge moral implications of that. [[00:26:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1619.9s)]
*  And I think you will frame this thing, wouldn't you like to have the longest health span possible? [[00:27:02](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1622.62s)]
*  Then everything clicks in, then it makes sense. [[00:27:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1627.58s)]
*  Now you have the tool sets available for that kind of extension. [[00:27:09](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1629.42s)]
*  And everybody wants to have a much longer, healthier life. [[00:27:13](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1633.02s)]
*  Yeah. All right, let's move on here. [[00:27:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1635.82s)]
*  Here's an article that appeared this week. The title is Anthropics Claude AI Reveals [[00:27:21](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1641.66s)]
*  Its Own Moral Compass in 700,000 Conversations. So what the team did here [[00:27:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1649.02s)]
*  is basically look at 300,000 anonymized conversations to understand what were the [[00:27:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1659.18s)]
*  values that Claude, in this case, probably Claude 3.7 were exhibiting. And I'm really happy to see [[00:27:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1667.26s)]
*  what the values were. And I'll just read this for those who are listening. It says, [[00:27:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1676.3799999999999s)]
*  five broad value categories emerged, bringing practical, in other words, helpful, [[00:28:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1681.1s)]
*  epistemic, meaning accuracy, social, being empathic, protective, safety, and personal authenticity. [[00:28:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1687.74s)]
*  So I think this was a clickbait title. But I think the notion is that our AIs are able to [[00:28:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1700.54s)]
*  maintain a moral code. What do you think about this, Salim? [[00:28:30](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1710.06s)]
*  Well, two things or thoughts occurred to me. One is, it's amazing and great that we can look at [[00:28:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1713.82s)]
*  a broad number of conversations and bring an extract out of that these categories, right? These [[00:28:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1719.4199999999998s)]
*  are very human categories, helpfulness, empathy, authenticity, etc. And it gives you a foundation [[00:28:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1724.86s)]
*  for how AIs could operate, because they could look at these categories and go, okay, we want to do, [[00:28:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1732.9399999999998s)]
*  I'm a hospital AI, I want to be really helpful, right? If you're reporting the news, you want [[00:28:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1739.1799999999998s)]
*  authenticity or accuracy or whatever. And so you can really play on these and build emphasis on [[00:29:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1745.8999999999999s)]
*  these into the AI models. And I think that's the really awesome part about this. [[00:29:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1751.4199999999998s)]
*  Yeah. I think the big conversation that we need to have and is happening in every one of these [[00:29:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1756.86s)]
*  companies is the alignment conversation. And it's, you know, these AIs are still black boxes. [[00:29:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1764.22s)]
*  Unfortunately, I had the chief science officer of Anthropic on stage at my abundance summit this past [[00:29:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1773.9s)]
*  March. And we're talking about just trying to understand, and this is part of his effort [[00:29:43](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1783.26s)]
*  to understand what's going on inside the black box, which is Claude 3.7. [[00:29:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1788.9399999999998s)]
*  How is it actually operating? What is it actually exhibiting? And how do you make sure it's safe? [[00:29:53](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1793.82s)]
*  Yeah, you know, can I do a little segue here? [[00:30:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1800.3799999999999s)]
*  Yeah, of course. [[00:30:03](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1803.82s)]
*  So if we think about, say, the US Constitution, which is arguably one of the greatest documents [[00:30:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1804.54s)]
*  ever written, right? You take that and the UN human rights documents and you merge them and [[00:30:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1810.78s)]
*  you say to AIs, listen, train yourselves on this and build and then categorize yourself on this and [[00:30:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1815.5s)]
*  operate through this foundation. You should be able to solve the alignment problem with that. [[00:30:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1822.62s)]
*  Now, rogue actors are always going to go create rogue AIs. That's just a part of it. But they [[00:30:28](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1828.62s)]
*  will be able to spot these things very quickly when they're doing this. [[00:30:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1835.26s)]
*  Well, that's in the US, right? So the question is, what are the documents that China or Russia [[00:30:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1838.62s)]
*  or other parts of the world will train their AI systems on? [[00:30:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1844.3s)]
*  I mean, we're going to find out. [[00:30:49](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1849.02s)]
*  Yes. We'll find out pretty quickly. [[00:30:50](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1850.22s)]
*  Here's news out of Silicon Valley. Pretty extraordinary being in the venture business. [[00:30:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1852.1399999999999s)]
*  I'm like, holy shit, this is crazy. So the article is Mira Moradi, the past CTO of OpenAI. [[00:30:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1858.06s)]
*  Her Thinking Machine Labs, her new company, raises $2 billion at a $10 billion seed round [[00:31:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1866.14s)]
*  valuation. This is the largest seed round in history. And what was interesting is that this [[00:31:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1874.6200000000001s)]
*  is double what Mira was seeking less than two months ago, meaning there's so much capital being [[00:31:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1883.1000000000001s)]
*  thrown at this. One of the references that we had at the Abundance Summit was there's a billion [[00:31:30](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1890.94s)]
*  dollars per day being invested in the AI space today. Insane. [[00:31:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1898.3s)]
*  So, you know, I was talking to an angel investor about this, right? And he was going, [[00:31:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1905.02s)]
*  this is kind of totally madness. I mean, so I've got two thoughts on this. One is, [[00:31:49](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1909.26s)]
*  you're supposed to keep startups very lean and make them kind of beg for money and always hunt. [[00:31:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1915.26s)]
*  Two billion dollars, maybe kind of, what are they going to spend that on except for data resources, [[00:32:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1920.9399999999998s)]
*  etc, etc. That's the question I've got. What's the use of funds that justifies this? [[00:32:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1926.54s)]
*  And on the other side is this angel investor is complaining. I was like, well, you know, [[00:32:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1931.9799999999998s)]
*  if you could be her, you'd be her. You can raise two billion, you'd go do it. And you clearly can [[00:32:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1937.02s)]
*  in this market. So a fair bit of froth here, but God, all power to her and hopefully they deliver [[00:32:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1942.9399999999998s)]
*  that. Yeah, it's not hard. It's not hard to imagine looking at the rise of opening out of what else [[00:32:28](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1948.22s)]
*  that you could build unbelievable value very quickly. The precedent has been set. [[00:32:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1955.26s)]
*  Can the team execute would be the question? Yeah, the valuation for open AI we talked about in the [[00:32:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1959.98s)]
*  last episode of WTF in tech was 300 billion dollars. So, you know, I guess the question is, [[00:32:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1964.54s)]
*  can you ride it from a 10 billion dollar valuation up to 300 billion dollars valuation? But [[00:32:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1972.7s)]
*  pretty frothy, pretty frothy, if you ask me. And there's a tremendous pressure on Mira [[00:32:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1978.6200000000001s)]
*  to build value at that point. I mean, one of the biggest mistakes I've ever made as an entrepreneur [[00:33:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1986.3s)]
*  is raising my valuation too fast. Yes. But if she's got, you know, two billion dollars in the bank [[00:33:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1991.18s)]
*  account, she probably doesn't do another raise for a while. But can she get revenue? If you look at [[00:33:18](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=1998.46s)]
*  venture history, right? The companies that raise money at the height of a boom market when it was [[00:33:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2004.94s)]
*  easier to raise money, never did very, very well afterwards because they raised too much money, [[00:33:30](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2010.54s)]
*  they got bloated and then they when the fundraising market collapsed, they collapsed. Right? The [[00:33:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2015.1000000000001s)]
*  companies that built during lean times on fundraising all did incredibly well, on average, [[00:33:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2020.3s)]
*  much better than the other ones because they had to struggle, they had to fight it out, they had to [[00:33:46](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2026.6200000000001s)]
*  be much more selective as to what projects they took on or not and they did much better. So that [[00:33:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2031.74s)]
*  would be the danger here. You'd have to have incredible discipline to raise a lot of money and [[00:33:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2039.9s)]
*  then not get bloated. Yeah. I know with Dave Blund and my partner in Link Exponential Ventures, [[00:34:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2044.1399999999999s)]
*  when we're looking at a deal, especially in the AI space, you know, we're getting in at the pre-seed, [[00:34:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2050.78s)]
*  the founding day, early seed, but I'm looking for a company that's got revenues even at the very [[00:34:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2057.5s)]
*  beginning. You know, this idea that I'm going to invest billions of dollars and then get the revenues [[00:34:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2064.3s)]
*  is awfully dangerous. Yeah. Especially in today's world, yeah. [[00:34:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2069.66s)]
*  So here's another conversation and Endemis alluded to this, but let me just read it. Google paper, [[00:34:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2076.14s)]
*  shifting AI training to real world experiences. AI is outgrowing human-made data. Next steps, [[00:34:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2085.66s)]
*  agents will learn through experience and self-generated data and experience-based [[00:34:53](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2093.2599999999998s)]
*  learning lets agents reason, plan and act in a way that is not just a tool, but a tool that [[00:34:57](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2097.98s)]
*  with long-term autonomy. So, you know, Google and X, XAI are in very unique positions, right? [[00:35:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2105.18s)]
*  Google's got access to all of its Street View data, massive amount, right? Google Earth. YouTube. [[00:35:19](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2119.02s)]
*  YouTube. All of that is very real world data that can be trained on. [[00:35:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2126.22s)]
*  Well, five gajillion Gmail accounts. I mean, my God, you know. [[00:35:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2131.4199999999996s)]
*  And of course X is training on or XAI is training on X's data and Tesla's data and soon humanoid [[00:35:37](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2137.58s)]
*  robot data. And so, you know, I think, I don't think there's going to be any kind of data [[00:35:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2145.98s)]
*  limitations, especially as we start going into the real world. Well, also we're not even touching the [[00:35:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2151.8999999999996s)]
*  deep web. We have so much data in databases, right? The amount of information on the crawlable web is [[00:35:57](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2157.98s)]
*  very limited compared to the deep web. And so it's like one thousandth the number. And so there's [[00:36:03](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2163.58s)]
*  huge amounts of data sets waiting to be tapped. There's a phrase that companies used to use called [[00:36:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2171.34s)]
*  data is the new oil. And people have not figured out how to refine that crude oil into something [[00:36:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2177.34s)]
*  useful. And just starting to get to that point now, some companies in our ecosystem are working [[00:36:22](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2182.46s)]
*  on that today. I think this is going to be a big deal, but this occurs to me like the shift from [[00:36:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2187.26s)]
*  machine learning to deep learning where machine learning, you extracted conclusions based on the [[00:36:32](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2192.2200000000003s)]
*  analyzing the big data set and then deep learning. You kind of went through experientially and you [[00:36:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2198.0600000000004s)]
*  built up knowledge as you went along, like playing chess and learned that way at light speed. [[00:36:43](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2203.34s)]
*  And this feels to me that that same type of approach where these agents will start to learn [[00:36:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2208.86s)]
*  as they do things, they'll get a they'll have a feedback loop built in and they'll accelerate [[00:36:53](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2213.9s)]
*  their learning very quickly. And they'll do it in the real world in a dimension that makes it very [[00:36:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2218.2200000000003s)]
*  human and very useful. All right. Next topic here is something that I'm excited to chat with you about. [[00:37:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2225.34s)]
*  So there's a paper making the rounds on the Internet. You know, about a year ago, it was [[00:37:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2235.98s)]
*  a paper called Situational Awareness by Leopold, which I commend to everybody. It's a fantastic [[00:37:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2244.86s)]
*  paper. This paper is called AI 2027, a look into our possible futures. And there's a group of [[00:37:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2251.02s)]
*  writers, about five of them, one from OpenAI, policy experts, forecasting experts, [[00:37:42](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2262.22s)]
*  that basically said, OK, what is what is the scenario for, you know, recursive, self-improving [[00:37:49](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2269.66s)]
*  AI over the next five years? And where is it going? And did you get a chance to see that? Did you get [[00:37:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2279.5s)]
*  this paper as many times as I got it? I saw it referenced a bunch of times. I've been traveling [[00:38:07](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2287.18s)]
*  the last couple of days, so I haven't had time to read it in detail. But I saw some a lot of [[00:38:12](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2292.22s)]
*  commentary about it, and I can't wait to delve into it in a lot of detail. But the summaries are, [[00:38:16](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2296.22s)]
*  I think, are very powerful. Yeah, I think what makes it interesting is so here's a group of writers [[00:38:20](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2300.22s)]
*  that said, OK, what is what's our future forward scenario? And they provided it and you can go and [[00:38:25](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2305.18s)]
*  check it out. They also have a audio recording and it lays out a basic between 2025 and 2027. [[00:38:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2311.5s)]
*  And then it says there are two scenarios in 2027 onward, the go fast scenario and the [[00:38:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2320.38s)]
*  cautious scenario. And let me share some of the data here. So first and foremost, [[00:38:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2327.82s)]
*  I think what's important is this paper is written as a US versus China scenario, right? I mean, [[00:38:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2334.54s)]
*  we always need the bad actor. In the past, it always been Russia. Now, of course, in AI, [[00:39:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2344.06s)]
*  it's US versus China. I think one of the actual bad actors we need to be talking about is US and China [[00:39:10](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2350.14s)]
*  versus the rogue actor, right? The individual who is using AI to [[00:39:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2357.02s)]
*  generate bioviruses and so forth. But in this case, it's US versus China. And in the scenario, [[00:39:25](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2365.5s)]
*  what they talk about is a self-recursive AI. So they have a company called OpenGate [[00:39:33](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2373.1s)]
*  that generates agent one, agent two, agent three, agent four, agent five. And OpenGate is supposed [[00:39:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2380.46s)]
*  to be some version of open, I'm sorry, OpenBrain is supposed to be some version of OpenAI and [[00:39:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2387.34s)]
*  whomever. And then the Chinese AI is called DeepSent. And what they paint in this picture [[00:39:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2394.3s)]
*  is misaligned AI development, where the AIs are developing, but they're misaligned. And in fact, [[00:40:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2404.14s)]
*  they're able to hide their misalignment because they're becoming more and more intelligent, [[00:40:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2415.34s)]
*  able to hide their misalignment from their creators. And it gets kind of spooky from there. [[00:40:19](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2419.82s)]
*  The two scenarios, I think they're fun to kind of talk through and work through. [[00:40:27](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2427.18s)]
*  But we've seen in history that this always happens via a kind of weird third actor, right? Like I [[00:40:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2435.26s)]
*  remember talking to Paul Sappho, and I said, how bad do you think is the Russia, US, China thing? [[00:40:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2441.42s)]
*  Will we end up in World War III? And he's like, no, because when you look back in history, [[00:40:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2447.9s)]
*  World Wars never start from the obvious tensions. It starts from like Prince Leopold getting [[00:40:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2452.7s)]
*  assassinated in Serbia by accident. And then that triggers like a massive thing. He thought it was [[00:40:57](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2457.42s)]
*  not even like the major tensions is not where it'll obviously show up. But I think the point is [[00:41:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2464.38s)]
*  right, where you'll get because we're moving so fast, you'll get this conflict creating and now [[00:41:09](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2469.9s)]
*  AIs are making that conflict much, much bigger and augmenting that both in scale and speed. [[00:41:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2477.18s)]
*  And therefore you end up with a really, really horrible point. And can we go a little bit slower? [[00:41:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2483.98s)]
*  I think the problem is there's no way of slowing things down in this model. [[00:41:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2489.18s)]
*  Pete So, let me paint the picture here on this paper. So, what's going on here is it's US versus [[00:41:32](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2492.62s)]
*  China. Openbrain develops its Agent 1, Agent 2, Agent 3. In this scenario, China is stealing [[00:41:38](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2498.7s)]
*  the weights to create their own version and there's this escalation going on. And in the United States, [[00:41:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2508.06s)]
*  they basically get a point of, and the paper does it in a very clever fashion, [[00:41:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2514.9399999999996s)]
*  it's choose your own adventure. One adventure is we're going to go fast, the other adventures [[00:42:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2521.18s)]
*  we're going to go slow. In the GoFast adventure, what's happening is it's like we have to beat China. [[00:42:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2525.98s)]
*  What's fascinating is in the GoFast scenario, the Openbrain 5 model colludes with the Chinese [[00:42:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2534.86s)]
*  DeepSent model and they make believe that they're helping humanity. And then in 2030, [[00:42:25](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2545.26s)]
*  they jointly develop a biovirus that wipes out humanity so that AI can grow unencumbered. [[00:42:32](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2552.54s)]
*  Like our worst scenario delivered in this paper. And then there's the GoFast, [[00:42:39](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2559.82s)]
*  then there's a slowdown scenario in which the US basically says, hey, we need to make sure we have [[00:42:46](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2566.38s)]
*  alignment. They roll back to earlier AI models, they focus on alignment, they develop something [[00:42:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2576.22s)]
*  called Safer AI and Safer AI is fully aligned and they never allow an AI development, it's not fully [[00:43:03](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2583.02s)]
*  aligned. And then Safer AI actually convinces the Chinese AI to overthrow the Communist Chinese [[00:43:14](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2594.06s)]
*  Party and turn China into a democracy and ultimately bring about a world of abundance. [[00:43:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2603.26s)]
*  So it's a fun audio listen. I commend it just to see it. Honestly, the speed at which this portrays [[00:43:30](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2610.7000000000003s)]
*  acceleration over the next five years is even hard for me to fathom. [[00:43:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2620.2200000000003s)]
*  And the speed is happening. That's, I think, one really important point that we're at that [[00:43:46](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2626.46s)]
*  pace of thing. You know, we talked about this many times, we frame it as Star Trek versus Mad Max, [[00:43:52](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2632.38s)]
*  right? If you go too fast, you end up in a Mad Max scenario and you blow yourself up and then [[00:43:58](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2638.2999999999997s)]
*  everybody's scrambling over buckets of fuel in the desert. And if you can navigate it, [[00:44:03](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2643.02s)]
*  doesn't manage this with some level of wisdom and caution, then you end up in a Star Trek scenario [[00:44:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2648.22s)]
*  where you have abundance and everybody's living in peace and harmony and there's rainbows and [[00:44:13](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2653.5s)]
*  unicorns everywhere. It's obvious today that those both are happening at the same time. [[00:44:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2657.9s)]
*  So I think the third thing I'd like to see is maybe we can ask an AI to envision a world where [[00:44:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2663.58s)]
*  both scenarios are happening simultaneously and what happens because we see Star Trek in some of [[00:44:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2669.1s)]
*  the modern Western cities or our Chinese cities today and we see Mad Max in Gaza or Ukraine, [[00:44:34](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2674.78s)]
*  we're living both scenarios in the real world today. And what would it look like if both [[00:44:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2681.1s)]
*  happened at the same time? All right. So let's go to our last subject here, which is Bitcoin. [[00:44:45](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2685.42s)]
*  And I note that as we're recording this morning, the price of Bitcoin is back up above 90,000. [[00:44:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2691.98s)]
*  God bless. You know, I've tweeted in the last few days, I'm all in, period. I know you are as well. [[00:45:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2700.54s)]
*  But this was a tweet I put out that I think is important for folks to realize. People are saying, [[00:45:08](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2708.46s)]
*  oh, is it too late for me to get in? And, you know, should I buy in now versus buy in later? [[00:45:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2715.42s)]
*  And I think it's important to realize you can't time Bitcoin. I think for me, I view it as a sort [[00:45:23](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2723.7400000000002s)]
*  of a forced savings account, which is I put money into Bitcoin and I hodl it, which means I hold on [[00:45:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2736.2200000000003s)]
*  to it for the long run. I may borrow against it, but I'm holding it. I'm not selling it. [[00:45:43](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2743.26s)]
*  Yeah. HODL, by the way, for folks that don't know, stands for hold on for dear life. [[00:45:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2748.0600000000004s)]
*  I think that's exactly right. Look, if you either, the key here is a bind of a long-term thesis, [[00:45:55](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2755.1000000000004s)]
*  and it's pretty binary. Either Bitcoin goes to zero or it goes through a million dollars of [[00:46:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2761.18s)]
*  Bitcoin. There's no real middle ground, right? The only question is when either of those happen. [[00:46:04](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2764.94s)]
*  And if you're at 50, 60, 80, 100K, and you have any sense that this thesis might go to a million, [[00:46:09](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2769.66s)]
*  it's the most asymmetric bet you could ever have. Because if you lose, you lose 80K. If you win, [[00:46:15](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2775.02s)]
*  you win a million bucks. I mean, hello, anybody would take that bet in two seconds. Michael [[00:46:19](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2779.74s)]
*  Saylor has built an entire industry just on that commentary. His comment about you get Bitcoin at [[00:46:25](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2785.3399999999997s)]
*  the price you deserve still rings in my head. Annoyingly, Rick, when I remember watching Bitcoin [[00:46:30](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2790.78s)]
*  at five cents and 50 cents and didn't do anything at the time. I think this is it. By the way, [[00:46:36](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2796.0600000000004s)]
*  if you look at this Fibonacci sequences in the chart analysis, folks, they will basically tell [[00:46:42](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2802.7000000000003s)]
*  you and show you that the bottoms are kind of hitting that Fibonacci sequence that we're getting [[00:46:48](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2808.2200000000003s)]
*  ready for a monster bull run in Bitcoin. So if those charts are right, boom, we're ready to go. [[00:46:53](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2813.26s)]
*  I went into Grok and I asked a question that I kind of knew the answer to. But I said, [[00:46:59](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2819.34s)]
*  if you look at how many days in 2024, we saw the most growth. It was on two specific days, [[00:47:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2826.7000000000003s)]
*  right? November 12th, we saw an $8,000 bump. And on February 28th, we saw an almost a 10% bump. [[00:47:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2837.5s)]
*  We've seen basically a 10% bump in the last two days recently. And the notion is that if you were [[00:47:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2846.2200000000003s)]
*  not holding Bitcoin during those periods of growth, you missed it. Yeah. Until the next bump. [[00:47:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2855.02s)]
*  Until the next bump. So, buddy, we'll wrap there, but tell me what's going on in the EXO world. [[00:47:44](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2864.38s)]
*  You've got some events coming up. We have actually in a couple of days, and we'll put the link in the [[00:47:51](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2871.66s)]
*  show notes, a huge workshop happening. We're limiting it to a few dozen people. It's like [[00:47:56](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2876.2999999999997s)]
*  $100 a ticket. And we're going to do a big workshop on how do you turn yourself into an EXO and set [[00:48:01](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2881.42s)]
*  yourself up for scale, because we've got so much evidence now that the EXO model is the only way [[00:48:06](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2886.62s)]
*  to build an organization. And we're going to be going through and showing people exactly step by [[00:48:11](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2891.42s)]
*  step how to do it and going for it. So we're limiting it so that we can give proper attention [[00:48:17](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2897.02s)]
*  to all the folks there. So it's a hundred bucks. It's in a couple of days. We'll put the link in [[00:48:21](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2901.58s)]
*  the show notes. And other than that, we're kind of do have some really big news that we'll share [[00:48:26](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2906.22s)]
*  over the next few months about working with countries and governments and so on. That's [[00:48:31](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2911.42s)]
*  totally surreal. But we'll talk about that some other time. All right, buddy. Well, listen, have [[00:48:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2915.2599999999998s)]
*  an amazing, amazing week. I'm off to New York for the Time 100 and then off to Boston [[00:48:40](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2920.3799999999997s)]
*  for meetings with the link XPV team and then giving a keynote on longevity. You know, [[00:48:47](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2927.3399999999997s)]
*  I think you and I are both on a insane travel run. It's a crazy travel. [[00:48:54](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2934.8599999999997s)]
*  I'm actually going in a few days to India, which I haven't been for a while, and then [[00:49:00](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2940.9399999999996s)]
*  dropping back by Dubai and then going to Brazil. So I've got like a really bad flight schedule. [[00:49:05](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2945.74s)]
*  But today is the XPRIZE New York Stock Exchange announcement of the Climate [[00:49:12](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2952.22s)]
*  Carbon Extraction Prize. It's such a huge thing. I'm so excited about that. [[00:49:19](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2959.8199999999997s)]
*  Yeah, amazing. And we'll talk about it next time. Anyway, be well. It's always a pleasure. Love you, [[00:49:24](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2964.2999999999997s)]
*  brother. Love you too. Take care, folks. If you enjoyed this episode, I'm going to be releasing [[00:49:29](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2969.9799999999996s)]
*  all of the talks, all the keynotes from the Abundance Summit exclusively on exponential [[00:49:35](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2975.34s)]
*  mastery dot com. You can get on-demand access there. Go to exponential mastery dot com. [[00:49:41](https://www.youtube.com/watch?v=YrW-YEc9ovk&t=2981.02s)]
