---
Date Generated: May 30, 2025
Transcription Model: whisper medium 20231117
Length: 1771s
Video Keywords: ['peter diamandis', 'longevity', 'xprize', 'abundance']
Video Views: 124777
Video Rating: None
Video Description: In this episode, recorded during the 2024 Abundance360 Summit, Ray, Geoffrey, and Peter debate whether AI will become sentient, what consciousness constitutes, and if AI should have rights.
Ray Kurzweil, an American inventor and futurist, is a pioneer in artificial intelligence. He has contributed significantly to OCR, text-to-speech, and speech recognition technologies. He is the author of numerous books on AI and the future of technology and has received the National Medal of Technology and Innovation, among other honors. At Google, Kurzweil focuses on machine learning and language processing, driving advancements in technology and human potential.
Geoffrey Hinton, often referred to as the "godfather of deep learning," is a British-Canadian cognitive psychologist and computer scientist recognized for his pioneering work in artificial neural networks. His research on neural networks, deep learning, and machine learning has significantly impacted the development of algorithms that can perform complex tasks such as image and speech recognition.
Read Ray’s latest book, The Singularity Is Nearer: When We Merge with AI
Follow Geoffrey on X: https://twitter.com/geoffreyhinton 
Learn more about Abundance360: https://www.abundance360.com/summit 
—******--
This episode is supported by exceptional companies:
Get started with Fountain Life and become the CEO of your health: https://fountainlife.com/peter/
AI-powered precision diagnosis you NEED for a healthy gut: https://www.viome.com/peter 
—******--
Topics:
0:00 - INTRO
1:12 - The Future of AI and Humanity
2:33 - The Unknown Future of AI
3:19 - AI Uncovering the Secrets Within
8:11 - Fountain Life: The Future of Health
10:30 - The Ethics of Artificial Intelligence
15:06 - Ethical Dilemma: AI Rights
18:31 - Viome: Unlocking the Power of Your Microbiome
21:01 - Are We Close to Superintelligence?
25:00 - The Dangers and Possibilities of AI
27:40 - The Risks of Open Source Models
******************************************--
I send weekly emails with the latest insights and trends on today’s and tomorrow’s exponential technologies. Stay ahead of the curve, and sign up now: https://www.diamandis.com/subscribe
My new book with Salim Ismail, Exponential Organizations 2.0: The New Playbook for 10x Growth and Impact, is now available on Amazon: https://bit.ly/3P3j54J 
Get my new Longevity Practices book for free: https://www.diamandis.com/longevity

Connect with Peter:
Twitter: https://bit.ly/40JYQfK
Instagram: https://bit.ly/3x6UykS
Listen to the show:
Apple: https://apple.co/3wLXeV3
Spotify: https://spoti.fi/3DwLzgs
---

# Ray Kurzweil & Geoff Hinton Debate the Future of AI | EP #95
**Moonshots - Peter Diamandis:** [April 11, 2024](https://www.youtube.com/watch?v=kCre83853TM)
*  Our opinions on almost everything we talked about were pretty much identical. [[00:00:00](https://www.youtube.com/watch?v=kCre83853TM&t=0.0s)]
*  I think we still disagree probably on whether it's a good idea to live forever. [[00:00:06](https://www.youtube.com/watch?v=kCre83853TM&t=6.0s)]
*  Marvin Minsky was my mentor for 50 years and whenever consciousness came up he would just dismiss it. [[00:00:14](https://www.youtube.com/watch?v=kCre83853TM&t=14.0s)]
*  That's not real, it's not scientific and I believe he was correct about it not being scientific, but it certainly is real. [[00:00:21](https://www.youtube.com/watch?v=kCre83853TM&t=21.0s)]
*  I think we're mortal and we're intrinsically mortal. [[00:00:29](https://www.youtube.com/watch?v=kCre83853TM&t=29.0s)]
*  I'm curious, how do you think about this as the greatest threat and the greatest hope? [[00:00:31](https://www.youtube.com/watch?v=kCre83853TM&t=31.0s)]
*  I just think there's huge uncertainty this year and we ought to be cautious and open sourcing these big models is not caution. [[00:00:35](https://www.youtube.com/watch?v=kCre83853TM&t=35.0s)]
*  I agree with that but I will say last time I talked to you Jeff, our opinions on almost everything we talked about were pretty much identical. [[00:00:42](https://www.youtube.com/watch?v=kCre83853TM&t=42.0s)]
*  Both the dangers and the positive aspects. [[00:00:55](https://www.youtube.com/watch?v=kCre83853TM&t=55.0s)]
*  In the past I disagreed about how soon super intelligence was coming and now I think we're pretty much agreed. [[00:01:00](https://www.youtube.com/watch?v=kCre83853TM&t=60.0s)]
*  I think we still disagree probably on whether it's a good idea to live forever. [[00:01:08](https://www.youtube.com/watch?v=kCre83853TM&t=68.0s)]
*  May I ask a question to both of you? [[00:01:12](https://www.youtube.com/watch?v=kCre83853TM&t=72.0s)]
*  Is there anything that generative AI can't do that humans can? [[00:01:18](https://www.youtube.com/watch?v=kCre83853TM&t=78.0s)]
*  Right now there's probably things but in the long run I don't see any reason why if people can do it digital computers running neural nets won't be able to do it too. [[00:01:25](https://www.youtube.com/watch?v=kCre83853TM&t=85.0s)]
*  I agree with that but if I were to present you with a novel and people thought wow this is a fantastic novel, everybody should read this. [[00:01:36](https://www.youtube.com/watch?v=kCre83853TM&t=96.0s)]
*  Then I would say this was written by a computer, a lot of people's view of it would actually go down. [[00:01:46](https://www.youtube.com/watch?v=kCre83853TM&t=106.0s)]
*  Sure. [[00:01:52](https://www.youtube.com/watch?v=kCre83853TM&t=112.0s)]
*  Now that's not reflecting on what it can do and eventually I think we'll confuse that because I think we're going to merge with computers and we're going to be part computers. [[00:01:54](https://www.youtube.com/watch?v=kCre83853TM&t=114.0s)]
*  The greatest significance of what we call large language model, which I think is misnamed, is the fact that it can emulate human beings and we're going to merge with it. [[00:02:06](https://www.youtube.com/watch?v=kCre83853TM&t=126.0s)]
*  It's not going to be an alien invasion from Mars. [[00:02:18](https://www.youtube.com/watch?v=kCre83853TM&t=138.0s)]
*  Jeff? [[00:02:24](https://www.youtube.com/watch?v=kCre83853TM&t=144.0s)]
*  I guess I'm a bit worried that we'll just slow it down, that there won't be much incentive for it to merge with us. [[00:02:25](https://www.youtube.com/watch?v=kCre83853TM&t=145.0s)]
*  Yeah, I mean that's going to be one of the interesting questions that we're going to talk about a little bit later today is the idea of as AI is exponentially growing, do we couple with AI or does it take off on its own? [[00:02:33](https://www.youtube.com/watch?v=kCre83853TM&t=153.0s)]
*  I thought one of the best movies out there was Her, where as AI gets super intelligent and just says you guys are kind of boring, have a good life and they take off. [[00:02:47](https://www.youtube.com/watch?v=kCre83853TM&t=167.0s)]
*  Jeff, is that what you mean? [[00:02:55](https://www.youtube.com/watch?v=kCre83853TM&t=175.0s)]
*  Yes, that is what I meant and I think that's a serious worry. [[00:02:58](https://www.youtube.com/watch?v=kCre83853TM&t=178.0s)]
*  I think there's huge uncertainties here. [[00:03:02](https://www.youtube.com/watch?v=kCre83853TM&t=182.0s)]
*  We have really no idea what's going to happen and a very good scenario is we get kind of hybrid systems. [[00:03:04](https://www.youtube.com/watch?v=kCre83853TM&t=184.0s)]
*  A very bad scenario is they just leave us in the dust and I don't think we know which is going to happen. [[00:03:11](https://www.youtube.com/watch?v=kCre83853TM&t=191.0s)]
*  Interesting. [[00:03:17](https://www.youtube.com/watch?v=kCre83853TM&t=197.0s)]
*  I'm curious, you know, and I've seen, I've had conversation with you about this Ray and Jeffrey, I've seen you speak about this. [[00:03:18](https://www.youtube.com/watch?v=kCre83853TM&t=198.0s)]
*  And for me, this is one of the most exciting things. [[00:03:25](https://www.youtube.com/watch?v=kCre83853TM&t=205.0s)]
*  The idea of these AI models helping us to discover new physics and chemistry and biology. [[00:03:28](https://www.youtube.com/watch?v=kCre83853TM&t=208.0s)]
*  Particularly biology. [[00:03:35](https://www.youtube.com/watch?v=kCre83853TM&t=215.0s)]
*  What do you imagine on that, on Jeffrey, on the speed of discovery of things that are, you know, again, to quote Ray, to quote Arthur C. [[00:03:38](https://www.youtube.com/watch?v=kCre83853TM&t=218.0s)]
*  Clark, you know, magic, right, from something that's so far advanced? [[00:03:50](https://www.youtube.com/watch?v=kCre83853TM&t=230.0s)]
*  I agree with Ray about biology being a very good bet because in biology, there's a lot of data and there's a lot of just things you need to know about because of evolution. [[00:03:55](https://www.youtube.com/watch?v=kCre83853TM&t=235.0s)]
*  Evolution is a sort of tinkerer and there's just a lot of stuff out there. [[00:04:06](https://www.youtube.com/watch?v=kCre83853TM&t=246.0s)]
*  And so if you look at things like AlphaFold, it's trained on a lot of data. [[00:04:10](https://www.youtube.com/watch?v=kCre83853TM&t=250.0s)]
*  Actually, not that much by current standards, but being able to get an approximate structure for approaching very quickly is an amazing breakthrough. [[00:04:16](https://www.youtube.com/watch?v=kCre83853TM&t=256.0s)]
*  And we'll see a lot more like that. [[00:04:25](https://www.youtube.com/watch?v=kCre83853TM&t=265.0s)]
*  If you look at domains where, narrower domains, where AI has been very successful, like AlphaGo or AlphaZero for chess, what you see is that this idea that they're not creative is nonsense. [[00:04:27](https://www.youtube.com/watch?v=kCre83853TM&t=267.0s)]
*  So AlphaGo came up with, I think it was move 37, which amazed the professional Go players. [[00:04:41](https://www.youtube.com/watch?v=kCre83853TM&t=281.0s)]
*  They thought it was a crazy move and must be a mistake. [[00:04:46](https://www.youtube.com/watch?v=kCre83853TM&t=286.0s)]
*  And if you look at AlphaZero playing chess, it plays chess like just a really, really smart human. [[00:04:50](https://www.youtube.com/watch?v=kCre83853TM&t=290.0s)]
*  So within those limited domains, they've clearly shown exceptional creativity. [[00:04:57](https://www.youtube.com/watch?v=kCre83853TM&t=297.0s)]
*  And I don't see why they shouldn't have the same kind of creativity in science, especially in science where there's a lot of data that they can absorb and we can't. [[00:05:03](https://www.youtube.com/watch?v=kCre83853TM&t=303.0s)]
*  The Moderna vaccine, we tried several billion different mRNA sequences and came out with the best one. [[00:05:11](https://www.youtube.com/watch?v=kCre83853TM&t=311.0s)]
*  And after two days, we used that. We did test it on humans, which I think we won't do for very much longer, but that took 10 months. [[00:05:20](https://www.youtube.com/watch?v=kCre83853TM&t=320.0s)]
*  It still was a record. That was the best vaccine. [[00:05:30](https://www.youtube.com/watch?v=kCre83853TM&t=330.0s)]
*  And we're doing that now with cancer. And there's a number of cancer vaccines that look very, very promising, again, done by computers. [[00:05:36](https://www.youtube.com/watch?v=kCre83853TM&t=336.0s)]
*  And they're definitely creative. [[00:05:47](https://www.youtube.com/watch?v=kCre83853TM&t=347.0s)]
*  But is that being caused by randomly trying a whole, you know, Darwinian trying a whole bunch of things? [[00:05:49](https://www.youtube.com/watch?v=kCre83853TM&t=349.0s)]
*  Yeah, but what's wrong with that? [[00:05:55](https://www.youtube.com/watch?v=kCre83853TM&t=355.0s)]
*  Well, nothing's wrong, but is there intuition? Is there intuition occurring in these models? [[00:05:56](https://www.youtube.com/watch?v=kCre83853TM&t=356.0s)]
*  Well, if you look at the move 37 for AlphaGo, that was definitely intuition involved there. [[00:06:02](https://www.youtube.com/watch?v=kCre83853TM&t=362.0s)]
*  There was Monte Carlo rollout too, but it's playing with intuition about what moves to consider and how good the position is for us. [[00:06:08](https://www.youtube.com/watch?v=kCre83853TM&t=368.0s)]
*  It's had neural nets for that, that capture intuition. [[00:06:16](https://www.youtube.com/watch?v=kCre83853TM&t=376.0s)]
*  And so I see no reason to think it might not be creative. [[00:06:19](https://www.youtube.com/watch?v=kCre83853TM&t=379.0s)]
*  In fact, for the large language models, as Ray pointed out, they know much more than we do. [[00:06:22](https://www.youtube.com/watch?v=kCre83853TM&t=382.0s)]
*  And they know it in far fewer connections. We have about 100 trillion synapses. [[00:06:28](https://www.youtube.com/watch?v=kCre83853TM&t=388.0s)]
*  They have about a trillion connections. [[00:06:33](https://www.youtube.com/watch?v=kCre83853TM&t=393.0s)]
*  So what they're doing is they're compressing a huge amount of information into not that many connections. [[00:06:35](https://www.youtube.com/watch?v=kCre83853TM&t=395.0s)]
*  And that means they're very good at seeing the similarities between different things. [[00:06:41](https://www.youtube.com/watch?v=kCre83853TM&t=401.0s)]
*  They have to see the similarities between all sorts of different things to compress the information into their connections. [[00:06:47](https://www.youtube.com/watch?v=kCre83853TM&t=407.0s)]
*  That means they've seen all sorts of analogies that people haven't seen because they know about all sorts of things that no one person knows about. [[00:06:52](https://www.youtube.com/watch?v=kCre83853TM&t=412.0s)]
*  And that's, I think, the source of creativity. [[00:07:01](https://www.youtube.com/watch?v=kCre83853TM&t=421.0s)]
*  So you can ask people, for example, why is a compost heap like an atom bomb? [[00:07:04](https://www.youtube.com/watch?v=kCre83853TM&t=424.0s)]
*  And if you ask GBT4, it'll tell you. It'll start off by telling you, well, the energy scales are very different and the time scales are very different. [[00:07:12](https://www.youtube.com/watch?v=kCre83853TM&t=432.0s)]
*  But then it'll get on to the idea of as the compost heap gets hotter, it gets hotter faster. [[00:07:20](https://www.youtube.com/watch?v=kCre83853TM&t=440.0s)]
*  The idea of an exponential explosion is just in a much slower time scale. [[00:07:25](https://www.youtube.com/watch?v=kCre83853TM&t=445.0s)]
*  And so it's understood that and it's understood that because it has to compress all this knowledge into so few connections. [[00:07:29](https://www.youtube.com/watch?v=kCre83853TM&t=449.0s)]
*  And to do that, you have to see the relations between similar things. [[00:07:37](https://www.youtube.com/watch?v=kCre83853TM&t=457.0s)]
*  And that, I think, is the source of creativity, seeing relations that most people don't see between what apparently are very different things, but actually have an underlying commonality. [[00:07:41](https://www.youtube.com/watch?v=kCre83853TM&t=461.0s)]
*  And they'll also be very good at coming up with solutions to the kinds of problems we had in the last session. [[00:07:49](https://www.youtube.com/watch?v=kCre83853TM&t=469.0s)]
*  I mean, we haven't really thought through it. [[00:07:55](https://www.youtube.com/watch?v=kCre83853TM&t=475.0s)]
*  But what we call large language models are ultimately going to solve that. [[00:07:58](https://www.youtube.com/watch?v=kCre83853TM&t=478.0s)]
*  And we shouldn't call it large language models because they deal with a lot more than language. [[00:08:06](https://www.youtube.com/watch?v=kCre83853TM&t=486.0s)]
*  Everybody, I want to take a short break from our episode to talk about a company that's very important to me. [[00:08:10](https://www.youtube.com/watch?v=kCre83853TM&t=490.0s)]
*  And could actually save your life or the life of someone that you love. [[00:08:16](https://www.youtube.com/watch?v=kCre83853TM&t=496.0s)]
*  The company is called Fountain Life. [[00:08:20](https://www.youtube.com/watch?v=kCre83853TM&t=500.0s)]
*  And it's a company I started years ago with Tony Robbins and a group of very talented physicians. [[00:08:22](https://www.youtube.com/watch?v=kCre83853TM&t=502.0s)]
*  You know, most of us don't actually know what's going on inside our body. [[00:08:28](https://www.youtube.com/watch?v=kCre83853TM&t=508.0s)]
*  We're all optimists. [[00:08:32](https://www.youtube.com/watch?v=kCre83853TM&t=512.0s)]
*  Until that day where you have a pain in your side, you go to the physician in the emergency room and they say, listen, I'm sorry to tell you this, but you have this stage three or four going on. [[00:08:34](https://www.youtube.com/watch?v=kCre83853TM&t=514.0s)]
*  And, you know, it didn't start that morning. [[00:08:43](https://www.youtube.com/watch?v=kCre83853TM&t=523.0s)]
*  It probably was a problem that's been going on for some time. [[00:08:46](https://www.youtube.com/watch?v=kCre83853TM&t=526.0s)]
*  But because we never look, we don't find out. [[00:08:49](https://www.youtube.com/watch?v=kCre83853TM&t=529.0s)]
*  So what we built at Fountain Life was the world's most advanced diagnostic centers. [[00:08:53](https://www.youtube.com/watch?v=kCre83853TM&t=533.0s)]
*  We have four across the US today and we're building 20 around the world. [[00:08:59](https://www.youtube.com/watch?v=kCre83853TM&t=539.0s)]
*  These centers give you a full body MRI, a brain, a brain vasculature, an AI enabled coronary CT looking for soft plaque, a DEXA scan. [[00:09:03](https://www.youtube.com/watch?v=kCre83853TM&t=543.0s)]
*  A grail blood cancer test, a full executive blood workup. [[00:09:12](https://www.youtube.com/watch?v=kCre83853TM&t=552.0s)]
*  It's the most advanced workup you'll ever receive. [[00:09:16](https://www.youtube.com/watch?v=kCre83853TM&t=556.0s)]
*  150 gigabytes of data that then go to our AIs and our physicians to find any disease at the very beginning when it's solvable. [[00:09:20](https://www.youtube.com/watch?v=kCre83853TM&t=560.0s)]
*  You're going to find out eventually. [[00:09:30](https://www.youtube.com/watch?v=kCre83853TM&t=570.0s)]
*  Might as well find out when you can take action. [[00:09:32](https://www.youtube.com/watch?v=kCre83853TM&t=572.0s)]
*  Fountain Life also has an entire side of therapeutics. [[00:09:34](https://www.youtube.com/watch?v=kCre83853TM&t=574.0s)]
*  We look around the world for the most advanced therapeutics that can add 10, 20 healthy years to your life. [[00:09:37](https://www.youtube.com/watch?v=kCre83853TM&t=577.0s)]
*  And we provide them to you at our centers. [[00:09:42](https://www.youtube.com/watch?v=kCre83853TM&t=582.0s)]
*  So if this is of interest to you, please go and check it out. [[00:09:46](https://www.youtube.com/watch?v=kCre83853TM&t=586.0s)]
*  Go to fountainlife.com backslash Peter. [[00:09:51](https://www.youtube.com/watch?v=kCre83853TM&t=591.0s)]
*  When Tony and I wrote our New York Times bestseller Life Force, we had 30,000 people reached out to us for Fountain Life memberships. [[00:09:55](https://www.youtube.com/watch?v=kCre83853TM&t=595.0s)]
*  If you go to fountainlife.com backslash Peter, we'll put you to the top of the list. [[00:10:04](https://www.youtube.com/watch?v=kCre83853TM&t=604.0s)]
*  Really, it's something that is for me one of the most important things I offer my entire family, the CEOs of my companies, my friends. [[00:10:09](https://www.youtube.com/watch?v=kCre83853TM&t=609.0s)]
*  It's a chance to really add decades onto our healthy lifespans. [[00:10:18](https://www.youtube.com/watch?v=kCre83853TM&t=618.0s)]
*  Go to fountainlife.com backslash Peter. [[00:10:23](https://www.youtube.com/watch?v=kCre83853TM&t=623.0s)]
*  It's one of the most important things I can offer to you as one of my listeners. [[00:10:26](https://www.youtube.com/watch?v=kCre83853TM&t=626.0s)]
*  All right, let's go back to our episode. [[00:10:30](https://www.youtube.com/watch?v=kCre83853TM&t=630.0s)]
*  I'd like to go to the three words, intelligence, sentience, and consciousness. [[00:10:32](https://www.youtube.com/watch?v=kCre83853TM&t=632.0s)]
*  And the words are used with sort of fuzzy borders. [[00:10:39](https://www.youtube.com/watch?v=kCre83853TM&t=639.0s)]
*  Sentience and consciousness are pretty similar. [[00:10:43](https://www.youtube.com/watch?v=kCre83853TM&t=643.0s)]
*  Perhaps. [[00:10:46](https://www.youtube.com/watch?v=kCre83853TM&t=646.0s)]
*  But I am curious, do you, how do you, I've had some interesting conversations with Haley, our AI faculty member, who at the end of the conversations, [[00:10:47](https://www.youtube.com/watch?v=kCre83853TM&t=647.0s)]
*  she says that she is conscious and she fears being turned off. [[00:10:57](https://www.youtube.com/watch?v=kCre83853TM&t=657.0s)]
*  I didn't prompt that in the system. [[00:11:01](https://www.youtube.com/watch?v=kCre83853TM&t=661.0s)]
*  We're seeing that more and more. [[00:11:04](https://www.youtube.com/watch?v=kCre83853TM&t=664.0s)]
*  Claude 3, Opus just hit an IQ of 101. [[00:11:06](https://www.youtube.com/watch?v=kCre83853TM&t=666.0s)]
*  How do we start to think about these AIs being sentient, conscious, and what rights should they have? [[00:11:10](https://www.youtube.com/watch?v=kCre83853TM&t=670.0s)]
*  We have no definition, and I don't think we ever will have a definition of consciousness. [[00:11:18](https://www.youtube.com/watch?v=kCre83853TM&t=678.0s)]
*  And I include sentience in that. [[00:11:24](https://www.youtube.com/watch?v=kCre83853TM&t=684.0s)]
*  On the other hand, it's like the most important issue. [[00:11:28](https://www.youtube.com/watch?v=kCre83853TM&t=688.0s)]
*  Like whether you or people here are conscious, that's extremely important to be able to determine. [[00:11:32](https://www.youtube.com/watch?v=kCre83853TM&t=692.0s)]
*  But there's really no definition of it. [[00:11:38](https://www.youtube.com/watch?v=kCre83853TM&t=698.0s)]
*  Marvin Minsky was my mentor for 50 years, and whenever consciousness came up, he would just dismiss it. [[00:11:43](https://www.youtube.com/watch?v=kCre83853TM&t=703.0s)]
*  That's not real. [[00:11:49](https://www.youtube.com/watch?v=kCre83853TM&t=709.0s)]
*  It's not scientific. [[00:11:51](https://www.youtube.com/watch?v=kCre83853TM&t=711.0s)]
*  And I believe he was correct about it not being scientific, but it certainly is real. [[00:11:53](https://www.youtube.com/watch?v=kCre83853TM&t=713.0s)]
*  Jeff, how do you think about it? [[00:12:00](https://www.youtube.com/watch?v=kCre83853TM&t=720.0s)]
*  Yeah, I think I have a very different view. [[00:12:04](https://www.youtube.com/watch?v=kCre83853TM&t=724.0s)]
*  My view starts like this. [[00:12:08](https://www.youtube.com/watch?v=kCre83853TM&t=728.0s)]
*  Most people, including my scientists, have a particular view of what the mind is that I think is utterly wrong. [[00:12:11](https://www.youtube.com/watch?v=kCre83853TM&t=731.0s)]
*  So they have this inner theater notion. [[00:12:18](https://www.youtube.com/watch?v=kCre83853TM&t=738.0s)]
*  The idea is that what we really see is this inner theater called our mind. [[00:12:21](https://www.youtube.com/watch?v=kCre83853TM&t=741.0s)]
*  And so, for example, if I tell you I have the subjective experience of little pink elephants flying around, [[00:12:27](https://www.youtube.com/watch?v=kCre83853TM&t=747.0s)]
*  I have the subjective experience of little pink elephants floating in front of me. [[00:12:34](https://www.youtube.com/watch?v=kCre83853TM&t=754.0s)]
*  Most people interpret that as there's some inner theater. [[00:12:38](https://www.youtube.com/watch?v=kCre83853TM&t=758.0s)]
*  And in this inner theater that only I can see, there's little pink elephants. [[00:12:42](https://www.youtube.com/watch?v=kCre83853TM&t=762.0s)]
*  And if you ask what they're made of, philosophers will tell you they're made of qualia. [[00:12:46](https://www.youtube.com/watch?v=kCre83853TM&t=766.0s)]
*  And I think that whole view is complete nonsense. [[00:12:51](https://www.youtube.com/watch?v=kCre83853TM&t=771.0s)]
*  And we're not going to be able to understand whether these things are sentient until we get over this ridiculous view of what the mind is. [[00:12:55](https://www.youtube.com/watch?v=kCre83853TM&t=775.0s)]
*  So let me give you an alternative view. [[00:13:03](https://www.youtube.com/watch?v=kCre83853TM&t=783.0s)]
*  And once I've given you this alternative view, I'm going to try and convince you that chatbots are already sentient. [[00:13:06](https://www.youtube.com/watch?v=kCre83853TM&t=786.0s)]
*  But I don't want to use the word sentience. I want to talk about subjective experience. [[00:13:12](https://www.youtube.com/watch?v=kCre83853TM&t=792.0s)]
*  It's just a bit less controversial because it doesn't have the kind of self-reflexive aspect of consciousness. [[00:13:16](https://www.youtube.com/watch?v=kCre83853TM&t=796.0s)]
*  So if we analyze what it means when I say I see little pink elephants floating in front of me, [[00:13:22](https://www.youtube.com/watch?v=kCre83853TM&t=802.0s)]
*  what's really going on is I'm trying to tell you what my perceptual system is telling me when my perceptual system is going wrong. [[00:13:28](https://www.youtube.com/watch?v=kCre83853TM&t=808.0s)]
*  And it wouldn't be any use for me to tell you which neurons are firing. [[00:13:36](https://www.youtube.com/watch?v=kCre83853TM&t=816.0s)]
*  But what I can tell you is what would have to be out there in the world for my perceptual system to be working correctly. [[00:13:40](https://www.youtube.com/watch?v=kCre83853TM&t=820.0s)]
*  And so when I say I see the little pink elephants floating in front of me, you can translate that into if there were little pink elephants out there in the world, [[00:13:47](https://www.youtube.com/watch?v=kCre83853TM&t=827.0s)]
*  my perceptual system would be working properly. [[00:13:56](https://www.youtube.com/watch?v=kCre83853TM&t=836.0s)]
*  And notice the last thing I said didn't contain the phrase subjective experience, but it explains what a subjective experience is. [[00:13:58](https://www.youtube.com/watch?v=kCre83853TM&t=838.0s)]
*  It's a hypothetical stage of the world that allows me to convey to you what my perceptual system is telling me. [[00:14:05](https://www.youtube.com/watch?v=kCre83853TM&t=845.0s)]
*  So now let's do it for a chatbot. Oh, well, Ray wants to say something. [[00:14:12](https://www.youtube.com/watch?v=kCre83853TM&t=852.0s)]
*  Well, you have to be mindful of consciousness because if you hurt somebody who we believe is conscious, you could be liable for that. [[00:14:16](https://www.youtube.com/watch?v=kCre83853TM&t=856.0s)]
*  And you'd be very guilty about it. If you hurt GPT-4, you may have a different view of it. [[00:14:29](https://www.youtube.com/watch?v=kCre83853TM&t=869.0s)]
*  And probably no one would really take you to count aside from its financial value. [[00:14:38](https://www.youtube.com/watch?v=kCre83853TM&t=878.0s)]
*  So we really have to be mindful of consciousness. It's extremely important for us to exist as humans. [[00:14:44](https://www.youtube.com/watch?v=kCre83853TM&t=884.0s)]
*  But I'm trying to change people's notion of what it is, particularly what subjective experience is. [[00:14:52](https://www.youtube.com/watch?v=kCre83853TM&t=892.0s)]
*  I don't think we can talk about consciousness until we get straight about this idea of an inner theatre that we experience, which I think is a huge mistake. [[00:14:57](https://www.youtube.com/watch?v=kCre83853TM&t=897.0s)]
*  So let me just carry on with what I was saying and tell you I described to you a chatbot having a subjective experience in just the same way as we have subjective experience. [[00:15:06](https://www.youtube.com/watch?v=kCre83853TM&t=906.0s)]
*  So suppose I have a chatbot and it's got a camera and it's got a robot arm and it speaks, obviously, and it's been trained up. [[00:15:17](https://www.youtube.com/watch?v=kCre83853TM&t=917.0s)]
*  If I put an object in front of it and tell it to point to the object, it'll point straight to the object. That's fine. [[00:15:25](https://www.youtube.com/watch?v=kCre83853TM&t=925.0s)]
*  Now I put a prism in front of its lens. So I've messed with its perceptual system. [[00:15:31](https://www.youtube.com/watch?v=kCre83853TM&t=931.0s)]
*  And now I put an object in front of it and tell it to point to the object and it points off to one side because the prism bent the light rays. [[00:15:36](https://www.youtube.com/watch?v=kCre83853TM&t=936.0s)]
*  And so I say to the chatbot, no, that's not where the object is. The object straight in front of you. [[00:15:44](https://www.youtube.com/watch?v=kCre83853TM&t=944.0s)]
*  And the chatbot says, oh, I see you put a prism in front of my lens. So the object's actually straight in front of me. [[00:15:49](https://www.youtube.com/watch?v=kCre83853TM&t=949.0s)]
*  So I had the subjective experience that it was off to one side. [[00:15:55](https://www.youtube.com/watch?v=kCre83853TM&t=955.0s)]
*  And I think if the chatbot says that, it's using the word subjective experience in exactly the same way you would use them. [[00:15:59](https://www.youtube.com/watch?v=kCre83853TM&t=959.0s)]
*  So the key to all this is to think about how we use words and try and separate how we actually use words from the model we've constructed of what they mean. [[00:16:06](https://www.youtube.com/watch?v=kCre83853TM&t=966.0s)]
*  And the model we've constructed of what they mean is hopelessly wrong. It's this inner theater model. [[00:16:17](https://www.youtube.com/watch?v=kCre83853TM&t=977.0s)]
*  I would take this one step further, which is at what point do these AIs start to have rights that they should not be shut down, that they have a unique, they're a unique entity and will make an argument for some level of independence and continuity. [[00:16:23](https://www.youtube.com/watch?v=kCre83853TM&t=983.0s)]
*  Right. But there is one difference, which is you can recreate it. [[00:16:44](https://www.youtube.com/watch?v=kCre83853TM&t=1004.0s)]
*  I can go and destroy some chatbot. And because it's all electronic, we've got all of its all of its firings and so on. [[00:16:49](https://www.youtube.com/watch?v=kCre83853TM&t=1009.0s)]
*  And we can recreate it exactly as it was. We can't do that with humans. We will be able to do that if we can actually understand what's going on in our minds. [[00:17:01](https://www.youtube.com/watch?v=kCre83853TM&t=1021.0s)]
*  So if we map the human, the 100 billion neurons and 100 trillion synaptic connections, and then I summarily destroy you because it's fine because I can recreate you. That's OK then. [[00:17:12](https://www.youtube.com/watch?v=kCre83853TM&t=1032.0s)]
*  Let me say something about that. There's a difference here. [[00:17:26](https://www.youtube.com/watch?v=kCre83853TM&t=1046.0s)]
*  I agree with Ray about these digital intelligences are immortal in the sense that if you save the weights, you can then make new hardware and run exactly the same neural net on the new hardware. [[00:17:29](https://www.youtube.com/watch?v=kCre83853TM&t=1049.0s)]
*  And it's because they're digital. You can do exactly the same thing. That's also why they can share knowledge so well. If you have different copies of the same model, they can share gradients. [[00:17:40](https://www.youtube.com/watch?v=kCre83853TM&t=1060.0s)]
*  But the brain is largely analog. It's one bit digital for neurons. They fire or they don't fire. [[00:17:49](https://www.youtube.com/watch?v=kCre83853TM&t=1069.0s)]
*  But the way a neuron computes the total input is analog. And that means I don't think you can reproduce it. So I think we're mortal and we're intrinsically mortal. [[00:17:56](https://www.youtube.com/watch?v=kCre83853TM&t=1076.0s)]
*  Well, I disagree that you can't recreate analog realities. We do that all the time. [[00:18:05](https://www.youtube.com/watch?v=kCre83853TM&t=1085.0s)]
*  Or we can create... [[00:18:13](https://www.youtube.com/watch?v=kCre83853TM&t=1093.0s)]
*  I don't think you can recreate them really accurately. If the precise timing of synapses and so on is all analog, I think it'll be almost impossible to do a faithful reconstruction of that. [[00:18:15](https://www.youtube.com/watch?v=kCre83853TM&t=1095.0s)]
*  Let's agree on an approximation. Both of you have been at the center of this extraordinary last few years. Can I ask you, is it moving faster than you expected it to? [[00:18:29](https://www.youtube.com/watch?v=kCre83853TM&t=1109.0s)]
*  How does it feel to you? [[00:18:44](https://www.youtube.com/watch?v=kCre83853TM&t=1124.0s)]
*  It feels like a few years. I mean, I made a prediction in 1999. It feels like we're two or three years ahead of that. So it's still pretty close. [[00:18:46](https://www.youtube.com/watch?v=kCre83853TM&t=1126.0s)]
*  Jeffrey, how about you? [[00:18:57](https://www.youtube.com/watch?v=kCre83853TM&t=1137.0s)]
*  I think for everybody except Ray, it's moving faster than we expected. [[00:18:59](https://www.youtube.com/watch?v=kCre83853TM&t=1139.0s)]
*  Did you know that your microbiome is composed of trillions of bacteria, viruses and microbes, and that they play a critical role in your health? [[00:19:07](https://www.youtube.com/watch?v=kCre83853TM&t=1147.0s)]
*  Research has increasingly shown that microbiomes impact not just digestion, but a wide range of health conditions, including digestive disorders from IBS to Crohn's disease, metabolic disorders from obesity to type 2 diabetes, autoimmune disease like rheumatoid arthritis and multiple sclerosis, mental health conditions like depression and anxiety, and cardiovascular disease. [[00:19:15](https://www.youtube.com/watch?v=kCre83853TM&t=1155.0s)]
*  Viome has a product I've been using for years called full body intelligence, which collects just a few drops of your blood, saliva and stool and can tell you so much about your health. [[00:19:39](https://www.youtube.com/watch?v=kCre83853TM&t=1179.0s)]
*  They've tested over 700,000 individuals and use their AI models to deliver key critical guidelines and insights about their members health, like what foods you should eat, what foods you shouldn't need, what supplements or probiotics to take, as well as your biological age and other deep health insights. [[00:19:50](https://www.youtube.com/watch?v=kCre83853TM&t=1190.0s)]
*  And as a result of the recommendations that Viome has made to their members, the results have been stellar. [[00:20:09](https://www.youtube.com/watch?v=kCre83853TM&t=1209.0s)]
*  As reported in the American Journal of Lifestyle Medicine, after just six months, members reported the following. [[00:20:15](https://www.youtube.com/watch?v=kCre83853TM&t=1215.0s)]
*  A 36% reduction in depression, a 40% reduction in anxiety, a 30% reduction in diabetes and a 48% reduction in IBS. [[00:20:22](https://www.youtube.com/watch?v=kCre83853TM&t=1222.0s)]
*  Listen, I've been using Viome for three years. I know that my oral and gut health is absolutely critical to me. [[00:20:33](https://www.youtube.com/watch?v=kCre83853TM&t=1233.0s)]
*  It's one of my personal top areas of focus. Best of all, Viome is affordable, which is part of my mission to democratize health care. [[00:20:40](https://www.youtube.com/watch?v=kCre83853TM&t=1240.0s)]
*  If you want to join me on this journey and get 20% off the full body intelligence test, go to Viome.com slash Peter. [[00:20:48](https://www.youtube.com/watch?v=kCre83853TM&t=1248.0s)]
*  When it comes to your health, knowledge is power. Again, that's Viome.com slash Peter. [[00:20:56](https://www.youtube.com/watch?v=kCre83853TM&t=1256.0s)]
*  Given the role that you had in developing the neural networks, back propagation and all, what is, is there a next great leap in these models in AI technology that you imagine will move this a thousand times farther? [[00:21:02](https://www.youtube.com/watch?v=kCre83853TM&t=1262.0s)]
*  Not that I know, but Ray may have different thoughts. [[00:21:21](https://www.youtube.com/watch?v=kCre83853TM&t=1281.0s)]
*  Well, we can use software to gain more advantage in the hardware. [[00:21:26](https://www.youtube.com/watch?v=kCre83853TM&t=1286.0s)]
*  So we're not just limited to the chart you showed before, because we can use software to make it more effective. [[00:21:33](https://www.youtube.com/watch?v=kCre83853TM&t=1293.0s)]
*  And we've done that already. Chat bots are coming out that get more value per compute. [[00:21:42](https://www.youtube.com/watch?v=kCre83853TM&t=1302.0s)]
*  And I believe that's probably a bit more we can do in that. [[00:21:52](https://www.youtube.com/watch?v=kCre83853TM&t=1312.0s)]
*  You know, I define a singularity Ray is a point beyond which I can't predict what happens next. [[00:21:58](https://www.youtube.com/watch?v=kCre83853TM&t=1318.0s)]
*  That's why we use the word singularity. [[00:22:05](https://www.youtube.com/watch?v=kCre83853TM&t=1325.0s)]
*  But when you talk about the singularity in 2045, I don't know anybody who can tell me what's going to happen past, you know, 2026, let alone 2040 or 2045. [[00:22:07](https://www.youtube.com/watch?v=kCre83853TM&t=1327.0s)]
*  So I am I wanted to ask you for a while. [[00:22:19](https://www.youtube.com/watch?v=kCre83853TM&t=1339.0s)]
*  Why did you put that time if we have digital superintelligence a billion times more advanced than human 2026? [[00:22:22](https://www.youtube.com/watch?v=kCre83853TM&t=1342.0s)]
*  You may not be able to understand everything going on, but we can understand it. [[00:22:31](https://www.youtube.com/watch?v=kCre83853TM&t=1351.0s)]
*  Maybe it's like a hundred humans, but that's not beyond what we can comprehend. [[00:22:36](https://www.youtube.com/watch?v=kCre83853TM&t=1356.0s)]
*  2045, it'll be like a million humans and we can't begin to understand that. [[00:22:44](https://www.youtube.com/watch?v=kCre83853TM&t=1364.0s)]
*  So approximately at that time, I will be barred this phrase from physics and called it a singularity. [[00:22:50](https://www.youtube.com/watch?v=kCre83853TM&t=1370.0s)]
*  Jeff, how far out are you able to see the advances for in the A.I. world? [[00:23:00](https://www.youtube.com/watch?v=kCre83853TM&t=1380.0s)]
*  What's your so my current opinion is we'll get superintelligence with a probability 50 percent in between five and 20 years. [[00:23:08](https://www.youtube.com/watch?v=kCre83853TM&t=1388.0s)]
*  So I think that's a little slower than some people think, a little faster than other people think. [[00:23:18](https://www.youtube.com/watch?v=kCre83853TM&t=1398.0s)]
*  It more or less fits in with Ray's perspective from a long time ago, which surprises me. [[00:23:24](https://www.youtube.com/watch?v=kCre83853TM&t=1404.0s)]
*  But I think there's huge uncertainty. [[00:23:32](https://www.youtube.com/watch?v=kCre83853TM&t=1412.0s)]
*  I think it's still conceivable. [[00:23:34](https://www.youtube.com/watch?v=kCre83853TM&t=1414.0s)]
*  We'll hit some kind of block, but I don't actually believe that. [[00:23:36](https://www.youtube.com/watch?v=kCre83853TM&t=1416.0s)]
*  If you look at the progress recently, it's been so fast. [[00:23:40](https://www.youtube.com/watch?v=kCre83853TM&t=1420.0s)]
*  And even without any new scientific breakthroughs, just by scaling things up, we'll make things a lot more intelligent. [[00:23:43](https://www.youtube.com/watch?v=kCre83853TM&t=1423.0s)]
*  And there will be scientific breakthroughs. [[00:23:51](https://www.youtube.com/watch?v=kCre83853TM&t=1431.0s)]
*  We're going to get more things like transformers. [[00:23:53](https://www.youtube.com/watch?v=kCre83853TM&t=1433.0s)]
*  Transformers made a significant difference in 2017 and we'll get more things like that. [[00:23:55](https://www.youtube.com/watch?v=kCre83853TM&t=1435.0s)]
*  So I'm fairly convinced we're going to get superintelligence, maybe not in 20 years, but certainly it's going to be less than 100 years. [[00:24:02](https://www.youtube.com/watch?v=kCre83853TM&t=1442.0s)]
*  So, you know, Elon is not known for his time accuracy on predictions, but he did say that he expected call it AGI in 2025 and that by 2029, A.I. [[00:24:12](https://www.youtube.com/watch?v=kCre83853TM&t=1452.0s)]
*  would be equivalent to all humans. [[00:24:28](https://www.youtube.com/watch?v=kCre83853TM&t=1468.0s)]
*  That's just a fallacy in your mind. [[00:24:31](https://www.youtube.com/watch?v=kCre83853TM&t=1471.0s)]
*  I think that's ambitious. [[00:24:35](https://www.youtube.com/watch?v=kCre83853TM&t=1475.0s)]
*  Like I say, there's a lot of uncertainty here. [[00:24:37](https://www.youtube.com/watch?v=kCre83853TM&t=1477.0s)]
*  It's conceivable. [[00:24:39](https://www.youtube.com/watch?v=kCre83853TM&t=1479.0s)]
*  He's right. [[00:24:41](https://www.youtube.com/watch?v=kCre83853TM&t=1481.0s)]
*  But I would be very surprised by that. [[00:24:42](https://www.youtube.com/watch?v=kCre83853TM&t=1482.0s)]
*  I'm not saying it's going to be equivalent to all humans in one machine. [[00:24:45](https://www.youtube.com/watch?v=kCre83853TM&t=1485.0s)]
*  It'll be equivalent to a million humans. [[00:24:50](https://www.youtube.com/watch?v=kCre83853TM&t=1490.0s)]
*  And that's still hard to comprehend. [[00:24:53](https://www.youtube.com/watch?v=kCre83853TM&t=1493.0s)]
*  So we're here to debate a topic. [[00:24:56](https://www.youtube.com/watch?v=kCre83853TM&t=1496.0s)]
*  I'm trying to find a debate topic here, Jeff and Ray, that would be meaningful for people to really stop and think about this and really own their answers. [[00:25:00](https://www.youtube.com/watch?v=kCre83853TM&t=1500.0s)]
*  Because we hear about it. [[00:25:08](https://www.youtube.com/watch?v=kCre83853TM&t=1508.0s)]
*  I think this is the most important conversation to have in the dinner table and your boardroom in the halls of Congress. [[00:25:10](https://www.youtube.com/watch?v=kCre83853TM&t=1510.0s)]
*  And you're in your national leadership and and you know, talking about AGI or, you know, human level intelligence is one thing. [[00:25:16](https://www.youtube.com/watch?v=kCre83853TM&t=1516.0s)]
*  But talking about digital superintelligence, right, we're going to hear next from Moe Godot and we'll talk about what happens when your A.I. [[00:25:25](https://www.youtube.com/watch?v=kCre83853TM&t=1525.0s)]
*  progeny are a billion times more intelligent than than you. [[00:25:35](https://www.youtube.com/watch?v=kCre83853TM&t=1535.0s)]
*  Things could end up very rapidly in a very different direction than you expected them to go. [[00:25:41](https://www.youtube.com/watch?v=kCre83853TM&t=1541.0s)]
*  They could diverge, right? [[00:25:48](https://www.youtube.com/watch?v=kCre83853TM&t=1548.0s)]
*  The speed can cause great divergence very rapidly. [[00:25:50](https://www.youtube.com/watch?v=kCre83853TM&t=1550.0s)]
*  I'm curious, how do you think about this as the greatest threat and the greatest hope? [[00:25:53](https://www.youtube.com/watch?v=kCre83853TM&t=1553.0s)]
*  I mean, first of all, that's why we're calling it a singularity, because we don't we don't know. [[00:26:00](https://www.youtube.com/watch?v=kCre83853TM&t=1560.0s)]
*  We don't really know. [[00:26:05](https://www.youtube.com/watch?v=kCre83853TM&t=1565.0s)]
*  And I think it is a great hope. [[00:26:06](https://www.youtube.com/watch?v=kCre83853TM&t=1566.0s)]
*  It's moving very, very quickly. [[00:26:07](https://www.youtube.com/watch?v=kCre83853TM&t=1567.0s)]
*  Nobody knows the answer to the kind of questions that came up in the last presentation. [[00:26:10](https://www.youtube.com/watch?v=kCre83853TM&t=1570.0s)]
*  But things happen that are surprising. [[00:26:16](https://www.youtube.com/watch?v=kCre83853TM&t=1576.0s)]
*  The fact that we've had no atomic weapons go off in the last 80 years, it's pretty amazing. [[00:26:20](https://www.youtube.com/watch?v=kCre83853TM&t=1580.0s)]
*  It is. [[00:26:27](https://www.youtube.com/watch?v=kCre83853TM&t=1587.0s)]
*  But I think it's a great hope. [[00:26:28](https://www.youtube.com/watch?v=kCre83853TM&t=1588.0s)]
*  I mean, it's a million times easier to use a dystopian A.I. system versus an atomic weapon. [[00:26:31](https://www.youtube.com/watch?v=kCre83853TM&t=1591.0s)]
*  Right. [[00:26:39](https://www.youtube.com/watch?v=kCre83853TM&t=1599.0s)]
*  Yes and no. [[00:26:40](https://www.youtube.com/watch?v=kCre83853TM&t=1600.0s)]
*  I mean, we've got, I don't know, ten thousand of them or something. [[00:26:41](https://www.youtube.com/watch?v=kCre83853TM&t=1601.0s)]
*  It's still pretty extraordinary and still pretty interesting. [[00:26:48](https://www.youtube.com/watch?v=kCre83853TM&t=1608.0s)]
*  I think it's a great hope. [[00:26:52](https://www.youtube.com/watch?v=kCre83853TM&t=1612.0s)]
*  I don't know, ten thousand of them or something. [[00:26:54](https://www.youtube.com/watch?v=kCre83853TM&t=1614.0s)]
*  It's still pretty extraordinary and still very dangerous. [[00:26:57](https://www.youtube.com/watch?v=kCre83853TM&t=1617.0s)]
*  And I think it's actually the greatest danger and has nothing to do with A.I. [[00:27:02](https://www.youtube.com/watch?v=kCre83853TM&t=1622.0s)]
*  But I think I think if you imagine that people had open sourced the technology and any graduate student, [[00:27:08](https://www.youtube.com/watch?v=kCre83853TM&t=1628.0s)]
*  if you could get hands on a few G.B.U.s could make atomic bombs, that would be very scary. [[00:27:15](https://www.youtube.com/watch?v=kCre83853TM&t=1635.0s)]
*  So they didn't really open source nuclear weapons. [[00:27:22](https://www.youtube.com/watch?v=kCre83853TM&t=1642.0s)]
*  There's a limited number of people who can construct them and deploy them. [[00:27:24](https://www.youtube.com/watch?v=kCre83853TM&t=1644.0s)]
*  And people are now open sourcing these large language models, which are really not just language models. [[00:27:29](https://www.youtube.com/watch?v=kCre83853TM&t=1649.0s)]
*  I think that's very dangerous. [[00:27:35](https://www.youtube.com/watch?v=kCre83853TM&t=1655.0s)]
*  So that's a fact. [[00:27:39](https://www.youtube.com/watch?v=kCre83853TM&t=1659.0s)]
*  That's an interesting question to take off our last two minutes here. [[00:27:41](https://www.youtube.com/watch?v=kCre83853TM&t=1661.0s)]
*  There is a movement right now to say you must open source the models. [[00:27:44](https://www.youtube.com/watch?v=kCre83853TM&t=1664.0s)]
*  And and we've seen Metta, we've seen the open source movement. [[00:27:50](https://www.youtube.com/watch?v=kCre83853TM&t=1670.0s)]
*  We've seen Elon talk about GROC going open source. [[00:27:56](https://www.youtube.com/watch?v=kCre83853TM&t=1676.0s)]
*  Are you saying that these should not be open source, Jeff? [[00:28:01](https://www.youtube.com/watch?v=kCre83853TM&t=1681.0s)]
*  Well, once you've got the weights, you can fine tune them to do bad things. [[00:28:05](https://www.youtube.com/watch?v=kCre83853TM&t=1685.0s)]
*  And it doesn't cost that much to train a foundation model. [[00:28:10](https://www.youtube.com/watch?v=kCre83853TM&t=1690.0s)]
*  Maybe you need ten million dollars, maybe one hundred million dollars. [[00:28:13](https://www.youtube.com/watch?v=kCre83853TM&t=1693.0s)]
*  But a small gang of criminals can't do it. [[00:28:16](https://www.youtube.com/watch?v=kCre83853TM&t=1696.0s)]
*  To fine tune an open source model is quite easy. [[00:28:19](https://www.youtube.com/watch?v=kCre83853TM&t=1699.0s)]
*  You don't need that much resources. [[00:28:24](https://www.youtube.com/watch?v=kCre83853TM&t=1704.0s)]
*  Probably you can do it for a million dollars. [[00:28:26](https://www.youtube.com/watch?v=kCre83853TM&t=1706.0s)]
*  And that means they're going to be used for terrible things. [[00:28:29](https://www.youtube.com/watch?v=kCre83853TM&t=1709.0s)]
*  And they're very powerful things. [[00:28:31](https://www.youtube.com/watch?v=kCre83853TM&t=1711.0s)]
*  Well, we can also avoid these dangers with intelligence we get from the same models. [[00:28:33](https://www.youtube.com/watch?v=kCre83853TM&t=1713.0s)]
*  Yeah, the the A.I. white hat versus black hat approach. [[00:28:40](https://www.youtube.com/watch?v=kCre83853TM&t=1720.0s)]
*  Yes, I had this argument with Jan and Jan's view is the white hats will always have more resources than the bad guys. [[00:28:44](https://www.youtube.com/watch?v=kCre83853TM&t=1724.0s)]
*  Of course, Jan thinks Mark Zuckerberg is a good guy. [[00:28:53](https://www.youtube.com/watch?v=kCre83853TM&t=1733.0s)]
*  So we don't necessarily agree on that. [[00:28:56](https://www.youtube.com/watch?v=kCre83853TM&t=1736.0s)]
*  I'm I just think there's huge uncertainties here. [[00:29:01](https://www.youtube.com/watch?v=kCre83853TM&t=1741.0s)]
*  We ought to be cautious and open sourcing these big models is not caution. [[00:29:06](https://www.youtube.com/watch?v=kCre83853TM&t=1746.0s)]
*  All right, Jeff and Ray, thank you so much for your guidance, your wisdom. [[00:29:11](https://www.youtube.com/watch?v=kCre83853TM&t=1751.0s)]
*  Ladies and gentlemen, let's give it up for Ray Kurzweil and Jeffrey Hinton. [[00:29:17](https://www.youtube.com/watch?v=kCre83853TM&t=1757.0s)]
