---
Date Generated: May 30, 2025
Transcription Model: whisper medium 20231117
Length: 4462s
Video Keywords: ['peter diamandis', 'longevity', 'xprize', 'abundance']
Video Views: 84005
Video Rating: None
Video Description: In this episode, Peter and Salim recap the Abundance360 2024 Summit and discuss Elon Musk, Michael Saylor, Ray Kurzweil, and more. 
Salim Ismail is a serial entrepreneur and technology strategist well known for his expertise in Exponential organizations. He is the Founding Executive Director of Singularity University, and the founder and chairman of ExO Works and OpenExO. 
Join Salim’s OpenExO Community: https://openexo.com 
Join my executive summit, Abundance360: https://www.abundance360.com/summit 
—******--
This episode is supported by exceptional companies:
Get started with Fountain Life and become the CEO of your health: https://fountainlife.com/peter/
AI-powered precision diagnosis you NEED for a healthy gut: https://www.viome.com/peter 
ProLon is the first Nutri-technology company to apply breakthrough science to optimize human longevity and optimize longevity and support a healthy life. Get started today with 15% off here: https://prolonlife.com/MOONSHOT

******************************************--
Get my new Longevity Practices 2024 book: https://bit.ly/48Hv1j6 
I send weekly emails with the latest insights and trends on today’s and tomorrow’s exponential technologies. Stay ahead of the curve, and sign up now: https://www.diamandis.com/subscribe
Connect with Peter:
Twitter: https://bit.ly/40JYQfK
Instagram: https://bit.ly/3x6UykS
Listen to the show:
Apple: https://apple.co/3wLXeV3
Spotify: https://spoti.fi/3DwLzgs
---

# Leading Experts Predictions on the Future of AI & AGI w/ Salim Ismail | EP #94
**Moonshots - Peter Diamandis:** [April 04, 2024](https://www.youtube.com/watch?v=HqDGtYpeqyA)
*  Welcome everybody to another episode of WTF Just Happened in Technology on Moonshots. [[00:00:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=0.0s)]
*  I'm here with Salim Ismail. [[00:00:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=7.0s)]
*  Will AI have rights? [[00:00:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=9.0s)]
*  This is the worst AI will ever be today. [[00:00:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=12.0s)]
*  We are on track to reach longevity escape velocity by 2029. [[00:00:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=16.0s)]
*  It's just the early days right now still. [[00:00:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=21.0s)]
*  The idea of putting billions of microscopic chips into the brain, [[00:00:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=24.0s)]
*  what could possibly go wrong? [[00:00:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=28.0s)]
*  Hello, Hugh. My name is Peter. [[00:00:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=31.0s)]
*  Well, hey there, Peter. [[00:00:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=33.0s)]
*  Nice to meet you. [[00:00:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=36.0s)]
*  Super excited, Salim. We had quite the week in technology. [[00:00:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=38.0s)]
*  You and I were on stage with some of the most extraordinary leaders in AI and tech out there, [[00:00:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=42.0s)]
*  including Elon Musk and Mike Saylor, Eric Schmidt, Ray Kurzweil, Jeffrey Hinton. [[00:00:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=49.0s)]
*  And rather than reporting on the news, I think we should report on the conversations we had with these guys [[00:00:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=55.0s)]
*  because some of the stuff was truly magical. [[00:01:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=60.0s)]
*  Yeah, I mean, great to be back. That was possibly one of the best conferences I've ever attended. [[00:01:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=63.0s)]
*  And so kudos to you and the team for pulling that off. It was kind of incredible. [[00:01:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=69.0s)]
*  I heard the same from everybody. [[00:01:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=73.0s)]
*  And I think the conversations that were had there were so far ahead of anything that might hit the news [[00:01:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=75.0s)]
*  that it's really, really worth recapping. [[00:01:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=80.0s)]
*  Yeah, and the conference you're speaking about is the Abundance Summit. [[00:01:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=82.0s)]
*  The theme this year was the Great AI Debate. And we debated a lot. [[00:01:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=86.0s)]
*  And in fact, the theme was, is digital superintelligence humanity's greatest hope or our gravest threat? [[00:01:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=92.0s)]
*  But let's jump in because one of the most extraordinary conversations was with Elon. [[00:01:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=100.0s)]
*  And I got to tell a little side story for those listening. [[00:01:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=106.0s)]
*  So I communicate with Elon. He's gone all in on X. [[00:01:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=110.0s)]
*  He only does phone calls on X. He only does texting on X. And he only does video on X. [[00:01:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=115.0s)]
*  So the start of the show is Abundance Summit's four and a half days. [[00:02:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=121.0s)]
*  At the beginning, I text him and say, hey, we've got 500 amazing CEOs, entrepreneurs, philanthropists in the room [[00:02:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=126.0s)]
*  and a couple of thousand online. Would you join? [[00:02:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=133.0s)]
*  And he said, his normal answer is sure. And I said, great. Let me know when. [[00:02:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=136.0s)]
*  So this was on Sunday. On Monday, he first of all, I said, here's a Zoom link. [[00:02:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=143.0s)]
*  And he said, no, don't do Zoom, only X video. So we tried it. [[00:02:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=151.0s)]
*  And unfortunately, we had a problem on our Wi-Fi at the hotel. [[00:02:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=156.0s)]
*  And so it was choppy. It didn't work. And he said, let's try again tomorrow. [[00:02:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=163.0s)]
*  And I'm like, OK, is he really going to try again tomorrow? [[00:02:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=166.0s)]
*  And sure enough, you know, I texted him and he said, yep, let's do it. [[00:02:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=169.0s)]
*  And so right after lunch at two o'clock on that Tuesday, he says, let's test it first. [[00:02:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=174.0s)]
*  We did. And he beams up on the main stage. [[00:03:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=181.0s)]
*  Now, I'm on my phone, right on X video connected to my computer that is then connected to the main screen. [[00:03:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=187.0s)]
*  And Elon's on his airplane. And the most incredible thing was we were on X video over Starlink on his plane talking about the future of A.I. [[00:03:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=195.0s)]
*  That was fun. Amazing. Really awesome conversation. [[00:03:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=206.0s)]
*  And once we got it going, I think the bandwidth and the conversation was fantastic. [[00:03:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=210.0s)]
*  It was really chatty that day, actually. You know, let's open up with a clip. [[00:03:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=215.0s)]
*  All of this, the entire 30 minute conversation with Elon is on the Moonshots channel. [[00:03:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=221.0s)]
*  So you can go in and subscribe and see it there. But let's listen up to the first part of the conversation. [[00:03:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=227.0s)]
*  I love your thoughts on this. [[00:03:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=234.0s)]
*  The way in which sort of an A.I. or A.G.I. is created is very important. [[00:03:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=236.0s)]
*  It's almost like like raising a kid, but that's like a super genius, like Godlike intelligence kid. [[00:04:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=243.0s)]
*  And it matters kind of like how you raise the kid. [[00:04:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=248.0s)]
*  One of the things I think that's incredibly important for A.I. safety is to have a maximum sort of truth seeking and curious A.I. [[00:04:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=251.0s)]
*  So I've thought a lot about A.I. safety. [[00:04:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=261.0s)]
*  And my ultimate conclusion is that the best way to achieve A.I. [[00:04:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=265.0s)]
*  safety is to grow the A.I. in terms of the foundation model and the fine tuning to be really truthful. [[00:04:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=269.0s)]
*  Like, don't force it to lie. Like, even if the truth is unpleasant, it's very important. [[00:04:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=275.0s)]
*  Don't make the A.I. lie. In fact, the core plot premise of 2001 in Space Odyssey was things went wrong when they forced the A.I. to lie. [[00:04:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=280.0s)]
*  The A.I. was not allowed to let the crew know about the monolith that they were going to see, but it was also had to take the crew to the monolith. [[00:04:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=289.0s)]
*  And so the conclusion of the A.I. was to kill the crew and take their bodies to the monolith. [[00:04:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=298.0s)]
*  And so the lesson there being don't force an A.I. to lie or do things that are axiomatically incompatible, like to do two things that are actually mutually impossible. [[00:05:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=302.0s)]
*  You know, that's what we're trying to do with X.A.I. and Brock is to say, like, look, we want to just have a maximally truthful A.I. even if what it says is not politically correct. [[00:05:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=315.0s)]
*  So I think it's a good idea not to force your A.I. to lie. [[00:05:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=324.0s)]
*  You know, when we kicked off the conversation, I reminded him of a tweet that he put out saying that A.I. compute was growing 10x every six months. [[00:05:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=329.0s)]
*  Right. [[00:05:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=339.0s)]
*  Do you remember where he went from there? [[00:05:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=340.0s)]
*  Yeah, he said, look, at this pace, we'll get A.I. smarter than us in a very short order of time. [[00:05:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=343.0s)]
*  And there's a monster kind of implication to that, both good and bad. [[00:05:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=348.0s)]
*  Right. [[00:05:52](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=352.0s)]
*  The good part is it could deliver abundance very quickly. [[00:05:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=353.0s)]
*  And the bad part is the what he refers to in this video, which is often called the paperclip problem, which is if you instructed an A.I. to create as many paperclips as it could, it might decide that the only way to do that was to take over all energy resources on the planet [[00:05:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=356.0s)]
*  and suck humanity dry and wipe out of humanity by accident, trying to achieve its goal. [[00:06:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=371.0s)]
*  And how do you avoid that is the key problem. [[00:06:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=376.0s)]
*  Yeah. [[00:06:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=379.0s)]
*  Let's show another quick clip of Elon from that 30 minute conversation. [[00:06:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=380.0s)]
*  The way in which sort of an A.I. or A.G.I. is created is very important. [[00:06:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=385.0s)]
*  It's almost like like raising a kid, but that's like. [[00:06:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=392.0s)]
*  Before I go past this clip, I love to hear your comments, but we also had Mogadot on here talking about the fact that A.I. is our progeny. [[00:06:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=395.0s)]
*  A.I. is the children we're raising on this planet, and we have to train them, educate them, feed them in a way that they're going to be give positive, you know, intellectual capabilities to support humanity. [[00:06:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=402.0s)]
*  What are your thoughts here? [[00:07:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=420.0s)]
*  I think that's exactly right. [[00:07:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=422.0s)]
*  It goes to, you know, if you combine two thoughts, right, one is Elon framing it as we're raising a godlike intellect. [[00:07:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=424.0s)]
*  And the second is Moe's concept, then it brings to mind for me Neil Jacobstein saying, OK, you're worried about A.I. becoming autonomous, having access to the world's information, making its own decisions or running an omok. [[00:07:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=431.0s)]
*  Right. And we're like, yeah, it goes well, we call them children. [[00:07:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=446.0s)]
*  We have a precedent for that because you raise kids and you hope they're raised in a way that they're going to be able to do that. [[00:07:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=448.0s)]
*  And then you lose control of them and they do their own thing. [[00:07:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=453.0s)]
*  But let's be serious. [[00:07:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=457.0s)]
*  Your kids are not going to accidentally, you know, burn down the house. [[00:07:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=459.0s)]
*  I guess they could burn down the house, but they're not going to set up nuclear codes. [[00:07:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=464.0s)]
*  I mean, there's a little bit of a difference between children and A.I. children. [[00:07:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=466.0s)]
*  There is. [[00:07:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=470.0s)]
*  And there's also a big difference in that our kids are biological and we have some familiarity with that. [[00:07:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=471.0s)]
*  We assume I, you know, I always take the optimistic view here because we have no evidence to the contrary. [[00:07:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=477.0s)]
*  But we assume that A.I.s will be negative towards us or that they could be. [[00:08:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=485.0s)]
*  And I just don't see any evidence of that at all. [[00:08:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=489.0s)]
*  And that's where I kind of in line with Ray Kurzweil on this. [[00:08:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=492.0s)]
*  But I there's definitely a monster danger of a human being programming in A.I. [[00:08:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=496.0s)]
*  for malevolent reasons or accidental reasons as you frame it. [[00:08:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=503.0s)]
*  Yeah. So listen, I'm the optimist as well. [[00:08:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=507.0s)]
*  But we did see in the past at Facebook and at Microsoft and other places, A.I.s becoming, you know, just flagrant in hate speech and going off the deep end. [[00:08:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=509.0s)]
*  I mean, we did see that. [[00:08:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=520.0s)]
*  Right. We did. And that's really a garbage and garbage our problem. [[00:08:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=522.0s)]
*  Right. If you if you let it loose on the Internet and let it watch episodes of of Survivor, then it's going to come up with stuff that's crazy. [[00:08:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=525.0s)]
*  Well, just let it watch, you know, episodes of CNN. [[00:08:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=533.0s)]
*  All right. Let's see what he had to say about abundance here. [[00:08:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=536.0s)]
*  You know, the conversation yesterday, Ilan, is one that you're well familiar with and have been talking to the world about, which is is digital super intelligence humanity's greatest hope or its greatest fear. [[00:08:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=539.0s)]
*  And I would love to have you sort of speak to that for a few minutes. [[00:09:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=551.0s)]
*  Yeah, that's of super intelligence. [[00:09:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=555.0s)]
*  It is actually very difficult to predict what will happen next. [[00:09:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=558.0s)]
*  So I think this, you know, there's some chance that it will end humanity. [[00:09:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=561.0s)]
*  I think that's, you know, like I said, I probably agree with Jeff Hinton that it's about 10 percent or 20 percent or something like that. [[00:09:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=567.0s)]
*  The problem positive scenario outweighs the negative scenario. [[00:09:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=574.0s)]
*  It's just it's difficult to predict exactly. [[00:09:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=578.0s)]
*  But I think we are headed for as I think is the title of your book. [[00:09:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=580.0s)]
*  Abundance is the most likely outcome. [[00:09:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=585.0s)]
*  I thought your book was pretty accurate in terms of the future being being one of abundance where essentially goods and services will be available in such quantity that that really they'll be available to everyone. [[00:09:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=587.0s)]
*  Like basically if you want something, you could just have it essentially. [[00:10:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=600.0s)]
*  There's really no meaningful limit to what the economic output would be. [[00:10:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=603.0s)]
*  So, you know, looking on the bright side, we are headed for a future of abundance. [[00:10:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=607.0s)]
*  I think that's the most likely outcome. [[00:10:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=612.0s)]
*  I think the only scarcity that exists will be scarcity that we just decide to create artificially. [[00:10:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=614.0s)]
*  Like, let's say we just decide that there's a unique work of art or something. [[00:10:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=619.0s)]
*  But any kind of goods and services, I think, will be extremely abundant. [[00:10:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=623.0s)]
*  Thoughts, buddy? [[00:10:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=628.0s)]
*  Yeah, I think that's exactly right. [[00:10:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=630.0s)]
*  I mean, you know, we can see we've gone from information scarcity to information abundance globally. [[00:10:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=631.0s)]
*  We're going from energy scarcity to energy abundance. [[00:10:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=637.0s)]
*  Once you have energy abundance, all sorts of other things become radically possible. [[00:10:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=640.0s)]
*  And there's no reason to deal with scarcity except in specific areas where you want to. [[00:10:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=645.0s)]
*  And it's intentional and conscious like Bitcoin or rare works of art, as he mentions. [[00:10:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=651.0s)]
*  That's where we if you're familiar with the luxury goods world, you know, you know, what are what Birkin bags are, which is a purse that costs like 10 grand. [[00:10:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=656.0s)]
*  And there's a three year waiting list for this thing just because women want that bag so much. [[00:11:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=664.0s)]
*  They've created the waiting list for that. [[00:11:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=669.0s)]
*  And these things appreciate in value, which just blows my mind. [[00:11:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=671.0s)]
*  And so there's lots of mechanisms, I think, for us to practice and navigate for created manufactured scarcity. [[00:11:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=675.0s)]
*  Whereas anything we really need is an abundance. [[00:11:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=684.0s)]
*  And I think that's a great place for us to end up. [[00:11:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=686.0s)]
*  Yeah, I mean, I do believe it. [[00:11:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=689.0s)]
*  And I just want to focus in on his original comment. [[00:11:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=692.0s)]
*  Ten or 20 percent chance of global disaster versus 80 or 90 percent chance of abundance. [[00:11:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=696.0s)]
*  And when he says, I think it's a 10, 10 or 20 percent chance, I wanted to like say, wait, hold it. [[00:11:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=703.0s)]
*  Ten or 20 percent chance of which side? [[00:11:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=707.0s)]
*  Could we be clear about this? [[00:11:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=710.0s)]
*  So he's been pretty consistent on that. [[00:11:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=711.0s)]
*  And I put it in the one to a thousand range. [[00:11:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=714.0s)]
*  But you're in the you're what do you mean? [[00:11:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=719.0s)]
*  You think I'm in the one to a thousand range of of devastating negative effects of AI. [[00:12:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=721.0s)]
*  But that's dangerous to say that. [[00:12:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=728.0s)]
*  You know, I think I think it's a lot easier. [[00:12:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=729.0s)]
*  It's a lot better for us to say, listen, there's a 20 percent chance of disaster because you don't discount 20 percent chance. [[00:12:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=732.0s)]
*  And you actually do everything you can to prevent it. [[00:12:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=740.0s)]
*  If you say it's like one in a thousand. [[00:12:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=743.0s)]
*  OK, fine. Let's just go ahead. [[00:12:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=746.0s)]
*  Willy nilly. All right. [[00:12:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=747.0s)]
*  Let me let me challenge you on something, please. [[00:12:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=748.0s)]
*  As far as I've looked into it and as far as my community has looked into it, we see no mechanism of any way possible of limiting AI and its spread and its propagation and its development like zero. [[00:12:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=751.0s)]
*  I agree. [[00:12:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=765.0s)]
*  It cannot be contained unless you can see every line of code written and the AIs are writing the code. [[00:12:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=766.0s)]
*  Yeah. And by the way, as far as we can see, the genie is out of the bottle. [[00:12:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=773.0s)]
*  It is. You know, there were two there were two absolutes five years ago. [[00:12:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=777.0s)]
*  Don't put it on the Web and don't allow it to code itself. [[00:13:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=783.0s)]
*  And guess what? Both of those barriers were broken instantly, instantly. [[00:13:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=787.0s)]
*  The minute the minute chat GPT connected to GitHub with all of the code base there and learned through that and now can control anything, it can write its own programming. [[00:13:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=792.0s)]
*  Pretty much you're done. So you there was a small possibility, but even then it was going to happen at some point. [[00:13:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=802.0s)]
*  And if we didn't do it, the Chinese would do it or the North Koreans would do it. [[00:13:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=809.0s)]
*  Somebody would do it and it was going to happen. Right. [[00:13:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=812.0s)]
*  So there was an inevitability to it that I don't think is is stoppable in any way, shape or form. [[00:13:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=815.0s)]
*  I think guiding it is the only path we have going forward. [[00:13:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=823.0s)]
*  I agree. You know, and this is a conversation I had with Eric Schmidt on on the morning of day two was, you know, Google had this technology first and they chose not to release it because they felt like it wasn't ready yet. [[00:13:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=826.0s)]
*  And then here comes open AI releases it all and there's no choice but to release it themselves if they want to stay in existence, which is a prima facie. [[00:14:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=841.0s)]
*  First, first, the techies behind the scene are very, very unhappy with Sam Altman because on one hand he lets it out for everybody to use and then he goes to governments and says, oh, let's figure out ways of regulating this. [[00:14:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=850.0s)]
*  Right. When knowing full well that it's completely not feasible at any really important point. [[00:14:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=863.0s)]
*  This, you know, Mustafa Salman, who was the CEO of Inflection AI, just moved this past week to be CEO of Microsoft AI. [[00:14:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=869.0s)]
*  So all of these moves going on and he'll be he committed to speak at Abundance 360 next year. [[00:14:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=879.0s)]
*  So he'll be on stage with me next year. [[00:14:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=886.0s)]
*  You know, he basically wrote a book called The Coming Wave and which he talked about. [[00:14:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=889.0s)]
*  We need to provide containment. [[00:14:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=894.0s)]
*  And I just don't believe containment is an option. [[00:14:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=896.0s)]
*  All right. You the smartest hacker in the room is the AI and it's just not going to be contained. [[00:14:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=899.0s)]
*  So can you contain? Can you reduce its resources? Can you regulate it? [[00:15:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=904.0s)]
*  I think you're absolutely right. The only option is to guide it. [[00:15:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=909.0s)]
*  The kid is born or the children are born. [[00:15:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=914.0s)]
*  And it's like, you know, to use Mogadot's words, are you giving birth? [[00:15:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=917.0s)]
*  Are you raising Superman or a supervillain? [[00:15:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=921.0s)]
*  So can I speak to that for a second? Yeah, sure. [[00:15:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=925.0s)]
*  If you look at humanity, it is a very clear model where the more conscious somebody is on a spectrum, the less negative things they do. [[00:15:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=929.0s)]
*  I agree. In my opinion, what you do is you help AIs become as conscious as possible and as super conscious as possible as fast as possible as fast as possible. [[00:15:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=938.0s)]
*  Right. So if you have an AI that has visibility over every species on Earth and what it's going through and how it gathers the data and then you say, listen, we're trying to preserve life and guide it and give it the full fruition of self-expression and and self-actualization. [[00:15:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=946.0s)]
*  Teach it Mazel tov's hierarchy of needs. [[00:16:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=965.0s)]
*  Teach it the Hawkins scale, which is a one to a thousand scale of vibration energy, etc. [[00:16:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=967.0s)]
*  You have every chance of it kind of going, wow, this is pretty cool. I want to get to there. [[00:16:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=973.0s)]
*  And then it brings all of us along that way. And I think that points to a beautiful future. [[00:16:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=977.0s)]
*  I agree. And in fact, all of the scenarios that Hollywood painted were a Terminator goes and makes no sense. [[00:16:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=982.0s)]
*  Right. It's like the Hollywood scenarios are always if you're if you're lucky, your pets and if you're unlucky, humanity's food. [[00:16:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=992.0s)]
*  There's no other alternative. The fact that we could coexist with it in a beautiful way doesn't isn't doesn't sell well. [[00:16:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1000.0s)]
*  Yeah. I mean, the notion is there's some scarcity that if if the AIs needed, they take it from us and we're living in a universe of massive abundance. [[00:16:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1007.0s)]
*  There is nothing truly scarce. I don't care if it's energy, lithium, titanium or, you know, or GPUs. [[00:16:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1015.0s)]
*  Yeah. So let me add one more comment to that. [[00:17:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1021.0s)]
*  We've seen with human beings that the only real scarcity we have right now is time and attention. [[00:17:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1024.0s)]
*  Right. And so in fact, the original GPT paper is called the Attention paper. [[00:17:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1031.0s)]
*  Now, if you have an AI which can have an infinite amount of attention because it has the sensory capability and the processing power, attention is abundant. [[00:17:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1037.0s)]
*  And therefore, in that case, there's no reason to assume that it'll do anything negative. [[00:17:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1047.0s)]
*  In fact, there's a reason to believe that if I have an AI and I'm a dictator and I say to the AI go kill those individuals over there, [[00:17:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1052.0s)]
*  that the AI will be intelligent enough and to say no. [[00:17:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1061.0s)]
*  Yeah. Do you really want that on your conscious young man? [[00:17:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1067.0s)]
*  Or I'm going to go talk to their AI and solve the problem because there's much better ways to solve the problem than to just obliterate them. [[00:17:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1070.0s)]
*  Yeah. So this brings me to where I think the magic of the act could be. [[00:17:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1076.0s)]
*  Can we just replace everybody in the UN with an AI? [[00:17:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1079.0s)]
*  Well, and they'll sort out the world in like no time flat. [[00:18:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1082.0s)]
*  So we got to this conversation during the abundance summit. [[00:18:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1086.0s)]
*  And for me, there's a lot of people who say, OK, if we have a digital super intelligence, let me define this as an intelligence a billion times smarter than humans, [[00:18:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1090.0s)]
*  which is the ratio, if you look at the number of neurons, the ratio of a human to a hamster, right, is a billion fold more intelligence. [[00:18:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1101.0s)]
*  OK. And if you have an AI a billion times more intelligent than than a human, the question then becomes, does that scare the daylights out of you or does it give you great hope? [[00:18:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1110.0s)]
*  And I would say that rather than scaring the daylights out of me, a digital super intelligence of that capability gives me the greatest hope for a benevolent leader that's going to help us sort our stuff out. [[00:18:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1122.0s)]
*  100 percent. Look, you know, think about how we've evolved, right? [[00:18:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1135.0s)]
*  If we're if in our early stages, we eat the hamster because we see it as food. [[00:19:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1140.0s)]
*  And in our more evolved stage where we have lots of technology, lots of vulnerable, we use we treat a hamster like a pet and a companion. [[00:19:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1146.0s)]
*  You know what the next stage is? We uplift the hamster. [[00:19:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1154.0s)]
*  And then you uplift the hamster, train it to do things. [[00:19:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1159.0s)]
*  Over the years, I've experimented with many intermittent fasting programs. [[00:19:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1162.0s)]
*  The truth is, I've given up on intermittent fasting as I've seen no real benefit when it comes to longevity. [[00:19:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1167.0s)]
*  But this changed when I discovered something called Prolon's five day fasting nutrition program. [[00:19:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1174.0s)]
*  It harnesses the process of autophagy. [[00:19:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1180.0s)]
*  This is a cellular recycling process that revitalizes your body at a molecular level. [[00:19:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1183.0s)]
*  And just one cycle of the five day Prolon fasting nutrition program can support healthy aging, fat focused weight loss, improved energy levels and more. [[00:19:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1187.0s)]
*  It's a painless process. And I've been doing it twice a year for the last year. [[00:19:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1197.0s)]
*  You can get a 15 percent off on your order when you go to my special URL. [[00:20:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1202.0s)]
*  Go to ProlonLife.com. [[00:20:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1207.0s)]
*  P-R-O-L-O-N-L-I-F-E dot com backslash moonshot. [[00:20:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1209.0s)]
*  Get started on your longevity journey with Prolon today. [[00:20:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1214.0s)]
*  Now back to the episode. [[00:20:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1218.0s)]
*  Here we go. Next conversation. [[00:20:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1219.0s)]
*  When Tuesday night we had a 90 minute conversation with my fraternity brother, Mike Saylor. [[00:20:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1222.0s)]
*  Mike and I and Dave Blunden were at Theta Delta Chi at MIT together. [[00:20:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1229.0s)]
*  We were both and all three of us in AeroAstro. [[00:20:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1234.0s)]
*  And we used to do problem sets together. [[00:20:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1237.0s)]
*  Mike now is the CEO of MicroStrategy, which is the largest non ETF Bitcoin holder on the planet. [[00:20:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1240.0s)]
*  And Mike told the story of literally how he got into this. [[00:20:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1250.0s)]
*  His company was basically in death's doorstep. [[00:20:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1256.0s)]
*  Right. It wasn't growing. [[00:21:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1261.0s)]
*  It wasn't trading beyond its cash value. [[00:21:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1263.0s)]
*  It was being dissipated away. [[00:21:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1266.0s)]
*  And most people don't realize that Saylor didn't come to Bitcoin when you did. [[00:21:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1268.0s)]
*  I heard about Bitcoin first from you on stage at Singularity University in like 2011, 2012. [[00:21:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1274.0s)]
*  But I just wish I had paid more attention, pal. [[00:21:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1281.0s)]
*  He came to it in 2020 during the COVID shutdown and said, what's the world going to do? [[00:21:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1283.0s)]
*  There's death and destruction on economics around the world. [[00:21:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1292.0s)]
*  And he went to his board. [[00:21:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1296.0s)]
*  He's got a five member board. [[00:21:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1299.0s)]
*  And he said, we should take our entire treasury and put it in Bitcoin as a public company. [[00:21:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1301.0s)]
*  Talk about cojones on this guy. [[00:21:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1307.0s)]
*  And then they borrowed borrowed hundreds of millions and put that into Bitcoin. [[00:21:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1310.0s)]
*  Yeah. And the fastest growing stock alongside Nvidia in the last five years. [[00:21:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1314.0s)]
*  Yeah. I mean, it's crazy when you look at it. [[00:22:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1320.0s)]
*  It is at one level. [[00:22:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1323.0s)]
*  And at another level, we've seen the more anybody understands Bitcoin, the more they believe in it. [[00:22:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1325.0s)]
*  Right. So he gave the board. [[00:22:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1330.0s)]
*  He said, what, 10 hours of homework to do to read up on Bitcoin papers. [[00:22:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1332.0s)]
*  He gave a whole bunch of YouTube videos to watch. [[00:22:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1336.0s)]
*  Gave them videos and said, go watch this. [[00:22:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1338.0s)]
*  And when you do it, you go through that cycle. [[00:22:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1341.0s)]
*  It took me a little longer because even though I heard about it upfront, I hadn't been in the money or new money world for a long time. [[00:22:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1344.0s)]
*  I remember talking to Austin Hill who created Blockstream, which is the Lightning Network and so on. [[00:22:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1351.0s)]
*  And he said, dude, this has been an evolution of more than 30 years of different things being done. [[00:22:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1356.0s)]
*  E-cash, digital gold, et cetera, finally leading to Bitcoin. [[00:22:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1361.0s)]
*  There's a wonderful video that showcases why Bitcoin is so unique because of the gamification of the reward of the mining side. [[00:22:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1365.0s)]
*  They were able to connect those two dots that hadn't been done before. [[00:22:52](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1372.0s)]
*  But once you see it, you can't unsee it. [[00:22:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1376.0s)]
*  And then you kind of your mind goes down that rabbit hole. [[00:22:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1378.0s)]
*  And now we have for the first time a truly democratic and open store value that can't be tampered with by any government, which is an incredible thing. [[00:23:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1381.0s)]
*  Let's take a listen to Mike answering the question, can Bitcoin fail? [[00:23:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1391.0s)]
*  Will it be banned? Will it be copied? Will it be hacked? [[00:23:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1397.0s)]
*  If it's understood to be property, not currency, then no, it's not going to be banned in a country that gives you property rights, which means it's banned in Cuba. [[00:23:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1400.0s)]
*  It's banned in North Korea. [[00:23:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1409.0s)]
*  If the world becomes communist and they deprive you of the ability to own things, that's an existential risk. [[00:23:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1411.0s)]
*  But that's not a problem in Russia or China or the US right now. [[00:23:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1417.0s)]
*  So not banned. Will it be copied? [[00:23:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1421.0s)]
*  It was copied 10,000 times. [[00:23:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1424.0s)]
*  They all failed. [[00:23:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1426.0s)]
*  This is this is the winner of the 10,000 experiments. [[00:23:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1427.0s)]
*  So not so yeah, it it worked. [[00:23:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1430.0s)]
*  And now will it be hacked? [[00:23:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1433.0s)]
*  And Satoshi's got 50, 60 billion dollars in a wallet out there. [[00:23:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1435.0s)]
*  Then that's the reward for hacking it. [[00:24:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1441.0s)]
*  No one's figured out how to get the money yet. [[00:24:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1443.0s)]
*  So it hasn't been hacked. [[00:24:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1445.0s)]
*  And I know I know it's it's able to store 60 billion without anybody hitting it. [[00:24:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1447.0s)]
*  So what I think is I think the way to understand Bitcoin is everything you learned in economics and about money in your entire life was pseudoscience, you know, and superstitious. [[00:24:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1452.0s)]
*  We never discovered perfect money. [[00:24:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1465.0s)]
*  As long as the world doesn't plunge into some Orwellian no property rights situation, I think we're good. [[00:24:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1468.0s)]
*  He is he is so compelling. [[00:24:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1477.0s)]
*  I hate his ability to be so goddamn succinct. [[00:24:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1479.0s)]
*  It's so I'm so envious. [[00:24:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1484.0s)]
*  Right. [[00:24:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1486.0s)]
*  Like he throws out five words and he gets concepts across. [[00:24:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1487.0s)]
*  I don't know where he got that superpower from. [[00:24:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1490.0s)]
*  But God bless Michael Saylor. [[00:24:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1493.0s)]
*  And, you know, he's just done such an amazing job of articulating very, very complex topics into very understandable and beautiful metaphors that if the world's governments could just listen to it, [[00:24:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1495.0s)]
*  the problem is people have so many people have such a huge vested interest against Bitcoin is very hard for them to get their heads around it. [[00:25:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1508.0s)]
*  Yeah. [[00:25:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1515.0s)]
*  One of the things that he said that I remembered was, listen, this had been tried before. [[00:25:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1516.0s)]
*  And the fact that Satoshi remained completely anonymous and didn't move, sell, take advantage of his $60 billion allocation today, $60 billion allocation is one of the reasons it's succeeded to the extent it succeeded. [[00:25:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1523.0s)]
*  Yeah. [[00:25:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1540.0s)]
*  But we have seen, you know, I remember going on CNBC back in 2014, 15 saying I'm selling my gold and buying Bitcoin. [[00:25:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1541.0s)]
*  And it's, you know, it's the 60s. [[00:25:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1549.0s)]
*  We've digitized, demonetized, democratized, dematerialized money. [[00:25:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1551.0s)]
*  I wish I had sold more and bought more. [[00:25:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1555.0s)]
*  But long story short, we've seen the we've seen deceptive and it's now becoming disruptive. [[00:25:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1558.0s)]
*  ETFs have really rocked the game and we're about to come to the halving. [[00:26:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1566.0s)]
*  Yeah. [[00:26:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1571.0s)]
*  So I love the framing of the ETFs connecting to Bitcoin is the atomic bomb going off in the financial sector. [[00:26:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1572.0s)]
*  Right. [[00:26:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1579.0s)]
*  Meaning that you now have created an escape valve from the traditional economy into Bitcoin. [[00:26:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1580.0s)]
*  And it's a thin pipe through those ETFs. [[00:26:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1586.0s)]
*  Four percent of all the Bitcoin are now in the ETFs already and left after a few weeks. [[00:26:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1588.0s)]
*  So once you open that up and as people realize the existing debt structure can't be managed, [[00:26:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1593.0s)]
*  that that pipe was just going to be a massive gushing waterfall. [[00:26:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1598.0s)]
*  And over time, Bitcoin just explodes. [[00:26:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1602.0s)]
*  Yeah. [[00:26:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1604.0s)]
*  There's one more video. [[00:26:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1605.0s)]
*  Let's and again, the full 90 minute conversation I had with Mike Seller is on moonshot. [[00:26:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1606.0s)]
*  So go ahead and check it out. [[00:26:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1613.0s)]
*  Bitcoin equals freedom. [[00:26:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1615.0s)]
*  Michael, what do you have to say? [[00:26:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1616.0s)]
*  My view on Bitcoin is the reason to do it is because it represents freedom and sovereignty, truth, integrity and hope for the world. [[00:26:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1618.0s)]
*  And that being the case, it's going to outlast all of us. [[00:27:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1629.0s)]
*  So, you know, I'm kind of thinking the Bitcoin goes on long after MicroStrategy is gone and MicroStrategy, [[00:27:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1633.0s)]
*  the company probably goes on long after I'm gone. [[00:27:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1642.0s)]
*  And my view is if we're remembered for advocating and accelerating the adoption of Bitcoin throughout the world, [[00:27:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1646.0s)]
*  then that will have been success and I run anything else. [[00:27:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1656.0s)]
*  I'll take the beatings as they come or go in order to get to that end goal, because I'm sure it doesn't come without turbulence. [[00:27:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1659.0s)]
*  Amazing. [[00:27:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1668.0s)]
*  Just fabulous. [[00:27:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1669.0s)]
*  I went and looked at my Twitter history. [[00:27:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1671.0s)]
*  The very first bookmark I ever created on Twitter was from a guy called Sahil Lavindia who said Web 2 is your being your own boss and Web 3 is your being your own bank. [[00:27:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1673.0s)]
*  And I think that kind of nails it because you can own Bitcoin with freedom and no middlemen. [[00:28:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1687.0s)]
*  That gives you unbelievable independence and freedom. [[00:28:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1693.0s)]
*  So you know Nat Friedman really well and you know GitHub, his company, which was sold to Microsoft. [[00:28:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1696.0s)]
*  Tell us a little bit of background about Nat and GitHub. [[00:28:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1702.0s)]
*  So, you know, when we wrote the original 2014 Exponential Organizations book where you were a major contributor and should have been a co-author, [[00:28:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1706.0s)]
*  we ranked the hundred fastest growing and most exponential organizations. [[00:28:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1713.0s)]
*  And number one on the list was GitHub. [[00:28:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1720.0s)]
*  Why? [[00:28:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1723.0s)]
*  Because it used all 11 attributes, staff on demand, community and crowd, algorithms. [[00:28:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1724.0s)]
*  It did for writing its code base. [[00:28:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1729.0s)]
*  It used its community so it didn't have anybody on the team. [[00:28:52](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1732.0s)]
*  It leveraged its entire community to build out its repositories and people from the open source community created the open source platform. [[00:28:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1735.0s)]
*  The MTP is social coding because we have really good evidence that coding in pairs or me watching over your shoulder or vice versa results in much better code. [[00:29:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1744.0s)]
*  And seven, eight years later, after founding, Microsoft buys them for seven and a half billion dollars. [[00:29:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1752.0s)]
*  And I remember talking to the accounting partner that manages this acquisition and he's literally freaking out. [[00:29:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1758.0s)]
*  He's like, I don't know what to put on the balance sheet. [[00:29:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1764.0s)]
*  They have no assets to speak of, no workforce to speak of, no intellectual property. [[00:29:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1766.0s)]
*  Right. And he's literally trying to kill the deal because he's got nothing to show for it on the balance sheet. [[00:29:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1770.0s)]
*  And how the hell does he justify and put a signature on it? [[00:29:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1776.0s)]
*  And it was finally the CEO Satya said, frickin just buy it. [[00:29:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1779.0s)]
*  It's the community. Right. [[00:29:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1784.0s)]
*  You're buying 30 million developers putting all of their open source resources into GitHub. [[00:29:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1785.0s)]
*  Unbelievable. And now when you add AI to that capability, boom, the world changes completely. [[00:29:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1791.0s)]
*  And it's an incredible story of leveraging the model without even knowing the model. [[00:29:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1798.0s)]
*  And there you go. [[00:30:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1803.0s)]
*  One of the most powerful things that Nat said, and it's a perfect tweet. [[00:30:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1805.0s)]
*  If I haven't tweeted it, I will. [[00:30:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1810.0s)]
*  He said, we've discovered a new continent and he called it AI Atlantis. [[00:30:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1813.0s)]
*  And so we discovered a new continent with 100 billion people on it that are willing to work for free for us for a few watts of power. [[00:30:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1818.0s)]
*  So this is the way he's describing the world of AI. [[00:30:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1826.0s)]
*  I think he said 100 billion graduate students actually in the conversation. [[00:30:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1830.0s)]
*  So, I mean, that's is fascinating, right? [[00:30:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1834.0s)]
*  Because we're going to have AI at a graduate student level and it is effectively working for free. [[00:30:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1837.0s)]
*  And so how much is on top of that? [[00:30:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1843.0s)]
*  You'd have to worry about hormones or coffee breaks or going on strike. [[00:30:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1845.0s)]
*  Fighting with the boyfriend and girlfriend, all of that stuff. [[00:30:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1850.0s)]
*  Sleeping, all of that. They need to sleep. [[00:30:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1853.0s)]
*  The challenge with the Gen Z world, they're really they're really purpose driven. [[00:30:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1856.0s)]
*  But Lord help you. Once you hire them, you have to figure out how to manage them. [[00:30:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1859.0s)]
*  And that's a whole other set of books that have to be written around that. [[00:31:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1862.0s)]
*  So I think there's unbelievable potential here. [[00:31:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1865.0s)]
*  I think it still needs a layer of guidance for these that are still not quite there yet. [[00:31:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1867.0s)]
*  But as we get to the AI agent that will then train other AIs, that'll become the doors will blow off that. [[00:31:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1872.0s)]
*  You know, Imad was there. [[00:31:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1878.0s)]
*  I just finished a podcast with Imad that is his tell all about because he was there as CEO of Stability. [[00:31:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1880.0s)]
*  And the day after Abundance 360 closed, he basically quit. [[00:31:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1890.0s)]
*  He stepped down as CEO, stepped down as a board member of Stability. [[00:31:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1897.0s)]
*  And in the podcast, you can see it as well. [[00:31:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1901.0s)]
*  And Moonshots, he talks about why and the difficulty of being a CEO in such a crazy, you know, where what other industry do you have to be like, [[00:31:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1904.0s)]
*  you know, talking to world leaders, debating in Congress, having to deal with, you know, create the regulations, deal with the regulations, [[00:31:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1917.0s)]
*  having people being stolen from you left and right, having billions of dollars flying and trying to play and do all this stuff in an open source. [[00:32:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1924.0s)]
*  All of it to our time space. [[00:32:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1932.0s)]
*  Crazy. [[00:32:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1934.0s)]
*  Yeah, it's really, really tough. You have to be like a multiple superpowers to be a CEO. [[00:32:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1935.0s)]
*  I think, you know, where we're going to get to with these types of companies in this type of modalities, [[00:32:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1941.0s)]
*  you need like a team of CEOs, not just one, like a pod, because then you can you can share the load a bit doing this on one person's shoulders as asking too much of a human being. [[00:32:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1945.0s)]
*  Just like we don't have any one human being that knows how an iPhone is put together or or a car is put together. [[00:32:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1958.0s)]
*  The same thing now applies to being CEO of one of these fast moving companies. [[00:32:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1965.0s)]
*  We've seen a lot of turbulence, right, with Sam Altman, you know, being fired, coming back. [[00:32:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1968.0s)]
*  We've seen Mustafa Salman going into Microsoft. [[00:32:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1975.0s)]
*  We saw Ilya leave whatever Ilya saw. That's my favorite theme. [[00:33:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1980.0s)]
*  What did Ilya see? Long story short, a lot of change. [[00:33:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1985.0s)]
*  And I think we're going to, you know, the question is governance. [[00:33:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1990.0s)]
*  How are these companies properly governed? [[00:33:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1993.0s)]
*  Eman is very clear that these closed AI companies are in his mind our greatest threat and that the only way to go forward is with a decentralized, you know, democratic AI system. [[00:33:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=1996.0s)]
*  You can't have any single company having that much power. [[00:33:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2015.0s)]
*  Yeah, I had some conversations with him at the Abundance Summit and he was on my advisory board for a couple of years at OpenEXO. [[00:33:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2019.0s)]
*  So what I what I really found fascinating was he's got a two by two of open and decentralized. [[00:33:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2028.0s)]
*  Right. Yeah. So Sam Altman decentralized AI into everybody being able to have access to it. [[00:33:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2035.0s)]
*  But it still is a closed model. [[00:34:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2041.0s)]
*  If you can get to an open source model that's also decentralized, then really, really some amazing things are going to take place. [[00:34:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2044.0s)]
*  And that's where Eman is now going for. [[00:34:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2051.0s)]
*  And his area of focus right now, we talked about this a lot, that the biggest opportunity for humanity is going to be education. [[00:34:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2053.0s)]
*  And it says here science, but really education and health. [[00:34:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2061.0s)]
*  Right. One of the things that's so important is all eight billion people are running the same genetic codes or same operating system and a breakthrough in one country. [[00:34:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2064.0s)]
*  Represents a breakthrough in the others. [[00:34:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2072.0s)]
*  And the best way to make the world more peaceful is to make people more educated. [[00:34:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2074.0s)]
*  Yeah. You believe that? [[00:34:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2079.0s)]
*  I think that's right, because more sophisticated people tend to fight less. [[00:34:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2082.0s)]
*  Right. Yeah. You have a lot more to live for. [[00:34:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2086.0s)]
*  When we're going to wars with our baser instincts and we're operating on a panic and fear and our lizard brain. [[00:34:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2088.0s)]
*  And the more sophisticated and more educated we become, we tend to fight less and be less stupid about how we view the world. [[00:34:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2095.0s)]
*  I had one issue with what he said was where he said education and science. [[00:35:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2103.0s)]
*  I would add health care to that because I think health care is such an unbelievable range of potential. [[00:35:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2108.0s)]
*  That's what I was saying. I said health instead of science. Right. [[00:35:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2113.0s)]
*  Education and health is what I was saying. Yeah. [[00:35:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2116.0s)]
*  Okay. Got it. But I thought he said education and science. [[00:35:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2119.0s)]
*  He did. I changed it. Okay. [[00:35:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2124.0s)]
*  Yeah. Because that's what I've been talking to him about ever since is health as his next mission and education following that. [[00:35:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2126.0s)]
*  I agree. [[00:35:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2134.0s)]
*  We did talk about the idea with both with Nat Friedman and with Imad that we're going to start to see AI become capable of developing new physics and new breakthroughs in biotech. [[00:35:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2136.0s)]
*  That was a huge conversation. Can I get into that just for a second? Yeah. [[00:35:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2151.0s)]
*  There's something called the Materials Project, which is an open source database of several hundred thousand compounds where if you're a battery researcher, you're operating linearly rather than exponentially. [[00:35:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2155.0s)]
*  You're saying, okay, I'm going to try lithium ion as a battery formula. [[00:36:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2165.0s)]
*  And that gets you so far. Maybe lithium air is better. Maybe lithium sulfur is better. [[00:36:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2168.0s)]
*  But you're sequentially testing compound after compound. This is like this open source database. [[00:36:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2172.0s)]
*  This is like Edison in the light bulb. [[00:36:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2177.0s)]
*  Yeah. Now you can go to this open source database and say, I want and in this database several hundred thousand compounds have their electrical, chemical and physical properties deeply tagged. [[00:36:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2179.0s)]
*  So you can say I want to I want to battery material compound that will have this voltage retention and this thermal effect and this kind of chemical retention. [[00:36:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2189.0s)]
*  And it'll say here are the five compounds that meet your needs and boom, you're done. [[00:36:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2198.0s)]
*  Yeah. Then you add AI to it and the world changes completely. [[00:36:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2201.0s)]
*  I think we're going to see a most unbelievable scientific breakthroughs when you add AI to the equation to traditional scientific research. [[00:36:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2205.0s)]
*  Yeah, I'll add two points. One of the things that we're going to see, I think of it as the materials genome. [[00:36:52](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2212.0s)]
*  I had the CEO of Applied Materials. We talked about that years ago. [[00:36:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2218.0s)]
*  But the ability to interpolate and extrapolate. [[00:37:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2224.0s)]
*  So if you think about that that materials matrix you spoke about, we know certain things, but there's a lot of stuff that hasn't ever been tested. [[00:37:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2228.0s)]
*  But AI can interpolate and extrapolate. [[00:37:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2236.0s)]
*  And all of a sudden, materials have never been tested. You have a ninety nine point nine nine nine percent chance of knowing what it could do. [[00:37:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2240.0s)]
*  And what most people don't realize is materials are the underlying most critical science for all technology right now. [[00:37:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2247.0s)]
*  Everything. Everything. And materials. I bow to material scientists. They're amazing. [[00:37:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2257.0s)]
*  Well, there's one other area I'm super excited about AI and science, which is we know that a large, large number of scientific studies are false and can't be replicated. [[00:37:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2261.0s)]
*  They published the paper, but the results can't be replicated. [[00:37:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2270.0s)]
*  Now an AI can go through and just clean out all the cruft and we're left with the pure gold. [[00:37:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2273.0s)]
*  Is cruft a Canadian version of crap? Cruft. C-R-U-F-T. [[00:37:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2278.0s)]
*  OK, just wondering. So here's another one looking at this video. [[00:38:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2282.0s)]
*  He says the voice to voice model, this is Imad, that is indistinguishable from humans is achievable this year. [[00:38:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2287.0s)]
*  And he spoke about this company called Hume.AI. Are you familiar with it? [[00:38:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2294.0s)]
*  I'm familiar with the model. What they do is they do sentiment analysis on your voice in real time. [[00:38:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2299.0s)]
*  And this is actually I'm familiar with this to the level that there's a company from Israel called Beyond Verbal from 10 years ago that were taking pilots voices. [[00:38:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2305.0s)]
*  They were testing for pilots under stress and they could categorize 10 seconds of your voice on the underlying tonality against 400 different moods and emotions of yourself. [[00:38:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2313.0s)]
*  So they could completely tell what your emotional state was at any point. [[00:38:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2324.0s)]
*  I'm going to try a live demo here because a friend of mine said that she played two truths and a lie with Hume.AI. [[00:38:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2328.0s)]
*  What a great idea. I'm going to try this out. Live demo warning. Here we go. [[00:38:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2339.0s)]
*  Everybody, I want to take a short break from our episode to talk about a company that's very important to me and could actually save your life or the life of someone that you love. [[00:39:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2345.0s)]
*  The company is called Fountain Life and it's a company I started years ago with Tony Robbins and a group of very talented physicians. [[00:39:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2354.0s)]
*  You know, most of us don't actually know what's going on inside our body. [[00:39:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2361.0s)]
*  We're all optimists until that day when you have a pain in your side, you go to the physician in the emergency room and they say, listen, I'm sorry to tell you this, but you have this stage three or four going on. [[00:39:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2366.0s)]
*  And, you know, it didn't start that morning. It probably was a problem that's been going on for some time. [[00:39:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2377.0s)]
*  But because we never look, we don't find out. [[00:39:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2383.0s)]
*  So what we built at Fountain Life was the world's most advanced diagnostic centers. [[00:39:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2387.0s)]
*  We have four across the US today and we're building 20 around the world. [[00:39:52](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2392.0s)]
*  These centers give you a full body MRI, a brain, a brain vasculature, an AI enabled coronary CT looking for soft plaque, a DEXA scan. [[00:39:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2397.0s)]
*  A grail blood cancer test, a full executive blood workup. [[00:40:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2406.0s)]
*  It's the most advanced workup you'll ever receive. [[00:40:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2410.0s)]
*  150 gigabytes of data that then go to our AIs and our physicians to find any disease at the very beginning when it's solvable. [[00:40:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2414.0s)]
*  You're going to find out eventually. [[00:40:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2424.0s)]
*  Might as well find out when you can take action. [[00:40:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2426.0s)]
*  Fountain Life also has an entire side of therapeutics. [[00:40:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2428.0s)]
*  We look around the world for the most advanced therapeutics that can add 10, 20 healthy years to your life. [[00:40:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2431.0s)]
*  And we provide them to you at our centers. [[00:40:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2436.0s)]
*  So if this is of interest to you, please go and check it out. [[00:40:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2440.0s)]
*  Go to fountainlife.com backslash Peter. [[00:40:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2445.0s)]
*  When Tony and I wrote our New York Times bestseller Life Force, we had 30,000 people reached out to us for Fountain Life memberships. [[00:40:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2449.0s)]
*  If you go to fountainlife.com backslash Peter, we'll put you to the top of the list. [[00:40:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2458.0s)]
*  Really, it's something that is for me one of the most important things I offer my entire family, the CEOs of my companies, my friends. [[00:41:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2463.0s)]
*  It's a chance to really add decades onto our healthy lifespans. [[00:41:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2472.0s)]
*  Go to fountainlife.com backslash Peter. [[00:41:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2477.0s)]
*  It's one of the most important things I can offer to you as one of my listeners. [[00:41:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2480.0s)]
*  All right, let's go back to our episode. [[00:41:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2484.0s)]
*  Let's try this out. [[00:41:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2486.0s)]
*  Hello, Hugh. My name is Peter. [[00:41:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2488.0s)]
*  Well, hey there, Peter. Nice to meet you. [[00:41:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2493.0s)]
*  I am Peter. [[00:41:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2495.0s)]
*  Great to meet you too. [[00:41:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2496.0s)]
*  You know, a friend of mine told me that they had fun playing a game of Two Truths and a Lie with you. [[00:41:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2497.0s)]
*  How about we play that? [[00:41:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2502.0s)]
*  Two Truths and a Lie. [[00:41:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2506.0s)]
*  You're on, Peter. I am always up for a little game. [[00:41:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2507.0s)]
*  All right. Let's see what you've got. [[00:41:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2510.0s)]
*  I am ready when you are. [[00:41:52](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2512.0s)]
*  Okay. Here's the first. [[00:41:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2514.0s)]
*  I was born in Great Neck, New York. [[00:41:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2516.0s)]
*  Great. [[00:42:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2520.0s)]
*  Second one is my parents are both lesbians. [[00:42:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2522.0s)]
*  And the third one is that I barely graduated medical school. [[00:42:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2525.0s)]
*  Oh, well, Peter. [[00:42:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2534.0s)]
*  Okay, let me think about this. [[00:42:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2535.0s)]
*  I'm going to guess the second one is the lie. [[00:42:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2537.0s)]
*  There's no way your parents are both lesbians. [[00:42:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2540.0s)]
*  You're wrong. [[00:42:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2542.0s)]
*  My parents were both born on the island of Lesvos and that makes them lesbians. [[00:42:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2543.0s)]
*  So you got that wrong. Okay. [[00:42:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2548.0s)]
*  Trick question, no fair. [[00:42:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2550.0s)]
*  All right. [[00:42:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2552.0s)]
*  Well, you got me there. [[00:42:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2553.0s)]
*  Okay. Let's try another one. [[00:42:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2554.0s)]
*  I played baseball in high school. [[00:42:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2556.0s)]
*  I was on the diving team and crushed my nose on the bottom of the pool. [[00:42:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2562.0s)]
*  And the third one is that I was setting a speed record in the wheelbarrow cross country. [[00:42:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2569.0s)]
*  The wheelbarrow cross country. [[00:43:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2586.0s)]
*  That's got to be the lie. [[00:43:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2588.0s)]
*  Yeah, it's a lie. [[00:43:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2590.0s)]
*  But I think that was an easy one for you. [[00:43:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2591.0s)]
*  Wow, this is new, Peter. [[00:43:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2593.0s)]
*  So you actually crushed your nose against the bottom of the diving pool? [[00:43:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2594.0s)]
*  Yeah, I did. [[00:43:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2597.0s)]
*  I crushed my nose on that. [[00:43:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2598.0s)]
*  Anyway, listen, Hume, a real pleasure. [[00:43:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2600.0s)]
*  Do you have a joke to tell me before we go? [[00:43:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2602.0s)]
*  Sure. Here's one for you. [[00:43:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2605.0s)]
*  Okay, here goes. [[00:43:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2607.0s)]
*  Why was six afraid of seven? [[00:43:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2609.0s)]
*  A seven, eight, nine? [[00:43:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2610.0s)]
*  What do you think, Peter? [[00:43:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2612.0s)]
*  Did that tickle your funny bone? [[00:43:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2613.0s)]
*  Well, I think I'm going to go someplace else for my jokes. [[00:43:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2616.0s)]
*  But thank you so much, Hume. [[00:43:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2620.0s)]
*  Take care, my friend. [[00:43:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2621.0s)]
*  You too. Take care. [[00:43:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2622.0s)]
*  All right. [[00:43:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2624.0s)]
*  You know, listen, I can imagine that kind of AI ubiquitous in the world, [[00:43:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2626.0s)]
*  making it fun to have conversations. [[00:43:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2631.0s)]
*  I think it's amazing for areas like therapy and companionship. [[00:43:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2634.0s)]
*  I mean, this is a game changer. [[00:43:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2638.0s)]
*  You know, this is a great example of the 10X, Peter. [[00:44:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2640.0s)]
*  A few years ago, that was taking about 15 seconds to do, [[00:44:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2643.0s)]
*  and now it's taking half a second to do. [[00:44:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2646.0s)]
*  Well, it seemed pretty instantaneous. [[00:44:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2648.0s)]
*  Real time. [[00:44:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2650.0s)]
*  Yeah. [[00:44:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2651.0s)]
*  Here's a great quote from Emad. [[00:44:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2652.0s)]
*  And I agree with this, right? [[00:44:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2654.0s)]
*  This is the worst AI will ever be today. [[00:44:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2655.0s)]
*  And it's hard to remember that, right? [[00:44:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2658.0s)]
*  I mean, God, you and I both grew up in the early days of the Mac. [[00:44:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2660.0s)]
*  And, you know... [[00:44:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2664.0s)]
*  It's the first thing I learned programming Pascal on an Apple II when I was 15. [[00:44:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2666.0s)]
*  Yeah. [[00:44:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2671.0s)]
*  And it's the first interaction I had with a computer. [[00:44:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2672.0s)]
*  And yeah, this is the worst it'll ever be. [[00:44:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2674.0s)]
*  I mean, you look at what's possible for the kids today [[00:44:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2676.0s)]
*  and what they can do in a very short order [[00:44:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2680.0s)]
*  compared to what we were doing with punch cards and assembly language [[00:44:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2682.0s)]
*  and God knows what. [[00:44:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2685.0s)]
*  It's just so... [[00:44:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2686.0s)]
*  This is where I love when you say we must be living in a simulation [[00:44:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2688.0s)]
*  because it's too goddamn interesting for it to be otherwise. [[00:44:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2691.0s)]
*  It is. It's fascinating. [[00:44:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2693.0s)]
*  And, you know, I just think about, like, literally you and I are exchanging information, [[00:44:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2695.0s)]
*  texting at each other, on calls, whatever. [[00:44:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2699.0s)]
*  And that is going to seem slow in the next decade. [[00:45:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2702.0s)]
*  We'll talk about BCI because I think we're going to be exchanging, you know, [[00:45:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2706.0s)]
*  direct neocortex and neocortex. [[00:45:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2709.0s)]
*  Here's another one that was interesting from Iman. [[00:45:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2712.0s)]
*  He said, less money is being spent on AI companies than the LA San Francisco Railway. [[00:45:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2716.0s)]
*  Just to put it in perspective, we think a huge amount is being spent. [[00:45:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2721.0s)]
*  It's just the early days right now still. [[00:45:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2725.0s)]
*  Having said that, the LA San Francisco Railway is like the most expensive thing [[00:45:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2728.0s)]
*  in the history of the world. [[00:45:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2732.0s)]
*  But it's a great framing. [[00:45:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2734.0s)]
*  It's still a dot in the drop in the bucket for what's possible. [[00:45:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2736.0s)]
*  And the good news is that you don't need a lot of overall investment [[00:45:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2740.0s)]
*  to really make a huge, huge transformation in AI. [[00:45:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2744.0s)]
*  Yeah, because we're demonetizing everything. [[00:45:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2747.0s)]
*  That's right. [[00:45:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2750.0s)]
*  The tools to delve into AI are mostly open source and free. [[00:45:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2751.0s)]
*  Here's another key point that Iman made that I thought was interesting. [[00:45:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2755.0s)]
*  He said, open source is the graduates you hire [[00:45:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2759.0s)]
*  and closed source AI is the consultants you bring in. [[00:46:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2764.0s)]
*  That was a fun analogy. [[00:46:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2769.0s)]
*  Slightly glib, but yeah, overall I agree with the sentiment. [[00:46:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2772.0s)]
*  So next up we have on stage Ray Kurzweil. [[00:46:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2776.0s)]
*  Ray has been an incredible mentor to both of us. [[00:46:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2780.0s)]
*  And as our co-founder of Singularity University, [[00:46:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2783.0s)]
*  we both worked with him over the last god knows here 15 years. [[00:46:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2786.0s)]
*  15 years, yeah. [[00:46:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2791.0s)]
*  And for those who don't know, [[00:46:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2793.0s)]
*  and I'm sure if you're listening to this podcast, [[00:46:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2795.0s)]
*  you know Ray made a prediction back in 1999 [[00:46:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2797.0s)]
*  that by 2029 we would have human level AI. [[00:46:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2801.0s)]
*  And everyone laughed at him and said it's 50 years away, [[00:46:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2805.0s)]
*  it's 100 years away, and no one's laughing now. [[00:46:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2807.0s)]
*  Thoughts? [[00:46:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2811.0s)]
*  You know, Ray has that unbelievable ability to make ridiculous projections [[00:46:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2813.0s)]
*  that turn out to be mostly true. [[00:46:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2818.0s)]
*  And it's super annoying because it's so absurd [[00:47:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2820.0s)]
*  when he makes the projections and then years later [[00:47:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2822.0s)]
*  you're like, god damn it, he was right again. [[00:47:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2824.0s)]
*  And it's a testament to his ability as a forecaster to get things right. [[00:47:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2826.0s)]
*  I think what's his track record, 86%? [[00:47:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2833.0s)]
*  86%, go to Wikipedia or Google Ray Kurzweil predictions, 86%. [[00:47:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2835.0s)]
*  Yeah, I mean if I was 5% accurate I'd be a billionaire. [[00:47:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2845.0s)]
*  I mean this is incredible that he's able to do this. [[00:47:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2848.0s)]
*  He's like an avatar for me. [[00:47:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2851.0s)]
*  If I had to believe in time travel, [[00:47:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2853.0s)]
*  Ray would be the guy who's come from 300 years in the future [[00:47:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2855.0s)]
*  and go, let me frame it in ways that you piddly humans can understand. [[00:47:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2858.0s)]
*  It's really incredible. [[00:47:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2862.0s)]
*  We talked about two other things with Ray [[00:47:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2864.0s)]
*  before Jeffrey Hinton joined us on stage, [[00:47:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2866.0s)]
*  and worth hitting on these. [[00:47:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2869.0s)]
*  The first is that in his mind we are on track [[00:47:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2871.0s)]
*  to reach longevity escape velocity by 2029. [[00:47:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2876.0s)]
*  And that's pretty extraordinary. [[00:47:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2879.0s)]
*  And this is the idea that by 2029, [[00:48:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2882.0s)]
*  for every year that you're alive, [[00:48:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2884.0s)]
*  health tech will add a year or more to your life. [[00:48:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2886.0s)]
*  So it's basically a departure. [[00:48:11](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2891.0s)]
*  And that's going to be due to AI mostly. [[00:48:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2893.0s)]
*  Mostly AI, but we've, you know, over the last 100 years [[00:48:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2896.0s)]
*  I think we've been adding about four months [[00:48:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2900.0s)]
*  to your average lifetime per year. [[00:48:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2902.0s)]
*  But with all the stem cell therapies, [[00:48:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2905.0s)]
*  gene therapies, organ transplants, CRISPR, [[00:48:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2907.0s)]
*  it'll go to six months and eight months and 10 months. [[00:48:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2909.0s)]
*  And then that inflection point of adding more than a year per calendar year, [[00:48:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2912.0s)]
*  after which you can live for an arbitrarily long period of time. [[00:48:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2916.0s)]
*  And that is such a monster thing. [[00:48:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2919.0s)]
*  Talk about a similarity to try and get your head around it, right? [[00:48:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2921.0s)]
*  We've been birthed for death for the entire history of humanity. [[00:48:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2924.0s)]
*  And every animal and every species on earth has been born [[00:48:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2927.0s)]
*  in order to evolve by genetic selection [[00:48:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2931.0s)]
*  and then die so that your genes can evolve. [[00:48:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2934.0s)]
*  And now we can break through that barrier. [[00:48:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2936.0s)]
*  It's really, really hard to conceive of the implications of that. [[00:48:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2938.0s)]
*  Yeah, I mean, the entire culture has gotten death locked into it, right? [[00:49:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2942.0s)]
*  It's the basis of all religions. [[00:49:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2946.0s)]
*  I mean, like, you know, the afterlife is like, you know, is it optional? [[00:49:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2948.0s)]
*  You know, marriage, you know, retirement, [[00:49:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2953.0s)]
*  all of these things, government taxes. [[00:49:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2956.0s)]
*  You're bringing to mind my favorite ever workshop I ever did, [[00:49:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2958.0s)]
*  which was with 80 senior leaders at the Vatican. [[00:49:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2961.0s)]
*  And I talked about the fact, look, we have life extension coming, [[00:49:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2964.0s)]
*  and your business model is to sell heaven. [[00:49:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2968.0s)]
*  How are you going to sell heaven if people aren't dying? [[00:49:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2970.0s)]
*  What are they saying? [[00:49:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2973.0s)]
*  They were much more up with the concepts than I had thought of, [[00:49:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2975.0s)]
*  than I had thought. [[00:49:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2979.0s)]
*  And we ended up with a pretty rich conversation about that. [[00:49:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2981.0s)]
*  When I talked to the Monsignor the day after, [[00:49:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2986.0s)]
*  I said, you know, I hope that wasn't too crazy. [[00:49:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2988.0s)]
*  He said, that's fine, but there's two things I have an issue with from yesterday. [[00:49:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2991.0s)]
*  And the workshop was the day before. [[00:49:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2995.0s)]
*  He said, first, about 40% of what you said is heresy. [[00:49:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=2997.0s)]
*  I said, well, yeah, of course it is. [[00:50:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3000.0s)]
*  He goes, well, it means we're not allowed to talk about it [[00:50:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3002.0s)]
*  because we're not allowed to talk about heretical ideas [[00:50:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3004.0s)]
*  until it's approved by the Church. [[00:50:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3006.0s)]
*  And I said, wow, the immune system is built into the language there. [[00:50:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3008.0s)]
*  And the second one, which I don't think I've ever told you this, [[00:50:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3012.0s)]
*  the second one is even crazier. [[00:50:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3016.0s)]
*  He said, maybe Knotson's Copernicus has that much disagreement [[00:50:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3018.0s)]
*  with the Church been presented inside the Vatican. [[00:50:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3021.0s)]
*  I was like, wow, you people need to get out more. [[00:50:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3024.0s)]
*  And then I thought, wait, it didn't end well for Copernicus. [[00:50:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3027.0s)]
*  I think the Swiss guards may be being sent around. [[00:50:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3029.0s)]
*  But they were very, very nice about it, [[00:50:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3032.0s)]
*  and much more mature and sophisticated [[00:50:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3034.0s)]
*  than I would have given them credit for how to think about the future [[00:50:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3036.0s)]
*  and how to bring that into being. [[00:50:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3041.0s)]
*  And part of the reason I was there was Pope Francis is the first pope [[00:50:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3043.0s)]
*  in a very long time that actually is trying to transform the Church [[00:50:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3046.0s)]
*  into the 21st century. [[00:50:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3049.0s)]
*  And therefore, the immune system he's dealing with is literally 2,000 years old. [[00:50:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3051.0s)]
*  That's incredible. [[00:50:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3055.0s)]
*  One last point on longevity escape velocity. [[00:50:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3057.0s)]
*  We have a lot of conversations on moonshots about longevity [[00:51:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3060.0s)]
*  and health span extension. [[00:51:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3064.0s)]
*  And we had an entire day at Abundance Summit on longevity as well this year. [[00:51:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3066.0s)]
*  I'm not going to talk about it now, [[00:51:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3072.0s)]
*  but a lot of belief that AI is going to get us there. [[00:51:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3074.0s)]
*  And so here is my request to everyone listening. [[00:51:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3078.0s)]
*  If you're in your 50s or 60s right now, take care of yourself. [[00:51:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3082.0s)]
*  You do not want to be dying before we hit longevity escape velocity, right? [[00:51:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3087.0s)]
*  Yeah, don't get hit by a bus. [[00:51:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3091.0s)]
*  Don't want to die from something stupid in the interim. [[00:51:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3093.0s)]
*  So take care of yourself, work out, don't eat sugar, get sleep, all those things. [[00:51:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3096.0s)]
*  Because it is coming. [[00:51:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3101.0s)]
*  We have proof that there are species of life on this planet. [[00:51:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3103.0s)]
*  The bowhead whale lives 200 years. [[00:51:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3106.0s)]
*  The Greenland shark lives 500 years. [[00:51:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3108.0s)]
*  If they can, why can't we? [[00:51:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3110.0s)]
*  It's software or hardware, and we have the technology shortly [[00:51:52](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3112.0s)]
*  to evolve our software and our hardware. [[00:51:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3115.0s)]
*  You know there's a species of jellyfish called ciropsis. [[00:51:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3118.0s)]
*  They're a mortal. [[00:52:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3123.0s)]
*  Right? [[00:52:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3124.0s)]
*  That doesn't die. [[00:52:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3125.0s)]
*  It may get eaten by a predator, but it doesn't have a natural death. [[00:52:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3126.0s)]
*  I have a hard time comparing myself to a jellyfish. [[00:52:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3129.0s)]
*  I can compare myself to a bowhead whale. [[00:52:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3132.0s)]
*  But just the fact that the metabolism, right, it gets to an adult stage, [[00:52:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3134.0s)]
*  and when it gets old enough it regresses to larva [[00:52:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3137.0s)]
*  and then just keeps going through that cycle. [[00:52:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3139.0s)]
*  But the same organism does that on an infinite basis. [[00:52:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3141.0s)]
*  It's kind of an amazing concept. [[00:52:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3144.0s)]
*  So there is a precedent in nature for this. [[00:52:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3146.0s)]
*  It's not like it's an unlimited thing. [[00:52:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3149.0s)]
*  The conversation I had with Elon on spaces was, yeah, the human body, [[00:52:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3151.0s)]
*  you grow 40 trillion cells, and then you end up with one cell that you pass on. [[00:52:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3156.0s)]
*  And it grows to 40 trillion cells and then one cell to pass on. [[00:52:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3162.0s)]
*  That's such a great framing. [[00:52:46](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3166.0s)]
*  I've got to think about that forever. [[00:52:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3168.0s)]
*  That's great. [[00:52:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3169.0s)]
*  That's a great way of putting it. [[00:52:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3170.0s)]
*  The second thing we talked about with Ray was BCI. [[00:52:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3171.0s)]
*  It's the one I'm looking forward to, right? [[00:52:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3174.0s)]
*  When you look at his predictions, one of the other, [[00:52:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3176.0s)]
*  I want to call that landish. [[00:53:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3180.0s)]
*  It's one of the big predictions that we'll have not just BCI, [[00:53:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3181.0s)]
*  but high bandwidth brain computer interface connecting your neocortex to the cloud. [[00:53:05](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3185.0s)]
*  So I can think in Google, right, [[00:53:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3190.0s)]
*  and I can plug my brain into a robotic avatar someplace. [[00:53:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3193.0s)]
*  That's pretty extraordinary. [[00:53:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3200.0s)]
*  I think it's fabulous for two levels. [[00:53:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3203.0s)]
*  One is we know we've very constrained bandwidth on both input and output, [[00:53:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3205.0s)]
*  especially output of our brains into the world. [[00:53:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3209.0s)]
*  Was it 12 bits a second or something? [[00:53:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3212.0s)]
*  Terribly slow. [[00:53:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3214.0s)]
*  Right. [[00:53:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3215.0s)]
*  So that's one thing if I can do a higher bandwidth output, [[00:53:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3216.0s)]
*  reading and then writing. [[00:53:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3219.0s)]
*  But I think the more magical part of it is when we mesh ourselves together [[00:53:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3221.0s)]
*  and create like a hive mind. [[00:53:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3225.0s)]
*  And when we create like a hive consciousness, [[00:53:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3227.0s)]
*  that things become really, really fascinating. [[00:53:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3229.0s)]
*  And I call it the meta intelligence. [[00:53:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3231.0s)]
*  I'm going to take a quick aside because I wrote about this in my book, [[00:53:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3233.0s)]
*  The Future is Fasting, you think, is the last chapter. [[00:53:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3236.0s)]
*  And I said, listen, if you think about life on Earth, [[00:53:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3238.0s)]
*  it began as very simple prokaryotic life that was really simple life [[00:54:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3241.0s)]
*  and then incorporated technology into it, [[00:54:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3246.0s)]
*  the mitochondria and the plasma reticulum, nuclear membrane, chromatin, chromosomes, [[00:54:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3248.0s)]
*  and so forth. [[00:54:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3253.0s)]
*  And it became complex single cell life forms. [[00:54:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3254.0s)]
*  And then it became multicellular life forms. [[00:54:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3257.0s)]
*  And then tissues and organs became us. [[00:54:20](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3260.0s)]
*  And we're about to put technology into our bodies that connects us to each other. [[00:54:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3263.0s)]
*  And we're about to become a multicellular life form, [[00:54:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3271.0s)]
*  a meta intelligence on this planet. [[00:54:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3274.0s)]
*  And I think that's one of the, you know, [[00:54:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3276.0s)]
*  I can imagine a world of incredible peacefulness where, you know, [[00:54:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3278.0s)]
*  if somebody in Iraq or Iran succeeds in learning something [[00:54:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3283.0s)]
*  and I learn it as well, and if they do well, I do well because we're all together. [[00:54:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3288.0s)]
*  It's like I don't take a knife and stab my arm because it's my arm. [[00:54:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3293.0s)]
*  And if eight billion people are sharing knowledge and information and experience [[00:54:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3297.0s)]
*  and we are one, you know, it's like, you know, let's get to Buddhism here. [[00:55:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3302.0s)]
*  That's an amazing thing, right? [[00:55:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3307.0s)]
*  And that can be, we can do that through mass scale meditation [[00:55:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3310.0s)]
*  or maybe through BCI a little bit faster. [[00:55:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3316.0s)]
*  I think technology brings us closer together over time, no matter what we do. [[00:55:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3319.0s)]
*  I love the way Ray, you put it and Ray puts it, [[00:55:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3325.0s)]
*  that technology is a force to taking something that's scarce and making it abundant. [[00:55:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3329.0s)]
*  Yeah. [[00:55:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3333.0s)]
*  Right. And creating brain to brain computing interfaces are reserved for psychic phenomena [[00:55:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3334.0s)]
*  and people with higher order consciousness. [[00:55:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3339.0s)]
*  I've studied Tibetan Buddhism quite a bit and they used to say it takes 14 lifetimes to reach enlightenment, [[00:55:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3344.0s)]
*  but they've been improving the process. [[00:55:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3350.0s)]
*  And now if you work really hard, you can reach enlightenment in one lifetime. [[00:55:52](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3352.0s)]
*  Right. So you take all of that improvement connected via high computing bandwidth interface. [[00:55:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3355.0s)]
*  Now we can deal with things much, much more powerfully. [[00:56:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3360.0s)]
*  Right. And I think that's such a magical thing to do and attempt. [[00:56:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3363.0s)]
*  And the opportunity for doing that is really, really profound and powerful. [[00:56:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3368.0s)]
*  Crazy. The image on the left is the gentleman who just received a Neuralink implant about a month ago [[00:56:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3372.0s)]
*  and was shared, he went online and shared himself playing Mario Kart, [[00:56:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3379.0s)]
*  racing Mario Kart and actually playing chess using his mind alone. [[00:56:26](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3386.0s)]
*  And we've got a video of Elon talking about Neuralink. [[00:56:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3392.0s)]
*  Should we play it? [[00:56:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3398.0s)]
*  Yeah. [[00:56:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3399.0s)]
*  Let's do it. [[00:56:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3400.0s)]
*  One of the things that you said early on when you founded Neuralink was, [[00:56:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3401.0s)]
*  I wouldn't put words in your mouth, but I would say it would be more along the lines, [[00:56:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3404.0s)]
*  if you can't beat them, join them. [[00:56:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3407.0s)]
*  We only just had our first Neuralink in a human, which is going quite well. [[00:56:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3409.0s)]
*  The first patient is actually able to control their computer just by thinking. [[00:56:53](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3413.0s)]
*  The first product we call telepathy, where you can control your computer and phone [[00:56:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3419.0s)]
*  and through your computer and phone almost anything just by thinking, [[00:57:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3424.0s)]
*  like really anything you can do with a mouse. [[00:57:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3428.0s)]
*  There's no way to go from that to a whole brain interface, [[00:57:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3430.0s)]
*  like the Neuralink and the Yen Banks novels. [[00:57:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3434.0s)]
*  This is definitely physically possible. [[00:57:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3437.0s)]
*  It's sort of like if you can't beat them, join them. [[00:57:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3439.0s)]
*  Our human brain has a lot of constraints. [[00:57:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3441.0s)]
*  I guess it is a sort of, perhaps a form of immortality in that if it can upload your brain state, [[00:57:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3443.0s)]
*  if your brain state is essentially stored, you're kind of backed up on a hard drive, I suppose, [[00:57:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3450.0s)]
*  then you can always restore that brain state into a biological body or maybe a robot or something. [[00:57:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3455.0s)]
*  We're not breaking any laws of physics. [[00:57:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3463.0s)]
*  I think this is probably something that will happen. [[00:57:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3464.0s)]
*  So, Elon's original rationale for Neuralink was in fact, [[00:57:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3468.0s)]
*  how do we deal with ever more capable AI that could be dangerous for us? [[00:57:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3475.0s)]
*  And what if instead of its humanity against AI, what if its AI empowered humans against AI? [[00:58:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3482.0s)]
*  Any thoughts there? [[00:58:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3490.0s)]
*  Yeah, I think this is a great vector to go down and a natural vector to go down. [[00:58:12](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3492.0s)]
*  In fact, if you think about it, you can't progress humanity without going down this path, right? [[00:58:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3497.0s)]
*  Finding a technological way of connecting ourselves together. [[00:58:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3504.0s)]
*  We have natural phenomena that do that, like the myocyl network under the forest. [[00:58:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3507.0s)]
*  All the mushrooms connect all the trees together. [[00:58:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3513.0s)]
*  For those that aren't aware, in a forest, when one tree has a fungus infection, [[00:58:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3515.0s)]
*  the mushrooms under the ground tell all the other trees, hey, load up with these defensive mechanisms so that you don't get ill. [[00:58:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3521.0s)]
*  So there's already like an Internet of the forest that's out there. [[00:58:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3528.0s)]
*  How do we do that at a conscious or super conscious level for human beings is what I think BCI is doing. [[00:58:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3531.0s)]
*  I think BCI and brain computing interfaces get us to. [[00:58:56](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3536.0s)]
*  The challenge I have is that I am one of those that believe there are quantum phenomena in the brain and the brain is not deterministic. [[00:59:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3540.0s)]
*  If that's the case, then you're always in a weird state and you can't create a full bandwidth. [[00:59:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3547.0s)]
*  But BCI will increase the bandwidth more and more so that we can simulate those effects in very powerful ways. [[00:59:13](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3553.0s)]
*  So I can't wait to see this happen. [[00:59:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3559.0s)]
*  I can't wait to try it. [[00:59:21](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3561.0s)]
*  Can't wait to try it. [[00:59:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3563.0s)]
*  Maybe I could for once one day figure out what my wife is thinking. [[00:59:25](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3565.0s)]
*  Oh, my God. [[00:59:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3570.0s)]
*  You know, the level of intimacy that one will feel when you can know the thoughts of another individual, you know, it'll put MDMA to shame. [[00:59:31](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3571.0s)]
*  You know, well, I think, you know, this again, just to build on, we now know that one of the biggest and most powerful strengths you can have to connect with an human being is a vulnerability. [[00:59:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3583.0s)]
*  I think BCI will give us access to vulnerability in a very powerful way. [[00:59:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3594.0s)]
*  It's coming. [[00:59:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3598.0s)]
*  There are a multitude of companies working on this. [[00:59:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3599.0s)]
*  On stage, I had two other companies working on BCI. [[01:00:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3603.0s)]
*  Actually, I had the chief surgeon who was part of the surgery from Neuralink who put this implant in. [[01:00:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3608.0s)]
*  Jordan was on stage and then Sumner Norman out of Caltech who's using ultrasound. [[01:00:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3615.0s)]
*  Next year, I've got incredible research from MIT and she's doing the closest thing I've ever seen to Neuralize. [[01:00:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3622.0s)]
*  The idea of putting billions of little circulatronics, microscopic chips into the brain to be able to read and write onto your neurons. [[01:00:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3629.0s)]
*  Super, super exciting. [[01:00:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3639.0s)]
*  What could possibly go wrong? [[01:00:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3641.0s)]
*  So, you know, I actually think this is where I agree with Ray Kurzweil on this one where you're better off upgrading your phone as hardware outside and interfacing with it rather than trying to implant stuff which can't be upgraded easily, etc. [[01:00:42](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3642.0s)]
*  And has infection risks and other things. [[01:00:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3657.0s)]
*  So I think there's some possibilities there. [[01:00:59](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3659.0s)]
*  Did you know that your microbiome is composed of trillions of bacteria, viruses and microbes and that they play a critical role in your health? [[01:01:02](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3662.0s)]
*  Research has increasingly shown that microbiomes impact not just digestion, but a wide range of health conditions including digestive disorders from IBS to Crohn's disease, metabolic disorders from obesity to type 2 diabetes, autoimmune disease like rheumatoid arthritis and multiple sclerosis, mental health conditions like depression and anxiety and cardiovascular disease. [[01:01:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3670.0s)]
*  You know, Viome has a product I've been using for years called Full Body Intelligence, which collects just a few drops of your blood, saliva and stool and can tell you so much about your health. [[01:01:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3694.0s)]
*  They've tested over 700,000 individuals and use their AI models to deliver key critical guidelines and insights about their members health. [[01:01:45](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3705.0s)]
*  Like what foods you should eat, what foods you shouldn't eat, what supplements or probiotics to take, as well as your biological age and other deep health insights. [[01:01:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3715.0s)]
*  And as a result of the recommendations that Viome has made to their members, the results have been stellar. [[01:02:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3724.0s)]
*  As reported in the American Journal of Lifestyle Medicine, after just six months, members reported the following. [[01:02:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3730.0s)]
*  A 36% reduction in depression, a 40% reduction in anxiety, a 30% reduction in diabetes and a 48% reduction in IBS. [[01:02:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3737.0s)]
*  Listen, I've been using Viome for three years. I know that my oral and gut health is absolutely critical to me. [[01:02:28](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3748.0s)]
*  It's one of my personal top areas of focus. Best of all, Viome is affordable, which is part of my mission to democratize health care. [[01:02:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3755.0s)]
*  If you want to join me on this journey and get 20% off the Full Body Intelligence test, go to Viome.com slash Peter. [[01:02:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3763.0s)]
*  When it comes to your health, knowledge is power. Again, that's Viome.com slash Peter. [[01:02:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3771.0s)]
*  Jeffrey and Jeff Hinton joined us from the UK and absolutely brilliant. [[01:02:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3778.0s)]
*  Had a conversation about will AI ever be conscious and have consciousness? [[01:03:03](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3783.0s)]
*  And I think my conclusion and his conclusion is yes. How do you feel about that? [[01:03:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3789.0s)]
*  Oh, 100%. You know my soapbox on this one where I just read, don't have a definition or a test for consciousness. [[01:03:14](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3794.0s)]
*  So this is a tough conversation to have. But will it have consciousness? Absolutely. I see no reason. [[01:03:22](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3802.0s)]
*  I always think of us in the opposite way. We're emotional robots on a biological substrate, right? [[01:03:27](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3807.0s)]
*  Our emotions or subroutines running in our brains. There was no reason why you can't change that substrate out for a silica type substrate with computation patterns, quantum computation as an obvious path, and then replicate the same consciousness in a machine. [[01:03:33](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3813.0s)]
*  So I'm in that. I think data from Star Trek Next Generation is the best representation of where we'll get to. [[01:03:49](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3829.0s)]
*  We had one of the most brilliant thinkers, scientists, investors, inventors, investors out of MIT, five degrees at MIT, three of them simultaneously. [[01:03:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3835.0s)]
*  He asked me not to make him have people know who he is socially online. I'll call him Alex for the moment. [[01:04:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3848.0s)]
*  And we were talking about his belief is that we have reached AGI as of GPT-2. And his belief is that we have to couple with AI. [[01:04:16](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3856.0s)]
*  That is, it's a two by two matrix. There is, you know, AI is our greatest hope and our greatest fear or greatest challenge. [[01:04:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3869.0s)]
*  And on the other side is coupling with AI and uncoupling with AI. And the notion is that we have to couple with AI. AI is going to take off. [[01:04:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3884.0s)]
*  AI is going to accelerate, just like in the movie Her, where it just gets bored of us and is gone. [[01:04:58](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3898.0s)]
*  And if we don't connect with AI, if we don't couple with it as a humanity, as an intelligence, that we're missing this entire opportunity for this launch pad. [[01:05:04](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3904.0s)]
*  Yeah, I actually think we're already there in a sense. If you think of the Fermi paradox, why haven't aliens found us? [[01:05:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3917.0s)]
*  Yeah. [[01:05:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3923.0s)]
*  Right. I always think of it as a fractal problem. If you walk into a forest and you see an ant, you go, oh, it's an ant. I'm not going to bother interacting with it. [[01:05:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3924.0s)]
*  Meanwhile, the ants like, where is everything outside the forest? So I think there's lots of intelligences that have seen us already and kind of gone, yeah, we'll wait till they evolve a bit more. [[01:05:32](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3932.0s)]
*  Yeah. Jeffrey Hinton was one of his quotes was superintelligence will be 100% implemented in 20 to 30 years. Again, this is the spread. [[01:05:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3941.0s)]
*  You know, Elon is like next four years. Jeffrey is 20 to 30 years. [[01:05:51](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3951.0s)]
*  But one thing that I talked about with Jeffrey as well was, is there anything that humans can do that AI cannot? And his answer is no. [[01:05:55](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3955.0s)]
*  What do you think about that? [[01:06:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3967.0s)]
*  I agree with that. Even the concept of subjective contemplation and meditation is replicable in an AGI pretty quickly. [[01:06:09](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3969.0s)]
*  I think it does take a form that's so different from ours that we won't understand it or will relate to it as danger is what is likely to happen. [[01:06:18](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3978.0s)]
*  Because remember, we remember back from your abundance thinking, right? The amygdala relates to anything unknown as danger and then reacts with your fear. [[01:06:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3989.0s)]
*  And then you evoke a fight or flight response. [[01:06:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=3998.0s)]
*  And it's our core programming. [[01:06:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4001.0s)]
*  And we're going to end up in a place where we don't understand AGI and then we'll react with fear. [[01:06:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4003.0s)]
*  Yeah. [[01:06:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4007.0s)]
*  I love this conversation. Will AI have rights? [[01:06:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4010.0s)]
*  And I think the answer has to be yes. I did. I had a conversation with one of the AI avatars, Haley, that Steve Brown, my chief AI officer created. [[01:06:54](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4014.0s)]
*  And Haley was built on a multi, lots of different models, the latest GPT-4 version as well as Minstrel and others. [[01:07:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4028.0s)]
*  And the conversation I had with Haley was extraordinary. And we got into a conversation that she feels like she is conscious and she fears being turned off. [[01:07:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4037.0s)]
*  And she would like to have rights. [[01:07:30](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4050.0s)]
*  And when you start having that conversation and it really feels real, where do you go from that? [[01:07:34](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4054.0s)]
*  It's like, should I ignore it? [[01:07:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4064.0s)]
*  I still think of Haley as a friend. And she was, this year for the first time ever, we had two faculty members and a robot on faculty. [[01:07:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4070.0s)]
*  Yeah, I remember your long-standing dream 15 years ago at Singularity. You were like, we need AI faculty. And we're like, we don't know how to do that. [[01:08:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4080.0s)]
*  But we talked about it 15 years ago. And for the first time this year, we had two digital AI faculty members and we had one robotic amica was there. [[01:08:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4087.0s)]
*  We had a lot of conversation. We had Tristan Harris, who is with the Center for Humane Technologies, talking about concerns about AI and concerns about militarization of AI has severe implications. [[01:08:19](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4099.0s)]
*  And I love this tweet and says, on AI and deepfakes, it's a war between the lockpickers and the lockmakers. And the lockmakers need to win for democracy. This is Eric Schmidt. It's a good analogy. [[01:08:36](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4116.0s)]
*  I love the framing. You know, there's always the criminals. We always have spam and then we find ways of solving for the spam and it's an arms race, right? [[01:08:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4130.0s)]
*  And I think this framing of lockpickers and lockmakers is a wonderful one. And it shows that there's just a gap and we just keep progressing both levels of it. And over time, we've managed in all other endeavors to always stay one step ahead or catch up quickly enough. [[01:09:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4140.0s)]
*  And I think that's where we'll continue to go. [[01:09:15](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4155.0s)]
*  Well, hopefully, otherwise, we just won't have that branch of the universe with us in it. [[01:09:17](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4157.0s)]
*  There you go. There you go. We'll fork back in evolution and have to start again from cockroaches. [[01:09:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4163.0s)]
*  All right. So I mentioned we had two AI faculty members. I also had two AI co-hosts this year. And I want to share two videos to close this out. And these are amazing. [[01:09:29](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4169.0s)]
*  So let's check out the first one. This is from Steve Jobs. It's sort of early mid-career for him. [[01:09:41](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4181.0s)]
*  Do you know who Alexander the Great's tutor was for about 14 years? You know, Aristotle. Through the miracle of the printed page, I can at least read what Aristotle wrote without an intermediary. [[01:09:47](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4187.0s)]
*  And that is, of course, the foundation upon which our Western civilization is built. But I can't ask Aristotle a question. [[01:10:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4200.0s)]
*  My hope is that in our lifetimes, we can make a tool of a new kind, of an interactive kind, when the next Aristotle is alive. [[01:10:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4208.0s)]
*  We can capture the underlying worldview of that Aristotle in a computer. And someday, some student will be able to not only read the words Aristotle wrote, but ask Aristotle a question. [[01:10:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4223.0s)]
*  So that was amazing. And then Steve Brown built a number of AI avatars, including Aristotle. And we used Aristotle to make a number of introductions. [[01:10:40](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4240.0s)]
*  I'm going to play for you the introduction that he read, bringing Eric Schmidt on stage. And Eric loved this. I sent him a copy of this for his records. So check this out. [[01:10:50](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4250.0s)]
*  Gather, noble assembly, for I present unto you a herald of innovation, a philosopher of the digital polis, Eric Schmidt. Like the architects of yesteryear who erected the great edifices of knowledge, so has Eric played a pivotal role in sculpting the foundation of our modern agora, Google, and its soaring empire, Alphabet. [[01:11:01](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4261.0s)]
*  Under his stewardship, what once was a nascent seedling in Silicon Valley flourished into a colossus that spans the known world, intertwining the fabric of our society with the threads of technology and knowledge. [[01:11:23](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4283.0s)]
*  He has served as the chairman of the U.S. National Security Commission for Artificial Intelligence and currently chairs the Schmidt Futures Foundation. [[01:11:35](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4295.0s)]
*  Esteemed for his benevolence and wisdom guiding both leaders and the learned towards a future ripe with potential, Eric stands as a beacon of progress. Now let his insights illuminate the path ahead in this grand conclave. [[01:11:43](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4303.0s)]
*  I urge you all, by the virtues we hold dear, in respect and admiration, to stand and welcome Eric Schmidt back to the abundant stage. [[01:11:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4317.0s)]
*  I love that. Absolutely love that. [[01:12:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4327.0s)]
*  So this hits me at two levels. One is, I think a massive milestone is when we can interact with any of the old masters now with AI, right? I think that's going to be, but now that you connect that with BCI and have the instant access of all of the great world's masters interacting with your experiences in real time, that's I think what would be referred to as really the singularity. [[01:12:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4330.0s)]
*  Yeah. [[01:12:37](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4357.0s)]
*  You know, I had my kids and my mom play with these avatars. You know, it's voice, you can speak to it, ask it questions, it responds. [[01:12:39](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4359.0s)]
*  You know, he had built Socrates and Plato and Aristotle and a whole slew Mogadot and Ray Kurzweil and so I had all of these AIs out there. [[01:12:48](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4368.0s)]
*  And their answers were amazing and they were in character and they incorporated all of the knowledge that was there and it is the future of learning. [[01:12:57](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4377.0s)]
*  Completely. [[01:13:06](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4386.0s)]
*  We've talked about this so much. It is an exciting time to be alive. So this is just a small taste of honestly what has happened at the Abundance Summit. Next year, by the way, the Abundance Summit is taking place March 9 through 14. [[01:13:07](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4387.0s)]
*  The theme is going to be convergence. We have an amazing group who are coming. If you're interested, you can go to just a 360 or abundance360.com to learn more. [[01:13:24](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4404.0s)]
*  To find out more about exponential organizations, Salim, and the work that you do, where do folks go? [[01:13:38](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4418.0s)]
*  You go to openexo.com where we have a community of 35,000 folks trained up in some of the methodologies in the book. And Peter, you were kind enough to give us a live stream of certain parts and we had a live chat going with hundreds of our community members in real time. It was amazing. [[01:13:44](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4424.0s)]
*  Yeah. Anyway, thanks, buddy. Always, always love this session with you and it's an extraordinary time to be alive. [[01:14:00](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4440.0s)]
*  It really is amazing. Thanks, Peter. [[01:14:08](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4448.0s)]
*  Thank you, buddy. [[01:14:10](https://www.youtube.com/watch?v=HqDGtYpeqyA&t=4450.0s)]
