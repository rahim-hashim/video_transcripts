---
Date Generated: June 01, 2025
Transcription Model: whisper medium 20231117
Length: 506s
Video Keywords: ['Jonathan Capehart', 'Eugene Daniels', 'Jacqueline Alemany']
Video Views: 1655
Video Rating: None
Video Description: Tech journalist Karen Hao joins The Weekend to discuss the potential damaging effects of AI on white collar jobs.
For more context and news coverage of the most important stories of our day click here: https://www.msnbc.com/
» Subscribe to MSNBC: https://www.youtube.com/msnbc
» Subscribe to MSNBC on TikTok https://www.tiktok.com/@msnbc 
» Subscribe to MSNBC on Instagram https://www.instagram.com/msnbc 
Download our new MSNBC app for the latest breaking news and daily headlines at a glance: https://www.msnbc.com/information/download-msnbc-app-n1241692
Follow MSNBC Show Blogs 
MaddowBlog: https://www.msnbc.com/maddowblog
MSNBC delivers breaking news, in-depth analysis of political headlines, commentary and informed perspectives. Find video clips and segments from The Rachel Maddow Show, The Briefing with Jen Psaki, Morning Joe, The Beat, Deadline: White House, The Weeknight, All In, The Last Word, The 11th Hour, and more.
Connect with MSNBC Online 
Visit msnbc.com: https://www.msnbc.com/ 
Subscribe to the MSNBC Daily Newsletter: https://link.msnbc.com/join/5ck/msnbc-daily-signup
#ai #tech #jobs
---

# Tech author: Unregulated AI companies represent a ‘new form of empire’
**MSNBC - The Latest:** [June 01, 2025](https://www.youtube.com/watch?v=RiKjcCKlvAA)
*  Those jobs, many new jobs will be created, I think much better jobs. [[00:00:00](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=0.0s)]
*  We feel a responsibility to educate society as we see it. [[00:00:05](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=5.36s)]
*  We'll be right about some things wrong about others and to be as good as we can at being [[00:00:08](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=8.76s)]
*  stewards of this technology. [[00:00:13](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=13.4s)]
*  But not everyone's going to like all of the impacts, but this is coming. [[00:00:15](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=15.200000000000001s)]
*  This is a scientific achievement of humanity that is going to get embedded in everything [[00:00:19](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=19.240000000000002s)]
*  we do. [[00:00:23](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=23.32s)]
*  That was OpenAI CEO Sam Altman late last year warning that quote, not everyone's going [[00:00:25](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=25.36s)]
*  to like all of the impacts of artificial intelligence. [[00:00:31](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=31.28s)]
*  And now we're getting a clearer picture of what some of those impacts might be. [[00:00:34](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=34.56s)]
*  A new estimate from the CEO of Anthropic, another leading AI company says half of all [[00:00:38](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=38.72s)]
*  entry level white collar jobs could be eliminated, driving up unemployment by as much as 10 to [[00:00:44](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=44.8s)]
*  20% in the next five years. [[00:00:51](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=51.16s)]
*  While some in the tech world are pushing back, Nvidia's CEO has said you won't lose your [[00:00:54](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=54.22s)]
*  job to AI, but to someone who knows how to use AI. [[00:00:59](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=59.9s)]
*  And while the public is still grappling with the pace and consequences of this technology, [[00:01:05](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=65.94s)]
*  Silicon Valley is moving full speed ahead. [[00:01:10](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=70.62s)]
*  As our next guest wrote in the New York Times, we are now closer than ever to a world in [[00:01:14](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=74.1s)]
*  which tech companies can seize land, operate their own currencies, reorder the economy [[00:01:19](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=79.02s)]
*  and remake our politics with little consequence. [[00:01:25](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=85.22s)]
*  And when companies rule supreme, democracy cannot hold. [[00:01:29](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=89.34s)]
*  Joining me now is joining us now is Karen Howe, got it right, tech journalist and author [[00:01:34](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=94.46s)]
*  of Empire of AI, Dreams and Nightmares and Sam Altman's whatever that word was that just [[00:01:41](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=101.7s)]
*  scrolled out of the way. [[00:01:50](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=110.78s)]
*  Karen, thank you very much for being here. [[00:01:51](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=111.98s)]
*  In that quote from the New York Times, from your piece in the New York Times, it made [[00:01:54](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=114.34s)]
*  me think of the line in the Constitution that says, Congress shall make no law that infringes [[00:01:57](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=117.42s)]
*  upon the rights of da, da, da, da, da. [[00:02:03](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=123.06s)]
*  And I remember Alberto Ibarguen, who was then the president of the Knight Foundation, remember [[00:02:05](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=125.76s)]
*  saying to me in a podcast interview 10 years ago that what happens when it's not Congress [[00:02:10](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=130.7s)]
*  that's abridging the rights of people, of Americans? [[00:02:17](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=137.42s)]
*  Seems to me what you're arguing is AI is going to be that thing that abridges the rights [[00:02:21](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=141.73999999999998s)]
*  of Americans. [[00:02:26](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=146.88s)]
*  Well, specifically the companies that are currently developing AI are using AI as a [[00:02:27](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=147.88s)]
*  cover to do that. [[00:02:32](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=152.45999999999998s)]
*  And I want to be clear, it's not the technology that's doing that, it's people developing [[00:02:34](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=154.82s)]
*  that technology. [[00:02:38](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=158.5s)]
*  And they keep pretending like they're not in charge of it. [[00:02:39](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=159.54s)]
*  They're like, Sam, almost like this is coming. [[00:02:41](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=161.54s)]
*  This is coming. [[00:02:43](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=163.54s)]
*  Exactly. [[00:02:44](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=164.54s)]
*  This is a scientific achievement. [[00:02:45](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=165.54s)]
*  No, it's not. [[00:02:46](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=166.98s)]
*  It's a commercial achievement. [[00:02:47](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=167.98s)]
*  They specifically chose to develop this technology in certain ways because it originally they [[00:02:49](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=169.66s)]
*  thought it would make them a lot of money. [[00:02:56](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=176.02s)]
*  Now it's not so clear. [[00:02:57](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=177.62s)]
*  But a lot of the choices that they made when developing this technology were not at all [[00:02:59](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=179.12s)]
*  scientific choices. [[00:03:04](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=184.14s)]
*  They were very much business decisions. [[00:03:06](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=186.08s)]
*  They were trying to earn a return on the investment that they got from investors so [[00:03:08](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=188.46s)]
*  that they could give that back to investors. [[00:03:13](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=193.26000000000002s)]
*  And now we are seeing the consequences of those move fast, break thing, profit-driven [[00:03:16](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=196.02s)]
*  decisions. [[00:03:21](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=201.86s)]
*  You have a great new book out on this and you two are bestsellers, buddies. [[00:03:23](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=203.32s)]
*  New York Times bestseller. [[00:03:27](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=207.86s)]
*  Right above me. [[00:03:29](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=209.86s)]
*  Really go into, you develop your arguments more deeply in your book. [[00:03:32](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=212.86s)]
*  Could you talk a bit and just explain why this is an inflection point when it comes [[00:03:37](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=217.44s)]
*  to this very powerful technology? [[00:03:42](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=222.6s)]
*  What baffles me is we have congressional members who have still failed to regulate social media [[00:03:45](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=225.36s)]
*  and now we're on the preface of this just cataclysmic change. [[00:03:51](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=231.34s)]
*  Absolutely. [[00:03:57](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=237.12s)]
*  And it's so related because social media really laid the groundwork for AI because it allowed [[00:03:58](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=238.12s)]
*  these companies to collect an enormous amount of data on people and that is what enables [[00:04:04](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=244.24s)]
*  these companies to then train AI models on that data so that they can automate away people's [[00:04:09](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=249.0s)]
*  jobs. [[00:04:15](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=255.64000000000001s)]
*  And so what I argue in the book is that we really need to think of these companies as [[00:04:17](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=257.0s)]
*  new forms of empire because they're not just amassing business power, they're amassing [[00:04:21](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=261.04s)]
*  economic and political leverage and they are quickly becoming the apex predator in the [[00:04:26](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=266.92s)]
*  ecosystem. [[00:04:33](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=273.32s)]
*  There is no other higher power to regulate and govern them. [[00:04:34](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=274.32s)]
*  And what we're seeing right now in Washington is the Trump administration is happily just [[00:04:37](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=277.92s)]
*  backing the companies and whatever they want to do, whatever is good for them, not necessarily [[00:04:42](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=282.84s)]
*  good for Americans. [[00:04:48](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=288.08s)]
*  And that is why I think we are leading to a place where democracy can't hold. [[00:04:50](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=290.12s)]
*  We cannot have a system where the average American feels like they have no control over [[00:04:54](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=294.6s)]
*  their data, over their agency, over their future economic opportunity. [[00:05:00](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=300.94s)]
*  They have no security or safety in the long term. [[00:05:05](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=305.06s)]
*  Karen, what do you make of the smiley facing of executives like Mark Cuban who argue that [[00:05:07](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=307.9s)]
*  AI will actually create jobs rather than eliminate them? [[00:05:13](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=313.7s)]
*  So what's so interesting is it does eliminate jobs and create jobs, but the thing that people [[00:05:18](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=318.88s)]
*  don't say is what kinds of jobs are eliminated and which ones are created. [[00:05:23](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=323.78s)]
*  So which ones? [[00:05:27](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=327.84s)]
*  So in the past, when there was automation in manufacturing, what happened was the entry-level [[00:05:29](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=329.2s)]
*  jobs disappeared and then there were lower skill jobs created and also higher skill jobs [[00:05:34](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=334.84s)]
*  created but the career ladder breaks. [[00:05:40](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=340.4s)]
*  And that's the most important impact that we will very likely see from this technology [[00:05:43](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=343.94s)]
*  with the way that Silicon Valley is choosing to deal with it right now is that people coming [[00:05:48](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=348.71999999999997s)]
*  into this profession, new college graduates, will not have any more opportunities to actually [[00:05:55](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=355.08s)]
*  learn the trade and actually be able to rise to the top. [[00:06:00](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=360.02s)]
*  They will end up falling into those lower skilled jobs that are being created and the [[00:06:03](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=363.53999999999996s)]
*  people who fortunately crossed over that hurdle before this technology automated away those [[00:06:08](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=368.06s)]
*  jobs, they will be the ones continuing to rise. [[00:06:14](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=374.18s)]
*  And so the gap, the chasm will increase over time. [[00:06:16](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=376.7s)]
*  This all sounds very terrifying, but it's the morning, so try to give people a little [[00:06:19](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=379.74s)]
*  bit. [[00:06:25](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=385.58s)]
*  Is it too late? [[00:06:26](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=386.58s)]
*  Has the train left the station or are there things that can be done to pull some of this [[00:06:27](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=387.58s)]
*  back or is this all too late? [[00:06:33](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=393.32s)]
*  No, it is not too late. [[00:06:34](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=394.98s)]
*  That is one of the most important things that I hope people can take from my book is technology [[00:06:36](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=396.40000000000003s)]
*  is never inevitable. [[00:06:40](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=400.56s)]
*  It is always a product of human choices and we are all humans that have choices that can [[00:06:41](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=401.56s)]
*  actually shape the future of this technology. [[00:06:46](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=406.44s)]
*  And so these companies, they require a lot of resources to develop these technologies. [[00:06:49](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=409.32s)]
*  They require our data. [[00:06:54](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=414.02s)]
*  They require our intellectual property. [[00:06:55](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=415.84s)]
*  They require community land so that they can build data centers for training these systems. [[00:06:58](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=418.06s)]
*  And what we've seen is a lot of different groups actually start pushing back against [[00:07:03](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=423.12s)]
*  these companies. [[00:07:08](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=428.28s)]
*  Artists and writers are suing these companies. [[00:07:09](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=429.65999999999997s)]
*  That is them reclaiming ownership of their data. [[00:07:11](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=431.18s)]
*  Makeup artists are suing. [[00:07:13](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=433.78s)]
*  Makeup artists are suing. [[00:07:16](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=436.1s)]
*  There are consumers that are not using these tools either. [[00:07:20](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=440.26000000000005s)]
*  They're saying I don't want to actually give my data to these companies because I don't [[00:07:22](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=442.98s)]
*  believe in them. [[00:07:26](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=446.66s)]
*  There are activists that are protecting their land and saying no, you cannot build a data [[00:07:27](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=447.90000000000003s)]
*  center here unless you give us some kind of mutually beneficial agreement for allowing [[00:07:31](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=451.26000000000005s)]
*  us. [[00:07:35](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=455.94s)]
*  And students and teachers are rising up saying wait a minute, what is this doing to our schools? [[00:07:36](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=456.94s)]
*  What is this doing to our education? [[00:07:41](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=461.14000000000004s)]
*  And so if we can do that 100,000 fold, then we will get to a place where technology will [[00:07:42](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=462.74s)]
*  be more broadly beneficial. [[00:07:48](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=468.62s)]
*  Karen Howe with the good, the bad, and the very terrifying. [[00:07:50](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=470.74s)]
*  Thank you, author of Empire of AI. [[00:07:54](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=474.62s)]
*  Thank you so much for joining us. [[00:07:56](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=476.46000000000004s)]
*  Thank you so much. [[00:07:57](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=477.46000000000004s)]
*  We'll have to have you come back on as this continues to terrify all of us. [[00:07:58](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=478.46000000000004s)]
*  We'll be back with a lot more. [[00:08:02](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=482.78000000000003s)]
*  I'm scared. [[00:08:04](https://www.youtube.com/watch?v=RiKjcCKlvAA&t=484.5s)]
