# Sunday Special: Elon Musk at 'DealBook'
**NewYorkTimesPodcasts:** [December 03, 2023](https://rr4---sn-ab5sznzk.googlevideo.com/videoplayback?expire=1710988544&ei=oEj7Za2oFI6N_9EPyuuTgAM&ip=128.59.179.6&id=o-AF_Yk4QTWc_urjdIFWbjcmomNnkLWPTrDhF4kscRUoqW&itag=139&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=7e&mm=31%2C26&mn=sn-ab5sznzk%2Csn-p5qddn7z&ms=au%2Conr&mv=m&mvi=4&pl=16&initcwndbps=1735000&vprv=1&mime=audio%2Fmp4&gir=yes&clen=34337842&dur=5630.879&lmt=1701602213318782&mt=1710966550&fvip=1&keepalive=yes&c=ANDROID_EMBEDDED_PLAYER&txp=6218224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Cmime%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIgdkqaqE3eeoyA1U1599RhOopWV2aRkGwSJxym8dDsBYcCIQCmX6q0Q7jqNVhSTnJ8JTpCFNsV9pFJtuevUstYJo-1Tw%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=ALClDIEwRQIgAO4JkaZqCmOidHouMYgpCwU3rP5A-ftcvj8-_VaNubICIQCN2Udz6_RygE6jb0RaWLk97QnKsQVActWX80DwPgKCnQ%3D%3D)
*  Hey, it's Michael.
*  This weekend we're bringing you something a little different from our colleagues here
*  at The New York Times.
*  Today, an interview with Elon Musk, one of the most consequential, complicated, and controversial
*  people of our time.
*  Just a few days ago, Musk sat down with business columnist Andrew Ross Sorkin for an interview
*  before a live audience.
*  It's a remarkable conversation.
*  Elon presses Musk on a recent public controversy, but he also explores Musk's ideas about a variety
*  of topics, freedom of speech, technology, optimism, aliens, and screen time.
*  It was all part of a series of live interviews put together by our colleagues at Dealbook
*  with significant leaders, including Vice President Kamala Harris and former House Speaker
*  Kevin McCarthy.
*  If you want to hear them all, you can listen on our NYT audio app or search Dealbook Summit
*  wherever you get your podcasts.
*  Now, here's Andrew Ross Sorkin in conversation with Elon Musk.
*  My mind often feels like a very wild storm.
*  Did your storm, a happy storm?
*  No.
*  This is Andrew Ross Sorkin with The New York Times, and you're listening to the best interviews
*  from our annual Dealbook Summit event recorded live yesterday in New York City.
*  Good evening, everybody.
*  Thank you so much for being with us throughout the day, and I couldn't be more pleased to
*  sit with Elon Musk as our final interview of this remarkable time we've all had together.
*  He doesn't need much of an introduction, but I want to say a couple things.
*  He's the richest person in the world.
*  He's the most consequential individual in the world right now.
*  He runs the most innovative companies in the world, Tesla SpaceX, Starlink, which is
*  part of that neural link, the boring company X and his X.ai.
*  He's disrupted each of these lanes.
*  He's moved at breakneck speeds, but he's faced a strong controversy in the process.
*  He joins us today following a visit as you all know so well.
*  We discussed earlier on Monday to Israel where he met with the Prime Minister there and
*  the President of Israel, and we're going to talk about everything.
*  And my hope is that we can talk about how he thinks about his influence, about his power,
*  about all of it, and we're going to talk about innovation and everything else.
*  I want to say just two other things real quick.
*  We met each other for the first time 16 years ago.
*  Yes, long time.
*  It's been a long time.
*  And all this kids were three.
*  When we first met, I think you were just, you were about to deliver your first roadster.
*  I don't think you had yet.
*  My page was still waiting.
*  Yeah, like 2007, 2008.
*  2007, 2008.
*  I remember going back to the newsroom and saying, I think I just met the next Steve Jobs.
*  And I'm going to hold to that.
*  I'm going to hold to that.
*  But a lot has happened between when I first met you and now you came to deal with.
*  I've been boring, that's for sure.
*  Well, I'll actually take you by a drug boring company.
*  2012, you came to deal book and sat on this stage and we're thrilled to have you back.
*  But there's been so much that's happened between now and then and there's been so much
*  that's happened in the past week, week and a half.
*  And a lot of folks called me up and said, you really, you're really going to host
*  you on Musqueer.
*  And you believe what he just said on Twitter, on X.
*  On X.
*  Yeah, yeah.
*  No idea what this Twitter is.
*  And.
*  And.
*  Should you platform him?
*  That's what they said.
*  Should you platform him?
*  And then I said, I think it's our role and I know you have issues with journalists.
*  I have a platform.
*  I know you have it in two journalists, oftentimes.
*  But I said it's our role to have conversations and to inquire and to and sometimes even
*  to interrogate ideas.
*  And I'm hoping we can do that.
*  So I want to start just so we can begin this conversation and just level said, take us
*  through everything that happened if you could.
*  Everything.
*  No, over the past week and a half.
*  How long have you got?
*  We're going to we've got the time.
*  Okay.
*  You send out a post or an X or a tweet.
*  Yeah, that was whatever.
*  Yeah, I'm trying to say like when things were just 140 characters, it made sense to call
*  them a tweet because it was like a much little bit of stripping.
*  But when you know, point of which you put like three hour videos on, it's like it's very
*  long tweet.
*  So here we are.
*  This is more descriptive, I think.
*  And at some point, I don't know where you were, but you write in responding to another
*  tweet.
*  Yeah.
*  This is the actual truth.
*  And it set off a firestorm of criticism all the way to the White House.
*  Right.
*  And then you make this trip to Israel.
*  You have advertisers who've left the platform.
*  People calling you.
*  Well, the trip to Israel is independent of it wasn't something like a apology tour.
*  I don't even clear.
*  That was.
*  Well, let's talk about that.
*  So just take us back to the moment at which you write that.
*  Trip to Israel is independent of it was like in response to that at all.
*  Well, let's do it.
*  We'll do Israel is a moment.
*  And I have no problem being hated by the way.
*  I hear it away.
*  Well, but you know what, let's go straight to that then for a second.
*  Sure.
*  Because there is an idea.
*  And you could say that I think it's a real weakness to want to be liked.
*  A real weakness.
*  I do not have that.
*  Let me ask you this then.
*  There's a difference between saying I don't care if anyone likes me or they hate me.
*  But given your power and given what you have amassed and the importance you have, I would
*  think you want to be trusted.
*  I would think maybe you don't need to be liked or hated.
*  But trusted matters.
*  If X is going to become a financial platform where people are going to put their money,
*  where the government is going to give you money for rockets, where people are going to
*  get into the cars, they need to ultimately decide that they don't have to say that they
*  love you, but that you are ultimately a decent and good human being.
*  Yes.
*  I think I am, but I'm certainly not going to do some sort of tap dance to prove to people
*  that I am.
*  As for trust, I think you break that down in a few ways.
*  If you want satellites sent to over reliably, SpaceX will do 80% of all mass to over this
*  year.
*  China will do 12%.
*  The rest of the world will do eight.
*  That includes Boeing, Lockheed, and everyone else.
*  So the track record of the rocket is the best by far of anything.
*  You could hate my guts.
*  You could not trust me.
*  It is relevant.
*  The rocket track record speaks for itself.
*  With respect to Tesla, we make the best cars.
*  Hate me or indifferent.
*  Do you want the best car or do you not want the best car?
*  So I will certainly not pander.
*  The only reason I'm here is because you are a friend.
*  What was my speaking fee?
*  First of all, I'm Andrew.
*  But yeah, sorry.
*  It's OK.
*  Second of all, we've known each other for a very long time.
*  I'm talking.
*  Yes.
*  And listen.
*  You know.
*  What I'm trying to illustrate is that sometimes I say the wrong thing.
*  I think there are a lot of people who are tired, but let me go back.
*  No.
*  But you should hear the sketches that SNL wouldn't post, by the way.
*  Those are really good.
*  And I would say unfortunately, or fortunately, unfortunately, whatever friendship we have,
*  not great.
*  We don't talk to you that much.
*  But let me ask you this.
*  That's true.
*  That's true.
*  Where am I?
*  Doesn't match with the footballs.
*  Yeah.
*  I hear because you're a friend, not because I'm being paid or because I need any validation
*  or anything.
*  And I promise you I'd be here, and that's why I'm here.
*  Well, I appreciate you being here.
*  I appreciate you being here.
*  But let me ask you this, then.
*  You write this tweet that says that this is the actual truth.
*  People read that tweet.
*  Yes.
*  And they say Elon Musk is an anti-Semite, that he is riling up this base.
*  You're hearing it from, as I said, the White House.
*  You're hearing it from Jewish groups all over.
*  I think Jonathan Greenblatt from the ADL is here.
*  There's lots of people who say this.
*  And by the way, it's not just that.
*  Did I read the whole thing?
*  I did.
*  And that's why I want to ask you that.
*  Excuse me?
*  I said more than what you just wrote.
*  Yes.
*  No, there was absolutely more.
*  But I'll tell you the thing that struck me.
*  It wasn't, and I'm an American Jew, it wasn't just the people who had that view.
*  It was actually people who really are anti-Semites who said, oh my goodness, go Elon.
*  This is fabulous.
*  And that actually was the thing that really, really set me back.
*  I said to myself, what's going on here?
*  And I want to know how you felt about that in that moment when you saw all of this happening.
*  Yeah.
*  Well, first of all, I did clarify almost immediately what I meant.
*  I would say that that was, if I could go back and say, I should, in retrospect, not have
*  replied to that particular person.
*  And I should have written in greater length as to what I meant.
*  I did subsequently clarify it and replies.
*  But those tarfcations were ignored by the media.
*  And essentially, I handed a loaded gun to those who hate me.
*  And arguably to those who are anti-Semitic, for that, I'm quite sorry, that that was not
*  my intention.
*  So I did post on my primary timeline to be absolutely clear that I'm not anti-Semitic.
*  And that I, in fact, if anything, am filersemitic.
*  And the trip to Israel was planned before any of that happened.
*  It was just nearly handled there.
*  Do you see this thing?
*  You know what it is?
*  I do, because I actually followed your tire trip to Israel.
*  Right.
*  What do you tell everybody?
*  This says, says bring them home.
*  The hostages.
*  It was given to me by the parents of one of the hostages.
*  And I said I would wear it as long as there was a hostage store meeting.
*  And I have.
*  What was that trip like?
*  And obviously, you know that there's a public perception that that was part of a apology
*  tour, if you will.
*  That this had been said online.
*  There was all of the criticism.
*  There was advertisers leaving.
*  We talked about bi-group today.
*  I hope they stop.
*  You hope.
*  You don't want them to advertise?
*  No.
*  What do you mean?
*  If somebody's going to try to blackmail me with advertising, blackmail me with money, go
*  f*** yourself.
*  But go f*** yourself.
*  Is that clear?
*  I hope it is.
*  Hey, Bob.
*  Sure, and the one is.
*  Well, let me ask you then.
*  Sorry, Phil.
*  I'm going to advertise.
*  How do you think that about the economics of X?
*  If part of the underlying model, at least today, and maybe it needs to shift, maybe the
*  answer that needs to shift away from advertising, if you believe that this is the one part of your
*  business where you will be beholden to those who have this view, what do you do?
*  F.
*  Why?
*  I understand that, but there's a reality too.
*  Right?
*  Yes.
*  No, no.
*  I mean, Linda Yaccarino is right here and she's got to sell advertising.
*  Absolutely.
*  No, no, no, no.
*  Tell me.
*  Actually, what this advertising boycott is going to do is going to kill a company.
*  And you think that the whole world will know that those advertisers killed the company and
*  we will document it in great detail.
*  But those advertisers, I imagine, are going to say, they're going to say, we didn't kill
*  the company.
*  Oh, yeah.
*  They're going to say, I'll tell you, to Earth.
*  But they're going to say that they're going to say you want that you killed the company
*  because you said these things and that they were inappropriate things and that they didn't
*  feel comfortable on the platform.
*  Right?
*  That's what I'm going to say.
*  And let's see how Earth responds to that.
*  Something like, okay, then this goes back to, we'll both make our cases.
*  Right.
*  And let's see what the outcome is.
*  What are the economics of that for you?
*  I mean, you have enormous resources so you can actually keep this company going for a
*  very long time.
*  Would you keep it going for a long time if there was no advertising?
*  I mean, if the company fails because an advertising boycott, it will fail because of an advertising
*  boycott and that will be what bankrupt the company and that's what everyone in Earth
*  will know.
*  What do you think then of the, again, it's the idea of trust though.
*  Then it'll be gone and it'll be gone because an advertising boycott.
*  But you recognize that some of those people are going to say that they didn't feel comfortable
*  on the platform.
*  And I just wonder and ask you and think about that for a second.
*  Tell us the judge.
*  But the judge is going to be the judge is the public.
*  And you think that the public is going to say that Disney is making a mistake.
*  Yes.
*  And they're going to boycott Disney?
*  They already are.
*  Well, there are some that are for lots of different reasons.
*  But you think that this is going to, that you have the, this goes to actually the interesting
*  of power and leverage.
*  Let the chips fall where they may.
*  Let the chips fall where they may.
*  Can I ask why that is the approach?
*  I ask it because you've been very approach.
*  Well, you've been very particular about the approach to Tesla.
*  I mean, you think about the engineering involved in that, the approach to SpaceX, the approach
*  to some of the stuff you're doing with AI has been very specific.
*  Right?
*  There's not a let the chips fall where they may approach to those businesses.
*  I don't think.
*  No, we focus on making the best products.
*  And Tesla has gotten to where it's gotten with no advertising at all.
*  I understand that.
*  Tesla currently sells to quite as much in terms of electric vehicles as rest of electric
*  car makers in the United States combined.
*  Tesla has done more to this healthy environment than all other companies combined.
*  We're fair to say that therefore as a leader of the company, I've done more for the environment
*  than any single human on earth.
*  How do you feel about that?
*  How do I feel about that?
*  Yeah, no, I'm asking you personally how you feel about that because this goes, we're
*  talking about power and influence and I'm saying, I'm saying what, what I care about is
*  the reality of goodness, not the perception of it.
*  And what I see all over the place is people who care about looking good while doing evil.
*  Fuck them.
*  Okay.
*  Let me ask you this because I think part of this, by the way, there's some people who
*  said look, owning X to begin with has just created problems that you've created.
*  So many amazing things that are changing our world.
*  And I know you want to make X this fabulous town square free speech platform, but that
*  onto itself that that has created such a distraction of all of these things.
*  This is the conversation we're having.
*  We're not focused, we're not talking at least yet and we will.
*  On Tesla you have your cyber truck deliveries tomorrow and everything else that you're doing.
*  But is there any, the biggest part of anything by far on earth this year?
*  Is there any part of you though that just says, you know what, I just shouldn't have done
*  this or maybe I should sell it or give it away or do something else with the X piece
*  of it.
*  Given the propensity for some of the things that you do and say on that platform to create
*  these issues.
*  Yeah.
*  I will oppose some, I've done on the platform.
*  I think there might be 30,000 or something like that.
*  Right.
*  Once in a while, I will say something foolish.
*  I have.
*  I would certainly put that comment that you've said the actual truth among perhaps one of the
*  most foolish, if not the most foolish thing I've ever done on the platform.
*  And I did do my best to clarify afterwards that I certainly do not mean anything and
*  symmetric in that.
*  The nature of the criticism was simply that the Jewish people have been persecuted for
*  thousands of years.
*  There is a natural affinity, therefore, for persecuted groups.
*  This has led to the funding of organizations that essentially promote any persecuted
*  group or any group with the perception of persecution.
*  This includes radical Islamic groups.
*  Everyone here has seen the massive demonstrations for Hamas in every major city in the West.
*  That should be jared.
*  Well, a number of those organizations received funding from prominent people in the Jewish
*  community.
*  They didn't expect that to happen.
*  But if you generically, without condition, if you found persecuted groups, in general,
*  some of those persecuted groups, unfortunately, weren't your annihilation.
*  And what I meant by that, when I subsequently clarified, is that it's unwise to find organizations
*  that support groups that want your annihilation.
*  Is this coming across?
*  Not really?
*  Yeah, it is.
*  My question to you, though, I think, is logically this makes a lot of sense.
*  Is there any part of you?
*  Tell me what happens, though, once all this happens.
*  Let's say you fund a group, and that group supports Hamas.
*  If you want it, you two die.
*  Perhaps you should not fund them.
*  But you do appreciate that when you wait into these very delicate waters, at these very
*  delicate times, that it can create a real, I mean, as it created headlines for the past
*  two weeks, an economic impact.
*  I'm just so curious, what happened with your brain when you see all this happening?
*  Are you sitting there going, oh my God, I stepped in and I wish I didn't do that.
*  Are you saying, through them, I hate these people, why are they after me?
*  But all of that.
*  Yeah, all of that.
*  I mean, look, I'm sorry for that pre-etern post.
*  It was foolish of me.
*  Of the 30,000, it might be literally the worst and dumbest post that I've ever done.
*  And I try to, my best to clarify, six races on day.
*  But you know, at least, I think over time, it will be obvious that, in fact, far from
*  being anti-Semitic, I'm in fact, philosemitic.
*  And all the evidence in my track record would support that.
*  There are people who say crazy things on X, as you know.
*  Maybe you think they're crazy, but they're not.
*  The aspiration for X is to be the global town square.
*  Now, if you were to walk down to, let's say, Times Square, do you occasionally hear
*  people saying crazy things?
*  Yes.
*  But they don't have the megaphone, right?
*  And that's the conundrum.
*  No, but they can only say it to the 50 or 100 people that are sitting standing there
*  in Times Square.
*  Look, the joke I used to make about old Twitter was it was like giving everyone in the
*  psych ward a megaphone.
*  So, you know, I'm aware that things can get promoted.
*  That are negative beyond the sort of circle of somebody simply screaming crazy things in
*  Times Square, which happens all the time.
*  It's pretty rare for something, frankly, that is hateful to be promoted.
*  It's not that it never happens, but it's fairly rare.
*  I mean, I would encourage people to look at, for those that use the system, when you look
*  at the feed that you receive, how often is it hateful?
*  And over time, has it gotten more or less hateful?
*  And I would say that if you look at the X-Pi-form today, versus a year ago, I think it is actually
*  much better.
*  I mean, what is your first one?
*  Are you surprised?
*  I'm just curious.
*  I use the platform religiously.
*  So you admit to being an addict.
*  And I use the for you.
*  And I will say, now the problem is, because I'm a journalist, I go looking for stuff.
*  Well, that's just saying.
*  And I also think the algorithm, for me personally, because I'm looking for stuff, also is feeding
*  the other things.
*  Well, this is actually a challenge in that.
*  Sometimes people will say, why is it showing me posts from this person that I hate?
*  And we're like, well, did you interact a lot with this person that you hate?
*  Well, yes.
*  Well, therefore, it thinks that you want to interact more with this person that you hate.
*  That's like a reasonable, you know, you kind of want to have an argument.
*  We tweet.
*  Yeah.
*  Post.
*  Let's say post.
*  When you post.
*  Listen, I'm open.
*  Anyone can have come up with a better word.
*  That would be great.
*  When you post, though.
*  But it's the least bad word I can think of as post.
*  When you post, though, do you, are you trying to do it?
*  Trying to rile up either a base or an audience.
*  Do you recognize the power you have in that?
*  And also, by the way, not just rile up, but also rile down, which is to say, as I said,
*  there are people who are demonstrably anti-Semitic on the site who I get, you boy things and all
*  sorts of things that come my way.
*  Hey, at the prawale for I was just so that I would get it too.
*  But no, but the question is.
*  My name is SuperJer.
*  You ever think to yourself, you know what?
*  I'm going to go online and I'm going to say, these people, I can't say, I'm going to
*  condemn these people that are on my site saying these things.
*  I have, you say I've condemned and I sense it.
*  But do you ever go?
*  Yeah, I said I can condemn, literally, I literally posted, I condemn anti-Semitism in all
*  its forms.
*  Like that is a literal, I believe literal post that I made.
*  I mean, I'm like, listen, I can get out the Thessaurus if you, you know, and we could,
*  you know, let me ask you a different question.
*  You, you, you, you compose it, I'll post it.
*  Okay, let me ask you this.
*  You, you are, you are on a podcast about a month ago and you said something that struck
*  me and it struck me as accurate came out of your mouth.
*  So hopefully it is.
*  But I'm hoping we go deep on this.
*  Just because I don't know, it does not mean it's true.
*  No, but you said, my mind is a storm.
*  I don't think most people would want to be me.
*  They may think they want to be me, but they don't know.
*  They don't understand.
*  What did you mean by that?
*  What was the, what, what, what, what, what, what, what, your mind being a storm, I,
*  and I think it, I mean, I have known you for quite some time.
*  I think it is a bit of a storm.
*  Yes.
*  Yeah, I mean, I, I, it as much as a, a way that metaphor makes sense.
*  My mind is often feels like a, like a, like a very wild storm.
*  I've, I've found no ideas.
*  I mean, I have more ideas than I could possibly execute.
*  So I have no shortage of ideas.
*  Innovation is not the problem.
*  Execution is the problem.
*  I've got a million ideas.
*  I mean, I've got an entire design for an electric supersonic vertical takeoff jet,
*  but I, I mean, I just, if I, I just can't do that as well.
*  I've had that for 10 years.
*  I mean, there's a million things.
*  Did you storm a happy storm?
*  No.
*  It's not a happy storm.
*  Yeah.
*  Tell us about that.
*  Because I, I think that that actually, when people try to really understand you,
*  I think that there's a lot of this comes from some other place.
*  And I want, I want to talk about that.
*  What do you think that is?
*  It was really like a psychiatrist catcher or something.
*  You know, I, I think this undergrig was born this way, but then it was amplified by a
*  difficult childhood, frankly.
*  So, but I can remember even in happy moments when I was a kid that there's just, it just
*  feels like this is just a, a rage of forces in my mind, constantly.
*  But now this, you know, productively manifests itself in technology and building things for
*  the most part.
*  So, and I think on balance, the output has been very productive.
*  I think the results as we discussed earlier with SpaceX, Tesla, PayPal, which is, you know,
*  so going today, the first year in a company that I started, in fact, the first year in
*  a company I started as a two was funded by a New York Times company, Hurston Nightrider,
*  and I remember we wrote some of the software for the New York Times website and we helped
*  bring online several hundred newspapers that previously were only in print.
*  Now this is in the 90s, which at this point is like, I'm like the grandpa flat, right
*  basically.
*  You know, the 90s and internet feels like a pre-came year in error when they were only
*  sponges.
*  So anyway, so, you know, I felt like a lot of productive things have been done and you
*  can also look at Tesla as being sort of many companies in one.
*  Like our super charging network is, if it were, if the Tesla super charging network were
*  its own company, it would be a fortune 500 company by itself.
*  Just the super charging system, we also make the cells, we build the power electronics
*  and the power train from scratch.
*  We have the most innovative structural design, the largest castings ever used.
*  We have the best manufacturing technology at Tesla, better manufacturing technology than
*  companies that have been doing it for a hundred years.
*  So these demons of the mind, for the most part, are honest to productive events.
*  That doesn't mean that once in a while they go wrong.
*  But, and this is a question I think a lot of people are always trying to figure out
*  about not just you, but sometimes themselves.
*  Meaning what is driving all of this?
*  You're doing all of these things.
*  Do you think that you would be as successful, whatever success is, if it wasn't being driven
*  by some, I think that there's something you're trying to prove, either to yourself or
*  to somebody, I don't know.
*  We're all trying to prove something.
*  I'm trying to prove to my mother.
*  I don't know.
*  No, if I were to describe my philosophy as philosophy of curiosity.
*  I mean, I did have this existential crisis when I was around 12.
*  About what's the meaning of life?
*  Isn't it all pointless?
*  Why not just commit suicide?
*  Why exist?
*  I read the religious texts.
*  I read the philosophy books, especially the German philosophy books made me quite depressed,
*  frankly.
*  Once you're not reading, show up an hour and each has a teenager.
*  But then I read Douglas Adams, who tracks the guy to the galaxy, which is a book on
*  philosophy in the form of humor.
*  And the point that Adams was making there was that we don't actually know what questions
*  to ask.
*  That's why I said that the answer is 42.
*  Basically, it was a giant computer and it came up with the answer 42.
*  But then to actually figure out what the question is, that's the actual hard part.
*  I think this is generally true also in physics.
*  At the point in which you can properly frame the question, the answer is actually the easy
*  part.
*  So, my motivation then was that, well, my life is finite, really a flash in the pan on
*  a galaxy pan scale.
*  But if we can expand the scope and scale of consciousness, then we are better able to
*  figure out what questions to ask about the answer that is the universe.
*  And maybe we can find out the meaning of life or even what question to ask is.
*  Where do we come from?
*  Where are we going?
*  Where are the aliens?
*  Are there aliens?
*  These questions, is there new physics to discover?
*  There are real questions about dark matter and dark energy.
*  So the purpose of SpaceX is to extend life beyond Earth on a sustained basis so that we
*  can at least pass one of the Fermi grade filters, which is that of being a single planet civilization.
*  If we are single planet civilization, then we are simply waiting around for some extinction
*  event, whether that is manmade or natural.
*  But if you are single planet civilization eventually, something will happen to that planet and
*  you will die.
*  If you are a multi planet civilization, you will live much longer.
*  Also, a multi planet civilization is the best natural stepping stone to being a multi-stellar
*  civilization and being out there among the stars.
*  This I think has two, this is not simply an offensive motivation, but it is also one that
*  gives meaning, man's search for meaning.
*  Let me finish this philosophy point, even though it makes seem rather esoteric, it may resonate
*  with a few people.
*  We must get past this Fermi filter of being a single planet civilization.
*  And if we do that, we are more likely to understand the nature of the universe and what questions
*  to ask.
*  If you believe in the philosophy of curiosity, then I think you should support this ambition.
*  But there is being a multi-times thesis, it is more than simply life insurance for life
*  collectively.
*  That is a defensive reason.
*  But I think also that life has to be more than simply solving one sad problem after another.
*  There have to be reasons for you wake up in the morning and you are happy to be alive.
*  There have to be reasons that you have to say why are you excited about the future?
*  What gives you hope?
*  And if you aren't sure ask your kids.
*  And I think the idea of us being a space-faring civilization and being out there among the stars
*  is incredibly inspiring and exciting and something to look forward to.
*  And there needs to be such things in the world.
*  Let me ask you a different question about competence.
*  We were having a conversation here earlier.
*  But people, where people get their competence from, some people have great security, other
*  people have great confidence.
*  And I was thinking about you because you have a very interesting history where people have
*  told you over and over again that you are wrong.
*  Well sometimes they are right.
*  Well sometimes they are but I would say that when it comes to Tesla, when it came to SpaceX,
*  people told you that you were crazy.
*  You were out of your mind.
*  This was never going to happen.
*  We are going to work.
*  And so we are going to ask you this.
*  So now when people say you are wrong, this isn't right.
*  Do you look at that and say, you know what, that's like a red flag for me because I've
*  been told so often that I'm wrong that I know and I know I'm right because I've had
*  that experience or are there people in your life when they say, you know what, you
*  know this is not right.
*  Do you know what I'm saying?
*  I think what you start to say is that, do I at this point think because I've been
*  right so many times, brothers, I said I'm wrong, that now I pass believe I'm right when
*  I fact I'm wrong.
*  You do very well.
*  What do you think?
*  No, I'm right.
*  So, yeah, look, here's the thing.
*  Physics is unforgiving.
*  Physics is unforgiving.
*  So, I mean, I have, you know, these various little things that I've come with, that physics
*  is the law and everything else is a recommendation.
*  In the sense that you can break any law made by humans, but try breaking a law made by physics
*  is much more difficult.
*  So if you are wrong and the system being wrong, the rockets will blow up and the cars will
*  fail.
*  So this is, we're not trying to just figure out what flavor of ice cream is the best flavor
*  of ice cream.
*  There's a thousand things that can happen on an rocket flight and only one of them gets
*  the rocket to orbit.
*  And so being wrong results in failure when dealing with physical objects.
*  But that's hugely important.
*  So now you've built these great companies that physically, the physics of them are enormous
*  and successful.
*  So successful, arguably, that you have leverage over everybody else, right?
*  Nobody else can do starlink.
*  Nobody else can get the rockets in space yet Amazon and Jeff Bezos are trying, but they
*  haven't yet.
*  I hope he does.
*  You hope he does.
*  Yeah, yeah.
*  I mean, I think, you know, I actually agree with, with, with, with, with, with, with
*  a lot of Jeff's motivations.
*  I mean, I think, you know, he's, you know, and I, so I'm, I, never put there with this
*  way.
*  If there was a button, I could press that would delete blue archer and I wouldn't press
*  it.
*  So I think it's good that he's spending money on, on, on, making rockets too.
*  You know, it's just perhaps he's been more talented, but, you know, it's up to him.
*  I should make a point here.
*  So nothing, nothing any of my companies have done has been to stifle composition.
*  In fact, we've done the opposite.
*  So at Tesla, we have open sourced our patents.
*  Anyone can use our patents for free.
*  How many companies do you know who've done that?
*  Can you name one?
*  I can't.
*  At SpaceX, we don't use patents.
*  So I mean, once in a while, we'll, we'll file a patent just so some patent troll doesn't
*  cause trouble.
*  But we're not stopping any, we've done, we've done nothing anti-competitive.
*  We've done nothing to stop.
*  I'm not just you at all.
*  I, I, I, I was more clarified for the audience because some companies have done, done anti-competitive
*  things.
*  I, I, I think the strange thing, or the unusual thing about SpaceX and Tesla is that
*  we've done things that have helped our competition.
*  So at Tesla, we have made our supercharger system open access.
*  We, we, we, we made our charger technology available for free to the other manufacturers.
*  The reason I know all of Garden, we could have put a wall up.
*  But instead we invited them in.
*  The reason I mentioned this though is because you've had the success in the physical physics
*  world, you now have these very difficult
*  decisions that have huge impacts on the world that are not physical decisions at all.
*  They're, they're decisions of the mind.
*  They're decisions that you and others have to make.
*  And there's a question whether you should be making these decisions at all.
*  And I, I think about it in the context of Starlink, obviously there was the report about
*  how it's being used in Ukraine and in the Russian war.
*  There's questions about, you know, Taiwan, whether Taiwan should use it or will use it.
*  I believe they're not right now because they're worried that at some point maybe the Chinese
*  will tell you that you have to, they have leverage over you and you're going to have to turn
*  that off, right?
*  I mean, these are, these are very difficult decisions.
*  And I'm so curious how you think about that.
*  And not just the decisions, the fact that you have that power.
*  I just, I think it's important for the order to understand that the reason I have these
*  powers is not because of some anti-competitive actions, it's simply because we've executed
*  very well.
*  Oh, I'm not dismissing it.
*  I think there are so many people by the way who are few supporters of what you have.
*  There are other satellites out there, you know.
*  But they're not as good as yours.
*  And we can say that maybe they're the same argument or the cars and everything else.
*  But as a result, that gives you enormous leverage, right?
*  Okay.
*  With the exception of the, by the way, these advertisers who are on X, in every other instance,
*  everybody needs you.
*  Well, I mean, nobody's letting me use our product if it's better than you somebody else's
*  product if it's the other product better.
*  And I accept that.
*  It may be one day somebody else's product.
*  You know, how is that about thing to make better products as other companies?
*  Well, and I wonder if you're back to this, to the Starlink piece of it though, because that has sort of a
*  geopolitical ramification in terms of your power and how you think about that specific power.
*  And then the power that the US government might have either over you or not over you.
*  The power that Chinese government might have over you or not over you.
*  And how those things get used.
*  I mean, what are you suggesting?
*  I'm asking the question around this very idea of how these satellites are going to be used.
*  Whether you think that you should have control of them, whether the government should have control of them.
*  How?
*  People trust the government?
*  Well, there's a lot of people who don't trust the government.
*  Exactly.
*  But then this goes back to the trust of you, right?
*  I mean, like I said, we're not the only company who has communications satellites.
*  The other satellites are just much better than theirs.
*  So it's not like we have a monopoly.
*  Do you feel like anybody has...
*  Do you feel like anybody has leveraged over you?
*  I mean, I think at the end of the day, if we make bad products that people don't want to use, then
*  the users will vote with their resources and do something else.
*  And it hit at the conversation for a second.
*  Certainly, my company is overseen by regulators.
*  And while SpaceX, Starlink, Tesla are overseen by, you know, cumulatively, over 100 regulators.
*  And actually more than that, few hundred regulators, because you've got, we're in 55 countries.
*  If you sum up all the times that I had an argument with regulators of hundreds of regulators
*  over decades, it can sound really terrible, except for they forgot to mention that there
*  were 10 million regulations we complied with and only five that I disagreed with.
*  But they list all the five.
*  And it sounds like, wow, this guy's a real maverick.
*  I'm like, yeah, but what about the 10 million we complied with?
*  One related to none of this, the leverage of countries and things over you and regulators.
*  X is this free speech platform.
*  You do business in China.
*  Lots of business, China, that's an important part of your business.
*  I imagine.
*  Well, lots of face-eye.
*  How do you think about the leverage that the Chinese have over you and do they have leverage
*  over you?
*  And how do you feel about some people would say, is it hypocritical for you to be doing
*  business in China or frankly in other countries as it relates to X and other things that don't
*  follow this free speech path that you have espoused?
*  The best that the platform can do is adhere to the laws of any given country.
*  Do you think there's something more we could do than that?
*  I think it would be very hard, but I just wonder given the strong philosophical approach
*  that you've been vocal about, whether you say to yourself, maybe I shouldn't be
*  doing business in that country?
*  Well, first of all, Starlink and SpaceX do our no business in China whatsoever.
*  Tesla has one of four factories, four vehicle factories in China.
*  In China is, you know, I don't know, a quarter of our market or something like that.
*  So it's a quarter of a market of one company.
*  The same is true, by the way, of all the other car companies.
*  They also have something on that order of quarter of their sales in China.
*  So if that's a problem for Tesla, it's a problem for every car company.
*  I mean, I think one has to be careful about not conflating the various companies because
*  I can only do things that are within the balance of the law.
*  I cannot do beyond that.
*  My aspiration is to do as much good as possible and to be as productive as possible within
*  the balance of what is legal.
*  All of them that I cannot do.
*  We'll be right back.
*  I want to pivot and talk about AI for a moment.
*  We had Jensen Wong here, whose big fan of yours is, you know.
*  Yeah, Jensen's also talking about bringing you the first box, by the way, with Ilya.
*  Interestingly enough.
*  Yes.
*  Back in 2016, I think.
*  There's a video of Jensen and me unpacking the first AI computer at OpenAI.
*  So I'm so curious what you think of what's just happened over the past two weeks.
*  While you were dealing with this other headline, series of headlines.
*  I mean, the whole other series of headlines.
*  It's so far.
*  What did you think?
*  Well, you founded it.
*  Co-founded.
*  Co-founded, yeah.
*  Well, the whole arc of OpenAI, frankly, is a little troubling because the reason for
*  starting OpenAI was to create a counterweight to Google in DeepMind, which at the time had
*  two thirds of all AI talent and basically infinite money and compute.
*  And there was no counterweight.
*  It was unipolar world.
*  And Larry in the page, and I used to be very close friends on our status house, and I'd
*  talk to Larry until the late hours of the night about AI safety.
*  And if it came apparent to me that Larry did not care about AI safety.
*  I think perhaps the thing that gave it away was what he called me a specious for being
*  pro-comality, as in, you know, like a race like that for specious.
*  So I'm like, wait a second.
*  What's out of you on, Larry?
*  And I'm like, okay, listen, this guy calling me a specious.
*  He doesn't care about AI safety.
*  We've got to have some counterpoint here because this seems like we could be listening
*  to this is no good.
*  So OpenAI was actually started, and it was meant to be open source.
*  I named it OpenAI after open source.
*  It is in fact closed source.
*  Super close.
*  It should be now renamed super close source for maximum profit AI.
*  So this is what it actually is.
*  I mean, fail loves irony.
*  I mean, in fact, friend of mine says like the way to predict outcomes is the most ironic
*  outcome is the most, it's like this outcomes razor, like the simplest sort of explanation
*  is most likely.
*  And my friend, Jonas, viewers that the most ironic outcome is the most likely.
*  And that's what happened with OpenAI.
*  It's gone from an open source foundation of I1, T3 to suddenly it's like a $90 billion
*  full profit corporation with closed source.
*  So I don't know how you go from here to there.
*  That seems like a, I don't know how you get, I don't know if, is this legal?
*  I'm like, let's go.
*  So as you saw Sam Waltman get ousted by somebody you know, Ilia.
*  And Ilia was somebody who was a friend of yours.
*  You brought him there.
*  Your relationship with Larry Page effectively broke down over you recruiting him away at
*  this.
*  That's correct.
*  That was the Larry Refuse repressor from the Afriya recruited Ilia.
*  And so here's Ilia apparently saying something is very wrong.
*  I think we should be concerned about this because I think Ilia actually has a strong moral
*  compass.
*  He thinks about, you know, he really sweats it over questions of what is right.
*  And if Ilia felt strongly enough to want to, you know, fire Sam, well, I think the world
*  should know what was that reason.
*  Have you talked him?
*  I've reached out, but he doesn't want to talk to anyone.
*  Have you talked to other people behind the scenes?
*  Is this all happening?
*  I've talked to a lot of people.
*  As nobody, I've not found anyone who knows why.
*  Have you?
*  I think we are all still trying to find out.
*  I mean, one of two things is, either it was a serious thing and we should know what
*  it is or it was not a serious thing and then the board should resign.
*  Anything to say, I'm all men.
*  I have mixed feelings about Sam.
*  I do, you know, the ring of power, you know, can corrupt.
*  And he is the ring of power.
*  So, you know, I don't know.
*  I think I want to know why Ilia felt so strongly as far as Sam.
*  The sounds like a serious thing.
*  I don't think it was trivial.
*  And I'm quite concerned that this, that this, you know, dangerous element of AI that they've
*  discovered.
*  Yes.
*  You think they've discovered something?
*  That'll be my guess.
*  Where are you with your own AI efforts relative to where you think open AI is?
*  Where you think Google is?
*  Where do the others go?
*  I mean, on the AI front, I'm in somewhat of a quandary here because I've thought AI could
*  be something that would change the world in a significant way since I was in college.
*  I mean, like 30 years ago.
*  So, the reason I didn't go bold AI right from the get go is because I was uncertain about
*  which edge of the double edge so it would be sharper.
*  The good edge of the bad edge.
*  So I held off on doing anything on AI.
*  I could have created, I think, a leading AI company and kind of open AI actually kind
*  of his that because I was just uncertain if you make this magic genie what will happen.
*  Whereas I think building sustainable energy technology is much more of a single edge
*  sword that is single edge good, making life multi planetary, I think single edge good.
*  Installing mostly single edge good, I mean, giving people better connectivity, people
*  that don't have connectivity or too expensive, I think is very much a good thing.
*  So, I think it was instrumental by the way and holding the Russian advance, the Ukrainian
*  said so.
*  So, you know, I think there is, but with AI, you've got the magic genie problem.
*  You may think you want a magic genie, but once you get that genie out of the bottle, it's
*  hard to say what happens.
*  How far are we away from that genie being out of the bottle, you think?
*  We think it's already out.
*  And the genie is certainly poking its head out.
*  But AGI, the idea of artificial general intelligence, given what you now are working on yourself and
*  you know how easy or hard it is to train, to create the inferences, to create the weights,
*  I hope I'm not getting too far in the weeds of just how this works, but those are the basics
*  behind the software end of this.
*  If funny, you know, all these weights, they're just basically numbers in a comma separated
*  value file.
*  And that's our digital god, the CSP file.
*  Not that funny.
*  That's kind of literally what it is.
*  So, I think it's coming pretty fast, you know.
*  Because that, I mean, you famously have admitted to overstating how quickly things will happen.
*  But how quickly do you think this will happen?
*  If you say smarter than the smartest human at anything, it may not be then quite smarter than
*  all humans.
*  Well, machine augmented humans, you know, because we people who got computers and stuff,
*  it's a higher bar.
*  But you say it's more than any, you know, can write as good a novel as say, Jacob Relling
*  or just go into physics or invent new technology.
*  I would say that we are less than three years from that point.
*  Let me ask you a question about XAI and what you're doing.
*  And because there's an interesting thing that's different, I think, about what you have
*  relative to some of the others, which is your data, your information, you have all of
*  the stuff that everybody in here has put on the platform to sort through.
*  And I don't know if everybody realized that initially.
*  What is the value of that?
*  Yeah, data is very important.
*  You could say that data is probably more valuable than gold.
*  And then maybe you have actually, maybe you have more, maybe you have the gold in X in
*  a different way.
*  In a way, again, that I don't know if the public appreciates what that means.
*  Yes.
*  X is the, it might be the single best source of data.
*  I mean, it is, there are more, you know, people, links that go to, if you feel click on more
*  links to X than anything else on Earth.
*  Sometimes people think Facebook or Instagram is a bigger thing, but actually there are more
*  links to X than anything.
*  You can, there's public information.
*  You can Google it.
*  Okay, let me ask you a, so it is, it is a, where you would find what is happening right
*  now on Earth at any given point in time.
*  The whole open-air drama played out in fact on the X platform.
*  So it is one of the, it's not, they're, you know, Google certainly has a massive amount
*  of data.
*  It is a massive amount of data.
*  So it is not like, but it is one of the best source of data.
*  Can I ask you an interesting IP issue, which I think is actually something I can say as
*  somebody who's in the creator business and journalistic business and whatnot, or care
*  about copyright.
*  So one of the things about training on data has been this idea that you're not going
*  to train or these things are not being trained on people's copyrighted information historically
*  that's been the concept.
*  Yeah, that's a huge lie.
*  Say that again?
*  Yes, with these, I, with these, as I will train on copyrighted data obviously.
*  So you think it's a lie when, when open AI says that this is not, none of these guys
*  say they're training on copyrighted data.
*  Oh, that's a lie.
*  It's a lie.
*  Yeah, straight up.
*  Straight up lie.
*  Okay.
*  Absolutely.
*  Obviously it's been trained on copyrighted data.
*  Okay, so the other.
*  That's a very interesting question, which is all of the people who have been uploading.
*  It's like a whatever.
*  All of the people who have been uploading articles, the best quotes from different articles,
*  videos, 2X.
*  All of that can be trained on.
*  And it's interesting because people put all of that there and those quotes have historically
*  been sort of fair use, right?
*  They do.
*  People are putting those quotes up there.
*  And individually, on a fair use basis, you'd say, okay, that makes sense.
*  But now there are people who do threads.
*  And by the way, there may be multiple people who've done, you know, an article that has
*  a thousand words, technically all thousand words could have made it onto X somehow.
*  And effectively, now you have this remarkable repository.
*  And I wonder what you, how you think about that?
*  Again, and how you think the creative community and those who, where the original IP owners
*  should think about that.
*  I don't know, except to say that by the time these lawsuits are decided, we'll have digital
*  God.
*  So, as digital God at that point, these lawsuits won't be decided before on a time frame
*  that is relevant.
*  Is that a good thing or a bad thing?
*  I think we live, you know, there's that, I don't know if it's actually real Chinese
*  or not, but maybe live an interesting time, which is apparently not a good thing.
*  But I would prefer to personally, I would prefer to live an interesting time.
*  And we live in the most interesting of times.
*  I think, for a while, I was like really getting demotivated and losing sleep over the sort
*  of the threat of AI danger.
*  And then I finally sort of became fatalistic about it and said, well, even if I knew it was
*  annihilation with certain, would I choose to be alive at that time or not?
*  And I said, I probably would have choose to be alive at that time because it's the
*  most interesting thing.
*  Even if there's nothing I could do about it.
*  So then, you know, then basically sort of a fatalistic resignation helped me sleep at
*  the night because I was having trouble sleeping at night because of AI danger.
*  Now what to do about it?
*  I mean, I've been the biggest, the one banging the drum, the hardest, by far the longest,
*  or at least one of longest for AI danger.
*  And the regulatory things that are happening, the single biggest reason that is happening
*  is because of me.
*  We're never going to get the wrong surround.
*  We talked to the Vice President this afternoon.
*  He said she wants to regulate it.
*  People can try to regulate social media for years and have done nothing effectively.
*  Well, there's regulation around anything which is a physical danger to the public.
*  So cars are heavily regulated.
*  Communications are heavily regulated.
*  Rockets are now crafted, heavily regulated.
*  The general philosophy about regulation is that when something is a danger to the public,
*  that then needs to be some government oversight.
*  So I think in my view, AI is more dangerous than nuclear bombs.
*  And we regulate nuclear bombs.
*  You can't just go make a nuclear bomb in your backyard.
*  I think we should have some kind of regulation with AI.
*  Now, this tends to cause the AI accelerationists to get up and on because they think AI is
*  sort of having basically.
*  But you typically don't like regulation.
*  You've pushed back on regulators for the most part of the world of Tesla and so many instances
*  where we read articles about you pushing back on the regulators.
*  And so curious why in this instance, now you own one of these businesses.
*  As I said a moment ago, one should not take what is viewed in the media as being the whole
*  picture.
*  There are literally hundreds, not an exaggeration, so there are probably 100 million regulations
*  that my companies comply with.
*  And there are probably five that we don't.
*  And if we just see some of those regulations, it's because we think the regulation that
*  is meant to do good doesn't actually do good.
*  But that's not the thing to find regulations for the system.
*  If there are laws and rules, whether the idea that you're making the decision that the
*  law and the rule shouldn't be the law and the rule, then right?
*  I'm saying you're following any mistaken.
*  And it should be obvious that you're mistaken.
*  My company's automotive is heavily regulated.
*  We would not be allowed to cause the road if we did not comply with this vast body of
*  regulation.
*  You could fill up the stage with literally six foot high with the regulations that you
*  have to comply with to make a car.
*  You could have a room full of phone books.
*  That's how big the regulations are.
*  And if you don't comply with all of those, you can't sell the car.
*  And if we don't comply with all the regulations for rockets or for stalling, they shut us down.
*  So in fact, I am incredibly compliant with regulations.
*  Now once in a while, there'll be something that I disagree with.
*  The reason I would disagree with this is because I think the regulation, in that particular
*  case, in that rare case, does not serve the public good.
*  And therefore, I think it is my obligation to object to a regulation that is meant to serve
*  the public good if it doesn't.
*  That's the only time I object.
*  Not because I seek to object.
*  In fact, I'm incredibly rule following.
*  And I ask you a separate question, a social media related question.
*  We've been talking about TikTok today, ahead of the election.
*  So TikTok is, what do you think of TikTok?
*  Do you think it's a national security threat?
*  I don't use TikTok.
*  Fifth, again, you don't.
*  I don't personally use it.
*  But for people that, for teenagers and people in their 20s, they seem almost religiously
*  addicted to TikTok.
*  So we will watch TikTok for like two hours a day.
*  I stopped using TikTok when I felt the AI probing my mind.
*  And I've made it uncomfortable.
*  So I stopped using it.
*  Anyway, and in terms of anti-Semitic content, I mean TikTok is right with that.
*  It has the most viral anti-Semitic content by far.
*  But do you think the Chinese government is using it to manipulate the minds of Americans?
*  No.
*  Is that something that you think we should worry about?
*  I mean, you have different states that are trying to ban it.
*  I don't think this is some Chinese government plot.
*  But it is the TikTok algorithm is entirely AI powered.
*  So it is really just trying to find the most viral thing possible.
*  What is going to keep you glued to the screen?
*  That's it.
*  Now, on sheer numbers, there are on the order of two billion Muslims in the world.
*  And I think, you know, much smaller number of Jewish people.
*  Which 20 million?
*  Something?
*  Many orders of magnitude fewer.
*  So if you just look at content production, just on sheer numbers basis, this is going to
*  be overwhelmingly anti-Semitic.
*  Let me have to keep on an argument.
*  I'm asking a political question.
*  And I've been trying to square this one in my head for a long time.
*  In the last two or three years, you have moved, decidedly, to the right.
*  I think.
*  Have I?
*  Well, we can discuss this.
*  I think that you have been espousing and promoting a number of Republican candidates and
*  others.
*  You have been frustrated with the Biden administration over I think unions and feeling like they did
*  not respect what you've created.
*  Well, I mean, without any, during nothing to provoke the Biden administration, they held
*  an electric vehicle summit at the White House and specifically refused to let Tesla attend.
*  This is in the first six months of the administration.
*  And we inquired.
*  We're like, we literally make more electric cars than everyone else combined.
*  Why are we not allowed?
*  Why are you only letting for GM, Chrysler, and U.A.W. and you're specifically disloving
*  us from the EV summit at the White House?
*  We're done nothing to provoke them.
*  Then Biden went on to add insult injury and publicly said that GM was leading the electric
*  car revolution.
*  This was in the same quarter that Tesla made 300,000 electric cars and GM made 26.
*  Does that seem fair to you?
*  So tell me this then.
*  It doesn't seem fair.
*  And I've asked repeatedly, you've probably seen the Obama.
*  I had a great relationship with Obama.
*  So there's not a, but then there's this.
*  But then there's this.
*  So certain hours for six, I've stood in line for six hours to shake Obama's head.
*  Okay.
*  So let me just ask on a personal level, I can see it in your face.
*  This hurt you personally.
*  And I heard the company too.
*  And it was the insult to, you know, Tesla has 140,000 employees.
*  Okay.
*  Half of them are in the United States.
*  Tesla has created more manufacturing jobs than everyone else combined.
*  So last this then, you've devoted at least the last close to 20 years of your life if
*  not more to the climate, climate change, trying to get Tesla off the ground in part
*  to improve climate.
*  You talked about that.
*  Yeah.
*  A real right-wing motive is.
*  Repeatedly.
*  Got far right, if anything.
*  No, I understand that.
*  And that is so, it's, it's, it's, it's, it's, it's reverse psychology next level.
*  Well, no, but so here's then the question, which is how do you square the support that
*  you have given?
*  I believe you were at a fundraiser for, Viva Grama Swami for example, who says that the
*  climate, climate issue is a hoax.
*  Right?
*  I'm not sure if it's a weird thing on that.
*  I, but I would think that that would be such a singular issue for you.
*  I would think that the climate issue is such a singular issue for you that actually it
*  would disqualify almost anybody who, who didn't take that issue seriously.
*  Well, I haven't endorsed anyone for, for present.
*  I mean, I wanted to hear what Viva had to say, because I think some of his things are,
*  that's one of the things he says, I think are pretty solid.
*  You know, he is concerned about government over each, about government control of information.
*  I mean, the degree to which old Twitter was basically a soft puppet of the government
*  was ridiculous.
*  So you know, it seems to me that there's a very severe violation of the First Amendment
*  in terms of how much the government control, how much control the government had of old
*  Twitter.
*  And it no longer does.
*  So you know, there's a reason for the First Amendment.
*  The reason for the First Amendment for freedom of speech is because the people that immigrated
*  to this country came from a place where there was not freedom of speech.
*  And they were like, you know what?
*  We've got to make sure that that's constitutional because where they came from, if they said
*  something, they have to be put in prison, or they've be, you know, something bad would
*  happen to them.
*  So and freedom of speech, you have to say, when is it relevant?
*  It's only relevant when someone you don't like can say something you don't like, or it
*  has no meaning.
*  And as soon as you sort of throw in the towel and concede to censorship, it is only
*  a matter of time before someone's censors you.
*  And that is why we have the First Amendment.
*  We'll be right back.
*  Could you see yourself voting for President Biden?
*  If it's a Biden Trump election, for example?
*  I think I would not vote for Biden.
*  You vote for Trump.
*  I'm not saying I'd vote for Trump, but I mean, this is definitely a different choice here.
*  You know, would you vote for Nikki Haley?
*  Nikki Haley, by the way, wants all social media names to be exposed, does you know?
*  No, I think that's outrageous.
*  Yeah, no, I'm not going to vote for some pro-centred censorship candidate.
*  I think you have to consider that there is a lot of wisdom in these amendments, you know,
*  in the Constitution.
*  And a lot of these things, we take for granted here in the United States that don't even
*  exist in Canada.
*  There's no constitutional rights to freedom of speech in Canada.
*  So, you know, and there's no random rights in Canada.
*  If you will, I think, you know, you have the right to remain on.
*  You don't actually in Canada.
*  So, you know, half-cannoted, and I can say these things off of.
*  But, you know, so like, you just got, you, the freedom of speech is incredibly important,
*  even when people sit at end of like that.
*  It's actually especially important.
*  In fact, it is only relevant when people you don't like can say things you don't like.
*  And do you think right now that's meaningless?
*  You think right now the Republican candidates or the Democrats are more inclined, I mean,
*  this is where you go to, I assume, to woke and anti-woken, the mind-bierist issue that
*  you've talked about.
*  Which party do you think is more pro-freedom of speech given all the things you've seen?
*  We also see, you know, desantis, you know, preventing people from reading certain things.
*  Maybe you think that's correct.
*  No.
*  Look, we actually are in an odd situation here where, on balance, the Democrats appear
*  to be more pro-sponsorship than the Republicans.
*  I mean, that used to be the opposite.
*  The left position was freedom of speech.
*  I believe at one point the ACLU even defended the right of someone to claim that there
*  were not, see or something like that.
*  So like the left was freedom of speech is fundamental.
*  And I mean, my perception, perhaps it is inaccurate, is that the pro-sensorship is more
*  on the left than the right.
*  We certainly get more complaints from the left than the right than the right.
*  So, but my aspiration for the X platform is that it is the best source of truth, or
*  the least inaccurate source of truth.
*  Well, you know, I don't know if you were believing or not, but I think honesty is the best
*  policy.
*  And I think that the truth will win over time.
*  And we've got this great system, and it's getting better called community notes, which
*  is fantastic, I think, at correcting falsehoods or adding context.
*  In fact, we make a point of not removing anything, but only adding context.
*  Now, that context could include that this is completely false, and here's why.
*  And no one is immune to this.
*  I'm not immune to it.
*  Avertizer is not immune to it.
*  In fact, we've had community notes, which has caused us some loss in advertising speaking
*  of loss in advertising revenue.
*  If a community note, if this false advertising, the community note will say, this is false.
*  And here is why.
*  I mean, there's one specific example that is public knowledge, so I'll mention it, which
*  is at one point Uber had this ad which said, earn like a boss.
*  And there was community note, if by a boss you mean $12.47 an hour.
*  This did cause at least a temporary suspension of advertising from Uber.
*  I got to ask you a question that might make everybody in the room uncomfortable or not
*  uncomfortable.
*  It goes to the free speech issue.
*  The New York Times company and the New York Times newspaper, it appeared over the summer
*  to be throttled.
*  What did?
*  The New York Times.
*  Well, we do require that everyone has to buy a subscription, and we don't make exceptions
*  for anyone.
*  And I think if I want the New York Times, I have to pay for a subscription, and they
*  don't give me a free subscription.
*  So I'm not going to give them a free subscription.
*  But were you throttling the New York Times relative to other news organizations, relative
*  to everybody else?
*  Was it specific to the Times?
*  They didn't buy a subscription.
*  I'm only cost like $1,000 a month.
*  So if they just do that, then they're back in the saddle.
*  But you are saying that it was throttled.
*  You're not saying?
*  I mean, was there a conversation that you had with somebody who said, look, I'm unhappy
*  with the Times, they should either be buying the subscription or I don't like their content
*  or whatever.
*  Any organization that refuses to buy a subscription is not going to be recommended?
*  But then what does that say about free speech?
*  Well, let's say about amplifying research and certain voices.
*  We had cost a little bit.
*  Right.
*  But that's an interesting.
*  Yeah, it's like in South Park, when they say freedom isn't free, it costs a buck oh five
*  or whatever.
*  So but it's pretty cheap.
*  Okay.
*  Low cost freedom.
*  I got a couple more questions for you.
*  You're heading back to Texas after this.
*  Freedom to launch the cyber truck.
*  Yeah.
*  It's going to be a big launch.
*  But I wanted to ask you right now more broadly just about the car business and what you see
*  actually happening.
*  And specifically, the government put in place lots of policies as you know to try to encourage
*  more EVs.
*  And one of the things that's happened uniquely is you have now a lot of car companies saying,
*  actually, this is too ambitious for us.
*  These plans are too ambitious.
*  4,000 dealers, I don't know if you saw it just yesterday, sent the letter to the White
*  House saying, this is gone too far.
*  You're going too far.
*  You had this.
*  And TV.
*  It was an, it was a, this is going too fast too far and that there's not enough demand.
*  Our underneath all of this is this idea that maybe there's not enough demand for EVs.
*  That the American public has not bought into the, I mean, they bought into with your company
*  but they haven't bought into it broadly enough.
*  Well, I think if you make a compelling electric car, if you will buy it, no question about
*  it.
*  I mean, electric car sales in China are gigantic.
*  That's by far the biggest category.
*  And I think that would be the, you know, I mean, it's worth noting.
*  Okay, so the, so the probably the best reputation of that is that the Tesla Model Y will be
*  the best selling car of any kind on earth this year.
*  Of any kind gasoline or otherwise.
*  Is there another car company that you think is doing a good job with EVs?
*  I mean, I think the Chinese car companies are extremely competitive.
*  By far, our toughest competition is in China.
*  So I mean, there's, there's a lot of people who out there think that the top 10 car companies
*  are going to be Tesla followed by nine Chinese car companies.
*  I think they might not be wrong.
*  So China is super good at manufacturing and the work ethic is incredible.
*  So you know, like if we consider different leagues of competitiveness at Tesla, we consider
*  the Chinese league to be the most competitive.
*  And by the way, we do very well in China because our China team is the best Chinese.
*  How worried are you that the unionized unionization effort that just took place at, well, I should
*  say, effort, but the new wages and like at GM and Ford are that they're coming for you.
*  They are coming for you.
*  What is that going to mean to you in your business?
*  Well, I mean, I think it's generally not good to have an adversarial relationship between
*  people online, you know, one group at the company and another group.
*  In fact, I mean, I disagree with the idea of unions.
*  But the past four or reason that is different than people may expect is which is I just don't like
*  anything which creates kind of a loads and peasants sort of thing.
*  And I think the unions naturally try to create negativity in a company and create a sort of
*  loads and peasants situation.
*  There are many people at Tesla who have come up on from working on the line to being in
*  China management.
*  There is no loads and peasants.
*  Everyone eats at the same table.
*  Everyone pocks at the same parking lot.
*  At GM is a special elevator for only senior executives.
*  We have no such thing at Tesla.
*  You know, the things that I actually know the people on the line because I worked on the
*  line and I walked the line and I stepped in the factory and I worked beside them.
*  So I'm no stranger to them.
*  And actually many times I said, well, can't we just hold a union boat but apparently a company
*  is not allowed to hold a union boat.
*  So it has to be somehow called for but the unions can't do it.
*  So I said well, just hold a vote and see what happens.
*  The actual problem is the opposite.
*  It's not that people are trapped at Tesla building cars.
*  The challenge is how do we retain great people to do the hard work of building cars when
*  they have like six other opportunities that they can do that are easier.
*  That's the actual difficulty is that building cars is hard work and there are much easier
*  jobs and I just want to say that I'm incredibly appreciative of those who have cars and they
*  know it.
*  So I don't know, maybe there will be unionized.
*  If Tesla gets unionized, it will be because we deserve it and we failed in some way.
*  But we certainly try hard to ensure the prosperity of everyone.
*  We give everyone stock options.
*  We've made many people who are just working the line who didn't even know what stocks were.
*  We've made the millionaires.
*  So we're going to run on time, final couple quick questions.
*  When do you have the time to tweet or to post?
*  I actually think about it all the time.
*  As I said, I use it all the time.
*  I use it all the time.
*  If we were to open up our phones and look at the screen time, what does yours look like?
*  Well about every three hours, I make a trip to the laboratory.
*  It's the only time you do this.
*  Seems like you're on there a lot.
*  No, I mean, there will be brief moments between meetings.
*  Obviously I have like 17 jobs.
*  No, I guess technically it's work.
*  It is.
*  But I think it just in terms of your mind share.
*  By the way, there's a lot of people who should be working who are homeless.
*  Technically posting on Twitter is work.
*  This count is work.
*  So that's, you know, there's that.
*  But no, I mean, I think I'm on, well, I guess usually probably I'm on for longer than I think I am.
*  I know, but do you think that's five hours a day?
*  If you work at the screen time of like a number hours per week, sometimes that's a scary number.
*  I don't know.
*  It's a little over an hour a day or something like that.
*  Just an hour a day.
*  If we really looked at this together, do you have your phone with you?
*  Yeah.
*  You want to look?
*  Okay.
*  Okay, here we go.
*  You ready?
*  Screen time.
*  Yeah, screen time.
*  Sometimes this is a scary number.
*  I know. That's why I thought...
*  I just got a new phone.
*  So I think this is not accurate because it says it's one minute.
*  For sure, it's more than that.
*  Over the week, I'll go.
*  Go to the week.
*  Okay, so it's still wrong.
*  It's more than four minutes.
*  I just got to be fine.
*  So this is not accurate.
*  It literally says four minutes.
*  New phone.
*  Tim Cook's in the phone?
*  New phone.
*  New phone.
*  Who does?
*  I should ask, by the way, because I just mentioned Tim Cook.
*  Do you feel like you're going to have to have a battle with him eventually?
*  Is that the next fight over the App Store?
*  The idea of making a phone.
*  Or were you mean like...
*  No, no, no.
*  Over the App Store.
*  Have you ever made a phone?
*  Sam Alvin's apparently thinking about making a phone with Johnny Av.
*  I mean, I don't think there's a real need to make a phone.
*  I mean, if there's an essential need to make a phone or make a phone,
*  but I had a lot of free supply.
*  So, I mean, I do think there's a fundamental challenge that the phone makers have at this point
*  because you've got a basically a black rectangle.
*  You know, how do you make that better?
*  So you want to do that?
*  What does that look like in Elon's head?
*  No, that's literally...
*  Yeah, good phrase.
*  In the head.
*  New link.
*  Well, there we go.
*  We need to have that before it's over.
*  You know, the best interface would be a neural interface directly to your brain.
*  So that would be a neural link.
*  How far would you think from that and how excited or scary does that seem to be?
*  And we read these headlines obviously about monkeys who died, as you know.
*  What should we think about that?
*  Yeah, actually, the...
*  The USDA inspector who came by, the neural link facilities,
*  literally said in her entire career,
*  she has never seen a better animal care facility.
*  It is...
*  We all have the nicest chatables that you could possibly be,
*  even to the rats and mice, even though they did the plague and everything.
*  So, it is like monkey paradise.
*  So, the thing that gets conflated is that there were some terminal monkeys
*  where, you know, this is actually several years ago,
*  where the monkeys were about to die.
*  And we're like, okay, we've got an experimental device.
*  It's the kind of thing which only put in a monkey that's about to die.
*  And then, you know, now the monkey died,
*  but it didn't die because the neural link died because it was, you know,
*  added to a case of cancer or something like that.
*  So,
*  the neural link has never caused the death of a monkey.
*  Unless they're hiding something from me,
*  there's never caused death of a monkey.
*  And in fact, we've now had monkeys with neural link implants for like two, three years,
*  and they're doing great.
*  So,
*  and we've even replaced the neural link twice.
*  And we're getting ready to do the first implants in hopefully in a few months.
*  The, the early implementations of neural link,
*  I think are unprocifically good,
*  speaking of the double-edged sword.
*  I think these early implementations are single-edged sword
*  because the first implementations will be to enable people who have lost the brain body connection
*  to be able to operate a computer or a phone faster than someone who has hands that work.
*  So, you can imagine if Stephen Hawking could communicate faster than someone
*  who had full, full body functionality.
*  Now, incredible that would be.
*  Well, that's what this device will do.
*  And we should have a proof of that in a human, hopefully in a few months.
*  It already works in monkeys and worked quite well with monkeys that can play video games just using, despite thinking.
*  So, then the next application after the sort of those, you know, dealing with tetraplegic's
*  quite a few quadrplegic's is going to be vision.
*  Vision is the next thing.
*  So, it's like if somebody has lost both eyes or the optic nerve has failed,
*  basically, where there's, they have no possibility of having sort of some ocular correction.
*  That would be the next thing for neural link is a direct vision interface.
*  In fact, then you could be like Jordy Lefort from Star Trek.
*  You could see in like any frequency actually.
*  You could see in radar if you want.
*  Two final questions.
*  And then we're going to do in this conversation, which I think has taken everybody inside the mind of Elon Musk today.
*  Not as well as in your link, WoW.
*  And actually goes to self-driving cars and vision and everything else.
*  And I asked this question to Pete Buttigieg of Transportation Secretary.
*  It's actually something you retweeted.
*  So, I wanted to ask you the same question.
*  There's a big question about autonomous vehicles and the safety of them.
*  But there's also a question about when it will be politically palatable in this country for people to die in cars that are controlled by computers.
*  Which is say we have 35,000, 40,000 deaths every year in this country.
*  If you could bring that number down to 10,000, 5,000, that might be a great thing.
*  But do we think that the country will accept the idea that 5,000 people that your family might have perished in a vehicle as a result not of a human making a mistake but of a computer?
*  Yes, first of all, humans are terrible drivers.
*  So if people text and drive, they drink and drive, they get into arguments, they, you know, the deal sorts of things in cars that they should not do.
*  So it's actually remarkable that there are not more deaths than there are.
*  What we'll find with computer driving is I think probably an order of magnitude reduction in deaths.
*  Now, in the US has actually far fewer deaths per capita than the rest of the world.
*  If you go worldwide, I think there's something close to a million deaths per year due to what a mode of accidents.
*  So I think computer driving will probably drop that by 90% or more.
*  It won't be perfect, but it'll be 10 times better.
*  And do you think that the public will accept that? Do you think the government will accept that?
*  Well, in large numbers, it will simply be so obviously true that it really cannot be denied.
*  And what do you think? I know we've talked about the timeline before.
*  And I know people have criticized you for putting out timelines that may not have come true just yet.
*  But what do you think it will be?
*  By the way, do you feel like you ever said yourself, I shouldn't have said that.
*  Sure, of course.
*  Wait, I should have said that.
*  So, yeah. I mean, I'm optimistic about, I mean, I think I'm like naturally optimistic about timescales.
*  If I was not naturally optimistic, I wouldn't be doing the things that I'm doing.
*  I mean, I suddenly want to start a rock company or a electric car company if I didn't have some sort of pathological optimism, frankly.
*  So as you pointed out, many people said there would fail. And in fact, I actually agree with them. I said, yes, it probably will fail.
*  But I thought it's basic. And Tesla had less than a 10% chance of success when we started them.
*  So, yeah, anyway, but the self-driving thing is, I've been optimistic about it.
*  But we certainly made a lot of progress. If anybody has tried the very, has been using the sort of full self-driving beta.
*  The progress is, you know, every year has been substantial.
*  It's really now at the point where in most places it'll take you from one place to another with no interventions.
*  And the data is unequivocal that that supervised full self-driving is somewhere around four times safer or maybe more than just human driving by by themselves.
*  So I'm glad. I know. I can certainly see it coming.
*  Really, I think it's another five or 10 years. No, no, no, definitely not.
*  Did you feel like investors have invested in something that hasn't happened yet? Is that fair to them? That's the other question that people have about that.
*  Well, I mean, I think that they've all with rare exception thought it wasn't happening. So they were investing in despite thinking that they're very clear that they don't think it's real.
*  So they don't saying, oh, we just leave everything you want. Says, hook line and sinker.
*  But the thing is that I mean, I would be a fair criticism of me to say that I'm late, but it isn't, but I always deliver in the end.
*  And that's a good final question. I took note of this. It was November 11th and you took to Twitter and you wrote only two words. You said amplify empathy.
*  Right. I was taken back by that. Keepin' all the things that are going on in the world.
*  Do you remember what you were thinking?
*  Well, I think it's quite literally. I understand it, but what was going on? Why did you write that?
*  Well, I was encouraging people to amplify empathy. Literally. I tend to be quite literal.
*  But was there something that had happened that you had seen that you said yourself I wanted to say that?
*  I think I was going to do some friends. I really agreed that we should try to amplify empathy. And so I wrote amplify empathy.
*  If you wanted an unvarnished look inside the mind of Elon Musk, I think you just saw it.
*  Well, it's pretty simple.
*  You know.
*  Elon Musk, thank you very, very much for the conversation.
*  Thank you. Thank you so much.
*  That was a conversation from the Dealbook Summit. You can check this feed for other interviews from the Dealbook stage, where we speak to leaders in business, politics, and culture, who are shaping the world.
*  This episode was produced by Evan Roberts. It was edited by Lane Chan, mixing by Kelly P. Glow,
*  original music by Daniel Powell. The rest of the Dealbook events team includes Julie Zahn, Caroline Brunel, Hayley Duffy, Angela Austin, Hayley Hess, Dana Priskowski, Matt Kaiser, Yen Wei Liu,
*  Special thanks to Sam Dolnick, Nina Lassam, Robbie Matto, Beth Weinstein, and Kate Carrington.
*  This is a production of The New York Times.
