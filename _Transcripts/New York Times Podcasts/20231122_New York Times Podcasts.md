# Inside the Coup at OpenAI
**NewYorkTimesPodcasts:** [November 22, 2023](https://rr1---sn-ab5sznze.googlevideo.com/videoplayback?expire=1711042849&ei=wRz8ZeyoB-zB_9EP7saH6AM&ip=2603%3A7000%3A3200%3Ade9e%3A68a7%3Ae516%3Aff66%3A8d9d&id=o-AIAYjSRJtoqF6E-z-jg05HwK6K-mqAZKAJcU_OdqlY_4&itag=139&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=L_&mm=31%2C29&mn=sn-ab5sznze%2Csn-ab5l6nrr&ms=au%2Crdu&mv=m&mvi=1&pl=37&pcm2=no&initcwndbps=1252500&vprv=1&mime=audio%2Fmp4&gir=yes&clen=10169509&dur=1667.535&lmt=1700650991333464&mt=1711021017&fvip=2&keepalive=yes&c=ANDROID_EMBEDDED_PLAYER&txp=6218224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cpcm2%2Cvprv%2Cmime%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRgIhALa-KjXBz6FjQGFitcYoZ8G8oeFQmi25_AURGM4n4rjGAiEAznEpL9QxiTskrJ_kQbPVhxhRSEjoZCQiGiUp5VngPEI%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=ALClDIEwRQIgJUUblJeOZVEkPO-M5LVnXkX7M9UDwvzPZAHlxdwyTQUCIQD3sm9vsekjmNVNy44GfLiZRqI7Iv2S1zLZgWo4i1sU9w%3D%3D)
*  From New York Times, I'm Michael Bavaro. This is the Daily.
*  Today, the surprise ouster of Sam Oldman as CEO of OpenAI, the fallout that it triggered
*  and what it all means for the future of the transformational technology at the center
*  of the boardroom drama. I speak with my colleague, Technology Reporter, Kade Metz.
*  It's Wednesday, November 22nd.
*  Okay, good morning.
*  Good morning.
*  Thank you for making time for us. We are now several days into a corporate drama that
*  has consumed the world that you cover Silicon Valley and that remains pretty headspinning
*  and a very fluid situation.
*  Absolutely. I mean, corporate dramas can be interesting, but never this interesting.
*  They're not supposed to be this interesting. It's supposed to be a bit more boring.
*  That's right.
*  So in the simplest possible terms, what happened?
*  Sam Oldman, the chief executive of OpenAI, the company that wowed millions of people late
*  last year with the debut of chat GPT, an online chatbot that can answer questions, generate
*  term papers, write poetry, even write its own computer code, has been ousted from that
*  company by the company's own board.
*  A boardroom coup is how we used to refer to that when I was a business reporter.
*  Yes. And the stakes are artificial intelligence of a level that most people, even in the industry,
*  did not expect to arrive this soon.
*  This is powerful technology that is already changing the way disinformation is spread across
*  the internet. It's starting to take away jobs.
*  And it has been improved at an incredibly fast rate that has caused great optimism in
*  parts of Silicon Valley and great concern in other parts.
*  And those two things are clashing.
*  And the clash is encapsulated in this very human story that is ultimately about ego and
*  power and money.
*  Kid Sam Oldman, that name is not a name we've ever really examined in great detail.
*  We've talked a lot about this technology. We've talked a lot about this company, OpenAI,
*  but not a ton about Oldman himself.
*  So help us understand really who Sam Oldman is, why his firing is, as you just said,
*  such a titanic moment for this technology and how he fits into this large clash that
*  you just outlined.
*  In many ways, Sam Oldman is the classic Silicon Valley archetype. He dropped out a Stanford
*  as a sophomore. He found his own company. And then he winds up as the president of a well-known
*  startup incubator, one of the most important things that we try to teach at Y-combinator,
*  called Y-combinator.
*  Is it more important to build something that a few users love than something that a lot
*  of users like?
*  For an organization, it helps other startups get off the ground.
*  If you can build a product that is so good, people spontaneously tell their friends about
*  it. You have done 80% of the work that you need to be a really successful startup.
*  And through that job, he becomes one of the most well-connected people in Silicon Valley.
*  Welcome to How To Build The Future. Today, our guest is Mark Zuckerberg. Today, we have Elon Musk.
*  Elon, thank you for joining us.
*  Thanks for having me.
*  And in 2015, he and others, including Elon Musk, found this company, OpenAI, to do artificial
*  intelligence.
*  But he is not the main name in the headline. Musk is the main name in the headline.
*  And Sam, he's not an AI researcher.
*  He will tell you that he studied it briefly when he was at Stanford, but he is ambitious.
*  And as he sees this technology rising, he is among those who go after it.
*  Google was in the lead, so to speak, at that point, in this push towards artificial intelligence.
*  They were building increasingly powerful technologies that could recognize objects the way a
*  driverless car does, that could recognize your voice, the way Siri does, that could translate
*  between language instantly as Google Translate does.
*  And Sam and Elon Musk and a group of researchers got together and decided they needed to challenge
*  Google.
*  There was a concern that Google was going to build this technology on its own.
*  It would become increasingly powerful, and Google would control the universe.
*  And so they felt they would be a counterweight to Google, and they would develop this technology
*  in the open.
*  They wouldn't bottle this thing up and keep it to themselves.
*  They would develop it in their way that would benefit humanity.
*  So from the start, you're saying Altman approached artificial intelligence with a sense of
*  altruism and a little bit of worry that in the wrong hands, this could be dangerous.
*  It may or may not have been his main motivation, but it was part of how those around him thought
*  and when they debuted in 2015, that was part of the ethos.
*  To that end, they created OpenAI, not as a company, but as a non-profit.
*  The idea was that they would be free of the corporate pressures that were dangerous at
*  places like Google.
*  They would not be beholden to the stop market.
*  They would be beholden to the people.
*  But a couple years later, Musk, in a huff, leaves OpenAI because he feels like they're
*  not pushing forward fast enough.
*  And Elon is not only gone, Elon's money is gone.
*  Elon was the main donor to this operation.
*  The SAM realizes if this operation is going to survive, he needs money.
*  And I need to underscore just how much money goes into the creation of this technology.
*  You need billions of dollars to build this stuff.
*  Billions of dollars of computing power needed to train these AI systems.
*  He recognizes this.
*  He creates a new company, a for-profit company because he needs to give investors a reason
*  to invest.
*  He needs to give them profits.
*  So he creates this for-profit and bolts it on to the nonprofit.
*  He does that and immediately raises one billion dollars from one of the tech giants here
*  in the US, Microsoft.
*  Okay.
*  Well, we're going to return to that structure you just explained of a corporation basically
*  being bolted to a nonprofit because that becomes important to this drama later on.
*  But what does this company that Altman bolts onto this nonprofit end up doing with this
*  big infusion of cash?
*  It ends up building an increasingly powerful technology called GPT, a technology that
*  can take in vast amounts of techs from across the internet, Wikipedia articles, digital
*  books, chat logs, even computer programs, and it can learn to generate techs on its own.
*  And Sam Altman is the person who is helping to push this forward because he continues to
*  raise vast sums of money from Microsoft, the initial one billion dollars that Microsoft
*  invested grew to three billion dollars.
*  All that goes into the creation of this technology and for people following the AI field, this
*  technology was increasingly impressive.
*  But the general public, for the most part, did not wake up to what was happening until
*  the end of last year when OpenAI and Sam Altman released chat GPT.
*  A new artificial intelligence tool is going viral for cranking out entire essays in a matter
*  of seconds.
*  It literally shows you how to do it, says how to do the math, and at the end, the answer
*  is B.
*  What the heck is insane?
*  That GPT is poised to change the way we interact with computers and AI.
*  In fact, chat GPT wrote everything I just said when we asked it to write an introduction
*  to this piece.
*  Right.
*  This is when everyone, the daily included, start covering the heck out of this new technology
*  because it is so insanely powerful and compelling and, let's be honest, a little bit scary.
*  Yes.
*  But as all this attention goes to chat GPT, so much attention also goes to Sam Altman.
*  He suddenly rises from a well-known figure in Silicon Valley to a well-known figure across
*  the world.
*  He is the face of this technology which so many millions of people have been wild by.
*  So what have you done?
*  Like ever?
*  No, I mean, what have you done with AI?
*  Sam's on every podcast.
*  I think it's going to be a great thing, but I think it's not going to be all a great thing.
*  And then he's in front of Congress.
*  Open AI was founded on the belief that artificial intelligence has the potential to improve nearly
*  every aspect of our lives.
*  And then...
*  Sam Altman, co-founder and CEO of Open AI, that is whole last week as...
*  He's on a global tour.
*  I would be surprised if Australia does not build great AI companies.
*  Talking with world leaders in Europe and in Asia, the thoughtfulness, the focus, the
*  urgency on figuring out how we mitigate these very huge risks that are coming so that we
*  get to enjoy the benefits of this technology.
*  Promoting this technology, but also acknowledging that it could be dangerous.
*  There's always this nod to the dangers and the concerns.
*  And that's part of who Sam is.
*  We've got to be cautious here.
*  And also, I think it doesn't work to do all this in a lab.
*  You've got to get these products out into the world.
*  And...
*  He will tell you one thing and then immediately nod to the opposite thing.
*  And this happens throughout a conversation.
*  He is optimistic.
*  This is going to be a good thing.
*  I'll always say, yeah, but there are concerns.
*  People should be happy that we're a little bit scared of this.
*  I think people should be a little bit scared.
*  A little bit, yeah.
*  You personally.
*  I think if I said I were not, you should either not trust me or be very unhappy I'm in
*  this job.
*  So in some ways it sounds like he is embodying the tensions all around this.
*  New technology.
*  He absolutely is.
*  And those tensions are real.
*  And in some ways this is a new thing for Silicon Valley.
*  The thing you have to realize about Silicon Valley is that it's very much about or has
*  been about optimism.
*  People believing that things were possible, that most people didn't.
*  They as Silicon Valley entrepreneurs were going to make the world better.
*  That's been the trope.
*  What happened with artificial intelligence in particular over the last decade is that
*  you also have a group of people who are looking into the future and they don't necessarily
*  see an optimistic picture.
*  They see a concerning picture.
*  And as this technology that Mr. Altman and his lab or building gets more powerful, that
*  becomes part of the Silicon Valley ethos.
*  You have your optimists and you have your pessimists.
*  And then you've got Sam Altman who's so good at balancing things, embodying both of those
*  two sides of the equation.
*  Can you just define these two camps?
*  I think the optimist's case is pretty straightforward, right?
*  That something like chat, GBT is going to enhance our lives and there can be safeguards
*  that protect us.
*  What exactly are the pessimists making the case for?
*  Well, the pessimists will acknowledge that this could be a powerful technology.
*  They'll even say this could be used to cure cancer or solve climate change.
*  But they are also fundamentally worried that if the right safeguards are not put in place,
*  this could destroy humanity.
*  It is a deeply held, sometimes strange to understand belief, but this is a real force in the
*  valley.
*  People are worried about this and some of those people were sitting on the board of that
*  not-for-profit that Sam Altman created back in 2015 when he initially put together open
*  AI.
*  So there are pessimists about this technology who sit on the board of the nonprofit that
*  basically employs Alman.
*  Right, and by November of 2023, that board is just six people and because of the unusual
*  structure of open AI, they have an incredible amount of power.
*  Those six people control the four-profit company alone.
*  They are not beholden to shareholders, investors who have put money into the company.
*  And Microsoft, with its billions in the company, even Microsoft, which is by this time put
*  $13 billion into the company, does not have control over the situation.
*  Six people control whether Mr. Altman is at the head of that company or not.
*  And a few days ago, Friday morning, while I was on the phone with another open AI employee,
*  I was told I'd better look out for an email around noon.
*  And then, just afternoon, that tiny board announces to the world that Sam Altman is no longer
*  the CEO of open AI and no one can believe it.
*  No one at open AI, no one at Microsoft, none of the investors in open AI.
*  Nobody saw this coming and no one understands how all this is going to play out over the
*  next 72 hours.
*  We'll be right back.
*  So, Kate, why did this board fire Sam Altman?
*  How does that firing fit into this divide?
*  We've been discussing of the AI Optimicity AI pessimist.
*  And what exactly has been the fallout?
*  One of the many remarkable things of this whole soap opera is that we don't really know
*  why they ousted Sam Altman.
*  What the board said was that they could no longer trust him to run this company and build
*  AI for the benefit of humanity.
*  But we still don't know why ultimately he was removed.
*  I mean, is it safe to assume that it does fit into the schism that you mentioned between
*  those who think that chat GPT is ultimately very good or very scary and that somehow in
*  trying to straddle those two universes that Altman somehow ran a foul of a board that
*  seems pretty full of pessimists?
*  That tension is fundamentally part of this situation.
*  You have essentially a board that is split in half.
*  You have three founders of open AI, including Sam Altman on the board, and you have three
*  other people, some of whom are very concerned about the future of AI.
*  And Sam and his leadership team thought that that balance would work out.
*  But one of the co-founders, Ilya Sutskovur, a very important AI researcher over the past
*  decade, has grown increasingly concerned about the dangers of the technology and he is among
*  those who ousted Mr. Altman.
*  He kind of broke the tie, as it were.
*  Ilya broke the tie.
*  Okay, so let's turn to the fallout of this board doing what it just did in getting rid
*  of Altman.
*  We have major breaking news related to open AI.
*  Sam Altman is out as CEO of Open AI.
*  The fallout is immediate.
*  You know, the minute this thing started to filter out, Microsoft shares started to fall.
*  They're down near two.
*  Investors across the world, the people and companies who have put billions of dollars into
*  this AI company, they don't understand the decision, they are blindsided by it.
*  Even key investors, they were only supposedly notified just a few minutes before that
*  mis-save went out.
*  And on top of it all, they're powerless to do anything.
*  Obviously, this just puts a spotlight on this nonprofit board.
*  They have no say in what this tiny little board does and that includes Satin Indela, the
*  CEO of Microsoft.
*  We really want to partner with Open AI and we want to partner with Sam.
*  And so he doesn't expect your where Sam is.
*  We and other investors start to put pressure on this board to take Altman back.
*  We're very confident in Sam and his leadership team.
*  I've not been told about anything.
*  You know, they published internally.
*  And the walls start to cave in, so to speak.
*  The company's president and co-founder Greg Brockman has quit after the CEO and fellow
*  co-founder.
*  And eventually, when other talent from Inside Open AI starts to leave, there's this support
*  spilling out across the internet.
*  Everyone is trying to put pressure on these four people on the board.
*  And pretty soon, Altman is inside the offices of Open AI in San Francisco trying to convince
*  them to take him back.
*  In the board, late on Sunday, they put out a note that says, we are standing firm by
*  our decision.
*  Sam Altman is out and out of the blue.
*  Microsoft announcing that it is hired Sam Altman to lead its artificial intelligence group.
*  That came just day.
*  Microsoft and Satin Indela say, okay, we're essentially going to rebuild what you were doing in Open
*  AI and we're creating a competitor.
*  And when that happens, other employees at Open AI start to sign a letter threatening to
*  leave Open AI and join this new venture.
*  Latest number we have right now, at least 700 of Open AI employees threatening to leave
*  the startup for Microsoft.
*  By the way, that's out of about 770 employees total.
*  Those demands include.
*  And still the board stands firm.
*  And if that wasn't enough for you, Ilya Sutskovur, the guy who switched sides and joined the board
*  in alstein, Mr. Altman, he switches sides again and he goes back to team Sam and he says,
*  I deeply regret what I have done.
*  And he puts his name on the letter that the 700 employees have sent out threatening to
*  join the Microsoft venture.
*  So one of the board members who is responsible for Altman's ouster, once the ouster's repercussions
*  become clear, says, I really regret that and signs a letter saying, I will leave the
*  company unless Altman returns as CEO.
*  What is pretty had spinning?
*  We're still trying to figure out what was inside his head and what is inside his head now.
*  How do you understand the depth of loyalty to Altman?
*  Why does everyone decide that if Altman leaves, they're going to leave too?
*  Well, there are many reasons here.
*  For one, they were on top of the world.
*  They had a good thing going.
*  They have a stake in the company.
*  They can make money.
*  They're also, for the most part, on the optimistic side, many people who are concerned about dangers
*  have left the company over the years because of this type of disagreement, just on a smaller
*  scale.
*  So you've got people who are more aligned with Altman at the company for the most part.
*  So in that sense, this board misunderstood where most people inside open AI were when
*  it came to this pessimistic versus optimistic approach to AI.
*  But if the board's goal was to constrain this technology and constrain someone like Altman
*  with whom they disagree about the future of this technology, haven't they just failed
*  to do that because that technology has just up and gone over to Microsoft, which would
*  seem to have even fewer safeguards in place?
*  What you have to realize ultimately is that this technology is going to happen one way
*  or another.
*  This is a story that shows that the genie is out of the bottle in many ways and the technology
*  is going to push forward, bottling the technology up in the way that the board seems to want
*  to do may not be the best way forward.
*  There are a lot of arguments that say we don't want to bottle it up inside these companies.
*  We want more people to be aware of what is being built so we can understand it so we can
*  find the flaws so we can find where the dangers might be.
*  And there are a lot of arguments about the future of this technology, but you can be sure
*  this technology has a future.
*  It does that mean that in this case and when we think about the future of this powerful
*  technology that the optimists have prevailed and that the safeguards have kind of lost.
*  Not necessarily.
*  This is an argument that will continue across Silicon Valley.
*  There are optimists and there are pessimists.
*  This battle has only just begun.
*  Okay.
*  Thank you very much.
*  We appreciate it.
*  Thank you.
*  Just before all of this unfolded, my colleague, Times Technology columnist Kevin Rus interviewed
*  Altman for his podcast, Hard Fork.
*  If you're curious to hear that conversation with the man at the center of all of this,
*  search for Hard Fork wherever you listen.
*  We'll be right back.
*  Here's what else you need to anoday.
*  On Wednesday morning, the Israeli government approved a hostage deal with Hamas that could
*  produce the longest pause in fighting since the war began 46 days ago.
*  Under the terms of the deal, Hamas will release at least 50 hostages held captive in Gaza,
*  while Israel will release 150 Palestinian prisoners from Israeli jails.
*  Those exchanges, which could start as early as tomorrow, are expected to occur over four
*  days during which fighting will pause.
*  And in the latest blow to the beleaguered cryptocurrency market, the founder of Binance,
*  the world's largest crypto exchange, has pleaded guilty to violating US money laundering
*  laws, and Binance itself said it would pay a $4.3 billion fine.
*  US prosecutors had accused Binance and its founder, Chung Peng-Zao, of engaging in outlawed
*  financial transactions, including with customers in countries under US sanctions.
*  The guilty plea comes shortly after the conviction of Sam Bankman-Free, the founder of another
*  crypto exchange, FTX.
*  Today's episode was produced by Olivia Nat and Will Read.
*  It was edited by Lisa Chow and Brendan Klingenberg, contains original music by Mary and Lazano
*  and Dan Powell, and was engineered by Chris Wood.
*  Our theme music is by Jim Brunberg and Ben Lantzberg of Wonderland.
*  That's it for the Daily.
*  I'm Michael Abor.
*  See you tomorrow.
