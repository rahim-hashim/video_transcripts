# A Strategy to Treat Big Tech Like Big Tobacco
**NewYorkTimesPodcasts:** [November 15, 2023](https://rr5---sn-ab5sznzz.googlevideo.com/videoplayback?expire=1711043734&ei=NiD8ZcjDH8q2_9EPkcqUqA4&ip=2603%3A7000%3A3200%3Ade9e%3A68a7%3Ae516%3Aff66%3A8d9d&id=o-AHzFofeNLQoTwRY3LobgLpKqvw3fVwVcsJbALMmPjNw7&itag=139&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=v5&mm=31%2C29&mn=sn-ab5sznzz%2Csn-ab5l6nkd&ms=au%2Crdu&mv=m&mvi=5&pl=37&initcwndbps=1420000&vprv=1&mime=audio%2Fmp4&gir=yes&clen=12294932&dur=2016.114&lmt=1700055157793597&mt=1711021735&fvip=3&keepalive=yes&beids=24350375&c=ANDROID_EMBEDDED_PLAYER&txp=6218224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Cmime%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRgIhAKo2RFr2GvNcGi2-PT0RCpKHgY1q0cfA87uirPv0MJ2wAiEA1l_xEGC1okreozxQT4rkKU9iXSGnSIUw1Nw_3tI-0uw%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=ALClDIEwRAIgA9JrAeE1aIlrVAJHqg_CaDYQTQK_At8k6VJVM2AUROcCIBAeeHc0WX0nGSAdK9_7K-R0RF1oQtSST4d__iRTLBf5)
*  From New York Times, I'm Michael Bavaro.
*  This is The Daily.
*  Today, a look inside a historic set of new lawsuits filed by dozens of states accusing
*  the country's largest social media company of lowering children onto its platforms and
*  hooking them onto its products.
*  My calling Natasha Singer has been reviewing the state's evidence and trying to understand
*  the long-term strategy behind the lawsuits.
*  It's Wednesday, November 15th.
*  Natasha, the last time you and I spoke, the state of Utah had just tried to restrict
*  the use of social media by children, past the first of its kind law.
*  Today, you come to us with something related but on a vastly different scale.
*  Right.
*  When we were talking about Utah, it was a single state trying to restrict social media
*  on behalf of young people.
*  And now what we have...
*  Good morning, everyone.
*  Good morning.
*  And thank you for joining me today.
*  There is a youth mental health crisis in America.
*  And we need to act.
*  Is dozens of states banding together?
*  So today, myself and 42 other attorney generals across this nation are announcing collective
*  action in states.
*  A kind of astonishing coalition of red states like Texas and Tennessee and blue liberal
*  states like Massachusetts.
*  Today, my office has filed a lawsuit against meta-platforms in the company formerly known
*  as Facebook.
*  For knowingly harming the mental health of young social media users.
*  Coming together to sue meta, which is the social media giant, as you know, that owns Instagram
*  and Facebook and WhatsApp.
*  Right.
*  I do very much see this as a public health crisis in the same way that tobacco was.
*  And the scale of this investigation, the way the states are banding together to investigate
*  and the kind of parallel lawsuits they filed, is right out of the big tobacco playbook.
*  META has been allowed to addict our children to a product that interferes with their mental
*  and physical health.
*  So from the point of view of the attorney's general, they have said they view the case
*  against meta as a case about severe health harms and hazards to young people in the
*  same way that states viewed the health hazards and harms to young people with cigarettes
*  or jewel or opioids.
*  Of course, Natasha, the industries you just mentioned stood accused of quite literally poisoning
*  people, including children with their products, cigarettes and vaping pens.
*  Meta is a technology company, so does the parallel to those industries kind of end there?
*  So I think the answer to your question is both yes and no.
*  Technology is different.
*  And the question of whether social media is addictive at the heart of this case will
*  have to be proven.
*  It's not clear, right?
*  So the methodology the states are using, all coming together to sue one company is similar.
*  The content is different.
*  Like big tobacco, it's hard to say anything good about.
*  Social media, lots of people use to connect to their friends, their family, their colleagues
*  to figure out what celebrities are doing, to look up recipes, right?
*  There's a lot of good things that happen with social media, and so it is not the same
*  in that way as big tobacco or jewel.
*  But when the case was first announced last month, we don't really know what evidence the
*  states had against Meta because their legal filings were redacted and it was all blacked
*  out and we couldn't see anything.
*  But since then, the Massachusetts Attorney General has gotten that states complaint unsealed.
*  And that gave us a much better sense, not only of the Massachusetts case, but of similar
*  cases that attorneys general in other states were filing.
*  Right.
*  So I want to better understand this lawsuit that all these states are involved in.
*  So walk us through the case of Dasha.
*  The case has a really interesting backstory.
*  It starts in the fall of 2020, which is when Netflix released a really ominous, dokey drama
*  called the Social Dilemma.
*  A lot of people think Google's just a search box and Facebook's just a place to see what
*  my friends are doing.
*  They don't realize is there's entire teams of engineers whose job is to use your psychology
*  against you.
*  And it featured former Facebook, Google and Twitter executives warning about how social
*  media platforms hacked users' psyches.
*  You get rewarded by parts, likes, thumbs up, and we conflate that with value and we conflate
*  it with truth.
*  A whole judge.
*  And state regulators around the country began to see the documentary.
*  Those kids are the first generation in history that got on social media in middle school.
*  And they began talking about how worrisome social media was for young people.
*  How do they spend their time?
*  They come up from school and they're on their devices.
*  And so some of them are parents who have seen their own kids use social media and it's
*  personal for them.
*  I spoke to the Attorney General of Massachusetts, Andrea Joy Campbell and she said, look, I'm
*  not just the Attorney General, I'm the mother of two young boys.
*  And these Attorney General had been watching spiking rates of teen depression, anxiety
*  and suicide in their states.
*  And they believed that social media was one of the causes.
*  And while the Attorney General were discussing the film and the alarms it raised for them,
*  Facebook is developing a children's version of the popular app Instagram for youngsters
*  13 and under.
*  Meta, right, Facebook's parent company announced an early 2021 plans to develop a new service
*  Instagram for kids.
*  And that caused even more alarm bells because Attorney General were worried that Meta was
*  trying to create kind of training wheels for Instagram proper.
*  And so more than 40 states got together and their Attorney General wrote a letter to
*  Berksucker Berg asking him to halt the plans to develop Instagram for kids.
*  And soon after they sent that letter, a whistleblower from Inside Meta appeared.
*  Many of Facebook's internal researcher ports indicate that Facebook has a serious negative
*  harm on a significant portion of teenagers and children.
*  Francis Hougan, a former Facebook product manager, had taken tens of thousands of internal
*  documents and she spoke to the Wall Street Journal and she testified in Congress that the
*  company knew that they were making young women feel worse.
*  The company's leadership knows how to make Facebook and Instagram saver but won't make
*  the necessary changes because they have put their astronomical profits before people.
*  And it causes a firestorm and Meta announced that it was going to pause the development
*  of Instagram for kids.
*  And more than 40 states announced that they were going to investigate whether Meta and
*  particularly Instagram had deliberately created a platform to a dick kids and knew that
*  it could cause them harm.
*  So that's how we get to these lawsuits.
*  It sounds like a slow burning realization by these states attorneys general that there
*  is a problem inside Meta with Instagram and that there's something they are uniquely
*  capable of doing about it.
*  Exactly.
*  And over the last two years, the attorneys general have amassed thousands of internal
*  documents from Meta showing how Instagram works.
*  And using that and also testimony from other whistleblowers, they contend they now have
*  a really strong case in which they are accusing Meta particularly Instagram of deliberately
*  designing addictive features that harm children of lying about the harms and also of allowing
*  underage users under 13 on this platform.
*  Okay, well, let's walk through those three claims in these lawsuits one by one.
*  Let's start with the claim that Meta Instagram design intentionally addictive features.
*  What's the evidence that the lawsuits?
*  You know, I think in simple terms, the attorneys general are accusing Meta, but particularly
*  Instagram of being an all powerful social media slot machine that has knowingly ensnared
*  addicted and harmed millions of young people.
*  And so if you think about how a slot machine works and some of the attorney generals have
*  used this phrase, right?
*  It can be endless.
*  And so that is one of the things they say is an addictive feature that there's no natural
*  end for young people that is really, really hard to get off.
*  Of all, they say that Instagram bambards young people with all kinds of notifications.
*  And if you've used Instagram, you have probably seen them.
*  Chad just posted a new photo.
*  Chloe has a new real.
*  Katie Kirk's going live.
*  Right.
*  And so first of all, that like is a dopamine hit because you're going to see something new,
*  right?
*  And you instantly have to go check.
*  Second of all, there's social pressure, right?
*  If you don't like your friends post fast enough, what is that going to mean?
*  And then there's also fear of missing out because some of those things like Instagram
*  live or stories are temporal.
*  If you don't do it now or in the next 24 hours, you're not going to see it.
*  And so the attorney general alleged that all this stuff is by design that these compelling
*  features have a particularly pernicious effect on young people because it overrides their
*  brains.
*  Right.
*  I mean, here I have to confess that I have lost two to three hours at a stretch on Instagram
*  because of the very features you're describing.
*  And I'm 44 years old.
*  But I think we all are, right?
*  You're scrolling down and there's this nanosecond where you're like salivating an anticipation
*  like Pavlov's dogs and then you see something new and you get a dopamine hit.
*  And look, there's George and I'm all Clooney, right?
*  Look, there's Chloe Kardashian's new fong.
*  There's Lionel Messi waving his pink jersey.
*  Things you absolutely don't need to know.
*  What are the specific claims of harm to children from all these features we're talking about?
*  So there are two sets of harms, right?
*  One is psychological.
*  The lawsuits are not simply saying that spending all this time on Instagram is causing
*  kids to lose sleep or take time away from school or distract from homework.
*  What they're saying is that the features they contend or designed to a kids cause compulsive
*  use of Instagram.
*  And that compulsive use can lead to increased depression among young people, increased anxiety,
*  increased isolation and loneliness and particularly among young women, increased dislike of their
*  own bodies.
*  For example, the lawsuit focuses on these cosmetic surgery and beauty filters that you can use
*  if you're on Instagram because you can use the filters to make your arms look thinner or
*  your boobs look bigger or to give you a stronger chin.
*  And there's a conversation inside Instagram that's cited in one of these lawsuits in which
*  even Instagram executives are saying, you know, we're actively encouraging young girls
*  to hate their bodies with these filters.
*  Right.
*  Because the filter like that basically encourages the people who use it to think that something
*  is wrong and needs to be improved.
*  Right.
*  And apart from the mental health harms, the state lawsuits also allege that there are
*  concrete harms that come from young people using the platforms.
*  For example, a whistleblower recently came forward with internal company documents and
*  said that a survey of Instagram users found that 22% of 13 to 15 year olds said they were
*  bullied on the platform just within the last week.
*  He also said that about 22% of young users had said they received unwanted sexual advances,
*  again, just within the last week.
*  So in the world of these lawsuits, Instagram especially is not a place where you go to
*  innocently post about your life and catch up with your friends.
*  Instagram, according to this lawsuit, is an addictive product whose most popular features
*  make it dangerous for kids.
*  Right.
*  That's what the lawsuits are saying and not only that, the states are accusing meta of knowingly
*  concealing those harms.
*  We'll be right back.
*  Natasha, tell us more about this allegation in these lawsuits, the second of the allegations
*  that meta new Instagram was harmful to kids, but tried to hide that from the public.
*  That's one of the really surprising things about these state complaints.
*  They describe how the company regularly did research on teen mental health, regularly
*  surveyed its users age 13 to 17 and knew that they were having negative experiences and
*  that they were experiencing harms.
*  And yet the complaints say, company executives from Mark Zuckerberg on down testified in
*  Congress or gave interviews on TV saying that they cared about the well-being of their
*  youngest users.
*  They were doing all this work to protect them and that the platform was safe.
*  In other words, that they knew better than what they were saying in public about what
*  Instagram did or didn't do to kids.
*  They had internal evidence showing it was bad and they'd go out and say, it's not bad
*  or even that it's good.
*  That's what the states contend.
*  I'm curious what, according to the lawsuits, did meta do with this data at had about what
*  its users were feeling this data that often showed these harms?
*  The lawsuits describe how a number of meta employees were worried by their own internal
*  data on their impact on teen users and these meta employees proposed different ways to
*  mitigate the problems and the harms that young people were having.
*  And yet their proposals were often shut down by their bosses.
*  Give us a couple examples of that.
*  One of the internal projects was about likes.
*  So, according to one complaint, meta's research found that teen users often like compare
*  their accounts to their friends and when they see other people getting more validation,
*  it's kind of a negative comparison and it led to negative outcomes like increased loneliness
*  or worse body image or negative mood.
*  And so, to try to change that, meta did a test program called Project Daisy where in
*  some cases they basically hid all the like counts you saw on Instagram except for your
*  own and then another experiment where like counts from like really popular accounts were
*  visible but not like normal people.
*  And they found that both of those experiments reduced user's experience of negative feelings
*  and negative social comparisons.
*  That's fascinating.
*  And so, the solution was let's hide the likes by default and it might make teens happier.
*  And around 2020, meta executives did this whole publicity tour saying that they were going
*  to put this into effect but ultimately meta did not take away the likes.
*  And why not?
*  That's a really important question that the complaints don't directly answer.
*  The implication in the lawsuits is that there was a profit motive for not taking the likes
*  away.
*  But because meta had publicly said they were going to take the likes away, there was some
*  kind of pressure to do something.
*  And so, at the end of the day, meta offered an opt in option that you could choose to hide
*  the likes and the lawsuit says that meta knew that that was really not going to make a difference
*  because they studied it.
*  And they found that if you offered people the chance to hide their like counts less than
*  1% of people would do it.
*  But if it was opted out by default, 35% would leave the like counts hidden.
*  And so, basically, the allegation is that here was something easy that meta could have done
*  to reduce social anxiety for teens and they chose not to do it.
*  Do we get a sense from these lawsuits of who at the company is blocking these efforts
*  to make Instagram better, safer for kids?
*  Yes, we do.
*  There's one striking example in the Massachusetts lawsuit against meta, which talked about those
*  cosmetic surgery filters we talked about before.
*  And there's this whole internal discussion in this lawsuit between different executives
*  saying these cosmetic filters are overwhelmingly used by teen girls.
*  We know it's not good for them.
*  But experts say that these filters are not good for young women.
*  Let us disallow them.
*  Again, a little bit like the likes.
*  Do something easy, low-hanging fruit.
*  Just make it go away.
*  Yeah.
*  And there is an internal discussion among a handful of top executives at Instagram and Mark
*  Zuckerberg according to the lawsuit is part of this chain.
*  And there's supposed to be a meeting with Mark Zuckerberg to discuss getting rid of these
*  filters.
*  But one day before the meeting, it's canceled.
*  And then according to the lawsuit, Mark Zuckerberg vetoed the proposal to formally ban these
*  plastic surgery camera filters himself.
*  And in the email, it says he specifically directed staff to relax.
*  And he said there was a clear demand for these filters.
*  And according to the lawsuit, he said in the email lady he had not seen data suggesting
*  that these filters were harmful.
*  So here you have the CEO of the company saying, I don't see a problem here.
*  And I reject the idea of getting rid of these filters.
*  You have the CEO saying, according to the lawsuit, these filters are popular.
*  But these are selected quotes from emails.
*  We do not have the full correspondence.
*  Nor do we know what data he looked at or didn't look at.
*  Natasha, the final allegation you mentioned earlier in these lawsuits is that meta knowingly
*  allowed very young children onto the platform.
*  What does the lawsuit have to say about that?
*  So meta's terms of use say that you cannot set up an account on Instagram if you are under
*  13.
*  And the reason for that is there's a federal law that says companies that know they have
*  kids on their platform must get permission from parents to let them create an account
*  that would involve collecting their personal data.
*  But what the lawsuit said is that meta made it easy for users under 13 to sign up for accounts.
*  And that initially there was a drop down menu that automatically generated a date and year
*  of birth for new users that would make them over 13.
*  So the default was basically to suggest what birth date to pick to be 13.
*  Which of course, if you're under 13, you'd pick.
*  And then they changed it because somebody internally according to this lawsuit said it should
*  be neutral.
*  But of course, it's very easy to lie and pick years that make you older than 13.
*  And the result was the lawsuit says that millions of kids under 13 were on Instagram in violation
*  of the federal children's privacy law.
*  And if meta were found guilty of violating that law, the fines can be more than $50,000
*  per violation.
*  So just to summarize this entire case in Tasha is that meta designed Instagram to be addictive,
*  knew that from its own research and pretty much lied to the public about that fact.
*  And internally rejected employees request to do something about this and make Instagram
*  better for kids.
*  And all the while it is not doing all that much to stop kids under 13 who are most vulnerable
*  to all the things we're talking about from using the platform.
*  That is what the majority of state attorneys general in the United States content.
*  So let's turn to meta's defense against this lawsuit.
*  What has the company said about the allegations and I think more importantly about the evidence
*  that's contained in these lawsuits?
*  So I reached out to meta to ask them what the response was to all these lawsuits.
*  They got back to me and they said, first of all, the company has made a major and ongoing
*  investment in protecting young folks on their platforms and that there were now more than
*  30 tools and resources to protect teens and help keep them safe and away from potentially
*  harmful content and unwanted contact on their platforms.
*  They also said that the state's complaint is basically cherry picked.
*  Meta said that the lawsuit was filled with like selective quotes from hand picked documents
*  and that they didn't provide real context of how the company operates and how it makes
*  decisions.
*  On the other issues, they pointed out that Instagram's terms of service prohibit users
*  under the age of 13 and that when the company finds users under 13, they remove those
*  accounts.
*  As for the beauty filters we talked about, meta said that it banned filters that directly
*  promoted cosmetic surgery or extreme weight loss.
*  I also asked them about the comparisons to Big Tobacco that some of the attorneys general
*  were making and meta said that it was an absurd comparison.
*  Unlike Tobacco, they said meta's apps add value to people's lives so they basically
*  completely rejected the comparison to Tobacco.
*  So at the end of the day, Natasha, based on your reporting, how strong is this case that's
*  being made against meta by the states and how likely are the states to win?
*  You know, Michael, it's not a slam dunk because the states are accusing meta of several
*  distinct and really big things and those could be hard to prove.
*  It's going to be hard to prove, for instance, that notifications and likes cause addiction
*  and that addiction leads to depression or isolation.
*  There are studies linking social media use to increase symptoms of depression or feelings
*  of isolation or negative self-esteem.
*  But unlike cigarettes, social media is relatively new.
*  We do not have decades of research and particularly we don't have rigorous research showing that
*  the typical use of social media by typical kids directly causes harm.
*  But there are larger legal issues that play here, including Section 230, which is part
*  of the Communications Decency Act.
*  And in simple terms, that provision generally allows digital services like Instagram to curate
*  speech and content anyway they like and not be held liable.
*  So you could see in these lawsuits from the states that they're carefully trying to avoid
*  talking about content.
*  They're talking about tools like algorithms but social media companies have argued that
*  they're entitled under the Section 230 to curate content as they see fit.
*  Interesting.
*  And that the algorithms do that curation and therefore the companies are not liable
*  for the content.
*  Okay.
*  I want to just for a moment Natasha asked us to put ourselves in meta's headspace because
*  we've been spending so much time talking about the state's case, the state's evidence,
*  the state's worries about what Meta is doing.
*  If you're meta and you're watching this case unfold, I wonder if it's likely that they're
*  asking the question, why are all these state attorneys general focused on us?
*  We're not the only social media platform out there where all this stuff is happening.
*  There's TikTok, there's Snapchat.
*  There's many others.
*  So are they feeling a little bit kind of picked on?
*  Right.
*  Why me?
*  So what you're saying is absolutely true, right?
*  Like TikTok also has these features that the states are concerned about like endless
*  feeds and likes and beauty filters and Snapchat has notifications and stories that disappear
*  after 24 hours.
*  In fact, meta essentially copied some of the features the states are complaining about
*  from other social media platforms.
*  And so it would be completely legitimate for them to say, why are you picking on us?
*  Except that the states are not only picking on Instagram.
*  In 2022, the states announced that they were investigating TikTok for many of the same
*  practices or similar practices that they were already investigating meta for.
*  And Tennessee and Colorado are leading that investigation into TikTok.
*  It's been going on about a year and a half.
*  And remember, in the meta case, right?
*  They announced it two years ago and now they're actually filing the lawsuit.
*  Right.
*  So this case isn't the only case.
*  It's just the furthest along.
*  Right.
*  And the implication of that is this is a moment, the AG's hope of possible reckoning for
*  these platforms, all of them.
*  I think that that is the design of the lawsuits, not only to try to litigate their way into
*  causing meta to change some of the things we discussed already, but it's going to attract
*  a lot of publicity, right?
*  And it's going to reinforce some of the concerns that lawmakers, the surgeon general and many
*  other people have already been voicing.
*  And so I think that it's kind of the beginning of a snowball.
*  And so I think that they're hoping to use these lawsuits to cause meta to change and then
*  therefore other social media platforms, whether they win the lawsuit or not.
*  Natasha, we had started this conversation using the analogy of the state cases against
*  tobacco companies all those years ago.
*  And when I think about those cases, one of the clear outcomes was that everybody started
*  to think of cigarettes as dangerous.
*  I wonder if the states in the case against meta, even if they don't win in court, would
*  be happy in a world where lots more parents walk around the world thinking of social media
*  platforms like Instagram as a danger to their kids.
*  Would that be a successful outcome for the states?
*  Yeah, I don't think it would, Michael.
*  I think that we already have a lot of parents walking around thinking that social media is
*  problematic, including some attorneys general.
*  Parents are struggling to keep their kids off their devices and not on social media for
*  hours and hours at a time.
*  So like newsflash, social media is problematic.
*  I don't think that's news, right?
*  I think what they want is they want the companies to stop using or dial down some of the
*  features we talked about, endless feeds, endless bumping of young people with notifications.
*  They want that stuff to stop.
*  You know, I think about Jonathan Scrametti, who is the attorney general of Tennessee,
*  who co-led the investigation into meta.
*  And what he said to me was, you know, social media companies know what they did to make
*  their platforms as habit forming as possible for kids.
*  And so the companies ought to know where the switches are to turn those habit forming
*  features off.
*  And so really, that's the end game for these attorneys general.
*  They want the companies to either turn these features off or dial them back.
*  On the Tasha, thank you very much.
*  Thank you.
*  We'll be right back.
*  Here's what else you need to know today.
*  Look at what Hamas is holding inside the hospital.
*  These are explosives.
*  These are vests, vests with explosives.
*  We have hand grenades, collage recalls, and then we have the RPGs.
*  On Tuesday, Israel released a pair of videos that it said were recorded from inside Gaza's
*  main children's hospital that showed weapons and explosives, purportedly stockpiled there
*  by Hamas.
*  This is Hamas firing hot produce for hospitals.
*  The world has to understand who is Israel fighting against.
*  Israel shared the videos to press its case that Hamas is using hospitals as cover for its
*  military operations and to justify Israel's operations aimed at evacuating the hospitals
*  which have sparked outrage.
*  Gaza's health ministry, which is run by Hamas, denied nearly every Israeli claim in
*  the video.
*  But, the health ministry acknowledged that the footage was taken from inside Gaza's
*  main children's hospital.
*  And on Tuesday afternoon, the Biden administration said that US intelligence sources had information
*  supporting Israel's claims.
*  And a temporary spending bill that would have burnt a government shutdown at the end of
*  the week was adopted by the Republican-controlled House after more than 200 Democrats,
*  most party lines to back it.
*  The bill was seen as a major test of the new House Speaker, Mike Johnson, who chose keeping
*  the government open over pleasing his party's far right.
*  The bill, which would fund some government departments until mid-January and the rest
*  of the government through early February, did not include the spending cuts that conservatives
*  had demanded, prompting more than 90 of them to vote against it.
*  Today's episode was produced by Alex Stern, Will Read and Carlos Prieto, with help from
*  Stella Tann.
*  It was edited by John Ketchum with help from Michael Benoit, contains original music by
*  Mary and Luzano and Dan Powell, and was engineered by Alyssa Moxley.
*  Our theme music is by Jim Brunberg and Ben Lanzberg of Wonderland.
*  That's it for the Daily.
*  I'm Michael Bavar.
*  See you tomorrow.
