---
Date Generated: June 13, 2025
Transcription Model: whisper medium 20231117
Length: 1903s
Video Keywords: ['andrew ng', 'ai', 'ai tools', 'ai news', 'deep learning ai', 'deeplearning.ai', 'landing ai', 'landing.ai', 'landing ai founder', 'generative ai', 'ai effect on jobs', 'ai effect on workforce', 'labor force', 'google brain', 'deep learning', 'wsj', 'wsj interiew', 'cio council', 'wsj ceo council', 'ai hallucinations', 'machine learning', 'large language models', 'artificial intelligence', 'coursera', 'computer scientist', 'tech entrepreneur', 'techy']
Video Views: 160783
Video Rating: None
Video Description: Can the workforce learn AI skills quickly enough to keep pace with innovation? Andrew Ng, Landing AI founder and CEO, discusses the effect AI will have on the labor force and which companies are positioning themselves the best in the AI market.
#AI #DeepLearning #WSJ
---

# Andrew Ng on AI's Potential Effect on the Labor Force | WSJ
**The Wall Street Journal - Interviews:** [February 14, 2024](https://www.youtube.com/watch?v=-mIjwN1o7nE)
*  To sum it up, to start, what would you say are going to be the biggest positive and negative impacts on the workforce from AI over the next, say, five years? [[00:00:00](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=0.0s)]
*  I think there will be massive productivity boosts for existing job roles and it will create many new job roles. [[00:00:10](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=10.0s)]
*  And I don't want to pretend that there will be no job loss. There will be some job loss, but I think it may not be as bad as people are worried right now. [[00:00:17](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=17.0s)]
*  I know that we're having an important societal discussion about AI's impact on jobs. And from a business perspective, I actually find it even more useful to not think about AI automating jobs, but instead AI is automating tasks. [[00:00:26](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=26.0s)]
*  So it turns out that most jobs, you know, we can think of as a bundle of tasks. And when I work with, you know, large companies, well, often many CEOs who come and say, hey, Andrew, I have 50,000 or 100,000 employees. [[00:00:39](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=39.0s)]
*  What are all my people actually doing? Right? It turns out none of us really know in detail what our workforces are doing. [[00:00:51](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=51.0s)]
*  But I found that if you look at the jobs and break them down into tasks, then analyzing individual tasks for potential for AI automation or augmentation often leads to interesting opportunities to use AI. [[00:00:57](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=57.0s)]
*  And maybe one concrete example, radiologists. We've talked about AI maybe automating some positive radiology, but it turns out that radiologists do many tasks. [[00:01:10](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=70.0s)]
*  They read x-rays, but they also do patient intake, gather patient histories. They consult with patients, mentor young doctors. They operate the machines, maintain the machines. [[00:01:19](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=79.0s)]
*  So they actually do many different tasks. And we found that when we go into businesses and do this task-based analysis, it often surfaces interesting opportunities. [[00:01:28](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=88.0s)]
*  And regarding the job question, it turns out that for many jobs, if AI automates, you know, 20, 30 percent of the tasks in a job, then the job maybe is actually decently safe. [[00:01:38](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=98.0s)]
*  But what will happen is not that AI will replace people. But I think people that use AI will replace other people that don't. [[00:01:49](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=109.0s)]
*  What are the types of tasks that you're seeing? And if you can say what professions do you think are most, you know, you have the highest concentration of those types of tasks? [[00:01:58](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=118.0s)]
*  So some job roles really disrupted right now. Call centers, call center operations, the customer support is one. [[00:02:10](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=130.0s)]
*  It feels like tons of companies are using AI to nearly automate that or automate a large fraction of that. [[00:02:16](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=136.0s)]
*  I think sales operations, sales back office, those routine tasks are being automated. I think a bunch of others. [[00:02:24](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=144.0s)]
*  I feel like we see different teams trying to automate something lower, you know, legal work, some of the lower level marketing work, a bunch of others. [[00:02:31](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=151.0s)]
*  But I would say the two biggest I'm seeing are customer service and then maybe some sort of sales operations. But I think there's a lot of opportunities out there. [[00:02:40](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=160.0s)]
*  How do you think it's going to change the role of CIOs, the folks in this room? [[00:02:49](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=169.0s)]
*  I think it's an exciting time to be a CIO. One thing that my team, AI fund does is we often work with large corporations to identify and then execute on AI projects. [[00:02:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=174.0s)]
*  So over the last week, I think I spent almost half day sessions with two fortune 500 companies. [[00:03:07](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=187.0s)]
*  I got to hear from their technology leadership about the use cases they are pursuing. [[00:03:14](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=194.0s)]
*  And some patterns I've seen every time we spend a little bit of time brainstorming AI projects, they're always way more promising ideas than anyone has the resources to execute. [[00:03:19](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=199.0s)]
*  And so it becomes a fascinating kind of prioritization exercise to just decide what to do. [[00:03:29](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=209.0s)]
*  And then the other decisions I'm seeing is after you do a task based analysis, identify tasks and jobs for ideas, or after your team learns about AI and then brainstorms ideas, [[00:03:36](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=216.0s)]
*  after you prioritize, there's a usual kind of, you know, buy versus build decision. [[00:03:47](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=227.0s)]
*  And it turns out that we seem to be in an opportunity rich environment where quite actually what AI fund winds up often doing is often the company will say these projects only keep close to my heart. [[00:03:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=234.0s)]
*  I will pay for 100% of this. But there's so many other ideas that you just don't want to pay completely by yourself for the development of. [[00:04:08](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=248.0s)]
*  And then kind of we then help our corporate partners build it outside so you can still get the capability without needing having to pay for it entirely by yourself. [[00:04:16](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=256.0s)]
*  But I find that AI fund, we see so many startup and project ideas that we wind up having to use task management software to just keep track of all these ideas because no one on our team can keep straight of these kind of hundreds of ideas that we see and have to prioritize. [[00:04:26](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=266.0s)]
*  So you ask the generative AI to keep track of all the tasks that generate I can do. Oh, that'd be interesting. We actually use our sauna to keep track of all the different. [[00:04:43](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=283.0s)]
*  I summarize it. [[00:04:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=294.0s)]
*  You've talked for years about the importance of lifelong learning, the enhanced importance that in the AI world. Is it realistic to think that people will be able to reskill to educate themselves at a pace that keeps up with the development of this technology? [[00:04:58](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=298.0s)]
*  Not necessarily the folks in this room, but the people who are, you know, whose tasks are being automated. Like how big of an issue do you think that's going to be the displacement? [[00:05:18](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=318.0s)]
*  Because when we talk about technology and jobs, we always talk about like in the long run, you know, look, we used to all be farmers. Now we're not. In the long run, it'll be fine. [[00:05:28](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=328.0s)]
*  But in the meantime, there's a lot of, you know, dislocation. Yeah, so this is my really kind of answer. Honestly, I think it's realistic. [[00:05:36](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=336.0s)]
*  I'm a little bit nervous about it, but I think it is up to all of us collectively in leadership roles to make sure that we do manage this well. [[00:05:45](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=345.0s)]
*  One thing I'm seeing so the last wave of tech innovation, you know, when deep learning predictive AI labeling technology, whatever you call it, started to work really well. [[00:05:53](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=353.0s)]
*  Ten years ago, it tended to be more of the routine, repetitive tasks like factory automation that we could automate with Genitive AI. [[00:06:02](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=362.0s)]
*  It seems to be more of the knowledge workers work that AI can now automate or augment. [[00:06:11](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=371.0s)]
*  And to the reskilling point, I think that almost all knowledge workers today can get a productivity boost by using Genitive AI right away, pretty much right now. [[00:06:17](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=377.0s)]
*  But the challenge is there is reskilling needed. Yeah, we've all seen the stories about a lawyer generating hallucinated, you know, quote citations and then getting in trouble with the judge. [[00:06:28](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=388.0s)]
*  So I feel like people need just a little bit of training to use AI responsibly and safely. [[00:06:39](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=399.0s)]
*  But with just a little bit of training, I think almost all knowledge workers, including all the way up to the C suite, can get a productivity boost right away. [[00:06:45](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=405.0s)]
*  But I think it is it is exciting, but also frankly daunting challenge to think about how do we help all of these knowledge workers gain those skills? [[00:06:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=414.0s)]
*  Is that that problem you alluded to, the hallucination problem, the accuracy concern? [[00:07:04](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=424.0s)]
*  Is that is that fixable with AI or is it more that we just have to learn to use it the right way and assume an error rate? [[00:07:10](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=430.0s)]
*  Yeah, so I don't see a path. [[00:07:19](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=439.0s)]
*  I myself did not see a path to solving hallucinations and making AI never hallucinate in the same way that I don't see a path to solving the problem that humans sometimes make mistakes. [[00:07:22](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=442.0s)]
*  But we've figured out how to work with humans and for humans and so on. [[00:07:34](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=454.0s)]
*  It seems to go OK most of the time. [[00:07:39](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=459.0s)]
*  And I think because gender AI burst onto the scene so suddenly, a lot of people have not yet gotten used to the workflow and processes of how to work with them safely and responsibly. [[00:07:41](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=461.0s)]
*  So I know that when AI makes a mistake, sometimes where it goes viral on social media or turns a lot of attention. [[00:07:51](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=471.0s)]
*  But I think that is probably not as bad as the widespread perception. [[00:08:00](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=480.0s)]
*  Yes, AI makes mistakes, but plenty of businesses are figuring out, despite some baseline error rate, how to deploy it safely and responsibly. [[00:08:06](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=486.0s)]
*  So I'm and I'm not saying that is never a blocker to getting things deployed, but I'm seeing tons of stuff deployed in very useful ways. [[00:08:14](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=494.0s)]
*  Just just don't don't don't. [[00:08:22](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=502.0s)]
*  I mean, don't use gender AI to render medical diagnosis and output directly what drug to tell a patient to take. [[00:08:24](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=504.0s)]
*  That would be really irresponsible. [[00:08:30](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=510.0s)]
*  But there are lots of other use cases where, you know, where it seems very responsible and safe to use. [[00:08:32](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=512.0s)]
*  Do you think improvements on on error rates will make the use cases increase the use cases? [[00:08:40](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=520.0s)]
*  I mean, right now, like maybe we'll never get to a point or not in the foreseeable future where you want the doctor to directly prescribe. [[00:08:46](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=526.0s)]
*  But, you know, are there other cases that are not optimal now because we're still figuring out error rates that will become more more usable over time? [[00:08:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=534.0s)]
*  Yeah, it's been exciting to see how technology improves month over month. [[00:09:05](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=545.0s)]
*  So I think today we have much better tools for guarding against hallucinations compared to, say, six months ago. [[00:09:11](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=551.0s)]
*  But just one example, if you ask the AI to use retrieve augmented generation, so don't just generate text, but ground it in a specific trusted article and give a citation that reduces hallucinations. [[00:09:18](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=558.0s)]
*  And then further, if AI generates something you really want to be right, it turns out you can ask the AI to check his own work. [[00:09:30](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=570.0s)]
*  You know, dear AI, look at this thing you just wrote. [[00:09:37](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=577.0s)]
*  Look at this trusted source. Read both carefully and tell me if everything is justified based on a trusted source. [[00:09:39](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=579.0s)]
*  And this won't squash hallucinations completely to zero, but it will massively squash it compared to if you ask AI to just say what it had on its mind. [[00:09:45](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=585.0s)]
*  So I think hallucinations is it is an issue, but I think it's not as bad an issue as people fear it to be right now. [[00:09:55](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=595.0s)]
*  You've been involved in AI for decades. [[00:10:05](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=605.0s)]
*  And, you know, the technology has been through lots of multiple hype cycles and declines and winters, AI winters. [[00:10:09](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=609.0s)]
*  And what do you think is different about this moment, you know, the last 15 months or so since the boom of generative AI? [[00:10:18](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=618.0s)]
*  Are we, is this more lasting? [[00:10:26](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=626.0s)]
*  So, you know, I think so. [[00:10:29](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=629.0s)]
*  I feel like compared to 10, 15 years ago, we've not really had another AI winter. [[00:10:32](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=632.0s)]
*  I think it's been growing in value. [[00:10:40](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=640.0s)]
*  So today, so years back, I used to lead the Google Brain team, which seemed to help Google adopt deep learning. [[00:10:42](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=642.0s)]
*  And the economics, fundamental economics are very strong. [[00:10:49](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=649.0s)]
*  Using deep learning to drive online advertising, maybe not the most inspiring thing I've worked on, but the economic fundamentals have been really strong for, you know, 10-ish plus years now. [[00:10:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=654.0s)]
*  And I feel like the economic, the fundamentals, the generative AI also feel quite strong in the sense that we can ultimately augment a lot of tasks and drive a lot of very fundamental business efficiency. [[00:11:06](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=666.0s)]
*  Now, there is one question, I think, Sequoia posted an interesting article, you know, asking over the last year or last year, we collectively invested, I don't know, maybe something like $50 billion in capital infrastructure, you know, buying GPUs and data centers. [[00:11:21](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=681.0s)]
*  And I think we better figure out the applications to make sure that pays off. [[00:11:36](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=696.0s)]
*  So I don't think we overinvested, but to me, whenever there's a new wave of technology, almost all the attention is on the technology layer. [[00:11:41](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=701.0s)]
*  So, you know, we all want to talk about what Google and OpenAI and Microsoft and Amazon and so on are doing, because it's fun to talk about the technology. [[00:11:52](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=712.0s)]
*  There's nothing wrong with that. [[00:12:00](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=720.0s)]
*  But it turns out that for every wave of technology, for the two builders like these companies to be successful, there's another layer that had better be even more successful, which is the applications you build on top of these tools, because the applications that better generate even more revenue so that they can afford to pay the two builders. [[00:12:01](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=721.0s)]
*  And for whatever reason, society's interest or whatever, the applications tend to get less interest than the two builders. [[00:12:21](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=741.0s)]
*  But I think for many of you in organizations where you are not trying to be the next, you know, large language model, foundation model provider, I think that as we look into the many years in the future, there will be more revenue generated, at least that better be in the applications that you might build than just in the two builders. [[00:12:30](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=750.0s)]
*  That gets to a question that I find fascinating about this. What is the effect on the power dynamics in the tech industry and the economy more broadly? [[00:12:51](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=771.0s)]
*  And to what degree is this a technology that is, you know, a disruptive technology that is ushering in a new wave of companies that, you know, 10 years from now will be big. [[00:13:00](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=780.0s)]
*  And even though we hadn't heard of them two years ago, to what degree is it just going to make Microsoft and Amazon and Google, etc. more powerful than they've ever been before? [[00:13:12](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=792.0s)]
*  Yeah, so I think the cloud businesses are decently positioned because it turns out that because it turns out that, you know, AWS is your GCP. [[00:13:22](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=802.0s)]
*  Those are beautiful businesses. They generate so much efficiency that, you know, even though I may have a huge bill, I need to pay them. [[00:13:34](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=814.0s)]
*  I don't mind paying it because it's much better than the alternative, you know, most of the time, but they also are very profitable businesses. [[00:13:42](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=822.0s)]
*  And it turns out that if you look at some of the generative startups today, the switching costs of my using, you know, one startup's API versus switching to AWS or zero or GCP, Google Cloud, the switching costs are actually still quite low. [[00:13:49](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=829.0s)]
*  So the moat of a lot of the generative startups, I'm not quite sure how strong their moat is, but it turns out the cloud businesses have very high surface area. [[00:14:06](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=846.0s)]
*  I mean, you know, frankly, once you build a deep tech stack on one of the clouds, it's really painful to move off that if you didn't, you know, design for multi cloud from day one or whatever, which is part of what makes the cloud business such a beautiful business model. [[00:14:17](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=857.0s)]
*  So I think a lot of cloud businesses will do OK selling API calls and integrating this with the rest of their existing cloud offerings. [[00:14:30](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=870.0s)]
*  And the market dynamics is very interesting, right? So Meta has been a really interesting kind of spoiler for some of the businesses by releasing open source software, open source genus, AI software. [[00:14:39](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=879.0s)]
*  And I think Meta, you know, it was my former team, Google Brain, that released TensorFlow. [[00:14:50](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=890.0s)]
*  And I think that it would make logical sense for Meta. So Meta was really, you know, hurt by having to build on Android and iOS platforms, right? [[00:14:57](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=897.0s)]
*  When Apple changed the privacy policies that really damaged Meta's business. [[00:15:09](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=909.0s)]
*  So, you know, kind of makes logical sense that Meta would be worried if Google Brain, my old team, released the dominant AI developer platform, TensorFlow, and everyone had to build on TensorFlow. [[00:15:13](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=913.0s)]
*  What are the implications on Meta's business? So frankly, Meta played this hand beautifully with open sourcing PyTorch as an alternative. [[00:15:26](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=926.0s)]
*  I think again today, Genesvier is very valuable for online advertising and also user engagement. [[00:15:34](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=934.0s)]
*  And so it actually makes very strong logical sense that Meta would be quite happy to have an open source platform to build on to make sure it's not locked into like iOS like platform in the gen. [[00:15:40](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=940.0s)]
*  AI era. Fortunately, the good news is for almost all of us, Meta's work and many other parties work on open sourcing AI gives all of us, you know, free tools to build on top of. [[00:15:51](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=951.0s)]
*  It gives us those building blocks that lets us innovate cheaply and build many more exciting applications on. Sorry, not sure if that was too inside the baseball on, you know, tech, company, marketing. [[00:16:04](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=964.0s)]
*  No, I think I mean, I won't answer for everybody out there, but I thought it was fascinating and I want to come back to open source in a minute. [[00:16:15](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=975.0s)]
*  But from the point of view of CIOs and other corporate leaders across the economy, I think. [[00:16:21](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=981.0s)]
*  There are lots of options coming at you right now. [[00:16:31](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=991.0s)]
*  Lots of people trying to sell products, lots of people saying this service will change your business and part of the job is, you know, figuring out what's wheat, what's chaff. [[00:16:35](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=995.0s)]
*  How do you do you have any advice on how to tell in a moment where the technology is fairly nascent and fast developing how to tell apart the sort of people who have real solutions from the snake oil salesman? [[00:16:45](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1005.0s)]
*  You know, I'll tell you the thing that I think is tough. Even even our VC friends right here on San, some of them on San Joao Road. [[00:16:57](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1017.0s)]
*  The one thing that's still quite tough is the technical judgment because AI is evolving so quickly. So I've seen really good investors here on San Joao Road. [[00:17:04](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1024.0s)]
*  They'll be pitched on some startup and sometimes, you know, someone let's say open AI or someone just released a new API and a starter built something really cool over a weekend on top of a new API that someone just released. [[00:17:14](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1034.0s)]
*  But unless you know, you know, about that new capability and what a starter really did, I've seen VCs come to me and say, wow, Andrew, this is so exciting. [[00:17:26](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1046.0s)]
*  Look, these three college students built this thing. This is amazing. I want to fund it. And I'll go, no, I just saw 50 other starters doing the exact same thing. [[00:17:35](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1055.0s)]
*  And so I think that technical judgment, because the tech is evolving so quickly, that's the one thing that I find difficult. [[00:17:44](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1064.0s)]
*  And then maybe I'd say for an important work of corporate saw those we tend to work of corporate is go through a systematic brainstorming process. [[00:17:52](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1072.0s)]
*  But I'll just mention one other thing that I think could probably many CIOs interest, which is we've all seen when we buy a new solution, you know, often we end up creating another data silo within within our organization. [[00:17:58](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1078.0s)]
*  And I feel like if we're able to work with vendors that, you know, let us continue to have full access to our data in a reasonably interchangeable format that significantly reduces vendor lock in so that if one vendor you decide to swap out for a different vendor in a month or two. [[00:18:11](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1091.0s)]
*  So that's one thing I tend to pay heavy attention to myself is if I buy it from a vendor, don't do stuff with my data because I want them to. That's what I'm paying them for. [[00:18:32](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1112.0s)]
*  But is that that transparency and interoperability to make sure that I control my own data and the ability to swap to my own team take a look at it or swap off a different vendor. [[00:18:42](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1122.0s)]
*  This does run counter to the interest of all the vendors that one right lock in candidly. But this is one thing I tend to rate higher than than some of my colleagues in my vendor selection and buying process. [[00:18:52](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1132.0s)]
*  It sounds like you see a world where the folks in this room are implementing a generative AI through a multiple multiplicity of different providers. It's not going to be like, yeah, we were with Microsoft. It's going to be. Yeah, we use Microsoft for this. We use this. [[00:19:06](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1146.0s)]
*  This company over here for that is that right like it's. [[00:19:25](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1165.0s)]
*  Yeah, I would say it seems like the Microsoft sales reps. [[00:19:29](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1169.0s)]
*  Oh, I'm actually well should we do a poll. How many of you has that Microsoft sales reps push copilot is really hard to you. [[00:19:33](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1173.0s)]
*  Yeah, I thought so. Right. So Microsoft is great. You know, love the team really capable copilot is can give a private abuse, but there's so much stuff out in the market. I think it's it's worthwhile to to to take a look at multiple options and then. [[00:19:41](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1181.0s)]
*  By the right to for the right job. [[00:19:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1194.0s)]
*  You touched on the hardware costs that the amount that's been invested. So so far. How concerned are you about the hardware bottleneck and the lack of GPUs, TPUs, you know, whatever one wants to call it. [[00:19:57](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1197.0s)]
*  And you know, in videos relative strength hold over the the last year or two. And and what do you think of what we reported is Sam Altman's plans to raise potentially trillions of dollars to solve this. [[00:20:10](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1210.0s)]
*  Yeah, it'll be it'll be Sam. Sam was my student at Stanford way back. I've known him for years. [[00:20:25](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1225.0s)]
*  He's a smart guy. Can't argue results. I don't know where we find trillions of seven trillion dollars that was up to you. [[00:20:32](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1232.0s)]
*  That lets you buy Apple twice. Right. More than twice. So it's an interesting figure to try to raise. [[00:20:41](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1241.0s)]
*  I think that over the next year, I think I think in a year or so the semiconductor shortage, I think it will feel much better. [[00:20:48](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1248.0s)]
*  And I want to give you know, AMD credit and Intel maybe. So Nvidia has been Nvidia's one of Nvidia's note has been the cruder programming language. [[00:20:58](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1258.0s)]
*  But AMD's open source alternative called Rockham has been making really good progress. [[00:21:09](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1269.0s)]
*  And so some of my teams, you know, we've built stuff on AMD hardware. And sometimes I don't think it is not at parity, but it's also so much better than a year ago. [[00:21:15](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1275.0s)]
*  So I think AMD is worth a careful look at Intel. Gaudi is also, you know, so we'll see how the market evolves. [[00:21:26](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1286.0s)]
*  You've mentioned open source several times. I know you're a champion of that. [[00:21:35](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1295.0s)]
*  It comes up in the regulatory discussion. And I think one argument that resonates is, well, if we have, you know, at least if we have these proprietary models, there's a handful of companies with these big, powerful LLMs that we can focus on, make sure they're doing the right thing to prevent this technology from being misused. [[00:21:41](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1301.0s)]
*  Open source proliferates and you're talking about not five or ten, but five hundred or a thousand or even larger numbers of people who have these tools. [[00:22:01](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1321.0s)]
*  And, you know, how do you know what they're going to do with it and how do you control it? What's your answer to the people who have that concern about open source? [[00:22:10](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1330.0s)]
*  Yeah, so I think over the last year or so, there's been intense lobbying efforts by a number of usually the bigger players in generative AI that would rather not have to compete with open source. [[00:22:17](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1337.0s)]
*  You know, if they invested hundreds of millions of dollars, right, to build a proprietary AI model, boy, isn't it annoying if someone open sources something similar for free? [[00:22:31](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1351.0s)]
*  That's that's just not good. So the level of intensity and lobbying in D.C. it really took me by surprise. [[00:22:40](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1360.0s)]
*  And so the main argument has been AI is dangerous, maybe even wipe out humanity. [[00:22:47](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1367.0s)]
*  So with the put in place, you know, regulatory burdening licensing requirements before you build AI, you need to report to the government and maybe maybe even get a license and prove a save. [[00:22:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1374.0s)]
*  And so there's been a lot of [[00:23:05](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1385.0s)]
*  people who have been put in place and basically put in place really heavy regulatory burdens in my opinion in a false name of safety that I think would really risk squashing open source. [[00:23:07](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1387.0s)]
*  It turns out that if these lobbying efforts succeed, I think almost all of us in this room will be losers and there'll be a very small number of, you know, people that will benefit from this. [[00:23:18](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1398.0s)]
*  I think that's the biggest thing that's happened to me here in Silicon Valley. [[00:23:29](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1409.0s)]
*  There's been and around the world has been actively pushing back against this narrative. [[00:23:31](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1411.0s)]
*  I think to all of you having the ability to open source components to build on that lets you control your own stack. [[00:23:35](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1415.0s)]
*  It means that some vendor can't deprecate one version. [[00:23:41](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1421.0s)]
*  This has happened, right? [[00:23:44](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1424.0s)]
*  And then you have to your whole software stack needs to be re-architected and so on. [[00:23:46](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1426.0s)]
*  And then to answer the safety thing, I feel like, you know, to me at the heart of it is do we want more or less intelligence in the world? [[00:23:50](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1430.0s)]
*  Until recently, our primary source of intelligence has been human intelligence. [[00:24:01](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1441.0s)]
*  Now we also have artificial intelligence or machine intelligence. [[00:24:06](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1446.0s)]
*  And yes, intelligence can be used for nefarious purposes. [[00:24:10](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1450.0s)]
*  But I think a lot of civilizations progress has been through people getting training and getting smarter and getting more intelligent. [[00:24:13](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1453.0s)]
*  And I think we're actually all much better off with more rather than less intelligence in the world. [[00:24:20](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1460.0s)]
*  So I think open source is a very positive contribution. [[00:24:24](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1464.0s)]
*  And then lastly, as far as I can tell, a lot of the fears of harm and nefarious actors, it's not that there are no negative use cases. [[00:24:27](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1467.0s)]
*  There are a few. [[00:24:34](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1474.0s)]
*  But when I look at it, I think a lot of fears have been overblown relative to the actual risk. [[00:24:36](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1476.0s)]
*  So I want to get to questions in a moment, but just to follow up on that, I interviewed you something like seven years ago at a conference and asked you about the singularity and those concerns. [[00:24:43](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1483.0s)]
*  And I think you said that worrying about like evil A.I. [[00:24:55](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1495.0s)]
*  robots is equivalent to worrying about overpopulation on Mars. [[00:24:59](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1499.0s)]
*  We're like not even there yet. [[00:25:03](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1503.0s)]
*  Are we on Mars yet in this metaphor? [[00:25:06](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1506.0s)]
*  Like where are we in that progress? [[00:25:08](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1508.0s)]
*  Yeah, at this point in time. [[00:25:11](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1511.0s)]
*  So I feel like that superintelligence singularity is much more science fiction than anything that any of us, the I-builders know how to build. [[00:25:13](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1513.0s)]
*  So I still feel that way. [[00:25:18](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1518.0s)]
*  And you were saying that you've seen less of that type of talk. [[00:25:20](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1520.0s)]
*  Like you were just Davos in the regulatory discussions. [[00:25:24](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1524.0s)]
*  There's less of this like, oh, my God, we got to like stop this. [[00:25:27](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1527.0s)]
*  We're building this thing that's so amazing. [[00:25:30](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1530.0s)]
*  It might take us. [[00:25:32](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1532.0s)]
*  It might take over humanity is not as much part of the discussion. [[00:25:34](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1534.0s)]
*  It's really dying down. [[00:25:38](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1538.0s)]
*  So last May, there was a statement signed by a bunch of people that I think made an analogy between A.I. nuclear weapons without justification. [[00:25:40](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1540.0s)]
*  You know, A.I. brings intelligence to the world. [[00:25:47](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1547.0s)]
*  Nuclear weapons blows up cities. [[00:25:49](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1549.0s)]
*  I don't know why they have anything to do with each other. [[00:25:51](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1551.0s)]
*  But that analogy just created a lot of hype. [[00:25:53](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1553.0s)]
*  Fortunately, since May, that degree of alarm, when I speak of people in the U.S. [[00:25:55](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1555.0s)]
*  government about A.I. human extinction, you know, people literally I'm very happy to see eye rolls at this point. [[00:26:00](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1560.0s)]
*  I think Europe takes this a little more seriously than the U.S. [[00:26:07](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1567.0s)]
*  But I just see the tenor dying down to talk more about concrete harms. [[00:26:11](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1571.0s)]
*  Like, you know, we want self-driving cars to be safe. [[00:26:16](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1576.0s)]
*  We want medical devices to be safe. [[00:26:18](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1578.0s)]
*  So instead of running about the A.I. [[00:26:20](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1580.0s)]
*  tech, let's look at the concrete applications. [[00:26:22](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1582.0s)]
*  Because when we look at general purpose technology like A.I., it's hard to regulate that without just slowing everything down. [[00:26:24](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1584.0s)]
*  But we look at the concrete applications. [[00:26:30](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1590.0s)]
*  We could say what do and don't we want in financial services? [[00:26:32](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1592.0s)]
*  What is fair and what is unfair in underwriting? [[00:26:36](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1596.0s)]
*  What standards should medical devices meet? [[00:26:39](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1599.0s)]
*  So good regulations in the application layer would be a very positive thing to even unlock innovation. [[00:26:42](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1602.0s)]
*  But these vague fears say, oh, intelligence is dangerous and A.I. is dangerous. [[00:26:48](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1608.0s)]
*  That just tends to lead to regulatory capture and lobbyists having very strange agendas. [[00:26:53](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1613.0s)]
*  Do we have any questions in the audience? [[00:26:58](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1618.0s)]
*  I see some down here. [[00:27:00](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1620.0s)]
*  Can we get a microphone? [[00:27:01](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1621.0s)]
*  The gentleman and then the lady. [[00:27:06](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1626.0s)]
*  Hi. [[00:27:10](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1630.0s)]
*  Thank you for all you do for this community. [[00:27:11](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1631.0s)]
*  I think your online courses are amazing. [[00:27:13](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1633.0s)]
*  Thank you. [[00:27:15](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1635.0s)]
*  You know, all innovation follows some kind of an S curve of like and we're in this rapid acceleration of innovation around generative A.I. [[00:27:17](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1637.0s)]
*  and machine learning. [[00:27:27](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1647.0s)]
*  Where do you think the plateau is and what are the rate limiters to drive us towards the plateau? [[00:27:29](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1649.0s)]
*  Like how much how much farther can this be pushed before we start to see ourselves hitting a plateau? [[00:27:35](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1655.0s)]
*  And what's going to limit that? [[00:27:40](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1660.0s)]
*  Yeah, so I think, you know, large language models, they are getting harder and harder to scale. [[00:27:42](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1662.0s)]
*  I think there is still more juice in that onion. [[00:27:47](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1667.0s)]
*  But the exciting thing is the core innovation of large language models. [[00:27:49](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1669.0s)]
*  We're now stacking other S curves on top of the first one. [[00:27:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1674.0s)]
*  So even the first S curves plateaus, I'm excited, for example, about edge A.I. or on device A.I. [[00:27:57](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1677.0s)]
*  I run it on my laptop all the time. [[00:28:03](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1683.0s)]
*  If you don't yet, it's easier than you might think. [[00:28:05](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1685.0s)]
*  It keeps all your data confidential with open source A.I. [[00:28:07](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1687.0s)]
*  You can run on your laptop. [[00:28:10](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1690.0s)]
*  I'm excited about agents. [[00:28:12](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1692.0s)]
*  Instead of you prompting A.I. it responds in a few seconds. [[00:28:13](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1693.0s)]
*  We now see A.I. systems where I can tell it, dear A.I., please do research for me and write a report. [[00:28:16](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1696.0s)]
*  It goes off for half an hour and browse the Internet, summarize all things, comes back in half an hour with a report. [[00:28:21](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1701.0s)]
*  This is kind of, you know, it's not working as well as I just described it, but it's working much better now than three months ago. [[00:28:27](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1707.0s)]
*  So I'm excited about A.I. autonomous agents goes and works for an extended period of time. [[00:28:33](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1713.0s)]
*  We saw the unlock of text processing with large language models, with large vision models, which are at a much earlier stage of development. [[00:28:39](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1719.0s)]
*  I think we're starting to see a revolution in image processing in the same way that we saw a revolution in text processing. [[00:28:48](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1728.0s)]
*  So these are some of the other S curves being stacked up on top and then some are even further out. [[00:28:55](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1735.0s)]
*  So I'm not seeing an overall plateau in A.I. yet. [[00:29:00](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1740.0s)]
*  Maybe there'll be one, but I'm not seeing it yet. [[00:29:04](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1744.0s)]
*  Do you have a very quick question? Yeah. OK. Thank you. [[00:29:08](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1748.0s)]
*  It's a great it's a great dialogue and our sophomore at Berkeley spends more time watching your videos and taking courses. [[00:29:11](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1751.0s)]
*  So thank you again. So you mentioned automating tasks and also human intelligence. [[00:29:17](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1757.0s)]
*  These the knowledge of the task are still owned by the humans in your dialogues with clients. [[00:29:22](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1762.0s)]
*  Are you seeing resistance to unpack the tasks the humans do accurately so that you can apply A.I. to it? [[00:29:28](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1768.0s)]
*  And if you are seeing resistance, what is the solve for that? [[00:29:35](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1775.0s)]
*  Let's see. So I feel like I find that when we have a realistic conversation. [[00:29:40](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1780.0s)]
*  So let's see when I work with corporations. [[00:29:46](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1786.0s)]
*  So I find we often work with corporations to brainstorm project ideas and figure out what can we help build. [[00:29:48](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1788.0s)]
*  That's actually as an A.I. person. I learned that my swim lane is A.I. [[00:29:54](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1794.0s)]
*  But all of these exciting businesses apply to that I just don't know anything about. [[00:29:58](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1798.0s)]
*  So a core part of what I our strategy is the work of large corporate partners are much smarter than I am about the business domains to apply to. [[00:30:02](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1802.0s)]
*  So one of the findings is that at the executive level, which pray who we work with the most day to day, there's not resistance at all. [[00:30:11](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1811.0s)]
*  There's just enthusiasm. Maybe one unlock that I found is I teach a class on Coursera. [[00:30:19](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1819.0s)]
*  It was the fastest growing course on Coursera last year. [[00:30:26](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1826.0s)]
*  But I did that to try to give business leaders and others a non-technical understanding of A.I. [[00:30:31](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1831.0s)]
*  What they can and cannot do. And we found that when some of our partners take genes of A.I. for everyone, you know, that non-technical understanding of A.I. unlocks a lot of brainstorming ideation. [[00:30:37](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1837.0s)]
*  So that's an executive level kind of learn about what Gen.A.I. brainstorming, execute lots of exciting projects. [[00:30:46](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1846.0s)]
*  And then many businesses are sensitive to the broader employee based concerns about about job loss. [[00:30:52](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1852.0s)]
*  And I find that when we have a really candid conversation, the fears usually go down. [[00:31:00](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1860.0s)]
*  I don't want to pretend there's zero job loss. That's just not true. [[00:31:07](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1867.0s)]
*  But when we do the task based analysis of jobs, you know, pay of A.I. automates 20 percent of my job to a lot of people. [[00:31:12](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1872.0s)]
*  That's great. I can be more productive, focus more on the other 80 percent of tasks. [[00:31:19](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1879.0s)]
*  So on average, once we have that more candid conversation, you know, I'm thinking of this one time the union stopped us from even installing one camera. [[00:31:24](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1884.0s)]
*  So there are some of that. But most of the time is a pretty rational and OK conversation. [[00:31:33](https://www.youtube.com/watch?v=-mIjwN1o7nE&t=1893.0s)]
