---
Date Generated: June 13, 2025
Transcription Model: whisper medium 20231117
Length: 1534s
Video Keywords: ['yuval noah harari', 'yuval noah harari interview', 'ai', 'ai news', 'human evolution', 'yuval noah harari sapiens', 'sapiens a brief history of humankind', 'homo deus', 'yuval noah harari books', 'writer', 'author', 'wsj', 'ai human evolution', 'global institutions', 'intelligence', 'ai impact', 'ai impact on environment', 'ai tools', 'sapiens yuval noah harari', 'artificial intelligence', 'sapiens by yuval noah harari', 'evolution', 'homo sapiens', 'yuval', 'machine learning', 'yuval harari', 'sapiens yuval harari', 'wonews']
Video Views: 5796
Video Rating: None
Video Description: Yuval Noah Harari, historian and bestselling author of books like "Sapiens: A Brief History of Mankind" and "Homo Deus," joins the WSJ Leadership Institute to examine, through his work on human evolution, ethics, and power, how AI is reshaping global institutions, executive decision-making, and our very concept of intelligence.
#AI #Writing #WSJ
---

# Yuval Noah Harari on AI and Human Evolution | WSJ Leadership Institute
**The Wall Street Journal - Interviews:** [June 12, 2025](https://www.youtube.com/watch?v=Ki5hosohNtQ)
*  So you are a military you studied the military history of the Middle East [[00:00:00](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=0.0s)]
*  Did you ever expect to now be the foremost expert on all things AI and whether we are doomed as humanity? [[00:00:04](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=4.68s)]
*  I'm not the foremost expert, but I know I didn't expect to be talking about AI with such such an audience [[00:00:10](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=10.8s)]
*  As you said, I was originally a specialist in medieval military history and [[00:00:18](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=18.12s)]
*  But the Middle Ages are coming back in many ways, okay [[00:00:23](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=23.16s)]
*  Okay, we're gonna get into that and then let me feel free to get into that as I ask you this first question you call [[00:00:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=27.1s)]
*  artificial intelligence or [[00:00:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=33.38s)]
*  Alien intelligence as you refer to it throughout your writing the rise of a new species that could replace [[00:00:35](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=35.3s)]
*  Replace [[00:00:42](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=42.38s)]
*  Homo sapiens. Yeah sapiens your prior book. What does it mean to be human right now? [[00:00:43](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=43.66s)]
*  To be aware that for the first time we have real competition on the planet [[00:00:51](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=51.019999999999996s)]
*  that [[00:00:56](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=56.66s)]
*  We have been the most intelligent [[00:00:58](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=58.58s)]
*  species by far [[00:01:00](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=60.9s)]
*  for tens of thousands of years and this is how we got from being an insignificant ape in a corner of Africa to [[00:01:02](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=62.82s)]
*  being the absolute rulers of the planet and of the ecosystem and [[00:01:10](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=70.53999999999999s)]
*  Now we are creating something that could compete with us in the very near future [[00:01:16](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=76.02s)]
*  the most important thing to know about AI is [[00:01:22](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=82.7s)]
*  That it is not a tool like all previous human inventions. It is an agent an [[00:01:26](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=86.42s)]
*  agent in the sense that it can make decisions [[00:01:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=93.58s)]
*  Independently of us it can invent new ideas [[00:01:38](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=98.78s)]
*  It can learn and change by itself all previous human inventions, you know [[00:01:42](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=102.5s)]
*  Whether they're printing press or the atom bomb they are tools that empower us [[00:01:47](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=107.82s)]
*  They needed us they need us because a printing press cannot write books by itself and it cannot decide which books to print [[00:01:52](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=112.97999999999999s)]
*  an [[00:02:01](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=121.05999999999999s)]
*  Atom bomb cannot invent the next more powerful bomb and an atom bomb cannot decide what to attack [[00:02:02](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=122.17999999999999s)]
*  An AI weapon can decide by itself which target to attack and design [[00:02:10](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=130.34s)]
*  The next generation of weapons by itself. So this is why you argue [[00:02:16](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=136.62s)]
*  That AI is potentially or it sounds like you're saying is by the way now [[00:02:22](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=142.58s)]
*  But you've written in the past potentially more momentous in the invention of the telegraph the printing press [[00:02:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=147.08s)]
*  even writing [[00:02:32](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=152.94s)]
*  But the way you talk about it in Nexus is that it is a baby [[00:02:34](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=154.98000000000002s)]
*  yeah, because it learns from us and [[00:02:39](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=159.9s)]
*  Therefore your argument is that we especially the powerful leaders in this room have a lot of responsibility [[00:02:43](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=163.62s)]
*  Because how we act is how AI will be you cannot expect to lie and cheat and have benevolent AI. Yeah, explain that [[00:02:50](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=170.70000000000002s)]
*  Yeah, there is a big discussion around the world about AI alignment. Okay, we are creating these increasingly [[00:02:59](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=179.34s)]
*  Superintelligent very powerful new agents [[00:03:06](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=186.82000000000002s)]
*  How do we make sure that these agents remain aligned with human goals and with the benefit of humanity? [[00:03:09](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=189.54000000000002s)]
*  That they do what is good for us and [[00:03:17](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=197.9s)]
*  So there is a lot of research and a lot of efforts [[00:03:22](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=202.06s)]
*  focused on the idea that if we can [[00:03:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=205.58s)]
*  Design these AI's in a certain way if we can teach them certain [[00:03:29](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=209.14000000000001s)]
*  Principles if we can code into them certain goals, then we will be safe [[00:03:34](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=214.66s)]
*  But there are two main problems with this approach [[00:03:40](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=220.74s)]
*  First of all and the very definition of AI is it it can learn and change by itself [[00:03:43](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=223.98s)]
*  If you have a machine that can act automatically but only following pre-programmed [[00:03:49](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=229.38s)]
*  orders [[00:03:56](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=236.3s)]
*  Then you know, it's a coffee machine [[00:03:57](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=237.34s)]
*  It can do something automatically produce coffee, but it cannot decide or invent anything by itself [[00:03:59](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=239.66s)]
*  It's not an AI [[00:04:06](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=246.38s)]
*  So when you design an AI by definition [[00:04:08](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=248.1s)]
*  This thing is going to do all kinds of things [[00:04:11](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=251.86s)]
*  Which you cannot anticipate if you can anticipate everything it will do it is by definition not an AI [[00:04:16](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=256.38s)]
*  So that's one problem the other even bigger problem [[00:04:24](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=264.14s)]
*  you know that we can think about AI like you said like a baby or a child and [[00:04:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=267.78s)]
*  You can educate a child [[00:04:32](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=272.74s)]
*  To the best of your ability and he or she will still surprise you for better or worse [[00:04:34](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=274.86s)]
*  No matter how much you invest in their education. They are independent agents [[00:04:41](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=281.42s)]
*  They might eventually do something which will surprise you and even horrify you [[00:04:47](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=287.18s)]
*  the other thing is [[00:04:53](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=293.3s)]
*  Everybody who has any knowledge of education knows that [[00:04:55](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=295.90000000000003s)]
*  In the education of children it matters far less [[00:05:01](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=301.5s)]
*  What you tell them and what you do it matters far more what you do [[00:05:05](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=305.5s)]
*  if you tell your kids don't lie and [[00:05:09](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=309.78000000000003s)]
*  They your kids watch you lying to other people they will copy your behavior [[00:05:13](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=313.18s)]
*  Not your instructions now if we have now these big projects to educate [[00:05:19](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=319.22s)]
*  the AI's [[00:05:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=325.02s)]
*  Not to lie [[00:05:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=327.02s)]
*  But the AI's are given access to the world and they watch [[00:05:28](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=328.66s)]
*  How humans behave and they see some of the most powerful humans on the planet? [[00:05:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=333.70000000000005s)]
*  including their parents [[00:05:40](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=340.26000000000005s)]
*  lying [[00:05:42](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=342.5s)]
*  The AI will copy the behavior [[00:05:43](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=343.90000000000003s)]
*  people who think that I can run say this huge AI corporation and [[00:05:47](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=347.46000000000004s)]
*  While I'm lying I will teach my AI's not to lie it will not work [[00:05:53](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=353.46s)]
*  It will copy your behavior your one of your central arguments is that we as society writ large have focused way too much on [[00:05:59](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=359.26s)]
*  power and [[00:06:07](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=367.53999999999996s)]
*  You also make the argument that some disagree with or recall counterintuitive that more information is great for [[00:06:09](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=369.34s)]
*  Democracies because you say all information is not true information [[00:06:16](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=376.34s)]
*  Most information is not the truth right there is a huge confusion between information and truth [[00:06:19](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=379.26000000000005s)]
*  Yes sign formation is true and you'll get information to get to know the truth [[00:06:23](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=383.90000000000003s)]
*  but generally the truth is a very very small subset of [[00:06:28](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=388.98s)]
*  Most of the of the of the information in the universe [[00:06:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=393.3s)]
*  So if we are focusing too much on power and that's a very important distinction you say this is why we have failed as [[00:06:36](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=396.22s)]
*  People largely to answer actually the biggest questions of life if we can be more productive we can be richer [[00:06:44](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=404.65999999999997s)]
*  We can have stronger militaries [[00:06:51](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=411.65999999999997s)]
*  But many of us can't answer the question as you write who are we? [[00:06:54](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=414.09999999999997s)]
*  What should we aspire to and what is a good life? [[00:06:58](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=418.65999999999997s)]
*  Essentially we are accumulating power not wisdom. Yeah, how can we change it? [[00:07:04](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=424.46s)]
*  And that's the big problem of human history, you know for thousands of years [[00:07:10](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=430.09999999999997s)]
*  We are extremely good in acquiring more power [[00:07:14](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=434.09999999999997s)]
*  And this is how we transform ourselves from an insignificant ape in East Africa [[00:07:17](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=437.53999999999996s)]
*  Into the ruler of the world we can fly to the moon. We can split the atom, but we don't seem to be significantly happier [[00:07:23](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=443.06s)]
*  Then we were in the Stone Age [[00:07:31](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=451.26s)]
*  We don't know how to translate power into happiness [[00:07:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=453.82s)]
*  Again, you look at the most powerful people on the planet. They don't seem to be the most the happiest people on the planet [[00:07:38](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=458.58s)]
*  So there is a very do I ask them? [[00:07:45](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=465.53999999999996s)]
*  I'm not necessarily referring to the people in this room. I don't I want to clarify. I don't think there is a [[00:07:49](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=469.14s)]
*  Contradiction, okay between power and happiness. I don't think that as you acquire more power you necessarily become miserable. No [[00:07:55](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=475.94s)]
*  But there is no [[00:08:04](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=484.2s)]
*  It can go together, but it doesn't necessarily [[00:08:06](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=486.44s)]
*  Go together and as a species we have not been particularly good in [[00:08:09](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=489.84s)]
*  Translating power into happiness or even into knowledge and wisdom again. We tend to confuse [[00:08:15](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=495.96s)]
*  intelligence [[00:08:22](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=502.71999999999997s)]
*  with with knowledge and with truth [[00:08:23](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=503.91999999999996s)]
*  But we are the most intelligent species on the planet we are also the most delusional [[00:08:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=507.96s)]
*  And destructive you argue and self-destructive. Yeah, the kind of things that people believe [[00:08:34](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=514.64s)]
*  No other animal on the planet will believe such nonsense like except if I look at my own country [[00:08:41](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=521.08s)]
*  like [[00:08:47](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=527.68s)]
*  You would not find any animal that believes that if you go and kill [[00:08:48](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=528.84s)]
*  Other members of your species you will be rewarded after death by entering paradise [[00:08:54](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=534.12s)]
*  No chimpanzee will believe that [[00:09:00](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=540.24s)]
*  No, horse would believe that no wolf will believe that [[00:09:02](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=542.9200000000001s)]
*  Millions of people believe that and they believe it so strongly that they actually go and kill people in the expectation [[00:09:07](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=547.2s)]
*  That as a result they will be rewarded in paradise with whatever you [[00:09:14](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=554.28s)]
*  We took a really interesting poll this morning asking the leaders in this room how [[00:09:19](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=559.4s)]
*  Consequential they think AI has been so far in their business and actually only a few the businesses they lead and only a small portion [[00:09:24](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=564.8s)]
*  Said significantly most it was [[00:09:32](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=572.56s)]
*  Moderately or not at all. Yeah, can you speak to them as if we were sitting here 36 months from now? [[00:09:35](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=575.92s)]
*  Is there any world in which AI doesn't have a significant impact on their business? [[00:09:41](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=581.96s)]
*  It depends on their business but in most fields and the question is one of [[00:09:46](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=586.76s)]
*  timescale, you know, I've been talking to a lot of the people who lead the AI revolution and [[00:09:53](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=593.5200000000001s)]
*  Many of them say, you know, we are already in the middle of the AI revolution [[00:09:59](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=599.5600000000001s)]
*  We still haven't seen anything really major and that's just the difference between how historians view time and how [[00:10:04](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=604.8000000000001s)]
*  CEOs and entrepreneurs view time [[00:10:12](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=612.8000000000001s)]
*  For an entrepreneur two years is a long time for historians. It's nothing [[00:10:15](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=615.48s)]
*  It's like imagine that we are now sitting in London and the year is [[00:10:20](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=620.64s)]
*  1835 [[00:10:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=625.68s)]
*  The first railway has been opened between Manchester and Liverpool five years ago [[00:10:26](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=626.8s)]
*  And we have now this conference in London in 1835 and people saying, you know [[00:10:32](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=632.34s)]
*  All this talk about railways changing the world the Industrial Revolution. This is nonsense [[00:10:37](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=637.6s)]
*  We have had railways for ages five years and look, okay [[00:10:42](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=642.1600000000001s)]
*  so there is some changes that they now have people traveling with the trains or they [[00:10:46](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=646.88s)]
*  Move around coal more easily, but nothing major happened [[00:10:54](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=654.64s)]
*  because there is a time lag between the invention of the technology and [[00:10:59](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=659.36s)]
*  The moment when you see the actual social and political consequences. Yeah [[00:11:05](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=665.2800000000001s)]
*  So we now know that the Industrial Revolution and trains they completely transformed everything [[00:11:11](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=671.1999999999999s)]
*  geopolitics the way people fight wars the economy family structure [[00:11:19](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=679.2399999999999s)]
*  But it just took more than five years [[00:11:24](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=684.2199999999999s)]
*  The same is likely to happen with AI [[00:11:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=687.3599999999999s)]
*  in all [[00:11:31](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=691.5999999999999s)]
*  fields from the obvious [[00:11:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=693.2399999999999s)]
*  Yeah to the less obvious like I think that one of the first fields will see major changes its finance [[00:11:35](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=695.6800000000001s)]
*  Okay, that AI is going very quickly to take over the financial system [[00:11:41](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=701.6s)]
*  We have some bankers in the room. So tell us more because finance is the ideal playing ground for AI [[00:11:46](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=706.66s)]
*  It's purely an informational real if you want to have an AI [[00:11:51](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=711.36s)]
*  Self-driving vehicle on the road which has been promised again and again and we are still not there the problem [[00:11:55](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=715.76s)]
*  Oh Waymo. Yeah, but you go around London [[00:12:02](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=722.24s)]
*  You don't see these tens of thousands of self-driving vehicles yet. I just passed my first driving lesson [[00:12:05](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=725.08s)]
*  Okay, and you still need to learn how to drive. Okay, so [[00:12:13](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=733.2s)]
*  but the problem is that for driving you need to deal with the messy physical world of [[00:12:18](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=738.2800000000001s)]
*  Pedestrians and [[00:12:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=745.76s)]
*  Holes in the road and whatever but in finance, it's only information in information out [[00:12:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=747.4000000000001s)]
*  It's much easier for an AI to master that and what happens to finance once AI's [[00:12:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=753.36s)]
*  For instance start inventing new financial devices [[00:12:41](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=761.16s)]
*  That the human brain is simply incapable of dealing with because it's mathematically too complex [[00:12:45](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=765.0799999999999s)]
*  We are going to see AI changing even things like religion [[00:12:51](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=771.8s)]
*  how at least [[00:12:56](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=776.0799999999999s)]
*  Religions which are based on texts like Judaism Islam Christianity [[00:12:58](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=778.96s)]
*  They give ultimate authority to the text. Yeah, not to any human being now until today [[00:13:04](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=784.08s)]
*  Humans were nevertheless the main authority in these religions because the texts could not speak [[00:13:10](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=790.84s)]
*  The Bible could not interpret itself. The Bible could not [[00:13:17](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=797.2s)]
*  Answer your questions. So you needed a human being as an intermediary [[00:13:22](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=802.0s)]
*  What happens when you have an AI text that can speak for itself? [[00:13:26](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=806.08s)]
*  No Jewish rabbi [[00:13:31](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=811.9200000000001s)]
*  Can know all the texts of Judaism because there are too many of them [[00:13:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=813.96s)]
*  For the first time in history [[00:13:38](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=818.4s)]
*  There is something on the planet that is able to remember every single word in every [[00:13:39](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=819.96s)]
*  writing of every rabbi in the last two thousand years and talk back to you and [[00:13:46](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=826.44s)]
*  Explain and defend its views [[00:13:52](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=832.28s)]
*  So I've friends who are now working on building religious AI's [[00:13:55](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=835.1999999999999s)]
*  That are meant to either [[00:14:00](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=840.76s)]
*  augment or replace [[00:14:03](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=843.92s)]
*  human religious leaders [[00:14:05](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=845.9599999999999s)]
*  Especially in text based religions if it's if the religion is not [[00:14:08](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=848.0799999999999s)]
*  Based on texts. It doesn't give authority to a text. It's a different story. Okay, but I go and we're going to questions next [[00:14:13](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=853.36s)]
*  I'm gonna come first to Mattia more if you want to raise your hand and we'll get you a microphone [[00:14:20](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=860.9599999999999s)]
*  But I go and talk to my pastor at our church when I am going through a difficult time [[00:14:24](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=864.4s)]
*  I am never going to talk to chat GPT like that [[00:14:29](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=869.9599999999999s)]
*  It's an individual choice [[00:14:35](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=875.7199999999999s)]
*  Well, I know that already millions of people do it [[00:14:38](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=878.4s)]
*  I mean, I know people who go for now a eyes to get psychological counseling [[00:14:42](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=882.12s)]
*  Yes, that AI is their best friend like teenagers something happened in school [[00:14:48](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=888.2s)]
*  They consult with they tell the AI what happened and ask for advice about relationships [[00:14:53](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=893.84s)]
*  So let me get back to and then the question is next. Let me get back to what you've said though about replacing jobs [[00:15:00](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=900.6800000000001s)]
*  This is really important and you write and talk a lot about it what you're worried about [[00:15:06](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=906.48s)]
*  What it becomes a useless class? That's what you've talked about and I it was five or six years ago [[00:15:10](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=910.9200000000001s)]
*  I interviewed Google CEO Sundar Pichai in Oklahoma and one of their data centers [[00:15:17](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=917.36s)]
*  We need many many more of them now to power AI and I remember asking him about AI [[00:15:21](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=921.3000000000001s)]
*  It was people talking about a lot then and he essentially told me and I'm paraphrasing here that if AI proves to be quote [[00:15:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=925.84s)]
*  In his words very disruptive to too many American jobs. He essentially said they would be open to slowing it down [[00:15:32](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=932.5600000000001s)]
*  Okay, I'm talking about this not just Google just writ large these companies right now [[00:15:41](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=941.0s)]
*  If we are headed for what you're talking about a potential useless class many interestingly white-collar jobs [[00:15:45](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=945.8399999999999s)]
*  So it's getting a little bit more attention perhaps and when it replaced blue-collar jobs, which is a whole issue in and of itself [[00:15:52](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=952.28s)]
*  What what what do we do to make sure we as a survive society not only? [[00:15:59](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=959.64s)]
*  survive but thrive [[00:16:05](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=965.04s)]
*  I want to emphasize that AI has enormous positive potential as well as dangerous potential and [[00:16:07](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=967.68s)]
*  I don't believe in historical or in technological determinism [[00:16:14](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=974.68s)]
*  You can use the same technology to create completely different kinds of societies [[00:16:19](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=979.52s)]
*  We saw it in the 20th century that you used exactly the same technology to build communist totalitarian regimes and liberal democracies [[00:16:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=985.0s)]
*  It's the same with AI [[00:16:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=993.68s)]
*  We have a lot of choices about what to do with it if again provided [[00:16:35](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=995.2s)]
*  Remember that for the first time we are dealing with agents and not tools so it makes it much more complicated [[00:16:40](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1000.64s)]
*  but we do have still most of the agency is in our hands and [[00:16:47](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1007.32s)]
*  The question of how we develop the technology and even more importantly how we how we deploy it [[00:16:52](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1012.92s)]
*  We can make a lot of choices there. We have agency and how we move forward [[00:16:59](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1019.8s)]
*  We don't have a choice that it has come. Yes, we have power and how we use it and go through it [[00:17:05](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1025.1599999999999s)]
*  Absolutely. The main problem is that now the [[00:17:10](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1030.4399999999998s)]
*  Companies and countries that lead the AI revolution has been locked into an an arms race [[00:17:14](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1034.4399999999998s)]
*  Situation so even if they know that it would be better to slow down [[00:17:22](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1042.9599999999998s)]
*  To invest more in safety to be careful about this or that potential development [[00:17:28](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1048.2399999999998s)]
*  They are constantly afraid that if we slow down and they don't slow down they will take over the world [[00:17:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1053.64s)]
*  So let's get to some questions here. Mattia more with an emotion network. Hi. Yes right here [[00:17:40](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1060.0400000000002s)]
*  Hi, no [[00:17:47](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1067.96s)]
*  So congratulations because I mean your books are really high opening and so you get really a lot of answers through your books and also today [[00:17:49](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1069.4s)]
*  We as a company we have a conference called tech emotion because we strongly believe in the power mixing technology [[00:17:57](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1077.44s)]
*  Technology innovation with emotional creativity and culture [[00:18:02](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1082.6s)]
*  But and and what you're saying, this is a lot of a mix of this. So what I think it's really interesting what you are saying about [[00:18:05](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1085.28s)]
*  also the effect of religion the fact of on the soul of the people and this is also related to what she was saying about [[00:18:13](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1093.52s)]
*  The purpose of the life of the people that is going to be destroyed or changed a lot by AI by all these innovations. So [[00:18:20](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1100.08s)]
*  How do you think it's possible to get a [[00:18:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1107.76s)]
*  Future where people is going to be more satisfied and more happy and also find more purpose what they do [[00:18:31](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1111.96s)]
*  With the difficulties that this world is changing [[00:18:39](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1119.72s)]
*  So I know there's a big question [[00:18:41](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1121.96s)]
*  But I think that is the most important thing in our life much more than business my more than anything else [[00:18:43](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1123.9199999999998s)]
*  Yes, it's a very big subject [[00:18:48](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1128.96s)]
*  The most important thing I only have time to talk about one thing [[00:18:51](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1131.72s)]
*  So the most important thing is that we need to solve our own human problems instead of relying on the AI to do it for us and the most in the key problem is the problem of trust and cooperation [[00:18:55](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1135.14s)]
*  At the present moment trust is collapsing all over the world both between countries and within societies and the hope that okay [[00:19:09](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1149.8200000000002s)]
*  Humans can no longer trust each other. So the international system and the trade system and everything is collapsing [[00:19:19](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1159.82s)]
*  But the AI will save us will so no it will not [[00:19:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1165.54s)]
*  In a world in which humans compete with each other ferociously and cannot trust each other [[00:19:30](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1170.42s)]
*  The AI produced by such a world will be a ferocious [[00:19:36](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1176.8999999999999s)]
*  competitive untrustworthy AI [[00:19:43](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1183.06s)]
*  It's not possible [[00:19:45](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1185.3s)]
*  For humans as they engaged in in this ferocious competition [[00:19:47](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1187.94s)]
*  To create [[00:19:53](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1193.94s)]
*  Benevolent trustworthy AI it will just not happen [[00:19:55](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1195.58s)]
*  So if you think about it's just a question of priority [[00:19:59](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1199.5s)]
*  We have now this big human trust problem and we have the issue. How do how do we develop AI? [[00:20:02](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1202.8999999999999s)]
*  Too many people think okay. Let's first solve [[00:20:09](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1209.3s)]
*  The how do we develop AI problem and then this will solve the human trust problem it will not work [[00:20:12](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1212.94s)]
*  We need to get our priorities the other way first solve the human trust problem [[00:20:20](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1220.58s)]
*  Then together we can create benevolent AI. Of course, this is not what is happening right now in the world [[00:20:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1227.62s)]
*  Do we have one more? Yes right here [[00:20:35](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1235.7s)]
*  Thanks very much Yuval quick question from me so you know in human history [[00:20:37](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1237.7s)]
*  There's been organizing principles and you write about that so much in your books [[00:20:41](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1241.42s)]
*  And there's been in some senses at least geographically monolithic organizing principles like religion and the church [[00:20:45](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1245.1000000000001s)]
*  Was one of those but when we talk about AI we're not talking about something that is monolithic [[00:20:51](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1251.1000000000001s)]
*  There is no the AI. This is really effectively going to be [[00:20:56](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1256.3s)]
*  multiple plethoras of AI's [[00:21:00](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1260.5800000000002s)]
*  Manifesting themselves. Absolutely [[00:21:03](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1263.46s)]
*  And in that context, you know when you when you describe AI [[00:21:06](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1266.02s)]
*  Replacing religions in some sense. I think the real question for me is when you have no single organizing principle [[00:21:09](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1269.9s)]
*  There is no the AI that gets developed with any kind of intent whether that intent is benevolent or otherwise and there's all of these competing [[00:21:15](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1275.26s)]
*  AI's that are effectively evolving fast. What does that world look like? [[00:21:22](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1282.98s)]
*  That's a very very important point. I mean the AI will not be one big AI [[00:21:28](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1288.78s)]
*  We are talking about potentially millions or billions of new AI agents with different characteristics [[00:21:33](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1293.22s)]
*  And then produced by different companies different countries [[00:21:40](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1300.02s)]
*  Everywhere in the military in the financial system in the religious system [[00:21:44](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1304.38s)]
*  So you'll have a lot of religious AI's competing with each other which AI will be the authoritative [[00:21:48](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1308.66s)]
*  AI rabbi for which currents of Judaism [[00:21:56](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1316.8600000000001s)]
*  And the same in Islam and the same in Hinduism and Buddhism and so forth [[00:22:01](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1321.18s)]
*  So you will have competition there and in the financial system [[00:22:04](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1324.78s)]
*  And we just have no idea what the outcome will be. We have [[00:22:08](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1328.54s)]
*  thousands of years of experience with [[00:22:14](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1334.22s)]
*  Human societies what happens when millions of humans compete for economic power for religious authority [[00:22:16](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1336.86s)]
*  It's very complex, but we as a society have to think about it [[00:22:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1345.62s)]
*  It's very complex, but we at least have some experience in how these things develop. We have zero experience [[00:22:29](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1349.42s)]
*  What happens in AI societies when millions of AI's compete with each other? [[00:22:36](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1356.8200000000002s)]
*  We just don't know now you this is not something you can simulate in the AI labs [[00:22:43](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1363.46s)]
*  If open AI for instance wants to check the safety or the potential outcome of its latest AI model [[00:22:49](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1369.18s)]
*  It cannot simulate history in a laboratory [[00:22:56](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1376.74s)]
*  It can check for all kinds of failures in the system [[00:23:01](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1381.42s)]
*  But it cannot tell in advance what happens when you have millions of copies of these AI's [[00:23:06](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1386.42s)]
*  in the big world outside [[00:23:13](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1393.5s)]
*  developing in unanticipated ways [[00:23:17](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1397.22s)]
*  interacting with each other and with billions of human beings [[00:23:20](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1400.46s)]
*  So it's the in a way it's the biggest [[00:23:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1405.02s)]
*  Social experiment in human history. We are all part of it and nobody has any idea [[00:23:28](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1408.3799999999999s)]
*  How it will develop? [[00:23:34](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1414.62s)]
*  You know one analogy to keep in mind we now have this [[00:23:38](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1418.26s)]
*  Immigration crisis in the US in Europe elsewhere lots of people worried about immigrants [[00:23:43](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1423.54s)]
*  Why are people worried about immigrants there are three main things that come to people's mind [[00:23:50](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1430.22s)]
*  They will take our jobs [[00:23:57](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1437.18s)]
*  They come with different cultural ideas. They will change our culture [[00:23:59](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1439.1000000000001s)]
*  They may have political agendas. They might try to take over the country politically [[00:24:04](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1444.98s)]
*  Do you know the three main? [[00:24:11](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1451.58s)]
*  things that people keep coming back to [[00:24:13](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1453.82s)]
*  Now you can think about the AI revolution as simply a wave of immigration of [[00:24:16](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1456.46s)]
*  millions and billions of AI immigrants [[00:24:23](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1463.86s)]
*  that will take people's jobs that have very different cultural ideas and [[00:24:27](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1467.6599999999999s)]
*  that might try to gain some kind of political power and [[00:24:34](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1474.06s)]
*  These AI immigrants these digital immigrants. They don't need visas [[00:24:39](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1479.86s)]
*  They don't cross [[00:24:44](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1484.48s)]
*  As a sea in some rickety boat in the middle of the night. They come at the speed of light and [[00:24:46](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1486.52s)]
*  I look for instance at far-right parties in [[00:24:53](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1493.2s)]
*  Europe and they talk so much about the human immigrants sometimes with justification [[00:24:57](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1497.16s)]
*  Sometimes without justification they talk they don't talk almost at all about the wave of [[00:25:02](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1502.72s)]
*  digital immigrants that is coming into Europe and [[00:25:09](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1509.3600000000001s)]
*  I think they should be much if they care about the sovereignty of their country if they care about the [[00:25:13](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1513.56s)]
*  Economic and cultural future of their country. They should be far more worried [[00:25:20](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1520.52s)]
*  about the digital immigrants than about the human immigrants [[00:25:25](https://www.youtube.com/watch?v=Ki5hosohNtQ&t=1525.3999999999999s)]
