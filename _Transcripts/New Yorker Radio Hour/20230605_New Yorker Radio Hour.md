---
Date Generated: January 18, 2025
Transcription Model: whisper medium 20231117
Length: 1959s
Video Keywords: ['new yorker', 'the new yorker', 'ronan farrow', 'david remnick', 'cartoon caption contest', 'new yorker cartoons', 'obsessions', 'side by side', 'backstory']
Video Views: 4952
Video Rating: None
Video Description: Sam Altman, CEO of OpenAI, which created ChatGPT, says that AI is a powerful tool that will streamline human work and quicken the pace of scientific advancement  But ChatGPT has both enthralled and terrified us, and even some of AI’s pioneers are freaked out by it – by how quickly the technology has advanced.  David Remnick talks with Altman, and with computer scientist Yoshua Bengio, who won the prestigious Turing Award for his work in 2018, but recently signed an open letter calling for a moratorium on some AI research until regulation can be implemented. The stakes, Bengio says, are high. “I believe there is a non-negligible risk that this kind of technology, in the short term, could disrupt democracies.”
---

# Should We, and Can We, Put the Brakes on Artificial Intelligence?
**New Yorker Radio Hour:** [June 05, 2023](https://www.youtube.com/watch?v=dp5eez84R-g)
*  This is the New Yorker Radio Hour, a co-production of WNYC Studios and The New Yorker. [[00:00:00](https://www.youtube.com/watch?v=dp5eez84R-g&t=0.0s)]
*  Welcome to the New Yorker Radio Hour. [[00:00:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=11.32s)]
*  I'm David Remnick. [[00:00:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=12.72s)]
*  Every technological revolution has frightened people, particularly people who've got something [[00:00:14](https://www.youtube.com/watch?v=dp5eez84R-g&t=14.68s)]
*  to lose. [[00:00:19](https://www.youtube.com/watch?v=dp5eez84R-g&t=19.46s)]
*  When Gutenberg began printing with movable type, religious and political authorities [[00:00:20](https://www.youtube.com/watch?v=dp5eez84R-g&t=20.94s)]
*  wondered how to confront a population that had new access to information and arguments [[00:00:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=26.400000000000002s)]
*  to challenge their authority. [[00:00:30](https://www.youtube.com/watch?v=dp5eez84R-g&t=30.96s)]
*  So it's not surprising that artificial intelligence is now causing grave concerns because it will [[00:00:33](https://www.youtube.com/watch?v=dp5eez84R-g&t=33.32s)]
*  affect every one of us. [[00:00:38](https://www.youtube.com/watch?v=dp5eez84R-g&t=38.88s)]
*  Perhaps the biggest nightmare is the looming new industrial revolution, the displacement [[00:00:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=41.32s)]
*  of millions of workers, the loss of huge numbers of jobs. [[00:00:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=47.2s)]
*  Congress has a choice now. [[00:00:53](https://www.youtube.com/watch?v=dp5eez84R-g&t=53.120000000000005s)]
*  We had the same choice when we faced social media. [[00:00:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=55.06s)]
*  We failed to seize that moment. [[00:00:57](https://www.youtube.com/watch?v=dp5eez84R-g&t=57.940000000000005s)]
*  What is surprising is that some of the very same people who have been racing to develop [[00:01:02](https://www.youtube.com/watch?v=dp5eez84R-g&t=62.78s)]
*  AI now seem deeply alarmed at how far they've come. [[00:01:07](https://www.youtube.com/watch?v=dp5eez84R-g&t=67.58s)]
*  In March, not long after chat GPT began captivating and terrifying us all at once, over a thousand [[00:01:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=72.18s)]
*  technology experts signed an open letter calling for a six month moratorium on certain AI research. [[00:01:20](https://www.youtube.com/watch?v=dp5eez84R-g&t=80.24000000000001s)]
*  And some of those experts say that unchecked AI could be as dangerous to our collective [[00:01:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=86.26s)]
*  future as nuclear weaponry or pandemics. [[00:01:31](https://www.youtube.com/watch?v=dp5eez84R-g&t=91.30000000000001s)]
*  So we're going to talk today about AI. [[00:01:37](https://www.youtube.com/watch?v=dp5eez84R-g&t=97.80000000000001s)]
*  How could it change the world? [[00:01:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=100.06s)]
*  And how concerned should we be? [[00:01:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=101.94s)]
*  I'll start with Sam Altman, the CEO of OpenAI, the company that's been releasing ever more [[00:01:44](https://www.youtube.com/watch?v=dp5eez84R-g&t=104.38000000000001s)]
*  sophisticated versions of chat GPT. [[00:01:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=109.86s)]
*  Years ago when the internet was in its earliest stages, we were surrounded or at least I felt [[00:01:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=115.30000000000001s)]
*  surrounded by a sense of internet euphoria. [[00:01:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=119.22s)]
*  And anyone who raised doubts about it was considered a ludite or ignorant or a charmingly [[00:02:02](https://www.youtube.com/watch?v=dp5eez84R-g&t=122.38000000000001s)]
*  fearful person past his sell by date. [[00:02:09](https://www.youtube.com/watch?v=dp5eez84R-g&t=129.28s)]
*  Now with the rise of AI, we're hearing alarm for many quarters. [[00:02:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=132.42s)]
*  So what I want to try to accomplish here is to have a rational discussion that at once [[00:02:16](https://www.youtube.com/watch?v=dp5eez84R-g&t=136.57999999999998s)]
*  gives a factual picture of where we are, where you think we're going. [[00:02:22](https://www.youtube.com/watch?v=dp5eez84R-g&t=142.26s)]
*  And at the same time, airs out the concerns. [[00:02:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=146.01999999999998s)]
*  So let's just start with the most basic thing. [[00:02:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=149.17999999999998s)]
*  You've been working on AI for nearly a decade. [[00:02:32](https://www.youtube.com/watch?v=dp5eez84R-g&t=152.61999999999998s)]
*  How did you get into it? [[00:02:35](https://www.youtube.com/watch?v=dp5eez84R-g&t=155.5s)]
*  And what were your expectations? [[00:02:36](https://www.youtube.com/watch?v=dp5eez84R-g&t=156.79999999999998s)]
*  I mean, this was what I wanted to work on from when I was like a little kid. [[00:02:38](https://www.youtube.com/watch?v=dp5eez84R-g&t=158.8s)]
*  I was like a very nerdy kid. [[00:02:42](https://www.youtube.com/watch?v=dp5eez84R-g&t=162.68s)]
*  I was very into sci-fi. [[00:02:45](https://www.youtube.com/watch?v=dp5eez84R-g&t=165.64000000000001s)]
*  I sort of never dreamed I'd actually get to work on it. [[00:02:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=167.60000000000002s)]
*  But then I went to school and studied AI. [[00:02:50](https://www.youtube.com/watch?v=dp5eez84R-g&t=170.56s)]
*  And one of the memorable things I was told was the only surefire way to have a bad career [[00:02:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=174.76000000000002s)]
*  in AI is to work on neural networks. [[00:02:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=179.20000000000002s)]
*  And we have all these other ideas, but this is the one that we've proven doesn't work. [[00:03:00](https://www.youtube.com/watch?v=dp5eez84R-g&t=180.60000000000002s)]
*  In 2012, there was a paper put out. [[00:03:04](https://www.youtube.com/watch?v=dp5eez84R-g&t=184.36s)]
*  One of the authors was my co-founder, Ilya Sudskiver, which was a neural network doing [[00:03:07](https://www.youtube.com/watch?v=dp5eez84R-g&t=187.4s)]
*  an amazing thing that performed extremely well in a competition to categorize images. [[00:03:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=191.68s)]
*  And that was amazing to me, given that I had sort of assumed this thing wasn't going to [[00:03:19](https://www.youtube.com/watch?v=dp5eez84R-g&t=199.28s)]
*  work. [[00:03:24](https://www.youtube.com/watch?v=dp5eez84R-g&t=204.08s)]
*  After that, a company called DeepMind did something with beating the world champion [[00:03:25](https://www.youtube.com/watch?v=dp5eez84R-g&t=205.16000000000003s)]
*  at Go. [[00:03:30](https://www.youtube.com/watch?v=dp5eez84R-g&t=210.44000000000003s)]
*  At the end of 2015, we started OpenAI. [[00:03:32](https://www.youtube.com/watch?v=dp5eez84R-g&t=212.24s)]
*  One of our first big projects was playing this computer game called Dota 2. [[00:03:34](https://www.youtube.com/watch?v=dp5eez84R-g&t=214.72s)]
*  And I got to watch that neural network, that effort, that system sort of grow up. [[00:03:39](https://www.youtube.com/watch?v=dp5eez84R-g&t=219.6s)]
*  Number one, we truly genuinely know Parler tricks had an algorithm that could learn. [[00:03:45](https://www.youtube.com/watch?v=dp5eez84R-g&t=225.2s)]
*  And it got better with scale. [[00:03:52](https://www.youtube.com/watch?v=dp5eez84R-g&t=232.02s)]
*  It took us a while to discover this current paradigm of these large language models. [[00:03:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=234.0s)]
*  But the fundamental insight and the fundamental algorithms were all right from the beginning [[00:03:58](https://www.youtube.com/watch?v=dp5eez84R-g&t=238.52s)]
*  of the company. [[00:04:02](https://www.youtube.com/watch?v=dp5eez84R-g&t=242.84s)]
*  So GPT suddenly appeared on the scene, and you have talked a lot about its potential. [[00:04:03](https://www.youtube.com/watch?v=dp5eez84R-g&t=243.84s)]
*  And at the same time, you've, well, let's put it this way, you freaked a lot of people [[00:04:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=251.08s)]
*  out. [[00:04:14](https://www.youtube.com/watch?v=dp5eez84R-g&t=254.68s)]
*  What do you see as its potential? [[00:04:15](https://www.youtube.com/watch?v=dp5eez84R-g&t=255.84s)]
*  And do you understand why people are unnerved about it? [[00:04:17](https://www.youtube.com/watch?v=dp5eez84R-g&t=257.76s)]
*  First of all, even the parts that I don't agree with about what people are freaked out [[00:04:21](https://www.youtube.com/watch?v=dp5eez84R-g&t=261.84000000000003s)]
*  about, I empathize with to the degree we are successfully able to create a computer [[00:04:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=266.56s)]
*  that can one day learn and perform new tasks like a human. [[00:04:31](https://www.youtube.com/watch?v=dp5eez84R-g&t=271.44s)]
*  Even if you don't believe in any of the sci-fi stories, you could still be freaked out about [[00:04:35](https://www.youtube.com/watch?v=dp5eez84R-g&t=275.92s)]
*  the level of change that this is going to bring society and the compressed time frame [[00:04:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=281.04s)]
*  in which that's going to happen. [[00:04:45](https://www.youtube.com/watch?v=dp5eez84R-g&t=285.22s)]
*  Well, let's let's slow down for a second. [[00:04:46](https://www.youtube.com/watch?v=dp5eez84R-g&t=286.92s)]
*  What does this imply in the much broader sense about what change is coming down the road? [[00:04:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=289.26s)]
*  In concrete terms? [[00:04:57](https://www.youtube.com/watch?v=dp5eez84R-g&t=297.32s)]
*  I think it means that we all are going to have much more powerful tools that significantly [[00:04:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=299.04s)]
*  increase what a person is capable of doing, but also raise the bar on what a person needs [[00:05:06](https://www.youtube.com/watch?v=dp5eez84R-g&t=306.96000000000004s)]
*  to do to be sort of a productive member of society and contribute. [[00:05:13](https://www.youtube.com/watch?v=dp5eez84R-g&t=313.76s)]
*  Because these tools will do eventually, they will augment us so powerfully that they'll [[00:05:20](https://www.youtube.com/watch?v=dp5eez84R-g&t=320.22s)]
*  change what one person or one small group of people can and do do. [[00:05:25](https://www.youtube.com/watch?v=dp5eez84R-g&t=325.64s)]
*  A lot of writers I know have naturally gotten very interested in chat GPT and they somehow [[00:05:30](https://www.youtube.com/watch?v=dp5eez84R-g&t=330.32s)]
*  think it's going to eliminate them. [[00:05:35](https://www.youtube.com/watch?v=dp5eez84R-g&t=335.8s)]
*  I have to admit, I've used your latest version of chat GPT to try and emulate my writing. [[00:05:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=340.32s)]
*  And without being over proud about it, it kind of didn't. [[00:05:46](https://www.youtube.com/watch?v=dp5eez84R-g&t=346.71999999999997s)]
*  What came out was like an encyclopedia entry with nouns that were subjects that I was interested [[00:05:50](https://www.youtube.com/watch?v=dp5eez84R-g&t=350.56s)]
*  in. [[00:05:58](https://www.youtube.com/watch?v=dp5eez84R-g&t=358.12s)]
*  So tell me where this where chat GPT is in its development now. [[00:05:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=359.12s)]
*  But should I should I basically pack it in in a couple of weeks when chat GPT is all [[00:06:06](https://www.youtube.com/watch?v=dp5eez84R-g&t=366.12s)]
*  the better? [[00:06:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=371.32s)]
*  We get excited about where things are. [[00:06:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=372.6s)]
*  But we also try always to talk about the limitations and where things aren't. [[00:06:14](https://www.youtube.com/watch?v=dp5eez84R-g&t=374.68s)]
*  Maybe a future version of GPT will replace bad writers. [[00:06:20](https://www.youtube.com/watch?v=dp5eez84R-g&t=380.03999999999996s)]
*  But it's very hard for me looking at it now. [[00:06:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=386.08s)]
*  Every time I talk to someone like you, I say this is, you know, this is really not it. [[00:06:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=389.64s)]
*  Yeah. [[00:06:34](https://www.youtube.com/watch?v=dp5eez84R-g&t=394.79999999999995s)]
*  And you think we're being defensive. [[00:06:35](https://www.youtube.com/watch?v=dp5eez84R-g&t=395.79999999999995s)]
*  No, no, no. [[00:06:36](https://www.youtube.com/watch?v=dp5eez84R-g&t=396.79999999999995s)]
*  I think you're right. [[00:06:38](https://www.youtube.com/watch?v=dp5eez84R-g&t=398.55999999999995s)]
*  I think in the sweep of emotion about chat GPT and this new world, it is so easy to say [[00:06:39](https://www.youtube.com/watch?v=dp5eez84R-g&t=399.88s)]
*  the writing is on the wall. [[00:06:48](https://www.youtube.com/watch?v=dp5eez84R-g&t=408.32s)]
*  There's going to be no role for humans. [[00:06:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=409.84000000000003s)]
*  This thing is going to take over. [[00:06:51](https://www.youtube.com/watch?v=dp5eez84R-g&t=411.36s)]
*  And I don't think that's going to be right. [[00:06:53](https://www.youtube.com/watch?v=dp5eez84R-g&t=413.36s)]
*  I don't think we are facing this total destruction of all human jobs in the very short term. [[00:06:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=415.92s)]
*  And I think it's it's difficult and important to balance that with the fact that some jobs [[00:07:03](https://www.youtube.com/watch?v=dp5eez84R-g&t=423.04s)]
*  are going to be totally replaced by this in the very short term. [[00:07:08](https://www.youtube.com/watch?v=dp5eez84R-g&t=428.72s)]
*  What jobs what jobs do you think will get eliminated pretty quickly in your view? [[00:07:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=432.44s)]
*  I think a lot of customer service jobs, a lot of data entry jobs get eliminated pretty [[00:07:17](https://www.youtube.com/watch?v=dp5eez84R-g&t=437.44s)]
*  quickly. [[00:07:22](https://www.youtube.com/watch?v=dp5eez84R-g&t=442.56s)]
*  So this is maybe useful. [[00:07:23](https://www.youtube.com/watch?v=dp5eez84R-g&t=443.56s)]
*  The thing that you do right now where like you go on some website and you're trying to [[00:07:24](https://www.youtube.com/watch?v=dp5eez84R-g&t=444.96s)]
*  return something and you like chat with somebody sitting on the other side of a chatbot and [[00:07:28](https://www.youtube.com/watch?v=dp5eez84R-g&t=448.44s)]
*  they send you a label. [[00:07:32](https://www.youtube.com/watch?v=dp5eez84R-g&t=452.08s)]
*  That job I think gets eliminated. [[00:07:35](https://www.youtube.com/watch?v=dp5eez84R-g&t=455.08s)]
*  Also the one where you call and talk to someone that takes a lot longer. [[00:07:37](https://www.youtube.com/watch?v=dp5eez84R-g&t=457.56s)]
*  I think that job gets eliminated too. [[00:07:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=461.48s)]
*  But I don't think that most people won't work. [[00:07:44](https://www.youtube.com/watch?v=dp5eez84R-g&t=464.16s)]
*  I think for a bunch of reasons that would be unfulfilling to a lot of people. [[00:07:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=467.88s)]
*  Some people won't work for sure. [[00:07:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=474.16s)]
*  I think there are people in the world who don't want to work and get fulfillment in [[00:07:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=475.16s)]
*  other ways and that shouldn't be stigmatized either. [[00:07:58](https://www.youtube.com/watch?v=dp5eez84R-g&t=478.44s)]
*  But I think many people, let's say, want to create, want to do something that makes them [[00:08:02](https://www.youtube.com/watch?v=dp5eez84R-g&t=482.15999999999997s)]
*  useful, want to somehow contribute back to society. [[00:08:07](https://www.youtube.com/watch?v=dp5eez84R-g&t=487.0s)]
*  And there will be new jobs or things that people think of as jobs that we today wouldn't [[00:08:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=491.4s)]
*  think of as jobs in the same way that maybe what you do or what I do wouldn't have seemed [[00:08:17](https://www.youtube.com/watch?v=dp5eez84R-g&t=497.03999999999996s)]
*  like a job to somebody that was like doing an actual hard physical job to survive. [[00:08:23](https://www.youtube.com/watch?v=dp5eez84R-g&t=503.15999999999997s)]
*  As the world gets richer and as we make technological progress, standards change and what we consider [[00:08:30](https://www.youtube.com/watch?v=dp5eez84R-g&t=510.36s)]
*  work and necessity and a whole bunch of other things change too. [[00:08:37](https://www.youtube.com/watch?v=dp5eez84R-g&t=517.92s)]
*  So I think that's going to happen again with AI. [[00:08:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=521.04s)]
*  I realize that some of this draws on your essay that was published a couple of years [[00:08:44](https://www.youtube.com/watch?v=dp5eez84R-g&t=524.04s)]
*  ago, Moore's Law for Everything. [[00:08:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=527.4s)]
*  You suggest economic policies like a universal basic income, taxes on land and capital rather [[00:08:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=529.02s)]
*  than on property and labor. [[00:08:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=535.5600000000001s)]
*  And all of those things have proven impossibly difficult to pass even in the most modified [[00:08:58](https://www.youtube.com/watch?v=dp5eez84R-g&t=538.36s)]
*  form. [[00:09:04](https://www.youtube.com/watch?v=dp5eez84R-g&t=544.72s)]
*  How would they become popular in the future? [[00:09:06](https://www.youtube.com/watch?v=dp5eez84R-g&t=546.04s)]
*  I think this stuff is really difficult, but A, that doesn't mean we shouldn't try and [[00:09:08](https://www.youtube.com/watch?v=dp5eez84R-g&t=548.6800000000001s)]
*  the way things that are outside the Overton window eventually happen is more and more [[00:09:15](https://www.youtube.com/watch?v=dp5eez84R-g&t=555.12s)]
*  people talking about them over time. [[00:09:18](https://www.youtube.com/watch?v=dp5eez84R-g&t=558.96s)]
*  And B, when the ground is shaking, I think is when you can make radical policy progress. [[00:09:21](https://www.youtube.com/watch?v=dp5eez84R-g&t=561.48s)]
*  So I agree with you, today we still can't do this, but if AI stays on the trajectory [[00:09:28](https://www.youtube.com/watch?v=dp5eez84R-g&t=568.5600000000001s)]
*  that it might, you know, perhaps in a few years these don't seem so radical. [[00:09:34](https://www.youtube.com/watch?v=dp5eez84R-g&t=574.9s)]
*  And we have like massive GDP growth at a time where we have a lot of turmoil in the job [[00:09:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=580.44s)]
*  market. [[00:09:48](https://www.youtube.com/watch?v=dp5eez84R-g&t=588.08s)]
*  Maybe all this stuff is possible and the more time upfront we have for people to be studying [[00:09:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=589.44s)]
*  ideas like this and contributing new ones, I think the better. [[00:09:53](https://www.youtube.com/watch?v=dp5eez84R-g&t=593.9200000000001s)]
*  I believe we have a real opportunity to shape that if you take something, a good that has [[00:09:57](https://www.youtube.com/watch?v=dp5eez84R-g&t=597.48s)]
*  been super expensive and limited and important and make that easy to access and extremely [[00:10:02](https://www.youtube.com/watch?v=dp5eez84R-g&t=602.2800000000001s)]
*  cheap that I believe that is mostly an equalizing force in the world. [[00:10:10](https://www.youtube.com/watch?v=dp5eez84R-g&t=610.96s)]
*  And we're seeing that with ChachiBT. [[00:10:15](https://www.youtube.com/watch?v=dp5eez84R-g&t=615.1600000000001s)]
*  One of the things that we tried to design into this and I think is an exciting part [[00:10:16](https://www.youtube.com/watch?v=dp5eez84R-g&t=616.68s)]
*  of this particular technological revolution is anyone can use it. [[00:10:21](https://www.youtube.com/watch?v=dp5eez84R-g&t=621.26s)]
*  You know, kids can use it, old people can use it, people that don't have familiarity [[00:10:25](https://www.youtube.com/watch?v=dp5eez84R-g&t=625.76s)]
*  with technology can use it. [[00:10:28](https://www.youtube.com/watch?v=dp5eez84R-g&t=628.6999999999999s)]
*  You can have a very like, you know, cheap, cheap mobile device that doesn't have much [[00:10:30](https://www.youtube.com/watch?v=dp5eez84R-g&t=630.3199999999999s)]
*  power and still get as much benefit out of this as someone with the best computing system [[00:10:35](https://www.youtube.com/watch?v=dp5eez84R-g&t=635.64s)]
*  in the world. [[00:10:39](https://www.youtube.com/watch?v=dp5eez84R-g&t=639.12s)]
*  My dream is that we figure out a way to let the governance of these systems, the benefits [[00:10:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=640.54s)]
*  they generate and the access to them be equally spread across every person on earth. [[00:10:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=647.54s)]
*  This is the New Yorker Radio Hour and I'm talking today with Sam Altman, the CEO of [[00:10:53](https://www.youtube.com/watch?v=dp5eez84R-g&t=653.18s)]
*  OpenAI, which developed ChatGPT and GPT-4. [[00:10:57](https://www.youtube.com/watch?v=dp5eez84R-g&t=657.62s)]
*  Sam, talk to me about artificial general intelligence, which seems to be a step even past what we've [[00:11:01](https://www.youtube.com/watch?v=dp5eez84R-g&t=661.86s)]
*  been talking about. [[00:11:08](https://www.youtube.com/watch?v=dp5eez84R-g&t=668.8199999999999s)]
*  I think it's a very blurry line. [[00:11:10](https://www.youtube.com/watch?v=dp5eez84R-g&t=670.46s)]
*  I think artificial general intelligence means to people like very powerful artificial intelligence. [[00:11:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=671.98s)]
*  It's sort of shorthand for that. [[00:11:19](https://www.youtube.com/watch?v=dp5eez84R-g&t=679.0600000000001s)]
*  My personal definition is systems that can really dramatically impact the rate that humans [[00:11:21](https://www.youtube.com/watch?v=dp5eez84R-g&t=681.1s)]
*  make scientific progress or that society makes scientific progress. [[00:11:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=689.0600000000001s)]
*  Other people use a definition like systems that can do half of the current economically [[00:11:33](https://www.youtube.com/watch?v=dp5eez84R-g&t=693.14s)]
*  valuable human work. [[00:11:38](https://www.youtube.com/watch?v=dp5eez84R-g&t=698.54s)]
*  Others use a system that can learn new things on its own. [[00:11:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=700.46s)]
*  That latter point is the thing that creates anxiety, isn't it? [[00:11:45](https://www.youtube.com/watch?v=dp5eez84R-g&t=705.26s)]
*  That it's a system that can operate beyond the bounds of human influence. [[00:11:48](https://www.youtube.com/watch?v=dp5eez84R-g&t=708.62s)]
*  Well, there's two versions of that. [[00:11:52](https://www.youtube.com/watch?v=dp5eez84R-g&t=712.62s)]
*  There's one that causes a lot of anxiety even to me and there's one that doesn't. [[00:11:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=714.46s)]
*  The one that doesn't and the one that I think is going to happen is not where an AI is off [[00:11:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=719.42s)]
*  writing its own code and changing its architecture and things like that, but that if you ask [[00:12:03](https://www.youtube.com/watch?v=dp5eez84R-g&t=723.8s)]
*  an AI a question that it doesn't know the answer to, it can go do what a human would [[00:12:08](https://www.youtube.com/watch?v=dp5eez84R-g&t=728.28s)]
*  do. [[00:12:13](https://www.youtube.com/watch?v=dp5eez84R-g&t=733.04s)]
*  Say, hey, I don't know that. [[00:12:14](https://www.youtube.com/watch?v=dp5eez84R-g&t=734.04s)]
*  I'm going to go read books. [[00:12:15](https://www.youtube.com/watch?v=dp5eez84R-g&t=735.04s)]
*  I'm going to go call smart people. [[00:12:16](https://www.youtube.com/watch?v=dp5eez84R-g&t=736.04s)]
*  I'm going to go have some conversations. [[00:12:18](https://www.youtube.com/watch?v=dp5eez84R-g&t=738.72s)]
*  I'm going to think harder and I'm going to have some new knowledge stored in my neural [[00:12:20](https://www.youtube.com/watch?v=dp5eez84R-g&t=740.28s)]
*  network and that feels fine to me. [[00:12:23](https://www.youtube.com/watch?v=dp5eez84R-g&t=743.72s)]
*  Definitely the one where it's off like writing its own code and changing its architecture. [[00:12:27](https://www.youtube.com/watch?v=dp5eez84R-g&t=747.4s)]
*  Very scary to me. [[00:12:31](https://www.youtube.com/watch?v=dp5eez84R-g&t=751.56s)]
*  AI systems have already generated skills that its creators didn't expect or prepare for [[00:12:32](https://www.youtube.com/watch?v=dp5eez84R-g&t=752.56s)]
*  learning languages. [[00:12:37](https://www.youtube.com/watch?v=dp5eez84R-g&t=757.6s)]
*  It wasn't programmed to learn figuring out how to code, for example. [[00:12:39](https://www.youtube.com/watch?v=dp5eez84R-g&t=759.02s)]
*  So the worry is that AI could break free from its human overseers and wreak havoc of one [[00:12:42](https://www.youtube.com/watch?v=dp5eez84R-g&t=762.98s)]
*  kind or another. [[00:12:48](https://www.youtube.com/watch?v=dp5eez84R-g&t=768.06s)]
*  The fundamental place that I find myself getting tripped up in thinking about this and that [[00:12:50](https://www.youtube.com/watch?v=dp5eez84R-g&t=770.12s)]
*  I've noticed in others too is, you know, is this a tool or is this a creature? [[00:12:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=774.76s)]
*  And I think it's so tempting to project creatureness onto this because it has language. [[00:12:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=779.72s)]
*  And because that feels so anthropomorphic. [[00:13:07](https://www.youtube.com/watch?v=dp5eez84R-g&t=787.44s)]
*  But what this system is, is a system that takes in some text, does some complicated [[00:13:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=791.1600000000001s)]
*  statistics on it and puts out some more text and amazing emergent behavior can happen from [[00:13:17](https://www.youtube.com/watch?v=dp5eez84R-g&t=797.9000000000001s)]
*  that as we've seen that can significantly influence a person's thinking. [[00:13:25](https://www.youtube.com/watch?v=dp5eez84R-g&t=805.0s)]
*  And we need a lot of constraints on that. [[00:13:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=809.4000000000001s)]
*  But I don't believe we're on a path to build a creature here. [[00:13:32](https://www.youtube.com/watch?v=dp5eez84R-g&t=812.72s)]
*  Now, humans can really misuse the tool in very big ways. [[00:13:35](https://www.youtube.com/watch?v=dp5eez84R-g&t=815.96s)]
*  And I worry a lot about that, much more than I worry about currently the sci-fi-esque kind [[00:13:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=820.72s)]
*  of stuff of this thing, you know, wakes up and loses control. [[00:13:46](https://www.youtube.com/watch?v=dp5eez84R-g&t=826.12s)]
*  Sam, you've had quite a few conversations lately with lawmakers. [[00:13:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=829.96s)]
*  You testified in front of a Senate subcommittee and that was widely reported. [[00:13:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=834.26s)]
*  But before that, you had a private meeting at the White House. [[00:13:58](https://www.youtube.com/watch?v=dp5eez84R-g&t=838.64s)]
*  Tell me who was there and what was the conversation about? [[00:14:02](https://www.youtube.com/watch?v=dp5eez84R-g&t=842.22s)]
*  There was a number of people from the administration led by Vice President Harris and then the [[00:14:05](https://www.youtube.com/watch?v=dp5eez84R-g&t=845.64s)]
*  CEOs of four tech and AI companies. [[00:14:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=852.04s)]
*  And the conversation was about as we go heading into this technological revolution, what can [[00:14:15](https://www.youtube.com/watch?v=dp5eez84R-g&t=855.64s)]
*  the companies do to help ensure that it's a good change and help sort of reassure people [[00:14:22](https://www.youtube.com/watch?v=dp5eez84R-g&t=862.24s)]
*  that we're going to get the things right, that we're able to get right and then we need [[00:14:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=869.68s)]
*  to in the short term. [[00:14:34](https://www.youtube.com/watch?v=dp5eez84R-g&t=874.6s)]
*  And then what can the government do? [[00:14:35](https://www.youtube.com/watch?v=dp5eez84R-g&t=875.6800000000001s)]
*  What are the kinds of policy ideas that might make sense as this technology develops? [[00:14:37](https://www.youtube.com/watch?v=dp5eez84R-g&t=877.28s)]
*  One area in particular that I am worried about in the short term is provenance of generated [[00:14:42](https://www.youtube.com/watch?v=dp5eez84R-g&t=882.84s)]
*  content. We've got an election next year. [[00:14:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=889.44s)]
*  The already image generation is incredibly good. [[00:14:53](https://www.youtube.com/watch?v=dp5eez84R-g&t=893.2s)]
*  Audio generation is getting very good. [[00:14:58](https://www.youtube.com/watch?v=dp5eez84R-g&t=898.6s)]
*  Video generation will take a little bit longer, but we'll get good too. [[00:15:01](https://www.youtube.com/watch?v=dp5eez84R-g&t=901.0s)]
*  I'm confident that we as a society with enough time can adapt to that. [[00:15:04](https://www.youtube.com/watch?v=dp5eez84R-g&t=904.64s)]
*  You know, we've learned when Photoshop came out, people were really tricked for a little [[00:15:08](https://www.youtube.com/watch?v=dp5eez84R-g&t=908.2s)]
*  while and pretty quickly people learned to be skeptical of images and people would say, [[00:15:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=912.2800000000001s)]
*  oh, that's Photoshopped or that's doctored or whatever. [[00:15:16](https://www.youtube.com/watch?v=dp5eez84R-g&t=916.2s)]
*  So I'm confident we can do it again. [[00:15:19](https://www.youtube.com/watch?v=dp5eez84R-g&t=919.08s)]
*  But we also have a different playing field now. [[00:15:21](https://www.youtube.com/watch?v=dp5eez84R-g&t=921.24s)]
*  And there's sort of Twitter and these telegram groups and however else the stuff spreads. [[00:15:23](https://www.youtube.com/watch?v=dp5eez84R-g&t=923.0s)]
*  There's a lot of regulation that could work and there's technical efforts like watermarking [[00:15:27](https://www.youtube.com/watch?v=dp5eez84R-g&t=927.76s)]
*  images or shipping detectors that could work in addition to just requiring people to disclose [[00:15:33](https://www.youtube.com/watch?v=dp5eez84R-g&t=933.4399999999999s)]
*  generated content. [[00:15:39](https://www.youtube.com/watch?v=dp5eez84R-g&t=939.76s)]
*  And then there's like education of the public about you've got to watch out for this. [[00:15:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=940.76s)]
*  Ultimately, who do you think was the most powerful people in the room? [[00:15:46](https://www.youtube.com/watch?v=dp5eez84R-g&t=946.3199999999999s)]
*  The people on the government side or the people heading the tech companies? [[00:15:48](https://www.youtube.com/watch?v=dp5eez84R-g&t=948.88s)]
*  That's an interesting question. [[00:15:52](https://www.youtube.com/watch?v=dp5eez84R-g&t=952.2s)]
*  I think the government certainly is more powerful here in even the medium term, but the government [[00:15:53](https://www.youtube.com/watch?v=dp5eez84R-g&t=953.68s)]
*  does take a little bit longer to get things done. [[00:16:02](https://www.youtube.com/watch?v=dp5eez84R-g&t=962.64s)]
*  And so I think it's important that the companies independently do the right thing in the short [[00:16:05](https://www.youtube.com/watch?v=dp5eez84R-g&t=965.36s)]
*  in the very short term. [[00:16:09](https://www.youtube.com/watch?v=dp5eez84R-g&t=969.96s)]
*  But you understand that, again, years ago, tech and, you know, the cover of Wired and [[00:16:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=971.68s)]
*  There was a kind of euphoria attached to technology that in the past several years. [[00:16:19](https://www.youtube.com/watch?v=dp5eez84R-g&t=979.8000000000001s)]
*  Doesn't feel like it this time around, does it? [[00:16:24](https://www.youtube.com/watch?v=dp5eez84R-g&t=984.8000000000001s)]
*  No, it doesn't feel that way at all. [[00:16:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=986.1600000000001s)]
*  Not because I relish it, but you know, the public images of places like Facebook and [[00:16:28](https://www.youtube.com/watch?v=dp5eez84R-g&t=988.84s)]
*  Google are not what they were. [[00:16:34](https://www.youtube.com/watch?v=dp5eez84R-g&t=994.88s)]
*  And I think trust in those companies to get things right. [[00:16:37](https://www.youtube.com/watch?v=dp5eez84R-g&t=997.6800000000001s)]
*  So when we hear about a conversation at the White House between the vice president and [[00:16:43](https://www.youtube.com/watch?v=dp5eez84R-g&t=1003.2s)]
*  her colleagues and the heads of tech companies, we want to intensely know what is going on, [[00:16:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=1007.8s)]
*  what the conversation is like and what it's leading toward. [[00:16:56](https://www.youtube.com/watch?v=dp5eez84R-g&t=1016.0s)]
*  Who's in charge? [[00:16:58](https://www.youtube.com/watch?v=dp5eez84R-g&t=1018.4399999999999s)]
*  It would be really good to know the details of that. [[00:16:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=1019.4399999999999s)]
*  The right answer here very clearly is for the government to be in charge and not just [[00:17:02](https://www.youtube.com/watch?v=dp5eez84R-g&t=1022.76s)]
*  our government. [[00:17:07](https://www.youtube.com/watch?v=dp5eez84R-g&t=1027.6s)]
*  I think this is one of these places where and I realize how naive this sounds and how [[00:17:08](https://www.youtube.com/watch?v=dp5eez84R-g&t=1028.6s)]
*  difficult it's going to be. [[00:17:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=1032.2s)]
*  We need international cooperation. [[00:17:13](https://www.youtube.com/watch?v=dp5eez84R-g&t=1033.92s)]
*  The example that I've been using recently is I think we will need something like the [[00:17:16](https://www.youtube.com/watch?v=dp5eez84R-g&t=1036.8799999999999s)]
*  IAEA that we had for nuclear for this and it's going to require atomic weapons, obviously, [[00:17:21](https://www.youtube.com/watch?v=dp5eez84R-g&t=1041.08s)]
*  and atomic energy. [[00:17:28](https://www.youtube.com/watch?v=dp5eez84R-g&t=1048.9599999999998s)]
*  And I think that's so difficult to do. [[00:17:30](https://www.youtube.com/watch?v=dp5eez84R-g&t=1050.08s)]
*  It requires international cooperation between superpowers that don't get along so well right [[00:17:32](https://www.youtube.com/watch?v=dp5eez84R-g&t=1052.84s)]
*  now. [[00:17:38](https://www.youtube.com/watch?v=dp5eez84R-g&t=1058.1999999999998s)]
*  That's what I think the right long term solution is, given how powerful this technology can [[00:17:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=1061.32s)]
*  grow. [[00:17:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=1067.6s)]
*  I'm actually optimistic that it's technically possible to do. [[00:17:48](https://www.youtube.com/watch?v=dp5eez84R-g&t=1068.6s)]
*  I think the way this technology works, the number of GPUs that are required, the small [[00:17:52](https://www.youtube.com/watch?v=dp5eez84R-g&t=1072.08s)]
*  number of people that can make them and the controls that could be imposed on them to [[00:17:57](https://www.youtube.com/watch?v=dp5eez84R-g&t=1077.8s)]
*  say nothing of the energy requirements for these systems, like it is possible to internationally [[00:18:00](https://www.youtube.com/watch?v=dp5eez84R-g&t=1080.52s)]
*  regulate this. [[00:18:06](https://www.youtube.com/watch?v=dp5eez84R-g&t=1086.1999999999998s)]
*  So I think the government has got to lead the way here. [[00:18:07](https://www.youtube.com/watch?v=dp5eez84R-g&t=1087.72s)]
*  I think we need serious regulation from the government setting the rules. [[00:18:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=1091.04s)]
*  I think it's good for the tech companies to provide input, say where we think the technology [[00:18:15](https://www.youtube.com/watch?v=dp5eez84R-g&t=1095.88s)]
*  is going, what might work technically and what won't. [[00:18:19](https://www.youtube.com/watch?v=dp5eez84R-g&t=1099.2s)]
*  But the government and really the people of the world have got to decide. [[00:18:22](https://www.youtube.com/watch?v=dp5eez84R-g&t=1102.44s)]
*  Sam Altman, thank you very much. [[00:18:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=1106.8s)]
*  Thank you. [[00:18:28](https://www.youtube.com/watch?v=dp5eez84R-g&t=1108.52s)]
*  Sam Altman is the CEO of OpenAI, which created ChatGPT. [[00:18:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=1109.52s)]
*  We're going to continue on the risks and benefits of AI in just a moment. [[00:18:37](https://www.youtube.com/watch?v=dp5eez84R-g&t=1117.28s)]
*  This is the New Yorker Radio Hour. [[00:18:43](https://www.youtube.com/watch?v=dp5eez84R-g&t=1123.2s)]
*  I'm David Remnick. [[00:18:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=1139.76s)]
*  We're talking today about the promise and the danger of artificial intelligence. [[00:19:01](https://www.youtube.com/watch?v=dp5eez84R-g&t=1141.52s)]
*  Computer scientist, Yoshua Bengio, began working on AI in the 80s and the 90s, and he's been [[00:19:07](https://www.youtube.com/watch?v=dp5eez84R-g&t=1147.0s)]
*  called one of the godfathers of AI. [[00:19:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=1152.96s)]
*  Bengio focused specifically on neural networks. [[00:19:15](https://www.youtube.com/watch?v=dp5eez84R-g&t=1155.76s)]
*  That's the idea that software can somehow mimic how the brain functions and learns. [[00:19:18](https://www.youtube.com/watch?v=dp5eez84R-g&t=1158.64s)]
*  The brain itself is a kind of network. [[00:19:24](https://www.youtube.com/watch?v=dp5eez84R-g&t=1164.78s)]
*  Now at the time, most scientists thought this would never really work out, but Bengio [[00:19:27](https://www.youtube.com/watch?v=dp5eez84R-g&t=1167.32s)]
*  and a few others persevered. [[00:19:32](https://www.youtube.com/watch?v=dp5eez84R-g&t=1172.52s)]
*  Their research led to advances in voice recognition and robotics and much more. [[00:19:34](https://www.youtube.com/watch?v=dp5eez84R-g&t=1174.96s)]
*  In 2018, Bengio received the Turing Award, kind of the Nobel Prize of computing, alongside [[00:19:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=1180.4399999999998s)]
*  Jeffrey Hinton and another colleague. [[00:19:46](https://www.youtube.com/watch?v=dp5eez84R-g&t=1186.2s)]
*  ChatGPT is also built on the foundation that Bengio helped to build. [[00:19:50](https://www.youtube.com/watch?v=dp5eez84R-g&t=1190.36s)]
*  It's a neural network. [[00:19:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=1194.12s)]
*  But Bengio, instead of celebrating this remarkable achievement in his field, has had quite a [[00:19:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=1195.34s)]
*  different reaction. [[00:20:00](https://www.youtube.com/watch?v=dp5eez84R-g&t=1200.1399999999999s)]
*  So in March, a group of very prominent people in tech signed an open letter that said that [[00:20:03](https://www.youtube.com/watch?v=dp5eez84R-g&t=1203.8999999999999s)]
*  all AI producers should stop training their systems for at least six months. [[00:20:09](https://www.youtube.com/watch?v=dp5eez84R-g&t=1209.98s)]
*  And you signed that letter. [[00:20:14](https://www.youtube.com/watch?v=dp5eez84R-g&t=1214.86s)]
*  Even Elon Musk, who's not known for his overweening sense of caution, also signed the letter. [[00:20:16](https://www.youtube.com/watch?v=dp5eez84R-g&t=1216.4199999999998s)]
*  Please tell me how that letter came about and what was the motivation? [[00:20:22](https://www.youtube.com/watch?v=dp5eez84R-g&t=1222.54s)]
*  We saw the unexpected and rapid rise of the abilities of AI systems like ChatGPT and then [[00:20:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=1226.92s)]
*  GPT-4. [[00:20:33](https://www.youtube.com/watch?v=dp5eez84R-g&t=1233.6599999999999s)]
*  We didn't ask to stop every AI research and development and deployment. [[00:20:35](https://www.youtube.com/watch?v=dp5eez84R-g&t=1235.76s)]
*  Only those very powerful systems that are of concern to us. [[00:20:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=1241.62s)]
*  I believe there is a non-negligible risk that this kind of technology in the short term [[00:20:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=1247.74s)]
*  could disrupt democracies. [[00:20:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=1254.78s)]
*  And in the coming years, with advances that people are working on, could yield to loss [[00:20:57](https://www.youtube.com/watch?v=dp5eez84R-g&t=1257.54s)]
*  of control of AI, which could have potentially even more catastrophic impacts. [[00:21:06](https://www.youtube.com/watch?v=dp5eez84R-g&t=1266.66s)]
*  So I just spoke to Sam Altman and I asked him about what seems to be the most frightening [[00:21:11](https://www.youtube.com/watch?v=dp5eez84R-g&t=1271.56s)]
*  concern of all, that an AI entity could basically become a sentient creature that could rewrite [[00:21:16](https://www.youtube.com/watch?v=dp5eez84R-g&t=1276.42s)]
*  its own source code and somehow, as if in a horrifying science fiction movie, break [[00:21:23](https://www.youtube.com/watch?v=dp5eez84R-g&t=1283.38s)]
*  free from human control. [[00:21:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=1289.14s)]
*  Altman assured me this is very unlikely. [[00:21:30](https://www.youtube.com/watch?v=dp5eez84R-g&t=1290.94s)]
*  What do you think? [[00:21:32](https://www.youtube.com/watch?v=dp5eez84R-g&t=1292.98s)]
*  Did he say it was unlikely with the current systems or in the future? [[00:21:33](https://www.youtube.com/watch?v=dp5eez84R-g&t=1293.98s)]
*  The current systems, to be sure. [[00:21:39](https://www.youtube.com/watch?v=dp5eez84R-g&t=1299.0600000000002s)]
*  Yes. [[00:21:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=1301.02s)]
*  So I agree with him. [[00:21:42](https://www.youtube.com/watch?v=dp5eez84R-g&t=1302.02s)]
*  But what about in the future? [[00:21:43](https://www.youtube.com/watch?v=dp5eez84R-g&t=1303.02s)]
*  For the future, yes, there is a real risk. [[00:21:45](https://www.youtube.com/watch?v=dp5eez84R-g&t=1305.16s)]
*  It's a risk we don't understand well enough. [[00:21:48](https://www.youtube.com/watch?v=dp5eez84R-g&t=1308.0800000000002s)]
*  In other words, you could see experts like my friend Yann LeCun saying one thing and [[00:21:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=1309.88s)]
*  other experts like Jeff Hinton and I saying the opposite. [[00:21:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=1315.0s)]
*  The scenarios by which bad things can happen haven't been sufficiently discussed, studied. [[00:21:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=1319.0800000000002s)]
*  A lot of people talk about AI alignment. [[00:22:04](https://www.youtube.com/watch?v=dp5eez84R-g&t=1324.18s)]
*  In other words, the fact that you may ask a machine to do something and it could act [[00:22:06](https://www.youtube.com/watch?v=dp5eez84R-g&t=1326.0s)]
*  in a different way that could be dangerous. [[00:22:10](https://www.youtube.com/watch?v=dp5eez84R-g&t=1330.4s)]
*  There is an alignment problem of a different kind between what's good for society and the [[00:22:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=1332.92s)]
*  general well-being of people and what companies are optimizing, which is profit under constraints [[00:22:18](https://www.youtube.com/watch?v=dp5eez84R-g&t=1338.7s)]
*  of being legal. [[00:22:27](https://www.youtube.com/watch?v=dp5eez84R-g&t=1347.28s)]
*  It's actually interesting because I find that as an inspiration to better understand what [[00:22:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=1349.3600000000001s)]
*  can go wrong with AI. [[00:22:33](https://www.youtube.com/watch?v=dp5eez84R-g&t=1353.1200000000001s)]
*  So you could think of corporations as special kind of intelligences that are not quite completely [[00:22:34](https://www.youtube.com/watch?v=dp5eez84R-g&t=1354.72s)]
*  artificial because there are human beings in there, but that can behave in a similar [[00:22:42](https://www.youtube.com/watch?v=dp5eez84R-g&t=1362.2s)]
*  way. [[00:22:46](https://www.youtube.com/watch?v=dp5eez84R-g&t=1366.76s)]
*  We try to bring corporations back into alignment with what society needs with all kinds of [[00:22:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=1367.76s)]
*  laws and regulations. [[00:22:52](https://www.youtube.com/watch?v=dp5eez84R-g&t=1372.8400000000001s)]
*  And it's in particular in the case of AI, I think we need regulation, a regulatory kind [[00:22:53](https://www.youtube.com/watch?v=dp5eez84R-g&t=1373.8400000000001s)]
*  of framework that's going to be very adaptive because technology moves quickly, science [[00:22:58](https://www.youtube.com/watch?v=dp5eez84R-g&t=1378.64s)]
*  moves quickly. [[00:23:03](https://www.youtube.com/watch?v=dp5eez84R-g&t=1383.68s)]
*  We don't want Congress or parliaments and other countries to be the ones dictating the [[00:23:04](https://www.youtube.com/watch?v=dp5eez84R-g&t=1384.92s)]
*  details. [[00:23:10](https://www.youtube.com/watch?v=dp5eez84R-g&t=1390.72s)]
*  They want to assign some more professional body that are not politicians, but they are [[00:23:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=1392.24s)]
*  experts to find the best ways to protect the public. [[00:23:17](https://www.youtube.com/watch?v=dp5eez84R-g&t=1397.84s)]
*  Well how would you and Jeff Hinton and others describe a very bad outcome? [[00:23:23](https://www.youtube.com/watch?v=dp5eez84R-g&t=1403.16s)]
*  What is the scenario that you envision is at least possible and unpredictable and dangerous? [[00:23:28](https://www.youtube.com/watch?v=dp5eez84R-g&t=1408.4s)]
*  Given that in a few years scientists figure out how to build an AI system that would be [[00:23:34](https://www.youtube.com/watch?v=dp5eez84R-g&t=1414.64s)]
*  autonomous and could be dangerous for humanity because it would have its own goals that may [[00:23:42](https://www.youtube.com/watch?v=dp5eez84R-g&t=1422.16s)]
*  conflict with ours. [[00:23:46](https://www.youtube.com/watch?v=dp5eez84R-g&t=1426.8000000000002s)]
*  And maybe we even also have figured out how we can build safe AI that wouldn't behave [[00:23:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=1429.5800000000002s)]
*  like this. [[00:23:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=1434.2800000000002s)]
*  The problem is we have that choice and maybe those scientists in the labs would choose [[00:23:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=1435.2800000000002s)]
*  the good AI solution, but there could be somebody anywhere in the world if they have [[00:24:03](https://www.youtube.com/watch?v=dp5eez84R-g&t=1443.64s)]
*  access to the required compute, which right now isn't that much. [[00:24:10](https://www.youtube.com/watch?v=dp5eez84R-g&t=1450.6000000000001s)]
*  You can take, so think about chat GPT, you don't need to retrain it, you just need to [[00:24:14](https://www.youtube.com/watch?v=dp5eez84R-g&t=1454.0400000000002s)]
*  give it the right instructions. [[00:24:18](https://www.youtube.com/watch?v=dp5eez84R-g&t=1458.72s)]
*  Anybody can do that. [[00:24:20](https://www.youtube.com/watch?v=dp5eez84R-g&t=1460.44s)]
*  What is the scenario that you see in specific terms as a possibility that you are trying [[00:24:22](https://www.youtube.com/watch?v=dp5eez84R-g&t=1462.0600000000002s)]
*  to prevent? [[00:24:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=1466.2800000000002s)]
*  There's an organization called Auto GPT, which arose just in the last few weeks or months [[00:24:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=1469.4s)]
*  that made it possible to turn something that has very little or no agency like chat and [[00:24:36](https://www.youtube.com/watch?v=dp5eez84R-g&t=1476.3600000000001s)]
*  GPT into something that actually pursues goals that the human would type, but then creating [[00:24:44](https://www.youtube.com/watch?v=dp5eez84R-g&t=1484.72s)]
*  its own sub goals in order to achieve those. [[00:24:50](https://www.youtube.com/watch?v=dp5eez84R-g&t=1490.5800000000002s)]
*  It's increasing the chances of an AI system becoming dangerous for humanity because they [[00:24:53](https://www.youtube.com/watch?v=dp5eez84R-g&t=1493.36s)]
*  are connecting, for example, that system to the internet. [[00:25:03](https://www.youtube.com/watch?v=dp5eez84R-g&t=1503.0s)]
*  It could ask people to do things for money through existing facilities for this. [[00:25:05](https://www.youtube.com/watch?v=dp5eez84R-g&t=1505.76s)]
*  If we had, instead of chat GPT, something that's smarter than humans, which may arrive [[00:25:14](https://www.youtube.com/watch?v=dp5eez84R-g&t=1514.12s)]
*  in as few as five years, I don't know, then that could become catastrophic. [[00:25:20](https://www.youtube.com/watch?v=dp5eez84R-g&t=1520.66s)]
*  You've raised the idea of AI being exploited in military use. [[00:25:26](https://www.youtube.com/watch?v=dp5eez84R-g&t=1526.02s)]
*  How should the military use artificial intelligence, if at all? [[00:25:32](https://www.youtube.com/watch?v=dp5eez84R-g&t=1532.04s)]
*  What are the dangers? [[00:25:36](https://www.youtube.com/watch?v=dp5eez84R-g&t=1536.2s)]
*  Well, the danger is first that we're putting a lot of difficult moral decisions in the [[00:25:37](https://www.youtube.com/watch?v=dp5eez84R-g&t=1537.2s)]
*  hands of machines that may not have the same understanding of what is right and wrong as [[00:25:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=1547.1399999999999s)]
*  we do. [[00:25:53](https://www.youtube.com/watch?v=dp5eez84R-g&t=1553.0s)]
*  You may know about the story of the Russian officer who decided not to press on the button [[00:25:56](https://www.youtube.com/watch?v=dp5eez84R-g&t=1556.06s)]
*  in spite of the instructions that would have led to probably catastrophic nuclear exchange [[00:26:04](https://www.youtube.com/watch?v=dp5eez84R-g&t=1564.74s)]
*  because he thought it was wrong and it was a false alarm. [[00:26:10](https://www.youtube.com/watch?v=dp5eez84R-g&t=1570.6999999999998s)]
*  If we build AI systems with agency and autonomy and they can kill because they are weapons, [[00:26:16](https://www.youtube.com/watch?v=dp5eez84R-g&t=1576.18s)]
*  it just makes the likelihood of something really catastrophic happening larger. [[00:26:25](https://www.youtube.com/watch?v=dp5eez84R-g&t=1585.74s)]
*  But then there's just like simple, let's say, Putin wants to destroy Western Europe and [[00:26:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=1589.7800000000002s)]
*  take advantage of AI technology to do it in a way that might not be possible otherwise. [[00:26:36](https://www.youtube.com/watch?v=dp5eez84R-g&t=1596.9s)]
*  If AIs are embedded into the weapons, the military, then it just gets easier to have [[00:26:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=1601.34s)]
*  large scale dangerous impacts. [[00:26:48](https://www.youtube.com/watch?v=dp5eez84R-g&t=1608.82s)]
*  I have to ask you, you've been working in this field for many years. [[00:26:51](https://www.youtube.com/watch?v=dp5eez84R-g&t=1611.1799999999998s)]
*  Why is it suddenly... [[00:26:56](https://www.youtube.com/watch?v=dp5eez84R-g&t=1616.3799999999999s)]
*  Decades. [[00:26:57](https://www.youtube.com/watch?v=dp5eez84R-g&t=1617.9399999999998s)]
*  Decades. [[00:26:58](https://www.youtube.com/watch?v=dp5eez84R-g&t=1618.9399999999998s)]
*  Suddenly everybody's very concerned about it. [[00:26:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=1619.9399999999998s)]
*  There have been rumblings about it over the year, not only in the field, but beyond the [[00:27:01](https://www.youtube.com/watch?v=dp5eez84R-g&t=1621.8999999999999s)]
*  field. [[00:27:04](https://www.youtube.com/watch?v=dp5eez84R-g&t=1624.6999999999998s)]
*  It's exploded, this level of concern. [[00:27:05](https://www.youtube.com/watch?v=dp5eez84R-g&t=1625.82s)]
*  What happened? [[00:27:08](https://www.youtube.com/watch?v=dp5eez84R-g&t=1628.22s)]
*  Why wasn't it foreseen a little earlier? [[00:27:10](https://www.youtube.com/watch?v=dp5eez84R-g&t=1630.14s)]
*  Well, it was foreseen by some, as you said, kind of a marginal group. [[00:27:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=1632.98s)]
*  So there's the fact that most of us in AI research did not expect that we would get [[00:27:18](https://www.youtube.com/watch?v=dp5eez84R-g&t=1638.7s)]
*  to the level of competence that we seem to see in the chat GPT and GPT-4. [[00:27:27](https://www.youtube.com/watch?v=dp5eez84R-g&t=1647.18s)]
*  We expected something like this, that level to come maybe in 10 or 20 years. [[00:27:34](https://www.youtube.com/watch?v=dp5eez84R-g&t=1654.18s)]
*  And the human level intelligence to come maybe in 50 years. [[00:27:39](https://www.youtube.com/watch?v=dp5eez84R-g&t=1659.74s)]
*  I mean, our horizon for risk just got much shorter. [[00:27:42](https://www.youtube.com/watch?v=dp5eez84R-g&t=1662.46s)]
*  If you're working on a topic, it's more psychologically comfortable to think that this is good for [[00:27:48](https://www.youtube.com/watch?v=dp5eez84R-g&t=1668.3s)]
*  humanity than to think, oh, gee, this could be really destructive. [[00:27:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=1675.42s)]
*  And we have these natural defenses as part of the problem with humans. [[00:27:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=1679.98s)]
*  We're not always rational. [[00:28:04](https://www.youtube.com/watch?v=dp5eez84R-g&t=1684.5s)]
*  Is there a possibility that AI leads to an even greater disparity, social disparity, [[00:28:06](https://www.youtube.com/watch?v=dp5eez84R-g&t=1686.06s)]
*  income disparity? [[00:28:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=1692.82s)]
*  What prevents a scenario where the benefits of AI are concentrated among a very small [[00:28:13](https://www.youtube.com/watch?v=dp5eez84R-g&t=1693.82s)]
*  slice of the population and vast numbers of people are experienced dislocation, unemployment [[00:28:18](https://www.youtube.com/watch?v=dp5eez84R-g&t=1698.94s)]
*  and actually get poorer? [[00:28:25](https://www.youtube.com/watch?v=dp5eez84R-g&t=1705.74s)]
*  In general, if you think about what AI is, it's just a very powerful tool. [[00:28:27](https://www.youtube.com/watch?v=dp5eez84R-g&t=1707.46s)]
*  If you just think about having very powerful tools, it can clearly be used by people who [[00:28:31](https://www.youtube.com/watch?v=dp5eez84R-g&t=1711.62s)]
*  have power to gain even more power. [[00:28:36](https://www.youtube.com/watch?v=dp5eez84R-g&t=1716.1399999999999s)]
*  What prevents that tends to be governments, you know, taxation, for example, and services [[00:28:39](https://www.youtube.com/watch?v=dp5eez84R-g&t=1719.1399999999999s)]
*  offered by governments to everyone and so on. [[00:28:46](https://www.youtube.com/watch?v=dp5eez84R-g&t=1726.6999999999998s)]
*  So as to balance things out. [[00:28:49](https://www.youtube.com/watch?v=dp5eez84R-g&t=1729.6599999999999s)]
*  Are you concerned that the warnings coming from Jeff Hinton, from Steve Wozniak come [[00:28:52](https://www.youtube.com/watch?v=dp5eez84R-g&t=1732.7399999999998s)]
*  across to some people as the warnings of an old guard complaining about a new generation [[00:29:00](https://www.youtube.com/watch?v=dp5eez84R-g&t=1740.86s)]
*  of scientists? [[00:29:06](https://www.youtube.com/watch?v=dp5eez84R-g&t=1746.86s)]
*  No, I mean, my students are concerned. [[00:29:07](https://www.youtube.com/watch?v=dp5eez84R-g&t=1747.86s)]
*  And there are young people who are concerned. [[00:29:12](https://www.youtube.com/watch?v=dp5eez84R-g&t=1752.3799999999999s)]
*  I think that the battle that is shaping up in a way has a lot of points in common with [[00:29:14](https://www.youtube.com/watch?v=dp5eez84R-g&t=1754.9399999999998s)]
*  concerns and the requirement for policies about climate change. [[00:29:24](https://www.youtube.com/watch?v=dp5eez84R-g&t=1764.94s)]
*  And a lot of young people are fighting to preserve the interests of future generations. [[00:29:33](https://www.youtube.com/watch?v=dp5eez84R-g&t=1773.18s)]
*  I think something similar is at stake with AI. [[00:29:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=1780.5400000000002s)]
*  One of the confounding things about confronting the climate emergency is the requirement for [[00:29:45](https://www.youtube.com/watch?v=dp5eez84R-g&t=1785.26s)]
*  coordinated international effort. [[00:29:51](https://www.youtube.com/watch?v=dp5eez84R-g&t=1791.94s)]
*  With AI, you not only have that, but you also have, I think it's fair to say, a level of [[00:29:57](https://www.youtube.com/watch?v=dp5eez84R-g&t=1797.54s)]
*  understanding of the basics of AI that's very low. [[00:30:03](https://www.youtube.com/watch?v=dp5eez84R-g&t=1803.14s)]
*  In other words, people can understand dried up rivers, raising temperatures, rising sea [[00:30:08](https://www.youtube.com/watch?v=dp5eez84R-g&t=1808.46s)]
*  levels and all the rest. [[00:30:15](https://www.youtube.com/watch?v=dp5eez84R-g&t=1815.3400000000001s)]
*  The complications of AI and predicting those complications are even more complex, don't [[00:30:17](https://www.youtube.com/watch?v=dp5eez84R-g&t=1817.1s)]
*  you think? [[00:30:23](https://www.youtube.com/watch?v=dp5eez84R-g&t=1823.78s)]
*  So I think what may bring countries to this international table that is needed indeed [[00:30:24](https://www.youtube.com/watch?v=dp5eez84R-g&t=1824.78s)]
*  is their self-interest in avoiding catastrophic outcomes where everyone loses. [[00:30:33](https://www.youtube.com/watch?v=dp5eez84R-g&t=1833.54s)]
*  So a good analogy is what happened after the Second World War between mostly the US [[00:30:40](https://www.youtube.com/watch?v=dp5eez84R-g&t=1840.7s)]
*  and the USSR and then to some extent China to come up with agreements to reduce the risks [[00:30:47](https://www.youtube.com/watch?v=dp5eez84R-g&t=1847.18s)]
*  of nuclear armageddon. [[00:30:54](https://www.youtube.com/watch?v=dp5eez84R-g&t=1854.02s)]
*  It's I think in good part thanks to these international agreements that it has been [[00:30:55](https://www.youtube.com/watch?v=dp5eez84R-g&t=1855.78s)]
*  okay. [[00:31:02](https://www.youtube.com/watch?v=dp5eez84R-g&t=1862.42s)]
*  So the comparison is to arms control, nuclear arms control? [[00:31:03](https://www.youtube.com/watch?v=dp5eez84R-g&t=1863.42s)]
*  Yes. [[00:31:07](https://www.youtube.com/watch?v=dp5eez84R-g&t=1867.9s)]
*  It's not exactly the same thing, but I think it's a good model. [[00:31:09](https://www.youtube.com/watch?v=dp5eez84R-g&t=1869.5s)]
*  Mr. Benjio, thank you so much. [[00:31:14](https://www.youtube.com/watch?v=dp5eez84R-g&t=1874.7s)]
*  I appreciate your time. [[00:31:15](https://www.youtube.com/watch?v=dp5eez84R-g&t=1875.98s)]
*  My pleasure. [[00:31:16](https://www.youtube.com/watch?v=dp5eez84R-g&t=1876.98s)]
*  Thanks for having me. [[00:31:17](https://www.youtube.com/watch?v=dp5eez84R-g&t=1877.98s)]
*  Yashua Benjio is the Scientific Director of the Montreal Institute for Learning Algorithms. [[00:31:18](https://www.youtube.com/watch?v=dp5eez84R-g&t=1878.98s)]
*  I'm David Remnick and that's the New Yorker Radio Hour for today. [[00:31:37](https://www.youtube.com/watch?v=dp5eez84R-g&t=1897.86s)]
*  Thanks for listening. [[00:31:41](https://www.youtube.com/watch?v=dp5eez84R-g&t=1901.22s)]
*  I hope you'll join us next time. [[00:31:42](https://www.youtube.com/watch?v=dp5eez84R-g&t=1902.22s)]
*  The New Yorker Radio Hour is a co-production of WNYC Studios and The New Yorker. [[00:31:59](https://www.youtube.com/watch?v=dp5eez84R-g&t=1919.42s)]
*  Our theme music was composed and performed by Meryl Garbes of Tune Yards with additional [[00:32:04](https://www.youtube.com/watch?v=dp5eez84R-g&t=1924.42s)]
*  music by Louis Mitchell. [[00:32:08](https://www.youtube.com/watch?v=dp5eez84R-g&t=1928.8600000000001s)]
*  This episode was produced by Max Balton, Brita Green, Adam Howard, Kalaliya, Avery Keatley, [[00:32:10](https://www.youtube.com/watch?v=dp5eez84R-g&t=1930.94s)]
*  David Krasnow, Jeffrey Masters, Louis Mitchell, and Gofen and Putubuele with guidance from [[00:32:17](https://www.youtube.com/watch?v=dp5eez84R-g&t=1937.14s)]
*  Emily Boutin and assistance from Harrison Kiepline, Michael May, David Gabel, and Alejandro [[00:32:23](https://www.youtube.com/watch?v=dp5eez84R-g&t=1943.02s)]
*  Decke. [[00:32:28](https://www.youtube.com/watch?v=dp5eez84R-g&t=1948.8600000000001s)]
*  The New Yorker Radio Hour is supported in part by the Chirina Endowment Fund. [[00:32:29](https://www.youtube.com/watch?v=dp5eez84R-g&t=1949.86s)]
