---
Date Generated: December 06, 2024
Transcription Model: whisper medium 20231117
Length: 7300s
Video Keywords: ['Joe Rogan Experience', 'JRE', 'Joe', 'Rogan', 'podcast', 'MMA', 'comedy', 'stand', 'up', 'funny', 'Freak', 'Party']
Video Views: 881825
Video Rating: None
Video Description: Jonathan Haidt is a social psychologist, professor, and author. His latest book, "The Anxious Generation: How the Great Rewiring of Childhood Is Causing an Epidemic of Mental Illness," will be available March 26.

www.jonathanhaidt.com
---

# Joe Rogan Experience #2121 - Jonathan Haidt
**Joe Rogan Experience:** [March 19, 2024](https://www.youtube.com/watch?v=jOC-RyoBcbQ)
*  The Joe Rogan Experience.
*  Good to see you sir.
*  Good to see you again, Joe.
*  The same problems that you talked about when you were here last that I've referenced many
*  times since on the podcast have only exacerbated, unfortunately.
*  And that's why you wrote this, The Anxious Generation.
*  And it could not be more true how the great rewiring of childhood is causing an epidemic
*  of mental illness.
*  I don't think anybody can dispute that.
*  Yeah, when I was on last time, there was a dispute.
*  There were some psychologists who said, oh, this is just a moral panic.
*  They said this about video games and comic books and you know, no, I think, you know,
*  this is not a real thing, they said.
*  Now they don't.
*  Yeah, I think it was pretty obvious.
*  I think it was only their preconceived notions that were keeping them from admitting it before
*  or at least looking at it before.
*  Or maybe they don't have children.
*  You know, could be that.
*  I think a lot of older people, particularly boomers, they're a little bit disconnected
*  from it because they're not, unless they're addicted to Twitter, you know, they're not
*  engaging in this stuff.
*  And they're often thinking, you know, when I was a kid, we watched too much TV and we
*  turned out okay.
*  Yeah.
*  But part of the message of the book is that social media and the things kids are doing
*  on screens are not really like TV.
*  They're much, much worse for development.
*  Yeah.
*  And even watching too much TV, I don't agree that they turned out okay.
*  I think it had a pervasive effect.
*  It did.
*  But nothing like this.
*  Yeah.
*  Well, that's right.
*  Because, you know, when we were watching TV, I'm a little older than you, I was born in
*  1963.
*  So I grew up watching a lot of TV, you know, maybe, you know, an hour or two a day, week
*  days and then two or three hours on the weekends.
*  But it was a bigger screen.
*  You're watching with your sisters or with your friends.
*  You're arguing about things.
*  You're eating.
*  So it's actually pretty social.
*  But now kids are spending the latest survey, Gallup finds that it's about what's five hours
*  a day just on social media, just social media, including TikTok and Instagram.
*  And when you add in all the other screen based stuff, it's like nine hours a day.
*  And that's not social.
*  It's private on your little screen.
*  You're not communicating with others.
*  So, you know, in all these ways, the new way that kids are digital is really not like what
*  we had when we were when we were on watching TV.
*  It's also an extraordinary amount of wasted resources.
*  I'm always embarrassed when I look at my phone, when I see my screen time, like four hours.
*  That's four hours I could have done so many different things with.
*  That's right.
*  And so that's the concept of opportunity cost is this great term that economists have, which
*  you buy something, if you invest an hour of your time and a hundred dollars to do something,
*  how much does it cost?
*  Well, you know, a hundred dollars.
*  But you could use that hundred dollars in that hour for something else.
*  So what are the things you gave up?
*  And when screen time goes up to now, it's about nine hours a day in the United States,
*  nine hours a day, not counting average, average, average.
*  Is that for a certain age group?
*  Teenagers, not little kids.
*  But you know, you know, 13 to 15, 17, that range, that's when it's heaviest.
*  It's around nine hours a day.
*  And so the opportunity cost is everything else.
*  Like imagine if somebody said to you, Joe, you know, you've got a full life here.
*  You have to do this thing, this additional thing for nine hours.
*  Like that's insane.
*  That would push out everything else, including sleep.
*  Yeah.
*  So when you are now talking to people that agree that this is an issue, what changed?
*  So you mean what changed?
*  Like why is there now more agreement?
*  Yes.
*  Yeah.
*  So in 2019, when I was last here with you, my book, The Coddling of the American Mind,
*  had just come out.
*  And back then, people were beginning to sense that, you know, this internet, the phones,
*  that we are all so amazed by.
*  You know, there was a very positive feeling about all this stuff in the early part, you
*  know, like in the 2000s.
*  It was beginning, sentiment was beginning to turn.
*  But there was a big academic debate because when you look at studies that look at how,
*  you know, do kids who spend a lot of time on screens, do they come out more depressed?
*  The answer is yes, but the correlation is not very big.
*  So there was a big argument among researchers.
*  And that's when I got into this around 2019, really getting into that debate.
*  And I think that Gene Twenge and I really had had good data showing, you know, there
*  is an issue here.
*  And then COVID came.
*  And that confused everything.
*  Because you know, basically, when I was on with you last time, 2019, I was saying, you
*  know, what kids most need is less time on their devices and more time outside playing
*  unsupervised.
*  Let them be out unsupervised.
*  That's what we need in 2019.
*  COVID comes in, boom, exactly the opposite.
*  What do kids get?
*  No more time unsupervised.
*  You can't even go out.
*  I mean, in New York City, they locked up the playgrounds.
*  They locked up the tennis courts.
*  It was insane.
*  No time outside with your friends.
*  Oh, spend your whole day on screens.
*  So that made everything worse.
*  But people thought, oh, yeah, the kids are really messed up now from COVID.
*  But they were wrong.
*  COVID was terrible for a lot of kids.
*  When you look at the mental health trends over the last 20 years, COVID was a blip.
*  COVID actually, you know, I've actually got some I've got some chart, you know, if you
*  don't mind, I'd like to actually show these because, you know,
*  Did you send the data to Jamie so he could pull it up?
*  I haven't sent it yet, but I'll, oh, right, because you want, yeah.
*  Do you want to stop and do that?
*  Yeah, let's pause real quick.
*  So you can give out, Jamie will give you the email address.
*  OK, we're back.
*  All right.
*  What are those things?
*  Oh, so these these are stickers for your kids.
*  So as part of the book, I'm trying to launch a movement called Free the Anxious Generation.
*  Here you go. You have two younger kids.
*  And so I've teamed up with the artist who did the book cover, Dave Cicerelli,
*  who's created these incredible artworks.
*  There's going to be billboards that he's putting together a 12 foot tall milk
*  carton, which is going to be traveling around different cities with this.
*  Missing childhood.
*  Do they do that anymore?
*  No, I don't think so.
*  Yeah. So I don't know if you're I don't know what your kids think about social media
*  and whether they think it's a good thing or a bad thing.
*  But we are hopeful that members of Gen Z are going to start and they are starting
*  to advocate that, you know what, this is messing us up.
*  OK, so here's the graph.
*  OK, so this is the graph that I showed last time I was I was on.
*  And what it shows, because I know most of your listeners are probably just listening to the audio.
*  It shows that from 2005 to 2010,
*  the rates of depression in girls was about 12 percent of American girls
*  had a major depressive episode in the last year.
*  And for boys was about four to five percent.
*  And it's flat. There's no change.
*  And then all of a sudden around 2011, 2012, 2013, the number 2012, 2013,
*  the numbers start rising, especially for girls.
*  And it goes all the way up to 20 percent for girls.
*  So that was a huge rise.
*  And that's what I showed you last time.
*  What is the difference between boys and girls?
*  So girls suffer from more internalizing disorders.
*  That is, when girls have difficulties, they turn it inwards.
*  They make themselves miserable.
*  So girls suffer from higher rates of anxiety and depression.
*  That's always been the case, especially once they hit puberty.
*  Boys, when they have psychological problems, they tend to turn it outwards.
*  They engage in more violent behavior, deviant behavior, substance use.
*  So boys, it's called externalizing disorders.
*  But, you know, you can see both boys and girls are getting more depressed.
*  It's just that the effect is bigger for girls.
*  So boys have gone up to about seven percent and girls are way up to 20.
*  That's right. And that was 2019.
*  So one out of five girls.
*  That's what it was. That's right.
*  And then it was. That's right.
*  And then Covid comes in.
*  So we can have the next slide.
*  So then Covid comes in.
*  And now this is this is the exact same data set.
*  Just this federal data.
*  Just got a few extra years of data.
*  And what you can see is that is that it goes way the hell up.
*  And if you look at the 2021 data point, you can see that little peak at the very top there.
*  That's because of Covid.
*  That is Covid was Covid did increase things.
*  It did make kids more depressed.
*  But as you can see, it's a blip.
*  Covid was just a tiny effect compared to this gigantic increase.
*  And so, you know, on the last slide, it was 20 percent of girls.
*  Now it's almost 30, almost 30 percent of girls who had a major
*  depressive episode in the last year.
*  And for boys, it's up to 12 percent, which is still quite a lot.
*  It's more than a doubling, although much less than for the girls.
*  It's still even if you look at boys or, excuse me, if you look at girls from 2018
*  pre-Covid, that ramp is very steep.
*  The upward ramp.
*  That's right. And that might be TikTok.
*  That is the you know, what.
*  So what happens is a lot of things change around 2011, 2012.
*  2010 is when you get the front facing iPhone.
*  It's when Instagram is founded.
*  It's when kids around when kids are getting high speed data plans.
*  So my argument in the book is that we had a complete rewiring of childhood
*  between 2010 and 2015.
*  In 2010, most of the kids had flip phones.
*  They didn't have Instagram.
*  They didn't have high speed data.
*  So they would use their flip phones to get together with each other.
*  They communicate with each other.
*  By 2015, about 80 percent, 70, 80 percent have a smartphone.
*  Most of them have high speed data, unlimited plan, Instagram accounts.
*  And this really messes up the girls.
*  So that's what I think happened between 2010 and 2015.
*  TikTok becomes popular only really more 20, you know, 18, 19, 20.
*  And it's so new, we don't have good data on just TikTok.
*  But I suspect that that sort of extra acceleration might be due to TikTok.
*  What specifically about TikTok?
*  So this is something I'm just really beginning to learn.
*  I don't even have much on it in the book.
*  Watching so kids love stories and stories are great.
*  All around the world, people tell children stories.
*  There are myths.
*  You know, we see plays, we see television shows.
*  And so just and so I asked my my undergrads at NYU, I said,
*  how many of you use Netflix?
*  Almost everybody says yes.
*  How many of you wish Netflix was never invented?
*  Nobody, nobody.
*  Watching stories is not a bad thing.
*  TikTok is not stories.
*  It's little tiny, tiny bits of something.
*  And it they're they're short.
*  They don't add up to anything. They're incoherent.
*  They're often disturbing and disgusting.
*  I mean, people, you know, people being hit by cars,
*  people being punched in the face.
*  And it's much more addictive and with no nutritive value.
*  They're not really stories.
*  And so it seems to be much more addictive.
*  Kids really get hooked on it much more so than Netflix or anything else.
*  And I and depends on what you're watching.
*  But I suspect that so many of them are consuming stuff about mental illness.
*  It has a variety of effects that we're not even
*  we don't even understand yet.
*  Now, I know that there's some push right now currently to ban TikTok.
*  And there's a lot of people that are very torn on this
*  because they don't want to give the government the ability to ban social media.
*  What is the argument about banning TikTok?
*  What specifically are they talking about?
*  They want to do
*  separate them from the company,
*  bite dance that owns them and just make them an American company.
*  Yeah, they can still operate, I suppose.
*  So it's a data issue.
*  Well, it's a national security issue.
*  So, yeah, right.
*  So thank you.
*  Let's let's separate the national security issue from the mental health issue.
*  OK, I have a lot of libertarian friends.
*  I have a lot of libertarian sympathies.
*  I would be uncomfortable about the government banning
*  a company or a product because it's harmful to children.
*  I personally think we should just have age verification.
*  We should not have kids on certain things.
*  But if we just if it was just a question of, you know,
*  this is really bad for children, let's ban it.
*  Like, no, I don't think I would support that.
*  But TikTok is different because it is a Chinese owned company.
*  And as many of your listeners will know, China, it says in whatever,
*  not it doesn't have a constitution, I don't think.
*  But by law, every Chinese company
*  must do what the Chinese Communist Party tells it to do.
*  And that's what's so scary that this is this is, you know,
*  Instagram reels and YouTube shorts.
*  They might have similar effects to TikTok,
*  but the Chinese government can literally tell ByteDance
*  to change the change what kids are seeing.
*  And they do that in China.
*  They tell them in China, you have to have this kind of content
*  and not that kind of content.
*  There was an incredible episode of you had Tristan Harris on.
*  Tristan Harris has this amazing podcast episode where they go
*  into the national security risks and they show that the day
*  that Russia invaded Ukraine,
*  TikTok and Russia changed radically, like the government was on,
*  like, you know, TikTok was on it, like, yep, we're going to do what,
*  you know, what Putin wants us to do.
*  Or, you know, so so the idea that the most influential,
*  the most influential platform on American children,
*  the idea that that must do what the Communist Party tells it to do
*  at a time when we have mounting tension with China and the possibility of a war.
*  I mean, as Tristan says, imagine if in the 1960s,
*  the Soviet Union owned and controlled, you know, PBS, ABC, NBC,
*  and all the kids programs, you know, we would never have allowed that.
*  So I hope listeners this I really strongly support this this bill.
*  I think Rep. Mike Gallagher, I think, was one of the ones proposing it
*  or at least certainly advocating for for this for this issue.
*  I hope people will not see it as a TikTok ban,
*  but they'll see it as an urgent national security move to force
*  forced by chance to sell to a non Chinese owner.
*  And specifically, what are they pointing to when they say national security risk?
*  What specifically have they seen?
*  So a lot of it seems to have to do with the data question.
*  Like all the, you know, Facebook pioneered this model
*  in which the person using the product is not really the customer.
*  They don't pay the money there.
*  You know, they're the product.
*  The the the user is the product, not the customer.
*  And they give them data and the data can be used for all sorts of purposes,
*  especially marketing and advertising.
*  And so TikTok has enormous amounts of data
*  and they can get all psychological on it because they know exactly
*  how long you hesitated, how much you like certain kinds of videos.
*  You know, many people have written articles on how TikTok seems to have known
*  they were gay before they did that sort of thing.
*  So TikTok has extraordinary amounts of data on most American,
*  most Americans, certainly most young Americans.
*  And they say, oh, but, you know, we don't share it like it's in a server over here
*  in Singapore or I don't know where, but it's, you know, it's not in China.
*  You know, oh, come on, come on.
*  You know, there's no way it could possibly be the case
*  that the data is really separated and not available to the Chinese Communist Party.
*  And what are they pointing to in terms of the danger of this data
*  that makes them want to have it sold to an American company?
*  I don't know whether the motivation behind the bill.
*  I don't know whether it's that the Chinese would have some access to data
*  on American citizens or whether what most alarmed me when I when I heard
*  the Tristan Harris podcast was the ease of influencing
*  American kids to to be pro this or pro that on any political issue.
*  Well, you're seeing that with Palestine and Gaza.
*  Yeah, I think so.
*  Yeah, you're definitely seeing that now.
*  It's it's very it's very obvious.
*  Well, it's very obvious with many things with TikTok,
*  trans stuff, and there's there's a lot of different things that they're encouraging.
*  And, you know, people that are opposed to that are being banned,
*  which is also very odd.
*  And specifically like female athletes, we had Riley Gaines,
*  who was the female athlete that competed against Leah Thomas.
*  And she has said that male biologically male athletes
*  should not be able to compete with biologically female athletes
*  because they have a significant advantage.
*  And she was banned from TikTok just for saying that.
*  Yeah, that's right.
*  So this relates to the larger issue that we talked about last time
*  and that I hope we'll continue to talk about today,
*  which is that we've social media has brought us into an environment
*  in which anyone has the ability to really harm anyone else.
*  There's an extraordinary amount of intimidation available via social media.
*  And so this has led the leaders of all kinds of organizations
*  to run scared.
*  Greg and I, Greg Lukianoff, and I saw this in universities.
*  Why don't the university president stand up to the protesters
*  who are shouting down visiting speakers?
*  Why isn't there a grownup in the room?
*  And then we saw it in journalism, newspapers and editors
*  who wouldn't stand up for journalistic principles.
*  And so I think what has happened here is that social media
*  allows whoever is angriest and can mobilize most force
*  to threaten, to harass, to surround, to mob anyone.
*  And when people are afraid to say something,
*  that's when you get the crazy distortions that we saw on campus
*  or that or that Riley Gaines was seeing, too,
*  just that people are afraid to speak up.
*  And in a in a democracy, in a large, secular, diverse democracy,
*  we have to be able to talk about things.
*  And so that's part of why we're in such a mess now is I've argued
*  that it's when social media became super viral after 2009, 2010.
*  You get the like button, the retweet button.
*  Social media wasn't really bad or harmful before.
*  That wasn't terribly harmful before then.
*  But by 2012, 2013, it had really become as though everyone had a dart gun.
*  Everybody could shoot everyone.
*  And that's when we began sort of like teaching on eggshells in universities
*  because our students could really do a lot of damage
*  if we said one word they didn't like.
*  And it's not just the students, which is really disturbing.
*  We've talked about this before.
*  There was an FBI security specialist who estimated that somewhere
*  in the neighborhood of 80 percent of the Twitter accounts were bots.
*  Yeah. Which is very strange, because that means that they're
*  they're mobilizing specifically to try to push different narratives.
*  Yeah, that's right.
*  So if you think of, you know, people say, well, you know, now Twitter
*  is the public square or things like that.
*  You know, it's not it's not a public square.
*  It's it's more like the Roman Coliseum.
*  It's more like, you know, a place where people say things and
*  the fans are in the stands are hoping to see blood
*  to move our discussions onto platforms like that.
*  That can be manipulated.
*  That can that anyone doesn't have to be a foreign intelligence service.
*  It could be anybody who wants to influence anything in this country
*  or anywhere in the world.
*  They can, you know, for very little money, they can hire someone
*  to create thousands, millions of bots.
*  And so we're living in this sort of funhouse world where everything
*  is weird mirrors and it's very hard to figure out what the hell is going on.
*  Have you ever sat down and tried to figure out a solution to this
*  other than trying to encourage people not to use?
*  Jimmy, does something happen? The volume just dropped lower.
*  OK, so what was I just saying?
*  We're talking about solutions other than asking kids to not use it,
*  which is very hard to do. Yeah, that's right.
*  So when we're talking about the democracy problems and the,
*  you know, manipulation of politics or anything else, those are really, really hard.
*  I have a few ideas of what would help.
*  And we're not going to do them because, you know, all of them are like the left
*  legs and the right doesn't or vice versa.
*  But what are those ideas?
*  Oh, it's things like, you know, like identity authentication.
*  If if large platforms had something like, know your customer laws,
*  that is, you know, if you want to open an account on Facebook or on on X,
*  you have to at least prove that you're a person.
*  And I think you should be able to have to prove that you're
*  a person in a particular country.
*  I think you should over a certain age.
*  You prove those to the to the platform, not directly.
*  You go through a third party.
*  So even if it's hacked, they wouldn't know anything about about you.
*  Just you establish that you're a real person and then you're cleared.
*  Go ahead. You open your account.
*  You can post without you don't use your real name.
*  If we did that, that would eliminate most of the bots.
*  That would make it much harder to influence.
*  That would make us have much better platforms for democracy.
*  Is that possible to do internationally?
*  Well, the platforms can certainly require whatever they want for membership.
*  Right now, they are legally required to ask you if you're over 13.
*  If you're 13 or over, they ask it and then they accept whatever you say.
*  And that's it. You're in.
*  So those those rules could be changed and they could be required to to do more.
*  And, you know, they're based in, you know, in the United
*  most in the United States, but their users are all around the world.
*  So, yeah, that could be done.
*  So one of the things that people are nervous about when it comes to
*  authentic authentication, authentication, is that if you could do that,
*  then you could target individuals that wouldn't be allowed to be anonymous.
*  So you eliminate the possibility of whistleblowers.
*  No, no, no, that's no. The point is that
*  the point is that you just have to establish that you are a person.
*  It doesn't mean that you have to post under your real name. Right.
*  And, you know, even if you want ultra high security, you could just have,
*  you know, dissidents in repressive countries.
*  They could just communicate by secure channels with a journalist who posts for them.
*  So I understand the concern.
*  And there are values to having anonymity.
*  But I think what we're seeing now is that the craziness, the way it's affecting
*  it's, you know, it's it's making it harder for democracies
*  to be good, vibrant democracies.
*  And it's making it easier for authoritarian countries like China
*  to be powerful and effective authoritarian countries.
*  So I think we have to start weighing the pluses and minuses,
*  the costs and benefits here.
*  Right. But how would you ramp that up?
*  Like, how would you implement that internationally?
*  Like, say, if you're talking about people in Poland, just pick a country.
*  Yeah. Well, the the platforms can do whatever they want.
*  But then, yes, how would if a company starts in Poland,
*  then the US Congress would have no influence on that.
*  Right. Like China could pretend that they could falsify
*  the data that shows that these are individuals.
*  Oh, I see. They wanted to empower a troll farm.
*  Oh, I see. You're saying even if American companies did this,
*  the Chinese could still get around. Yeah, that's true.
*  They you're never going to have a perfect system.
*  But right now, it's just so easy and cheap and free
*  to have massive influence on anything you want.
*  So, you know, but the larger question here was you asked me like,
*  what can we do?
*  And what I'm saying is, you know, there are some things like identity
*  authentication that I think would help.
*  But yes, there are implementation problems.
*  There's all kinds of political questions.
*  So my basic point is, man, those problems, I don't I don't know
*  that we can solve, but we can do better.
*  Oh, and I should point out a lot of these have to do with the basic
*  architecture of the web.
*  When we move from Web 1, which was put up information, it's amazing.
*  You can see things from everywhere to Web 2, which was directly interactive.
*  Now you can you can buy things, you can post stuff.
*  And it's the Web 2 that gave us these business models that are about
*  that have led to the exploitation of children and everyone else.
*  And I'm part of a group, Project Liberty, if you go to Project Liberty dot
*  IO, that's trying to have a better Web 3 where people will own their own
*  data more clearly, you know, as the architecture changes, it opens us up
*  to new possibilities and risks.
*  So there are some hopes for a better internet coming down the pike.
*  But I wanted actually I just wanted to like put all this stuff out there
*  about democracy to say this is really hard.
*  But when we talk about kids and mental health, this is actually
*  amazingly doable.
*  Like we could do this in a year or two.
*  And the trick, the key to solving this whole problem with kids is to understand
*  what's called a collective action problem.
*  So collective, there are certain things where, you know, like if you have a
*  bunch of fishermen and they realized, oh, we're overfishing, we're overfishing
*  the lake, let's reduce our catch.
*  And if one person does that, no one else does.
*  Well, then he just loses money.
*  But if everyone does it, well, then actually can solve the problem and
*  everyone can do fine with social media.
*  What we see over and over again is kids are on it because everyone else is.
*  And parents are giving their kids a phone in sixth grade because the kids
*  says everyone else has one and I'm left out and over and over again, you see
*  this when you ask kids, you know, how, how would you feel if I took your, how
*  would you feel if I took your Instagram or tick tock away?
*  You're like, oh, I'd hate that.
*  I hate that.
*  But then you say, well, what if it was taken away from everyone?
*  What if no one had it?
*  And they almost always say that would be great.
*  I did this.
*  There's an academic article that showed this with college students.
*  I did, I did it as a test with my students at NYU and a review of the book of the
*  anxious generation in the Times of London and the UK Times, the woman ended by
*  asking her 16 year old, would you have liked there to be a social media ban
*  until you were 16?
*  Or I think the daughter was like 18 at the time.
*  This was last month.
*  Um, and the daughter says, would everyone else be off it too?
*  And she says, yes.
*  And then the daughter says, yeah, I would have rather liked that.
*  And so you have this consumer product that the people using it don't, they
*  don't see value in it.
*  They're using it because everyone else is.
*  Um, and there's evidence suggesting it's messing up their mental health.
*  So anyway, this is a solvable problem if we act together and that's what
*  the book is about.
*  How would you do that though?
*  How would you, would you get all the parents to do it?
*  Would you get the social media companies to do it?
*  Like, how would you do that?
*  Yeah, I'm not counting on the social media companies or Congress.
*  I'm assuming we'll never get help from either one.
*  Now I hope I'm wrong about Congress.
*  Um, but as a social psychologist, I'm trying to point out, you know, we can
*  actually solve this ourselves.
*  And so let's work, the simplest one is, is this.
*  So I propose four norms.
*  If we can enact these four norms ourselves as parents and working with
*  schools, we can largely solve the problem.
*  We can reduce, we can certainly reduce rates of mental illness a lot.
*  The first norm is the simplest, no smartphone before high school.
*  Um, now people say, oh my God, but my kid needs a phone.
*  Sure.
*  Give them a flip phone.
*  The millennials had flip phones and they were fine.
*  Flip phones did not harm millennials, mental health.
*  They're on, they're good for communication.
*  You text, you call.
*  That's it.
*  So the first rule is no smartphones before high school.
*  And as long as a third of the parents do this, well, then the rest of the parents
*  are free to say when their kid says, mom, you know, I need a smartphone.
*  You know, some other kids have one.
*  Then you can say, well, no, you'll here's a flip phone.
*  You'll be with the kids who, who don't have one.
*  Oh, and by the way, you're also going to get a lot more freedom to
*  hang out with the other kids.
*  So, um, we don't need everybody, but we need to break the feeling that everyone
*  has to have one because everyone else has one.
*  Yeah.
*  That sounds great on paper.
*  I just, I can't imagine that most parents would agree to it because of the most
*  pair, there's just so many parents that don't pay attention.
*  That's true.
*  Especially to two families where two people are working.
*  Yeah.
*  No, you're right.
*  You're right.
*  When, just when we look right now, um, it's, you know, kids with married parents
*  are, are trying harder to keep the kids off.
*  These things are good babysitting device in the sense that the kids are off doing
*  their thing, you don't have to think about them.
*  Um, so it is true that, that this would not be adopted universally at first.
*  Um, but I think we could still develop a norm that it's just not appropriate
*  children to have a smartphone.
*  They should have flip phones.
*  And I think that any community that wants to do this, because what I find over and
*  over again is that most parents are really concerned about this.
*  And this, this is across social classes.
*  Most parents are seeing the problems.
*  And so I don't have to convince parents to change their minds about something.
*  What I'm trying to do with the book is show them here are four norms that are
*  pretty easy to do if every, if others are doing them and these are going to make
*  your kids happier, less mentally ill.
*  Yeah, it's like I said, it sounds like a good suggestion.
*  I just don't imagine that with the momentum that social media has today and
*  the ubiquitous use that kids are going to give it up, they're not going to want to
*  give it up.
*  I think there's a lot of kids that have had problems that if you talk to them
*  alone and you say, wouldn't it be better if social media didn't exist, if they've
*  been bullied or what have you, they'd say yes.
*  Yeah.
*  But the idea of getting a massive group of people to adopt this is highly unlikely.
*  Well, you know, you may be right, but I'm encouraged because whenever I speak to
*  Gen Z audiences and you know, I've spoken to middle schools, high schools, college
*  audiences, I always ask, you know, do you think I got this wrong or do you think
*  this is a correct description of what's happening?
*  They agree.
*  They, I've never, they're not in denial.
*  They see the phones are messing them up.
*  They see that social media is messing up the girls, especially.
*  So, you know, even in middle school, certainly high school, they, the kids
*  actually agree that this is a problem.
*  Um, and so if it was offered to them, you know what, let's, let's do the other
*  three norms, let's get them all off for all the time.
*  All right.
*  So the first is no smartphone before high school.
*  Second is no social media till 16.
*  That one's going to be a little harder to do.
*  Um, but, um, you know, the big platforms like Instagram, the plant where you're
*  posting and the whole world is seeing and strangers are contacting you, you know, I
*  think the age is currently 13 and it's not enforced.
*  I think that needs to go up to 16.
*  Um, here it would be nice if Congress would raise the age to 16 and make the
*  companies enforce it, but even if they don't parents, if, as long as many other
*  parents are doing it, me, I, as a parent, you know, Mike, my, my kids are 14 and 17.
*  Um, as long as many other parents are saying 16 is the age, then it's very easy
*  for me to say that also that's the second.
*  Yeah.
*  If you, again, if you could get them to say it, and I think the kids would push
*  back so hard because so many other kids are on it and that's how they interact
*  with each other.
*  You're just reiterating the social, the collective action problem.
*  You're just saying they react because all the other kids are on it.
*  Yes.
*  So it does require a big push, but I think we're ready.
*  I don't think we were ready in 2019.
*  It wasn't as clear.
*  Uh, but now that we're through COVID, now that the numbers are through the roof,
*  um, I think, I think we're ready.
*  And if it starts in some places, not others, that's okay with me.
*  That's the way it's going to be.
*  And then we'll see whether it spreads.
*  And then we'll see the data.
*  Yeah.
*  Cause look at smoking, you know, smoking is highly addictive.
*  It was very common, uh, up through the 1990s.
*  And now it's very rare in high school, very few high school kids smoke.
*  So it's possible to change norms.
*  And what was the third?
*  The third is phone free schools.
*  And this one is happening.
*  This is already happening.
*  Um, so I've published articles in the Atlantic and on my, on my sub stack,
*  after babble.com, um, bringing together the research when kids have a phone in
*  their pocket in school, they're going to be texting because if anyone is texting
*  during the day, during the school day, they all have to check cause they don't
*  want to be out of the loop.
*  They don't want to be the one who doesn't know.
*  So, um, when kids started bringing smartphones into school instead of flip
*  phones, um, academic achievement actually went down.
*  Kids are stupider today than they were 15 years ago.
*  I mean, stupider meaning measuring their academic progress after 50 years of
*  improvement, it turns around after 2012.
*  And this is true in the U S and internationally.
*  So there's just no reason why kids should have the phone on them.
*  They should come in in the morning, put it in a phone locker or yonder
*  pouch, go about their day.
*  And guess what?
*  The schools that have tried it after a week or two, everyone loves it.
*  The kids are like, Oh wow.
*  We actually talk in between classes.
*  You know, we have five minutes in the hallway.
*  We actually talk and you hear laughter.
*  Whereas right now in a lot of schools, it's just zombies looking at their phones
*  in between as they're walking from class to class.
*  Yeah.
*  Um, so the assumption is that from 2012 kids are just much more distracted.
*  Oh my God.
*  I mean, look, Joe, I think I heard you say in one of, um, yeah, it was a conversation
*  you had a few weeks ago with a comedian friend of yours, and I think this was a
*  direct quote from you, my fucking phone runs my goddamn life.
*  Does that sound like you?
*  Yeah, it sounds like me.
*  Okay.
*  So, so, um, you know, as adults, you know, we have a fully formed prefrontal cortex.
*  You and I had a normal childhood.
*  Our brains developed.
*  We have the ability to stay on task and man, it is hard with notifications coming in.
*  There's always so many interesting things you could do instead of what you need to do.
*  Um, so it's hard enough for us as adults.
*  Imagine if you didn't have a normal childhood where you developed executive
*  function, where you develop that ability, um, as a, as a teenager, cause it
*  puberty is when the prefrontal cortex, the front part of the brain, that's when
*  it rewires into the adult configuration.
*  So the fact that we're scrambling kids attention at the time when they're
*  supposed to be learning how to pay attention, I think is terrible.
*  Where do you think this is going?
*  This is my concern is that this is just the beginning of this integration that
*  we have, uh, with devices and that the, the social media model and it's been
*  immensely profitable and incredibly addictive.
*  And there's a massive, massive amount of capital that's invested in keeping
*  us locked into these things.
*  Where do you think this goes from here?
*  Have you paid attention to the technology?
*  Like AI?
*  Yeah.
*  Yeah.
*  Yes.
*  So let me just draw a very, very sharp, bright line between adults and children.
*  I'm very reluctant to tell adults what to do.
*  Um, if adults want to spend their time on an addictive substance or device or
*  gambling, I'm reluctant to tell them that they can't.
*  So when we're talking about adults, I think where this is going, um, is well,
*  where it's, where it's gone so far is everything that you might want becomes,
*  um, available instantly and for free with no effort.
*  And so in some ways that's a life of convenience.
*  Uh, but in other ways it's, it's messing us up and it's making us weaker.
*  So, you know, you want, you want sexual satisfaction.
*  Okay, here you go.
*  Free porn and it gets better and better and more and more intense.
*  Um, you want a girlfriend or boyfriend who you can customize that you, you know,
*  that you have that already, uh, advances in robotics are such that, um, I'm, you
*  know, it's, it's just a matter of time before AI girlfriends are put into these
*  incredible female bodies that you can customize.
*  So I think the adult world for young adults, especially is going to get really,
*  really messed up.
*  Um, and again, I'm not saying we'd need to ban it now, but what I'm saying is for
*  God's sakes, don't let this be 11 year old children's lives.
*  Let's at least keep children separate from all this craziness until their brains
*  develop and then they can jump into the whirlpool of the tornado.
*  But the fact that our 11 year old girls are now shopping at Sephora for anti
*  wrinkle cream or, you know, all sorts of expensive skin treatments, this is
*  complete insanity.
*  So let's at least protect the kids until they're through puberty.
*  Well, that would be nice.
*  That would be nice.
*  I just kind of essential, I think.
*  It's just the way I see adults being so hooked on these things.
*  Um, I, there's so many adults that I know that are engrossed in this world of other
*  people's opinions of everything they think and say, and it just doesn't give
*  you enough time to develop your own thoughts and opinions on things.
*  So many people are dependent upon other people's approval and there's, there's
*  just so many people that are addicted to interacting with people online and not
*  interacting with exceptional people in the real world.
*  Yeah, that's right.
*  Um, one way to think about this is let's look at, let's look at junk food, uh,
*  which became very popular after the second world war.
*  You know, the manufacturing of food became very good.
*  There were science labs.
*  Um, they said Frito-Lay, they studied the exact degree of tensile strength for
*  that a chip should have before it snaps.
*  And, you know, how do you make this, what's the perfect crunch?
*  So they designed the foods to be as addictive as possible.
*  And in the seventies and eighties, Americans switched over to a lot of
*  junk food and we became obese, like huge increase in obesity.
*  Um, and that kept going on for a few decades.
*  As I understand it, obesity has finally turned around a little bit and many
*  people are still eating huge amounts of junk food, but at least some people are,
*  are beginning to, beginning to say, you know what, I'm going to resist that deep
*  evolutionary programming for, uh, for fat and sugar.
*  Um, the companies played to that.
*  They hijacked those desires and they got us hooked on junk food, but we're fine.
*  After 50 years, we're making some progress in, in pushing back and having
*  healthier snacks and eating, eating less.
*  What's the root of that progress?
*  I don't actually know the numbers.
*  I just know a few years ago, I saw something that for the first time, obesity
*  actually went down in the United States.
*  I don't know that that's still true today, but this was like three or four
*  years ago before COVID, I saw something.
*  Do we know what caused it to go down?
*  Um, I don't, uh, I'm, I'm just assuming that this is an issue that
*  we dealt with as a society and we didn't know what we were doing at first.
*  And we got hooked and the efforts to, um, uh, you know, efforts to educate people
*  and to develop healthier alternatives.
*  So again, I don't know that I haven't, I, you know, I, uh, I should have looked
*  at the data before I came here.
*  Um, but I'm just using this as an analogy.
*  We're sure Jamie can find something.
*  Okay.
*  Yeah.
*  Maybe look it up online.
*  Is it, is obesity still rising in the United States or is it actually a little
*  lower than it was 10 years ago?
*  That's the question.
*  I mean, I quickly found this study here, but I haven't even got a chance to look at it yet.
*  This is the second time I've done this.
*  Something about this is giving me anxiety.
*  I'm spilling update on the
*  after the sudden rise is the upward trajectory beginning to flatten.
*  Okay.
*  Yeah.
*  So it's a question.
*  And what year was this?
*  So do you think it's just people recognizing that they're developing health issues
*  and they're taking steps to discipline themselves and mitigate some of these
*  issues or is there, is there some sort of information push that's leading them in that
*  direction?
*  Yeah, that I don't know because it's not my field, but I would say that that is a,
*  uh, a probably necessary precondition, like understanding the problem and developing
*  people a desire to, to change it.
*  And then it's hard to change.
*  You know, I love, I love chips.
*  I love chocolate.
*  I love ice cream.
*  It's hard to change, but over time, a society adapts.
*  And now the question is, will we adapt to social media?
*  Because the desire for sugar and fat and salt is very deep.
*  The desire for others to think well of us, to, to the other, to hold us in esteem, I
*  would say is just as deep and much more pervasive.
*  It's much stronger, I would say.
*  And so because, you know, as adults, we're very concerned, you know, when I, like when
*  I put out a tweet, um, you know, I know all this stuff.
*  I know how terrible this is for me to check.
*  I'm busy.
*  I've got things to do, but I'll go back and I'll check how the tweet is doing 30 seconds
*  later, like I'll go, you know, and then I'll check again five minutes later and 10, you
*  know, so it's hard for me to, me to resist that.
*  Like, what are people saying about the thing that I just said?
*  Yeah.
*  Um, but the question is, will we, will we adapt to it in some way so that we begin,
*  you know, as with junk food, we're still going to be consuming junk food, but maybe
*  we'll keep a lid on it.
*  I don't know.
*  I don't know.
*  But what I can say with not confidence, but I think is the case is as long as our kids
*  are going through puberty on social media and video games and they're not developing
*  executive control, I do not think they will be able to keep a handle on this as adults.
*  I do not either.
*  Again, as you're saying, we are adults.
*  We grew up without the internet and we got rid of all these problems and it is hard.
*  I try to tell all my friends to use my strategy, which I call post and ghost.
*  Okay.
*  I don't read anything.
*  I just post things.
*  I post things.
*  I don't read comments.
*  That's really smart.
*  It's made me immensely more happy.
*  It's, it's a massive difference.
*  I very rarely use Twitter.
*  The only reason why, or X, whatever.
*  I only, the only reason why I use it is to see information, to see things.
*  I don't read anything about myself and I certainly don't.
*  I very rarely post at all.
*  And if I do post, I certainly don't read what, because first of all, I'm aware of this
*  number, this FBI security specialist, the 80% of it, and I see it all the time.
*  There's so many times where I'll see any, any social issue, any political issue,
*  anything that's in the zeitgeist.
*  When you see someone post about it, you'll see these people posting and I'll look at
*  it.
*  It's like a couple of letters and a bunch of numbers and I'll go, okay, is that a real
*  person?
*  And then I go to their page.
*  Nope, nope, not a real person.
*  How many of them are there?
*  There's a lot of them.
*  There's a lot of them, especially when it comes to things like Ukraine, Israel, Gaza.
*  Right, because those are areas where various actors are, various parties and actors in
*  countries are trying to manipulate us.
*  Yes.
*  And they're doing it.
*  They're doing a great job of it.
*  They're very focused.
*  It's really incredible.
*  It's incredible to see the impact that it has when you see 50 posts on 50 comments and
*  35 of those seem to be not real people.
*  That's right.
*  I think your strategy is very wise.
*  And for this reason, when social media began, you would put something up and then people
*  could comment on it.
*  Okay, that was that goes until about 2013, 2014.
*  I think it's 2013 when Facebook introduces threaded comments.
*  So now you put something up, someone says some horrific, nasty, racist, whatever thing
*  in your comment thread.
*  And now everyone can reply to that comment.
*  And people can reply to the reply to the.
*  So you get basically everyone fighting with each other in the comment thread.
*  Yes.
*  And what social media is good for is putting out information quickly.
*  You know, I'm a professor, I'm a researcher.
*  I am engaged in various academic disputes and debates.
*  And Twitter is amazing for finding current articles, for finding what people are talking
*  about. So the function of putting information out is great.
*  But the function of putting something out and then watching everyone fight in the
*  comments. That's why I use the analogy of the Roman Coliseum, like with the gladiators.
*  That's just sick. That's just there's nothing good comes from that.
*  Right. My concern is that we are paddling upriver and that there's a raging waterfall
*  that's powering this whole thing that you cannot fight against and that we are moving in a
*  direction as a society with the implementation of new, more sophisticated technology
*  that's going to make it even more difficult unless you completely opt out.
*  And some people are going to opt out.
*  But it's going to be like my 600 pound life.
*  You know, people that are realizing, oh, my God, what have I done?
*  I've ruined my my body.
*  I've ruined my life. How do I slowly get back to a normal state?
*  And it's going to take a tremendous amount of effort.
*  Think about the amount of effort, the amount of focus that people have on comments and
*  things. If you're addicted, if you're currently deep into it right now, where you're tweeting
*  constantly. There's people that I follow that I know they're tweeting 12 hours a day.
*  Yeah, that's right. It's sad.
*  It's so sad. Yeah, there are addicts.
*  Yeah. Like how weird.
*  My fear is that this is only going to get greater.
*  Yeah, I share that fear.
*  And, you know, if current trends continue, you know, it's really not clear how we get
*  out of this. Something might break in a big way.
*  Humanity has faced many crises before.
*  That doesn't mean, you know, as they say, you know, past performance is no guarantee of
*  future success. So we face many crises and we've always come out stronger.
*  But I've never faced anything like this.
*  That's right. This is a category.
*  That's right. Exactly.
*  That's right. So we face many external threats.
*  We face diseases. We faced wars.
*  Those have come and gone. But this is a rewiring of the basic communication network
*  of society in ways that link up with so many of our deepest motivations.
*  This is a challenge unlike any we've ever faced.
*  And, you know, so I think, you know, what we really need, I'm speaking as a university
*  professor, is we really need great social sciences.
*  We need great sociologists.
*  We need people really studying this.
*  But, you know, it's all happening so fast.
*  And then the problems in universities of, you know, political concerns sweeping in.
*  So I feel I fear we're sort of heading towards this.
*  Well, you said like going upstream to a waterfall.
*  I think it was like going like downstream.
*  We're about, you know, at the top of waterfall going to go over the edge.
*  That too. Yeah.
*  Well, we're trying to paddle, but that's the direction we're moving.
*  Yeah, that's right. Yeah, that might be the case that, you know.
*  So, yeah, we live at a very interesting time in history when the, you know, in the 90s,
*  the future looked so bright.
*  And, yeah, now it doesn't.
*  My fear is that we are no longer going to become human, that we will no longer be human.
*  We'll be a different thing.
*  And I think the implementation of technology is what's going to facilitate that.
*  That we're, I think we're, you know, how many years away from Neuralink and something
*  similar to it that's going to change how we interact completely.
*  And then it's not going to be a salute.
*  It's not going to be a question of whether or not you opt out, whether you pick up your
*  device, your device is going to be a part of you.
*  And there'll be incentives that whether it's performance incentives, whether it's you're
*  going to have more bandwidth, whether whatever it is.
*  A competitive advantage.
*  Yeah, that's the real fear of something like Neuralink or whatever.
*  If they can figure out a Neuralink that doesn't require surgery, if they could figure out
*  something that does that without surgery, the advantage of having that in a competitive
*  sense in terms of like business and technology and industry, it's going to be massive and
*  it's going to be so difficult to get people to not do that, that it's going to be like
*  phones. I mean, I remember when I moved to Los Angeles in 1994, I bought a Motorola Star
*  Attack and I was like, look at me.
*  I got I had a phone in 1989.
*  Oh, wow. One of the big ones that went to a satellite.
*  It was actually connected to my car in 1989 and it was very advantageous.
*  My friend Bill Bluenreich, who owns the he owned the Comedy Connection.
*  He owns the Wilbur Theater now in Boston.
*  And I got a lot of gigs from him because he could call me when someone canceled.
*  Someone got sick and they said, hey, can you get the Dartmouth at 10 p.m.?
*  I'm like, fuck yeah.
*  And so I got gigs from that.
*  We joke about it to this day that I was like the first guy that he knew that had a cell
*  phone. It was a very it was a huge advantage.
*  And I remember when I had one in 94, I was like, this is great.
*  I can call my friends. I don't even have to be home.
*  There was so many positives to it.
*  And it gave you an advantage.
*  It gave you an advantage.
*  You didn't have to be home if there was a business thing that I had to deal with.
*  There was something going on with my career.
*  I could I could deal with it on the phone at Starbucks or wherever I was.
*  My fear is that this is going to be that times a million.
*  It's going to be you have to have it in order to compete, just like you have.
*  You kind of have to have an email today.
*  You kind of have to have a cell phone today.
*  That's right. That's right.
*  Yes, we are certainly headed headed in that way.
*  And I think the word human is a very good word to put on the table here.
*  Some things seem human or inhuman.
*  And when you simply connect people, you know, Mark Zuckerberg sometimes says, how
*  could it be wrong to give more people more voice?
*  If you're simply connecting people, making it easier for them to contact each other,
*  you know, I think that's mostly going to have good effects.
*  And that happened with the telephone.
*  You know, we all got telephones and we could do all sorts of things.
*  We could coordinate with our friends.
*  Telephones are great.
*  But when it became not technology making it easier for this guy to reach you or me
*  to communicate with you, but rather it's a way it's a way to put things out to try
*  to gain prestige from me in front of thousands or maybe millions of people.
*  Now it changes all of our incentives.
*  It changes the game we're playing.
*  You know, what games are we playing as we go about our day?
*  And the more people are playing the game of I'm struggling to get influence in an
*  influence economy where everyone else is on these seven platforms.
*  So I have to be too, or they have an advantage over me.
*  Right. That is the way that things have been revived already.
*  Already we're there.
*  Now you're raising the possibility that the next step is more hardware based, that
*  it's going into our bodies.
*  And I think that is likely to happen.
*  And so I hope what we'll do now and I hope I hope my book, The Action Generation, will
*  sort of promote a pause.
*  Let's think where we are.
*  Let's think what we've done.
*  Let's look at what has happened.
*  When our kids got on phones and social media, we thought, oh, this could be amazing.
*  Like they can connect.
*  They can form communities.
*  It's going to be great.
*  And now it's clear.
*  No, it's been horrible.
*  It's been really, really terrible.
*  As soon as they got on their mental health suffered, you know, they might feel like they
*  have a community, but it's much worse than what it replaces.
*  So I think what we're seeing is the sort of the techno optimist, the sort of the
*  futurists who say, oh, it's going to be amazing.
*  You know, we'll have Neuralink.
*  We'll have all this technology.
*  We'll be able to do everything.
*  Like here's where we have to heed.
*  I think the warnings of the ancients, of religious authorities, of those who warn us
*  that we are leaving our humanity and we're stepping into an unknown zone where
*  so far the initial the initial verdict is horrible.
*  So if we keep going without, you know, without putting on some breaks.
*  Yeah, I think we're going to a horrible place.
*  Yeah.
*  My fear is that it won't be horrible.
*  Oh, it'll feel good.
*  Yeah.
*  That it would be amazing.
*  So my fear, my genuine fear is the re rewiring of the mind in a way that can enhance
*  dopamine, enhance serotonin and do things that can genuinely make you feel better.
*  Yeah.
*  And that in the short run.
*  Yes.
*  And that we will decide that this is a better thing.
*  You know, just like, look, regardless of how you feel about SSRIs, most people think
*  that they're being dispensed too readily and that too many people that get on
*  antidepressants could have solved that issue with exercise and diet because this is a
*  big part of the reason why people are feeling shitty in the first place is their
*  body's failing.
*  Yeah.
*  And having less having less sex, I read recently that the SSRIs are suppressing sex
*  drive in many people.
*  So there's that.
*  There's there's a lot of issues that come along with those.
*  And yet there's immense profit in making sure that people take those and stay on
*  those.
*  My fear is that if you can do something that allows people to have their mind
*  function, have their brain, their endocrine system, have all these things function at
*  a higher level, then everyone is going to do it.
*  You would not want to just be natural and depressed if you could just put on this
*  little headset and feel fantastic.
*  And maybe it could be a solution to so many of our society issues.
*  Maybe bullying would cease to exist if everyone had an increase in dope.
*  It sounds silly.
*  But if dopamine increased by look, if you have an entire society that's essentially
*  on a low dose of MDMA, you're not going to have nearly as much anger and frustration.
*  And you also are not going to have as much blues.
*  You're not going to have as many sad songs that people love.
*  You're not going to have the kind of literature that people write when they feel like
*  shit. You know, it's unfortunate.
*  But also as a whole, as a society, it probably would be an overall net positive if
*  people did not want to engage in bullying, did not want to engage in violence, did not
*  want to engage in theft, were more charitable, you know, if if you if more benevolent.
*  And if you look at things in that direction, that's my concern is that the rewiring of
*  the mind, what we're essentially seeing right now is a rewiring of a mind that we
*  didn't anticipate it.
*  It has negative consequences.
*  We thought about it in a positive way.
*  Oh, that's going to be great. We're all going to be connected.
*  You know, what how would it be bad that people could have more voices like Zuckerberg
*  says? But my fear is that it's going to just change what it means to be a human being.
*  And my genuine feels that this is inevitable and that as technology scales upward, this
*  is unavoidable.
*  Right now, it certainly feels that way.
*  And and while I'm not optimistic about the next 10 years, I share your vision of what's
*  coming, but I'm not resigned to it.
*  People always say to me, I go around saying we need to do these four norms.
*  We can do them. And people say, oh, that ship has sailed like, you know, the trains left
*  the station. You know, but if a ship has sailed and we know that, you know, it's going
*  to sink, we can actually call it back.
*  I've been on airplanes where they leave the you know, leaves the the jetway and then they
*  call it back because they discover a safety issue.
*  So we are headed that way.
*  I agree. But I think there are I think we can I mean, we humans are an amazingly adaptable
*  species. We I think we can figure this out.
*  And I there are definitely pathways to a future that's much better.
*  These technologies could in theory give us the best democracy ever where people really do
*  have the right kind of voice.
*  It's not just the extremes who are super empowered as it is now.
*  So, you know, we're in we're in a we're at a point in space and time, let's say right now.
*  And I can imagine a future that's really fantastic.
*  And but how do we get there?
*  And are we able to get there?
*  Is there a path or is it like, you know, there's no path from A to B?
*  So I don't know. But I think we sure as hell have to try.
*  And and the first thing we have to do is not be resigned and just say, oh, well, the world's
*  going to hell. What are you going to do about it?
*  It's too big. So let's start.
*  I have a proposal.
*  Let's start with the one area that we can all agree on, which is our kids.
*  It's the most amazing thing in Congress.
*  You can't, you know, any issue if the right likes it, the left won't and vice versa,
*  except for this one. This is the only thing in Washington that's really bipartisan.
*  The senators and congressmen have kids.
*  They see it. So let's you know, let's test the proposition that all is lost and we're
*  helpless. Let's test that proposition and let's test it in the place where we can
*  we're most likely to succeed, which is rolling back the phone based childhood and
*  replacing replacing it with a more play based childhood.
*  Oh, so actually, I said there are four norms.
*  We talked about three. So if you don't mind, I'll put in the fourth norm now.
*  Yeah. So the first three about phones, no smartphone before high school, no social
*  media till 16 phone preschools.
*  OK, but if you take away the phones and you don't give you don't give kids back each
*  other and playtime and independence, what are they going to do?
*  You're going to keep them at home all day long without screens.
*  So the fourth norm is more independence, free play and responsibility in the real
*  world. And this is a thing that you and I talked about last time.
*  We actually had a small disagreement where, you know, I'm a big fan of Lenore
*  Scanesi, the woman who wrote Free Range Kids.
*  She and I co-founded an organization called Let Grow Parents.
*  Please go to let grow dot org.
*  All kinds of ideas for how to how to help your kid have more independence, which
*  makes them more mature, makes them more less fragile.
*  So this fourth norm, this is the harder one.
*  This is the one that we have to really overcome our fears of letting our kids out.
*  And so, actually, let me ask you, I think our disagreement last time was I talked
*  about this and like I said, like letting kids go for sleepovers and spend more time
*  with other kids and unsupervised.
*  And then you said, I think you said, no, I'm not let my kid go to sleepovers because
*  I don't trust the other families.
*  Does that sound familiar to you?
*  I don't believe that's what I said.
*  I think our concern was with people wandering around with kids being free to walk
*  home in cities. Yes, you had that also.
*  We did talk about sleepovers.
*  My kids had sleepovers.
*  OK, they've always had sleepovers.
*  If you know the parents and you trust the parents, it's a great way to give the kids
*  independence and have them interact with other people.
*  Yes. So tell me that.
*  But what was your policy with your kids, with your younger, with all three, when you
*  let them out, like they could go out the door, get on a bicycle, walk seven blocks to a
*  friend's house without any adult with them?
*  What do you mean? What age or grade?
*  No, I don't. I mean, it's fine if you live in a good neighborhood.
*  That the problem is, if you're if, you know, childhood predators are real.
*  Not really, not anymore.
*  What I mean is, what do you mean?
*  Well, when you and I were growing up, there were childhood predators out there in the
*  physical world approaching children.
*  And I think you said there you told the story about one who approached you when you
*  were doing magic tricks.
*  So there were child predators out there.
*  That's true. They're all on Instagram now.
*  The kids are in doubt.
*  And Instagram and especially Instagram makes it super easy for them to get in touch
*  with with children.
*  Yeah. So the physics.
*  So this is my point.
*  I can summarize the whole book with a single sentence.
*  We have overprotected our kids in the real world and under protected them online.
*  I would agree to that.
*  So that, you know, yes, child predators are terrible.
*  But guess what? We actually locked up most of them.
*  You know, when you and I were growing up, they weren't all locked up.
*  They were just eccentric who were exposing themselves.
*  Remember flashing flashers that, you know, that doesn't happen anymore.
*  Because if you do that now, you're going to jail for a long, long time.
*  So we actually locked up most of the predators and they know don't approach kids in a
*  playground, approach them on social media.
*  I don't know if we are doing that.
*  And there's this new push.
*  Oh, yeah. No. Once you're once you're identified as a sex offender, you'll never, you
*  know, you are gone for a long time and then there's sex offender.
*  No, we've really done a lot since the 90s to change the change to make the real world
*  safer.
*  But there is push against that.
*  You're aware of this term minor attracted persons that's being pushed.
*  Disgusting, disgusting and freaky.
*  It's such a bizarre term that I got to imagine is only being done by people who don't
*  have children. And they're they're pushing this thing that it's an identity and that
*  it's not the fault of the person who has this issue.
*  Yeah.
*  Where's what's the root of that?
*  Have you investigated that?
*  Yes. Not that specific issue, but I can I can, you know, from so look, I study moral
*  psychology. That's my academic discipline.
*  And I study the roots of it evolutionarily, historically and child development.
*  What is our moral sense?
*  And there are different moralities.
*  And in some ways, that's good.
*  And, you know, left and right push against each other.
*  So I'm very open to different moralities.
*  But when when a group makes something sacred and they say this is the most important
*  thing and nothing else matters other than this, then they can kind of go insane and
*  they kind of lose touch with reality.
*  And I think, you know, again, I don't know the history of this particular movement,
*  that that horrible term.
*  But there is a certain kind of morality which is all about, you know, oppression and
*  victimhood. And once you, you know, someone, I guess somewhere said, oh, you know, men
*  who are attracted to boys or, you know, little girls are being, you know, are victims.
*  I don't know what some some in some little eddy of weird morality.
*  Someone put that forward as a new victim class.
*  Because, you know, we've been, you know, we've been trying to address victimhood all
*  over the place. Once someone puts that up as a new victim class and you have to do
*  that, you have to change the terms.
*  This is very Orwellian.
*  You change the terms and then some others who share this morality, which is focused
*  on on not making anyone feel marginalized, not allowing any labels that will slander
*  someone or make them look bad.
*  I think, you know, I think people who approach children for sexual goals, I'm very
*  happy to have them slandered and labeled and and separated.
*  But, you know, I suspect that some people, once they lock this in as a group that's
*  being marginalized, they say, well, we have to we have to defend them and we don't
*  think about what the hell we're actually saying.
*  It seems purely an academic thing.
*  It seems that this is something that with people that only exist in sort of an academic
*  space where it's almost like an intellectual exercise in understanding oppression,
*  that's not it's you can't apply it in the real world.
*  It's just it's too fucked up.
*  The consequences of it are horrific.
*  Yeah, that's right.
*  Normalizing, victimizing children.
*  Now, the one thing. So before we go any further with this particular topic, I would
*  want to point out one of the problems that our social media world has given us, which
*  is somewhere in all of the academy and all the universities, some philosopher, let's
*  say, proposed that term or raised an idea.
*  So this has been going on for thousands of years.
*  Someone in a conversation proposes a provocative idea.
*  What if we think about this as minor track, you know, minor attracted person?
*  They put that idea out and then other people say, no, that's really stupid.
*  And it doesn't catch on because this is not an idea that's going to catch on even in
*  the academy. So but I think where we are now is I'm guessing someone
*  proposed this. Some buddy else got wind of it, posted it online.
*  And now you're going to have a whole media ecosystem going crazy about this terrible
*  idea. So maybe can you look up minor like minor attracted person?
*  Is this just like a thing that was from one academic talk or is this an actual movement?
*  Well, I've seen politicians discuss.
*  No way. Wait, wait, wait.
*  That's like as like decriminalizing or de de stigmatizing.
*  Oh, God.
*  There was a recent politician that went viral for this discussion.
*  All right. Maybe more than one.
*  There was two specific women that were doing that.
*  And I didn't investigate what these women had families or what it was.
*  But this is this push to.
*  To try to alleviate bullying or alleviate shame or alleviate the stigma that's attached
*  to what they're calling an identity.
*  Yeah, that's right. So actually, so that that brings us to the issue of identitarianism,
*  which I think is a useful term for us these days.
*  So I think a lot of what's happened on campus is the move to focus on identity as the
*  primary analytical lens in a number of disciplines, not in most disciplines, but in a
*  lot of humanities, the studies departments.
*  So putting identity first and then ranking identities and saying some identities are
*  good, some are bad. This this really activates our ancient tribalism.
*  And I think that the liberal tradition, going back hundreds of years, is really an
*  attempt to push back against that and to create an environment in which we can all get
*  along. And so, you know, as I see it from inside the academy, it's we've always been
*  interested in identity. It's an important topic.
*  There's a lot of research on it going back many decades.
*  But something happened in 2015 on campus that really elevated identitarianism into the
*  dominant paradigm, not dominant in that most people believed it, but dominant in the sense
*  that if you go against it, you're going to be destroyed socially.
*  And that's what cancel culture is. That's what Greg Lukianoff and Ricky Schlott, their
*  new book, The Cancelling of the American Mind is about.
*  So, yes, it's the people who are putting identity first.
*  And that's sort of their religion and their morality.
*  You know, I mean, they're welcome to live in the United States.
*  But when they get when they get influenced in universities or in school boards, yeah,
*  bad stuff will happen.
*  It's just bizarre the effect that it does have when people push back against identity
*  politics. It's a small, very vocal minority that pushes this agenda.
*  And it's not the majority of people.
*  The majority of people mostly disagree with these ideas.
*  Yeah, absolutely. This is, again, a really important point about how our society has
*  changed. Those of us from the 20th century still think in terms of public opinion, like,
*  do most people believe this or do most people not believe it?
*  And most people are sane.
*  Most people are not at all crazy.
*  Most people are pretty reasonable.
*  And I think what's happened since social media became much more viral in 2009, 2010, is
*  that the extremes are now much more powerful and they're able to intimidate the moderates
*  on their side.
*  So on the right, you know, the sort of the center right, you know, what I call like true
*  conservatives or like Berkey and Edmund Burke conservatives, you know, they get shot and
*  they get excluded. And there's not many of them in Congress anymore.
*  And on the left, you have the far left, the identitarian left, you know, shooting darts
*  into, you know, people like me and to anybody who is, you know, anybody who questions.
*  So they shoot their moderates.
*  And what you have is even though most people are still moderate and reasonable, our public
*  discourse is dominated by the far right, the far left and all these crazy fringe, you
*  know, I mean, it can be, you know, neo-Nazis on one side and then these, you know, identitarians
*  defending minor attracted people on the other side.
*  So don't lose faith in humanity.
*  Lose. Well, don't lose faith in humanity.
*  Recognize that we've moved into this weird, weird world because of social media, in
*  which it's hard to see reality and in which people are afraid to speak up.
*  And so we get warped ideas rising to dominance, even though very few people believe them.
*  And I think this is where bots come into play.
*  Yeah, because I think I really do believe that this is being amplified, whether it's
*  by foreign governments or by special interest groups or by whatever, whoever it is, is
*  trying to push these specific narratives.
*  Absolutely. And this can bring us right back to TikTok and the national security threat.
*  So Vladimir Putin was a KGB agent in the 20th century and the KGB going back, I think it
*  was in the 50s. They had some sort of a meeting or something where they decided that they
*  were going to take, I think it's called active measures.
*  They were going to try to mess up American democracy and they would, you know, they'd
*  spray paint racial slurs.
*  They put swastikas on synagogues.
*  They saw that we're a multiethnic democracy.
*  We're making a lot of progress towards tolerance.
*  And the Russians were trying to, the Soviets were trying to put a stop to that and make
*  us hate each other. So they were doing that back since the 1950s.
*  And it was expensive.
*  They had to fly people over or they had to try to win people over.
*  You couldn't scale the operation.
*  But that's the tradition that Vladimir Putin comes from.
*  Now, the Soviet Union falls in 1991.
*  I think he's I think he's like in Berlin or so.
*  I can't remember where he was. But he was very influenced by this and the humiliation
*  of the Soviet Union.
*  And so, you know, he rises to power again in the 21st century.
*  Do you think he suddenly no longer wants to mess with American democracy?
*  Like, did he suddenly drop that desire?
*  You know, we basically handed him the tools.
*  We said, OK, you know, you can open as many Facebook accounts as you want, Twitter
*  accounts, open as many as you want.
*  There's no identity authentication.
*  There's no age verification.
*  Create bots all you want and have them mess with us.
*  And Renee DiResta has a book coming out soon.
*  She really did amazing work to get to the bottom of this.
*  You know, they started running tests in 2013.
*  They created accounts on all these platforms long before, but they started running tests.
*  Could they, you know, could they get Americans to believe that an explosion had occurred
*  at a refinery plant in Louisiana?
*  Yes, they made it all up and people believed it.
*  Could they get Americans to believe some, you know, extreme BLM post that was completely
*  outrageous? Yes.
*  And, you know, same thing, you know, to enrage, you know, to enrage people on the left.
*  So the right we know that the Russians are messing with us.
*  We know that the Russians know our weak point.
*  And by Russians, again, I don't mean the Russian people.
*  I mean Vladimir Putin, the government, the government.
*  So, you know, we're handing them the tools and the instruction book for how to divide
*  us, how to weaken us, how to make us lose our resolve and our will.
*  Have you seen Yuri Besmanov give a speech?
*  Oh, is that? Yeah.
*  Yes. I've seen that.
*  Conversation about the ideological subversion.
*  And he did this in the 1980s.
*  I think it was 84. And he was talking about how the work is already done.
*  That's right. And that is just a matter of these generations now going into the workforce
*  with Marxist ideas and with all this ideological subversion that the Soviet Union has
*  injected into the universities.
*  That's right. That that could be right.
*  I mean, that it is chilling to watch and it is prophetic.
*  But, you know, they were playing a long game.
*  I mean, the communists planning the communist revolution, they were patient and they were
*  playing the long game.
*  Yeah, as is China. Yeah.
*  Yeah, that's right. Very smart.
*  I mean, it's there's so much more because they're dictatorships.
*  They have complete control over what they choose to do.
*  They don't have to meet with subcommittees.
*  They don't have to have congressional hearings.
*  They just can just do it.
*  Oh, and that's OK. That's a good point, because that that brings us to the big
*  difference between democracies and autocracies.
*  Back in the 1930s, when the West was in economic collapse and it was the Soviet
*  Union and then the Italian fascists and the German and then Hitler, the German
*  fascists, they were making rapid economic progress.
*  And the criticism of democracy has always been it's chaotic.
*  There's no good leadership.
*  They can't plan ahead.
*  And that's all true. But why did we triumph in the 20th century over all these other
*  models? Because democracy gives us a degree of dynamism where we can do things
*  in a distributed way. We have people just figuring stuff out.
*  We have an incredibly creative economy and business sector.
*  And so democracies have this incredible ability to be generative, creative,
*  regenerative. Unless you mess with their basic operating system and say, let's
*  take this this environment in which people talk to each other, share ideas,
*  take each other's ideas, compete, try to get a bigger, you know, better company.
*  Let's take that and let's let's change the way people talk so that it's not about
*  sharing information.
*  It's about making them spend all day long, nine hours a day competing for prestige on
*  social media platforms and and in a way that empowers everyone to complain all the
*  time. This, I think, really saps the dynamism.
*  I think this social media, what I'm suggesting, I haven't thought this through,
*  but I'm suggesting is that whatever the magic ingredient that made democracy so
*  triumphant in the 20th century, Western liberal democracy, American style
*  democracy, whatever made it so triumphant is being sapped and reduced by the rapid
*  rewiring of our society onto social media.
*  Yeah, I would agree with that.
*  And I think it's also being influenced, again, by these foreign governments that
*  have a vested interest in us.
*  Why wouldn't they?
*  Why wouldn't they? It's so cheap.
*  It's so cheap. It's so effective.
*  And it seems to be the predominant way that people interact with each other.
*  That's right.
*  When you say that you've been attacked, like what have you specifically been
*  attacked about?
*  Oh, it's just, you know, in the academic world, if you say anything about any DEI
*  related policy, you know, you'll be called racist or sexist or homophobic or
*  something.
*  And if you so I was always on the left, I was always a Democrat.
*  Now I'm nothing.
*  I'm an extremely alarmed patriotic American citizen who sees my country going
*  to hell.
*  I'm in that camp.
*  A lot of us are. A lot of us are politically homeless now.
*  Yeah.
*  But I sort of started my my career in political psychology.
*  So my original work was on how morality varies across cultures.
*  I did my dissertation research in Brazil and then I did some work in India.
*  And it was only in the 90s that we our culture were heated up.
*  And I began to see that left and right were like different countries with
*  different different economics textbook, different American history, different U.S.
*  Constitution. It was like different worlds.
*  And and I began actually trying to help the left stop losing elections like in
*  2000, 2004.
*  You know, as a Democrat, I thought I could use my research in moral psychology to
*  help the Democrats understand American morality, which they were not
*  understanding.
*  You know, Al Gore and John Kerry did a very bad job.
*  So I've all along been sort of critical of the left originally from within the
*  left. And that's a pretty good way to get a bunch of darts shot at you.
*  Nothing nothing terrible ever really happened.
*  I don't want to you know, lots of people have been truly canceled, you know,
*  shamed, lost their jobs, committed considered suicide.
*  So nothing like that has ever happened to me.
*  But, you know, when there's some minor thing on so, you know, people take a line
*  out of one of your talks, they put it up online with a commentary about what an
*  awful person you are.
*  Thousands of people comment on it or like it or retweet it.
*  It hurts. It's frightening in a way like nothing else I've ever known.
*  And how many of those people were even real people?
*  Yeah, that's right. This is the question.
*  That's right. Because it really is in dispute.
*  And it was one of the major disputes.
*  Oh, yeah. Right. That's right.
*  I mean, one of the things that's come out of Elon buying Twitter and thank God he
*  did as much as people want to talk about the negative aspects, which are real,
*  which I've seen racism and hate go up on Twitter.
*  I've seen it being openly discussed, which is very disturbing.
*  But what we did find out is that the government was involved in this, that the
*  federal government was interfering with people's ability to use these platforms.
*  For speech. I mean, because of COVID.
*  Yes, that's right. Yes.
*  But I feel like that's just just a test run.
*  Being able to implement that for that, then you can implement it for so many
*  different things. Dissent about foreign policy issues, dissent about social issues.
*  There's so many different ways they can do it if they can somehow or another frame
*  it in a way that this is good.
*  The overall better for the overall good of America.
*  Yeah, that's right. So that's why I never talk about content moderation.
*  I'm not interested in it.
*  There has to be some. But most people focus on the content and they think if we
*  can clean up the content or change the content or, you know, in those Senate
*  hearings we saw a couple of months ago, you know, just, you know, if we can reduce
*  the amount of suicide promoting or self harm promoting content that our kids are
*  seeing, then all will be well.
*  Like, no, it's not primarily about the content.
*  I agree with you that that the government was influencing these platforms to to
*  to to suppress views that they thought were were wrong and some of which turned out
*  to be right. I am a big fan of my friend Greg Lukianoff, who runs the Foundation for
*  Individual Rights and Expression.
*  So I think we shouldn't be thinking about social media like, well, how do we keep the
*  wrong stuff off and only have it have the right stuff?
*  I think almost only about architecture.
*  How is this platform designed?
*  And can we improve it in ways that are content neutral?
*  Can we improve it in ways that aren't going to advantage the left or the right, but
*  are going to make it more truth seeking?
*  And so Frances Haugen, the Facebook whistleblower, when she came out, she had
*  all kinds of ideas about how settings things that Facebook could have done to
*  reduce the incredible power of the extremes, the farthest right three percent,
*  the farthest left three percent, and then a bunch of just like random weirdos who
*  just post a lot.
*  They have extraordinary influence.
*  That's not about a left right thing.
*  That's about do we want an information ecosystem that super duper empowers the
*  extremes and silences the middle 80 percent?
*  Hell no.
*  So that's that's the kind of regulation that I favor focusing on making these
*  platforms less explosive and more useful.
*  And there's also this discussion that comes up a lot about algorithms.
*  Algorithms have essentially changed the entire game because it's not just what's
*  online. It's what do you interact with more frequently?
*  And that's accentuated.
*  Yes. And the problem with that is most people interact with things that rile them
*  up. And so you're you're developing these platforms that are immensely profitable
*  that ramp up dissent and ramp up anger and ramp up arguments.
*  And and like in the case of yourself, instead of just debating you on these
*  issues and doing it in a good faith manner, Jonathan Haight believes this.
*  This is why I disagree.
*  I think of this and that instead they'll label you as whatever racist sexist,
*  homophobic, Islamophobic, xenophobic, whatever they can say, whatever pejoratives
*  they can throw at you that essentially this reductionist view of your perspective
*  that makes it incredibly negative.
*  That's right. And then you'll get bots that interact with that.
*  That push that.
*  That's right. So Twitter only went to algorithms, I think, in 2017.
*  So before then, you know, people who tweet a lot, you know, you know, people talk
*  about a lot about algorithms as that's the cause of the whole problem.
*  And they're not the cause of the problem.
*  But man, are they amplifiers?
*  And I think that's what you're saying.
*  They're just super duper amplifiers on whatever craziness would be there even
*  without them.
*  And so that certainly is shaping what, you know, what is what we receive, what our
*  children receive.
*  And so this is some of the stuff that I think, again, we have to really protect our
*  children from to have a company able to micro target their exact desires, even
*  when they don't know what their desires are.
*  It's a degree of control and influence over children in particular that I think
*  they should just be protected from.
*  Do you think that if you looked at algorithms, do you think that it's an
*  overall net negative?
*  And could the argument be made that algorithms should be banned?
*  Yeah, no, I don't think so.
*  I mean, algorithms are there for a reason.
*  You know, we all know on Amazon, you know, if you look up a book, it's going to
*  suggest some other books you might be interested in.
*  And it's pretty darn good.
*  Like, yeah, you're right.
*  I would be interested in that.
*  So, no, I would never say, oh, we can't have algorithms.
*  I mean, that's that would just be a Luddite sort of move to make.
*  You know, I think again, as a social psychologist who studies morality, I,
*  you know, I just see everything going up in flames.
*  So here's a metaphor that I sometimes use.
*  Suppose you're the California Department of Parks and you have a hundred years of
*  experience fighting forest fires.
*  You know, everything about the wind, the humidity, you know, what season you've
*  got it down to a science and you can do you doing the best you can to keep
*  forest fires under control.
*  And then one day God decides to just mess with the world and changes the atmosphere
*  from 20% oxygen to 80% oxygen.
*  And if we suddenly were in a world where 80% of the atmosphere was oxygen,
*  everything would go up in flames.
*  Every electronic device would be burning right now.
*  So that's kind of what happened after 2009, 2010.
*  That's kind of what happened once, once we switched over to be about, so I would
*  say the retweet button that that that moved to virality that I think is even more
*  guilty of causing the problems even than algorithms.
*  I don't know that it's necessarily one versus the other, but but that's the way I
*  see it, that that we're in a world that is the technology is so quick to ramp up
*  whatever will most engage us.
*  And that's mostly emotions such as anger.
*  So, yeah, that's why it feels like everything's burning.
*  And this doesn't seem like it's slowing down.
*  It seems like it's ramping up and it seems like they've gotten more efficient at
*  the use of algorithms and all these different methods like retweeting and reposting
*  and different things that sort of accentuate what people are upset about and what
*  people get riled up about.
*  Yeah, yes, I think it is accelerating.
*  And for two reasons, one is that it's just the nature of exponential growth.
*  It's the nature of progress.
*  I think in the 19th century, a guy named Adams gave us the Adams curve.
*  It was like he was noticing like, wow, the amount of work we're able to do now
*  that we're harnessing steam and coal, you know, keeps growing and growing and growing.
*  And at some point, it's going to be going up so fast that it'll go up an infinite
*  amount every day or something.
*  You know, you reach an asymptote, you reach a point at which it's insane.
*  And yeah, so many people think that we're now at the singularity.
*  We're at the point at which things are changing so fast that we just can't even
*  understand them. And we haven't yet mentioned the word AI.
*  Now you bring in AI and of course, you know, AI could unlock extraordinary
*  material progress.
*  Mark Andreessen has been arguing that.
*  But as a social scientist, I fear it's going to give us material progress and
*  sociological chaos.
*  It's it's it's going to be used in ways that make our already unstable social
*  structures and systems even less stable.
*  Well, what's very bizarre that we're seeing with the initial implementation of
*  it specifically with Google's version of it, is that it's ideologically captured.
*  That was so horrible.
*  And that was so irresponsible of Google to do so.
*  No, I'm glad we have a chance to talk about this because I'm really horrified by
*  what Google did in introducing Gemini.
*  And just to give a little background here.
*  So I'm sure you're listening.
*  Many of your listeners know Google Gemini was programmed to to answer in ways that
*  basically, you know, the most extreme DEI officer would demand that people speak.
*  And so, you know, if you ask for a picture of the founding fathers, they're
*  multiracial or all black.
*  You know, this is just Nazi soldiers.
*  Even Nazis had had to be multiracial or black.
*  So so there's two things to say about this.
*  The first is that Google must be an unbelievably stupid company.
*  Like, did nobody test this before they released it to the public?
*  And obviously, Google is not a stupid company, which leads me to my next
*  conclusion, which is if Google did such a stupid, stupid thing.
*  So disgraced its product that it's banking so much on.
*  I mean, it depends a lot on the success of Gemini.
*  And now they've alienated half the country right away on the first day.
*  Practically alienated them.
*  They couldn't be that stupid.
*  I think what's happening to them is what happened to us in universities, which is
*  what I've called structural stupidity.
*  So you have very smart people.
*  But if anyone questions a D.E.I.
*  related policy on campus, they would get attacked.
*  And that's what most of the early blowups were.
*  I think you probably had Brett Weinstein on here.
*  That's what, you know, Erica Christakis at Yale and Nicholas Christakis at Yale.
*  You know, it's it's you know, people wrote these thoughtful, caring memos
*  about a poll opposing a policy.
*  There would be a conflagration.
*  They'd be attacked and they would sometimes lose their jobs.
*  So that's what happened to us in universities in 2015 to usher in our now nine
*  years of insanity, which I think are might be ending.
*  I think, you know, last fall was so humiliating for higher ed that I think we
*  might be at a turning point.
*  But my point is for Google.
*  I suspect that Google was suffering from an extreme case of structural stupidity
*  because surely a lot of those engineers could see that this is terrible.
*  This is a massive violation of the truth.
*  And part of Google's brand is truth and trust.
*  So I suspect they were just afraid to say anything.
*  And that's why Google made this colossal blunder of introducing, you know, woke AI
*  at a time when we desperately need to trust our institutions that are related to
*  knowledge. And Google was trusted and now they've lost a lot of it.
*  And it's not just Google. It's chat GPT.
*  But chat GP is not as explicit.
*  I mean, that's not as explicit, but it does do certain things.
*  Like if you ask it to say something positive about Donald Trump, it refuses.
*  You ask it to say something positive about Joe Biden, it'll gaslight you.
*  Yeah, no, that's right. I'm not.
*  And there was recently was it David Rosato or who was it put out some listing
*  of how far left each of the different different AI products are.
*  So you can certainly say that chat GPT is is not politically neutral.
*  But you wouldn't say from that that the people at chat GPT or open AI are stupid.
*  You would not look at this product and say, how could they be so dumb as to have it
*  be left leaning? But with Google, you have to say, how could they be so dumb as to
*  produce black Nazis for us?
*  Right. I just don't think they played it all out.
*  I think this ideological subversion, this thing that they've done with DEI and with
*  universities and the education system, it just seemed like you had to apply that to
*  artificial intelligence because you're essentially you're giving artificial intelligence
*  these protocols. You're giving it these parameters in which it can address things.
*  And if you're doing it through that lens, this is the inevitable result of that.
*  You're going to get black Nazis.
*  Oh, no, I don't know about the black Nazi.
*  I don't think it goes that extreme.
*  So to the extent that.
*  But if you say DEI, if you apply that to everything across the board and don't make
*  exceptions in terms of historical accuracy, the founding fathers of America being all
*  black. Yeah. Yeah.
*  So large again, I don't you know, I'm not an expert in AI, but large language models
*  are basically just consuming everything written and then spitting stuff back out.
*  And so it might be that, you know, most stuff is written, you know, the people on the
*  left are dominant universities.
*  They probably publish more books, whatever.
*  There's nothing written about black Nazis.
*  That's right. That's right.
*  So what I think is going on here is that I could see AI seeming to lean left, even if
*  it wasn't programmed to lean left.
*  That might just be the data input that it takes.
*  But to get black Nazis, you need somebody had a program in those commands.
*  Somebody had to consciously say, you know, anything about representation is going to
*  everything's going to look like a Benetton.
*  No, it's not even like a Benetton.
*  Benetton ads had much more diversity in the 1980s and 90s.
*  Yeah. So, no, I would I would agree that that the Gemini case clearly someone deliberately
*  programmed in all kinds of rules that they seem to come from a D.E.I.
*  manual just without much thinking.
*  Yeah. How do they come back from that?
*  I don't know. That's a good question.
*  I don't know how deep the rot runs.
*  I don't know how bad things are.
*  You know, Google used to have an amazing corporate culture.
*  Oh, boy. Look at this.
*  Apple is in talks to let Google Gemini power iPhone AI features.
*  Companies. Go back.
*  Yeah. Go back.
*  Companies considering a ideal that would build on search packed.
*  Apple also recently held discussions with open AI about deal on this news.
*  Then a bunch of big investment happened to Magnificent Seven ads, three and fifty billion
*  on Gemini's reported iPhone deal.
*  So because Google has implemented AI into their phones, specifically Samsung, Samsung's
*  new Galaxy S24 Ultra has a bunch of pretty fantastic AI features, one of them being
*  real time translation, your ability to summarize web pages instantaneously,
*  summarizing notes, bullet points, very helpful features.
*  So because of that, another one is your ability to circle any image and it automatically
*  will search that image for you.
*  Like, what is that? Circle it.
*  Boom. The Samsung phone will immediately give you a result and tell you what it is.
*  So very, very helpful.
*  But the now there becomes this is something that Apple has to compete with.
*  So Apple's decided to try to implement AI, but it has to outsource.
*  Yeah. Yeah.
*  No, it is. It is alarming.
*  I guess the point that I'd like to add on, which I hope will be useful for people, is
*  part of what we're seeing across our institutions is a loss of professional responsibility,
*  a loss of people doing their jobs.
*  And I don't mean, you know, base level employees.
*  I mean, leadership institutions have important roles to play.
*  Companies have missions.
*  Universities must be completely committed to the truth.
*  Research discovery.
*  Journalists must be committed also to the truth and methods to find the truth.
*  And what we've seen in the 2010s, especially, is many of these institutions being led away
*  from their their their their mission, their purpose towards the political agenda
*  of one side or another.
*  And so I think this is what we're seeing.
*  And we, you know, if we're going to make it through this difficult period, we need some way
*  to find the truth. And we know the more we've gone into the Internet age, the harder it is
*  to find the truth. Like we just look like, you know, something's incredible.
*  Like we just say, you know, hey, look this up and we got it.
*  But on anything contested, it's just very hard to find the truth.
*  And so that's why I'm especially disappointed in Google.
*  I always loved Google. I thought it was an incredible company.
*  And for them to, you know, to so explicitly say, you know, our our mission is political, it's
*  not to help you find the truth. That I thought was so disappointing.
*  Yeah, it is disturbing when a large company decides their mission is political.
*  Like to which side?
*  To who? Is it the truth?
*  Are you are you is that your main politics?
*  You know, or is it you decide that one side is good overall net positive, the other side is net
*  negative. And whatever you can do to subvert that other side is valuable.
*  That's right. And so that's a mindset in which the ends justify the means.
*  Yeah. And so part of the genius of American liberal democracy was to calm down those tribal
*  sentiments to the point where we could live together.
*  We could celebrate diversity in its real forms.
*  We could get the benefits of diversity.
*  And that was all possible when we didn't feel that the other side was an existential risk to the
*  country. That if the other side gets in, it's going to be the end.
*  And that's a very powerful image.
*  And that's an image that helped Donald Trump win.
*  There was an essay was by Michael Anton, I think, called the Flight 93 election.
*  You know, if you're on Flight 93 being hijacked to crash into the into Congress and, you
*  know, if you do nothing, you're going to crash into Congress.
*  You'll do anything. And so he framed it as a sort of a Hail Mary pass that, you know,
*  patriotic Americans were supposed to vote for for Donald Trump.
*  That mindset of of the ends justify the means.
*  The situation is so dire that even violence, even violence is justified.
*  That is really frightening.
*  And that's my that's my concern is that we could be headed that way.
*  We have not had much political violence.
*  There's been an uptick, but, you know, not very little compared to, say, 1968 to 73.
*  That period was much more violent.
*  Some hopeful will avoid that.
*  But this, you know, once you say the ends justify the means and we can cheat, we can
*  lie, we can subvert the company's purpose because the end we're fighting for is so
*  noble. Well, the other side is going to do the same thing.
*  Before you know it, your culture war becomes a real war.
*  Yeah. And you're seeing that in the news, how it's implemented in the news.
*  I mean, I'm sure you're aware of this recent Donald Trump speech where he talked about
*  a bloodbath. Oh, God.
*  What did the actual yeah, the actual phrase was what.
*  See if you can find that, Jamie, because it's actually important to highlight how.
*  Not just inaccurate, but it's just deceptive.
*  The media was in their depiction of what he said and that they are taking this
*  quote out of context and trying to say that there's going to be a civil war if he
*  doesn't get elected, which is not what he was talking about at all.
*  See, pull it up because it's it's so disturbing that they would first of all, they
*  would think that they could get away with it in this day and age with all the
*  scrutiny and all the with with social media and all the independent journalists that
*  exist now, which is one of the more interesting things about the divide demise
*  of corporate media, the demise and trust trust in corporate media is at an all time
*  low. And so this has led to a rise in true independent journalists.
*  The real ones out there, the Matt Tiebes, the Glenn Greenwald, the people that are
*  actually just trying to say what is really going on and what are the influences behind
*  these things and why are these things happening?
*  But this one was bizarre.
*  When I saw it, then I saw the actual speech.
*  Let's play the actual. Yeah, I have the actual speech.
*  The headlines are different, but I'll just play this.
*  Let's play the actual speech.
*  Think to China, if you're listening, President Xi and this is our friends, but he
*  understands the way I deal.
*  Those big monster car manufacturing plants that you're building in Mexico right
*  now and you think you're going to get that, you're going to not hire Americans and
*  you're going to sell the cars to us.
*  Now we're going to put a 100 percent tariff on every single car that comes across
*  the line and you're not going to be able to sell those cars.
*  If I get elected now, if I don't get elected, it's going to be a bloodbath for
*  the whole. That's going to be the least of it.
*  It's going to be a bloodbath for the country.
*  That'll be the least of it.
*  If this election, if this election isn't won, I'm not sure that you'll ever have
*  another election in this country.
*  Does that make sense?
*  I don't think you're going to have another election in this country.
*  If we don't win this election, I don't think you're going to have another election
*  or certainly not an election that's meaningful.
*  And we better get out of we better.
*  I actually say that the date, remember this, November 5th, I believe it's going
*  to be the most important date in the history of our country.
*  I believe that.
*  So that's what he said.
*  Well, that sounds pretty bad.
*  That sounds like a flight 93 election argument that if I don't win, the country's
*  over. But what he was saying, yeah, but what he's talking about is this subversion
*  of our economy and the subversion of our democracy that we will never have an
*  election again.
*  I don't think he's saying that'll be a bloodbath in terms of a civil war.
*  He's saying that the economy is going to be destroyed.
*  But there was no, I was listening for that.
*  I was thinking maybe he meant it as a metaphor.
*  I didn't hear any, I mean, the bloodbath is.
*  It's an unfortunate term, but he's not, I don't think he's saying it's a civil war.
*  It sounded to me like he was.
*  It sounded to me like, you know, if he doesn't win, there will be violence.
*  Right. You have to really give him a hell of a lot of benefit of the doubt.
*  He's talking about the economy.
*  He's talking about, he's talking about China, building plants.
*  He's talking about all these things and saying that if he doesn't get elected, it's
*  going to be a bloodbath.
*  It's going to be a mess.
*  I don't think he's, I mean, I think he would elaborate on that if he was saying
*  there'll be violence.
*  I don't think that's what he's saying.
*  I think he's saying destruction of our economy, the destruction of our.
*  You know, he makes a lot of asides.
*  So he was talking about the economy.
*  That's true.
*  And then he said, if I'm not elected, and then he makes an aside about what would
*  happen to the country if he.
*  So look, we might disagree on this.
*  We might disagree.
*  We surely disagree on our priors.
*  It's surely the wrong way to say it.
*  Surely.
*  We both agree on that.
*  Yeah.
*  It's an unfortunate term to use.
*  For him to, yes, that's right.
*  But it doesn't sound to me as though the media took that one out of context.
*  Well, they sort, I just rewatched the longer video on closed captioning.
*  Yeah.
*  Cut it out.
*  The video we watched cuts it off right after he says bloodbath.
*  Oh, oh, oh, let's see.
*  It's going to be a bloodbath for the whole.
*  That's going to be the least of it.
*  It's going to be a bloodbath for the country.
*  That'll be the least of it, but they're not going to sell those cars.
*  They're building massive factories.
*  A friend of mine.
*  All he does is build car manufacturers.
*  So he's back on the economy.
*  Yeah.
*  He was talking about that.
*  But he made an, but the aside was not about the economy.
*  The aside was him making one of these typical asides about how, you
*  know, how important he is.
*  All right.
*  We know, Joe, I think we're not going to settle this.
*  I think, look, I do agree that the media as a progressive left-leaning
*  institution like universities has violated its duty many times to the truth
*  and thereby lost the trust of much of the country.
*  Um, most of the people who work in these industries, I think are wonderful
*  and are trying to do a good job, but the net effect, and this is my point
*  about structural stupidity during our culture war, institutions that have had
*  very little viewpoint diversity have been subject to, uh, to, um, hijacking
*  by those with a political agenda.
*  So I agree with you about that.
*  Um, uh, although I disagree with you about what that comment from Donald Trump meant.
*  I just, it sounded to me like it was not taken out of context.
*  Well, he was talking about the, about the economy though.
*  Before.
*  I know, but in the aside he doesn't.
*  In the aside, he elaborates in the aside about the economy.
*  No, he just makes this aside about the bloodbath.
*  But that's the least of our problems.
*  Now back to what I was saying about the economy.
*  All right, look, we're not going to sell this one.
*  It's a terrible term.
*  It's a very unfortunate term.
*  If he said it will be a disaster instead of a bloodbath, that would
*  have been the better term.
*  Yes, that would have been a reasonable thing to say.
*  He's filled with hyperbole.
*  I mean, he's talking about, he's trying to excite people about the idea.
*  You're right.
*  Words matter when you're presidential candidate.
*  You do.
*  You're right.
*  But no, no argument there and no, I mean, I'm in no way saying that that
*  was the correct thing to say.
*  But the way they phrased it, the way they just, they just tried to make it seem
*  like that was the only thing that he was talking about.
*  Okay.
*  I'm just not going to say anything else on this.
*  I get it.
*  Um, but what you're saying is that these people are good people, but that they
*  are ideologically captured.
*  Is that what you're saying?
*  What I'm saying is that most people are reasonable wherever you go, but in the
*  social media age, it's no longer about what most people are like, it's about how
*  much power do the extremists have because anyone now has the power to
*  hijack, threaten, intimidate.
*  So, uh, that's, that's, that's my concern.
*  And that means it's actually more easily fixable because if it would be one thing,
*  if, you know, if 90% of journalists were rabid left-wingers who didn't give a
*  damn about journalistic integrity, and that's just not true.
*  Right.
*  Um, you know, most of the journalists I've met are really good journalists.
*  Like they really care about sourcing and accuracy.
*  Um, so, um, you know, and it's the same with professors, you know, many people,
*  especially those who listen to conservative sources might think that
*  professors are mostly tenured radicals who care more about Marxism than about
*  educating their kids.
*  That's just not true.
*  What is true is that the minority that have extreme views now have a much bigger
*  platform, they have more power, but most people are reasonable wherever you go.
*  Is the issue that the reasonable people are afraid of pushing back against the
*  radical people?
*  Exactly.
*  That's it.
*  Yeah.
*  That's the issue.
*  And because there really are consequences in terms.
*  That's right.
*  And people say, well, you've got tenure.
*  What are you worried about?
*  And the answer is, yeah, we've got incredible security, but everybody is afraid
*  of being publicly shamed, humiliated, attacked and mobbed.
*  Right.
*  And the people that go through it, I mean, it's, it's really, it's incredibly
*  painful.
*  They, they have to take, take sleeping pills at night.
*  They, they sometimes contemplate suicide and then one case committed
*  suicide that I know of.
*  Um, so yes, that's exactly the problem.
*  That's what I think the effect of not the original social media platforms
*  like MySpace or early Facebook, but of the hyper viral ones that we've got in
*  the 2010s.
*  Yes.
*  And the result of that in terms of people terrified about people attacking them is
*  what you get when you got those people from Penn, from Harvard.
*  We're talking about the, this rampant antisemitism on campus where people were
*  actively calling for the death of Jews saying that this does not constitute
*  harassment unless it's actionable.
*  Which is just stunning.
*  Insane.
*  Right.
*  It's not wrong unless they act on it.
*  What is that like as a person when, when, you know, you are an academic and you are
*  a professor, when you see that from these, especially from somewhere like Harvard,
*  like it just.
*  Yeah.
*  So, so yes, I'm a professor at NYU.
*  I was at UVA for 16 years.
*  I love being a professor.
*  I love universities.
*  I'm also Jewish and I can understand the argument that those, that those
*  presidents were making.
*  The argument was a very narrow technical argument about whether students should be
*  allowed to say from the river to the sea, Palestine will be free.
*  And so I understand why it was, it would have been reasonable for them to say, well,
*  we're not going to punish students for saying that.
*  That is political speech that's protected under the first amendment.
*  So I understand the point that they were making, but they were such screaming
*  hypocrites in making that point because, and this is what the Kotlin American
*  time was all about.
*  How did it happen that, you know, if an administrator, if a professor
*  administrator writes a single word that a, that a student objects to and calls
*  racist, suddenly this person out of a job, like really, like you're going to fire
*  someone or let someone be tormented and fired because they said something that
*  someone interpreted in a certain way.
*  And that, that led us to be super hyper crazy sensitive about every word we say
*  because you never know when it'll explode and cause a scandal.
*  And so for the presidents to say, Oh yeah, you know, anything anyone ever said
*  between 2015 and yesterday would be punished if anyone was bothered by it.
*  But from the river to the sea.
*  Oh yeah, sure.
*  That's constitutionally protected.
*  Just from the river to the sea.
*  It was the literal expression death to Jews.
*  Yeah.
*  Yes.
*  That's right.
*  And that's what they were specifically defending saying, unless it's actionable,
*  which is insane, unless you commit actual genocide.
*  Is that what you're saying?
*  That's right.
*  No, I'm sorry, Joe, you're right.
*  The question, right.
*  The, the, the deeper question is about political speech, but you're right.
*  That was Stefanik, I believe was asking them.
*  It was about calls for genocide.
*  Yes.
*  And so, so yes, calls for genocide.
*  It seems to me, you know, again, I'm not a first amendment lawyer, maybe from the
*  first amendment legally, like you can't be arrested for it, but for God's sakes
*  on a university campus where you're trying to make everyone feel included.
*  You can't even comment, not just about the calls for genocide, uh, you know, but
*  about the actual events on, on October 7th.
*  So that I think is what really brought higher ed to a, really a nadir, a low
*  point, um, in public esteem, like literally a low point in public esteem.
*  But I think it was a wake up call for a lot of people that are kind of on the
*  fence about how big the issue is.
*  Because these are the same people that call for you being kicked out of the
*  university if you dead name someone.
*  Yeah, that's right.
*  These are the same people that if you use the wrong pronouns.
*  Yeah, that's right.
*  And so, um, I'm actually, you know, so last semester was the worst one
*  ever for higher education.
*  Um, data from Gallup and Pew show that the public higher ed used to have an
*  incredible brand, global brand.
*  We were the best.
*  Everyone wanted to come here with scientific innovation.
*  All the top academics were here in the United States.
*  And in 2015, people on the left had a very high opinion of higher ed and
*  actually people on the right had a moderately high opinion of it.
*  Um, and then since 2015, it's dropped not just among people on the right, but
*  among centrists and moderates as well.
*  So higher ed really lost the trust of most of the country.
*  Um, and, and I was running an organization called heterodox academies.
*  I started it, uh, with some other social scientists that advocates for
*  viewpoint diversity.
*  And that's why I was kind of a target sometimes, cause, you know, here I am
*  saying we need viewpoint diversity.
*  We need, you know, some conservatives, some libertarians.
*  We need to not all be on the same side politically.
*  Um, which is an amazing thing to fight against.
*  Yeah, that's right.
*  That's right.
*  Because right viewpoint, I mean, we, we know, we're the experts in why
*  diversity is beneficial and the most important kind of diversity turns out
*  to be viewpoint diversity.
*  Well, it's also the most important aspect of an open and free society is
*  the ability to debate things and find out who's right or whose ideas resonate
*  the most, who makes the most sense, who has thought about this further and who
*  has the more enlightened and educated perspective, who has more information,
*  who, who has more balance.
*  That's right.
*  That's right.
*  So I think we hit a low point, um, in the fall in such a way that I'm actually
*  optimistic that things are going to change because I've been concerned
*  about these issues in universities, the culture issues since 2014, 2015,
*  when Greg Lukianoff and I wrote our first Atlantic article titled the
*  coddling the American mind.
*  And every year it's gotten worse and worse and worse.
*  There's never been a turnaround until last year.
*  And as with the emperor's new clothes, you know, people can see that something
*  is stupid and crazy and wrong, but they won't say anything.
*  But then when somebody does, then everybody can speak.
*  And I, I'm feeling finally, for the first time since 2015, I'm feeling that
*  people, people sort of understand, you know what, wait, that was crazy.
*  What happened to us?
*  That was crazy.
*  People were saying crazy stuff.
*  We let's put our head above the parapet.
*  Let's like start sometimes saying, maybe that is not right.
*  So I think that things are actually going to turn around.
*  Maybe not at the IVs, although there are movements of faculty.
*  They're saying, no, let's return to academic values, the pursuit of truth.
*  So I think what I'm hoping when I think is likely to happen is we're going to see a
*  split in the academic world.
*  That is, there are already schools like Arizona State University.
*  There are schools that already have basically said no to all the crazy stuff.
*  And they're focusing on educating their students.
*  And I think we're going to see more students going that way.
*  The University of Chicago is another model.
*  So I think there are a few schools that departed while almost all the other schools
*  went in the same direction.
*  But I think now that's going to change and it can change actually pretty quickly
*  because most of the university presidents don't like this stuff.
*  They were, I've spoken to many of them, you know, all the crazy politics, the
*  activist students, it made their job very difficult.
*  So I'm actually hopeful that we're going to start, we are starting to see some
*  university presidents standing up and saying, you know, it's not okay to shout
*  down every conservative speaker like, no, we're not going to allow that.
*  So, you know, we'll see, you know, a year from now, if I come back on a year or two,
*  we'll see.
*  But I think things are actually beginning to get better for the first time since 2015.
*  Well, I hope you're correct.
*  And I do agree that the pushback was so extreme that some action is likely to take place.
*  I think the first step of that is got to be to allow people with differing perspectives
*  to debate and not shout them down.
*  And also to show that that shouting people down and setting off fire alarms is shameful.
*  It's disgraceful.
*  That's right.
*  That's what we have to get to.
*  Education institution.
*  That's right.
*  If there was any punishment, the students would change very quickly.
*  The students are very concerned about getting a job, about their futures.
*  And, you know, what the early presidents who didn't do anything, what they conveyed was
*  you can yell and scream all you want, nothing will happen to you.
*  You can bang on the glass and frighten speakers, nothing will happen to you.
*  You can throw rocks through windows, nothing will happen to you.
*  And of course, that just, you know, brought us more obnoxious behavior on campus and shame
*  to higher ed in the eyes of the country.
*  So we had a brand that was based on extreme excellence and truth.
*  I think we damaged our brand very severely.
*  I think finally now there's a reckoning and a realization of what we've done.
*  And I think we're going to see a recovery, an uneven recovery.
*  But I do think that a year or two from now, the mood, the, well, who knows what's going
*  to happen with the election and whether there'll be a bloodbath.
*  Don't take that out of context.
*  I just was referring to the early part of our conversation that you're not quoting when
*  you quote this.
*  Yeah, let's say disaster.
*  Yeah, disaster could be disaster.
*  But I am actually, you know, about certain things, I'm pretty pessimistic like you.
*  But at least the future of universities, I do think for the first time, I'm actually
*  optimistic.
*  I wasn't optimistic a year or two ago.
*  Well, that's great because you're on the ground.
*  So you would really understand more than most.
*  And do you sense that with students, there's also recognition that this is a gigantic issue?
*  Like, what was the reaction to students?
*  I mean, not specifically Jewish students, but the Jewish students must have been the
*  most horrified by this.
*  Oh, my God.
*  Yes.
*  Stabbed in the back is the way many of us feel.
*  The, you know, what I've found all along, as I say, most people are reasonable.
*  When all this stuff was breaking out in 2015, 2016, most students just wanted to get an
*  education.
*  They don't want to take part in this.
*  Right.
*  And, you know, now I find out, of course, I teach in a business school.
*  I teach at NYU Stern.
*  Our students are pretty pragmatic.
*  They're, you know, they want to get a job.
*  Most of them are from immigrant backgrounds.
*  You know, they're not here to protest, you know, the latest political.
*  They're here to succeed.
*  That's right.
*  So, you know, so that is an aspect of Gen Z that gives me hope is that they, you know,
*  they see the problems.
*  They see the problems with social media.
*  They see the problems with the extreme activists.
*  So what we have to change is not the average student.
*  What we have to change is the dynamics so that the average student feels freer to speak up.
*  And how can that be done?
*  Well, so, you know, so I founded two organizations to do that.
*  One is Heterodox Academy.
*  We need more viewpoint diversity among the professors, or at least we need more toleration
*  of people who are centrist or libertarian or, you know, so that's one on the faculty side,
*  what we need to do.
*  And also the culture on campus.
*  But I also co-founded another organization called the Constructive Dialogue Institute
*  with a woman named Caroline Mel.
*  And what we did is we took some of the insights of moral psychology and some of the content
*  from my book, The Righteous Mind, and it's now it evolved.
*  It's now it's six 30 minute modules that teach you about moral psychology.
*  Why are we divided?
*  What do liberals believe?
*  What do conservatives believe?
*  Why do conversations go wrong?
*  How can you start more skillfully?
*  How do you need to listen first?
*  So there's a lot of like Dale Carnegie sort of wisdom in there.
*  And it's really effective.
*  So if people go to constructivedialogue.org, the program is called Perspectives.
*  It's being used in, you know, I think more than 50 universities now.
*  So there are things that we can do, but it's going to it's going to take leadership
*  and good psychology.
*  That's so important what you just said.
*  And I think that if those programs gain momentum and that people recognize that
*  it's really beneficial to all to have these ideas debate.
*  If you truly believe that opposing ideas to your ideology are evil,
*  you should be able to debate those.
*  And the only way to do that is to have someone to have the ability to express themselves
*  and for you to counter those those points that they make.
*  Yeah, exactly.
*  And this is what many commentators on the left have been pointing out since 2015.
*  Van Jones has an amazing talk.
*  He's a progressive, democratic, well-connected, smart person.
*  And he's been pointing out there's a great talk he gave the University of Chicago.
*  I have a quote on this in The Coddling of the American Mind,
*  where he talks about the move to protect students from bad feelings,
*  the move to protect them for emotional safety is really bad for the students.
*  But then his talk goes on and he says, this is actually really bad for the Democrats.
*  It's really bad for young activists to drown out opposition,
*  to not listen to the arguments, to not get stronger.
*  And so a lot of what's happened on campus, I think, is what you might call a Pyrrhic victory.
*  Pyrrhic victory is one where you won the battle, but that made you lose the war.
*  And so I think when institutions, when your side is able to wipe out opposition,
*  it might feel like a victory at first, but it's ultimately going to weaken you.
*  The same thing is going on in the far right.
*  There's a lot more fear and really bad consequences for people who dissent on the right too.
*  But if we're talking about universities,
*  that's more an issue of what's been happening on the left.
*  Are there any universities that don't have a left-leaning perspective?
*  Oh, sure.
*  Sure.
*  What universities?
*  Yeah, not in the top 20 or 50.
*  Right.
*  Isn't that a problem?
*  Well, that is a problem. That's right. Yeah, it is.
*  Well, actually, no, but let's put it this way.
*  First of all, I mean, there are lots of religious universities,
*  Christian universities that don't have this problem.
*  There are, let's see, there are large state schools tend to have much less of it.
*  Because again, most people are reasonable.
*  The great majority of faculty want to do their research, teach their classes.
*  They don't want to get involved in this stuff.
*  The problem is especially severe.
*  For some reason, the Ivy League schools, that's what's really surprising.
*  I thought it was just like, well, the elite schools.
*  No, it's actually the Ivies are the place where the worst anti-Semitic actual threats
*  and intimidation and even some violence are happening or threats of violence are happening.
*  Something about the Ivies makes them more extreme.
*  What do you think that is?
*  Well, I think it's in part the region.
*  So most of the shout downs, most of, you know, Greg Lukianoff and FIRE,
*  they've really been tracking this for a long time.
*  Most of the shout downs happen in the Northeast and along the West Coast and then around Chicago.
*  That's where most of the really nasty stuff happens.
*  This is not happening at the great majority of American universities.
*  It's not happening in the top schools in the South.
*  It's not happening at top schools in the Southwest.
*  So it is in part where it is.
*  And then I think also, you know, the Ivy League is full of really rich kids.
*  The statistic a number of years ago that the top schools have more people from the top
*  1% of the income distribution than from the bottom 60%.
*  So there's a real concentration, especially in the Ivies,
*  of, you know, rich kids who don't need to worry as much about getting a job and have the bandwidth
*  to devote themselves to politics while they're students.
*  Hmm.
*  God.
*  It's just, I just fear for the children that come out of that too,
*  these young people that come out of that, that have these distorted
*  perspectives that have to kind of rewire their view of the world once they get out.
*  Almost like taking someone from a cult and trying to just delete the indoctrination.
*  That's right. And it's almost impossible to do that, especially if most of what's coming in
*  is coming in from TikTok, not from your parents or your friends or your teachers.
*  So again, back to the problem.
*  That's right. So again, back to the question of the TikTok ban.
*  It's not, you know, the issue here is not, should we ban TikTok?
*  The issue is, should we, should American law require a divestiture
*  of TikTok from a Chinese corporation that is beholden to the CCP?
*  Which seems logical.
*  Yes.
*  There's an issue that's happening in Texas currently where one of the porn sites has pulled
*  out of Texas because they require age verification. And so there's all this pushback about whether or
*  not they should be able to require age verification. You have to be 18 to use porn websites,
*  which I think is very reasonable.
*  Yes. It's insane that we're even debating it.
*  Yeah, we're running a mass psychology experiment on children by having smartphones with large
*  screens and having instantaneous access to porn.
*  That's right. That's right. I mean, I forget the exact number, but a very large number of boys
*  are on porn hub or porn sites daily, every day. And again, as we were talking about before,
*  in puberty, the prefrontal cortex, the brain's really rewiring itself.
*  This is when you're supposed to be developing the ability for a boy to talk to a girl,
*  you know, for straight kids.
*  Right.
*  It's hard because boys and girls, they think a little differently. It's awkward. They're always
*  mistakes. They need to be practicing, but instead they're exposed to this diet of just horrible,
*  horrible stuff. And the girls see it too. The girls are not on as much, but they're all exposed
*  to it. And so we now see that many more members of Gen Z, they don't want to get married. They
*  don't want to have children. They're not having as much sex. I kind of understand it. If that's
*  what you think this sex stuff is, when you're an 11-year-old and you see this stuff, you're not
*  going to be like, Ooh, I want that to happen to me.
*  It's also so distorted. The relationships in these porn videos, it's not, it's bizarre fantasy.
*  And about step siblings, like why is so much about step sisters? I mean, it's a lot of step moms too.
*  Right. So the whole thing is sick. And once again, I'm not going to tell adults what they
*  should do with their spare time, but for God's sakes, I am going to try to tell companies
*  that they can't just have access to my kids from the age of nine or 10 and do what they want with
*  them. So, you know, I don't know the details of the Texas law, but I think we've got to do something
*  to age gate pornography. Like I just can't see. I mean, yes, there's a libertarian argument on
*  the other side that, Oh, we should never require identification from anyone for anything. Well,
*  if that's the way you're going to go, no restrictions, no, no, no, you know, then either
*  we have to keep kids off the internet, which is insane. We can't keep them off of the entire
*  internet. Or we have to say, you know what? Maybe some companies should be held liable.
*  Maybe Congress was wrong to grant them blanket immunity from lawsuits for what they're doing to
*  our kids. I think we should change that. Do you think at a certain point in time,
*  all this is going to become more obvious? And do you think the trend is that it's becoming more
*  obvious to people, whether it's to politicians or to parents or to overtime, the negative effects
*  of it are just so obvious? Yes. And I think that is happening right now. We're right at the beginning
*  of the tipping point. And I'm confident about this because the tipping point began in Britain
*  last month. So parents everywhere are fed up. They all see it. They don't know what to do,
*  but they're all frustrated in Britain. You know, some parents put up a, you know, a website delay
*  smartphones. People rushed to it. They had a WhatsApp group for, for parents to come together,
*  you know, thousands and thousands joined right away. In Britain, the government actually has
*  mandated phone free schools, which is one of my four norms. So in, so whenever you have a situation
*  where most people hate it, but they're either afraid or confused, that can change really,
*  really quickly. And that's like the fall of the Berlin wall, fall of the iron curtain. We thought
*  it was going to be there forever. But since most people hated, I traveled behind the iron curtain
*  in 2000, in 1987, everybody hated it. And so once the Berlin wall fell, it fell everywhere very
*  quickly. I think the same is going to be true for social media and the digital environment for
*  children. I think that 2024 is going to be for the digital environment, what 1989 was for Soviet
*  communism. Parents are fed up. The data is in, there's no doubt that there's no doubt that there's
*  an epidemic now. The evidence that it's caused by social media is a lot stronger than it was a few
*  years ago. People are ready to act. Congress is ready to act. So I'm actually, again, you know,
*  I think universities are going to get, are actually now, they are now actually getting better now that
*  they've been through, through that. And I think that the situation around kids and digital media
*  is going to change radically this year. That's my goal in, that's my goal in writing the book and
*  writing The Anxious Generation. And I'm, I have this amazing collaborator, the artist Dave Ciccarelli.
*  So these, these stickers here that I gave you, I don't know if we can hold them up. I'll just hold
*  them with my camera. It's a milk carton with a child on it. And it says, missing childhood.
*  So my friend, Dave Ciccarelli is a great artist in New York City. He designed the cover for the book.
*  And he and I had a plan for some like guerrilla art campaign with posters, you know, linking,
*  you know, Instagram to cigarettes, that sort of thing a couple years ago. So Dave had the idea
*  to really go big. And so Dave has built a 12 foot tall milk carton of the thing you just showed,
*  a 12 foot tall milk carton. It's going to be on the National Mall in Washington this Friday.
*  If you're in DC, check it out. It's coming to New York City, the northeast corner of Union Square.
*  I'll be there on March 26th, 25th, rather, 25th and 26th. I'll be there on the 25th.
*  We're starting a national movement. There are lots of organizations that are joining us here.
*  But we're starting a national movement to get parents to encourage parents to work together.
*  Because as I said, we can escape this if we work together. It doesn't have to be all of us.
*  But if a lot of us say, we're not going to give our kids smartphones till 14, we're not going to
*  let them open an Instagram or TikTok account until they're 16. We're going to ask our schools to go
*  phone free. And we're going to give our kids a lot more independence of the sort that we had
*  in a much more dangerous world. If we do those four norms, we really can turn that around.
*  And I'm confident we are at the tipping point right now. A few months, even a few months,
*  even by July and August, or let's say by September, when school starts again in the fall,
*  I think there's going to be a different vibe about phones and the roles of technology in kids' lives.
*  Well, I hope you're right, Jonathan. And I really appreciate you. And I really appreciate
*  you writing this and spending so much time on this and thinking about it so thoroughly.
*  The anxious generation, how the great rewiring of childhood is causing an
*  epidemic of mental illness. It's available right now. Go get it, folks. Listen to it,
*  read it, absorb it, take it in. Thank you very much. Really appreciate you.
*  Thank you, Joe. It's always fun to talk with you.
*  Fun to talk to you too. Thank you. Bye, everybody.
