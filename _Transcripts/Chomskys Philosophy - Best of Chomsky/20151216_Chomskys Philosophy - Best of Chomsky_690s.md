---
Date Generated: May 24, 2024
Transcription Model: whisper medium 20231117
Length: 690s
Video Keywords: ['Consciousness (Quotation Subject)', 'Mind (Quotation Subject)', 'Noam Chomsky (Author)', 'Artificial Intelligence (Industry)', 'Alan Turing (Computer Scientist)', 'Philosophy (Field Of Study)', 'Philosophy Of Mind (Field Of Study)']
Video Views: 85797
Video Rating: None
---

# Noam Chomsky - Mind, Consciousness, and A.I.
**Chomsky's Philosophy - Best of Chomsky:** [December 16, 2015](https://www.youtube.com/watch?v=0ORHGa-vQp0)
*  Do you believe that the mind is in principle computable,
*  implying that it could be emulated on other substrates in the future?
*  On other substrates, like silicon, I think he's talking about.
*  As far as, look, the mind is organized matter.
*  It's organized in a particular way which we don't understand,
*  but we don't understand much about bee communication.
*  And there's no reason, we don't know of any physical reason,
*  to believe that the particular components of that organized matter
*  are critical for its operation.
*  It appears to be something about the way it's organized.
*  That's as far as we know, so therefore it could be emulated,
*  presumably, in some other substances.
*  Yeah, I mean, as a physicist, I mean, we are a computing machine of some sort.
*  And it happens to be, we happen to use a certain system for storing
*  and reproducing, whether it's genetic or electrical.
*  It's hard to imagine any other system that if we were able to reproduce
*  all that information, we wouldn't get the same person.
*  It's one of those cases, as you said before, where you really have to be humble,
*  because so little is understood about it.
*  And the major question, what is the puppeteer doing?
*  That one we don't even know how to address.
*  This emerging notion that many of our conscious decisions are really not conscious.
*  Maybe you want to elaborate on that.
*  Well, there's some experimental evidence by now that when you undertake
*  a voluntary action, like say picking this up, very briefly before you are conscious
*  of making the decision, the parts of your brain that are organizing the action
*  are already active, which means that the decision is made pre-consciously
*  and then reaches consciousness at some point.
*  Most of our decisions never reach consciousness.
*  We're doing all kinds of things all the time, totally unaware of them.
*  And parts of the way are, we have two brains, remember.
*  There's this one and there's this one, sometimes called the gut brain,
*  the enteric nervous system, which is a real nervous system, rich in neurons,
*  it suffers Alzheimer's.
*  It's very similar to this one.
*  And we have the slightest consciousness about what it's doing.
*  Unless you get a stomach ache, then you know it's not working properly.
*  But with regard to language, unfortunately there has been no investigation,
*  serious investigation of the question, though it could be investigated.
*  So we're left at the moment with introspection.
*  That's not a good state, but try it.
*  When you introspect about your thinking and language, I think what you find is
*  that the expressions you articulate to yourself come almost instantaneously,
*  indicating that there was pre-conscious organization of the thought
*  that is sometimes reaching consciousness and often is not.
*  And I suspect that when these topics begin to be investigated,
*  which is not impossible, that's what we're going to discover,
*  that most, this mystery of what the puppeteer is doing is probably pre-conscious.
*  We will not get access to it through conscious introspection,
*  but only in indirect ways, the way we learn what the enteric nervous system is doing.
*  That's a guess about what will be discovered if these topics are ever investigated seriously.
*  One of the reasons they're not investigated is because of the assumption
*  in modern philosophy, psychology, that consciousness is the hard problem.
*  I don't think that's true.
*  I suspect consciousness is a problem that we know how to address.
*  You can find the mechanisms involved in consciousness.
*  You'll learn a lot about it.
*  Pre-conscious decisioning choices, I suspect, is a much deeper problem.
*  Okay, well, this is interesting.
*  I mean, we're asked to speculate on things about the future,
*  which we really, as we should emphasize, about a system that we don't understand much of now.
*  But in that spirit, and following up on this idea that maybe we could,
*  that the brain is a material entity and therefore might be reproduced elsewhere,
*  Bishop has asked, do you think that AI, and this is a really interesting question, I think,
*  do you think that AI will have the same snowflake language apparatus
*  or quick evolutionary moments in regards to creativity and language,
*  namely, assuming AI becomes conscious, would you imagine it would have the same kind of language development?
*  It's a really speculative question, but it's an interesting one, it seems to me.
*  Well, first of all, I should be a little cautious about AI.
*  What exactly is it?
*  There's two variants of AI.
*  One is roughly science and engineering.
*  I mean, it's a rough distinction.
*  There's the kind of AI which is trying to construct devices that are useful,
*  you know, self-driving cars, robots that can clean your house, things like that.
*  That's fine, you know.
*  It's not really contributing, except very indirectly,
*  to the understanding of how cognitive systems, intelligent systems work.
*  It's doing things that are useful, which is fine.
*  It's like building a bigger bulldozer. It's great.
*  There's another kind of AI which is pure science,
*  which is trying to discover the nature of what is going on when a nematode decides to turn to the left
*  or when I decide to pick this up.
*  But that's the same as, it might be called AI, if you like,
*  but it's the same as just science, cognitive science.
*  What will happen if the, I think the question is asking,
*  what if robots are designed which have the same properties,
*  the mechanisms that we will come to understand are essential for consciousness?
*  Will they be conscious?
*  We can already ask that question about dogs.
*  I mean, are they conscious?
*  In fact, you can ask that question about me.
*  You know you're conscious. Do you know that I'm conscious?
*  No, just because I tell you I am. That doesn't mean anything.
*  The robot could too.
*  There's the Turing test, which it turns out to be not a very good test after all.
*  Well, the Turing test is kind of interesting.
*  Turing himself was a very brilliant mathematician and scientist.
*  He understood that the test didn't amount to much.
*  The history of the Turing test is kind of intriguing.
*  This is based on an eight-page paper around 1950 called Can Machines Think or something.
*  Turing in that paper says the question whether machines can think
*  is too meaningless to deserve discussion.
*  And he's right.
*  Asking whether machines can think is like asking whether submarines swim.
*  If you want to call that swimming, it's swimming.
*  And in fact, it takes a...
*  It takes a... Airplanes fly.
*  In English, they fly.
*  In Hebrew, they glide.
*  Do people fly?
*  In Japanese, when they're jumping, they fly.
*  In English, they don't.
*  These are terminological questions.
*  What we can do in Turing...
*  Turing did suggest this imitation game,
*  but it is not, as he pointed out, an answer to the question whether machines think
*  because it's not a serious question.
*  The notion thinking isn't well enough defined,
*  so you can ask whether it's being achieved by some device.
*  Now, it's kind of striking that if you go back to the 17th century,
*  the same questions were asked, but as scientific questions.
*  So go back to Descartes, who observed, as far as we know correctly,
*  that this creative aspect of language use is a unique human capacity.
*  Well, that immediately led to experimental proposals.
*  Descorte-Amois, the minor Cartesians, outlined tests that you could use,
*  a series of experiments that you could use,
*  if there was another creature who looked like you,
*  and you wanted to find out if he had this capacity.
*  And he pointed out, like a scientist, that if the creature passes all the tests you can think of,
*  then it would be reasonable to assume that he has the capacity.
*  It doesn't prove it, but you don't prove things in science.
*  That was a serious version of the Turing test.
*  It was about something real, namely a capacity that you're trying to test for.
*  It's kind of like a litmus test for acidity.
*  There's something real, you're trying to find out whether some object has it.
*  That's very different from the Turing test.
*  In fact, in many ways, I think there's been kind of intellectual regression
*  from the 17th century to today,
*  replacing the serious tests about reality, litmus tests for a particular capacity,
*  by a test that's basically like answering the question whether submarines swim.
*  Doesn't mean much more than that.
*  Let's follow up on that a little, because you talked earlier this evening
*  about the idea that maybe things, whatever it was that initiated the possibility of language,
*  had to be, in a sense, because of the laws of nature.
*  The thing that would be interesting to me is whether, therefore,
*  there is a unique set of cognitive processes.
*  And so it would be interesting if one had machines to think to see if they think differently.
*  I think that would be a fascinating question.
*  Certainly. We know that there are some that are different.
*  So, for example, an automated procedure for, say, determining whether a paper
*  in the American Mathematical Society gives a real proof.
*  If you look at things that are called proofs, there are lots of intuition and appeal to what people know.
*  You try to formalize it and fill them in.
*  The details, it's pretty hard, but sometimes they're going to be very hard.
*  But you can think of automated ways of doing that, which are not the ways we do it.
*  And as I've said in the stage before, we know that computers think, at least right now, think differently,
*  because they use energy in a very vastly different way.
*  They do all kinds of things that we can't do.
*  And they also do it in some sense much more inefficiently in terms of energy consumption.
*  So do cars.
*  Yeah, yeah.
