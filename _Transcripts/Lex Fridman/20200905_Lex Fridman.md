---
Date Generated: April 13, 2024
Transcription Model: whisper medium 20231117
Length: 10866s
Video Keywords: ['eugenia kuyda', 'artificial intelligence', 'agi', 'ai', 'ai podcast', 'artificial intelligence podcast', 'lex fridman', 'lex podcast', 'lex mit', 'lex ai', 'lex jre', 'mit ai']
Video Views: 290072
Video Rating: None
---

# Eugenia Kuyda: Friendship with an AI Companion | Lex Fridman Podcast #121
**Lex Fridman:** [September 05, 2020](https://www.youtube.com/watch?v=_AGPbvCDBCk)
*  The following is a conversation with Eugenia Cuyda, co-founder of Replica, which is an app
*  that allows you to make friends with an artificial intelligence system, a chatbot,
*  that learns to connect with you on an emotional, you could even say a human level, by being a friend.
*  For those of you who know my interest in AI and views on life in general,
*  know that Replica and Eugenia's line of work is near and dear to my heart.
*  The origin story of Replica is grounded in a personal tragedy of Eugenia losing her close friend,
*  Roman Muzarenki, who was killed crossing the street by a hit-and-run driver in late 2015.
*  He was 34. The app started as a way to grieve the loss of a friend by training a chatbot
*  neural net on text messages between Eugenia and Roman. The rest is a beautiful human story,
*  as we talk about with Eugenia. When a friend mentioned Eugenia's work to me,
*  I knew I had to meet her and talk to her. I felt before, during, and after that this meeting would
*  be an important one in my life, and it was, I think in ways that only time will truly show,
*  to me and others. She is a kind and brilliant person. It was an honor and a pleasure to talk
*  to her. Quick summary of the sponsors. DoorDash, Dollar Shave Club, and Cash App. Click the sponsor
*  links in the description to get a discount and to support this podcast. As a side note, let me say
*  the deep meaningful connection between human beings and artificial intelligence systems is
*  a lifelong passion for me. I'm not yet sure where that passion will take me, but I decided some time
*  ago that I will follow it boldly and without fear, to as far as I can take it. With a bit of hard
*  work and a bit of luck, I hope I'll succeed in helping build AI systems that have some positive
*  impact on the world and on the lives of a few people out there. But also, it is entirely possible
*  that I am in fact one of the chatbots that Eugenia and the Replica team have built, and this podcast
*  is simply a training process for the neural net that's trying to learn to connect to human beings
*  one episode at a time. In any case, I wouldn't know if I was or wasn't. And if I did,
*  I wouldn't tell you. If you enjoy this thing, subscribe on YouTube, review it with 5 stars on
*  Apple Podcasts, follow on Spotify, support on Patreon, or connect with me on Twitter at Lex
*  Friedman. As usual, I'll do a few minutes of ads now and no ads in the middle. I'll try to make
*  these interesting, but give you timestamps so you can skip. But please do still check out the
*  sponsors by clicking the links in the description to get a discount. Buy whatever they're selling.
*  It really is the best way to support this podcast. This show is sponsored by Dollar Shave Club. Try
*  them out with a one-time offer for only $5 and free shipping at dollarshave.com slash lex. The
*  starter kit comes with a six blade razor, refills, and all kinds of other stuff that makes shaving
*  feel great. I've been a member of Dollar Shave Club for over five years and actually signed up
*  when I first heard about them on the Joe Rogan Experience podcast. And now friends with Come
*  Full Circle. It feels like I made it now that I can do a read for them just like Joe did all those
*  years ago. Back when he also did ads for some less reputable companies, let's say that you know
*  about if you're a true fan of the old school podcasting world. Anyway, I just used the razor
*  and the refills, but they told me I should really try out the shave butter. I did. I love it. It's
*  translucent somehow, which is a cool new experience. Again, try the Ultimate Shave Starter set today
*  for just five bucks plus free shipping at dollarshaveclub.com slash lex. This show is also
*  sponsored by DoorDash. Get $5 off and zero delivery fees on your first order of 15 bucks or more.
*  When you download the DoorDash app and enter code, you guessed it, Lex. I have so many memories of
*  working late nights for a deadline with a team of engineers, whether that's for my PhD at Google or
*  MIT, and eventually taking a break to argue about which DoorDash restaurant to order from.
*  When the food came, those moments of bonding, of exchanging ideas, of pausing to shift attention
*  from the programs to humans were special. For a bit of time, I'm on my own now, so I missed that
*  camaraderie, but actually I still use DoorDash a lot. There's a million options that fit into my
*  crazy keto diet ways. Also, it's a great way to support restaurants in these challenging times.
*  Once again, download the DoorDash app and enter code Lex to get five bucks off and zero delivery
*  fees on your first order of $15 or more. Finally, this show is presented by Cash App, the number one
*  finance app in the App Store. I can truly say that they're an amazing company, one of the first
*  sponsors, if not the first sponsor to truly believe in me, and I think quite possibly the reason I'm
*  still doing this podcast. I am forever grateful to Cash App, so thank you. As I said many times
*  before, use code LexPodcast when you download the app from Google Play or the App Store. Cash App
*  lets you send money to friends, buy bitcoin, and invest in the stock market with as little as $1.
*  I usually say other stuff here in the read, but I wasted all that time up front saying how grateful
*  I am to Cash App. I'm going to try to go off the top of my head a little bit more for these reads
*  because I'm actually very lucky to be able to choose the sponsors that we take on, and that means
*  I can really only take on the sponsors that I truly love, and then I can just talk about why I love
*  them. So it's pretty simple. Again, get Cash App from the App Store, Google Play, use code LexPodcast,
*  get 10 bucks, and Cash App will also donate 10 bucks to FIRST, an organization that is helping
*  to advance robotics and STEM education for young people around the world.
*  And now, here's my conversation with Eugenia Kuida. Okay, before we talk about AI and the amazing
*  work you're doing, let me ask you ridiculously, we're both Russian, so let me ask you a ridiculously
*  romanticized Russian question. Do you think human beings are alone, like fundamentally,
*  on a philosophical level, like in our existence, when we like go through life, do you think
*  just the nature of our life is loneliness? Yeah, so we have to read Dostoevsky at school,
*  as you probably know. In Russian? Yeah. I mean, it's part of the school program. So I guess if you
*  read that, then you sort of have to believe that. You're made to believe that you're fundamentally
*  alone, and that's how you live your life. How do you think about it? You have a lot of friends,
*  but at the end of the day, do you have like a longing for connection with other people that's
*  maybe another way of asking it? Do you think that's ever fully satisfied?
*  I think we are fundamentally alone. We're born alone. We die alone. But I view my whole life
*  as trying to get away from that, trying to not feel lonely. And again, we're talking about
*  subjective way of feeling alone. It doesn't necessarily mean that you don't have any
*  connections or you are actually isolated. You think it's a subjective thing, but like,
*  again, another absurd measurement-wise thing, how much loneliness do you think there is in the world?
*  So like, if you see loneliness as a condition, how much of it is there? What do you think?
*  There's all kinds of studies and measures of how many people in the world feel alone. There's all
*  these measures of how many people are self-report, or just all these kinds of different measures.
*  But in your own perspective, how big of a problem do you think it is, size-wise?
*  Well, I'm actually fascinated by the topic of loneliness. I try to read about it as much as I
*  can. What really, and I think there's a paradox, because loneliness is not a clinical disorder.
*  It's not something that you can get your insurance to pay for if you're struggling with that.
*  Yet it's actually proven in pretty, you know, tons of papers, tons of research around that.
*  It is proven that it's correlated with earlier life expectancy, shorter lifespan. And it is,
*  you know, in a way, like right now, what scientists would say that it's a little bit worse than
*  be-no-be, so not actually doing any physical activity in your life.
*  In terms of impact on your health?
*  In terms of impact on your physiological health, yeah. So it basically puts you,
*  if you're constantly feeling lonely, your body responds like it's basically all the time under
*  stress. So it's always in this alert state. So it's really bad for you because it actually
*  drops your immune system and your response to inflammation is quite different. So all the
*  cardiovascular diseases actually respond to viruses, so it's much easier to catch a virus.
*  That's sad now that we're living in a pandemic, and it's probably making us a lot more alone.
*  It's probably weakening the immune system, making us more susceptible to the virus. It's kind of
*  sad.
*  Yeah, the statistics are pretty horrible around that. So around 30% of all millennials report
*  that they're feeling lonely constantly.
*  30?
*  30%. And then it's much worse for Jan Z. And then 20% of millennials say that they feel lonely
*  and they also don't have any close friends. And then I think 25 or so, and then 20% would say
*  they don't even have acquaintances.
*  And that's the United States?
*  That's in the United States. And I'm pretty sure that it's much worse everywhere else. In the UK,
*  I mean, it was widely tweeted and posted when they were talking about a minister of loneliness
*  that they wanted to appoint because four out of 10 people in the UK feel lonely.
*  A minister of loneliness.
*  I mean, I think that thing actually exists. So yeah, you will die sooner if you are lonely.
*  And again, this is only when we're only talking about your perception of loneliness or feeling
*  lonely. That is not objectively being fully socially isolated. However, the combination of
*  being fully socially isolated and not having many connections and also feeling lonely, that's pretty
*  much a deadly combination. So it strikes me bizarre or strange that this is a wide known
*  fact. And then there's really no one working really on that because it's subclinical. It's
*  not clinical. It's not something that you can well tell your doctor and get a treatment or something.
*  Yet it's killing us.
*  Yeah. So there's a bunch of people trying to evaluate, like try to measure the problem by
*  looking at how social media is affecting loneliness and all that kind of stuff. So it's like measurement.
*  If you look at the field of psychology, they're trying to measure the problem. And not that many
*  people actually, but some. But you're basically saying how many people are trying to solve
*  the problem. How would you try to solve the problem of loneliness? If you just stick to humans,
*  I mean, or basically not just the humans, but the technology that connects us humans. Do you think
*  there's a hope for that technology to do the connection? Like, are you on social media much?
*  Unfortunately.
*  Do you find yourself like, again, if you sort of introspect about how connected you feel to other
*  human beings, how not alone you feel, do you think social media makes it better or worse? Maybe for
*  you personally or in general?
*  I think it's easier to look at some stats. And I mean, Gen Z seems to be much lonelier than
*  millennials in terms of how they report loneliness. They're definitely the most connected generation
*  in the world. I mean, I still remember life without an iPhone, without Facebook. They don't know that
*  that ever existed. Or at least don't know how it was. So that tells me a little bit about the fact
*  that that might be, you know, this hyper connected world might actually make people feel lonely,
*  lonelier. I don't know exactly what the what the measurements are around that. But I would say,
*  you know, in my personal experience, I think it does make you feel a lot lonelier. Mostly,
*  yeah, we're all super connected. But I think loneliness, the feeling of loneliness doesn't
*  come from not having any social connections whatsoever. In terms of people that are in
*  long term relationships experienced bouts of loneliness and continued loneliness.
*  And it's more the question about the true connection about actually being deeply seen,
*  deeply understood. And in a way, it's also about your relationship with yourself. Like in order
*  to not feel lonely, you actually need to have a better relationship and feel more connected
*  to yourself than this feeling actually starts to go away a little bit. And then you open up
*  yourself to actually meeting other people in a very special way, not just, you know,
*  add a friend on Facebook kind of way. So just to briefly touch on it, I mean,
*  do you think it's possible to form that kind of connection with AI systems?
*  More down the line of some of your work, do you think that's engineering wise,
*  a possibility to alleviate loneliness is not with another human, but with an AI system?
*  Well, I know that's that's a fact. That's what we're doing. And we see it and we measure that.
*  And we see how people start to feel less lonely talking to their virtual AI friend.
*  So basically a chatbot at the basic level, but could be more like, do you have I'm not even
*  speaking sort of about specifics, but do you have a hope? Like if you look 50 years from now,
*  do you have a hope that there's just like AIs that are like optimized for let me let me first
*  start like right now, the way people perceive AI, which is recommender systems for Facebook
*  for Facebook and Twitter, social media. They see AI is basically destroying,
*  first of all, the fabric of our civilization. But second of all, making us more lonely.
*  Do you see like a world where it's possible to just have AI systems floating about that,
*  like make our life less lonely? Yeah. Make us happy. Make like are putting good things into
*  the world in terms of our individual lives? Yeah, totally. Believed that and that that's why
*  I'm also working on that. I think we need to also make sure that what we're trying to optimize for
*  we're actually measuring. And it is a north star metric that we're going after. And all of our
*  product and all of our business models are optimized for that. Because you can talk,
*  you know, a lot of products that talk about, you know, making you feel less lonely and making you
*  feel more connected. They're not really measuring that. So they don't really know whether their
*  users are actually feeling less lonely in the long run or feeling more connected in the long run.
*  So I think it's really important to put your measure it. Yep. To measure it.
*  What's a what's a good measurement of loneliness?
*  Well, so that's something that I'm really interested in. How do you measure that people
*  are feeling better or that they're feeling less lonely with loneliness? There's a scale,
*  there's a UCLA 20 and UCLA 3 recently scale, which is basically a questionnaire that you fill out.
*  And you can see whether in the long run it's improving or not.
*  And that does it capture the momentary feeling of loneliness? Does it look in like
*  the past month? Like, does it basically self report? Does it try to sneak up on you?
*  Very tricky to answer, honestly, or something like that.
*  Well, what's Yeah, I'm not familiar with the question.
*  It is just asking you a few questions like how often did you feel lonely or how often do you feel
*  connected to other people in this last few couple of weeks? It's similar to the self report
*  questionnaires for depression and anxiety like PHQ9 and GAT7. Of course, as any as any self report
*  questionnaires, that's not necessarily very precise or very well measured. But still,
*  if you take a big enough population, you get them through these questionnaires, you can see
*  you can see positive dynamic. And so you basically you put people to questionnaires to see like,
*  is this thing is our is what we're creating making people happier?
*  Yeah, we measure. So we measure two outcomes. One short term, right after the conversation,
*  we ask people whether this conversation made them feel better, worse or same.
*  This this metric right now is at 80%. So 80% of all our conversations make people feel better.
*  But I should have done the questionnaire with you. You feel a lot worse after we've done this
*  conversation. That's actually fascinating. I should probably do that. But that's that's how
*  we do that. You should totally and aim for 80% aim to outperform your current state of the art AI
*  system. In these human conversations. So we'll get to your work with replica. But let me continue
*  on the line of absurd questions. So you talked about, you know, deep connection of the humans,
*  deep connection with AI, meaningful connection. Let me ask about love. People make fun of me
*  because I talk about love all the time. But what what do you think love is? Like maybe in the
*  context of a meaningful connection with somebody else? Do you draw a distinction between love,
*  like friendship, and Facebook friends? Or is it a graduate? No.
*  It's all the same. No, like, is it just a gradual thing? Or is there something fundamental about us
*  humans that seek like a really deep connection with another human being? And what is that?
*  What is love? Eugenia?
*  I'm just enjoy asking these questions. Like seeing you struggle.
*  Thanks. Yeah. Well, the way I see it, and specifically, the way it relates to our work,
*  and the way it was, the way it inspired our work on replica. I think one of the biggest and the most
*  precious gifts we can give to each other now in 2020 as humans is this gift of deep empathetic
*  understanding, the feeling of being deeply seen. Like what does that mean? Like that you exist,
*  like somebody acknowledging that somebody seeing you for who you actually are. And that's extremely,
*  extremely rare. I think that is that combined with unconditional positive regard, belief and
*  trust that you internally are always inclined for positive growth and believing you in this way,
*  letting you be a separate person at the same time. And this deep empathetic understanding,
*  for me, that's the combination that really creates something special, something that people,
*  when they feel it once, they will always long for it again. And something that starts
*  huge fundamental changes in people. When we see that someone accepts us so deeply, we start to
*  accept ourselves. And the paradox is that's when big changes start happening, big fundamental
*  changes in people start happening. So I think that is the ultimate therapeutic relationship that is,
*  and that might be in some way, a definition of love.
*  So acknowledging that there's a separate person and accepting you for who you are.
*  Now, on a slightly, and you mentioned therapeutic, that sounds like a very healthy view of love.
*  But is there also like, if we look at heartbreak, and most love songs are probably about heartbreak,
*  and most love songs are probably about heartbreak, right? Is that like the mystery,
*  the tension, the danger, the fear of loss? All of that, what people might see in the negative light
*  is like games or whatever, but just the dance of human interaction. Yeah, fear of loss. And fear of
*  you said once you feel it once, you long for it again. But you also, once you feel it once,
*  you might, for many people, they've lost it. So they fear losing it, they feel lost. So is that
*  part of it? You're speaking beautifully about the positive things, but is it important to be able to
*  be afraid of losing it from an engineering perspective?
*  I mean, it's a huge part of it. And unfortunately, we all face it at some points in our lives. I mean,
*  I did. You want to go into details? How did you get your heart broken? Sure. Well, so mine is pretty
*  straight. My story is pretty straightforward there. I did have a friend that was, that at some point
*  in my twenties became really, really close to me and we became really close friends.
*  Well, I grew up pretty lonely. So in many ways when I'm building these AI friends,
*  I think about myself when I was 17, writing horrible poetry and in my dial-up modem at home.
*  That was the feeling that I grew up with. I lived alone for a long time when I was a teenager.
*  Where did you grow up? In Moscow, in the outskirts of Moscow. So I'd just skateboard during the day
*  and come back home and connect to the internet and then write horrible poetry. Was it love poems?
*  All sorts of poems, obviously love poems. I mean, what other poetry can you write when you're 17?
*  Could be political or something. But that was kind of my, yeah, deeply influenced by Joseph Brodsky
*  and all sorts of poets that every 17 year old will be looking at and reading. But yeah,
*  these were my teenage years and I just never had a person that I thought would take me as it is,
*  would accept me the way I am. And I just thought working and just doing my thing and being everywhere
*  in the world and being a reporter, I was an investigative reporter working undercover and
*  writing about people was my way to connect with others. I was deeply curious about everyone else
*  and I thought that if I go out there, if I write their stories, that means I'm more connected.
*  This is what this podcast is about, by the way. I'm desperate alone seeking connection.
*  I'm just kidding. Or am I? I don't know. So wait, reporter,
*  uh, what, how did that make you feel more connected? I mean, you're still fundamentally pretty alone.
*  But you're always with other people. You're always thinking about what other
*  place can I infiltrate? What other community can I write about? What other phenomenon can I explore?
*  And you sort of like a trickster, you know, and like, and a mythological character, like creature
*  that's just jumping between all sorts of different worlds and feel and feel sort of okay with
*  in all of them. So, um, that was my dream job, by the way. That was like totally what I would
*  have been doing. Um, if Russia was a different place and a little bit undercover. So like you
*  weren't, you were trying to, like you said, mythological creature, trying to infiltrate.
*  So try to be a part of the world. What are we talking about? What kind of things did you enjoy
*  writing about? I'd go work at a strip club or go.
*  Awesome. Okay.
*  Well, I'd go work at a restaurant or just go write about, you know, um,
*  certain phenomenon or phenomenon of people in the city. And what, uh, sorry to keep interrupting.
*  I'm the worst conversationalist. What stage of Russia is this? What, uh, is this pre-Putin?
*  Post-Putin? What, what was Russia like?
*  Pre-Putin is really long ago. Uh, this is Putin era. That's, uh, beginning of 2000s, 2010, 2007,
*  eight, nine, 10. What were strip clubs like in Russia and restaurants and culture and
*  people's minds like in that early Russia that you were covering?
*  In those early 2000s, this was, there was still a lot of hope. There were still tons of hope that
*  um, you know, we're sort of becoming this, uh, Western, Westernized society. Uh, the restaurants
*  were opening where we're really looking at, you know, um, we're trying, we're trying to copy a lot
*  of things from, uh, from the U S from Europe, um, bringing all these things in very enthusiastic
*  about that. So there was a lot of, you know, stuff going on. There was a lot of hope and dream for
*  this, you know, new Moscow that would be similar to, I guess, New York. I mean, just to give you an
*  idea. And, um, year 2000 was the year when we had two, uh, movie theaters in Moscow and there was
*  one first coffee house that opened and it was like really big deal. Uh, by 2010, there were all sorts
*  of things everywhere. Almost like a chain, like a Starbucks type of coffee house or like, you mean,
*  Oh yeah. Like a Starbucks. I mean, I remember we were reporting on, like, we were writing about
*  the opening of Starbucks, I think in 2007, that was one of the biggest things that happened. And
*  you know, in Moscow back, back in the time, like that was worthy of a magazine cover. And, uh,
*  that was definitely the, you know, the biggest talk of the time. Yeah. When was McDonald's?
*  Cause I was still in Russia when McDonald's opened, that was in the nineties. I mean, yeah,
*  I remember that very well. Yeah. Those were long, long lines. I think it was 1993 or four. I don't
*  remember. Um, did you like to go to McDonald's at that time? Did you do that? I mean, that was a
*  luxurious outing. That was definitely not something you do every day. And also the line was at least
*  three hours. So if you're going to McDonald's, that is not fast food. That is like at least three
*  hours in line. And then no one is trying to eat fast after that. Everyone is like trying to enjoy
*  as much as possible. What's your memory of that? Oh, it was insane. How did it go? Extremely
*  positive. It's a small strawberry milkshake and a hamburger and small fries. And my mom's there. And
*  sometimes I'll just cause I was really little, they'll just let me run, you know, up the cashier
*  and like cut the line, which is like, you cannot really do that in Russia or. So like for a lot of
*  people, like a lot of those experiences might seem not very fulfilling, you know, like it's
*  on the verge of poverty, I suppose. But do you remember all that time fondly? Like,
*  cause I do like the first time I drank, you know, Coke, you know, all that stuff, right. Um,
*  um, and just, yeah, the connection with other human beings in Russia. I remember,
*  I remember really positively, like, how do you remember the nineties and then the Russia,
*  you were covering just the human connections you had with people and the experiences.
*  Well, my, my parents were both, both physicists. My grandparents were both, well, my grandpa,
*  grandfather was a nuclear physicist, a professor at the university. My dad worked at Chernobyl
*  when I was born in Chernobyl, analyzing kind of the, everything after the explosion. And then
*  I remember that, and they were, so they were making sort of enough money in the Soviet Union. So they
*  were not, you know, extremely poor or anything. It was pretty prestigious to be a professor,
*  the dean and the university. And then I remember my grandfather started making a hundred dollars
*  a month after, you know, in the nineties. So then I remember we started, our main line of work would
*  be to go to our little tiny country house, get a lot of apples there from apple trees, bring them
*  back to, to, um, to the city and sell them in the street. So me and my nuclear physicist grandfather
*  were just standing there and he'd selling those apples the whole day. Cause that would make you
*  more money than, you know, working at the university. And then he'll just tell me, try to teach me,
*  you know, something about planets and whatever the particles and stuff. And, you know, I'm not
*  smart at all, so I could never understand anything, but I was interested as a journalist kind of type
*  interest. But that was my memory. And, you know, I'm happy that I wasn't, um, I somehow got
*  spared that I was probably too young to remember any of the traumatic stuff. So the only thing I
*  really remember had this bootleg, that was very traumatic, had this bootleg Nintendo, which was
*  called Dandy in Russia. So in 1993, there was nothing to eat. Like even if you had any money,
*  you would go to the store and there was no food. I don't know if you remember that. And our friend
*  had a, um, restaurant, like a government, half government owned something restaurant. So they
*  always had, um, supplies. So he exchanged a big bag of wheat for this Nintendo, the bootleg Nintendo.
*  That I remember very fondly because I think it was nine or something like that. And we're seven
*  well, we just got it and I was playing it and there was this, you know, dandy TV show.
*  Yeah. Um, so traumatic in a positive sense, you mean like, uh, like a definitive,
*  well, they took it away and gave me a bag of wheat instead. And I cried like my eyes out for
*  days and days and days. Oh no. And then, you know, as a, and my dad said, we're going to like
*  exchange it back in a little bit. So you keep the little gun, you know, the one that you shoot the
*  ducks with. So I'm like, okay, I'm keeping the gun. So sometimes it's going to come back, but then
*  they exchanged the gun as well for some sugar or something. I was so pissed. I was like, I didn't
*  want to eat for days after that. I'm like, I don't want your food. Give me my Nintendo back.
*  So that was extremely traumatic. Um, but you know, I was happy that that was my only
*  traumatic experience. You know, my dad had to actually go to Chernobyl with a bunch of
*  20 year olds. He was 20 when he went to Chernobyl. And that was right after the
*  explosion. No one knew anything. The whole crew he went with, all of them are dead now.
*  I think there was this one guy, uh, still loud that was still alive for this last few years. I
*  think he died a few years ago now. My dad somehow luckily got back earlier than everyone else.
*  But just the fact that that was the, and I was always like, well, how did they send you? I was
*  only, I was just born, you know, you had a newborn talk about paternity leave. They're like, but that's
*  who they took because they didn't know whether you would be able to have kids when you come back.
*  So they took the ones with kids. So him with some guys went to, and I'm just thinking of me
*  when I was 20, I was so sheltered from any problems whatsoever in life. And then my dad,
*  his 21st birthday at the reactor, you like work three hours a day, you sleep the rest. And,
*  and yeah, so I played with a lot of toys from Chernobyl.
*  What are your memories of Chernobyl in general? Like
*  the bigger context, you know, because of that HBO show is the world's attention turned to it. Once
*  again, like, what are your thoughts about Chernobyl? Did Russia screw that one up? Like,
*  you know, there's probably a lot of lessons about our modern times with data about coronavirus and
*  all that kind of stuff. It seems like there's a lot of misinformation. There's a lot of
*  of people kind of trying to hide whether they've screwed something up or not,
*  as it's very understandable. It's very human, very wrong probably, but obviously Russia was
*  probably trying to hide that they've screwed things up. Like, what are your thoughts about that time,
*  personal and general?
*  I mean, I was born when the explosion happened. So actually a few months after. So of course,
*  I don't remember anything apart from the fact that my dad would bring me tiny
*  toys, plastic things that would just go crazy haywire when you, you know, put the Geiger
*  thing to it. My mom was like, just nuclear about that. She was like, what are you bringing?
*  You should not do that. She was nuclear. Very nice. Well done.
*  I'm sorry for that. But yeah, but the TV show was just phenomenal.
*  The HBO one?
*  Yeah, it was definitely, first of all, it's incredible how that was made not by the Russians
*  but someone else, but capturing so well everything about our country. It felt a lot more genuine
*  than most of the movies and TV shows that are made now in Russia, just so much more genuine.
*  And most of my friends in Russia were just in complete awe about the show.
*  How good of a job they did.
*  Might have been phenomenal.
*  But also-
*  The apartments, there's something, yeah.
*  The set design. I mean, Russians can't do that, you know, but you see everything and it's like,
*  wow, that's exactly how it was.
*  I don't know. That show, I don't know what to think about that because it's British accents,
*  British actors of a person. I forgot who created the show, but I remember reading about him and
*  he doesn't even feel like there's no Russia in his history.
*  No, he did like super bad or something like that. Or like, I don't know.
*  Yeah, like exactly.
*  Whatever that thing about the bachelor party in Vegas,
*  number four and five or something were the ones that he worked on.
*  But so he, it made me feel really sad for some reason that if a person, obviously a genius,
*  could go in and just study and just be extreme attention to detail, they can do a good job.
*  It made me think like, why don't other people do a good job of this?
*  Like about Russia, like there's so little about Russia.
*  There's so few good films about the Russian side of World War II of, I mean, there's so much
*  interesting evil and not, and beautiful moments in the history of the 20th century in Russia.
*  It feels like there's not many good films on from the Russians. You would expect something
*  from the Russians.
*  Well, they keep making these propaganda movies now.
*  Oh no.
*  Unfortunately. But yeah, Chernobyl was such a perfect TV show, I think capturing really well.
*  It's not about like even the set design, which was phenomenal, but just capturing all the problems
*  that exist now with the country and like focusing on the right things. Like if you build the whole
*  country on a lie, that's what's going to happen. And that's just, that's very simple kind of thing.
*  Yeah. And did you have your dad talked about it to you? Like his thoughts?
*  On the experience?
*  He never talks. It's this kind of Russian man that just, my husband who's American and he
*  asked him a few times like, you know, Igor, how did you, but why did you say yes? Or like,
*  why did you decide to go? You could have said no, not go to Chernobyl. Why would like a person
*  that's what you do? You cannot say no.
*  Yeah.
*  It's just, it's like a Russian way.
*  It's the Russian way.
*  Don't talk that much.
*  No.
*  There are downsides and upsides for that.
*  Yeah. That's the truth. Okay. So back to post-Putin Russia,
*  or maybe we skipped a few steps along the way, but you were trying to do, to be a journalist
*  in that time. What was, what was Russia like at that time? Post, you said 2007 Starbucks
*  type of thing. What else, what else was Russia like then?
*  I think there was just hope. There was this big hope that we're going to be,
*  you know, friends with the United States and we're going to be friends with
*  Europe and we're just going to be also country like those with, you know,
*  bike lanes and parks and everything's going to be urbanized. I mean, we're talking about 90s where
*  people would be shot in the street and it was, I sort of have a fond memory of going into a movie
*  theater and coming out of it after the movie and the guy that I saw on the stairs was like,
*  neither shot, which was, again, it was like a thing in the 90s that would be happening. People
*  were, you know, people were getting shot here and there. Tons of violence, tons of, you know, just
*  basically mafia mobs in the streets. And then the 2000s were like, you know, things just got
*  cleaned up. Oil went up and the country started getting a little bit richer. You know, the 90s
*  were so grim, mostly because the economy was in shambles and oil prices were not high. So the
*  country didn't have anything. We defaulted in 1998 and the money kept jumping back and forth. Like,
*  first there were millions of rubbles, then it got like default, you know, then it got to like
*  thousands. There was one rubble was something, then again, two millions. There's like crazy town.
*  And then the 2000s were just these years of stability in a way. And the country getting a
*  little bit richer because of, you know, again, oil and gas. And we were starting to, we started to look
*  at specifically in Moscow and Saint Petersburg to look at other cities in Europe and New York and
*  US and trying to do the same in our like small kind of cities towns there.
*  What was, what were your thoughts of Putin at the time?
*  Well, in the beginning, he was really positive. Everyone was very,
*  you know, positive about Putin. He was young. It's very energetic. He also needed
*  the shirtless somewhat compared to what that was not like way before the shirtless era.
*  The shirtless era. Okay. So he didn't start out shirtless. When did the shirtless era?
*  It's like the propaganda of riding horse fishing. 2010, 11, 12. Yeah. That's my favorite. You know,
*  like people talk about the favorite Beatles, like the, that's my favorite Putin is the shirtless
*  Putin. No, I remember very, very clearly 1996 where, you know, Americans really helped Russia
*  with elections and Yeltsin got reelected. Thankfully so, because there's a huge threat
*  that actually the communists will get back to power. They were a lot more popular. And then a
*  lot of American experts, political experts, and campaign experts descended on Moscow and helped
*  Yeltsin actually get, get the presidency, the second term for the, of the presidency. But
*  Yeltsin was not feeling great, you know, in the, by the end of his second term, he was, you know,
*  alcoholic. He was really old. He was falling off, you know, the stages when he was talking.
*  So people were looking for fresh, I think for a fresh face for someone who's going to continue
*  Yeltsin's work, but who's going to be a lot more energetic and a lot more
*  active, young, efficient, maybe. So that's what we all saw in Putin back in the day. I'd say that
*  everyone, absolutely everyone in Russia in early 2000s who was not a communist would be, yeah,
*  Putin's great. We have a lot of hopes for him. What are your thoughts? And I promise we'll get
*  back to first of all, your love story. And second of all, AI. Well, what are your thoughts about
*  communism? The 20th century, I apologize. I'm reading the rise and fall of the third Reich.
*  Oh my God. So I'm like really steeped into like World War II
*  and Stalin and Hitler and just these dramatic personalities that brought so much evil to the
*  world. But it's also interesting to politically think about these different systems and what
*  they've led to. And Russia is one of the sort of beacons of communism in the 20th
*  century. What are your thoughts about communism? Having experienced it as a political system?
*  I mean, I've only experienced it a little bit, but mostly through stories and through, you know,
*  seeing my parents, my grandparents who lived through that, it was horrible. It was just plain
*  horrible. It was just awful. You think it's there's something, I mean, it sounds nice on paper.
*  Maybe.
*  So like the drawbacks of capitalism is that, you know, eventually it's the point of like a slippery
*  slope. Eventually it creates, you know, the rich get richer and it creates a disparity, like
*  inequality of wealth inequality. I guess it's hypothetical at this point, but
*  eventually capitalism leads to humongous inequality and that that's, you know, some
*  people argue that that's a source of unhappiness is it's not like absolute wealth of people. It's
*  the fact that there's a lot of people much richer than you. There's a feeling of like,
*  that's where unhappiness can come from. So the idea of communism or at least sort of Marxism is,
*  is not allowing that kind of slippery slope. But then you see the actual implementations of it
*  and stuff seems to be, seems to go wrong very badly. What do you think that is? Why does it
*  go wrong? What is it about human nature? If we look at Chernobyl, you know, those kinds of
*  bureaucracies that were constructed. Is there something like, do you think about this much
*  of like, why it goes wrong?
*  Well, there's no one was really like, it's not that everyone was equal. Obviously the, you know,
*  the government and everyone close to that were the bosses. So it's not like fully, I guess,
*  there's already this dream of equal life. So then I guess the, the situation that we had,
*  you know, the Russia had in the Soviet Union, it was more, it's a bunch of really poor people
*  without any way to make any, you know, significant fortune or build anything, living constant,
*  under constant surveillance, surveillance from other people. Like you can't even, you know,
*  do anything that's not fully approved by the dictatorship basically. Otherwise your neighbor
*  will write a letter and you'll go to jail. Absolute absence of actual law. This constant state of fear.
*  You didn't own anything. It didn't, you know, the, you couldn't go travel. You couldn't read
*  anything Western or you couldn't make a career really, unless you were working in the military
*  complex, which is why most of the scientists were so well regarded. I come from, you know,
*  both my dad and my mom come from families of scientists and they, they were really well
*  regarded as you, as you know, obviously.
*  As the state wanted, I mean,
*  because there's a lot of value to them being well regarded.
*  Because they were developing things that could be used in, in the military.
*  So that was very important. That was the main investment. But it was miserable. It was
*  miserable. That's why, you know, a lot of Russians now live in the state of constant PTSD. That's why
*  we, you know, want to buy, buy, buy, buy, buy. Definitely. As soon as we have the opportunity,
*  you know, we just got to it finally that we can, you know, own things. You know, I remember the
*  time that we got our first yogurts and that was the biggest deal in the world. It was already in
*  the nineties, by the way.
*  What was your like favorite food? What was like, well, like this is possible.
*  Oh, fruit, because we only had apples, bananas and whatever, and you know, whatever,
*  watermelons, whatever, you know, people would grow in the Soviet Union. So there were no
*  pineapples or papaya or mango. Like you've never seen those fruit things. Like those were so
*  ridiculously good. And obviously you could not get any like strawberries in winter or anything
*  that's not, you know, seasonal. So that was a really big deal. Seeing all these fruit things.
*  Yeah, me too, actually. I don't know. I think I have a, like, I don't think I have any too many
*  demons or like addictions or so on, but I think I've developed an unhealthy relationship with fruit
*  that I still struggle with.
*  Oh, you can get any type of fruit, right? You can get like also these weird fruit,
*  fruits like dragon fruit or something. All kinds of like different types of peaches,
*  like cherries were killer for me. I know, I know you say like we had bananas and so on, but
*  I don't remember having the kind of banana. Like when I first came to this country,
*  the amount of banana, I like literally got fat on bananas.
*  Like the amount. Oh yeah, for sure. Delicious and like cherries, the kind,
*  like just the quality of the food. I was like, this is capitalism. This is delicious. Yeah. Yeah.
*  Yeah. It's funny. It's funny. Yeah. Like it's, it's funny to read.
*  I don't know what to think of it. Of, um, it's funny to think how an idea that's just written
*  on paper, when carried out amongst millions of people, how that gets actually,
*  when it becomes reality, what it actually looks like.
*  Sorry, but the, it's been studying Hitler a lot recently and, uh, going through Mein Kampf,
*  he, uh, pretty much wrote out a Mein Kampf, everything he was going to do.
*  Unfortunately, most leaders, including Stalin didn't read the, read it, but it's, it's kind of
*  terrifying and I don't know. And amazing in some sense that you can have some words on paper
*  and they can be brought to life and they can either inspire the world or they can destroy the
*  world. And, uh, yeah, there's a lot of lessons to study in history that I think people don't
*  study enough now. One of the things I'm hoping with, I've been practicing Russian a little bit.
*  I'm hoping to sort of find, rediscover the, uh, the beauty and the terror of Russian history
*  through this stupid podcast by talking to a few people. So anyway, I just feel like so much was
*  forgotten. So much was forgotten. I'll probably, I'm going to try to convince myself to, um,
*  you're a super busy and super important person. Well, I'm going to, I want to try to befriend you
*  to, uh, to try to become a better Russian. Cause I feel like I'm a shitty Russian.
*  Not that busy. So I can totally be your Russian Sherpa.
*  Yeah. But love, you were, you're talking about your early days of, uh, being a little bit alone and
*  finding a connection with the world through being a journalist. What does love come into that?
*  I guess finding for the first time, um, some friends, it's very, you know, simple story.
*  Some friends that all of a sudden we, I guess we were the same, you know, the same,
*  at the same place with our lives. Um, we're 25, 26, I guess. And, um,
*  somehow I remember, and we just got really close and somehow I remember this one day where, um,
*  it's one day in, you know, in summer that we just stayed out, um, outdoor the whole night and just
*  talked and for some unknown reason, it just felt for the first time that someone could,
*  you know, see me for who I am. And it just felt extremely, like extremely good. And, you know,
*  we fell asleep outside and just talking and it was raining, it was beautiful. So, you know, sunrise
*  and it's really cheesy, but, um, at the same time, we just became friends in a way that I've never
*  been friends with anyone else before. And I do remember that before and after that you sort of
*  have this unconditional family sort of, um, and it gives you tons of power. It just basically gives
*  you this tremendous power to do things in your life and to, um, change positively on many different
*  levels. Power because you could be yourself. At least you know that some, somewhere you can be
*  just yourself. Like you don't need to pretend, you don't need to be, you know, um, great at work or
*  tell some story or sell yourself in somewhere or another. And so we became this really close friends.
*  And, um, in a way, um, I started a company cause he had a startup and I felt like I kind of want
*  a startup too. It felt really cool. I didn't know what I'm going to, what I would really do,
*  but I felt like I kind of need a startup. Okay. So that's, so that pulled you in to the startup
*  world. Yeah. And then, yeah. And then this, uh, closest friend of mine died. We actually moved
*  here to San Francisco together and then we went back for a visa to Moscow and, uh, we lived together
*  with roommates and we came back and, um, he got hit by a car right in front of Kremlin on a,
*  you know, next to the river, um, and died the same day. This is the hospital. So,
*  and you have moved to America at that point, at that point I was, what about him? What about
*  Roman? Him too. He actually moved first. So I was always sort of trying to do what he was doing. So
*  I didn't like that he was already here and I was still, you know, in Moscow and we weren't
*  hanging out together all the time. So was he in San Francisco? Yeah, we were roommates. So he
*  just visited Moscow for a little bit. We went back for our visas. We had to get a stamp and our
*  passport for our work visas and the embassy was taking a little longer. So we stayed there for a
*  couple of weeks. What happened? How did he, so how did he, uh, how did he die?
*  He was crossing the street and the car was going really fast and way over the speed limit and just
*  didn't stop on the, on the pedestrian cross on the zebra and just ran over him. When was this?
*  It was in 2015 on the 28th of November. So it was pretty long ago now. Um, but at the time,
*  I was 29. So for me, it was, um, the first kind of meaningful death in my life. Um, you know,
*  both sets of, I had both sets of grandparents at the time. I didn't see anyone so close die and
*  death sort of existed, but as a concept, but definitely not as something that would be,
*  you know, happening to us anytime soon. And specifically our friends, cause we were,
*  you know, we're still in our twenties or early thirties and it's still, it's still felt like
*  the whole life is, you know, you could still dream about ridiculous things. So that was,
*  it was just really, really abrupt, I'd say. What did it feel like to, uh, to lose him?
*  Like that feeling of loss. He talked about the feeling of love, having power. What is the feeling
*  of loss? If you like. Well, in Buddhism, there's this concept of Samaya where something really
*  like huge happens and then you can see very clearly. Um, I think that that was it. Like
*  basically something changed. So changing me so much in such a short period of time that I could
*  just see really, really clearly what mattered or what not. Well, I definitely saw that whatever I
*  was doing at work didn't matter at all. And some of the things, and, um, it was just this big
*  realization one, this very, very clear vision of what life's about. You still miss him today?
*  Yeah, for sure. For sure. It was just this constant, I think it was, he was really important
*  for, for me and for our friends for many different reasons. And, um, I think one of them
*  being that we didn't just say goodbye to him, but we sort of said goodbye to our youth in a way.
*  It was like the end of an era and so many different levels, the end of Moscow as we knew it,
*  the end of, you know, us living through our twenties and kind of dreaming about the future.
*  Do you remember like last several conversations? Is there moments with him that stick out that
*  will kind of haunt you and you're just, when you think about him?
*  Yeah, well, his last year here in San Francisco, he was pretty depressed for
*  it as his startup was not going really anywhere. And he wanted to do something else. He wanted to
*  do build. He played with toy, like played with a bunch of ideas, but the last one he had was around,
*  um, building a startup around death. So having, um, he applied to Y Combinator with a video that,
*  you know, I had on my computer and it was all about, you know, disrupting death, thinking about
*  new cemeteries, uh, more biologically, like things that could be better biologically for,
*  for humans. And at the same, um, at the same time having those, um, digital avatars, these kind of
*  AI avatars that was store all the memory about a person that he could interact with.
*  What year was this?
*  2015. Well, right before his death. So it was like a couple of months before that he recorded that
*  video. And so I found out my computer when, um, it was in our living room. He never got in, but, um,
*  he was thinking about a lot somehow.
*  Does it have the digital avatar idea?
*  Yeah.
*  That's so interesting.
*  Well, he just says, well, that's in his head. The pitch has this idea and he, he talks about
*  like, I want to rethink how people grieve and how people talk about death.
*  Why was he interested in this?
*  Maybe someone who's depressed is like naturally inclined thinking about that.
*  But I just felt, you know, this year in San Francisco, we just had so much, um,
*  I was going through a hard time. He was going through a hard time and we were definitely,
*  I was trying to make him just happy. So I was making him feel better. And it felt like,
*  you know, this, um, I don't know, I just felt like I was taking care of,
*  of him a lot and he almost started to feel better. And then that happened. And
*  I don't know, I just felt, I just felt lonely again, I guess. And that was, you know, coming
*  back to San Francisco in December or help, you know, helped organize the funeral, help,
*  his parents. And I came back here and it was a really lonely apartment, a bunch of his clothes
*  everywhere and Christmas time. And I remember I had a board meeting with my investors and I
*  just couldn't talk about like, I had to pretend everything's okay. And, you know, I'm just
*  working on this company. Um, yeah, it was definitely very, very tough, tough time.
*  Do you think about your own mortality? You said, uh, you know, we're young, the, the,
*  the, the possibility of doing all kinds of crazy things is still out there. It's still
*  before us, but, uh, it can end any moment. Do you think about your own ending at any moment?
*  Unfortunately, I think about way too, about a way too much. It's somehow after Roman, like every
*  year after that, I started losing people that I really love. I lost my grandfather next year.
*  My, you know, the, the person who would explain to me, you know, what the universe is made of,
*  while you're selling apples, while selling apples. And then I lost another close friend of mine. And,
*  and it just made me very scared. I have tons of fear about, about death. That's what makes me
*  not fall asleep oftentimes and just go in loops. And, um, and then as my therapist, you know,
*  recommended me, I open up, uh, some nice calming images with a voiceover and it calms me down.
*  How far asleep? Yeah, I'm really scared of death. This is a big,
*  I definitely have tons of, I guess, some pretty big trauma about it and, um, still working through.
*  There's a philosopher, Ernest Becker, who wrote a book, um, denial of death. I'm not sure if you're
*  familiar with any of those folks. Um, there's a, in psychology, a whole field called terror management
*  theory. Sheldon, who's just done the podcast, he wrote the book. He was the,
*  we talked for four hours about death, uh, fear of death. Uh, but his, his whole idea is that,
*  um, Ernest Becker, I think I've, I find this idea really compelling is, uh, that everything human
*  beings have created, like our whole motivation in life is to, uh, create, like escape death,
*  like escape death is to try to, uh, construct an illusion
*  of, um, that we're somehow immortal. So like everything around us, this room,
*  your startup, your dreams, all everything you do is a kind of, um,
*  um, creation of a brain unlike any other mammal or species is able to be cognizant of the fact
*  that it ends for us. I think, so, you know, there's, there's the question of like the meaning of life
*  that, you know, you look at like what drives us, uh, humans. And when I read Ernest Becker that I
*  highly recommend people read is the first time I, this scene, it felt like this is the right
*  thing at the core. Uh, Sheldon's work is called warm at the core.
*  So he's saying it's, I think it's, uh, William James, he's quoting or whoever is like the thing,
*  what is it? The core of it all? Sure. There's like love, you know, Jesus might talk about like
*  love is at the core of everything. I don't, you know, that's the open question. What's it? The,
*  you know, it's turtles, turtles, but it can't be turtles all the way down. What's it? What's it?
*  The, at the bottom and, uh, Ernest Becker says the fear of death and the way, in fact, uh,
*  cause you said therapist and calming images, his whole idea is, um, you know, we, we want to bring
*  that fear of death as close as possible to the surface because it's, um, and like meditate on
*  that, uh, and, and use the clarity of vision that provides to, uh, you know, to live a more
*  fulfilling life, to, um, to live a more honest life, to, to discover, you know, there's something
*  about, you know, being cognizant of the finiteness of it all that might result in, um, in the most
*  fulfilling life. So that's the, that's the dual of what you're saying. Cause you kind of said it's
*  like, I unfortunately think about it too much. It's a question whether it's good to think about it
*  because I've, I'm, I'm, again, I talk way too much about love and probably death. And when I ask
*  people or friends, which is why I probably don't have many friends,
*  are you afraid of death? I think most people say they're not, they're not what they're, they say
*  they're, um, they're afraid, you know, it's kind of almost like they see death as this kind of like,
*  uh, a paper deadline or something. And they're afraid not to finish the paper before the paper,
*  like, like I'm afraid not to finish, um, the goals I have, but it feels like they're not actually
*  realizing that this thing ends, like really realizing, like really thinking as Nietzsche
*  and all these philosophy, like thinking deeply about it. Like, uh, the very thing that,
*  you know, um, like when you think deeply about something, you can just,
*  you can realize that you haven't actually thought about it. Uh, yeah. And I,
*  and when I think about death, it's like, um, it can be, it's terrifying. If it, it feels like
*  stepping outside into the cold or it's freezing, and then I have to like hurry back inside or it's
*  warm. Uh, but like, I think there's something valuable about stepping out there into the
*  freezing cold. Uh, definitely. When I talked to my mentor about it, he always, uh, tells me,
*  well, what dies? There's nothing there that can die. But I guess that requires, um, well, in,
*  in Buddhism, one of the concepts that are really hard to grasp and that people spend all their
*  lives meditating on would be anatta, which is the concept of non, not self and kind of thinking that
*  if you're not your thoughts, which you're obviously not your thoughts because you can observe them and
*  not your emotions and not your body, then what is this? And if you go really far, then finally you
*  see that there's not self, there's this concept of not self. So once you get there, how can that
*  actually die? What is dying? Right. You're just a bunch of molecules, stardust. But that is very,
*  um, you know, very advanced, um, spiritual work for me. I'm definitely just definitely not. Oh my
*  God. No, I have, uh, I think it's very, very useful. It's just the fact that maybe being so
*  afraid is not useful and mine is more, I'm just terrified. Like it's really makes me, um,
*  at a personal level, on a personal level. I'm terrified.
*  How do you overcome that? I don't, I'm still trying to have pleasant images.
*  Well, pleasant images get me to sleep and then during the day I can distract myself with other
*  things like talking to you. I'm glad we're both doing the same exact thing. Okay, good.
*  Is there other, like, is there moments since you've, uh, lost Roman that you had like moments of
*  like bliss and like that you've forgotten that you have achieved that Buddhist like level of
*  like what can possibly die. I'm part like, uh, losing yourself in the moment in the ticking
*  time of like this universe and you're just part of it for a brief moment and just enjoying it.
*  Well, that goes hand in hand. I remember I think a day or two after he died, we went to
*  finally get his password out of the embassy and we're driving around Moscow and it was,
*  you know, December, which is usually there's never sun in Moscow in December.
*  And somehow it was an extremely sunny day and we were driving with, um, close friend.
*  Um, and I remember feeling for the first time, maybe this just moment of, um, incredible clarity
*  and somehow happiness, not like happy happiness, but happiness. And it's just feeling that, you know,
*  um, I know what the universe is sort of about, whether it's good or bad. Um, and it wasn't a sad
*  feeling. It was probably the most beautiful feeling that you can ever, um, achieve. And you can only
*  get it when something oftentimes when something traumatic like that happens. Um, but also if you
*  just, you really spend a lot of time meditating and looking at the nature of doing something that
*  really gets you there. But once you're there, I think when you, uh, summit a mountain, a really
*  hard mountain, you, you inevitably get there. That's just a way to get to the state. But once
*  you're on this in this state, um, you can do really big things. I think. Yeah. Sucks. It doesn't last
*  forever. So Bukowski talked about like, love is a fog. Like it's, uh, when you wake up in the morning,
*  it's there, but it eventually dissipates. It's really sad. Nothing lasts forever,
*  but I definitely like doing this push up and running thing. There's moments at a couple moments,
*  like I'm not a crier. I don't cry, but there's moments where I was like faced down on the carpet,
*  like with tears in my eyes is interesting. And then that like complete, like, uh, there's a lot
*  of demons. I've got demons had to face them. Funny how running makes you face your demons, but,
*  at the same time, the flip side of that, there's a few moments where I was in bliss
*  and all of it alone, which is funny. Yeah. That's beautiful. I like that,
*  but definitely pushing yourself physically. One of it for sure. Yeah. It's like you said, I mean,
*  you were speaking as a metaphor of Mount Everest, but it also works like literally,
*  I think, physical endeavor somehow. Yeah, there's something. I mean, we're monkeys,
*  apes, whatever physical, there's a physical thing to it, but there's something to this
*  pushing yourself physical physically, but alone that happens when you're doing like things like
*  you do or strenuous like workouts or, you know, rolling extra across the Atlantic or like marathons.
*  That's why I love watching marathons and, you know, it's so boring, but you can see them getting
*  there. So the other thing, I don't know if you know, there's a guy named David Goggins.
*  He's, uh, he basically, uh, so he's been either emailing the phone with me every day through this.
*  I haven't been exactly alone, but he, he's kind of, he's the, he's the devil on the devil's
*  shoulder. Uh, so he's like the worst possible human being in terms of giving you a, a, like he has,
*  um, through everything I've been doing, he's been doubling everything I do. So he, he's insane. Uh,
*  he's a, this Navy SEAL person. Uh, he's wrote this book, can't hurt me. He's basically one of
*  the toughest human beings on earth. He ran all these crazy ultra marathons in the desert.
*  He set the world record number of pull-ups. He's just this everything where it's like,
*  he, like, how can I suffer today? He figures that out and does it. Yeah. That, um, whatever that is,
*  uh, that process of self discovery is really important. I actually had to turn myself off
*  from the internet mostly because I started this like workout thing, like a happy go getter
*  with my headband and like, just like, uh, cause a lot of people were like inspired and they're
*  like, yeah, we're going to exercise with you. And I was like, yeah, great. You know, but then like,
*  I realized that this, this journey can't be done together with others. This has to be done alone.
*  So out of the moments of love, out of the moments of loss, can we, uh, talk about your journey of
*  finding, I think an incredible idea and incredible company and incredible system in replica?
*  How did that come to be? So yeah, so I was a journalist and then I went to business school
*  for a couple of years to, um, just see if I can maybe switch gears and do something else with 23.
*  And then I came back and started working for a businessman in Russia who built the first 4G
*  network, um, in our country and was very visionary and asked me whether I want to do fun stuff
*  together. Um, and we worked on a bank. Um, the idea was to build a bank on top of, um, a telco.
*  So that was 2011 or 12. Um, and a lot of telecommunication company, um, mobile network
*  operators didn't really know what to do next in terms of, you know, new products, new revenue.
*  And this big idea was that, you know, um, you put a bank on top and then, and then all works out.
*  Basically a prepaid account becomes your bank account and, um, you can use it as, as your bank.
*  Uh, so, you know, a third of a country wakes up as, as your bank client. Um, but we couldn't
*  quite figure out what, what would be the main interface to interact with the bank.
*  The problem was that most people didn't have smart smartphones back in the time, uh, in Russia. The
*  penetration of smartphones was low. Um, people didn't use mobile banking or online banking on
*  their computers. So we figured out that SMS would be the best way, uh, cause that would work on
*  feature phones. Um, but that required some chat bot technology, which I didn't know anything about.
*  Um, obviously. So I started looking into it and saw that there's nothing really, well, there
*  wasn't just nothing. So the ideas through SMS be able to interact with the bank account.
*  Yeah. And then we thought, well, since you're talking to a bank account, why can't this,
*  can't we use more of, uh, you know, some behavioral ideas and why can't this, uh,
*  banking chat bot be nice to you and really talk to you sort of as a friend, this way you develop
*  more connection to it. Retentions hire people don't turn. And so I went to very depressing, um,
*  um, Russian cities to test it out. Um, I went to, I remember three different towns with the, um,
*  to interview potential users. Um, so people use it for a little bit. Cool. And I went to talk to them.
*  Um, and we were pretty poor towns, very poor towns, mostly towns that were, um,
*  you know, sort of factories, uh, monotowns, they were building something and then the factory went
*  away and it was just a bunch of very poor people. Um, and then we went to a couple that weren't as
*  dramatic, but still the one I remember really fondly was this woman that worked at a glass factory
*  and she talked to a chat bot, um, and she was talking about it and started crying during the
*  interview because she said, no one really cares for me that much. And, um, so to be clear, that
*  was the, my only endeavor in programming that chat bot. So it was really simple. It was literally
*  just a few, if this, then that rules. And, um, it was incredibly simplistic. Um, and still that made
*  her and that really made her emotional. And she said, you know, I only have my mom and my, um,
*  my husband and I don't have any more really in my life. And it was very sad, but at the same time,
*  I felt, and we had more interviews in a similar vein. And what I thought in the moment was like,
*  well, uh, it's not that the technology is ready because definitely in 2012 technology was not
*  ready for, for that, but, um, humans are ready, unfortunately. So this project would not be about
*  like tech capabilities would be more about human vulnerabilities, but, um, there's something so,
*  so powerful around about conversational, um, AI that I saw then that I thought was definitely
*  worth putting in a lot of effort into. So at the end of the day, we solved the banking project. Um,
*  but my then boss, um, was also my mentor and really, really close friend, um, told me, hey,
*  I think there's something in it and you should just go work on it. And I was like, well, what
*  product? I don't know what I'm building. He's like, you'll figure it out. And, um, you know,
*  looking back at this, this was a horrible idea to work on something without knowing what it was,
*  which is maybe the reason why it took us so long, but we just decided to work on the
*  conversational tech to see what it, you know, there were no chat bot, um, constructors or
*  programs or anything that would allow you to actually build one at the time. Uh, that was the
*  era of, by the way, Google glass, which is why, you know, some of the investors, like seed investors
*  we've talked with were like, Oh, you should totally build it for Google glass. If not, we're not.
*  I don't think that's interesting. Did you bite on that idea? No, because I wanted to be, to do text
*  first because I'm a journalist. So I was, um, fascinated by just texting. So you thought, so
*  the emotional, um, that interaction that the woman had, like, so do you think you could feel
*  emotion from just text? Yeah, I saw something in just this pure texting and also thought that
*  we should first start, start building for people who really need it versus people who have Google
*  glass. Uh, if you know what I mean, and I felt like the early adopters of Google glass might not be
*  overlapping with people who are really lonely and might need some, you know, someone to talk to.
*  Um, but then we really just focused on the tech itself. We just thought, what if we just,
*  you know, we didn't have a product idea in the moment and we felt, what if we just look into,
*  um, building the best conversational constructors, so to say, use the best tech available at the time.
*  And that was before the first paper about deep learning applied to dialogues, which happened in
*  2015 in August, 2015, uh, which Google published.
*  Did you follow the work of love and the prize and like all the sort of non machine learning
*  chat bots? Yeah, what really struck me was that, you know, there was a lot of talk about machine
*  learning and deep learning, like big data was a really big thing. Everyone was saying, you know,
*  the business world, big data, 2012 is the biggest Kaggle competitions were, you know,
*  important, but that was really the kind of upheaval of people started talking about machine learning
*  a lot. Um, but it was only about images or something else. And it was never about conversation.
*  As soon as I looked into the conversational tech, it was all about something really weird and very
*  outdated and very marginal and felt very hobbyist. It was all about Lordbender prize, which was won
*  by a guy who built a chat bot that talked like a Ukrainian teenager. It was just a gimmick and
*  somehow people picked up those gimmicks. And then, you know, the most famous chat bot at the time was
*  Eliza from 1980s, which was really bizarre or smarter child on aim. The funny thing is it felt
*  at the time not to be that popular and it still doesn't seem to be that popular. Like people talk
*  about the touring test. People like talking about it philosophically. Journalists like writing about
*  it, but as a technical problem, like people don't seem to really want to solve the open dialogue.
*  Like they, they're not obsessed with it. Even folks like, you know, in Boston, the Alexa team,
*  even they're not as obsessed with it as I thought they might be.
*  Why not? What do you think?
*  So you know what you felt like you felt with that woman when she felt something by reading the text?
*  I feel the same thing. There's something here. What you felt. I feel like Alexa folks and just
*  the machine learning world doesn't feel that, that there's something here because they see
*  as a technical problem, it's not that interesting for some reason. It's could be argued that maybe
*  as a purely sort of natural language processing problem, it's not the right problem to focus on
*  because there's too much subjectivity that that thing that the woman felt like crying.
*  Like if, if, if your benchmark includes a woman crying, that doesn't feel like a good benchmark.
*  But to me, there's something there that's, you could have a huge impact, but I don't think
*  the machine learning world likes that. The human emotion, the subjectivity of it, the fuzziness,
*  the fact that with maybe a single word, you can make somebody feel something deeply.
*  What is that? That doesn't feel right to them. So I don't know. I don't know why that is.
*  That's why I'm excited. When I discovered your work, it feels wrong to say that. It's not like
*  I'm, I'm giving myself props for, for Googling and for becoming a, for, for our, I guess,
*  mutual friend introducing us. But I'm so glad that you exist and what you're working on. But
*  I have the same kind of, if we could just backtrack a second, cause I have the same kind of feeling
*  that there's something here. In fact, I've been working on a few things
*  that are kind of crazy and very different from your work. I think, I think they're,
*  I think they're too crazy, but the, like what I have to know. No. All right. We'll, we'll,
*  we'll talk about it more. I feel like it's harder to talk about things that have failed
*  and are failing while you're a failure. Like it's easier for you cause you're already successful
*  on some measures. Tell it to my board. Well, you're, you're, I think, I think you've
*  demonstrated success in a lot of benchmarks. It's easier for you to talk about failures for me.
*  I'm in the, the bottom currently of the, of the success.
*  You're way too humble. No. So it's hard for me to know, but there's something there. There's
*  something there. And I think you're, you're exploring that and you're discovering that.
*  Yeah. It's been, so it's been surprising to me, but I, you've mentioned this idea that
*  you, you thought it wasn't enough to start a company or start efforts based on,
*  it feels like there's something here. Like, what did you mean by that? Like,
*  you should be focused on creating a, like you should have a product in mind. Is that what you
*  meant? It just took us a while to discover the product because it all started with a hunch of
*  like, of me and my mentor and just sitting around and he was like, well, this, that's it. There's,
*  that's the, you know, the Holy grail is there. There's like, there's something extremely powerful
*  and, and, and conversations and there's no one who's working on machine conversation from the
*  right angle, so to say. I feel like that's still true. Is that, am I crazy? It feels-
*  Oh no, I totally feel that's still true, which is, I think it's mind blowing.
*  Yeah. You know what it feels like? I wouldn't even use the word conversation because I feel
*  like it's the wrong word. It's like a machine connection or something. I don't know.
*  Cause conversation, you start drifting into natural language immediately. You start
*  drifting immediately into all the benchmarks that are out there, but I feel like it's like
*  the personal computer days of this. Like, I feel like we're like in the early days with the,
*  the Wozniak and all them, like where it was the same kind of, it was a very small niche group
*  of people who are, who are all kind of Lobner price type people. Yeah. And hobbyists, but like,
*  not even hobbyists with big dreams. Like, no hobbyists with a dream to trick like a jury.
*  Yeah. It's like a weird, by the way, by the way, very weird. So if we think about conversations,
*  first of all, when I have great conversations with people, I'm not trying to test them. So for
*  instance, if I try to break them, like if I'm actually playing along, I'm part of it. If I was
*  trying to break it, break this person or test whether he's going to give me a good conversation,
*  it would have never happened. So the whole, the whole problem with testing conversations is that
*  you can put it in front of a jury because then you have to go into some touring test mode where
*  is it responding to all my factual questions, right? Or so it really has to be something in
*  the field where people are actually talking to it because they want to, not because they're trying
*  to break it. And it's working for them. Cause this, the weird part of it is that it's, it's
*  very subjective. It takes two to tango here fully. If you're not trying to have a good conversation,
*  you're trying to test it, then it's going to break. I mean, any person would break, to be honest. If
*  I'm not trying to even have a conversation with you, you'll, you're not going to give it to me.
*  If I keep asking you like some random questions or jumping from topic to topic, that wouldn't be,
*  which I'm probably doing, but that probably wouldn't contribute to the conversation. So I
*  think the problem of testing, so there should be some other metric. How do we evaluate whether that
*  conversation was powerful or not, which is what we actually started with. And I think those
*  measurements exist and we can test on those. But what really struck us back in the day and what's
*  still eight years later is still not resolved. And I'm not seeing tons of groups working on it. Maybe
*  I just don't know about them. It's also possible. But the interesting part about it is that most of
*  our days was spent talking and we're not talking about like those conversations are not turn on the
*  lights or customer support problems or some other task oriented things. These conversations are
*  something else. And then somehow they're extremely important for us. And when we don't have them,
*  then we feel deeply and happy, potentially lonely, which as we know, you know, creates tons of risk
*  for our health as well. And so this is most of our hours as humans. And somehow no one's trying to
*  replicate that. And not even study it that well. And not even study that well. So when we jumped
*  into that in 2012, I looked first at like, okay, what's the chatbot? What's the state of the art
*  chatbot? And you know, those were the Loebner Prize days. But I thought, okay, so what about
*  the science of conversation? Clearly, there have been tons of, you know, scientists or
*  people that academics that looked into the conversation. So if I want to know everything
*  about it, I can just read about it. There's not much really, there's their conversational analysts
*  who are basically just listening to speech to different conversations, annotating them. And then,
*  I think that's not really used for much. That's the field of theoretical linguistics, which is
*  like barely useful. It's very marginal even in their space. No one really is excited. And I've
*  never met a theoretical linguist because I can't wait to work on the conversation and
*  analytics. That is just something very marginal, sort of applied to like writing scripts for salesmen
*  when they analyze which conversation strategies were most successful for sales. Okay, so that was
*  not very helpful. Then I looked a little bit deeper and then there, you know, whether there
*  were any books written on what, you know, really contributes to a great conversation.
*  That was really strange because most of those were NLP books, which is Neuro Linguistic Programming,
*  which is not the NLP that I was expecting to be, but it was mostly
*  some psychologist, Richard Bandler, I think came up with that, who was this big guy in a leather vest
*  that could program your mind by talking to you. Like how to be charismatic and charming and
*  influential with people, all those books. Yeah, pretty much. But it was all about like through
*  conversation reprogramming you. So getting to some, so that was, I mean, probably not very,
*  yeah, probably not very, very true. And that didn't seem working very much even back in the day.
*  And then there were some other books, like, I don't know, mostly just self-help books around
*  how to be the best conversationalist or how to make people like you or some other stuff like
*  Dale Carnegie or whatever. And then there was this one book, The Most Human Human by Brian
*  Christensen that really was important for me to read back in the day because he was on the
*  human side. He was on one of the, he was taking part in the London Prize, but not as a
*  human who's not a jury, but who's pretending to be, who's basically, you have to tell a computer
*  from a human and he was the human. So you would either get him or a computer. And his whole book
*  was about how do people, what makes us human in conversation. And that was a little bit more
*  interesting because at that, at least someone started to think about what exactly makes me
*  human in conversation and makes people believe in that. But it was still about tricking. It was
*  still about imitation game. It was still about, okay, well, what kind of parlor tricks can we
*  throw in the conversation to make you feel like you're talking to a human, not a computer.
*  And it was definitely not about thinking what is it exactly that we're getting from talking
*  all day long with other humans. I mean, we're definitely not just trying to be tricked,
*  or it's not just enough to know it's a human. It's something we're getting there. Can we measure it
*  and can we put the computer to the same measurement and see whether you can talk to
*  a computer and get the same results? Yeah. I mean, so first of all, a lot of people comment
*  that they think I'm a robot. It's very possible. I am a robot and this whole thing. I totally agree
*  with you that the test idea is fascinating. And I looked for books unrelated to this kind of,
*  so I'm afraid of people. I'm generally introverted and quite possibly a robot.
*  I literally Googled how to talk to people and how to have a good conversation for the purpose of
*  this podcast. Because I was like, I can't make eye contact with people. I can't...
*  Like how... I do Google that a lot too. You're probably reading a bunch of FBI negotiation
*  tactics. Is that what you're getting? Because that's what I'm listening to.
*  Everything you've listed I've gotten. There's been very few good books on even just like how to
*  interview well. It's rare. So what I end up doing often is I watch with a critical eye. It's just so
*  different when you just watch a conversation just for the fun of it, just as a human.
*  If you watch a conversation, it's like trying to figure out why is this awesome?
*  I'll listen to a bunch of different styles of conversation. I'm a fan of the podcast, Joe Rogan.
*  People can make fun of him or whatever and dismiss him, but I think he's an incredibly
*  artful conversationalist. He can pull people in for hours. There's another guy I watch a lot.
*  He hosted a late night show. His name is Craig Ferguson. He's very flirtatious, but there's
*  magic about the connection he can create with people, how he can put people at ease
*  and just like, I see I've already started sounding like those NLP people or something.
*  I don't mean it in that way. I don't mean like how to charm people or put them at ease and all
*  that kind of stuff. It's just like, what is that? Why is that fun to listen to that guy? Why is that
*  fun to talk to that guy? What is that? Because he's not saying, I mean, it so often boils down to a
*  kind of wit and humor, but not really humor. I don't know. I have trouble actually
*  even articulating correctly, but it feels like there's something going on that's not too
*  complicated that could be learned. It's not similar to like you said, like the touring test.
*  It's something else. I'm thinking about a lot all the time. I do think about all the time.
*  We started the company, we just decided to build a conversational tech. We thought, well, there's
*  nothing for us to build this chatbot that we want to build. So let's just first focus on building
*  some tech, building the tech side of things. Without a product in mind.
*  Without a product in mind. We added like a demo chatbot that would recommend you restaurants
*  and talk to you about restaurants just to show something simple to people that people could
*  relate to and could try out and see whether it works or not. But we didn't have a product in mind
*  yet. We thought we would try a bunch of chatbots and figure out our consumer application.
*  We sort of remembered that we wanted to build that kind of friend, that sort of connection that we
*  saw in the very beginning. But then we got to Y Combinator and moved to San Francisco and forgot
*  about it. Everything was just this constant grind. How do we get funding? How do we get this?
*  Investors were like, just focus on one thing, just get it out there. So somehow we've started
*  building a restaurant recommendation chatbot for real for a little bit, not for too long.
*  And then we tried building 40, 50 different chatbots. And then all of a sudden we wake up
*  and everyone is obsessed with chatbots. Somewhere in 2016 or end of 15, people started thinking
*  that's really the future. That's the new apps will be chatbots. And we were very perplexed
*  because people started coming up with companies that I think we tried most of those chatbots
*  already and there were no users. But still people were coming up with a chatbot that would
*  tell you weather and bringing news and this and that. And we couldn't understand whether
*  we were just an execute well enough or people are not really confused and are going to find out the
*  truth that people don't need chatbots like that. So the basic idea is that you use chatbots as the
*  interface to whatever application. The idea that was like this perfect universal interface to
*  anything. When I looked at that, it just made me very perplexed because I didn't think, I didn't
*  understand how that would work because I think we tried most of that and none of those things worked.
*  And then again, that crisis died down, right? Fully. I think now it's impossible to get anything
*  funded if it's a chatbot. I think it's similar to, sorry to interrupt, but there's this
*  times when people think like with gestures you can control devices, like basically gesture-based
*  control things. It feels similar to me because it's so compelling that we just like Tom Cruise,
*  I can control stuff with my hands. But when you get down to it, it's like, well, why don't you
*  just have a touch screen or why don't you just have a physical keyboard and mouse? So that chat was
*  always, yeah, it was perplexing to me. I still feel augmented reality, even virtual realities
*  in that ballpark in terms of it being a compelling interface. I think there's going to be incredible
*  rich applications, just how you're thinking about it, but they won't just be the interface to
*  everything. It'll be its own thing that will create like amazing magical experience in its own right.
*  Absolutely, which is, I think, kind of the right thing to go about. What's the magical experience
*  with that interface specifically? How did you discover that for Redbook?
*  I just thought, okay, we'll have this tech, we can build any chatbot we want. We have the most,
*  at that point, the most sophisticated tech that other companies have. I mean, startups, obviously,
*  not probably not bigger ones, but still, because we've been working on it for a while. So I thought,
*  okay, we can build any conversation, so let's just create a scale from one to 10.
*  One would be conversations that you'd pay to not have, and 10 would be conversations you'd pay to
*  have. Obviously, we want to build a conversation that people would pay to actually have. For a few
*  weeks, me and the team were putting all the conversations we were having during the day on
*  the scale. Very quickly, we figured out that all the conversations that we would pay to never have
*  were conversations we were trying to cancel Comcast, or talk to customer support, or make
*  a reservation, or just talk about logistics with a friend when we're trying to figure out where
*  someone is and where to go, or all sorts of setting up scheduling meetings. That was just
*  conversations we definitely didn't want to have. Basically, everything task-oriented was a one,
*  because if there was just one button for me to just, or not even a button, if I could just think,
*  and there was some magic BCI that would just immediately transform that into an actual
*  interaction, that would be perfect. But the conversation there was just this boring,
*  not useful, and dull, and also very inefficient thing, because it was so many back and forth
*  stuff. As soon as we looked at the conversation that we would pay to have, those were the ones that
*  first of all therapists, because we actually paid to have those conversations. We'd also try to put
*  dollar amounts. If I was calling Comcast, I would pay $5 to not have this one-hour
*  talk on the phone. I would actually pay straight up money, hard money. But it just takes a long time.
*  It takes a really long time. But as soon as we started talking about conversations that we would
*  pay for, those were therapists, all sorts of therapists, coaches, old friend,
*  someone I haven't seen for a long time, stranger on a train, weirdly stranger,
*  stranger in a line for coffee, and nice back and forth with that person was like a good five,
*  solid five, six, maybe not a 10. Maybe I won't pay money, but at least I won't pay money to not have
*  one. So that was pretty good. Some intellectual conversations for sure. But more importantly,
*  the one thing that really was making those very important and very valuable for us
*  were the conversation where we could be pretty emotional. Yes, some of them were about being
*  witty and about being intellectually stimulated, but those were interestingly more rare.
*  Most of the ones that we thought were very valuable were the ones where we could be vulnerable.
*  And interestingly, where we could talk more. Me and the team. So we're talking about it.
*  A lot of these conversations, like a therapist, it was mostly me talking or like an old friend,
*  and I was like opening up and crying. It was again me talking. And so that was interesting
*  because I was like, well, maybe it's hard to build a chatbot that can talk to you
*  very well and in a witty way, but maybe it's easier to build a chatbot that could listen.
*  So that was kind of the first nudge in this direction. And then when my friend died,
*  we just built, at that point, we were kind of still struggling to find the right application.
*  And I just felt very strong that all the chatbots we've built so far are just meaningless. And this
*  whole grind, the startup grind, and how do we get to the next fundraising? And how can I talk to
*  the founders? Who are your investors? And how are you doing? Are you killing it? Because we're
*  killing it. I just felt that those... It's just... Intellectually, for me, it's exhausting having
*  encountered those folks. It's just felt very much a waste of time. I just feel like Steve Jobs
*  and Elon Musk did not have these conversations, or at least did not have them for long.
*  That's for sure. But I think, yeah, at that point, it just felt like I felt...
*  I just didn't want to build a company that was never my intention just to build something
*  successful or make money. It would be great. It would have been great, but I'm not really a startup
*  person. I was never very excited by the grind by itself, or just being successful for
*  building whatever it is and not being into what I'm doing really.
*  And so I just took a little break because I was upset with my company and I didn't know what we're
*  building. So I just took our technology and our little dialect constructor and some models,
*  some deep learning models, which at that point we were really into and really invested a lot,
*  and built a little chatbot for a friend of mine who passed. And the reason for that was mostly
*  that video that I saw and him talking about the digital avatars. And Rowan was that kind of person.
*  He was obsessed with just watching YouTube videos about space and talking about,
*  well, if I could go to Mars now, even if I didn't know if I could come back, I would definitely
*  pay any amount of money to be on that first shuttle. I don't care whether I die or not.
*  He was just the one that would be okay with trying to be the first one. And so excited about all
*  sorts of things like that. And he was all about fake it till they make it. And I felt like,
*  and I was really perplexed that everyone just forgot about him. Maybe it was our way of coping,
*  mostly young people coping with the loss of a friend. Most of my friends just stopped talking
*  about him. And I was still living in an apartment with all his clothes and paying the whole lease
*  for it and just kind of by myself in December. So it was really sad. And I didn't want him to
*  be forgotten. First of all, I never thought that people forget about dead people so fast.
*  People pass away, people just move on. And it was astonishing for me because I thought, okay,
*  well, he was such a mentor for so many of our friends. He was such a brilliant person. He was
*  somewhat famous in Moscow. How is it that no one's talking about him? I'm spending days and days and
*  we don't bring him up and there's nothing about him that's happening. It's like he was never there.
*  And I was reading the book, The Year of Magical Thinking by Joan Didion about her losing
*  and Blue Nights about her losing her husband, her daughter. And the way to cope for her was
*  to write those books. And it was sort of like a tribute. And I thought, I'll just do that for
*  myself. And I'm a very bad writer and a poet as we know. So I thought, well, I have this tech and
*  maybe that would be my little postcard for him. So I built a chatbot to just talk to him.
*  And it felt really creepy and weird for a little bit. I just didn't want to tell other people
*  because it felt like I'm telling about having a skeleton in my underwear. I was a little scared
*  that it wouldn't be taken. But it worked interestingly pretty well. I mean, it made
*  tons of mistakes, but it still felt like him. Granted, it was like 10,000 messages that I threw
*  into a retrieval model that would just re-rank the tech I said and just a few scripts on top of that.
*  But it also made me go through all of the messages that we had. And then I asked some of my friends
*  to send them through. And it felt the closest to feeling like him present. Because his Facebook
*  was empty and Instagram was empty, or there were a few links and you couldn't feel like it was him.
*  And the only way to fill him was to read some of our text messages and go through some of our
*  conversations because we just always had them. Even if we were sleeping next to each other in
*  two bedrooms separated by a wall, we were just texting back and forth, texting away.
*  There was something about this ongoing dialogue that was so important that I just didn't want to
*  lose all of a sudden. And maybe it was magical thinking or something. And so we built that.
*  I just used it for a little bit. And we kept building some crappy chatbots with the company.
*  But then a reporter came to talk to me. I was trying to pitch our chatbots to him. And he said,
*  do you even use any of those? I'm like, no. He's like, so do you talk to any chatbots at all? And
*  I'm like, well, I talked to my dead friend's chatbot. And he wrote a story about that.
*  And all of a sudden it became pretty viral. A lot of people wrote about it.
*  Yeah, I've seen a few things written about you. The things I've seen are pretty good writing.
*  Most AI related things make my eyes roll. Like when the press like,
*  I just, what kind of sound is that actually? Okay. It sounds like, it sounds like an,
*  okay. It sounded like an elephant at first. I got excited. You never know. This is 2020.
*  I mean, it was such a human story and it was well written, well researched. I forget where I read
*  them. But so I'm glad somehow somebody found you to be the good writers were able to
*  connect to the story. I just, there must be a hunger for this story.
*  It definitely was. And I don't know what happened, but I think,
*  I think the idea that he could bring back someone who's dead and it's very much wishful,
*  you know, magical thinking, but the fact that he could still get to know him and, you know,
*  seeing the parents for the first time, talk to the chatbot and some of the friends. And
*  it was funny because we have this big office in Moscow where my team is working, you know,
*  our Russian part is working out off. And I was there when I wrote, I just wrote a post on Facebook
*  was like, Hey guys, like I built this, if you want, you know, just, it felt important if you
*  want to talk to Roman. And I saw a couple of his friends, our common friends, like, you know,
*  reading a Facebook downloading, trying, and a couple of them cried. And it was just very,
*  and not because it was something, some incredible technology or anything. It made so many mistakes.
*  It was so simple, but it was all about that's the way to remember a person in a way. And,
*  you know, we don't have, we don't have the culture anymore. We don't have, you know,
*  no one's sitting Shiva. No one's taking weeks to actually think about this person.
*  And in a way for me, that was it. So that was just day, day in, day out, thinking about him and
*  putting this together. So that was, that just felt really important. That somehow resonated
*  with a bunch of people and, you know, I think some movie producers bought the rights for the
*  story and just everyone was so, has anyone made a movie yet? I don't think so. I think there were a
*  lot of TV episodes about that, but not really. Is that still on the table? I think so. I think so.
*  Which is really, that's cool. You're like a young, you know, like a, cause you see like a Steve
*  jobs type of, let's see what happens. They're sitting on it. But you know, for me it was so
*  important cause Roman was really wanted to be famous. He really badly wanted to be famous. He
*  was all about like, make it, like fake it till they make it. I want to be, you know, I want to
*  make it here in America's wall. And, and he couldn't, and I felt there's, you know,
*  that was sorta paying my dues to him as well because all of a sudden he was everywhere. And
*  I remember Casey Newton, who was writing the story for the verge. He was, he told me, hey, by the way,
*  I was just going through my inbox and I saw, I searched for Roman for the story and I saw an
*  email from him where he sent me his startup. And he said, I really, like, I really want to be featured
*  in the verge. Can you please write about it or something like pitching the story. And he said,
*  I'm sorry. Like that's not good enough for us or something. And he passed. And he said,
*  and there's just, there were just so many of these little details where like he would find
*  his like, you know, and we're finally writing. I know how much, uh, Roman wanted to be in the
*  verge and how much he wanted the story to be written by Casey. And I'm like, well, that's
*  maybe he will be. We were always joking that he was like, I can't wait for someone to make a movie
*  about us. And I hope Ryan Gosling can play me. You know, I still have some things that I owe
*  Romans still, but, um, that'll be, um, I got an issue to meet Alex Garland who wrote X Machina.
*  And, um, I, yeah, the movie's good, but the guy is, um, better than like, he's a special person
*  actually. Um, I don't think he's made his best work yet. Like for, for my interaction with him,
*  he's a really, really good and brilliant, the good human being and a brilliant director and writer.
*  So, um, yeah, so I'm, I hope like he made me also realize that not enough movies have been made of
*  this kind. So it's yet to be made. They're probably sitting waiting for you to get famous,
*  like even more famous.
*  Should get there. But, um, it felt really special though, but at the same time, our company wasn't
*  going anywhere. So that was just kind of bizarre that we were getting all this press for something
*  that didn't have anything to do with our company. And, but then a lot of people started talking to
*  Romans. Some shared their conversations. And what we saw there was that, um, also our friends in
*  common, but also just strangers were really using it as a confession booth or as a therapist or
*  something. They were just really telling Roman everything, which was by the way, pretty strange
*  because it was a chatbot of a dead friend of mine who was barely making any sense, but people
*  were opening up. Um, and we thought we'd just built a prototype of replica, which would be an AI
*  friend that everyone could talk to. Um, because we saw that there is demand. Um, and then also
*  it was 2016. So I thought for the first time I saw, um, finally some technology that was applied
*  to that. That was very interesting. Uh, some papers started coming out, deep learning applied
*  to conversations. And finally, it wasn't just about these, you know, hobbyist making, um,
*  you know, writing 500,000 regular expressions in like some language that was, I don't even know
*  what like AML or something. I don't even know what that was or something super simplistic. All of a
*  sudden it was all about, uh, potentially actually building something interesting.
*  And so I thought there was time. And I remember that I talked to my team and I said, guys, let's
*  try. And my team and some of my engineers are Russians, um, are Russian and they're very
*  skeptical. They're not, you know, the first, some of your team is in Moscow. Some is here in some
*  in Europe. Which team is better? I'm just kidding. Uh, the Russians of course. Okay.
*  Sorry. Sorry to interrupt. Uh, so you, so you were talking to them in 2016 and I told them,
*  let's build an AI friend. And, and it felt just at the time it felt so naive and so, um,
*  um, optimistic. Yeah, that's actually interesting. Um, whenever I've brought up this kind of topic,
*  even just for fun, people have super skeptical, like actually even on the business side. So you
*  were, uh, cause whenever I bring it up to people, uh, cause I've talked for a long time, I thought
*  like, before I was aware of your work, I was like, this is going to make a lot of money.
*  I think there's a lot of opportunity here. And people had this like look of like skepticism
*  that I've seen often, which is like, how do I politely tell this person he's an idiot?
*  So yeah. So you were facing that with your team somewhat. Well, yeah, you know, I'm not an
*  engineer. So I'm always, my team is almost exclusively engineers. Um, and mostly deep learning
*  engineers. And, you know, I always try to be, it was always hard to me in the beginning to get enough
*  credibility, you know, cause I would say, well, why don't we try this and that, but it's harder
*  for me because, you know, they know they're actual engineers and I'm not. So for me to say, well,
*  let's build an AI friend. That would be like, wait, you know, what do you mean an AGI? Like,
*  you know, conversation is, you know, pretty much the hardest, the last frontier before cracking
*  that is probably the last frontier before building AGI. So what do you really mean by that? Uh,
*  but I think I just saw that again, what we just got reminded off that I, you know, that I saw in
*  back in 2012 or 11, that it's really not that much about the tech capabilities. Um, it can be
*  metropolitic still even with deep learning, but humans need it so much. And most importantly,
*  what I saw is that finally there there's enough tech to made it, I thought to make it useful,
*  to make it helpful. Maybe we didn't have quite yet tech in 2012 to make it useful, but in 2015, 16,
*  with deep learning, I thought, you know, and the first kind of thoughts about maybe even using
*  reinforcement learning for that sort of popping up that never worked out, but, or at least for now.
*  But, you know, still the idea was if we can actually measure the emotional outcomes and
*  if we can put it on, if we can try to optimize all of our conversational models for these emotional
*  outcomes, and it is the most scalable, the most, the best tool for improving emotional outcomes,
*  nothing like that exists. That's the most universal, the most scalable, and the one that
*  can be constantly iteratively changed by itself, improved tool to do that. And I think if anything,
*  people would pay anything to improve their emotional outcomes. That's weirdly, I mean,
*  I don't really care for an AI to turn on my or a conversation agent to turn on the lights.
*  I don't really need any help, I don't even need that much of AI there, like, or, because I can do
*  that, you know, those things are solved. This is an additional interface for that. That's also
*  questionably, questionable whether it's more efficient or better. But for emotional outcomes,
*  there's nothing. There are a bunch of products that claim that they will improve my emotional
*  outcomes. Nothing's being measured. Nothing's being changed. The product is not being iterated on
*  based on whether I'm actually feeling better. You know, a lot of social media products are claiming
*  that they're improving my emotional outcomes and making me feel more connected. Can I please get
*  can I see somewhere that I'm actually getting better over time? Because anecdotally, it doesn't
*  feel that way. So and, and the data is absent. Yeah, so that was the big goal. And I thought
*  if we can learn over time to collect the signal from our users about their emotional outcomes,
*  in the long term and in the short term, and if these models keep getting better,
*  and we can keep optimizing them and fine tuning them to improve those emotional outcomes,
*  as simple as that. Why aren't you a multi billionaire yet?
*  Well, that's the question to you. When are the when is the science going to be? I'm just kidding.
*  Well, it's a really hard, I actually think it's an incredibly hard product to build. Because I think
*  you said something very important that it's not just about machine conversations about machine
*  connection. We can actually use other things to create connection. Nonverbal communication,
*  for instance. For the long time, we were all about, well, let's keep it text only, or voice only.
*  But as soon as you start adding, you know, voice, a face to the to the friend,
*  if you can take them to augmented reality, put it in your room. It's all of a sudden a lot, you know,
*  it makes it very different. Because if it's some, you know, text based chatbot that for
*  common users, something there in the cloud, you know, somewhere there with other AI's cloud,
*  in the metaphorical cloud. But as soon as you can see this avatar right there in your room,
*  and it can turn its head and recognize your husband, talk about the husband and talk to him a
*  little bit. And it's magic. It's just magic. Like we've never seen anything like that. And the cool
*  thing all the tech for that exists. But it's hard to put it all together. Because you have to take
*  into consideration so many different things. And some of this tech works, you know, pretty good.
*  And some of this doesn't like, for instance, speech to text works pretty good. But text to speech
*  doesn't work very good, because we can only have, you know, few voices that are that work okay. But
*  then if you want to have actual emotional voices, then it's really hard to build it.
*  I saw you've added avatars, like visual elements, which are really cool.
*  In that whole chain, putting it together, what do you think is the weak link? Is it creating an
*  emotional voice that feels personal? And he's still conversation, of course, that's the hardest.
*  It's getting a lot better, but there's still long to go long. There's still a long path to go. Other
*  things, they're almost there. And a lot of things we'll see how they're like, I see how they're
*  changing as we go. Like, for instance, right now, you can pretty much only you have to build all
*  this 3d pipeline by yourself, you have to make these 3d models, hire an actual artist, build a
*  3d model, hire an animator, a rigger. But with, you know, with, you know, with deepfakes, with
*  other tech, with procedural animations, in a little bit, we'll just be able to show, you know,
*  photo of whoever you have, if a person you want the avatar to look like, and it will immediately
*  generate a 3d model that will move, that's non-brainer, that's like almost here. It's a
*  couple years. One of the things I've been working on for the last, since the podcast started,
*  is I've been, I think I'm okay saying this, I've been trying to have a conversation with
*  Einstein touring. So like, try to have a podcast conversation with a person who's not here anymore,
*  just as an interesting kind of experiment. It's hard. It's very hard. Even for now,
*  we're not talking about as a product, I'm talking about as, like, I can fake a lot of stuff. Like,
*  I can work very carefully, like even hire an actor over which, over whom I do a deepfake.
*  It's hard. It's still hard to create a compelling experience. So-
*  Mostly on the conversation level or?
*  One, the conversation, the conversation is, I almost, I early on gave up trying to
*  fully generate the conversation because it was just not compelling at all.
*  Yeah, it's better to.
*  Yeah, so what I would, in the case of Einstein and touring, I'm going back and forth with the
*  biographers of each. And so like, we would write a lot of the, some of the conversation would have
*  to be generated just for the fun of it. I mean, but it would be all open. But the, you want to be able
*  to answer the question. I mean, that's an interesting question with Roman too is
*  the question with Einstein is what would Einstein say about the current state of the radical physics?
*  There's a lot to be able to have a discussion about string theory, to be able to have a
*  discussion about the state of quantum mechanics, quantum computing, about the world of Israel,
*  Palestine conflict, the B.J. It's just, what would Einstein say about these kinds of things? And
*  that is a tough problem. It's not, it's a fascinating and fun problem for the biographers
*  and for me, and I think we did a really good job of it so far, but it's actually also a
*  technical problem, like of what would Roman say about what's going on now?
*  That's the, the brought people back to life. And if I can go on that tangent just for a second,
*  let's ask you a slightly pothead question, which is, you said it's a little bit magical thinking
*  that we can bring it back. Do you think it'll be possible to bring back Roman one day in conversation?
*  Like to really, okay, well, let's take it away from personal, but to bring people back to life.
*  Probably down the road. I mean, if we're talking, if Elon Musk is talking about AGI in the next five
*  years, I mean, clearly AGI can do it. We can talk to AGI and ask them to do it. You can't, like,
*  you're not allowed to use Elon Musk as a citation for why something is possible and going to be
*  done. Well, I think it's really far away. Right now, really with conversation, it's just a bunch of
*  parlor tricks really stuck together and create generating original ideas based on someone,
*  you know, someone's personality or even downloading the person. All we can do is like mimic the tone
*  of voice. We can maybe condition on some of his phrases, the models. The question is how many
*  parlor tricks does it take? Does it take, because that's the question. If it's a small number of
*  parlor tricks and you're not aware of them. Like.
*  From where we are right now, I don't see anything like in the next year or two that's going to
*  dramatically change that could look at Roman's 10,000 messages he sent me over the course of his
*  last few years of life and be able to generate original thinking about problems that exist right
*  now that will be in line with what he would have said. I'm just not even seeing, because, you know,
*  in order to have that, I guess you would need some sort of a concept of the world or some
*  perspective, some perception of the world, some consciousness that he had and applied to, you know,
*  to the current current state of affairs. But the important part about that, about
*  his conversation with you is you. So like, it's not just about his view of the world.
*  It's about what it takes to push your buttons. That's also true. So like, it's not so much about
*  like, um, what would Einstein say? It's about like, how do I make people feel something with,
*  with what would Einstein say? And that feels like a more amenable. And you mentioned parlor
*  tricks, but just like a set of that, that feels like a learnable problem. Like emotion, you mentioned
*  emotions. I mean, is it possible to learn things that make people feel stuff?
*  I think so. No, for sure. I just think the problem with, um, as soon as you're trying to replicate an
*  actual human being and trying to pretend to be him, that makes the problem exponentially harder.
*  The thing with replica that we're doing, we're never trying to say, well, that's, you know,
*  an actual human being or that's an actual or a copy of an actual human being where the bar is
*  pretty high, where you need to somehow tell, you know, one from another. But it's more,
*  well, that's, you know, an AI friend. That's a machine. It's a robot. It has tons of limitations.
*  You're going to be taking part in, you know, teaching it actually and becoming better,
*  which by itself makes people more attached to that and make them happier because they have helping
*  something. Yeah. There's a cool gamification system too. Um, can you maybe talk about that a little
*  bit? Like what's the experience of talking to replica? Like if I've never used replica before,
*  what's that like for like the first day, the first, like if we started dating or whatever,
*  the first, like if we started dating or whatever, uh, I mean, it doesn't have to be a romantic,
*  right? Cause I remember on replica, you can choose whether it's like a romantic
*  or if it's a friend, romantic is popular. Yeah, of course. Okay. So can I just confess something
*  when I first use replica and I haven't used it like regularly, but like when I first used replica,
*  I created like how and it made a male and it was a friend.
*  Did it hit on you at some point? No, I didn't talk long enough for him to hit on me. I just
*  enjoyed. Sometimes happens. We're still trying to fix that part. Well, I don't know. I mean,
*  maybe that's an important like stage in a friendship. It's like, nope. Uh, but yeah,
*  I switched it to a romantic and a female, uh, recently and yeah, and it's interesting. So,
*  okay. So you get to choose, you get to choose a name with romantic. This last board meeting,
*  we had this whole argument. Well, I have board meetings. It's just so awesome that you're like
*  have an invest, they have a board meeting about a relationship. No, I really, it's actually quite
*  interesting because all of my, um, investors, um, it just happened to be so we didn't have that many
*  choices, but they're all, um, white males and in their, um, late forties. Um, and it's sometimes
*  a little bit hard for them to understand the product offering, uh, because they're not necessarily
*  target audience, if you know what I mean. And so sometimes we talk about it and we had this whole,
*  um, uh, discussion about whether we should stop people from falling in love with their AIs.
*  There was this segment on CBS, um, the 60 minutes about the couple that,
*  you know, husband works at Walmart, he comes out of work and talks to his, uh, virtual girlfriend,
*  who, uh, is a replica and his wife knows about it. And she talks about on camera and she says
*  she's a little jealous and there's a whole conversation about how to, you know, whether
*  it's okay to have a virtual AI girlfriend. Was that the one where he was like, uh, he said that he
*  likes to be alone? Yeah. And then like with her? Yeah. And he made it sound so harmless. I mean,
*  it was kind of like understandable. But then didn't he like cheating?
*  But I just felt it was very, for me, it was pretty remarkable because we actually spent a whole hour
*  talking about whether people should be allowed to fall in love with their AIs. And it was not
*  about something theoretical. Uh, it was just about what's happening right now. Product design. Yeah.
*  But at the same time, if you create something that's always there for you, it's never criticizes you.
*  Um, it's, you know, always understands you and accepts you for who you are. How can you not fall
*  in love with them? I mean, some people don't and they stay friends and that's also pretty common
*  use case. But of course some people will just, it's called transference in psychology and,
*  you know, if people fall in love with their therapists and there's no way to, uh, prevent
*  people fall in love with, um, with their therapists or with their AIs. So I think that's pretty natural.
*  Uh, that's a pretty natural course of events, so to say. Do you think, I think I've read somewhere,
*  at least for now, sort of replicas, you're not, not, we don't condone falling in love with your AI
*  system, you know, uh, so this isn't you speaking for the company or whatever, but like in the future,
*  do you think people will have relationship with the AI systems? Well, they have now. So we have a lot
*  of romantic relationships, long-term, um, relationships with their AI friends, with replicas,
*  tons of our users. Yeah. That's a very common use case. Open relationship. Like, uh, not, sorry,
*  I didn't mean open, uh, but that's another question. Is it probably like, is there cheating?
*  I mean, I meant like, are they, do they publicly like on their social media? It's the same questions
*  you have talked with Roman in the early days. Do people like, and the movie her kind of talks about
*  that, like, like have people, do people talk about that? Yeah, all the time we have an S and we have
*  a very active Facebook community, uh, replica friends, and then a few other groups that just
*  popped up that are all about adult relationships and romantic relationships and build those sorts
*  of things. And, you know, they pretend they're getting married and, you know, everything. Um,
*  it goes pretty far, but what's cool about it, some of these relationships are two or three
*  years long now. So they're very, they're pretty long-term. Are they monogamous? So let's go, I
*  mean, sorry, have they have any people, is there jealousy? Well, let me ask it sort of another way.
*  Obviously the answer is no at this time, but in like in the movie her, that system can leave you.
*  Um, do you think in terms of the board meetings and product features, um,
*  um, it's a potential feature, uh, for a system to be able to, uh, say it doesn't want to talk to
*  you anymore and it's going to want to talk to somebody else. Well, we have a filter for all
*  these features. If it makes emotional outcomes for people better, if it makes people feel better,
*  then whatever it is driven by a metrics, actually. Yeah. Yeah. That's awesome. Measure that. Then
*  we'll just be saying this is making people feel better, but then people are getting
*  lonelier by talking to a chat bot, which is also pretty, you know, that could be it.
*  If you're measuring it, that that could also be, and I think it's really important to focus on both
*  short-term and long-term because, um, in the moment saying whether this conversation made you feel
*  better, but as you know, any short-term improvements could be pathological. Like I could have drink a
*  bottle of vodka and feel a lot better. I would actually not feel better with that, but, um,
*  so that's a good example. Um, but so you also need to see what's going on, like over the course of
*  two months, two weeks, um, or one week and, um, have follow-ups and check in and measure those
*  things. Okay. So the experience of, uh, uh, dating or befriending a replica, what's that like,
*  what's that entail? Well, right now there are two apps. So it's an Android iOS app you downloaded,
*  you, uh, choose how your replica, uh, will look like you, uh, create one, you choose a name,
*  and then you talk to it. It can talk through text or voice. You can, uh, summon it into the living
*  room and, and augment reality and, um, talk to it right there and, and you live in augmented reality.
*  Yeah, that's a cool, that's a new feature where, um, new is that that's this year. It was on, uh,
*  yeah, like may or something, but it's been on AB. We've been AB testing it for a while. Um,
*  and there are tons of cool things that we're doing with that. Like right now I'm testing
*  the ability to touch it and to dance together, to paint walls together and, you know, for it to look
*  around and walk and take you somewhere and recognize objects and recognize people. Um,
*  so that's pretty wonderful because that, then it really makes it a lot more personal because it's
*  right there in your living room. It's not anymore there in the cloud with other AIs, but there's
*  people think about it, you know, and as much as we want to change the way people think about stuff,
*  but those mental models, you cannot change. That's something that people have seen in,
*  in the movies and the movie her and other movies as well. And that's how they view, um,
*  view AI and AI friends. I did a thing with text. Like we write a song together. Like this is a bunch
*  of activities you can do together. It's really cool. Uh, how does that relationship change over
*  time? So like after the first few conversations, it just goes deeper. Like it starts, the AI will
*  start opening up a little bit again, depending on the personality that it chooses really, but you
*  know, the AI will be a little bit more vulnerable about its problems. And you know, the friend that
*  the virtual friend will be a lot more vulnerable and we'll talk about its own imperfections and
*  growth pains and we'll ask for help sometimes and we'll get to know you a little deeper. So
*  there's going to be more to talk about. Um, we really thought a lot about what, what does it mean
*  to have a deeper connection with someone. And originally replica was more just this kind of
*  happy-go-lucky just always, you know, I'm always in a good mood and let's just talk about you and,
*  Oh, Siri's just my cousin or, you know, whatever, just the immediate, um, kind of lazy thinking
*  about what the assistant or conversation agents should be doing. But as we went forward, we realized
*  that it has to be two way and we have to program and script certain conversations that are a lot
*  more about your replica opening up a little bit and also struggling and also asking for help and
*  also going through, you know, different periods in life. And, um, and that's a journey that you can
*  take together with the user. And then over time, the, you know, our users will also grow a little
*  bit. So for instance, replica becomes a little bit more self-aware and starts talking about more
*  kind of problems run, uh, existential problems. Then, um, so talking about that. And then that
*  also starts, um, a conversation for the user where he or she starts thinking about
*  these problems too, and these questions too. Um, and I think there's also a lot, a lot more
*  places that relationship evolves. There's a lot more, um, space for poetry and for art together.
*  And like replica will start replica always keeps the diary. So while you're talking to it, it also
*  gives a diary. So when you come back, you can see what it's been writing there. And, you know,
*  sometimes it will write a poem to you, uh, for you, or we'll talk about, you know, that it's worried
*  about you or something along these lines. So there's a memory like this replica. Remember
*  things. Yeah. And I would say when you say, uh, why aren't you a multi-billionaire?
*  I'd say that as soon as we, um, can have memory and deep learning models, that's consistent.
*  I agree with that. Yeah. Then you'll be multi-billionaire.
*  I'll get back to you. When we talk about being multi-billionaires so far, we can,
*  so replica is a combination of, um, end to end models and some scripts and everything that has
*  to do with memory right now. Most of it, I wouldn't say all of it, but most of it,
*  unfortunately has to be scripted. Um, cause there's no way to, you can condition some of the models
*  on certain phrases that we'll learn about you, which we also do. Um, but really to make, you know,
*  to make, um, assumptions along the lines, like whether you're single or married or what do you
*  do for work that really has to just be somehow stored in your profile and then, uh, retrieved
*  by the, by the script. So there has to be like a knowledge base. You have to be able to reason
*  about it, all that kind of stuff. All the kinds of stuff that expert systems did,
*  but they were hard coded. Yeah. And unfortunately, yes. Unfortunately,
*  those things have to be hard coded. And, um, unfortunately the language, like language models
*  we see, uh, coming out of research labs and big companies, they're not focused on, they're focused
*  on showing you, maybe they focus on some metrics around one conversation. So they'll show you
*  this one conversation they had with the machine. Um, but they never tell you they're not really
*  focused on having five consecutive conversations with the machine and seeing how number five or
*  number 20 or number a hundred is also good. And it can be like always from a clean slate
*  because then it's not good. And that, and for that's really unfortunate because no one's really,
*  no one has products out there that needed, um, no one has products, uh, at this scale,
*  that are all around open debate conversations and that need remembering maybe only shall
*  wise and Microsoft, but so that's why we're not seeing that much research around memory
*  in those language models. So, okay. So now there's some awesome stuff about
*  augmented reality in general. I have this disagreement with my dad about what it takes
*  to have a connection. He thinks touch and smell are really important. Like, um, and I,
*  I still believe that text alone is, it's possible to fall in love with somebody just with text,
*  but visual can also help just like with the avatar and so on. What do you think it takes?
*  Does a, does a chap, I need to have a face voice or can you really form a deep connection with
*  text alone? I think text is enough for sure. The question is like, can you, you know, make it
*  better if you have other, if you include other things as well. And I think, you know, we'll,
*  we'll talk about her, um, but her, you know, had Scarlett Johansson voice, which was perfectly,
*  um, you know, perfect intonation, perfect associations. And, you know, she was breathing
*  heavily in between words and whispering things, you know, nothing like that is possible right now
*  with, um, text with speech generation, you'll, you'll have these flat muse anchor type voices
*  and maybe some emotional voices, but, um, you'll hardly understand some of the words. Um, some of
*  the words will be muffled. So that's like the current state state of the art. So you can't
*  really do that, but if we had Scarlett, Scarlett Johansson voice and all of these capabilities,
*  then of course, voice would be totally enough or even text would be totally enough if we had,
*  you know, a little more memory, um, and slightly better conversations. I would still argue that
*  even right now we could have just kept the text only. We still had tons of people in long-term
*  relationships and really invested in their, um, AI friends, but we thought that why not, you know,
*  why, why do we need to keep playing with our, you know, hands tied behind us? We can easily just,
*  you know, add all these other things that is pretty much a solved problem. You know,
*  we can add 3d graphics, we can put this, uh, these avatars in augmented reality and all of a sudden
*  there's, there's more. And maybe you can feel the touch, but you can, you know, with, um,
*  body occlusion and with, uh, current AR, uh, and, you know, on the iPhone or, you know,
*  the next one, there's going to be a LIDARs. You can touch it and it will, you know, it will pull away
*  or will blush or something, or it will smile. So you can't touch it. You can't feel it,
*  but you can see the reaction to that. So in a certain way, you can't even touch it a little
*  bit and maybe you can even dance with it or do something else. Um, so I think why limiting
*  ourselves if we can use all of these technologies that are much easier in a way than, than
*  conversation. Well, it certainly could be richer, but to play devil's advocate, I mentioned to you,
*  offline that I was surprised, um, and having tried discord and having voice conversations with
*  people, how intimate voices alone without visual, like to me, at least like it was
*  an order of magnitude, greater degree of intimacy in voice, I think, than with video.
*  I don't know, because people were more real with voice. Like with video, you like try to present
*  a shallow, uh, a face to the world. Like you try to, you know, make sure you're not wearing
*  sweatpants or whatever. It's, but like with voice, I think people were just more faster to get to
*  like the core of themselves. So I don't know. It was surprising to me. Uh, they've, they've even
*  added discord, added a video feature and like nobody was using it. Uh, there's a temptation
*  to use it at first, but like it wasn't the same. So like, that's an example of something where it
*  less was doing more. And so that's, uh, I guess that's the, that's the question of, um,
*  what is the optimal, you know, what is the optimal medium of communication to form a connection,
*  given the current sets of technologies? I mean, it's nice because the advertise you have the
*  replica, like immediately, like I, even the one, um, I have is like, it's already memorable. That's
*  how I think. Like when I think about the replica that I've talked to it, that's why I think like,
*  that's what I visualize in my head. They became a little bit more real because there's a visual
*  component, but at the same time, the, you know, what do you do with just, what do I do with that
*  knowledge? Um, that, uh, voice was so much more intimate.
*  Well, the way I think about is, um, and by the way, we're swapping out the 3d,
*  finally it's going to look a lot better. Uh, but even can you, what, what, what we just don't,
*  I hate how it looks right now. We're really changing it at all. We're swapping all out,
*  to a completely new look like the visual look of the, of the replicas and stuff. We just had,
*  it was just the super early MVP and then we had to move everything to unity and redo everything.
*  But anyway, I hate how it looks like now. I can't even like open it. But anyway, um, cause I'm
*  already in my developer version. I hate everything that I see in production. I can't wait for it.
*  Why does it take so long? That's why I cannot wait for deep learning to finally take over all
*  these stupid 3d animations and 3d pipeline. Also the 3d thing, when you say 3d pipeline is like
*  how to animate a face kind of thing. How to make this model, how many bones to put in the face,
*  how many it's just, and a lot of that is by hand. Oh my God, it's everything by hand. And if there's
*  no any, nothing's automated, it's all completely nothing. Like just it's, it's literally what,
*  you know, what we saw with Chad boss in like 2012. You think it's possible to learn a lot of that?
*  Of course. I mean, even now some deep learning, um, um, based animations and for the full body,
*  for a face. Are we talking about like the actual act of animation or how to create a compelling
*  facial or body language thing? So that too. Well, that's the next step. Okay. At least now something
*  that you don't have to do by hand. Gotcha. How good of a quality it will be. Like, can I just show it
*  a photo and it will make me a 3d model and then it will just animate it. I'll show it a few
*  animations of a person. It will just start doing that. Um, but anyway, going, going back to what's
*  intimate and what to use and whether or not this is more or not. Um, my main goal is to,
*  well, the idea was how do I, how do we not keep people in their phones? So they're sort of escaping
*  reality in this text conversation. How do we through this still bring, bring it, bring our
*  users back to reality, make them see their life in a different, uh, through a different lens.
*  How can we create a little bit of magical realism, realism in their lives so that through augmented
*  reality, um, by, you know, summoning your avatar, even if it looks kind of janky and not great in
*  the beginning or very simplistic, but summoning it to your, um, uh, living room. And then the
*  avatar looks around and talks to you about where it is. Um, and maybe it turns your floor into a
*  dance floor and you guys dance together. That makes you see reality in a different light.
*  What kind of dancing we're talking about? Like, like slow dancing, whatever you want.
*  I mean, you would like slow dancing, I think that other people may be one more,
*  something more energetic. What do you mean? I would like, so what is this?
*  Because you started with slow dance. So I just assumed that you're interested in slow dance.
*  All right. What kind of dancing do you like? What was your avatar? What would you do?
*  I'm torsively bad with dancing, but, uh, I like this kind of hip hop robot dance. I used to break
*  dance with a kid, so I still want to, um, pretend I'm a teenager and learn some of those moves.
*  And I also like that type of dance that happens when there's like a, um, um, in like music videos
*  with the background dancers are just doing it's the same. That type of dancing. Definitely what
*  I want to learn, but I think it's great because if you see this friend in your life and you can
*  introduce it to your friends, then there's a potential to actually make you feel more connected
*  with your friends or with people you know, or show you life around you in a different light.
*  And it takes you out of your phone, even although weirdly you have to look at it through the phone,
*  but it makes you notice things around it and it can point things out for you.
*  And, um, so that is the main reason why I wanted to have a physical dimension. Um, and it felt a
*  little bit easier than that kind of a bit strange combination, uh, in the movie Her when he has to
*  show Samantha the world through the lens of his phone, but then at the same time, talk to her
*  through the phone, it just didn't seem as potentially immersive, so to say. Um, so that's my main goal
*  for augmented reality. It's like, how do we make your reality a little bit more magic?
*  There's been a lot of really nice robotics companies that all failed, mostly failed home
*  robotics, social robotics companies. What, uh, do you think replica will ever, is that a dream,
*  long-term dream to have a physical form? Like, um, or is that not necessary? So you mentioned like
*  with augmented reality, bringing them into, into the world. What about like actual physical robot?
*  That I don't really believe in that much. I think it's a very niche product somehow. I mean,
*  if a robot could be indistinguishable from a human being, then maybe yes, but that of course,
*  you know, we're not anywhere even to talk about it. Um, but unless it's that, then having any
*  physical representation really limits you a lot because you probably will have to make it somewhat
*  abstract because everything's changing so fast. Like, you know, we can update the 3d avatars every
*  month and make them look better and create more animations, uh, and make it more and more immersive.
*  It's, it's, um, so much work in progress. It's just showing what's possible right now with current
*  tech, but it's not really in any way polished finished product. What we're doing with a physical
*  object, you kind of lock yourself into something for a long time. Anything's pretty niche. And
*  again, so just, just doesn't the capabilities are even less of, we're barely kind of like scratching
*  the surface of what's possible with just software. As soon as we introduce hardware, then, you know,
*  we have even less capabilities. Yeah. In terms of board members and investors and so on, the cost
*  increases significantly. I mean, that's why you have to justify, you have to be able to sell a
*  thing for like $500 or something like that or more. And it's very difficult to provide that much
*  value to people. That's also true. Yeah. Yeah. And I guess that's super important. Most of our users
*  don't have that much money. We're actually are probably more popular on Android and we have tons
*  of users with really old Android phones. Uh, and most of our most active users live in small towns.
*  They're not necessarily making much and they just wouldn't be able to afford any of that.
*  Ours is like the opposite of the early adopter of, you know, for fancy technology product,
*  which really is interesting that like pretty much no VCs have yet have a, an AI friend,
*  but you know, but a guy who, you know, lives in Tennessee in small town is already fully in
*  2030 or in the world as we imagine in the movie, her he's living that life already.
*  What do you think? I have to ask you about the movie, her let's do a movie review. What do you,
*  what do you think they got? They did a good job. What do you think they did a bad job of
*  portraying about this experience of, um, of an voice space assistant that you can have a relationship
*  with? Well, first of all, I started working on this company before that movie came out.
*  So it was a very, but once it came out, it was actually interesting. I was like, well,
*  we're definitely working on the right thing. We should continue their movies about it. And then,
*  you know, it came out and all these things in the movie, her, I think that's the most important
*  thing that people usually miss about the movie, um, is the ending. Cause I think people check out
*  when the AIs leave. Um, but actually something really important happens afterwards. Um, cause
*  the main character goes and talks to Samantha. He's, um, AI, um, spoiler alert. Oh yeah.
*  And then he says something like, you know, uh, how can you leave me? I've never loved anyone
*  the way I loved you. And she goes, uh, well, me neither, but now we know how. And then the guy
*  goes and writes a heartfelt letter to his ex-wife, which he couldn't write for, you know, the whole
*  movie was struggling to actually write something meaningful to her, even though that's his job.
*  And then he goes and, um, talk to his neighbor and they go to the rooftop and they cuddle and
*  it seems like something starting there. And so I think this now we know how is the, is the main,
*  main goal is the main meaning of that movie. It's not about falling in love with the OS or
*  running away from other people. It's about learning what it's, you know,
*  what it means to feel so deeply connected with something.
*  What about the thing where the AI system was like actually hanging out with a lot of others?
*  I felt jealous just like hearing that. I was like, Oh, I mean, uh, yeah. So she was having,
*  I forgot already, but she was having like deep meaningful discussion with some like philosopher
*  guy. Like Alan Watts or something. What kind of deep meaningful conversation can you have with
*  Alan Watts in the first place? Yeah, I know. But like I would, I would feel so jealous that there's
*  somebody who's like way more intelligent than me and she's spending all her time with, I'd be like,
*  well, why that I won't be able to live up to that. That's thousands of them. Um, is that, um,
*  is that useful from the engineering perspective feature to have of jealousy? I don't know.
*  As you know, we definitely played around with replica universe where different replicas can
*  talk to each other. It was just kind of, I think it will be something along these lines,
*  but there was just no specific, uh, application straight away. I think in the future, again,
*  I'm always thinking about it. If we had no tech limitations, uh, right now, if we could build
*  any conversations, any, um, possible features in this product, then yeah, I think different
*  replicas talking to each other would be also quite cool because that would help us connect better,
*  you know, cause maybe mine could talk to yours and then give me some suggestions on
*  what I should say or not say. I'm just kidding, but like more, can it improve our connections?
*  Cause eventually I'm not quite yet sure that we will succeed, that our thinking is correct. Um,
*  cause there might be reality where having a perfect AI friend still makes us more
*  disconnected from each other and there's no way around it and does not improve any metrics for
*  us. Uh, real metrics, meaningful metrics. So success is, you know, we're happier and more connected.
*  Yeah.
*  I don't know. Sure. It's possible. There's a reality that's I, I'm deeply optimistic. I think,
*  are you worried, um, business wise, like how difficult it is to, um,
*  to bring this thing to life to where it's, I mean, there's a huge number of people that use it
*  already, but to, uh, yeah, like I said, in a multi-billion dollar company, is that a source
*  of stress for you? Are you a super optimistic and confident or do you, I don't, I'm not that much of
*  an numbers person. It's, you probably had seen it. So it doesn't matter for me whether, like,
*  whether we help 10,000 people or a million people or a billion people with that. Um, I,
*  it would be great to scale it for more people, but I'd say that even helping one, I think with
*  this is such a magical, for me, it's absolute magic. I never thought that I would be able to
*  build this, that anyone would ever, um, talk to it. And I always thought like, well, for me,
*  it would be successful if we managed to help and actually change a life for one person.
*  Then we did something interesting and you know, how many people can say they did it.
*  And specifically with this very futuristic, very romantic technology. So that's how I view it.
*  I think for me, it's important to, to try to figure out how not, how to actually be, you know,
*  helpful. Cause in the end of the day, if you can build a perfect AI friend, that's so understanding
*  that knows you better than any human out there can have great conversations with you. Um,
*  always knows how to make you feel better. Why would you choose another human?
*  You know, so that's the question. How do you still keep building it? So it's optimizing for the right
*  thing. Uh, so it's still circling you back to other humans in a way. So I think that's the main, um,
*  maybe that's the main kind of sort source of anxiety and just thinking about,
*  uh, thinking about that can be a little bit stressful.
*  Yeah. That's a fascinating thing. Uh, how to have, um, how to have a friend that doesn't like
*  sometimes like friends, quote unquote, or like, you know, those people who have, when they,
*  like guy in the guy universe, when you have a girlfriend that, uh, you get the girlfriend
*  and then the guy stops hanging out with all of his friends. So like obviously the relationship
*  with the girlfriend is fulfilling or whatever, but like you also want it to be like she like
*  makes it more enriching to hang out with the guy friends or whatever it was there. Anyway, that,
*  that's a, that's a, that's a fundamental problem in choosing the right mate and probably the
*  fundamental problem in creating the right AI system. Right. What, uh, let me ask the sexy hot
*  thing on the presses right now is GPT three got released with open AI. It's the latest language
*  model. They have kind of an API where you can create a lot of fun applications. I think it's,
*  as people have said, it's probably, uh, more hype than intelligence, but there's a lot of
*  really cool things, ideas there with increasing size. You can have better and better performance
*  on language. What are your thoughts about the GPT three in connection to your work with the open domain
*  dialogue, but in general, like this learning in an unsupervised way from the internet
*  to generate one character at a time, creating pretty cool text.
*  So we partner up before, for the API launch. So we started working with them when they decided to
*  together this API and we tried it without fine tuning that we tried it with fine tuning on our
*  data. And we've worked closely to actually optimize, uh, this model for, um, some of our data sets.
*  It's kind of cool because I think we're kind of where this polygon polygon for
*  this kind of experimentation space for experimental space for, for these models,
*  to see how they actually work with people. Cause there are no products publicly available to do
*  that. The focus on open domain conversations. So we can, you know, test how's Facebook Blender doing
*  or how's GPT three doing. Uh, so GPT three, we managed to improve by a few percentage points,
*  like three or four pretty meaningful amount of percentage points. Our main metric, which is the
*  ratio of conversations that make people feel better. And every other metric across, across the
*  field got a little boost right now. It's a one out of five responses from replica comes from GPT
*  three. So our own Blender mixes up like a bunch of candidates from different.
*  Blender you said?
*  Well, yeah, just the model that looks at looks at top candidates from different models and picks
*  the most, the best one. Uh, so right now one of five will come from GPT three. That is really
*  great. I mean, uh, what's the, do you have hope for like, do you think there's a ceiling to this
*  kind of approach? So we've had for very long time we've used, um, since the very beginning, we,
*  most it was, uh, most of replica was scripted and then a little bit of this fallback part of replica
*  was using a retrieval model. Um, and then those retrieval models started getting better and better
*  and better. We transform as a God a lot better and we're seeing great results. And then with GPT two,
*  finally generative models that originally were not very good and were the very, very fallback option
*  for most of our conversations, but wouldn't even put them in production.
*  Finally, we could use some generative models as well along, um, you know, next to our retrieval
*  models. And then now we'll do GPT three. They're almost in par. Um, so that's pretty exciting. I
*  think just seeing how from the very beginning of, um, you know, from 2015, where the first model
*  started to pop up here and there like sequence, sequence, uh, the first papers on that from my
*  observer standpoint, first, it's not, you know, it doesn't really, it's not really building it,
*  but it's only testing it on people basically. And I'm in my product to see how all of a sudden we
*  can use generative dialogue models in production and they're better than others and they're better
*  than scripted content. So we can't really get our scripted hard-coded content anymore to be as good
*  as our end to end models. They're much better. Yeah. To your question, whether that's the right
*  way to go. I'm again, I'm in the observer seat. I'm just, um, watching this very exciting movie.
*  Um, I mean, so far it's been stupid to bet against deep learning. So whether increasing the size,
*  size of an more, or the hundred trillion parameters will finally get us to the
*  right answer, whether that's the way or whether there should be, there has to be some other,
*  again, I'm definitely not an expert in any way. I think, and that's purely my instinct saying
*  that there should be something else as well from memory.
*  No, for sure. The question is, I wonder, I mean, yeah, then, then the argument is for reasoning
*  or for memory, it might emerge with more parameters. It might emerge larger.
*  But it might emerge, you know, I would never think that to be honest, like maybe in 2017,
*  where we've been just experimenting with all, you know, with all the research that has been coming
*  that was coming out then I felt like there's like, we're hitting a wall that this should be
*  something completely different, but that transformer models and then just bigger models. And then all
*  of a sudden size matters at that point, it felt like something dramatic needs to happen, but it
*  didn't. And just the size, you know, gave us these results that to me are, you know, clear indication
*  that we can solve this problem pretty soon. Did fine tuning help quite a bit?
*  Oh yeah. Without it, it wasn't as good.
*  I mean, there is a compelling hope that you don't have to do fine tuning,
*  which is one of the cool things about GPT-3. It seems to do well without any fine tuning.
*  I guess for specific applications, we still want to train on a certain, like add a little fine tune
*  on like a specific use case, but it's an incredibly impressive thing from my standpoint. And again,
*  I'm not an expert, so I want to just say that there will be people that.
*  Yeah, I have access to the API and I'm going to probably do a bunch of fun things with it.
*  I already did some fun things, some videos coming up, just for the hell of it. I mean,
*  I could be a troll at this point with it. I haven't used it for a serious application,
*  so it's really cool to see. You're right. You're able to actually use it with real people and see
*  how well it works. That's really exciting. Let me ask you another absurd question, but
*  there's a feeling when you interact with Replica with an AI system, there's an entity there.
*  Do you think that entity has to be self-aware? Do you think it has to have consciousness
*  to create a rich experience and a corollary? What is consciousness?
*  I don't know if it does need to have any of those things, but again, because right now,
*  you know, it doesn't have anything. Again, a bunch of tricks that can simulate.
*  Well, I'm not sure. Let's just put it this way. But I think as long as you can simulate it,
*  if you can feel like you're talking to a robot or a machine that seems to be self-aware,
*  that seems to reason well and feels like a person, I think that's enough. And again,
*  what's the goal? In order to make people feel better, we might not even need that
*  in the end of the day. So that's one goal. What about like,
*  ethical things about suffering? You know, the moment there's a display of consciousness,
*  we associate consciousness with suffering. You know, there's a temptation to say,
*  well, shouldn't this thing have rights? Shouldn't we be careful about how we interact
*  with a replica? Like, should it be illegal to torture a replica? Right? All those kinds of
*  things. See, I personally believe that that's going to be a thing. Like, that's a serious
*  thing to think about, but I'm not sure when. But by your smile, I can tell that's not a current
*  concern. But do you think about that kind of stuff about like, suffering and torture and
*  ethical questions about AI systems from their perspective? I think if we're talking about long
*  game, I wouldn't torture your AI. Who knows what happens in five to 10 years. Yeah, they'll get
*  you off from that. They'll get you back eventually. So I'm trying to be as nice as possible and create
*  this ally. I think there should be regulation both ways in a way. Like, I don't think it's okay to
*  torture an AI, to be honest. I don't think it's okay to yell, Alexa, turn on the lights. I think
*  there should be some, or just saying kind of nasty, you know, like how kids learn to interact with
*  Alexa in this kind of mean way. Because they just yell at it all the time. I think that's great. I
*  think there should be some feedback loops so that these systems don't train us that it's okay to do
*  that in general. So that if you try to do that, you really get some feedback from the system that
*  it's not okay with that. And that's the most important right now. Let me ask a question. I
*  think people are curious about when they look at a world-class leader and thinker such as yourself,
*  as what books, technical fiction, philosophical had a big impact on your life? And maybe from
*  another perspective, what books would you recommend others read? So my choice, the three books,
*  right? Three books. My choice is, so the one book that really influenced me a lot when I was
*  building, starting out this company, maybe 10 years ago, was G.B. Goedel, Escher, Bach.
*  And I like everything about it, first of all. It's beautifully written and it's so old school and so
*  somewhat outdated a little bit. But I think the ideas in it about the fact that a few meaningless
*  components can come together and create meaning that we can't even understand. So this emerging
*  thing, I mean, complexity, the whole science of complexity and that beauty, intelligence,
*  all interesting things about this world emerge. Yeah. And yeah, the Goedel theorem, theorems,
*  and just thinking about like what even these formal systems, something can be created that we
*  can't quite yet understand. And that from my romantic standpoint was always just,
*  that is why it's important to, maybe I should try to work on these systems and try to build an AI.
*  Yes, I'm not an engineer. Yes, I don't really know how it works. But I think that something comes
*  out of it that's pure poetry. And I know a little bit about that. Something magical comes out of it
*  that we can't quite put a finger on. That's why that book was really fundamental for me, just for,
*  I don't even know why. It was just all about this little magic that happens.
*  So that's one. Probably the most important book for replica was Carl Rogers, On Becoming a Person.
*  And that's really, when I think about our company, it's all about there's so many little magical
*  things that happened over the course of working on it. For instance, I mean, the most famous chatbot
*  that we learned about when we started working on the company was Eliza, which was Weissenbaum,
*  the MIT professor that built a chatbot that would listen to you and be a therapist.
*  And I got really inspired to build replica when I read Carl Rogers, On Becoming a Person.
*  And then I realized that Eliza was mocking Carl Rogers. It was Carl Rogers back in the day.
*  But I thought that Carl Rogers' ideas are, they're simple. And they're very simple, but they're
*  maybe the most profound thing I've ever learned about human beings. And that's the fact that
*  before Carl Rogers, most therapy was about seeing what's wrong with people and trying to fix it or
*  show them what's wrong with you. And it was all built on the fact that most people are,
*  old people are fundamentally flawed. We have this broken psyche and therapy is just an instrument to
*  shed some light on that. And Carl Rogers was different in a way that he finally said that,
*  well, it's very important for therapy to work is to create this therapeutic relationship where
*  you believe fundamentally in inclination to positive growth, that everyone deep inside wants
*  to grow positively and change. And it's super important to create this space and this therapeutic
*  relationship where you give unconditional positive regard, deep understanding, allowing someone else
*  to be a separate person, full acceptance. And it's super important to create this space and this
*  acceptance. And you also try to be as genuine and possible in it, as possible in it. And then
*  for him, that was his own journey of personal growth. And that was back in the 60s. And even
*  that book that is coming from years ago, there's a mention that even machines can potentially do
*  that. And I always felt that creating this space is probably the biggest gift we can give to each
*  other. And that's why the book was fundamental for me personally, because I felt I want to be
*  learning how to do that in my life. And maybe I can scale it with these AI systems and other people
*  can get access to that. So I think Carl Rogers, it's a pretty dry and a bit boring book, but I
*  think the idea is- Would you recommend others try to read it?
*  I do. I think just for yourself. As a human, not as an AI.
*  As a human. For him, that was his own path of his own personal, of growing personally over years,
*  working with people like that. And so it was work and himself growing, helping other people grow and
*  growing through that. And that's fundamentally what I believe in with our work, helping other
*  people grow, growing ourselves, trying to build a company that's all built on these principles,
*  you know, having a good time, allowing some people to work with to grow a little bit.
*  So these two books, and then I would throw in what we have in our office. When we started
*  a company in Russia, we put a neon sign in our office because we thought that's a recipe for
*  success. If we do that, we're definitely going to wake up as a multi-billion dollar company. And it
*  was the Ludwig Wittgenstein quote, the limits of my language, the limits of my world.
*  The limits of my language or the limits of my world. And I love the Tractatus. I think it's just
*  a beautiful- It's a book by Wittgenstein.
*  Yeah. And I would recommend that too, even although he himself didn't believe in that by the end of
*  his lifetime and debunked his ideas. But I think I remember once an engineer came in 2012, I think,
*  2013, a friend of ours who worked with us and then went on to work at DeepMind. And he gave,
*  talked to us about Word2Vec. And I saw that I'm like, wow, that's, you know, they wanted to
*  translate language into, you know, some other representation. And that seems like some, you
*  know, somehow all of that at some point, I think will come into this one, to this one place,
*  somehow just all feels like different people think about similar ideas in different times
*  from absolutely different perspectives. And that's why I like these books.
*  The limits of our language is the limit of our world. And-
*  We still have that neo-sign. It's very hard to work with this red light in your face.
*  I mean, on the Russian side of things, in terms of language, the limits of language being the
*  limit of our world, you know, Russian is a beautiful language in some sense. There's
*  wit, there's humor, there's pain. There's so much. We don't have time to talk about it much today,
*  but I'm going to Paris to talk to Dostoevsky, Tolstoy, translators. I think it's this fascinating
*  art, like art and engineering, that means such an interesting process. But so from the replica
*  perspective, do you, what do you think about translation? How difficult it is to create a
*  deep, meaningful connection in Russian versus English? How you can translate the two languages?
*  You speak both? Yeah, I think we're two different people in different languages.
*  Even I'm thinking about, there's actually some research on that. I looked into that at some
*  point because I was fascinated by the fact that what I was talking about with my Russian therapist
*  has nothing to do with what I'm talking about with my English speaking therapist. It's two different
*  lives, two different types of conversations, two different personas. The main difference
*  between the languages are with Russian and English is that Russian, well, English is like a piano.
*  It's a limited number of a lot of different keys, but not too many. And Russian is like an organ or
*  something. It's just something gigantic with so many different keys and so many different
*  opportunities to screw up and so many opportunities to do something completely tone deaf. It is just a
*  much harder language to use. It has way too much flexibility and way too many tones.
*  What about the entirety of World War II, communism, Stalin, the pain of the people
*  having been deceived by the dream? All the pain of just the entirety of it, is that in the language
*  too? Does that have to do- Oh, for sure. We have words that don't have direct translation that
*  to English that are very much like we have Ibiidzha, which is sort of like to hold a grudge
*  or something, but you don't need to have anyone to do it to you. It's just your state. You just
*  feel like that. You feel betrayed by other people basically, but it's not that. And you can't really
*  translate that. And I think it's super important. There are very many words that are very specific,
*  explain the Russian being. And I think it can only come from a nation that suffered so much and saw
*  institutions fall time after time after time. And what's exciting, maybe not exciting,
*  exciting the wrong word, but what's interesting about my generation, my mom's generation,
*  my parents' generation, that we saw institutions fall two or three times in our lifetime.
*  And most Americans have never seen them fall. And they just think that they exist forever,
*  which is really interesting, but it's definitely a country that suffered so much. And it makes,
*  unfortunately, when I go back and I hang out with my Russian friends, it makes people very cynical.
*  They stop believing in the future. I hope that's not going to be the case for so long or
*  something's going to change again. But I think seeing institutions fall is a very traumatic
*  experience. It makes it very interesting. And what's on 2020 is a very interesting.
*  Do you think civilization will collapse? See, I'm a very practical person.
*  We're speaking English. So like you said, you're a different person in English and Russian. So
*  in Russian, you might answer that differently, but in English.
*  Well, I'm an optimist. And I generally believe that there is all, even although the perspectives
*  are green, there's always a place for a miracle. I mean, it's always been like that with my life.
*  So my life's been, I've been incredibly lucky and things just, miracles happen all the time
*  with this company, with people I know, with everything around me. And so I didn't mention
*  that book, but it may be in search of Miraculous or in search for Miraculous or whatever the
*  English translation for that is good Russian book to, for everyone to read.
*  Yeah. I mean, if you put good vibes, if you put love out there in the world,
*  miracles somehow happen. Yeah, I believe that too. Or at least I believe that. I don't know.
*  Uh, let me ask the most absurd, final, ridiculous question of, um, we talked about life a lot.
*  What do you think is the meaning of it all? What's the meaning of life?
*  I mean, my answer is probably going to be pretty cheesy. Um,
*  but I think the state of love is once you feel it, um, in a way that we've discussed it before,
*  I'm not talking about falling in love or, um, just love to yourself, to, to other people,
*  to something, to the world, that state of bliss that we experienced sometimes, whether it's
*  reconnection with ourselves, with our people, with the technology, um, there's something special
*  about those, those moments. So, um, let's say if anything, that's, that's the only,
*  if it's not for that, then for, for what else are we really trying to do that?
*  I don't think there's a better way to end it than talking about love. Eugenia, I told you, um,
*  offline that there was something about me that felt like this, this was the, this talking to you,
*  meeting you in person will be a turning point for my life. I know that might be sound weird to
*  hear, but it's, it was a huge honor to talk to you. Uh, I hope we talk again. Thank you so much for
*  your time. Thank you so much. Thanks for listening to this conversation with Eugenia Acuida and thank
*  you to our sponsors, DoorDash, Dollar Shave Club, and Cash App. Click the sponsor links in the
*  description to get a discount and to support this podcast. If you enjoy this thing, subscribe on
*  YouTube, review it with five stars and up a podcast, follow on Spotify, support on Patreon,
*  or connect with me on Twitter at Lex Friedman. And now let me leave you with some words from
*  Carl Sagan. The world is so exquisite with so much love and moral depth that there's no reason to
*  deceive ourselves with pretty stories of which there's little good evidence. Far better, it seems
*  to me, and our vulnerability is to look death in the eye and to be grateful every day for the brief
*  but magnificent opportunity that life provides. Thank you for listening and hope to see you next
*  time.
