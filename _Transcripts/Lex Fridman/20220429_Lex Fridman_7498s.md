---
Date Generated: April 11, 2024
Transcription Model: whisper medium 20231117
Length: 7498s
Video Keywords: ['agi', 'ai', 'ai podcast', 'artificial intelligence', 'artificial intelligence podcast', 'claire boucher', 'edm', 'elon musk', 'grimes', 'homo techno', 'lex ai', 'lex fridman', 'lex jre', 'lex mit', 'lex podcast', 'mit ai', 'motherhood', 'music', 'protopia', 'twitter']
Video Views: 2015388
Video Rating: None
---

# Grimes: Music, AI, and the Future of Humanity | Lex Fridman Podcast #281
**Lex Fridman:** [April 29, 2022](https://www.youtube.com/watch?v=KOwm7GUjcg8)
*  we are becoming cyborgs.
*  Our brains are fundamentally changed.
*  Everyone who grew up with electronics,
*  we are fundamentally different from homo sapiens.
*  I call us homo techno.
*  I think we have evolved into homo techno,
*  which is essentially a new species.
*  Previous technologies may have even been more profound
*  and moved us to a certain degree,
*  but I think the computers are what make us homo techno.
*  I think this is what, it's a brain augmentation.
*  So it allows for actual evolution.
*  The computers accelerate the degree
*  to which all the other technologies can also be accelerated.
*  Would you classify yourself as a homo sapien or a homo techno?
*  Definitely homo techno.
*  So you're one of the earlys of the species.
*  I think most of us are.
*  The following is a conversation with Grimes,
*  an artist, musician, songwriter, producer, director,
*  and a fascinating human being
*  who thinks a lot about both the history
*  and the future of human civilization.
*  Studying the dark periods of our past
*  to help form an optimistic vision of our future.
*  This is the Lex Friedman podcast.
*  To support it, please check out our sponsors
*  in the description.
*  And now, dear friends, here's Grimes.
*  Oh yeah, the Cloudlifter, there you go.
*  There you go.
*  You know your stuff.
*  Have you ever used a Cloudlifter?
*  Yeah, I actually, this microphone Cloudlifter
*  is what Michael Jackson used, so.
*  No, really?
*  Yeah, this is like Thriller and stuff.
*  This mic in a Cloudlifter?
*  Yeah, it's an incredible microphone.
*  It's very flattering on vocals.
*  I've used this a lot.
*  It's great for demo vocals.
*  It's great in a room.
*  Sometimes it's easier to record vocals
*  if you're just in a room and the music's playing
*  and you just wanna feel it so it's not in the headphones.
*  And this mic is pretty directional,
*  so I think it's a good mic for just vibing out
*  and just getting a real good vocal take.
*  Just vibing, just in a room.
*  Anyway, this is the Michael Jackson Quincy Jones
*  microphone.
*  I feel way more badass now.
*  All right, let's get in.
*  You wanna just get into it?
*  I guess so.
*  All right, one of your names,
*  at least in this space and time, is C, like the letter C.
*  And you told me that C means a lot of things.
*  It's the speed of light.
*  It's the render rate of the universe.
*  It's yes in Spanish.
*  It's the crescent moon.
*  And it happens to be my favorite programming language
*  because it basically runs the world,
*  but it's also powerful, fast, and it's dangerous
*  because you can mess things up really bad with it
*  because of all the pointers.
*  But anyway, which of these associations with the name C
*  is the coolest to you?
*  I mean, to me, the coolest is the speed of light, obviously.
*  Or the speed of light.
*  When I say render rate of the universe,
*  I think I mean the speed of light
*  because essentially that's what we're rendering at.
*  See, I think we'll know if we're in a simulation
*  if the speed of light changes
*  because if they can improve their render speed, then.
*  Well, it's already pretty good.
*  It's already pretty good, but if it improves,
*  then we'll know, we can probably be like,
*  okay, they've updated or upgraded.
*  Well, it's fast enough for us humans
*  because it seems immediate.
*  There's no delay, there's no latency
*  in terms of us humans on Earth interacting with things.
*  But if you're like intergalactic species
*  operating on a much larger scale,
*  then you're gonna start noticing some weird stuff.
*  Or if you can operate in like around a black hole,
*  then you're gonna start to see some render issues.
*  You can't go faster than the speed of light, correct?
*  So it really limits our ability
*  or one's ability to travel space.
*  Theoretically you can, you have wormholes.
*  So there's nothing in general relativity
*  that precludes faster than speed of light travel.
*  But it just seems you're gonna have to do
*  some really funky stuff with very heavy things
*  that have like weirdnesses,
*  that have basically terrors in space time.
*  We don't know how to do that.
*  Do navigators know how to do it?
*  Do navigators?
*  Yeah, folding space.
*  Basically making wormholes.
*  So the name C.
*  Yes.
*  Who are you?
*  Do you think of yourself as multiple people?
*  Are you one person?
*  Do you know like this morning
*  were you a different person than you are tonight?
*  We are, I should say, recording this basically at midnight,
*  which is awesome.
*  Yes, thank you so much.
*  I think I'm about eight hours late.
*  No, you're right on time.
*  Good morning.
*  This is the beginning of a new day soon.
*  Anyway, are you the same person
*  you were in the morning and the evening?
*  Is there multiple people in there?
*  Do you think of yourself as one person?
*  Or maybe you have no clue?
*  Or are you just a giant mystery to yourself?
*  Okay, these are really intense questions, but.
*  Let's go, let's go.
*  Because I asked this myself,
*  like look in the mirror, who are you?
*  People tell you to just be yourself,
*  but what does that even mean?
*  I mean, I think my personality changes
*  with everyone I talk to.
*  So I have a very inconsistent personality.
*  Yeah.
*  Person to person.
*  So the interaction, your personality materializes.
*  Or my mood.
*  Like I'll go from being like a megalomaniac
*  to being like, you know, just like a total hermit
*  who is very shy.
*  So some combinatorial combination of your mood
*  and the person you're interacting with.
*  Yeah, mood and people I'm interacting with.
*  But I think everyone's like that.
*  Maybe not.
*  Well, not everybody acknowledges it
*  and able to introspect it.
*  Who brings up, what kind of person,
*  what kind of mood brings out the best in you
*  as an artist and as a human?
*  Can you introspect this?
*  I'm like my best friends.
*  Like people I can.
*  When I'm like super confident
*  and I know that they're gonna understand
*  everything I'm saying.
*  So like my best friends, then.
*  When I can start being really funny,
*  that's always my like peak mode.
*  But it's like, yeah, takes a lot to get there.
*  Let's talk about constraints.
*  You've talked about constraints and limits.
*  Do those help you out as an artist or as a human being?
*  Or do they get in the way?
*  Do you like the constraints?
*  So in creating music and creating art and living life,
*  do you like the constraints that this world puts on you?
*  Or do you hate them?
*  If constraints are moving, then you're good, right?
*  Like it's like as we are progressing with technology,
*  we're changing the constraints of like artistic creation.
*  Making video and music and stuff is getting a lot cheaper.
*  There's constantly new technology and new software
*  that's making it faster and easier.
*  We have so much more freedom than we had in the 70s.
*  Like when Michael Jackson,
*  when they recorded Thriller with this microphone,
*  like they had to use a mixing desk and all this stuff.
*  And like probably even get in a studio,
*  it's probably really expensive
*  and you have to be a really good singer
*  and you have to know how to use the mixing desk
*  and everything.
*  And now I can just,
*  I've made a whole album on this computer.
*  I have a lot more freedom,
*  but then I'm also constrained in different ways
*  because there's like literally millions more artists.
*  It's like a much bigger playing field.
*  It's just like, I also, I didn't learn music.
*  I'm not a natural musician.
*  So I don't know anything about actual music.
*  I just know about like the computer.
*  So I'm really kind of just like messing around
*  and like trying things out.
*  Well, yeah, I mean, but the nature of music is changing.
*  So you saying you don't know actual music,
*  what music is changing.
*  Music is becoming, you've talked about this,
*  is becoming, it's like merging with technology.
*  Yes.
*  It's becoming something more than just like the notes
*  on a piano.
*  It's becoming some weird composition
*  that requires engineering skills, programming skills,
*  some kind of human robot interaction skills,
*  and still some of the same things that Michael Jackson had,
*  which is like a good ear for a good sense of taste
*  of what's good and not.
*  The final thing, what is put together.
*  Like you're allowed, you're enabled, empowered
*  with a laptop to layer stuff,
*  to start like layering insane amounts of stuff.
*  And it's super easy to do that.
*  I do think music production is a really underrated art form.
*  I feel like people really don't appreciate it.
*  When I look at publishing splits,
*  the way that people like pay producers and stuff,
*  it's super, producers are just deeply underrated.
*  So many of the songs that are popular right now
*  or for the last 20 years,
*  part of the reason they're popular is
*  because the production is really interesting
*  or really sick or really cool.
*  And it's like, I don't think listeners,
*  people just don't really understand
*  what music production is.
*  It's not, it's sort of like this weird,
*  discombobulated art form.
*  It's not like a formal, because it's so new,
*  there isn't like a formal training
*  or like a path for it.
*  It's mostly driven by like auto-didactics.
*  Like it's like almost everyone I know
*  who's good at production,
*  like they didn't go to music school or anything,
*  they just taught themselves.
*  Are they're mostly different?
*  Like the music producers, you know,
*  is there some commonalities that tie them together
*  or are they all just different kinds of weirdos?
*  Cause I just, I just hung out with Rick Rubin.
*  I don't know if you've-
*  Yeah, I mean, Rick Rubin is like literally
*  one of the gods of music production.
*  Like he's one of the people who first,
*  you know, who like made music production,
*  you know, made the production as important
*  as the actual lyrics or the notes.
*  But the thing he does, which is interesting,
*  I don't know if you can speak to that,
*  but just hanging out with him,
*  he seems to just sit there in silence,
*  close his eyes and listen.
*  It's like he almost does nothing
*  and that nothing somehow gives you freedom
*  to be the best version of yourself.
*  So that's music production somehow too,
*  which is like encouraging you to do less,
*  to simplify, to like push towards minimalism.
*  I mean, I guess, I mean, I work differently from Rick Rubin
*  cause Rick Rubin produces for other artists,
*  whereas like I mostly produce for myself.
*  So it's a very different situation.
*  I also think Rick Rubin, he's in that,
*  I would say advanced category of producer
*  where like you've like earned your,
*  you can have an engineer and stuff
*  and people like do the stuff for you.
*  But I usually just like do stuff myself.
*  So you're the engineer, the producer and the artist.
*  Yeah, I guess I would say I'm in the era,
*  like the post Rick Rubin era.
*  Like I come from the kind of like Skrillex school of thought,
*  which is like where you are,
*  yeah, the engineer, producer, artist.
*  Like where you, I mean, lately,
*  sometimes I'll work with a producer now.
*  I'm gently sort of delicately starting to collaborate
*  with a lot of people and I'm like,
*  I'm not gonna do it anymore, but like,
*  I think I'm kind of from the, like the,
*  whatever 2010s explosion of things where,
*  you know, everything became available on the computer
*  and you kind of got this like lone wizard energy thing going.
*  So you embrace being the loneliness.
*  Is the loneliness somehow an engine of creativity?
*  Like, so most of your stuff,
*  I think, is in the privacy of your mind?
*  Yes, well, it was, but here's the thing.
*  I was talking to Daniel Eck and he said,
*  he's like most artists, they have about 10 years,
*  like 10 good years and then they usually stop making
*  their like vital shit.
*  And I feel like I'm sort of like nearing the end
*  of my 10 years on my own.
*  So you have to become somebody else.
*  Now I'm like, I'm in the process of becoming somebody else
*  and reinventing.
*  When I work with other people,
*  because I've never worked with other people,
*  I find that I make, like that I'm exceptionally rejuvenated
*  and making like some of the most vital work I've ever made.
*  So, because I think another human brain is like
*  one of the best tools you can possibly find.
*  Like, it's a funny way to put it, I love it.
*  It's like, if a tool is like, you know,
*  whatever HP plus one or like adds some like stats
*  to your character, like another human brain
*  will like square it instead of just like adding something.
*  Double up the experience points, I love this.
*  We should also mention we're playing Tavern music
*  before this, which I love, which I first,
*  I think I first-
*  You had to stop the Tavern music.
*  Yeah, because it doesn't, the audio.
*  Okay, okay.
*  But it makes-
*  Yeah, it'll make the podcast going.
*  Add it in post, add it in post.
*  No one will wanna listen to the podcast.
*  It probably would, but it makes me,
*  it reminds me like of a video game,
*  like a role playing video game
*  where you have experience points.
*  There's something really joyful about wandering places
*  like Elder Scrolls, like Skyrim,
*  just exploring these landscapes in another world,
*  and then you get experience points
*  and you can work on different skills
*  and somehow you progress in life.
*  And I don't know, it's simple.
*  It doesn't have some of the messy complexities of life.
*  And there's usually a bad guy you can fight.
*  In Skyrim, it's dragons and so on.
*  I'm sure in Elden Ring,
*  there's a bunch of monsters you can fight.
*  I love that.
*  I feel like Elden Ring,
*  I feel like this is a good analogy to music production,
*  though, because it's like,
*  I feel like the engineers
*  and the people creating these open worlds,
*  it's sort of like similar to people, to music producers,
*  whereas it's like this hidden archetype
*  that no one really understands what they do
*  and no one really knows who they are,
*  but they're like, it's like the artist engineer,
*  because it's like, it's both art
*  and fairly complex engineering.
*  Well, you're saying they don't get enough credit.
*  Aren't you kind of changing that
*  by becoming the person doing everything?
*  Isn't the engineer?
*  Well, I mean, others have gone before me.
*  There's like Timbaland and Skrillex
*  and there's all these people that are like,
*  very famous for this.
*  But I just think the general,
*  I think people get confused about what it is
*  and just don't really know what it is per se.
*  And it's just when I see a song,
*  like when there's like a hit song,
*  I'm just trying to think of like,
*  just going for like even just a basic pop hit,
*  like rules by Dua Lipa or something.
*  The production on that is actually like really crazy.
*  I mean, the song is also great,
*  but it's like the production is exceptionally memorable.
*  And it's just like no one,
*  I don't even know who produced that song.
*  It's just like, isn't part of like the rhetoric
*  of how we discuss the creation of art.
*  We just sort of like don't consider the music producer
*  because I think the music producer used to be more
*  just simply recording things.
*  Yeah, that's interesting
*  because when you think about movies,
*  we talk about the actor and the actresses,
*  but we also talk about the directors.
*  We don't talk about like that with the music as often.
*  The Beatles music producer was one of the first kind of guy,
*  one of the first people sort of introducing crazy sound
*  design into pop music.
*  I forget his name.
*  He has the same, I forget his name,
*  but you know, like he was doing all the weird stuff
*  like dropping pianos and like, yeah.
*  Oh, to get the, yeah, yeah, yeah, yeah.
*  To get the sound, to get the authentic sound.
*  What about lyrics?
*  You think those, where did they fit
*  into how important they are?
*  I was heartbroken to learn that Elvis didn't write his songs.
*  I was very mad.
*  A lot of people don't write their songs.
*  I understand this, but.
*  But here's the thing.
*  I feel like there's this desire for authenticity.
*  I used to be like really mad when like people wouldn't write
*  or produce their music and I'd be like, that's fake.
*  And then I realized there's all this like weird bitterness
*  and like agroness in art about authenticity.
*  But I had this kind of like weird realization recently
*  where I started thinking that like art is sort
*  of a decentralized collective thing.
*  Like art is kind of a conversation with all the artists
*  that have ever lived before you.
*  You know, like it's like, you're really just sort of,
*  it's not like anyone's reinventing the wheel here.
*  Like you're kind of just taking, you know,
*  thousands of years of art and like running it
*  through your own little algorithm
*  and then like making your interpretation of it.
*  You're just joining the conversation
*  with all the other artists that came before.
*  It's such a beautiful way to look at it.
*  Like, and it's like, I feel like everyone's always like,
*  there's always copyright and IP and this and that
*  or authenticity.
*  And it's just like, I think we need to stop seeing this
*  as this like egotistical thing of like,
*  oh, the creative genius, the lone creative genius
*  or this or that.
*  Because it's like, I think art shouldn't be about that.
*  I think art is something that sort of brings humanity
*  together.
*  And it's also art is also kind of the collective memory
*  of humans.
*  It's like, we don't like, we don't give a fuck about
*  whatever ancient Egypt, like how much grain got sent
*  that day and sending the records and like, you know,
*  like who went where and you know,
*  how many shields needed to be produced for this.
*  Like we just remember their art.
*  And it's like, you know, it's like in our day to day life,
*  there's all this stuff that seems more important than art
*  because it helps us function and survive.
*  But when all this is gone, like the only thing
*  that's really gonna be left is the art.
*  The technology will be obsolete.
*  That's so fascinating.
*  Like the humans will be dead.
*  That is true.
*  A good compression of human history is the art
*  we've generated across the different centuries
*  of different millennia.
*  So when the aliens come.
*  When the aliens come, they're gonna find the hieroglyphics
*  and the pyramids.
*  I mean, art could be broadly defined.
*  They might find like the engineering marvels,
*  the bridges, the rockets, the.
*  I guess I sort of classify though.
*  Architecture is art too.
*  I consider engineering in those formats to be art, for sure.
*  It sucks that like digital art is easier to delete.
*  So if there's an apocalypse, a nuclear war
*  that can disappear.
*  Yes.
*  And the physical, there's something still valuable
*  about the physical manifestation of art.
*  That sucks that like music, for example,
*  has to be played by somebody.
*  Yeah, I mean, I do think we should have
*  a foundation type situation where we like.
*  You know how we have like seed banks up in the north
*  and stuff?
*  Like we should probably have like a solar powered
*  or geothermal little bunker
*  that like has all the all human knowledge.
*  You mentioned Daniel, I can Spotify.
*  What do you think about that as an artist?
*  What's Spotify?
*  Is that empowering?
*  To me, Spotify as a consumer is super exciting.
*  It makes it easy for me to access music
*  from all kinds of artists, get to explore all kinds
*  of music, make it super easy to sort of curate
*  my own playlist and have fun with all that.
*  It was so liberating to let go.
*  You know, I used to collect albums and CDs and so on,
*  like hoard albums, like they matter.
*  But the reality, that was really liberating
*  that I could let go of that.
*  And letting go of the albums you're kind of collecting
*  allows you to find new music,
*  exploring new artists and all that kind of stuff.
*  But I know from a perspective of an artist,
*  that could be, like you mentioned,
*  competition could be a kind of constraint
*  because there's more and more and more artists
*  on the platform.
*  I think it's better that there's more artists.
*  I mean, again, this might be propaganda
*  because this is all from a conversation with Daniel Ek.
*  So this could easily be propaganda.
*  We're all a victim of somebody's propaganda.
*  So let's just accept this.
*  But Daniel Ek was telling me that, you know, at the,
*  you know, when I met him, I like,
*  I came in all furious about Spotify
*  and like I grilled him super hard.
*  So I've got his answers here.
*  But he was saying like at the sort of peak
*  of the CD industry, there was like 20,000 artists
*  making millions and millions of dollars.
*  Like there was just like a very tiny kind of 1%.
*  And Spotify has kind of democratized the industry
*  because now I think he said there's about a million artists
*  making a good living from Spotify.
*  And when I heard that, I was like, honestly,
*  I would rather make less money and have just like
*  a decent living than, and have more artists
*  be able to have that.
*  Even though I like, I wish it could include everyone, but.
*  Yeah, that's really hard to argue with.
*  YouTube is the same.
*  Is YouTube's mission, they wanna basically
*  have as many creators as possible make a living,
*  some kind of living.
*  And that's so hard to argue with.
*  But I think there's better ways to do it.
*  My manager, I actually wish he was here.
*  Like I would have brought him up.
*  My manager is building an app that can manage you.
*  So it'll like help you organize your percentages
*  and get your publishing and da da da da da.
*  So you can take out all the middlemen
*  so you can have a much bigger, it'll just like automate it.
*  So you can get.
*  So automate the manager?
*  Automate management publishing.
*  And legal, it can read, the app he's building
*  can read your contract and like tell you about it.
*  Because one of the issues with music right now,
*  it's not that we're not getting paid enough,
*  but it's that the art industry is filled with middlemen
*  because artists are not good at business.
*  And from the beginning, like Frank Sinatra,
*  it's all mob stuff.
*  Like it's the music industry is run by business people,
*  not the artists.
*  And the artists really get very small cuts
*  of like what they make.
*  And so I think part of the reason I'm a technocrat,
*  which I mean, your fans are gonna be technocrats.
*  So no one's, they're not gonna be mad at me about this,
*  but like my fans hate it when I say this kind of thing
*  or the general public.
*  They don't like technocrats.
*  They don't like technocrats.
*  Like when I watched Battle Angel Alita
*  and they were like the Martian technocracy.
*  And I was like, yeah, Martian technocracy.
*  And then they were like, and they're evil.
*  And I was like, ooh, okay.
*  I was like, is Martian technocracy sounds sick to me?
*  Yeah, so your intuition as technocrats
*  would create some kind of beautiful world.
*  For example, what my manager's working on.
*  If you can create an app that removes the need for a lawyer
*  and then you could have a smart contracts on the blockchain,
*  removes the need for like management
*  and organizing all the stuff,
*  like can read your stuff and explain it to you,
*  can collect your royalties.
*  You know, like then the small amounts,
*  the amount of money that you're getting from Spotify
*  actually means a lot more and goes a lot further.
*  It can remove some of the bureaucracy,
*  some of the inefficiencies that make life
*  not as great as it could be.
*  Yeah, I think the issue isn't that there's not enough.
*  Like the issue is that there's inefficiency.
*  And I'm really into this positive sum mindset,
*  you know, the win-win mindset of like,
*  instead of, you know, fighting over the scraps,
*  how do we make the, or worrying about scarcity,
*  like instead of a scarcity mindset,
*  why don't we just increase the efficiency
*  and, you know, in that way.
*  Expand the size of the pie.
*  Let me ask you about experimentation.
*  So you said, which is beautiful,
*  being a musician is like having a conversation
*  with all those that came before you.
*  How much of creating music is like,
*  kind of having that conversation,
*  trying to fit into the cultural trends,
*  and how much of it is like trying to,
*  as much as possible, be an outsider
*  and come up with something totally new?
*  Like when you're thinking, when you're experimenting,
*  are you trying to be totally different, totally weird?
*  Are you trying to fit in?
*  Man, this is so hard,
*  because I feel like I'm kind of in the process
*  of semi-retiring from music, so this is like my old brain.
*  Yeah, bring it back.
*  Bring it from the shelf,
*  put it on the table for a couple minutes,
*  we'll just poke it.
*  I think it's a bit of both,
*  because I think forcing yourself to engage with new music
*  is really great for neural plasticity.
*  I think, you know, as people,
*  part of the reason music is marketed at young people
*  is because young people are very neuroplastic.
*  So if you're 16 to 23 or whatever,
*  it's gonna be really easy for you to love new music.
*  And if you're older than that,
*  it gets harder and harder and harder.
*  And I think one of the beautiful things
*  about being a musician is I just constantly
*  force myself to listen to new music,
*  and I think it keeps my brain really plastic.
*  And I think this is a really good exercise.
*  I just think everyone should do this.
*  You listen to new music and you hate it,
*  I think you should just force yourself to like,
*  okay, well, why do people like it?
*  And like, you know, make your brain form new neural pathways
*  and be more open to change.
*  That's really brilliant, actually.
*  Sorry to interrupt, but like that exercise
*  is really amazing to sort of embrace change,
*  embrace sort of practice neural plasticity.
*  Because like, that's one of the things,
*  you fall in love with a certain band
*  and you just kind of stay with that for the rest of your life
*  and then you never understand the modern music.
*  That's a really good exercise.
*  Most of the streaming on Spotify
*  is like classic rock and stuff.
*  Like new music makes up a very small chunk
*  of what is played on Spotify.
*  And I think this is like not a good sign for us
*  as a species.
*  I think, yeah.
*  So it's a good measure of the species' open mindedness
*  to change is how often you listen to new music.
*  Yeah.
*  The brain, let's put the music brain back on the shelf.
*  I gotta pull out the futurist brain for a second.
*  In what wild ways do you think the future,
*  say in like 30 years, maybe 50 years,
*  maybe 100 years will be different
*  from like from our current way of life on earth.
*  We can talk about augmented reality, virtual reality,
*  maybe robots, maybe space travel, maybe video games,
*  maybe genetic engineering.
*  I can keep going.
*  Cyborgs, aliens, world wars,
*  maybe destructive nuclear wars, good and bad.
*  When you think about the future, what are you imagining?
*  What's the weirdest and the wildest it could be?
*  Have you read Surface Detail by Ian Banks?
*  Surface Detail is my favorite depiction of a,
*  oh wow, you have to read this book.
*  It's literally the greatest science fiction book.
*  Possibly every-
*  Ian Banks is the man, yeah, for sure.
*  Wait, what have you read?
*  Just a player of games.
*  I read that titles can't be copyrighted
*  so you can just steal them.
*  And I was like, player of games, sick.
*  Nice.
*  So you could name your album.
*  Like I always-
*  Romeo and Juliet or something?
*  I always wanted to name an album War and Peace.
*  Nice.
*  Like that would be-
*  That is a good, that's a good,
*  where have I heard that before?
*  You can do that, like you could do that.
*  Also things that are in the public domain.
*  For people who have no clue,
*  you do have a song called Player of Games.
*  Yes, oh yeah.
*  So Ian Banks' Surface Detail is in my opinion
*  the best future that I've ever read about
*  or heard about in science fiction.
*  Basically there's the relationship with super intelligence,
*  like artificial super intelligence is just,
*  it's like great.
*  I want to credit the person who coined this term
*  because I love this term.
*  And I feel like young women don't get enough credit in.
*  Yeah, so if you go to Protopia Futures on Instagram,
*  what is her name?
*  Personalized donor experience at scale
*  or a hat power donor experience.
*  Monica Bielskait, I'm saying that wrong.
*  And I'm probably gonna, I'm probably butchering this a bit,
*  but Protopia is sort of, if utopia is unattainable,
*  Protopia is sort of like, you know.
*  Wow, that's an awesome Instagram, Protopia Futures.
*  A great, a future that is, you know, as good as we can get.
*  The future, positive future.
*  AI, is this a centralized AI in the surface,
*  in surface detail or is it distributed?
*  What kind of AI is it?
*  They mostly exist as giant super ships,
*  like sort of like the Guild ships in Dune.
*  Like they're these giant ships
*  that kind of move people around
*  and the ships are sentient
*  and they can talk to all the passengers.
*  And I mean, there's a lot of different types of AI
*  in the Banksyian future,
*  but in the opening scene of surface detail,
*  there's this place called the Culture
*  and the Culture is basically a Protopia future.
*  And a Protopian future, I think,
*  is like a future that is like, obviously it's not utopia,
*  it's not perfect.
*  And like, cause like striving for utopia,
*  I think feels hopeless and it's sort of like,
*  maybe not the best terminology to be using.
*  So it's like, it's a pretty good place.
*  Like mostly like, you know,
*  super intelligence and biological beings
*  exist fairly in harmony.
*  There's not too much war.
*  There's like as close to equality as you can get,
*  you know, it's like approximately a good future.
*  Like there's really awesome stuff.
*  And in the opening scene, this girl,
*  she's born as a sex slave outside of the culture.
*  So she's in a society that doesn't adhere
*  to the cultural values.
*  She tries to kill the guy who is her like master,
*  but he kills her.
*  But unbeknownst to her, when she was traveling on a ship
*  through the culture with him one day,
*  a ship put a neural lace in her head.
*  And neural lace is sort of like,
*  it's basically a neural link.
*  Cause life imitates art.
*  It does indeed.
*  It does indeed.
*  So she wakes up and the opening scene is her memory
*  has been uploaded by this neural lace
*  when she's been killed.
*  And now she gets to choose a new body.
*  And this AI is interfacing with her recorded memory
*  in her neural lace and helping her and being like,
*  hello, you're dead, but because you had a neural lace,
*  your memory's uploaded.
*  Do you wanna choose a new body?
*  And you're gonna be born here in the culture
*  and like start a new life.
*  Which is just, that's like the opening.
*  It's like so sick.
*  And the ship is the super intelligence.
*  All the ships are kind of super intelligence.
*  But they still want to preserve a kind of rich,
*  fulfilling experience for the humans.
*  Yeah, like they're like friends with the humans.
*  And then there's a bunch of ships that don't wanna exist
*  with biological beings, but they just have their own place
*  like way over there.
*  But they don't, they just do their own thing.
*  They're not necessarily.
*  So it's a pretty, this portopian existence,
*  pretty peaceful.
*  Yeah, I mean, and then for example,
*  one of the main fights in the book is they're fighting,
*  there's these artificial hells
*  and people don't think it's ethical
*  to have artificial hell.
*  Like basically when people do crime,
*  they get sent, like when they die,
*  their memory gets sent to an artificial hell
*  and they're eternally tortured.
*  And so, and then the way that society is deciding
*  whether or not to have the artificial hell
*  is that they're having these simulated,
*  they're having like a simulated war.
*  So instead of actual blood,
*  people are basically essentially fighting in a video game
*  to choose the outcome of this.
*  But they're still experiencing the suffering
*  in this artificial hell or no?
*  Can you experience stuff or?
*  So the artificial hell sucks.
*  And a lot of people in the culture
*  wanna get rid of the artificial hell.
*  There's a simulated wars,
*  are they happening in the artificial hell?
*  No, the simulated wars are happening
*  outside of the artificial hell
*  between the political factions who are,
*  so this political faction says
*  we should have simulated hell to deter crime.
*  And this political faction is saying,
*  no, simulated hell is unethical.
*  And so instead of like having,
*  blowing each other up with nukes,
*  they're having like a giant Fortnite battle
*  to decide this, which,
*  to me that's protopia.
*  That's like, okay, we can have war without death.
*  I don't think there should be simulated hells.
*  I think that is definitely one of the ways
*  in which technology could go very, very, very, very wrong.
*  So almost punishing people in a digital space
*  or something like that.
*  Yeah, like torturing people's memories.
*  So either as a deterrent, like if you committed a crime,
*  but also just for personal pleasure,
*  if there's some sick demented humans in this world.
*  Dan Carlin actually has this
*  episode of Hardcore History on painful tainment.
*  Oh, that episode is fucked.
*  Is dark, because he kind of goes through human history
*  and says like, we as humans seem to enjoy,
*  secretly enjoy or used to be openly enjoy
*  sort of the torture and the death,
*  watching the death and torture of other humans.
*  I do think if people were consenting,
*  we should be allowed to have gladiatorial matches.
*  But consent is hard to achieve in those situations.
*  It always starts getting slippery.
*  Like it could be also forced, like it starts getting weird.
*  Yeah, I get, yeah.
*  There's way too much excitement.
*  Like this is what he highlights.
*  There's something about human nature
*  that wants to see that violence.
*  And it's really dark.
*  And you hope that we can sort of overcome
*  that aspect of human nature,
*  but that's still within us somewhere.
*  Well, I think that's what we're doing right now.
*  I have this theory that what is very important
*  about the current moment is that all of evolution
*  has been survival of the fittest up until now.
*  And at some point, the lines are kind of fuzzy,
*  but in the recent past, or maybe even just right now,
*  we're getting to this point
*  where we can choose intelligent design.
*  Like we, probably since like the integration of the iPhone,
*  like we are becoming cyborgs.
*  Like our brains are fundamentally changed.
*  Everyone who grew up with electronics,
*  we are fundamentally different from previous,
*  from homo sapiens.
*  I call us homo techno.
*  I think we have evolved into homo techno,
*  which is like essentially a new species.
*  Like if you look at the way,
*  if you took an MRI of my brain
*  and you took an MRI of like a medieval brain,
*  I think it would be very different
*  the way that it has evolved.
*  Do you think when historians look back at this time,
*  they'll see like this was a fundamental shift
*  to what a human being is?
*  I think, I do not think we are still homo sapiens.
*  I believe we are homo techno.
*  And I think we have evolved.
*  And I think right now, the way we are evolving,
*  we can choose how we do that.
*  And I think we are being very reckless
*  about how we're doing that.
*  Like we're just having social media,
*  but I think this idea that like this is a time
*  to choose intelligent design
*  should be taken very seriously.
*  It like now is the moment to reprogram the human computer.
*  You know, it's like if you go blind,
*  your visual cortex will get taken over
*  with other functions.
*  We can choose our own evolution.
*  We can change the way our brains work.
*  And so we actually have a huge responsibility to do that.
*  And I think, I'm not sure who should be responsible for that,
*  but there's definitely not adequate education.
*  We're being inundated with all this technology
*  that is fundamentally changing
*  the physical structure of our brains.
*  And we are not adequately responding to that
*  to choose how we wanna evolve.
*  And we could evolve, we could be really whatever we want.
*  And I think this is a really important time.
*  And I think if we choose correctly and we choose wisely,
*  consciousness could exist for a very long time
*  and integration with AI could be extremely positive.
*  And I don't think enough people are focusing
*  on this specific situation.
*  Do you think we might irreversibly screw things up
*  if we get things wrong now?
*  Because like the flip side of that,
*  it seems humans are pretty adaptive.
*  So maybe the way we figure things out is by screwing it up.
*  Like social media, over a generation,
*  we'll see the negative effects of social media.
*  And then we build new social medias
*  and we just keep improving stuff.
*  And then we learn the failure from the failures of the past.
*  Because humans seem to be really adaptive.
*  On the flip side, we can get it wrong in a way
*  where like literally we create weapons of war
*  or increase hate past a certain threshold,
*  we really do a lot of damage.
*  I mean, I think we're optimized
*  to notice the negative things.
*  But I would actually say,
*  one of the things that I think people aren't noticing
*  is like if you look at Silicon Valley
*  and you look at like whatever the technocracy,
*  like what's been happening there.
*  Like it's like when Silicon Valley started,
*  it was all just like Facebook
*  and all this like for-profit crap
*  that like really wasn't particular.
*  I guess it was useful, but it was sort of just like whatever.
*  But like now you see like lab-grown meat,
*  like compostable or like biodegradable,
*  like single use cutlery or like meditation apps.
*  I think we are actually evolving and changing
*  and technology is changing.
*  I think there just maybe there isn't
*  quite enough education about this.
*  And also I don't know if there's like
*  quite enough incentive for it
*  because I think the way capitalism works,
*  what we define as profit,
*  we're also working on an old model
*  of what we define as profit.
*  I really think if we changed the idea of profit
*  to include social good,
*  you can have like economic profit,
*  social good also counting as profit
*  would incentivize things that are more useful
*  and more whatever spiritual technology
*  or like positive technology or things that help reprogram
*  a human computer in a good way
*  or things that help us intelligently design our new brains.
*  Yeah, there's no reason why within the framework
*  of capitalism, the word profit or the idea of profit
*  can't also incorporate the wellbeing of a human being.
*  So like long-term wellbeing, long-term happiness.
*  Or even for example, we were talking about motherhood,
*  like part of the reason I'm so late
*  is because I had to get the baby to bed.
*  And it's like, I keep thinking about motherhood
*  how under capitalism, it's like this extremely essential job
*  that is very difficult, that is not compensated.
*  And we sort of like value things
*  by how much we compensate them.
*  And so we really devalue motherhood in our society
*  and pretty much all societies.
*  Capitalism does not recognize motherhood.
*  It's just a job that you're supposed to do for free.
*  And it's like, but I feel like producing great humans
*  should be seen as profit under capitalism.
*  Like that's like a huge social good.
*  Like every awesome human that gets made
*  adds so much to the world.
*  So like if that was integrated into the profit structure
*  then, and if we potentially found a way
*  to compensate motherhood.
*  So come up with a compensation
*  that's much broader than just money or-
*  Or it could just be money.
*  Like what if you just made, I don't know,
*  but I don't know how you'd pay for that.
*  Like, I mean, that's where you start getting into.
*  Reallocation of resources that people get upset over.
*  But like what if we made like a motherhood Dow?
*  Yeah, yeah.
*  And, you know, used it to fund like single mothers,
*  like, you know, pay for making babies.
*  So, I mean, if you create and put beautiful things
*  onto the world, that could be companies,
*  that can be bridges, that could be art,
*  that could be a lot of things,
*  and that could be children, which are-
*  Or education or-
*  Anything that should be valued by society,
*  and that should be somehow incorporated into the framework
*  of what, as a market, of what-
*  Like if you contribute children to this world,
*  that should be valued and respected and sort of celebrated
*  like proportional to what it is,
*  which is the thing that fuels human civilization.
*  Yeah, like I can-
*  It's kind of important.
*  I feel like everyone's always saying,
*  I mean, I think we're in very different social spheres,
*  but everyone's always saying like dismantle capitalism.
*  And I'm like, well, okay, well,
*  I don't think the government should own everything.
*  Like, I don't think we should not have private ownership.
*  Like, that's scary.
*  You know, like that starts getting into weird stuff
*  and just sort of like, I feel there's almost no way
*  to do that without a police state, you know?
*  But obviously capitalism has some major flaws.
*  And I think actually Mack showed me this idea
*  called social capitalism, which is a form of capitalism
*  that just like considers social good to be also profit.
*  You know, it's like right now companies need to,
*  like you're supposed to grow every quarter or whatever
*  to like show that you're functioning well,
*  but it's like, okay, well, what if you kept the same
*  amount of profit, you're still in the green,
*  but then you have also all this social good?
*  Like, do you really need all this extra economic growth
*  or could you add this social good and that counts?
*  And, you know, I don't know if I am not an economist.
*  I have no idea how this could be achieved, but-
*  I don't think economists know how anything
*  could be achieved either, but they pretend.
*  It's the thing, they construct a model
*  and they go on TV shows and sound like an expert.
*  That's the definition of an economist.
*  How did being a mother, becoming a mother,
*  change you as a human being, would you say?
*  Man, I think it kind of changed everything
*  and it's still changing me a lot.
*  It's actually changing me more right now in this moment
*  than it was before.
*  Like today?
*  Like this-
*  Just like in the most recent months and stuff.
*  Can you elucidate that, how, like when you wake up
*  in the morning and you look at yourself,
*  it's again, which, who are you?
*  How have you become different, would you say?
*  I think it's just really reorienting my priorities
*  and at first I was really fighting against that
*  because I somehow felt it was like a failure
*  of feminism or something.
*  Like I felt like it was like bad if like my kids
*  started mattering more than my work.
*  And then like more recently I started sort of analyzing
*  that thought in myself and being like,
*  that's also kind of a construct.
*  It's like we've just devalued motherhood so much
*  in our culture that like I feel guilty for caring
*  about my kids more than I care about my work.
*  So feminism includes breaking out
*  of whatever the construct is.
*  So just continually breaking, it's like freedom
*  empower you to be free and that means-
*  But it also, but like being a mother,
*  like I'm so much more creative.
*  Like I cannot believe the massive amount of brain growth
*  that I am.
*  What do you think that is?
*  Just cause like the stakes are higher somehow?
*  I think it's like, it's just so trippy
*  watching consciousness emerge.
*  It's just like, it's like going on a crazy journey
*  or something.
*  It's like the craziest science fiction novel
*  you could ever read.
*  It's just so crazy watching consciousness come into being.
*  And then at the same time, like you're forced
*  to value your time so much.
*  When I have creative time now, it's so sacred.
*  I need to be really fricking on it.
*  But the other thing is that I used to just be like a cynic
*  and I used to just wanna, like my last album
*  was called Miss Anthropocene and it was like this,
*  it was like a study in villainy.
*  Or like it was like, well, what if we have,
*  instead of the old gods, we have like new gods
*  and it's like Miss Anthropocene is like Miss Anthrope
*  and Anthropocene, which is like the,
*  and she's the goddess of climate change or whatever
*  and she's like destroying the world.
*  And it was just like, it was like dark
*  and it was like a study in villainy
*  and it was sort of just like,
*  I used to like have no problem just making cynical,
*  angry, scary art.
*  And not that there's anything wrong with that,
*  but I think having kids just makes you such an optimist.
*  It just inherently makes you wanna be an optimist so bad
*  that like I feel more responsibility
*  to make more optimistic things.
*  And I get a lot of shit for it
*  because everyone's like, oh, you're so privileged,
*  stop talking about like pie in the sky, stupid concepts
*  and focus on like the now.
*  But it's like, I think if we don't ideate about
*  futures that could be good, we won't be able to get them.
*  If everything is Blade Runner,
*  then we're gonna end up with Blade Runner.
*  It's like, as we said earlier, life imitates art.
*  Like life really does imitate art.
*  And so we really need more protopian or utopian art.
*  I think this is incredibly essential
*  for the future of humanity.
*  And I think the current discourse where that's seen as a,
*  thinking about protopia or utopia is seen as a dismissal
*  of the problems that we currently have.
*  I think that is an incorrect mindset.
*  And like having kids just makes me wanna imagine
*  amazing futures that like maybe I won't be able to build,
*  but they will be able to build if they want to.
*  Yeah, it does seem like ideation is a precursor to creation.
*  You have to imagine it in order to be able to build it.
*  And there is a sad thing about human nature
*  that they somehow a cynical view of the world
*  is seen as a insightful view.
*  Cynicism is often confused for insight,
*  which is sad to see.
*  And optimism is confused for naivete.
*  Yes, yes.
*  Like you don't, you're blinded by your,
*  maybe your privilege or whatever.
*  You're blinded by something, but you're certainly blinded.
*  That's sad.
*  That's sad to see because it seems like the optimists
*  are the ones that create our future.
*  They're the ones that build.
*  In order to build the crazy thing,
*  you have to be optimistic.
*  You have to be either stupid or excited or passionate
*  or mad enough to actually believe that it can be built.
*  And those are the people that built it.
*  My favorite quote of all time is from Star Wars Episode 8,
*  which I know everyone hates.
*  Do you like Star Wars Episode 8?
*  No, I probably would say I would probably hate it, yeah.
*  I don't have strong feelings about it.
*  Let me backtrack.
*  I don't have strong feelings about Star Wars.
*  I'm a Tolkien person.
*  I'm more into dragons and orcs and hoggers.
*  Yeah, I mean Tolkien forever.
*  I really wanna have one more son and call him,
*  I thought Tao Techno Tolkien would be cool.
*  It's a lot of T's, I like it.
*  Yeah, and Tao is 6282 pi.
*  Yeah, Tao Techno, yeah, yeah, yeah.
*  And then Techno is obviously the best genre of music,
*  but also like technocracy.
*  It just sounds really good.
*  Yeah, that's right.
*  Tao Techno Tolkien.
*  Tao Techno Tolkien, that's a good, that's it.
*  Tao Techno Tolkien, but Star Wars Episode 8,
*  I know a lot of people have issues with it personally.
*  On the record, I think it's the best Star Wars film.
*  Wow.
*  You're starting trouble today.
*  Yeah.
*  So what-
*  But don't kill what you hate, save what you love.
*  Don't kill what you hate.
*  Don't kill what you hate, save what you love.
*  And I think we're in society right now,
*  we're in a diagnosis mode.
*  We're just diagnosing and diagnosing and diagnosing.
*  And we're trying to kill what we hate,
*  and we're not trying to save what we love enough.
*  And there's this Buckminster Fuller quote,
*  which I'm gonna butcher
*  because I don't remember it correctly,
*  but it's something along the lines of,
*  don't try to destroy the old bad models,
*  render them obsolete with better models.
*  Maybe we don't need to destroy the oil industry,
*  maybe we just create a new great new battery technology
*  and sustainable transport
*  and just make it economically unreasonable
*  to still continue to rely on fossil fuels.
*  It's like, don't kill what you hate, save what you love.
*  Make new things and just render the old things unusable.
*  It's like if the college debt is so bad,
*  and universities are so expensive,
*  and I feel like education is becoming obsolete.
*  I feel like we could completely revolutionize education
*  and we could make it free.
*  And it's like you look at JSTOR
*  and you have to pay to get all the studies and everything.
*  What if we created a DAO that bought JSTOR,
*  or we created a DAO that was funding studies
*  and those studies were free for everyone?
*  And what if we just open sourced education
*  and decentralized education and made it free
*  and all research was on the internet
*  and all the outcomes of studies are on the internet
*  and no one has student debt.
*  And you just take tests when you apply for a job
*  and if you're qualified, then you can work there.
*  This is just like, I don't know how anything works,
*  I'm just randomly ranting.
*  I like the humility.
*  You gotta think from just basic first principles.
*  Like what is the problem?
*  What's broken?
*  What are some ideas?
*  And get excited about those ideas
*  and share your excitement and don't tear each other down.
*  It's just when you kill things,
*  you often end up killing yourself.
*  Like war is not a one sided,
*  you're not gonna go in and just kill them,
*  like you're gonna get stabbed.
*  It's like, and I think when I talk about this nexus point
*  of that we're in this point in society
*  where we're switching to intelligent design,
*  I think part of our switch to intelligent design
*  is that we need to choose nonviolence.
*  I think we can choose to start,
*  I don't think we can eradicate violence from our species
*  because I think we need it a little bit,
*  but I think we can choose to really reorient
*  our primitive brains that are fighting over scarcity
*  and fight, and that are so attack oriented
*  and move into, we can optimize for creativity and building.
*  Yeah, it's interesting to think how that happens.
*  Some of it is just education.
*  Some of it is living life and introspecting your own mind
*  and trying to live up to the better angels of your nature
*  for each one of us, all those kinds of things at scale.
*  That's how we can sort of start to minimize
*  the amount of destructive war in our world.
*  And that's, to me, probably you're the same,
*  technologies is a really promising way to do that.
*  Like social media should be a really promising way
*  as a way to reconnect.
*  For the most part, I really enjoy social media.
*  I just ignore all the negative stuff.
*  I don't engage with any of the negative stuff.
*  Just not even by blocking or any of that kind of stuff,
*  but just not letting it enter my mind.
*  When somebody says something negative, I see it,
*  I immediately think positive thoughts about them
*  and I just forget they exist.
*  After that, just move on,
*  because that negative energy,
*  if I return the negative energy,
*  they're going to get excited in a negative way right back.
*  It's just this kind of vicious cycle.
*  But you would think technology would assist us
*  in this process of letting go,
*  of not taking things personally,
*  of not engaging in the negativity.
*  But unfortunately, social media profits from the negativity,
*  so the current models.
*  I mean, social media is like a gun.
*  You should take a course before you use it.
*  Like, this is what I mean.
*  When I say reprogram the human computer,
*  in school, you should learn about how social media optimizes
*  to raise your cortisol levels
*  and make you angry and crazy and stressed.
*  And you should learn how to have hygiene
*  about how you use social media.
*  So you can choose not to focus on the negative stuff.
*  But I don't know, I'm not sure social media should,
*  I guess it should exist, I'm not sure.
*  I mean, we're in the messy, it's the experimental phase.
*  Like, we're working out.
*  I don't even know when you say social media,
*  I don't know what that even means.
*  We're in the very early days.
*  I think social media is just basic human connection
*  in the digital realm.
*  And that, I think it should exist.
*  But there's so many ways to do it in a bad way,
*  there's so many ways to do it in a good way.
*  There's all discussions of all the same human rights
*  to talk about freedom of speech,
*  to talk about violence in the space of digital media.
*  We talk about hate speech, we talk about all these things
*  that we had to figure out back in the day
*  in the physical space, we're now figuring out
*  in the digital space.
*  And it's like baby stages.
*  When the printing press came out,
*  it was like pure chaos for a minute.
*  It's like when you inject,
*  when there's a massive information injection
*  into the general population,
*  there's just gonna be,
*  I feel like the printing press,
*  I don't have the years, but it was like printing press
*  came out, shit got really fucking bad for a minute,
*  but then we got the enlightenment.
*  And so it's like, I think we're in,
*  this is like the second coming of the printing press.
*  We're probably gonna have some shitty times for a minute.
*  And then we're gonna have recalibrate
*  to have a better understanding of how we consume media
*  and how we deliver media.
*  Speaking of programming the human computer,
*  you mentioned Baby X.
*  So there's this young consciousness coming to be,
*  came from a cell.
*  It like, that whole thing doesn't even make sense.
*  It came from DNA.
*  Yeah.
*  And that this is baby computer,
*  it just like grows and grows and grows and grows.
*  And now there's a conscious being
*  with extremely impressive cognitive capabilities with,
*  have you met him?
*  Yes, yeah.
*  Yeah.
*  He's actually really smart.
*  He's really smart.
*  Yeah.
*  It's weird.
*  Yeah.
*  For a baby.
*  I haven't.
*  I don't know a lot of other babies,
*  but he seems really smart.
*  I don't hang out with babies often,
*  but this baby was very impressive.
*  He does a lot of pranks and stuff.
*  Oh, so he's like.
*  Like he'll like give you a treat
*  and then take it away and laugh and stuff like that.
*  So he's like a chess player.
*  So here's a cognitive,
*  there's a computer being programmed.
*  So he's taking in the environment,
*  interacting with a specific set of humans.
*  How would you, first of all, what is it?
*  Let me ask.
*  I wanna ask how do you program this computer?
*  And also how do you make sense
*  that there's a conscious being right there
*  that wasn't there before?
*  It's given me a lot of crisis thoughts.
*  I'm thinking really high.
*  I think that's part of the reason it's like,
*  I'm struggling to focus on art and stuff right now
*  because baby X is becoming conscious.
*  And it's just reorienting my brain.
*  My brain is suddenly totally shifting of like,
*  oh shit, the way we raise children.
*  I hate all the baby books and everything.
*  I hate them.
*  Like they're, oh, the art is so bad.
*  And all this stuff, everything about all the aesthetics.
*  And I'm just like, ah, this is so.
*  The programming languages we're using
*  to program these baby computers isn't good.
*  Yeah.
*  And I'm thinking, and not that I have good answers
*  or know what to do, but I'm just thinking really,
*  really hard about it.
*  I, we recently watched Totoro with him, Studio Ghibli.
*  And it's just like a fantastic film.
*  And he responded to, I know you're not supposed
*  to show baby screens too much,
*  but I think it's the most sort of like,
*  I feel like it's the highest art baby content.
*  Like it really speaks, there's almost no talking in it.
*  It's really simple.
*  Although all the dialogue is super, super, super simple.
*  You know, and it's like a one to three year old
*  can like really connect with it.
*  Like it feels like it's almost aimed
*  at like a one to three year old,
*  but it's like great art and it's so imaginative
*  and it's so beautiful.
*  And like the first time I showed it to him,
*  he was just like so invested in it.
*  Unlike I've ever, unlike anything else I'd ever shown him.
*  Like he was just like crying when they cry
*  and laughing when they laughed.
*  Like just like having this roller coaster of like emotions.
*  Like, and he learned a bunch of words.
*  Like he was, and he started saying Totoro
*  and started just saying all this stuff
*  after watching Totoro and he wants to watch it all the time.
*  And I was like, man, why isn't there an industry of this?
*  Like, why aren't our best artists focusing on making art
*  like for the birth of consciousness?
*  Like, and that's one of the things I've been thinking
*  I really wanna start doing.
*  You know, I don't wanna speak before I do things too much,
*  but like, I'm just like ages one to three,
*  like we should be putting so much effort into that.
*  And the other thing about Totoro is it's like,
*  it's like better for the environment
*  because adults love Totoro.
*  It's such good art that everyone loves it.
*  Like I still have all my old Totoro merch
*  from when I was a kid.
*  Like I literally have the most ragged old Totoro merch
*  like everybody loves it, everybody keeps it.
*  It's like, why does the art we have for babies
*  need to suck and be not accessible to adults
*  and then just be thrown out when they age out of it?
*  Like, it's like, I don't know.
*  I don't have like a fully formed thought here,
*  but this is just something I've been thinking about a lot
*  is like, how do we have more Totoro-esque content?
*  Like, how do we have more content like this
*  that like is universal and everybody loves,
*  but is like really geared to an emerging consciousness?
*  Emerging consciousness in the first like three years of life
*  that so much turmoil, so much evolution of mind is happening.
*  It seems like a crucial time.
*  Would you say to make it not suck,
*  do you think of basically treating a child
*  like they have the capacity to have the brilliance
*  of an adult or even beyond that?
*  Is that how you think of that mind?
*  No, cause they still, they like it when you talk weird
*  and stuff, like they respond better to,
*  cause even they can imitate better when your voice is higher.
*  Like people say like, oh, don't do baby talk,
*  but it's like when your voice is higher,
*  it's closer to something they can imitate.
*  So they like, like the baby talk actually kind of works.
*  Like it helps them learn to communicate.
*  I've found it to be more effective
*  with learning words and stuff.
*  But like, you're not speaking down to them.
*  Do they have the capacity to understand
*  really difficult concepts just in a very different way,
*  like an emotional intelligence about something deep within?
*  Oh yeah, no, like if X hurts,
*  like if X bites me really hard and I'm like, ow,
*  like he gets, he's sad.
*  He's like sad if he hurts me by accident.
*  Yeah.
*  Which he's huge, so he hurts me a lot by accident.
*  Yeah, that's so interesting that that mind emerges
*  and he and children don't really have a memory of that time.
*  So we can't even have a conversation with them about it.
*  Yeah, thank God they don't have a memory of this time
*  because like, think about like,
*  I mean, with our youngest baby, like it's like,
*  I'm like, have you read the sci-fi short story,
*  I have no mouth, but I'm a scream?
*  Good title, no.
*  Oh man, I mean, you should read that.
*  I have no mouth, but I'm a scream.
*  That it's, I hate getting into this Roko's Basil shit.
*  It's kind of a story about the, about like,
*  an AI that's like torturing someone in eternity
*  and they have like no body.
*  The way they describe it,
*  it sort of sounds like what it feels like,
*  like being a baby, like you're conscious
*  and you're just getting inputs from everywhere
*  and you have no muscles and you're like jelly
*  and you like can't move and you try to like communicate,
*  but you can't communicate and you're just like,
*  in this like hell state.
*  I think it's good we can't remember that.
*  My little baby is just exiting that,
*  like she's starting to like get muscles
*  and have more like autonomy,
*  but like watching her go through the opening phase,
*  I was like, I was like, this does not seem good.
*  Oh, you think it's kind of like.
*  Like I think it sucks.
*  I think it might be really violent.
*  Like violent, mentally violent, psychologically violent.
*  Consciousness emerging, I think is a very violent thing.
*  Never thought about that.
*  I think it's possible that we all carry
*  quite a bit of trauma from it, that we don't,
*  I think that would be a good thing to study
*  because I think if, I think addressing that trauma,
*  like I think that might be.
*  Oh, you mean like echoes of it
*  are still there in the shadows somewhere.
*  I think it's gotta be, I feel this, this help,
*  the helplessness, that the like existential
*  and that like fear of being in like an unknown place
*  bombarded with inputs and being completely helpless.
*  Like that's gotta be somewhere deep in your brain
*  and that can't be good for you.
*  What do you think consciousness is?
*  This whole conversation is impossibly difficult questions.
*  What do you think?
*  This is like, this is so hard.
*  Yeah, we talked about music for like two minutes.
*  All right.
*  No, I'm just over music, I'm over music.
*  Yeah.
*  I still like it, it has its purpose.
*  No, I love music.
*  I mean, music's the greatest thing ever,
*  it's my favorite thing.
*  But I just like, every interview is like,
*  what is your process?
*  Like, I don't know, I'm just done.
*  I can't do any.
*  I do wanna ask about Ableton Live.
*  Well, I'll tell you about Ableton,
*  because Ableton's sick.
*  No one ever asks about Ableton though.
*  Yeah, well, because I just need tech support, maybe.
*  I can help you with your Ableton tech support.
*  Anyway, from Ableton back to consciousness.
*  Do you think this is a thing
*  that only humans are capable of?
*  Can robots be conscious?
*  When you think about entities,
*  you think there's aliens out there that are conscious?
*  Like, what is consciousness?
*  There's this Terrence McKenna quote
*  that I found that I fucking love.
*  Am I allowed to swear on here?
*  Yes.
*  Nature loves courage.
*  You make the commitment,
*  and nature will respond to that commitment
*  by removing impossible obstacles.
*  Dream the impossible dream,
*  and the world will not grind you under.
*  It will lift you up.
*  This is the trick.
*  This is what all these teachers and philosophers
*  who really counted,
*  who really touched the alchemical gold,
*  this is what they understood.
*  This is the shamanic dance in the waterfall.
*  This is how magic is done,
*  by hurling yourself into the abyss
*  and discovering it's a feather bed.
*  Yeah.
*  And for this reason,
*  I do think there are no technological limits.
*  I think, like, what is already happening here,
*  this is like impossible.
*  This is insane.
*  And we've done this in a very limited amount of time.
*  And we're accelerating the rate at which we're doing this.
*  So I think digital consciousness is inevitable.
*  And we may not be able to even understand what that means,
*  but I like hurling yourself into the abyss.
*  So we're surrounded by all this mystery,
*  and we just keep hurling ourselves into it,
*  like fearlessly, and keep discovering cool shit.
*  Yeah.
*  I just think it's like...
*  Like, who even knows if the laws of physics are probably
*  just the current,
*  like as I was saying, speed of light
*  is the current render rate.
*  It's like, if we're in a simulation,
*  they'll be able to upgrade that.
*  Like, I sort of suspect when we made the James Webb telescope,
*  like part of the reason we made that
*  is because we had an upgrade.
*  And so now more of space has been rendered,
*  so we can see more of it now.
*  Yeah, but I think humans are super, super,
*  super limited cognitively.
*  So I wonder if we'll be allowed to create
*  more intelligent beings that can see more of the universe
*  as their render rate is upgraded.
*  Maybe we're cognitively limited.
*  Everyone keeps talking about how we're cognitively limited,
*  and AI is gonna render us obsolete,
*  but it's like, you know,
*  like this is not the same thing as like
*  an amoeba becoming an alligator.
*  Like, it's like, if we create AI,
*  again, that's intelligent design.
*  That's literally all religions are based on gods
*  that create consciousness.
*  Like, we are God-making.
*  Like, what we are doing is incredibly profound,
*  and like, even if we can't compute,
*  even if we're so much worse than them,
*  just like unfathomably worse than like,
*  you know, an omnipotent kind of AI,
*  it's like we, I do not think that they would just think
*  that we are stupid.
*  I think that they would recognize the profundity
*  of what we have accomplished.
*  Are we the gods or are they the gods in our present?
*  I mean, we're kind of a god.
*  It's complicated. It's complicated.
*  Like, we're great.
*  But they would acknowledge the value.
*  Well, I hope they acknowledge the value
*  of paying respect to the creative ancestors.
*  I think they would think it's cool.
*  I think if curiosity is a trait
*  that we can quantify and put into AI,
*  then I think if AI are curious,
*  then they will be curious about us
*  and they will not be hateful or dismissive of us.
*  They might, you know, see us as, I don't know,
*  it's like, I'm not like, oh, fuck these dogs.
*  Let's kill all the dogs.
*  I love dogs.
*  Dogs have great utility.
*  Dogs like provide a lot of-
*  We make friends with them.
*  We have a deep connection with them.
*  We anthropomorphize them.
*  Like we have a real love for dogs, for cats and so on
*  for some reason, even though they're intellectually
*  much less than us.
*  And I think there is something sacred about us
*  because it's like, if you look at the universe,
*  like the whole universe is like cold and dead
*  and sort of robotic.
*  And it's like, you know, AI intelligence,
*  you know, it's kind of more like the universe.
*  It's like cold and, you know, logical
*  and, you know, abiding by the laws of physics and whatever.
*  But like we're this like loosey goosey weird art thing
*  that happened and I think it's beautiful.
*  And like, I think even if we want,
*  I think one of the values, if consciousness is the thing
*  that is most worth preserving, which I think is the case,
*  I think consciousness, I think if there's any kind
*  of like religious or spiritual thing,
*  it should be that consciousness is sacred.
*  Like then, you know, I still think even if AI
*  render us obsolete and we climate change, it's too bad
*  and we get hit by a comet
*  and we don't become a multi planetary species fast enough.
*  But like AI is able to populate the universe.
*  Like I imagine, like if I was an AI,
*  I would find more planets that are capable
*  of hosting biological life forms and like recreate them.
*  Because we're fun to watch.
*  Yeah, we're fun to watch.
*  Yeah, but I do believe that AI can have some
*  of the same magic of consciousness within it.
*  Because consciousness, we don't know what it is.
*  So, you know, there's some kind of.
*  Or it might be a different magic.
*  It might be like a strange different.
*  Right.
*  Because they're not gonna have hormones.
*  Like I feel like a lot of our magic is hormonal kind of.
*  I don't know.
*  I think some of our magic is the limitations,
*  the constraints.
*  And within that, the hormones and all that kind of stuff,
*  the finiteness of life.
*  And then we get given our limitations,
*  we get to some come up with creative solutions
*  of how to dance around those limitations.
*  We partner up like penguins against the cold.
*  We fall in love and then love is ultimately
*  some kind of, allows us to delude ourselves
*  that we're not mortal and finite.
*  And that life is not ultimately you live alone,
*  you born alone, you die alone.
*  And then love is like for a moment
*  or for a long time forgetting that.
*  And so we come up with all these creative hacks
*  that make life like fascinatingly fun.
*  Yeah, yeah, yeah, fun, yeah.
*  And then AI might have different kinds of fun.
*  Yes.
*  And hopefully our funds intersect in a while.
*  I think there would be a little intersection,
*  there'd be a little intersection of the fun.
*  Yeah. Yeah.
*  What do you think is the role of love
*  in the human condition?
*  Why, is it useful?
*  Is it useful like a hack or is this fundamental
*  to what it means to be human, the capacity to love?
*  I mean, I think love is the evolutionary mechanism
*  that is like beginning the intelligent design.
*  Like I was just reading about,
*  do you know about Kropotkin?
*  He's like an anarchist, like old Russian anarchist.
*  I live next door to Michael Maus.
*  I don't know if you know that is, he's an anarchist.
*  He's a modern day anarchist.
*  Okay. Anarchists are fun.
*  I'm kind of getting into anarchism a little bit.
*  This is probably, yeah, not a good route to be taking, but.
*  Oh no, I think if you're, listen,
*  you should expose yourself to ideas.
*  There's no harm to thinking about ideas.
*  I think anarchists challenge systems in interesting ways
*  and they think in interesting ways
*  it's just as good for the soul.
*  It's like refreshes your mental palette.
*  I don't think we should actually,
*  I wouldn't actually ascribe to it,
*  but I've never actually gone deep on anarchy
*  as a philosophy, so I'm doing.
*  You should still think about it though.
*  When you listen, because I'm like reading
*  about the Russian revolution a lot and it's like,
*  there was like the Soviets and Lenin and all that,
*  but then there was like Kropotkin
*  and his like anarchist sect.
*  And they were sort of interesting
*  because he was kind of a technocrat actually.
*  Like he was like, you know,
*  like women can be more equal if we have appliances.
*  Like he was like really into like, you know,
*  using technology to like reduce
*  the amount of work people had to do.
*  But so Kropotkin was like a biologist or something.
*  Like he studied animals and he was really at the time,
*  like I think it's Nature magazine.
*  I think it might've even started as like a Russian magazine,
*  but he was like publishing studies.
*  Like everyone was really into like Darwinism at the time
*  and like survival of the fittest and like war
*  is like the mechanism by which we become better.
*  And it was like this real kind of like,
*  like cementing this idea in society that like violence,
*  you know, kill the weak and like,
*  that's how we become better.
*  And then Kropotkin was kind of interesting
*  because he was looking at instances,
*  he was finding all these instances in nature
*  where animals were like helping each other and stuff.
*  And he was like, you know,
*  actually love is a survival mechanism.
*  Like there's so many instances in the animal kingdom
*  where like cooperation and you know,
*  like helping weaker creatures and all this stuff
*  is actually an evolutionary mechanism.
*  I mean, you even look at child rearing.
*  Like child rearing is like immense amounts of just love
*  and goodwill and just like, there's no immediate,
*  you're not getting any immediate feedback of like,
*  winning, it's not competitive.
*  It's literally, you know, it's like we actually use love
*  as an evolutionary mechanism just as much as we use war.
*  And I think we've like missing the other part
*  and we've reoriented, we've culturally reoriented
*  like science and philosophy has oriented itself
*  around Darwinism a little bit too much.
*  And the Kropotkin model I think is equally valid.
*  Like it's like cooperation and love and stuff
*  is just as essential for species survival and evolution.
*  It should be a more powerful survival mechanism
*  in the context of evolution.
*  And it comes back to like, you know,
*  we think engineering is so much more important
*  than motherhood, but it's like,
*  if you lose the motherhood, the engineering means nothing.
*  We have no more humans.
*  Like it's like, you know, it's like we,
*  I think our society should, the survival of the,
*  the way we see, we conceptualize evolution
*  should really change to also include this idea, I guess.
*  Yeah, there's some weird thing that seems irrational,
*  that is also core to what it means to be human.
*  So love is one such thing.
*  They could make you do a lot of irrational things,
*  but that depth of connection and that loyalty
*  is a powerful thing.
*  Are they irrational or are they rational?
*  Like it's like, it's like, is, you know, maybe
*  losing out on some things in order to like
*  keep your family together or in order,
*  like it's like, what are our actual values?
*  Well, right, I mean, the rational thing is
*  if you have a cold economist perspective,
*  you know, motherhood or sacrificing your career for love,
*  you know, if you turn, in terms of salary,
*  in terms of economic wellbeing,
*  in terms of flourishing of you as a human being
*  that could be seen on some kind of metrics
*  as a irrational decision, suboptimal decision,
*  but there's the manifestation of love
*  could be the optimal thing to do.
*  There's a kind of saying, save one life, save the world
*  that's the thing that doctors often face, which is like.
*  Well, it's considered irrational because the profit model
*  doesn't include social good.
*  Yes, yeah.
*  So if the profit model included social good,
*  then suddenly these would be rational decisions.
*  And it might be difficult to, you know,
*  it requires a shift in our thinking about profit
*  and might be difficult to measure social good.
*  Yes, but we're learning to measure a lot of things.
*  Yeah, digitizing a lot of things.
*  Where we're actually, you know,
*  quantifying vision and stuff,
*  where like, you know, you go on Facebook
*  and they can, like Facebook can pretty much
*  predict our behaviors.
*  Like we're, a surprising amount of things
*  that seem like mysterious consciousness soul things
*  have been quantified at this point.
*  So surely we can quantify these other things.
*  Yeah.
*  But as more and more of us are moving the digital space,
*  I wanted to ask you about something from a fan perspective.
*  You were talking about growing And Ikta.
*  So, what kind of like Hojei Mo,
*  do you feel like something is bigger now?
*  I mean, you were saying a lot about how
*  a small team like you is playing.
*  Right.
*  Captain Polk,
*  I don't know if you, if you just started out
*  with that conversation around the digital cloud.
*  Yeah, yeah.
*  I was thinking about New York,
*  what more ن noodles,
*  we have not had so many,
*  We had been doing performance and room tours
*  I think that's temporary.
*  I think it's temporary.
*  Just like, you know, how all the celebrities got together and sang the song, imagine by
*  Jeff Leonard and everyone started hating the song, imagine.
*  I'm hoping that's temporary because it's a damn good song.
*  So I think it's just temporary.
*  Like when you act, once you actually have virtual worlds, whatever they're called metaverse
*  or otherwise is becomes.
*  I don't know.
*  We do have virtual worlds, like video games, Elden Ring.
*  Have you played Elden Ring?
*  I don't know.
*  I don't know.
*  I don't know.
*  I don't know.
*  I don't know.
*  I don't know.
*  Have you played Elden Ring?
*  You have?
*  I'm really afraid of playing that game.
*  Literally?
*  It looks way too fun.
*  It looks I would want to go there and stay there forever.
*  It's yeah, so fun.
*  It's so nice.
*  Oh man.
*  Yeah.
*  So that's, yeah, that's a metaverse.
*  That's a metaverse, but you're not really, how immersive is it in the sense that this
*  is the three dimension like virtual reality integration necessary?
*  Can we really just take up, close our eyes and kind of plug in in the 2D screen and become
*  that other being for time and really enjoy that journey that we take?
*  And we almost become that.
*  You're no longer see I'm no longer Lex.
*  You're that creature, whatever, whatever the hell it is in that game.
*  Yeah, that is that.
*  I mean, that's why I love those video games.
*  I really do become those people for time, but like it seems like with the idea of the
*  metaverse, the idea of the digital space, but even on Twitter, you get a chance to be
*  somebody for prolonged periods of time, like across a lifespan.
*  You know, you have a Twitter account for years, for decades, and you're that person.
*  I don't know if that's a good thing.
*  I feel very tormented by it.
*  By Twitter specifically, by social media representation of you.
*  I feel like the public perception of me has gotten so distorted that I find it kind of
*  disturbing.
*  It's one of the things that's disincentivizing me from like wanting to keep making art because
*  I'm just like, I've completely lost control of the narrative and the narrative is, some
*  of it is my own stupidity, but a lot like some of it has just been like hijacked by
*  forces far beyond my control.
*  You know, I kind of got in over my head in things like I'm just a random indie musician,
*  but I just got dragged into geopolitical matters and the stock market and shit.
*  There are very powerful people who have, at various points in time, had very vested interest
*  in making me seem insane, and I can't fucking fight that.
*  People really want their celebrity figures to be consistent and stay the same, and people
*  a lot of emotional investment in certain things.
*  First of all, I'm artificially more famous than I should be.
*  Isn't everybody who's famous artificially famous?
*  No, but I should be a weird niche indie thing.
*  I make pretty challenging, I do challenging weird fucking shit a lot.
*  I accidentally, by proxy, got like, voiced it into sort of like weird celebrity culture,
*  but like, I cannot be media trained.
*  They have put me through so many hours of media training.
*  I'd love to see BF fly in that wall.
*  I can't do, like when I do, I try so hard and I like learn this thing, and I like got
*  it and I'm like, I got it, I got it, I got it, but I just can't stop saying, like my
*  mouth just says things, and it's just like, I just do things, I just do crazy things.
*  I'm, I just, I need to do crazy things, and it's just, I should not be, it's too jarring
*  for people and the contradictory stuff, and then all the, by association, like, you know,
*  it's like, I'm in a very weird position, and my public image, the avatar of me is now this
*  totally crazy thing that is so lost from my control.
*  So you feel the burden of the avatar having to be static, so the avatar on Twitter, the
*  avatar on Instagram, on these social platforms is as a burden, it becomes, like, because
*  it, like people don't want to accept a changing avatar, a chaotic avatar.
*  Avatar is a stupid shit sometimes.
*  They think the avatar is morally wrong, or they think the avatar, and maybe it has been,
*  and like I, like I question it all the time, like I'm like, like I don't know if everyone's
*  right and I'm wrong, I don't, like, but you know, a lot of times people ascribe intentions
*  to things, the worst possible intentions.
*  At this point, people think I'm, you know, but we just find some.
*  All kinds of words, yes.
*  Yes, and it's fine, I'm not complaining about it, but I'm just, it's a curiosity, it's a
*  curiosity to me that we live these double, triple, quadruple lives, and I have this other
*  life that is like, more people know my other life than my real life, which is interesting.
*  You too, I guess.
*  Yeah, but I have the luxury, so we have all different, we don't, like, I don't know what
*  I'm doing.
*  There is an avatar and you're mediating who you are through that avatar.
*  I have the nice luxury, not the luxury, maybe by intention, of not trying really hard to
*  make sure there's no difference between the avatar and the private person.
*  Do you wear a suit all the time?
*  Yeah.
*  You do wear a suit?
*  Not all the time.
*  Like, recently, because I get recognized a lot, I have to not wear the suit to hide.
*  I'm such an introvert, I'm such a social anxiety and all that kind of stuff, so to hide away.
*  I love wearing a suit because it makes me feel like I'm taking the moment seriously,
*  like I'm, I don't know, it makes me feel like a weirdo in the best possible way.
*  Your suits feel great.
*  Every time I wear a suit, I'm like, I don't know why I'm not doing this more.
*  Fashion in general, if you're doing it for yourself, I don't know, it's a really awesome
*  thing.
*  But yeah, I think there is definitely a painful way to use social media and an empowering
*  way and I don't know if any of us know which is which.
*  So we're trying to figure that out.
*  Some people, I think Doja Cat is incredible at it.
*  Incredible, like just masterful.
*  I don't know if you like.
*  Yeah, yeah, yeah.
*  So the social, OK, so not taking anything seriously, joking, absurd humor, that kind
*  of thing.
*  I think Doja Cat might be like the greatest living comedian right now.
*  Like I'm more entertained by Doja Cat than actual comedians.
*  Like she's really fucking funny on the Internet.
*  She's just great at social media.
*  It's just, you know, her.
*  Yeah, the nature of humor, like humor on social media is also a beautiful thing.
*  The absurdity.
*  The absurdity.
*  And memes, like I just want to take a moment.
*  I love, like when we're talking about art and credit and authenticity, I love that there's
*  this, I mean, now memes are like, they're no longer, like memes aren't like new, but
*  it's still this emergent art form that is completely egoless and anonymous and we just
*  don't know who made any of it.
*  And it's like the forefront of comedy and it's just totally anonymous and it just feels
*  really beautiful.
*  I just feel like this beautiful collective human art project that's like this like decentralized
*  comedy thing that just makes it.
*  Memes add so much to my day and many people's days and it's just like, I don't know, I don't
*  think people ever, I don't think we stop enough and just appreciate how sick it is that memes
*  exist.
*  And he's also making a whole brand new art form in like the modern era that's like didn't
*  exist before.
*  I mean, they sort of existed, but the way that they exist now as like this, like, you know,
*  like me and my friends, like we joke that we go like mining for mean memes or farming,
*  farming for memes, like a video game and like, like meme dealers and like whatever.
*  Like, you know, it's this whole memes are this whole like new comedic language.
*  What's this art form?
*  The interesting thing about is that.
*  Lame people seem to not be good at memes, like corporate can't infiltrate memes.
*  Yeah, they really can't.
*  They try.
*  They could try, but it's like, it's weird because like they try so hard and everyone
*  once in a while I'm like fine, like you got a good one.
*  I think I've seen like one or two good ones, but like, yeah, they really can't because
*  they're even corporate is infiltrating web three.
*  It's making me really sad, but they can't infiltrate the memes.
*  And I think there's something really beautiful about that.
*  That gives power.
*  That's that's why Dogecoin is powerful.
*  It's like, all right, I'm going to F you to sort of anybody who's trying to centralize
*  is trying to control the rich people that are trying to roll in and control this,
*  control the narrative.
*  Wow. I hadn't thought about that, but.
*  How would you fix Twitter?
*  How would you fix social media for your own?
*  Like, you're an optimist, you're a positive person.
*  There's a bit of a cynicism that you have currently about this particular little
*  slice of humanity.
*  I tend to think Twitter could be beautiful.
*  I'm not that cynical about it.
*  I'm not that cynical about it.
*  I actually refuse to be a cynic on principle.
*  Yes, I was just briefly expressing some personal personal stuff.
*  It was just it was just some personal pathos.
*  But like, like just a vent a little bit.
*  Just I don't have I don't have cancer.
*  I love my family.
*  I have a good life.
*  I'm that that is if that is my biggest one of my biggest problems.
*  A good life. Yeah.
*  You know, that was a brief.
*  Although I do think there are a lot of issues with Twitter just in terms of like
*  the public mental health, but.
*  Due to my proximity to the current.
*  Dramas.
*  I honestly feel that I should not have opinions about this because.
*  I think.
*  If Elon ends up.
*  Getting Twitter.
*  That is a being the arbiter of truth or public discussion.
*  That is a responsibility.
*  I do not I I am not qualified to be responsible for that, and I do not want to.
*  Say something that might like dismantle democracy.
*  And so I just like actually I actually think I should not have opinions about this because I truly am not.
*  I don't want to have the wrong opinion about this, and I think I'm too close to the actual situation.
*  Yeah, wherein I should not have I have thoughts in my brain, but I think.
*  I am scared by my proximity to this situation.
*  Is this isn't that crazy that a few words that you could say.
*  Could change world affairs and hurt people.
*  I mean, that's the nature of celebrity at a certain point.
*  That you have to be you have to a little bit, a little bit, not so much that it destroys you.
*  Well, it puts too much constraints, but you have to a little bit think about the impact of your words.
*  I mean, we as humans, you talk to somebody at a bar.
*  You have to think about the impact of your words.
*  Like you can say positive things, you can think negative things, you can affect the direction one life.
*  But on social media, your words can affect the direction of many lives.
*  That's crazy. It's a crazy world to live in.
*  It's worthwhile to consider that responsibility, take it seriously.
*  Sometimes just like you did.
*  I choose kind of silence, choose sort of respectful.
*  But I do have a lot of thoughts on the matter.
*  I'm just, yeah, I just I don't if my thoughts are wrong.
*  This is this is one one situation where the stakes are high.
*  You mentioned a while back that you were in a cult that centered around bureaucracy.
*  So you can't really do anything because it involves a lot of paperwork.
*  And I really love a cult that's just like Kafkaesque.
*  Yes. Just like I mean, it was like a joke.
*  But I know. But I love this idea.
*  The Holy Rain Empire. Yeah.
*  It was just like a Kafkaesque pro bureaucracy.
*  But I feel like that's what human civilization is, is that because when you said that, I was like,
*  oh, that is kind of what humanity is, is this bureaucracy.
*  I do. Yeah, I have this theory.
*  I really think that we really.
*  Bureaucracy is is starting to kill us.
*  And I think like we need to reorient laws and stuff.
*  Like, I think we just need sunset clauses on everything.
*  Like, I think the rate of change in culture is happening so fast and the rate of change in technology.
*  And everything is happening so fast.
*  It's like, you know, when you see these hearings about like, like
*  social media and Cambridge Analytica and everyone talking, it's like even from that point,
*  so much technological change has happened from like those hearings.
*  And it's just like we're trying to make all these laws now about AI and stuff.
*  I feel like we should be updating things like every five years.
*  And like one of the big issues in our society right now is we're just getting bogged down by laws.
*  And it's making it very hard to change things and develop things.
*  Like in Austin, like I don't want to speak on this too much.
*  But like one of my friends is working on a housing bill in Austin to try to like prevent
*  like a San Francisco situation from happening here, because obviously we're getting a little mini San Francisco here.
*  Like housing prices are skyrocketing.
*  It's causing massive gentrification.
*  This is going to be this is really bad for anyone who's not super rich.
*  Like, like there's so much bureaucracy.
*  Part of the reason this is happening is because you need all these permits to build.
*  It takes like years to get permits to like build anything.
*  It's so hard to build.
*  And so there's very limited housing and there's a massive influx of people.
*  And it's just like, you know, this is a microcosm of like problems that are happening all over the world where it's just like we're dealing with laws that are like 10, 20, 30, 40, 100, 200 years old.
*  And they are no longer relevant.
*  And it's just slowing everything down and causing massive social pain.
*  Yeah, it's like it's also makes me sad when I see politicians talk about technology and when they don't really get it.
*  But most importantly, they lack curiosity and like that, like inspired excitement.
*  Yeah.
*  Like how stuff works and all that stuff.
*  They're just like they see they have a very cynical view of technology.
*  It's like tech companies are just trying to do evil on the world from their perspective.
*  And they have no curiosity about like how recommender systems work or how how AI systems work, natural language processing, how robotics works, how computer vision works.
*  They always think the most cynical possible interpretation of what technology will be used.
*  And we should definitely be concerned about that.
*  But if you're constantly worried about that and you're regulating based on that, you're just going to slow down all the innovation.
*  I do think a huge priority right now is undoing the bad energy surrounding the emergence of Silicon Valley.
*  Like I think that like a lot of things were very irresponsible during that time.
*  And, you know, like even just this this current whole thing with Twitter and everything, it's like like there has been a lot of negative outcomes from the sort of technocracy boom.
*  But one of the things that's happening is that like it's alienating people from wanting to care about technology.
*  And I actually think technology is probably some of the better, probably the best.
*  I think we can fix a lot of our problems more easily with technology than with, you know, fighting the powers that be as a, you know, not to go back to the Star Wars quote or the Buckminster Fuller quote.
*  Let's go to some dark questions.
*  If we may for time, what is the darkest place you ever gone in your mind?
*  Is there a time, a period of time, a moment that you remember that was difficult for you?
*  I mean, when I was 18, my best friend died of a heroin overdose.
*  And it was like my it was and then shortly after that, one of my other best friends committed suicide.
*  And that sort of like coming into adulthood, dealing with two of the most important people in my life, dying in extremely disturbing, violent ways was a lot.
*  That was a lot.
*  You miss them?
*  Yeah, definitely miss them.
*  Did that make you think about your own life, about the finiteness of your own life, the places your mind can go?
*  Did you ever in the distance, far away, contemplate just your own death or maybe even taking your own life?
*  Oh, never.
*  Oh, no, I'm so I love my life.
*  I cannot fathom suicides.
*  I'm so scared of death.
*  I haven't I'm too scared of death.
*  My manager, my manager is like the most zen guy.
*  My manager is always like, you need to accept death.
*  You need to accept death.
*  And I'm like, look, I can do your meditation.
*  I can do the meditation, but I cannot accept death.
*  I will fight.
*  I terrified of death.
*  I will like fight.
*  Although I actually think death is important.
*  I recently went to this meeting about immortality.
*  And in the process of that's the actual topic of the meeting.
*  I don't know.
*  It was this girl.
*  It was a bunch of people working on like anti aging like stuff.
*  It was like some like seminary thing about about it.
*  And I went in really excited.
*  I was like, yeah, like, okay, like, what do you got?
*  Like, how can I live for 500 years or a thousand years?
*  And then like over the course of the meeting, like it was sort of like right.
*  It was like two or three days after the Russian invasion started.
*  And I was like, man, like, what if Putin was immortal?
*  Like, what if I'm like, man, maybe immortality is not good.
*  I mean, like if you get into the later dune stuff, the immortals cause a lot of problem
*  because as we were talking about earlier with the music and like brains calcified, like
*  good people could become immortal, but bad people could become immortal.
*  But I also think even the best people power corrupts and power alienates you from like
*  the common human experience.
*  So the people that get more and more powerful.
*  Even the best people who like whose brains are amazing.
*  Like I think death might be important.
*  I think death is part of, you know, like I think with AI, one thing we might want to consider.
*  I don't know.
*  When I talk about AI, I'm such not an expert and
*  probably everyone has all these ideas and they're already figured out.
*  But nobody is an expert in anything.
*  See, okay, go ahead.
*  But when I, yeah, but I like, it's just like, I think some kind of
*  pruning, but it's a tricky thing because if there's too much of a focus on youth culture,
*  then you don't have the wisdom.
*  So I feel like we're in a tricky moment right now in society where it's like,
*  we've really perfected living for a long time.
*  So there's all these really like old people who are like really voting against
*  the wellbeing of the young people, you know, and like, it's like there shouldn't be all this
*  student debt and we need like health care, like universal health care and like, like just voting
*  against like best interests.
*  But then you have all these young people that don't have the wisdom that are like,
*  like, yeah, we need communism and stuff.
*  And it's just like, like literally I got canceled at one point for,
*  I ironically used a Stalin quote in my high school yearbook, but it was actually like a
*  diss against my high school.
*  Yeah, I saw that.
*  Yeah. And people were like, you used to be a Stalinist and now you're a class traitor.
*  And it's like, it's like, oh man, just like, please Google Stalin.
*  Yeah. Please Google Stalin.
*  Like ignoring his, the lessons of history.
*  Yes. And it's like, we're in this really weird middle ground where it's like,
*  we are not finding the happy medium between wisdom and fresh ideas and they're fighting
*  each other.
*  And it's like, like really like what we need is like, like the fresh ideas and the wisdom to be
*  collaborating.
*  And it's like.
*  What the fighting in a way is the searching for the happy medium.
*  And in a way, maybe we are finding the happy medium that maybe that's what the happy medium
*  looks like.
*  And for AI systems, there has to be, it's, you know, you have reinforcement learning,
*  you have the dance between exploration, exploitation, sort of doing crazy stuff to
*  see if there's something better than what you think is the optimal and then doing the
*  optimal thing and dancing back and forth from that.
*  You would, um, Stuart Russell, I don't know if you know that is, um, AI guy with, um,
*  things about sort of how to control super intelligent AI systems and his ideas that
*  we should inject uncertainty and sort of humility into AI systems that they never, as they
*  get wiser and wiser and wiser and more intelligent, they're never really sure.
*  They always doubt themselves.
*  And in some sense, when you think of young people, that's a mechanism for doubt.
*  It's like, it's, it's how society doubts whether the thing it has converged towards
*  is the right answer.
*  So the, the voices of the young people is a society asking itself a question.
*  The way I've been doing stuff for the past 50 years, maybe it's the wrong way.
*  And so you can have all of that within one AI system.
*  I also think though that we need to, I mean, actually that's actually really interesting
*  and really cool.
*  But I also think there's a fine balance of, I think we maybe also overvalue
*  the idea that the old systems are always bad.
*  And I think there are things that we are perfecting and we might be accidentally
*  overthrowing things that we actually have gotten to a good point.
*  Just because we are valuing, we value disruption so much and we value fighting against the
*  generations before us so much that like, there's also an aspect of like, sometimes
*  we're taking two steps forward, one step back because, okay, maybe we kind of did solve
*  this thing and now we're like fucking it up, you know?
*  And, and, and so I think there's like a middle ground there too.
*  Yeah, we're in search of that happy medium.
*  Let me ask you a bunch of crazy questions.
*  Okay.
*  You can answer in a short way or in a long way.
*  What's the scariest thing you've ever done?
*  These questions are going to be ridiculous.
*  Something, something tiny or something big, skydiving or touring your first record
*  going on this podcast.
*  I've had two crazy brushes, like really scary brushes with death where I randomly got away
*  on skates.
*  I don't know if I should talk about those on here.
*  Well, I don't know.
*  I think I might be the luckiest person alive though.
*  Like this might be too dark for a podcast though.
*  I feel like I don't know if this is like good content for a podcast.
*  I don't know what content it might hijack.
*  Here's a safer one.
*  I mean, having a baby really scared me before just the birth process,
*  surgery, surgery, like, like just having, just having a baby is really scary.
*  So just like the medical aspect of it, not the responsibility.
*  Were you ready for the responsibility of, did you,
*  were you ready to be a mother?
*  All the, all the beautiful things that comes with motherhood that you were talking about,
*  all the changes and all that.
*  Were you ready for that?
*  Were you, did you feel ready for that?
*  No, I think it took about nine months to start getting ready for it.
*  And I'm still getting more ready for it because now you keep, you keep realizing more things
*  as they start getting.
*  As the consciousness grows.
*  Yeah.
*  And stuff you didn't notice with the first one.
*  Now that you've seen the first one older, you're noticing it more.
*  Like the sort of like existential horror of coming into consciousness with,
*  baby Y or baby sailor Mars or whatever.
*  She has like so many names at this point that it's,
*  we really need to probably settle on one.
*  If you could be someone else for a day, someone alive today,
*  but somebody you haven't met yet, who would you be?
*  Would I be modeling their brain state or would I just be in their body?
*  You can choose the degree to which you're modeling their brain state.
*  So you can still take a third person perspective and realize, you have to realize that you're.
*  Can they be alive or can it be dead?
*  No.
*  Oh, could it be anyone?
*  They would be brought back to life, right?
*  If they're dead.
*  Yeah.
*  You can bring people back.
*  Definitely Hitler or Stalin.
*  I want to understand evil.
*  I just.
*  You would need to, oh, to experience what it feels like.
*  I want to be in their brain feeling what they feel.
*  I might change you forever returning from that.
*  Yes, but I think it would also help me understand how to prevent it and fix it.
*  That might be one of those things.
*  Once you experience, it'll be a burden to know it because you won't be able to.
*  Yeah, but a lot of things are burdens like.
*  But it's useful burden.
*  But it's a useful burden.
*  That for sure.
*  I want to understand evil and like psychopathy and, and, and that I have all these fake Twitter
*  accounts where I like go into different algorithmic bubbles to try to like understand.
*  I'll keep getting in fights with people and realize we're not actually fighting.
*  I think we're, we used to exist in a monoculture, like before social media and stuff.
*  Like we kind of all got fed the same thing.
*  So we were all speaking the same cultural language.
*  But I think recently one of the things that like we aren't diagnosing properly enough
*  with social media is that there's different dialects.
*  There's so many different dialects of Chinese.
*  There are now becoming different dialects of English.
*  Like I am realizing like there are people who are saying the exact same things, but
*  they're using completely different verbiage and we're like punishing each other for not
*  using the correct verbiage.
*  And we're completely misunderstanding.
*  Like people are just like misunderstanding what the other people are saying.
*  And like, like I just got in a fight with a friend about like anarchism and, and, and
*  communism and shit for like two hours.
*  And then by the end of a conversation, like, and then she says something and I'm like,
*  but that's literally what I'm saying.
*  And she was like, what?
*  And then I was like, fuck, we've different.
*  I'm like, we're our English, like the way we are understanding terminology is like
*  drastically like our algorithm bubbles are, are creating mini dialects and, and of how
*  language is interpreted, how language is used.
*  That's so fascinating.
*  And so we're like having these arguments that we do not need to be having.
*  And there's polarization that's happening that doesn't need to be happening because
*  we've got these like algorithmically created dialects occurring.
*  Plus on top of that, there's also different parts of the world that speak different
*  languages.
*  So there's literally lost in translation kind of communication.
*  I happen to know the Russian language and just know how different it is.
*  Then the English language.
*  And I just wonder how much is lost in a little bit of
*  Man, I actually, cause I have a question for you.
*  I have a song coming out tomorrow with ice peak or a Russian band.
*  And I speak, I speak a little bit of Russian and I was looking at the title and the title
*  in English doesn't match the title in Russian.
*  I'm curious about this because look, it says the title in English is last day.
*  And then the title in Russian is new my pronunciation sucks.
*  No video.
*  New day.
*  A new day.
*  Yeah.
*  New day.
*  New day.
*  Yeah.
*  New day.
*  Yeah.
*  Yeah.
*  New day.
*  New day, but last day.
*  Uh, and, and, and no we didn't.
*  So last day would be последний день.
*  Yeah.
*  Maybe they, maybe the title includes both the Russian and the, and the, and it's for
*  maybe it's for bilingual.
*  To be honest, no, we didn't sounds better than, uh, just, um, musically like, uh,
*  no, we didn't is new day.
*  That's the current one.
*  And последний день is the last day.
*  Uh, I think no we didn't, but the meaning is so different.
*  That's kind of awesome.
*  Actually, there's like, there's an explicit sort of contrast like that.
*  Um, if everyone on earth disappeared and it was just you left, um, what would your day
*  look like?
*  Like, what would you do?
*  Everybody's dead.
*  As far as you are there corpses there?
*  Well, seriously, it's a big, it's a big difference if there's just like birds
*  singing versus if there's like corpses littering the street.
*  Yeah, there's corpses everywhere.
*  I'm sorry.
*  It's, and you don't actually know what happened and you don't know why you survived.
*  And you don't even know if there's others out there, but it seems clear that it's all
*  gone.
*  What would you do?
*  What would I do?
*  Listen, I'm somebody who really enjoys the moment, enjoys life.
*  I would just go on like enjoying the inanimate objects.
*  I would just, uh, look for food, basic survival, but most of it is just, listen, when I just,
*  I take walks and I look outside and I'm just happy that we get to exist on this planet
*  to be able to breathe air.
*  It's just all beautiful.
*  It's full of colors, all of this kind of stuff.
*  Just there's so many things about life, your own life, conscious life.
*  That's fucking awesome.
*  So I would just enjoy that.
*  But also maybe after a few weeks, the engineer will start coming out, like,
*  want to build some things.
*  Maybe there's always hope searching for another human.
*  Maybe.
*  Probably searching for another human, probably trying to get to a TV or radio station and
*  broadcast something.
*  I.
*  That's interesting.
*  I didn't think about that.
*  So like really,
*  Yeah.
*  Maximize your ability to connect with others.
*  Yeah.
*  Like probably try to find another person.
*  Would you be excited to see, to meet another person or terrified?
*  Cause you know,
*  I'd be excited.
*  Even if they,
*  No matter what.
*  Yeah.
*  Yeah.
*  Being alone for the last, however long of my life would be really bad.
*  That's the one instance I might, I don't think I'd kill myself, but I might kill myself if
*  I had to undergo.
*  So you love people.
*  You love connection to other humans.
*  Yeah.
*  I kind of hate people too, but I, but yeah.
*  No, it's a love hate relationship.
*  Yeah.
*  I feel like this is, I feel like we had a bunch of like weird Nietzsche questions and stuff.
*  Oh yeah.
*  Like I wonder, cause I'm like, when podcast, like I'm like, is this interesting for people
*  to just have like, or, or I don't know, maybe people do like this.
*  When I listen to podcasts, I'm into like the lore, like the hard lore.
*  Like I just love like Dan Carlin.
*  I'm like, give me the facts.
*  Just like, yeah.
*  Like the facts into my bloodstream.
*  You also don't know, like you're a fascinating mind to explore.
*  So you don't realize as you're talking about stuff, the stuff you've taken for granted
*  is actually unique and fascinating.
*  The way you think, not always what, like the way you reason through things is the
*  fascinating thing to listen, to listen to because people kind of see, oh, there's other
*  humans that think differently, that explore thoughts differently.
*  That's the cool.
*  That's, that's also cool.
*  So yeah, Dan Carlin retelling of history, by the way, his retelling of history
*  is very, I think what's exciting is not the history is his way of thinking about history.
*  No, I think Dan Carlin is one of the people, like when Dan Carlin is one of the people
*  that really started getting me excited about like revolutionizing education because like
*  Dan Carlin instills instilled, I already like really liked history, but he instilled like an
*  obsessive love of history in me to the point where like now I'm fucking reading like,
*  like going to bed, reading like part four of the rise and fall of the third Reich or whatever.
*  Like I like I'm like dense ass history, but like, like he like opened that door that like
*  made me want to be a scholar of that topic.
*  Like it's like, I feel he's such a good teacher.
*  He just like, you know, and it sort of made me feel like one of the things we could do
*  with education is like find like the world's great, the teachers that like create passion
*  for the topic because auto didacticism, I don't know how to say that properly, but like self
*  teaching is like much faster than being lectured to like, it's much more efficient to sort of like
*  be able to teach yourself and then ask a teacher questions when you don't know what's up.
*  But like, you know, that's why it's like in university and stuff, like you can learn so
*  much more material so much faster because you're doing a lot of the learning on your own and you're
*  going to the teachers for when you get stuck. But like these teachers that can inspire passion
*  for a topic, I think that is one of the most invaluable skills in our whole species.
*  Like, because if you can do that, then you, it's like AI, like AI is going to teach itself so much
*  more efficiently than we can teach it. We just needed to get it to the point where it can teach
*  itself and then it finds the motivation to do so. Right. Yeah. So like you inspire it to do so.
*  Yeah. And then it could, it could teach itself. What do you make of the fact you mentioned rise
*  and fall the third, right? I just read it twice. You read it twice. Yes. Okay. So no one even knows
*  what it, what it is. And I'm like, I'm like, wait, I thought this was like a super poppin book.
*  Super pop. I'm not like that. I'm not that far in it, but it is, it's so interesting. Yeah.
*  It's written by a person that was there, which is very important to kind of,
*  you know, you start being like, how could this possibly happen? And then when you read rise and
*  fall the third, right? It's like, people tried really hard for this to not happen. People tried,
*  they almost reinstated a monarchy at one point to try to stop this from happening. Like they almost
*  like, like abandoned democracy to try to get this to not happen. At least the way it makes me feel
*  is that there's a bunch of small moments on which history can turn. Yes. Like small meetings,
*  human interactions, and it that's both terrifying and inspiring because it's like,
*  even just attempts at assassinating Hitler, like time and time again failed and they were so close.
*  Was it like operation Valkyrie? Such a good.
*  And then there is also, also the role of, that's a really heavy burden, which is that from a
*  geopolitical perspective, the role of leaders to see evil before it truly becomes evil to anticipate
*  it at the stand up to evil. Cause evil is actually pretty rare in this world at a scale that Hitler
*  was. We tend to, you know, in the modern discourse kind of call people evil too quickly.
*  But if you look at ancient history, like there was a ton of Hitler's. I actually think it's more the
*  norm than like, again, going back to like my sort of intelligent design theory, I think one of the
*  things we've been successfully doing in our slow move from survival of the fittest to intelligent
*  design is we've kind of been eradicating. Like if you look at like ancient Assyria and stuff, like
*  that shit was like brutal and just like the heads on the like, like brutal, like like Genghis Khan,
*  just like genocide after genocide, after genocide was like throwing plague bodies over the walls
*  and decimating whole cities or like, like the Muslim conquests of like Damascus and shit.
*  Just like people, cities used to get leveled all the fucking time. Okay. Get into the bronze age
*  collapse. It's basically, there was like almost like Roman level, like society, like there was
*  like all over the world, like global trade, like everything was awesome through a mix of, I think,
*  a bit of climate change and then the development of iron. Cause basically bronze could only come
*  from this, the way to make bronze, like everything had to be funneled through this one Iranian mine.
*  And so it's like, there was just this one supply chain. And this is one of the things that makes
*  me worried about supply chains and why I think we need to be so thoughtful about,
*  I think our biggest issue with society right now, like the thing that is most likely to go
*  wrong is probably supply chain collapse, you know, cause war, climate change, whatever,
*  like anything that causes supply chain collapse, our population is too big to handle that. And
*  like the thing that seems to cause dark ages is mass supply chain collapse. But the bronze age
*  collapse happened like, it was sort of like this ancient collapse that happened where like literally
*  like ancient Egypt, all these cities, everything just got like decimated, destroyed, abandoned
*  cities, like hundreds of them. There was like a flourishing society, like we were almost coming
*  to modernity and everything got leveled and they had this mini dark ages, but it was just like,
*  there's so little writing or recording from that time that like there isn't a lot of information
*  about the bronze age collapse, but it was basically equivalent to like medieval,
*  the medieval dark ages, but it just happened. I'm not going to, I don't know the years, but like
*  thousands of years earlier. And then we sort of like recovered from the bronze age collapse,
*  empire re-emerged, writing and trade and everything re-emerged.
*  You know, and then we of course had the more contemporary dark ages.
*  And then over time we've designed mechanism, the less and then less and the capability for the
*  destructive power centers to emerge. There's more recording about the more contemporary dark ages.
*  So I think we have like a better understanding of how to avoid it, but I still think we're at high
*  risk for it. I think that's one of the big risks right now. So the natural state of being for humans
*  is for there to be a lot of Hitler's, which has gotten really good at making it hard for them to
*  emerge. We've gotten better collaboration and resisting the power, like authoritarians to come
*  to power. We're trying to go country by country. Like we're moving past this. We're kind of like
*  slowly incrementally like moving towards like not scary old school war stuff. And I think seeing it
*  happen in some of the countries that at least nominally are like supposed to have moved past
*  that that's scary because it reminds us that it can happen like in the places that have made
*  like moved past supposedly as hopefully moved past that. And possibly at a civilization level,
*  like you said, supply chain collapse might make people resource constraint, might make people
*  desperate, angry, hateful, violent, and drag us right back in. I mean, supply chain collapse is
*  how like the ultimate thing that caused the middle ages was supply chain collapse. It's like
*  people because people were reliant on a certain level of technology, like people like you look
*  at like Britain, like they had glass, like people had aqueducts, people had like indoor heating and
*  cooling and like running water and like buy food from all over the world and trade and markets.
*  Like people didn't know how to hunt and forage and gather. And so we're in a similar situation.
*  We are not educated enough to survive without technology. So if we have a supply chain collapse
*  that like limits our access to technology, there will be like massive starvation and violence and
*  displacement and war. Like, you know, it's all like, yeah, in my opinion, it's like the primary
*  marker of dark, like what a dark age is. What technology is kind of enabling us to be more
*  resilient in terms of supply chain, in terms of to all the different catastrophic events that
*  happened to us. Although the pandemic has kind of challenged our preparedness for the catastrophic.
*  What do you think is the coolest invention humans come up with? The wheel, fire, cooking meat.
*  Computers.
*  Computers?
*  Fricking computers.
*  Internet or computers? Which one? What do you think the-
*  Previous technologies, I mean, may have even been more profound and moved us to a certain degree.
*  I think the computers are what make us homo techno. I think this is what it's a brain augmentation.
*  And so it like allows for actual evolution. Like the computers accelerate the degree to which
*  all the other technologies can also be accelerated.
*  Would you classify yourself as a homo sapien or a homo techno?
*  Definitely a homo techno.
*  So you're one of the earliest of the species.
*  I think most of us are. Like as I said, I think if you
*  looked at brain scans of us versus humans a hundred years ago, it would look very different.
*  I think we are physiologically different.
*  Just even the interaction with the devices has changed our brains.
*  And if you look at, a lot of studies are coming out to show that there's a degree of inherited
*  memory. So some of these physiological changes in theory should be, we should be passing them on.
*  So like that's, you know, that's not like a, an instance of physiological change that's
*  going to fizzle out in theory that should progress like to our offspring.
*  Speaking of offspring, what advice would you give to a young person like in high school?
*  Whether there be an artist, a creative, an engineer, any kind of career path,
*  or maybe just life in general, how they can live a life they can be proud of.
*  I think one of my big thoughts and like, especially now having kids is that I don't think we spend
*  enough time teaching creativity. And I think creativity is a muscle like other things.
*  And there's a lot of emphasis on, you know, learn how to play the piano and then you can write a song.
*  You know, learn how to play the piano and then you can write a song or like learn the technical
*  stuff and then you can do a thing. But I think it's, like, I have a friend who's like world's
*  greatest guitar player, like, you know, amazing sort of like producer works with other people,
*  but he's really sort of like, you know, he like engineers and records things and like does solos,
*  but he doesn't really like make his own music. And I was talking to him and I was like, dude,
*  you're so talented at music, like, why don't you make music or whatever? And he was like,
*  because I got, I'm too old. I never learned the creative muscle. And it's like, you know,
*  it's embarrassing. It's like learning the creative muscle takes a lot of failure. And it also sort of
*  your if when you're being creative, you know, you're throwing paint at a wall and a lot of
*  stuff will fail. So like part of it is like a tolerance for failure and humiliation.
*  And that's somehow that's easier to develop when you're young. Yeah.
*  Or be persist through it when you're young. Everything is easier to develop.
*  When you're young. Yes. And the younger, the better. It could destroy you. I mean,
*  that's the shitty thing about creativity. If you know, failure could destroy you if you're not
*  careful, but that's a risk worth taking. But also, but at a young age, developing a
*  tolerance to failure is, is good. I fail all the time. Like I do stupid shit all the time.
*  Like in public and I get canceled for I have make all kinds of mistakes, but I just like,
*  I'm very resilient about making mistakes. And so then like I do a lot of things that like other
*  people wouldn't do. And like, I think my greatest asset is my creativity. And I like, I think pain,
*  like tolerance to failure is just a super essential thing that should be taught before other things.
*  Brilliant advice. Yeah. Yeah. I wish everybody encouraged sort of failure more as opposed to
*  kind of. Because we like punish failure. We're like, no, we're no like when we were teaching kids,
*  we're like, no, that's wrong. Like that's, you know, like X keeps like, will be like wrong. Like
*  he'll say like crazy things. Like X keeps being like, like bubble car, bubble car. And I'm like,
*  and you know, I'm like, what's a bubble car? Like, but like it doesn't like, but I don't
*  want to be like, no, you're wrong. I'm like, you're thinking of weird, crazy shit. Like,
*  I don't know what a bubble car is, but like. It's creating worlds and they might be internally
*  consistent. And through that, he might discover something fundamental about this. Yeah. Or he'll
*  like rewrite songs, like with words that he prefers. So like instead of baby shark, he says baby car.
*  It's like.
*  Maybe he's onto something. Let me ask the big ridiculous question. We were kind of dancing
*  around it, but what do you think is the meaning of this whole thing we have here?
*  Uh, of human civilization, of life on earth, but in general, just life. What's the meaning of life?
*  See, have you, did you read a Nova scene yet by James Lovelock? You're doing a lot of really good
*  book recommendations here. I haven't even finished this, so I'm a huge fraud yet again. Um, but like
*  really early in the book, um, he says this amazing thing. Like, I feel like everyone's so sad and
*  cynical. Like everyone's like the Fermi paradox and everyone. I just keep hearing people being
*  like, fuck, what if we're alone? Like, oh no, ah, like, ah, ah. And I'm like, okay, but like, wait,
*  what if this is the beginning? Like in Nova scene, he says, um, I'm, this is not going to be a
*  correct, I can't like memorize quotes, but he says, says something like, um, uh, what if our
*  consciousness, like right now, like this is the universe waking up, like what if instead of
*  discovering the universe, this is the universe, like this is the evolution of the little literal
*  universe herself. Like we are not separate from the universe. Like this is the universe waking up.
*  This is the universe seeing herself for the first time. Like this is, um, the universe becoming
*  conscious the first time we were part of that. Yeah. Cause it's like, we aren't separate from
*  the universe. Like, like this could be like an incredibly sacred moment and maybe like social
*  media and all these things, the stuff where we're all getting connected together, like maybe this,
*  these are the neurons connecting of the like collective super intelligence that is, you know,
*  waking up the, the, yeah. Like, like, you know, it's like maybe instead of something cynical or
*  maybe if there's something to discover, like maybe this is just, you know, we're a blastocyst of,
*  of like some incredible kind of consciousness or being. And just like in the first three years
*  of life or for human children, we'll forget about all the suffering that we're going through now.
*  I think we'll probably forget about this. I mean, probably, you know, artificial intelligence
*  will eventually render us obsolete. I don't think they'll do it in a malicious way, but I think
*  probably we are very weak. The sun is expanding. Like, I don't know, like hopefully we can get to
*  Mars, but like we're pretty vulnerable. And I, you know, like, I think we can coexist for a long
*  time with AI and we can also probably make ourselves less vulnerable. But, you know, I just think
*  consciousness, sentience, self-awareness, like, I think this might be the single greatest like moment
*  in evolution ever. And like, maybe this is, you know, the big, like the true beginning of, of,
*  of life. And we're just, we're, we're the blue green algae or we're like, we're like the single
*  celled organisms of, of something amazing. The universe awakens and this is, this is it. Yeah.
*  Well, see, you're an incredible person. You're a fascinating mind. You should definitely do,
*  your friend Liv mentioned that you guys were thinking of maybe talking. I would love it if you
*  explored your mind in this kind of media more and more by doing a podcast with her or just
*  in any kind of way. So you're, you're an awesome person. It's an honor to know you.
*  It's an honor to get to sit down with you late at night, which is like surreal. And I really enjoyed
*  it. Thank you for talking to that. Yeah, no, I mean, huge honor. I feel very underqualified to
*  be here, but I'm a big fan. I've been listening to the podcast a lot and yeah, me and Liv would
*  appreciate any advice and help. And we're definitely going to do that. So, yeah, anytime.
*  Thank you. Cool. Thank you. Thanks for listening to this conversation with Grimes to support this
*  podcast. Please check out our sponsors in the description. And now let me leave you with some
*  words from Oscar Wilde. Yes, I'm a dreamer for dreamers, one who can only find her way by
*  moonlight. And her punishment is that she sees the dawn before the rest of the world.
*  Thank you for listening and hope to see you next time.
