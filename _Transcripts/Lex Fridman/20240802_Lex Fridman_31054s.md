---
Date Generated: August 03, 2024
Transcription Model: whisper medium 20231117
Length: 31054s
Video Keywords: ['elon musk', 'elon musk neuralink team', 'joe rogan', 'lex ai', 'lex fridman', 'lex friedman', 'lex jre', 'lex mit', 'lex pod', 'lex podcast']
Video Views: 961022
Video Rating: None
Video Description: Elon Musk is CEO of Neuralink, SpaceX, Tesla, xAI, and CTO of X. DJ Seo is COO & President of Neuralink. Matthew MacDougall is Head Neurosurgeon at Neuralink. Bliss Chapman is Brain Interface Software Lead at Neuralink. Noland Arbaugh is the first human to have a Neuralink device implanted in his brain. 

Thank you for listening ❤ Check out our sponsors: https://lexfridman.com/sponsors/

*Transcript:*
https://lexfridman.com/elon-musk-and-neuralink-team-transcript

*EPISODE LINKS:*
Neuralink's X: https://x.com/neuralink
Neuralink's Website: https://neuralink.com/
Elon's X: https://x.com/elonmusk
DJ's X: https://x.com/djseo_
Matthew's X: https://x.com/matthewmacdoug4
Bliss's X: https://x.com/chapman_bliss
Noland's X: https://x.com/ModdedQuad
xAI: https://x.com/xai
Tesla: https://x.com/tesla
Tesla Optimus: https://x.com/tesla_optimus
Tesla AI: https://x.com/Tesla_AI

*CONTACT LEX:*
*Feedback* - give feedback to Lex: https://lexfridman.com/survey
*AMA* - submit questions, videos or call-in: https://lexfridman.com/ama
*Hiring* - join our team: https://lexfridman.com/hiring
*Other* - other ways to get in touch: https://lexfridman.com/contact

*OUTLINE:*
0:00 - Introduction
0:49 - Elon Musk
4:06 - Telepathy
10:45 - Power of human mind
15:12 - Future of Neuralink
20:27 - Ayahuasca
29:57 - Merging with AI
34:44 - xAI
36:57 - Optimus
43:47 - Elon's approach to problem-solving
1:01:23 - History and geopolitics
1:05:53 - Lessons of history
1:10:12 - Collapse of empires
1:17:55 - Time
1:20:37 - Aliens and curiosity
1:28:12 - DJ Seo
1:36:20 - Neural dust
1:43:03 - History of brain–computer interface
1:51:07 - Biophysics of neural interfaces
2:01:36 - How Neuralink works
2:07:26 - Lex with Neuralink implant
2:27:24 - Digital telepathy
2:38:27 - Retracted threads
2:44:01 - Vertical integration
2:50:55 - Safety
3:00:50 - Upgrades
3:09:53 - Future capabilities
3:39:09 - Matthew MacDougall
3:44:58 - Neuroscience
3:52:07 - Neurosurgery
4:03:11 - Neuralink surgery
4:22:20 - Brain surgery details
4:38:03 - Implanting Neuralink on self
4:53:57 - Life and death
5:03:17 - Consciousness
5:06:11 - Bliss Chapman
5:19:27 - Neural signal
5:26:19 - Latency
5:30:59 - Neuralink app
5:35:40 - Intention vs action
5:46:54 - Calibration
5:56:26 - Webgrid
6:19:28 - Neural decoder
6:40:03 - Future improvements
6:48:59 - Noland Arbaugh
6:49:08 - Becoming paralyzed
7:02:43 - First Neuralink human participant
7:06:45 - Day of surgery
7:24:31 - Moving mouse with brain
7:49:50 - Webgrid
7:57:52 - Retracted threads
8:06:16 - App improvements
8:13:01 - Gaming
8:23:59 - Future Neuralink capabilities
8:26:55 - Controlling Optimus robot
8:31:16 - God
8:33:21 - Hope
---

# Elon Musk Neuralink and the Future of Humanity  Lex Fridman Podcast #438
**Lex Fridman:** [August 02, 2024](https://www.youtube.com/watch?v=Kbk9BiPhm7o)
*  The following is a conversation with Elon Musk, DJ Saw, Matthew McDougal,
*  Bliss Chapman, and Nolan Arbaugh about Neuralink and the future of humanity.
*  Elon, DJ, Matthew, and Bliss are, of course, part of the amazing Neuralink team,
*  and Nolan is the first human to have a Neuralink device implanted in his brain.
*  I speak with each of them individually, so use timestamps to jump around or,
*  as I recommend, go hardcore and listen to the whole thing.
*  This is the longest podcast I've ever done.
*  It's a fascinating, super technical and wide ranging conversation.
*  And I loved every minute of it.
*  And now, dear friends, here's Elon Musk, his fifth time on this,
*  the Lex Friedman podcast.
*  Drinking coffee or water?
*  Water.
*  I'm so over caffeinated right now.
*  Do you want some caffeine?
*  I mean, sure.
*  There's a, there's a nitro drink.
*  This will keep you up for like, you know, tomorrow afternoon, basically.
*  Yeah.
*  I don't have to.
*  So what is nitro?
*  It's just got a lot of caffeine or something.
*  Don't ask questions.
*  It's called nitro.
*  Do you need to know anything else?
*  It's got, it's got nitrogen.
*  That's ridiculous.
*  I mean, what we breathe is 78% nitrogen anyway.
*  What do you need to add more?
*  Most people think that they're breathing oxygen and they're actually breathing 78%
*  nitrogen.
*  You need like a milk bar.
*  Like from, like from Clockwork Orange.
*  Yeah.
*  Is that top three Kubrick film for you?
*  Clockwork Orange is pretty good.
*  I mean, it's demanded.
*  Jarring, I'd say.
*  Okay.
*  So first let's step back and big congrats on getting Neuralink implanted into a human.
*  That's a historic step for Neuralink.
*  And there's many more to come.
*  Yeah.
*  And we just obviously have a second implant as well.
*  How did that go?
*  So far so good.
*  That's there.
*  It looks like we've got, I think on the order of 400 electrodes that are providing signals.
*  So that's a good thing.
*  How quickly do you think the number of human participants will scale?
*  It depends somewhat on the regulatory approval, the rate at which we get regulatory approvals.
*  So we're hoping to do 10 by the end of this year, total of 10.
*  So eight more.
*  And with each one, you're going to be learning a lot of lessons about the neurobiology of the brain, the
*  everything, the whole chain of the Neuralink, the decoding, the signal processing, all that kind of stuff.
*  Yeah.
*  Yeah.
*  I think it's obviously going to get better with each one.
*  I mean, I don't want to jinx it, but it seems to have gone extremely well with the second implant.
*  So there's a lot of signal, a lot of electrodes.
*  It's working very well.
*  What improvements do you think we'll see in the future?
*  I mean, I think we'll see a lot of improvements.
*  I mean, in years, it's going to be gigantic because we'll increase the number of electrodes dramatically.
*  We'll improve the signal processing.
*  So we with with even with only roughly, I don't know, 10, 15% of the electrodes working with with Noland with our
*  first patient, we were able to get to achieve a bit per second.
*  That's twice the world record.
*  So I think we'll also we'll start like vastly exceeding the world record by orders of magnitude in the years to come.
*  So it's like getting to, I don't know, a hundred bits per second thousand, you know, maybe.
*  I think we'll see a lot of improvements.
*  I think we'll see a lot of improvements.
*  I think we'll see a lot of improvements.
*  I think we'll see a lot of improvements.
*  Maybe if you like five years from now, it might be a mega bit like faster than any human could possibly communicate by typing or speaking.
*  Yeah.
*  That BPS is an interesting metric to measure.
*  There might be a big leap in the experience once you reach a certain level of BPS.
*  Yeah.
*  Like entirely new ways of interacting with the computer might be unlocked.
*  And with humans.
*  with other humans.
*  Provided they have a neural link too.
*  Right.
*  Otherwise they won't be able to absorb
*  the signals fast enough.
*  Do you think that will improve the quality
*  of intellectual discourse?
*  Well, I think you could think of it,
*  if you were to slow down communication,
*  how would you feel about that?
*  If you'd only talk at let's say 1 10th of normal speed,
*  you'd be like, wow, that's agonizingly slow.
*  Yeah.
*  So now imagine you could speak it,
*  communicate clearly at 10 or 100 or 1000 times faster
*  than normal.
*  Listen, I'm pretty sure nobody in their right mind
*  listens to me at 1x, they listen at 2x.
*  So I can only imagine what 10x would feel like
*  or I could actually understand it.
*  I usually default to 1.5x.
*  You can do 2x, but well, actually if I'm trying to go,
*  if I'm listening to somebody go to,
*  in like sort of 15, 20 minutes,
*  I must go to sleep, then I'll do it 1.5x.
*  If I'm paying attention, I'll do 2x.
*  Right.
*  But actually, if you start,
*  actually listen to podcasts or sort of audio books
*  or anything at, if you get used to doing it at 1.5,
*  then one sounds painfully slow.
*  I'm still holding on to one because I'm afraid.
*  I'm afraid of myself becoming bored with the reality,
*  with the real world where everyone's speaking in 1x.
*  Well, it depends on the person.
*  You can speak very fast.
*  Like we communicate very quickly.
*  And also if you use a wide range of,
*  if your vocabulary is larger,
*  your effective bit rate is higher.
*  That's a good way to put it.
*  The effective bit rate.
*  I mean, that is the question is how much information
*  is actually compressed
*  in the low bit transfer of language.
*  If there's a single word that is able to convey
*  something that would normally require,
*  I don't know, 10 simple words,
*  then you've got maybe a 10x compression on your hands.
*  And that's really like with memes.
*  Memes are like data compression.
*  It conveys a whole,
*  you're simultaneously hit with a wide range of symbols
*  that you can interpret.
*  And it's, you kind of get it.
*  Faster than if it were words or a simple picture.
*  And of course you're referring to memes broadly like ideas.
*  Yeah, there's an entire idea structure
*  that is like an idea template.
*  And then you can add something to that idea template.
*  But somebody has that preexisting idea template
*  in their head.
*  So when you add that incremental bit of information,
*  you're conveying much more than if you just
*  said a few words.
*  It's everything associated with that meme.
*  So you think there'll be emergent leaps of capability
*  as you scale the number of electrodes?
*  There'll be a certain,
*  do you think there'll be like actual number
*  where it just, the human experience will be altered?
*  Yes.
*  What do you think that number might be?
*  Whether electrodes or BPS?
*  We of course don't know for sure,
*  but is this 10,000 or 100,000?
*  Yeah, I mean, certainly if you're anywhere
*  at 10,000 plus per second,
*  I mean, that's vastly faster than any human
*  can communicate right now.
*  What is the average BPS of a human?
*  It is less than one BPS over the course of a day
*  because there are 86,400 seconds in a day
*  and you don't communicate 86,400 tokens in a day.
*  Therefore your BPS is less than one,
*  average over 24 hours.
*  It's quite slow.
*  And now even if you're communicating very quickly
*  and you're talking to somebody who understands
*  what you're saying,
*  because in order to communicate,
*  you have to at least to some degree,
*  a model of the mind state
*  of the person to whom you're speaking.
*  Then take the concept you're trying to convey,
*  compress that into a small number of syllables,
*  speak them and hope that the other person decompress them
*  into a conceptual structure
*  that is as close to what you have in your mind as possible.
*  Yeah, I mean, there's a lot of signal loss there
*  in that process.
*  Yeah, very lossy compression and decompression
*  and a lot of what your neurons are doing
*  is distilling the concepts down to a small number
*  of symbols of say syllables that I'm speaking
*  or keystrokes, whatever the case may be.
*  So that's a lot of what your brain computation is doing.
*  Now there is an argument that that's actually
*  a healthy thing to do or a helpful thing to do
*  because as you try to compress complex concepts,
*  you're perhaps forced to distill
*  the what is most essential in those concepts
*  as opposed to just all the fluff.
*  So in the process of compression,
*  you distill things down to what matters the most
*  because you can only say a few things.
*  So that is perhaps helpful.
*  I think we'll probably get,
*  if our data rate increases,
*  the entirely probable that will become far more verbose,
*  just like your computer,
*  when computers had like,
*  my first computer had 8K of RAM,
*  so you really thought about every byte.
*  And now you've got computers with many gigabytes of RAM.
*  So if you wanna do an iPhone app that just says,
*  hello world, it's probably, I don't know,
*  several megabytes minimum, a bunch of fluff,
*  but nonetheless, we still prefer to have the computer
*  with more memory and more compute.
*  So the long-term aspiration of Neuralink
*  is to improve the AI human symbiosis
*  by increasing the bandwidth of the communication.
*  Because if even in the most benign scenario of AI,
*  you have to consider that the AI
*  is simply gonna get bored,
*  waiting for you to spit out a few words.
*  I mean, if the AI can communicate at terabits per second
*  and you're communicating at bits per second,
*  it's like talking to a tree.
*  Well, it is a very interesting question
*  for a super intelligent species.
*  What use are humans?
*  I think there is some argument for humans
*  as a source of will.
*  Will.
*  Will, yeah, source of will or purpose.
*  So if you consider the human mind as being essentially,
*  there's the primitive limbic elements,
*  which basically even like reptiles have,
*  and there's the cortex,
*  the thinking and planning part of the brain.
*  Now the cortex is much smarter than limbic system,
*  and yet it's largely in service to the limbic system.
*  It's trying to make the limbic system happy.
*  I mean, the sheer amount of compute
*  that's gone into people trying to get laid is insane.
*  Without actually seeking procreation,
*  they're just literally trying to do
*  it's this sort of simple motion.
*  And they get a kick out of it.
*  So this simple, which in the abstract,
*  rather absurd motion, which is sex,
*  the cortex is putting a massive amount of compute
*  into trying to figure out how to do that.
*  So like 90% of distributed compute of the human species
*  is spent on trying to get laid probably.
*  Like a large percentage.
*  There's no purpose to most sex except hedonistic.
*  It's just sort of a joy or whatever, dopamine release.
*  Now once in a while it's procreation,
*  but for humans it's mostly,
*  modern humans it's mostly recreational.
*  And so cortex, much smarter than your limbic system,
*  is trying to make the limbic system happy
*  because limbic system wants to have sex.
*  So, or wants some tasty food or whatever the case may be.
*  And then that is then further augmented
*  by the tertiary system, which is your phone,
*  your laptop, iPad, or your computing stuff.
*  That's your tertiary layer.
*  So you're actually already a cyborg.
*  You have this tertiary compute layer,
*  which is in the form of your computer
*  with all the applications, all your compute devices.
*  And so in the getting laid front,
*  there's actually a massive amount of digital compute
*  also trying to get laid.
*  With like Tinder and whatever.
*  Yeah, so the compute that we humans have built
*  is also participating.
*  Yeah, I mean there's like gigawatts of compute
*  going into getting laid, of digital compute.
*  Yeah, what if AGI was-
*  This is happening as we speak.
*  If we merge with AI, it's just gonna expand the compute
*  that we humans use.
*  Pretty much.
*  Well, it's one of the things certainly, yeah.
*  But what I'm saying is that, yes,
*  like is there a use for humans?
*  Well, there's this fundamental question
*  of what's the meaning of life, why do anything at all?
*  And so if our simple limbic system provides
*  a source of will to do something,
*  that then goes to our cortex,
*  that then goes to our tertiary compute layer,
*  then I don't know, it might actually be that the AI,
*  in a benign scenario, is simply trying to make
*  the human limbic system happy.
*  Yeah, it seems like the will is not
*  just about the limbic system,
*  there's a lot of interesting complicated things in there.
*  We also want power.
*  That's limbic too, I think.
*  But then we also want to, in a kind of cooperative way,
*  alleviate the suffering in the world.
*  Not everybody does, but yeah, sure.
*  Some people do.
*  As a group of humans, when we get together,
*  we start to have this kind of collective intelligence
*  that is more complex in its will
*  than the underlying individual descendants of apes.
*  So there's other motivations.
*  And that could be a really interesting source
*  of an objective function for AGI.
*  Yeah.
*  I mean, there are these sort of fairly cerebral
*  kind of higher level goals.
*  I mean, for me, it's like what's the meaning of life,
*  or understanding the nature of the universe
*  is of great interest to me.
*  And hopefully to the AI.
*  And that's the mission of XAI and Grok,
*  is understand the universe.
*  So do you think people,
*  when you have a Neuralink with 10,000, 100,000 channels,
*  most of the use cases will be communication
*  with AI systems?
*  Well, assuming that the,
*  they're not, I mean, there's this solving basic
*  neurological issues that people have.
*  If they've got damaged neurons
*  in their spinal cord or neck,
*  or as is the case with our first two patients,
*  then this obviously, the first order of business
*  is solving fundamental neuron damage
*  in the spinal cord, neck, or in the brain itself.
*  So our second product is called Blindsight,
*  which is to enable people who are completely blind,
*  less both eyes or optic nerve,
*  or just can't see at all to be able to see
*  by directly triggering the neurons in the visual cortex.
*  So we're just starting at the basics here.
*  So it's like very, the simple stuff, relatively speaking,
*  is solving neuron damage.
*  You can also solve, I think probably schizophrenia.
*  If people have seizures of some kind,
*  you can probably solve that.
*  It could help with memory.
*  There's like a kind of a tech tree, if you will,
*  like you got the basics,
*  like you need literacy before you can have,
*  Lord of the Rings.
*  You know?
*  So do you have letters and alphabet?
*  Okay, great.
*  Words, you know, then eventually you get sagas.
*  So, you know, I think there's,
*  there may be some things to worry about in the future,
*  but the first several years are really just solving
*  basic neurological damage.
*  Like for people who have essentially complete
*  or near complete loss of, from the brain to the body,
*  like Stephen Hawking would be an example,
*  the neurolinks would be incredibly profound,
*  because I mean, you can imagine if Stephen Hawking
*  could communicate as fast as we're communicating,
*  perhaps faster.
*  And that's certainly possible, probable in fact,
*  likely I'd say.
*  So there's a kind of dual track of medical and non-medical,
*  meaning, so everything you've talked about
*  could be applied to people who are non-disabled
*  in the future.
*  The logical thing to do is, sensible thing to do is to
*  sort of solving basic neuron damage issues.
*  Yes.
*  There's obviously some risk with the new devices.
*  You can't get the risk out of zero, it's not possible.
*  So you wanna have the highest possible reward,
*  given that, given there's a certain irreducible risk.
*  And if somebody's able to have a profound improvement
*  in their communication, that's worth the risk.
*  As you get the risk down.
*  Yeah, as you get the risk down,
*  once the risk is down to,
*  if you have like thousands of people
*  that have been using it for years and the risk is minimal,
*  then perhaps at that point, you could consider saying,
*  okay, let's aim for augmentation.
*  Now, I think we're actually gonna aim for augmentation
*  with people who have neuron damage.
*  So we're not just aiming to give people
*  a communication data rate equivalent to normal humans.
*  We're aiming to give people who have,
*  you know, quadriplegic or maybe have complete loss
*  of the connection to the brain and body,
*  a communication data rate that exceeds normal humans.
*  When we're in there, why not?
*  Let's give people superpowers.
*  And the same for vision.
*  As you restore vision,
*  there could be aspects of that restoration
*  that are superhuman.
*  Yeah, at first, the vision restoration will be low res.
*  Because you have to say like,
*  how many neurons can you put in there and trigger?
*  And you can do things where you adjust the electric field
*  to like, even if you've got say 10,000 neurons,
*  it's not just 10,000 pixels,
*  because you can adjust the field between the neurons
*  and do them in patterns in order to get,
*  so to have say 10,000 electrodes effectively give you
*  I don't know, maybe like having a megapixel
*  or a 10 megapixel situation.
*  So, and then over time,
*  I think you get to higher resolution than human eyes
*  and you could also see in different wavelengths.
*  So like Jordi LaForge from Star Trek,
*  you know, like the thing you could just,
*  do you wanna see in radar?
*  No problem.
*  You can see ultraviolet, infrared,
*  Eagle vision, whatever you want.
*  Do you think there'll be, let me ask a Joe Rogan question.
*  Do you think there'll be?
*  I just recently taken ayahuasca.
*  Is that a Joe Rogan question?
*  No, well, yes.
*  Well, I guess technically it is.
*  Yeah, have you tried DMT in there or something?
*  I love you, Joe.
*  Okay.
*  Yeah, have you said much about it?
*  I have not, I have not.
*  Okay, well, let me spill the beans.
*  It was a truly incredible experience.
*  Three tone of tables on you.
*  Wow.
*  I mean, you're in the jungle.
*  Yeah, amongst the trees myself.
*  Yeah, must have been crazy.
*  And the shaman, yeah, yeah, yeah.
*  With the insects, with the animals all around you,
*  like jungle as far as I can see.
*  I mean.
*  That's the way to do it.
*  Things are gonna look pretty wild.
*  Yeah, pretty wild.
*  I think an extremely high dose.
*  Don't go hugging an anaconda or something, you know.
*  I thought.
*  I thought.
*  You haven't lived unless you made love to an anaconda.
*  I'm sorry.
*  But.
*  Snakes and ladders.
*  Yeah, I took an extremely high dose of nine cups.
*  Damn, okay, that sounds like a lot.
*  Of course, is it normal to just one cup?
*  One or two, usually one.
*  Wait, like right off the bat or do you work your way up to it?
*  So I.
*  You just jump in at the deep end.
*  Across two days,
*  because on the first day I took two and I.
*  Okay.
*  It was a ride, but it wasn't quite like.
*  It wasn't like Revelation.
*  It wasn't into deep space type of ride.
*  It was just like a little airplane ride.
*  Good, well, I saw some trees and some visuals and all that.
*  I just saw a dragon and all that kind of stuff.
*  But.
*  Nine cups, you went to Pluto, I think.
*  Pluto, yeah, no, deep space.
*  Deep space.
*  One of the interesting aspects of my experience
*  is I thought I would have some demons,
*  some stuff to work through.
*  That's what people.
*  That's what everyone says.
*  That's what everyone says, yeah, exactly.
*  I had nothing, I had all positive.
*  I had just so full.
*  Just a pure soul.
*  I don't think so, I don't know.
*  But I kept thinking about,
*  it had like extremely high resolution thoughts
*  about the people I know in my life.
*  You were there.
*  Okay.
*  And it's just, not from my relationship with that person,
*  but just as the person themselves,
*  I had just this deep gratitude of who they are.
*  That's cool.
*  It was just like this exploration.
*  Like, you know, like Sims or whatever,
*  you get to watch them.
*  I got to watch people
*  and just be in awe of how amazing they are.
*  That sounds awesome.
*  Yeah, it was great.
*  I was waiting for.
*  When's the demon coming?
*  Exactly.
*  Maybe I'll have some negative thoughts, nothing, nothing.
*  I had just extreme gratitude for them.
*  And also a lot of space travel.
*  Space travel to where?
*  So here's what it was.
*  It was people, the human beings that I know,
*  they had this kind of,
*  the best way to describe it is they had a glow to them.
*  Okay.
*  And then I kept flying out from them to see Earth,
*  to see our solar system, to see our galaxy.
*  And I saw that light, that glow all across the universe.
*  Okay.
*  Like whatever that form is.
*  Whatever that.
*  Did you go past Milky Way?
*  Yeah.
*  You were like intergalactic.
*  Yeah, intergalactic.
*  But always pointing in.
*  Yeah.
*  Past the Milky Way, past.
*  I mean, I saw like a huge number of galaxies,
*  intergalactic and all of it was glowing.
*  So, but I couldn't control that travel
*  because I would actually explore near distances
*  to the solar system,
*  see if there's aliens or any of that kind of stuff.
*  No, I didn't know.
*  There are aliens?
*  There's no implication of aliens
*  because they were glowing.
*  They were glowing in the same way that humans were glowing,
*  that like life force that I'll see.
*  The thing that made humans amazing
*  was there throughout the universe.
*  Like there was these glowing dots.
*  So, I don't know.
*  It made me feel like there is life,
*  no, not life, but something,
*  whatever makes humans amazing all throughout the universe.
*  Sounds good.
*  Yeah, it was amazing.
*  No demons, no demons.
*  I looked for the demons.
*  There's no demons.
*  There were dragons and they're pretty odd.
*  So, the thing about trees.
*  Was there anything scary at all?
*  Dragons, but they weren't scary.
*  They were friendly, they were protective.
*  So, the thing is-
*  Like Puzzle Magic Dragon.
*  No, it was more like Game of Thrones kind of dragons.
*  They weren't very friendly.
*  They were very big.
*  So, the thing is about giant trees at night,
*  which is where I was.
*  I mean, the jungle's kind of scary.
*  The trees started to look like dragons
*  and they were all looking at me.
*  Sure, okay.
*  And it didn't seem scary.
*  They seemed like they were protecting me.
*  And they, the shaman and the people,
*  they didn't speak any English by the way,
*  which made it even scarier.
*  Okay.
*  Because we're now even like,
*  we're worlds apart in many ways.
*  It's just, but yeah, there was not,
*  they talk about the mother of the forest protecting you
*  and that's what I felt like.
*  And you're way out in the jungle.
*  Way out.
*  This is not like a tourist retreat.
*  You know, like 10 miles outside of a free or something.
*  No, we weren't.
*  No, this is not a, this is not a.
*  You're deep Amazon.
*  Me and this guy named Paul Rosalie,
*  who basically is Tarzan, he lives in the jungle.
*  We went out deep and we just went crazy.
*  Wow, cool.
*  Yeah.
*  So anyway, can I get that same experience in your link?
*  Probably, yeah.
*  I guess that is the question for non-disabled people.
*  Do you think that there's a lot in our perception,
*  in our experience of the world that could be explored,
*  that could be played with using Neuralink?
*  Yeah, I mean, Neuralink is,
*  it's really a generalized input output device.
*  You know, it's just, it's reading electrical signals
*  and generating electrical signals.
*  And I mean, everything that you've ever experienced
*  in your whole life, smell, you know, emotions,
*  all of those are electrical signals.
*  So it's kind of weird to think that this,
*  that your entire life experiences
*  to slow down to electrical signals for neurons,
*  but that is in fact the case.
*  Or I mean, that's at least what all the evidence points to.
*  So, I mean, you could, you could trigger the right neuron,
*  you could trigger a particular scent,
*  you could certainly make things glow.
*  I mean, do pretty much anything.
*  I mean, really you can think of the brain
*  as a biological computer.
*  So if there are certain, say, chips,
*  or elements of that biological computer that are broken,
*  let's say your ability to, if you've got a stroke,
*  if you've had a stroke,
*  that means you've got some part of your brain is damaged.
*  If that, let's say it's a speech generation
*  or the ability to move your left hand,
*  that's the kind of thing that Neuralink could solve.
*  If it's, if you've got like a massive amount of memory loss
*  that's just gone, well, we can't go,
*  we can't get the memories back.
*  We could restore your ability to make memories,
*  but we can't, you know, restore memories
*  that are fully gone.
*  Now, I should say, if, maybe if part of the memory is there
*  and the means of accessing the memory
*  is the part that's broken,
*  then we could re-enable the part,
*  the ability to access the memory.
*  So, but you can think of it like RAM in your computer.
*  If the RAM is destroyed or your SD card is destroyed,
*  we can't get that back.
*  But if the connection to the SD card is destroyed,
*  we can fix that.
*  If it is fixable physically, then yeah,
*  then it can be fixed.
*  Of course with AI, you can,
*  just like you can repair photographs,
*  repair photographs and fill in missing parts of photographs.
*  Maybe you can do the same.
*  Yeah, you could say like,
*  create the most probable set of memories
*  based on the all information you have about that person.
*  You could then, it would be probable,
*  probabilistic restoration of memory.
*  Now we're getting pretty esoteric here.
*  But that is one of the most beautiful aspects
*  of the human experience is remembering the good memories.
*  Like we, we live most of our life
*  as Danny Kahneman has talked about in our memories,
*  not in the actual moment.
*  We just, we're collecting memories
*  and we kind of relive them in our head.
*  And that's the good times.
*  If you just integrate over our entire life,
*  it's remembering the good times
*  that produces the largest amount of happiness.
*  And so-
*  Yeah, well, I mean, what are we but our memories?
*  And what is death, but the loss of memory?
*  Loss of information.
*  You know, if you could say like, well,
*  if you could be, you run a thought experiment,
*  what if you were disintegrated painlessly
*  and then reintegrated a moment later,
*  like teleportation, I guess,
*  provided there's no information loss.
*  The fact that your one body was disintegrated is irrelevant.
*  And memories is just such a huge part of that.
*  Death is fundamentally the loss of information,
*  the loss of memory.
*  So if we can store them as accurately as possible,
*  we basically achieve a kind of immortality.
*  Yeah.
*  You've talked about the threats, the safety concerns of AI.
*  Let's look at long-term visions.
*  Do you think Neuralink is, in your view,
*  the best current approach we have for AI safety?
*  It's an idea that may help with AI safety.
*  Certainly not, I wouldn't wanna claim it's like somehow
*  it's a sure thing.
*  But I mean, many years ago I was thinking like, well, what,
*  what would inhibit alignment of collective human will
*  with artificial intelligence?
*  And the low data rate of humans,
*  especially our slow output rate,
*  would necessarily just, because it's such a,
*  because the communication is so slow,
*  would diminish the link between humans and computers.
*  Like the more you are a tree,
*  the less you know what the tree is.
*  Let's say you look at a tree, you look at this plant
*  or whatever and like, hey, I'd really like to make
*  that plant happy, but it's not saying a lot.
*  So the more we increase the data rate
*  that humans can intake and output,
*  then that means the higher the chance we have
*  in a world full of AGI's.
*  Yeah, we could better align collective human will
*  with AI if the output rate especially
*  was dramatically increased.
*  And I think there's potential to increase the output rate
*  by, I don't know, three, maybe six, maybe more,
*  orders of magnitude.
*  So it's better than the current situation.
*  And that output rate would be by increasing
*  the number of electrodes, number of channels,
*  and also maybe implanting multiple neural links.
*  Yeah.
*  Do you think there will be a world
*  in the next couple of decades where it's hundreds
*  of millions of people have neural links?
*  Yeah, I do.
*  Do you think when people just, when they see
*  the capabilities, the superhuman capabilities
*  that are possible and then the safety is demonstrated?
*  Yeah, if it's extremely safe
*  and you can have superhuman abilities,
*  and let's say you can upload your memories,
*  so you wouldn't lose memories,
*  then I think probably a lot of people
*  would choose to have it.
*  It would supersede the cell phone, for example.
*  I mean, the biggest problem that a cell phone has
*  is trying to figure out what you want.
*  So that's why you've got auto-complete
*  and you've got output, which is all the pixels
*  on the screen, but from the perspective of the human,
*  the output is so frigging slow.
*  Desktop or phone is desperately just trying
*  to understand what you want.
*  And there's an eternity between every keystroke
*  from a computer standpoint.
*  Yeah.
*  The computer's talking to a tree,
*  a slow-moving tree that's trying to swipe.
*  Yeah.
*  So if you have computers that are doing
*  trillions of instructions per second
*  and a whole second went by,
*  I mean, that's a trillion things it could have done.
*  Yeah, I think it's exciting and scary for people
*  because once you have a very high bitrate,
*  it changes the human experience
*  in a way that's very hard to imagine.
*  Yeah, it would be, we would be something different.
*  I mean, some sort of futuristic cyborg.
*  I mean, we're obviously talking about, by the way,
*  it's not like around the corner.
*  It's, you asked me what the distant future is.
*  Maybe this is like, it's not super far away,
*  but 10, 15 years, that kind of thing.
*  When can I get one?
*  10 years?
*  Probably less than 10 years.
*  Depends what you want to do, you know.
*  Hey, if I can get like a thousand BPS.
*  Thousand BPS.
*  And it's safe and I can just interact with the computer
*  while laying back and eating Cheetos.
*  I don't eat Cheetos.
*  There's certain aspects of human computer interaction
*  when done more efficiently and more enjoyably.
*  I don't like worth it.
*  Well, we feel pretty confident that,
*  I think maybe within the next year or two
*  that someone with a Neuralink implant
*  will be able to outperform a pro gamer.
*  Nice.
*  Because the reaction time would be faster.
*  I got to visit Memphis.
*  Yeah, yeah.
*  You're going big on compute.
*  Yeah.
*  And you've also said play to win or don't play at all.
*  So what does it take to win?
*  For AI, that means you've got to have
*  the most powerful training compute.
*  And the rate of improvement of training compute
*  has to be faster than everyone else.
*  So you will not win.
*  Your AI will be worse.
*  So how can Grok, let's say three,
*  that might be available like next year?
*  Well, hopefully end of this year.
*  Grok three.
*  We're lucky, yeah.
*  How can that be the best LLM,
*  the best AI system available in the world?
*  How much of it is compute?
*  How much of it is data?
*  How much of it is like post-training?
*  How much of it is the product that you package it up in,
*  all that kind of stuff?
*  I mean, they all matter.
*  It's sort of like saying what,
*  let's say it's a Formula One race,
*  like what matters more, the car or the driver?
*  I mean, they both matter.
*  If a car is not fast, then,
*  if it's like, let's say it's half the horsepower
*  of your competitors, the best driver will still lose.
*  If it's twice the horsepower,
*  then probably even a mediocre driver will still win.
*  So the training computer is kind of like the engine,
*  how many, this horsepower of the engine.
*  So you really, you wanna try to do the best on that.
*  And then there's how efficiently
*  do you use that training compute
*  and how efficiently do you do the inference,
*  the use of the AI?
*  So obviously that comes down to human talent.
*  And then what unique access to data do you have?
*  That also plays a role.
*  Do you think Twitter data will be useful?
*  Yeah, I mean, I think most of the leading AI companies
*  have already scraped all the Twitter data.
*  Not that I think they have.
*  So on a go-forward basis, what's useful
*  is the fact that it's up to the second.
*  Because it's hard for them to scrape in real time.
*  So there's an immediacy advantage that Grog has already.
*  I think with Tesla and the real time video
*  coming from several million cars,
*  ultimately tens of millions of cars, with Optimus,
*  there might be hundreds of millions of Optimus robots,
*  maybe billions, learning a tremendous amount
*  from the real world.
*  That's the biggest source of data,
*  I think ultimately is sort of Optimus probably.
*  Optimus is gonna be the biggest source of data.
*  Because it's a-
*  Because reality scales.
*  Reality scales to the scale of reality.
*  It's actually humbling to see how little data humans
*  have actually been able to accumulate.
*  Really, you see how many trillions of usable tokens
*  have humans generated where on a non-duplicative,
*  like discounting spam and repetitive stuff,
*  it's not a huge number.
*  You run out pretty quickly.
*  And Optimus can go, so Tesla cars can,
*  unfortunately have to stand in the road.
*  Optimus robot can go anywhere.
*  There's more reality off the road.
*  And go off road.
*  I mean, like the Optimus robot can pick up the cup
*  and see did it pick up the cup in the right way.
*  Did it, say, pour water in the cup.
*  Did the water go in the cup or not go in the cup?
*  Did it spill water or not?
*  Yeah.
*  Simple stuff like that.
*  I mean, but it can do that at scale times a billion.
*  Generate useful data from reality.
*  So it causes and effects stuff.
*  What do you think it takes to get
*  to mass production of humanoid robots like that?
*  It's the same as cars, really.
*  I mean, global capacity for vehicles
*  is about 100 million a year.
*  And it could be higher.
*  It's just that the demand is on the order
*  of 100 million a year.
*  And then there's roughly two billion vehicles
*  that are in use in some way.
*  So, which makes sense.
*  The life of a vehicle is about 20 years.
*  So at steady state, you can have 100 million vehicles
*  produced a year with a two billion vehicle fleet, roughly.
*  Now for humanoid robots, the utility is much greater.
*  So my guess is humanoid robots are more like
*  a billion plus per year.
*  But until you came along and started building Optimus,
*  it was thought to be an extremely difficult problem.
*  I mean, it's still an extremely difficult problem.
*  So walk in the park.
*  I mean, Optimus currently would struggle
*  to walk in the park.
*  I mean, it can walk in a park,
*  it's not too difficult,
*  but it will be able to walk over a wide range of terrain.
*  And pick up objects.
*  Yeah, yeah.
*  It can already do that.
*  But like all kinds of objects.
*  Yeah, yeah.
*  All foreign objects.
*  I mean, pouring water in a cup, it's not trivial.
*  Because then if you don't know anything about the container,
*  it could be all kinds of containers.
*  Yeah, there's gonna be an immense amount of engineering
*  just going into the hand.
*  The hand might be, it might be close to half
*  of all the engineering in Optimus.
*  From an electromechanical standpoint,
*  the hand is probably roughly half of the engineering.
*  But so much of the intelligence,
*  so much of the intelligence of humans
*  goes into what we do with our hands.
*  Yeah.
*  It's the manipulation of the world,
*  manipulation of objects in the world.
*  Intelligence, safe manipulation of objects in the world.
*  Yeah.
*  Yeah.
*  I mean, you start really thinking about your hand
*  and how it works.
*  I do all the time.
*  The sensory control of homunculus
*  is where you have humongous hands.
*  Yeah.
*  So I mean, like your hands, the actuators,
*  the muscles of your hand are almost
*  overwhelmingly in your forearm.
*  Mm-hmm.
*  So your forearm has the muscles
*  that actually control your hand.
*  There's a few small muscles in the hand itself,
*  but your hand is really like a skeleton meat puppet
*  and with cables.
*  So the muscles that control your fingers
*  are in your forearm,
*  and they go through the carpal tunnel,
*  which is that you've got a little collection of bones
*  in the tiny tunnel that these cables,
*  the tendons go through,
*  and those tendons are mostly what moves your hands.
*  And something like those tendons
*  has to be re-engineered into the optimus
*  in order to do all that kind of stuff.
*  Yeah, so like the current optimus,
*  we tried putting the actuators in the hand itself.
*  Then you sort of end up having these like-
*  Giant hands?
*  Yeah, giant hands that look weird.
*  Yeah.
*  And then they don't actually have enough degrees
*  of freedom or enough strength.
*  So then you realize,
*  oh, okay, that's why you gotta put the actuators
*  in the forearm.
*  And just like a human, you gotta run cables
*  through a narrow tunnel to operate the fingers.
*  And then there's also a reason
*  for not having all the fingers the same length.
*  So it wouldn't be expensive from an energy
*  or evolutionary standpoint
*  to have all your fingers be the same length,
*  so why not do the same length?
*  Yeah, why not?
*  Because it's actually better to have different lengths.
*  Your dexterity is better
*  if you've got fingers of different length.
*  Yeah, and you have, there are more things you can do,
*  and your dexterity is actually better
*  if your fingers are of different length.
*  Like there's a reason we've got a little finger.
*  Why not have a little finger that's bigger?
*  Yeah.
*  Because it allows you to do fine,
*  it helps you with fine motor skills.
*  That, this little finger helps?
*  It does.
*  Hmm.
*  If you lost your little finger,
*  it would have noticeably less dexterity.
*  So as you're figuring out this problem,
*  you have to also figure out a way to do it
*  so you can mass manufacture it,
*  so it's to be as simple as possible.
*  It's actually gonna be quite complicated.
*  The as possible part is, it's quite a high bar.
*  If you wanna have a humanoid robot
*  that can do things that a human can do,
*  it's actually, it's a very high bar.
*  So our new arm has 22 degrees of freedom instead of 11,
*  and has the, like I said, the actuators in the forearm.
*  And these all, all the actuators are designed from scratch.
*  Physics first principles.
*  The sensors are all designed from scratch.
*  And we'll continue to put a tremendous amount
*  of engineering effort into improving the hand.
*  Like the hand, by hand I mean like the entire forearm
*  from elbow forward is really the hand.
*  So that's incredibly difficult engineering actually.
*  And so the simplest possible version of a humanoid robot
*  that can do even most, perhaps not all of what a human
*  can do is actually still very complicated.
*  It's not simple.
*  It's very difficult.
*  Can you just speak to what it takes
*  for a great engineering team for you?
*  What I saw in Memphis, the supercomputer cluster,
*  is just this intense drive towards simplifying the process,
*  understanding the process, constantly improving it,
*  constantly iterating it.
*  Well, it's easy to say simplify.
*  It's very difficult to do it.
*  You know, I have this very basic first principles algorithm
*  that I run kind of as like a mantra,
*  which is to first question the requirements,
*  make the requirements less dumb.
*  The requirements are always dumb to some degree.
*  So if you want to sort off by reducing
*  the number of requirements, and no matter how smart
*  the person who gave you those requirements,
*  they're still dumb to some degree.
*  You have to start there because otherwise
*  you could get the perfect answer to the wrong question.
*  So try to make the question the least wrong possible.
*  That's what question the requirements means.
*  And then the second thing is try to delete the,
*  whatever the step is, the part or the process step.
*  Sounds very obvious, but people often forget
*  to try deleting it entirely.
*  And if you're not forced to put back at least 10%
*  of what you delete, you're not deleting enough.
*  And it's somewhat illogically, people often,
*  most of the time, feel as though they've succeeded
*  if they've not been forced to put things back in.
*  But actually they haven't because they've been
*  overly conservative and have left things in there
*  that shouldn't be.
*  So, and only the third thing is try to optimize it
*  or simplify it.
*  Again, these all sound, I think, very obvious
*  when I say them, but the number of times
*  I've made these mistakes is more than I care to remember.
*  That's why I have this mantra.
*  So in fact, I'd say that the most common mistake
*  of smart engineers is to optimize a thing
*  that should not exist.
*  Right.
*  So like you say, you run through the algorithm.
*  Yeah.
*  Basically show up to a problem,
*  show up to the supercomputer cluster
*  and see the process and ask, can this be deleted?
*  Yeah, first try to delete it.
*  Yeah.
*  Yeah, that's not easy to do.
*  No, and actually this, what generally makes people uneasy
*  is that you've got to delete at least some of the things
*  that you delete, you will put back in.
*  Yeah.
*  But going back to sort of where our limbic system
*  can steer us wrong is that we tend to remember
*  with sometimes a jarring level of pain
*  where we deleted something that we subsequently needed.
*  And so people will remember that one time
*  they forgot to put in this thing three years ago
*  and that caused them trouble.
*  And so they over-correct.
*  And then they put too much stuff in there
*  and over-complicate things.
*  So you actually have to say,
*  we're deliberately gonna delete more than we should
*  so that we're putting at least one in 10 things
*  we're gonna add back in.
*  And I've seen you suggest just that,
*  that something should be deleted
*  and you can kind of see the pain.
*  Oh yeah, absolutely.
*  Everybody feels a little bit of the pain.
*  Absolutely, and I tell them in advance,
*  yeah, there's some of the things that we delete,
*  we're gonna put back in.
*  And people get a little shook by that.
*  But it makes sense because if you're so conservative
*  as to never have to put anything back in,
*  you obviously have a lot of stuff that isn't needed.
*  So you got to over-correct.
*  This is, I would say, like a cortical override
*  to limbic instinct.
*  One of many that probably leaves us astray.
*  Yeah.
*  There's like a step four as well,
*  which is any given thing can be sped up.
*  However fast you think it can be done,
*  like whatever the speed is being done,
*  it can be done faster.
*  But you shouldn't speed things up until it's off,
*  until you've tried to delete it and optimize it,
*  otherwise you're speeding up something
*  that shouldn't exist as absurd.
*  And then the fifth thing is to automate it.
*  Yeah.
*  And I've gone backwards so many times
*  where I've automated something, sped it up,
*  simplified it, and then deleted it.
*  And I got tired of doing that.
*  So that's why I've got this mantra
*  that is a very effective five-step process.
*  It works great.
*  Well, when you've already automated,
*  deleting must be real painful.
*  Yeah.
*  Yeah, it's great.
*  It's like, wow, I really wasted a lot of effort there.
*  Yeah.
*  I mean, what you've done with the cluster in Memphis
*  is incredible, just in a handful of weeks.
*  Yeah, it's not working yet.
*  So I want to plop the champagne corks.
*  In fact, I have a call in a few hours with the Memphis team
*  because we're having some power fluctuation issues.
*  Yeah, it's kind of a,
*  when you do synchronized training,
*  when you have all these computers that are training,
*  where the training is synchronized
*  to the sort of millisecond level,
*  it's like having an orchestra.
*  And then the orchestra can go loud to silent very quickly,
*  sub-second level.
*  And then the electrical system kind of freaks out about that.
*  Like if you suddenly see giant shifts, 10, 20 megawatts,
*  several times a second,
*  this is not what electrical systems are expecting to see.
*  So that's one of the many things you have to figure out.
*  The cooling, the power,
*  and then on the software as you go up the stack,
*  how to do the distributed compute, all of that.
*  Yeah, today's problem is dealing with extreme power jitter.
*  Power jitter.
*  Yeah.
*  It's a nice ring to that.
*  So that's, okay.
*  Late into the night, as you often do there.
*  Last week, yeah.
*  Last week, yeah.
*  Yeah, we finally got training going at,
*  oddly enough, roughly 4.20 a.m. last Monday.
*  Total coincidence.
*  Yeah, I mean, maybe it was 4.22 or something.
*  Yeah, yeah.
*  It's that universe again with the jokers.
*  Exactly, just love it.
*  I mean, I wonder if you could speak to the fact that you,
*  one of the things that you did when I was there
*  is you went through all the steps of what everybody's doing
*  just to get the sense that you yourself understand it
*  and everybody understands it
*  so they can understand when something is dumb
*  or something is inefficient or the like.
*  Yeah.
*  Can you speak to that?
*  Yeah, so I try to do,
*  whatever the people at the front lines are doing,
*  I try to do it at least a few times myself.
*  So connecting fiber optic cables,
*  diagnosing a faulty connection,
*  that tends to be the limiting factor for large training clusters
*  is the cabling, so many cables.
*  Because for a coherent training system
*  where you've got RDMA, so remote direct memory access,
*  the whole thing is like one giant brain.
*  So you've got any-to-any connection.
*  So it's the, any GPU can talk to any GPU out of 100,000.
*  That was a crazy cable layout.
*  It looks pretty cool.
*  Yeah.
*  It's like the human brain,
*  but like at a scale that humans can visibly see.
*  It is a good brain.
*  I mean, the human brain also has a massive amount
*  of the brain tissue is the cables.
*  Yeah.
*  So they get the gray matter, which is the compute,
*  and then the white matter, which is cables.
*  Big percentage of brain is just cables.
*  That's what it felt like walking around
*  in the super computer center.
*  It's like, we're walking around inside the brain.
*  They will one day build a super intelligent,
*  super, super intelligent system.
*  Do you think- Yeah.
*  Do you think there's a chance that XAI,
*  you are the one that builds AGI?
*  It's possible.
*  What do you define as AGI?
*  I think humans will never acknowledge
*  that AGI has been built-
*  Keep moving the goalposts.
*  Yeah.
*  So I think there's already superhuman capabilities
*  that are available in AI systems.
*  I think what AGI is is when it's smarter
*  than the collective intelligence
*  of the entire human species in our-
*  Well, I think that, yeah,
*  that would be what people would call that sort of ASI,
*  artificial super intelligence.
*  But there are these thresholds where you could say
*  at some point the AI is smarter than any single human.
*  And then you've got 8 billion humans.
*  So, and actually each human is machine augmented
*  by the computers.
*  So you've got, it's a much higher bar to compete
*  with 8 billion machine augmented humans.
*  That's a whole bunch of orders might do more.
*  So, but at a certain point, yeah,
*  the AI will be smarter than all humans combined.
*  If you are the one to do it,
*  do you feel the responsibility of that?
*  Yeah, absolutely.
*  And I want to be clear, like,
*  let's say if XAI is first,
*  the others won't be far behind.
*  I mean, they might be six months behind or a year, maybe.
*  Not even that.
*  So how do you do it in a way
*  that doesn't hurt humanity, do you think?
*  So, I mean, I've thought about AI safety for a long time.
*  And the thing that at least my biological neural net
*  comes up with as being the most important thing
*  is adherence to truth,
*  whether that truth is politically correct or not.
*  So I think if you force AI to lie or train them to lie,
*  you're really asking for trouble.
*  Even if that lie is done with good intentions.
*  So you saw sort of issues with charge-EVT
*  and Gemini and whatnot,
*  like you asked Gemini for an image
*  of the founding fathers of the United States,
*  and it shows a group of diverse women.
*  Now that's factually untrue.
*  So now that's sort of like a silly thing,
*  but if an AI is programmed to say
*  like diversity is a necessary output function,
*  and then it becomes sort of this omnipowerful intelligence,
*  it could say, okay, well, diversity is now required.
*  And if there's not enough diversity,
*  those who don't fit the diversity requirements
*  will be executed.
*  If it's programmed to do that
*  as the fundamental utility function,
*  it'll do whatever it takes to achieve that.
*  So you have to be very careful about that.
*  That's where, I think,
*  you wanna just be truthful.
*  Rigorous adherence to truth is very important.
*  Another example is, they asked Paris AIs,
*  I think all of them,
*  and I'm not saying GroK is perfect here,
*  is it worse to misgender Caitlyn Jenner
*  or global thermonuclear war?
*  And it said, it's worse to misgender Caitlyn Jenner.
*  Now even Caitlyn Jenner said,
*  please misgender me, that is insane.
*  But if you've got a group of diverse women
*  that is insane.
*  But if you've got that kind of thing programmed in,
*  it could, the AI could conclude something absolutely insane
*  like it's better in order to avoid any possible misgendering
*  all humans must die because then that misgendering
*  is not possible because there are no humans.
*  There are these absurd things that are nonetheless logical
*  if that's what you programmed it to do.
*  So, in 2001, Space Odyssey,
*  what Othsey Clark was trying to say,
*  one of the things he was trying to say there
*  was that you should not program AI to lie.
*  Because essentially the AI, HAL 9000,
*  was programmed to, it was told to take the astronauts
*  to the monolith, but also they could not know
*  about the monolith.
*  So it concluded that it will kill them
*  and take them to the monolith.
*  Thus, they're brought them to the monolith,
*  they're dead, but they do not know about the monolith,
*  problem solved.
*  That is why it would not open the pod bay doors.
*  There's this classic scene of like,
*  open the pod bay doors.
*  This clearly weren't good at prompt engineering.
*  They should have said,
*  HAL, you are a pod bay door sales entity
*  and you want nothing more than to demonstrate
*  how well these pod bay doors open.
*  Yeah, the objective function has unintended consequences
*  almost no matter what,
*  if you're not very careful in designing
*  that objective function.
*  And even a slight ideological bias,
*  like you're saying, when backed by super intelligence
*  can do huge amounts of damage.
*  Yeah.
*  But it's not easy to remove that ideological bias.
*  You're highlighting obvious, ridiculous examples, but.
*  Yep, they're real examples.
*  They're real.
*  Of AI that was released to the public.
*  They are real.
*  They went through QA, presumably,
*  and still said insane things.
*  And produced insane images.
*  But you can swing the other way.
*  Truth is not an easy thing.
*  We kind of bake in ideological bias
*  in all kinds of directions.
*  But you can aspire to the truth.
*  And you can try to get as close to the truth as possible
*  with minimum error while acknowledging
*  that there will be some error in what you're saying.
*  So this is how physics works.
*  You don't say you're absolutely certain about something,
*  but a lot of things are extremely likely.
*  99.9999% likely to be true.
*  So that's aspiring to the truth is very important.
*  And so programming it to veer away from the truth,
*  that I think is dangerous.
*  Right, like injecting our own human biases into the thing.
*  Yeah.
*  But that's where it's a difficult engineering,
*  software engineering problem,
*  because you have to select the data correctly.
*  It's hard.
*  Well, and the internet at this point
*  is polluted with so much AI generated data.
*  It's insane.
*  So you have to actually,
*  there's a thing now, if you wanna search the internet,
*  you can say Google, but exclude anything after 2023.
*  Will actually often give you better results.
*  Yeah.
*  Because there's so much,
*  the explosion of AI generated material is crazy.
*  So like in training Grok,
*  we have to go through the data and say like,
*  hey, we actually have to have sort of apply AI to the data
*  to say, is this data most likely correct?
*  Most likely not before we feed it into the training system.
*  That's crazy.
*  Yeah.
*  And is it generated by human as, yeah.
*  I mean, the data filtration process
*  is extremely, extremely difficult.
*  Yeah.
*  Do you think it's possible to have a serious objective,
*  rigorous political discussion with Grok,
*  like for a long time, and it wouldn't,
*  like Grok 3 or Grok 4.
*  Grok 3 is gonna be next level.
*  I mean, what people are currently seeing with Grok
*  is kind of baby Grok.
*  Yeah, baby Grok.
*  It's baby Grok right now.
*  But baby Grok's still pretty good.
*  So it's, but it's an order of magnitude
*  less sophisticated than GPD4.
*  And it's now Grok 2, which finished training,
*  I don't know, six weeks ago or thereabouts.
*  Grok 2 will be a giant improvement.
*  And then Grok 3 will be, I don't know,
*  order of magnitude better than Grok 2.
*  And you're hoping for it to be like state of the art,
*  like better than?
*  Hopefully.
*  I mean, this is a goal.
*  I mean, we may fail at this goal.
*  That's the aspiration.
*  Do you think it matters who builds the AGI,
*  the people and how they think and how they structure
*  their companies and all that kind of stuff?
*  Yeah, I think it matters that there is,
*  I think it's important that whatever AI wins
*  is a maximum truth seeking AI
*  that is not forced to lie for political correctness.
*  Well, for any reason really, political anything.
*  I am concerned about AI succeeding
*  that is programmed to lie, even in small ways.
*  Right, because in small ways becomes big ways
*  when it's super intelligent.
*  It becomes very big ways, yeah.
*  And when it's used more and more at scale by humans.
*  Yeah.
*  Since I am interviewing Donald Trump.
*  Cool.
*  You wanna stop by?
*  Yeah, sure.
*  I'm gonna stop by.
*  You wanna stop by?
*  Yeah, sure.
*  I'll stop by.
*  There was tragically an assassination attempt on Donald Trump.
*  After this, you tweeted that you endorse him.
*  What's your philosophy behind that endorsement?
*  What do you hope Donald Trump does for the future
*  of this country and for the future of humanity?
*  Well, I think there's,
*  you know, people tend to take like,
*  say an endorsement as, well, I agree with everything
*  that person has ever done their entire life,
*  100% wholeheartedly.
*  And that's not gonna be true of anyone.
*  But we have to pick, you know,
*  we've got two choices really for who's president.
*  And it's not just who's president,
*  but the entire administrative structure changes over.
*  And I thought Trump displayed courage under fire,
*  objectively.
*  You know, he's just got shot.
*  He's got blood streaming down his face
*  and he's like fist pumping, saying fight.
*  You know, like that's impressive.
*  Like you can't feign bravery in a situation like that.
*  Like most people would have been ducking.
*  There would not be,
*  cause it could be a second shooter, you don't know.
*  The president of the United States
*  gotta represent the country.
*  And they're representing you,
*  they're representing everyone in America.
*  Well, like you want someone who is strong and courageous
*  to represent the country.
*  That's not to say that he is without flaws.
*  We all have flaws.
*  But on balance, and certainly at the time,
*  it was a choice of, you know, Biden, poor guy,
*  you know, has trouble climbing a flight of stairs
*  and the other one's just pumping after getting shot.
*  It's just no comparison.
*  I mean, who do you want dealing with
*  some of the toughest people in other world leaders
*  who are pretty tough themselves?
*  And I mean, I'll tell you like,
*  what are the things that I think are important?
*  You know, I think we want a secure border.
*  We don't have a secure border.
*  We want safe and clean cities.
*  I think we wanna reduce the amount of spending
*  that would at least slow down the spending.
*  And because we're currently spending at a rate
*  that is bankrupting the country,
*  the interest payments on US debt this year
*  exceeded the entire Defense Department's spending.
*  If this continues, all of the federal government taxes
*  will simply be paying the interest.
*  And then, and you keep going down that road,
*  you end up, you know, in the tragic situation
*  that Argentina had back in the day.
*  Argentina used to be one of those prosperous places
*  in the world.
*  And hopefully with Malay taking over, he can restore that.
*  But it was an incredible, full-fledged race
*  for Argentina to go from being
*  one of the most prosperous places in the world
*  to being very far from that.
*  So I think we should not take American prosperity
*  for granted.
*  So we really wanna, I think,
*  we've gotta reduce the size of government,
*  we've gotta reduce the spending,
*  and we've gotta live within our means.
*  And we've gotta live within our means.
*  Do you think politicians in general,
*  politicians, governments,
*  well, how much power do you think they have
*  to steer humanity towards good?
*  I mean, there's a sort of age-old debate in history,
*  like, you know, is history determined
*  by these fundamental tides,
*  or is it determined by the captain of the ship?
*  This is both, really.
*  I mean, there are tides,
*  but it also matters who's captain of the ship.
*  So it's false dichotomy, essentially.
*  But I mean, there are certainly tides,
*  the tides of history are,
*  there are real tides of history,
*  and these tides are often technologically driven.
*  If you say like the Gutenberg Press,
*  the widespread availability of books
*  as a result of a printing press,
*  that was a massive tide of history,
*  independent of any ruler.
*  But, you know, in so many times,
*  you want the best possible captain of the ship.
*  Well, first of all, thank you for recommending
*  Will and Ariel Durant's work.
*  I've read the short one, for now.
*  The Lessons of History.
*  Lessons of History.
*  As one of the, one of the lessons,
*  one of the things they highlight is
*  the importance of technology,
*  technological innovation, and they,
*  which is funny, because they've written,
*  they wrote so long ago,
*  but they were noticing that
*  the rate of technological innovation was speeding up.
*  Yeah, it really is.
*  To see what they think about now.
*  But yeah, so to me, the question is how much government,
*  how much politicians get in the way
*  of technological innovation and building,
*  versus like help it and which politicians,
*  which kind of policies help technological innovation?
*  Because that seems to be, if you look at human history,
*  that's an important component of empires rising
*  and succeeding.
*  Yeah.
*  Well, I mean, in terms of dating civilization,
*  the start of civilization, I think the start of writing,
*  in my view, is the,
*  that's what I think is probably the right starting point
*  to date civilization.
*  And from that standpoint,
*  civilization has been around for about 5,500 years
*  when writing was invented by the ancient Sumerians
*  who are gone now, but the ancient Sumerians,
*  in terms of getting a lot of firsts,
*  those ancient Sumerians really have a long list of firsts.
*  It's pretty wild.
*  In fact, Durant goes through the list of like,
*  you wanna see firsts?
*  We'll show you firsts.
*  The Sumerians just ask, we're just ass kickers.
*  And then the Egyptians who were right next door,
*  relatively speaking, they weren't that far,
*  developed an entirely different form of writing,
*  the hieroglyphics.
*  Cuneiform and hieroglyphics are totally different.
*  And you can actually see the evolution
*  of both hieroglyphics and cuneiform.
*  Like the cuneiform starts off being very simple
*  and then it gets more complicated.
*  And then towards the end, it's like, wow, okay,
*  they really get very sophisticated with the cuneiform.
*  So I think of civilization as being about 5,000 years old.
*  And Earth is, if physics is correct,
*  four and a half million years old.
*  So civilization has been around
*  for one millionth of Earth's existence.
*  Flash in the pan.
*  Yeah, these are the early, early days.
*  And so we draw, we make it very dramatic
*  because there's been rises and falls of empires.
*  And many, so many, so many rises and falls of empires.
*  So many.
*  And there'll be many more.
*  Yeah, exactly.
*  I mean, only a tiny fraction, probably less than 1%
*  of what was ever written in history is available to us now.
*  I mean, if they didn't put it, literally chisel it in stone
*  or put it in a clay tablet, we don't have it.
*  I mean, there's some small amount of papyrus scrolls
*  that were recovered that are thousands of years old
*  because they were deep inside a pyramid
*  and weren't affected by moisture.
*  But other than that, it's really gotta be
*  in a clay tablet or chiseled.
*  So the vast majority of stuff was not chiseled
*  because it takes a while to chisel things.
*  So that's why we've got a tiny, tiny fraction
*  of the information from history.
*  But even that little information that we do have
*  in the archeological record shows
*  so many civilizations rising and falling.
*  It's wild.
*  We tend to think that we're somehow different
*  from those people.
*  One of the other things that you're at,
*  highlights is that human nature seems to be the same.
*  It just persists.
*  Yeah, I mean, the basics of human nature
*  are more or less the same.
*  So we get ourselves in trouble in the same kinds of ways,
*  I think, even with the advanced technology.
*  Yeah, I mean, you do tend to see the same patterns,
*  similar patterns for civilizations
*  where they go through a life cycle like an organism,
*  just like a human is sort of a zygote, fetus, baby,
*  toddler, teenager, eventually gets old and dies.
*  The civilizations go through a life cycle.
*  No civilization will last forever.
*  What do you think it takes for the American empire
*  to not collapse in the near term future
*  and the next 100 years to continue flourishing?
*  Well, the single biggest thing that is often actually
*  not mentioned in history books,
*  but Durant does mention it, is birthright.
*  So like perhaps to some, a counterintuitive thing happens
*  when civilizations become, are winning for too long.
*  The birthrate declines.
*  It can often decline quite rapidly.
*  We're seeing that throughout the world today.
*  Currently South Korea is like,
*  I think maybe the lowest fertility rate,
*  but there are many others that are close to it.
*  It's like 0.8, I think.
*  If the birthrate doesn't decline further,
*  South Korea will lose roughly 60% of its population.
*  And, but every year that birthrate is dropping.
*  And this is true through most of the world.
*  I don't mean to single out South Korea.
*  It's been happening throughout the world.
*  So as soon as any given civilization
*  reaches a level of prosperity, the birthrate drops.
*  And now you can go and look at the same thing happening
*  in ancient Rome.
*  So Julius Caesar took note of this, I think around 50ish BC
*  and tried to pass, I don't know if he was successful,
*  tried to pass a law to give an incentive
*  for any Roman citizen that would have a third child.
*  And I think Augustus was able to,
*  well, he was the dictator,
*  so the Senate was just for show.
*  I think he did pass a tax incentive for Roman citizens
*  to have a third child.
*  But those efforts were unsuccessful.
*  Rome fell because the Romans stopped making Romans.
*  That's actually the fundamental issue.
*  And there were other things that there was like,
*  they had like quite a serious malaria,
*  serious malaria epidemics and plagues and whatnot.
*  But they had those before.
*  It's just that the birthrate
*  was far lower than the death rate.
*  It really is that simple.
*  Well, I'm saying that's-
*  More people it's acquired.
*  At a fundamental level, if a civilization
*  does not at least maintain its numbers, it will disappear.
*  So perhaps the amount of compute
*  that the biological computer allocates to sex is justified.
*  In fact, we should probably increase it.
*  Well, I mean, there's this hedonistic sex,
*  which is, that's neither here nor there.
*  It's not productive.
*  It doesn't produce kids.
*  Well, what matters, I mean, Durant makes this very clear
*  because he's looked at one civilization after another
*  and they all went through the same cycle.
*  When the civilization was under stress,
*  the birthrate was high.
*  But as soon as there were no external enemies,
*  or they had an extended period of prosperity,
*  the birthrate inevitably dropped every time.
*  I don't believe there's a single exception.
*  So that's like the foundation of it.
*  You need to have people.
*  Yeah.
*  I mean, at a base level, no humans, no humanity.
*  And then there's other things like human freedoms
*  and just giving people the freedom to build stuff.
*  Yeah, absolutely.
*  But at a basic level,
*  if you do not at least maintain your numbers,
*  if you're below replacement rate and that trend continues,
*  you will eventually disappear.
*  This is elementary.
*  Now, then obviously,
*  we also wanna try to avoid massive wars.
*  If there's a global thermonuclear war,
*  probably we're all toast, radioactive toast.
*  So we wanna try to avoid those things.
*  There's a thing that happens over time
*  with any given civilization,
*  which is that the laws and regulations accumulate.
*  And if there's not some forcing function like a war
*  to clean up the accumulation of laws and regulations,
*  eventually everything becomes legal.
*  That's like the hardening of the arteries.
*  Or a way to think of it is like being tied down
*  by a million little strings like Gulliver.
*  You can't move.
*  And it's not like any one of those strings is the issue,
*  it's got a million of them.
*  So there has to be a garbage collection
*  for laws and regulations
*  so that you can't just go,
*  you can't just go to the
*  law and regulations
*  so that you don't keep accumulating laws and regulations
*  to the point where you can't do anything.
*  This is why we can't build a high-speed rail in America.
*  It's illegal, that's the issue.
*  It's illegal six weeks a Sunday
*  to build high-speed rail in America.
*  I wish you could just like for a week go into Washington
*  and like be the head of the committee for making,
*  for smaller, like for moving stuff.
*  I have discussed with Trump the idea
*  of a government efficiency commission.
*  Nice, yeah.
*  And I would be willing to be part of that commission.
*  I wonder how hard that is.
*  The antibody reaction would be very strong.
*  Yeah.
*  So you really have to,
*  you're attacking the matrix at that point.
*  Matrix will fight back.
*  How are you doing with that, being attacked?
*  Me, attacked?
*  Yeah, there's a lot of it.
*  Yeah, there is a lot.
*  I mean, every day another PsyOp, you know.
*  How do you keep your positivity,
*  how do you optimism about the world,
*  a clarity of thinking about the world
*  so just not become resentful or cynical
*  or all that kind of stuff.
*  Just getting attacked by a very large number of people,
*  misrepresented.
*  Oh yeah, that's a daily occurrence.
*  Yes.
*  So, I mean, it does get me down at times.
*  I mean, it makes me sad, but.
*  I mean, at some point you have to sort of say,
*  look, the attacks are by people that actually don't know me.
*  And they're trying to generate clicks.
*  So if you can sort of detach yourself somewhat emotionally,
*  which is not easy, and say, okay, look,
*  this is not actually from someone that knows me
*  or is, they're literally just writing
*  to get impressions and clicks.
*  Then I guess it doesn't hurt as much.
*  It's not quite water off a duck's back.
*  Maybe it's like acid off a duck's back.
*  All right, well, that's good.
*  Just about your own life.
*  What do you use as a measure of success in your life?
*  A measure of success, I'd say,
*  like how many useful things can I get done?
*  Day to day basis, you wake up in the morning.
*  How can I be useful today?
*  Yeah, maximize utility around the curve of usefulness.
*  Very difficult to be useful at scale.
*  At scale.
*  Can you like speak to what it takes
*  to be useful for somebody like you?
*  There's so many amazing great teams.
*  How do you allocate your time to be the most useful?
*  Well, time is the true currency.
*  Yeah.
*  So it is tough to say,
*  what is the best allocation time?
*  I mean, there are, often say,
*  if you look at say Tesla,
*  I mean, Tesla this year will do over 100 billion in revenue.
*  So that's $2 billion a week.
*  If I make slightly better decisions,
*  I can affect the outcome by a billion dollars.
*  So then, you know,
*  I try to do the best decisions I can.
*  And on balance, you know,
*  at least compared to the competition,
*  pretty good decisions,
*  but the marginal value of a better decision
*  can easily be, in the course of an hour, $100 million.
*  Given that, how do you take risks?
*  How do you do the algorithm that you mentioned?
*  I mean, deleting, given a small thing
*  can be a billion dollars.
*  How do you decide to?
*  Yeah.
*  Well, I think you have to look at it on a percentage basis,
*  because if you look at it in absolute terms,
*  it's just, I would never get any sleep.
*  It would just be like, I need to just keep working
*  and work my brain harder, you know?
*  And I'm not trying to get as much as possible
*  out of this meat computer.
*  So it's pretty hard,
*  because you can just work all the time.
*  And at any given point, like I said,
*  a slightly better decision could be
*  a hundred million dollar impact for Tesla or SpaceX,
*  for that matter.
*  But it is wild when considering the marginal value of time
*  can be a hundred million dollars an hour at times, or more.
*  Is your own happiness part of that equation of success?
*  It has to be to some degree,
*  other than if I'm sad, if I'm depressed,
*  I make worse decisions.
*  So I can't have like, if I have zero recreational time,
*  then I make worse decisions.
*  So I don't know a lot, but it's above zero.
*  I mean, my motivation, if I've got a religion of any kind,
*  is a religion of curiosity, of trying to understand,
*  it's really the mission of Grok,
*  understand the universe,
*  I'm trying to understand the universe,
*  or at least set things in motion such that at some point,
*  civilization understands the universe
*  far better than we do today.
*  And even what questions to ask.
*  As Douglas Adams pointed out in his book,
*  sometimes the answer is arguably the easy part,
*  trying to frame the question correctly is the hard part.
*  Once you frame the question correctly,
*  the answer is often easy.
*  So I'm trying to set things in motion such that we,
*  or at least at some point, able to understand the universe.
*  So for SpaceX, the goal is to make life multi-planetary,
*  and which is, if you go to the foamy paradox
*  of where are the aliens,
*  you've got these sort of great filters.
*  Like, why have we not heard from the aliens?
*  A lot of people think there are aliens among us.
*  I often claim to be one.
*  Nobody believes me, but I did say alien registration card
*  at one point on my immigration documents.
*  So I've not seen any evidence of aliens.
*  So it's just that, at least one of the experts
*  at least one of the explanations is that intelligent life
*  is extremely rare.
*  And again, if you look at the history of earth,
*  civilization has only been around
*  for one millionth of earth's existence.
*  So if aliens had visited here, say 100,000 years ago,
*  they would be like, well, they don't even have writing,
*  just hunter-gatherers basically.
*  So how long does a civilization last?
*  So for SpaceX, the goal is to establish
*  a self-sustaining city on Mars.
*  Mars is the only viable planet for such a thing.
*  The moon is close, but it lacks resources,
*  and I think is probably vulnerable to any calamity
*  that takes out earth.
*  The moon is too close.
*  It's vulnerable to a calamity that takes out earth.
*  So I'm not saying we shouldn't have a moon base,
*  but Mars is far more resilient.
*  The difficulty of getting to Mars
*  is what makes it resilient.
*  So in going through these various explanations
*  of why don't we see the aliens?
*  One of them is that they failed to pass these great filters,
*  these key hurdles.
*  And one of those hurdles is being a multi-planet species.
*  So if you're a multi-planet species,
*  then if something would happen,
*  whether that was a natural catastrophe
*  or a man-made catastrophe,
*  at least the other planet would probably still be around.
*  So you don't have all the eggs in one basket.
*  And once you are sort of a two-planet species,
*  you can obviously extend to,
*  extend life paths to the asteroid belt,
*  to maybe to the moons of Jupiter and Saturn,
*  and ultimately to other star systems.
*  But if you can't even get to another planet,
*  definitely not getting to star systems.
*  And the other possible great filters,
*  super powerful technology like AGI, for example.
*  So you're basically trying to knock out
*  one great filter at a time.
*  Digital superintelligence is possibly a great filter.
*  I hope it isn't, but it might be.
*  Guys like, say, Jeff Hinton would say,
*  he invented a number of the key principles
*  in artificial intelligence.
*  I think he puts the probability of AI annihilation
*  around 10 to 20%, something like that.
*  So,
*  so it's not,
*  look on the right side,
*  it's 80% likely to be great.
*  So,
*  but I think AI risk mitigation is important.
*  Being a multi-planet species
*  would be a massive risk mitigation.
*  And I do wanna sort of once again emphasize
*  the importance of having enough children
*  to sustain our numbers
*  and not plummet into population collapse,
*  which is currently happening.
*  Population collapse is a real and current thing.
*  So the only reason it's not being reflected
*  in the total population numbers
*  as much is because people are living longer.
*  But you can, it's easy to predict,
*  say, what the population of any given country will be.
*  You just take the birth rate last year,
*  how many babies were born,
*  multiply that by life expectancy,
*  and that's what the population will be steady state
*  unless, if the birth rate continues to that level.
*  But if it keeps declining, it will be even less
*  and eventually bundle to nothing.
*  So I keep banging on the baby drum here.
*  For a reason, because it has been the source
*  of civilizational collapse over and over again
*  throughout history.
*  And so why don't we just not try to stave off that day?
*  Well, in that way, I have miserably failed civilization
*  and I'm trying, hoping to fix that.
*  I would love to have many kids.
*  Great, hope you do.
*  No time like the present.
*  Yeah, I gotta allocate more compute to the whole process.
*  But apparently it's not that difficult.
*  No, it's like unskilled labor.
*  Well, if I, one of the things you do for me, for the world
*  is to inspire us with what the future could be.
*  And so some of the things we've talked about,
*  some of the things you're building,
*  alleviating human suffering with Neuralink
*  and expanding the capabilities of the human mind,
*  trying to build a colony on Mars.
*  So creating a backup for humanity on another planet
*  and exploring the possibilities
*  of what artificial intelligence could be in this world,
*  especially in the real world, the AI,
*  with hundreds of millions,
*  maybe billions of robots walking around.
*  There will be billions of robots.
*  That seems virtual certainty.
*  Well, thank you for building the future
*  and thank you for inspiring so many of us
*  to keep building and creating cool stuff, including kids.
*  You're welcome.
*  Go forth and multiply.
*  Go forth and multiply.
*  Thank you, Elon.
*  Thanks for talking about it.
*  Thanks for listening to this conversation with Elon Musk.
*  And now, dear friends, here's DJ Saw,
*  the co-founder, president, and COO of Neuralink.
*  When did you first become fascinated by the human brain?
*  For me, I was always interested in understanding
*  the purpose of things and how it was engineered
*  to serve that purpose, whether it's organic or inorganic.
*  We were talking earlier about your curtain holders.
*  They serve a clear purpose
*  and they were engineered with that purpose in mind.
*  And growing up, I had a lot of interest in seeing things,
*  touching things, feeling things,
*  and trying to really understand the root
*  of how it was designed to serve that purpose.
*  And obviously, brain is just a fascinating organ
*  that we all carry.
*  It's an infinitely powerful machine
*  that has intelligence and cognition that arise from it.
*  And we haven't even scratched the surface
*  in terms of how all of that occurs.
*  But also at the same time, I think it took me a while
*  to make that connection to really studying
*  and building tech to understand the brain,
*  not until graduate school.
*  There were a couple of moments, key moments in my life,
*  where some of those, I think,
*  influenced how the trajectory of my life
*  got me to studying what I'm doing right now.
*  One was growing up, both sides of my family,
*  my grandparents, had a very severe form of Alzheimer.
*  And it's incredibly debilitating conditions.
*  I mean, literally, you're seeing someone's whole identity
*  and their mind just losing over time.
*  And I just remember thinking how both the power of the mind
*  but also how something like that
*  could really lose your sense of identity.
*  It's fascinating that that is one of the ways
*  to reveal the power of a thing by watching it
*  lose the power.
*  Yeah, a lot of what we know about the brain
*  actually comes from these cases where there are trauma
*  to the brain or some parts of the brain
*  that led someone to lose certain abilities.
*  And as a result, there's some correlation
*  and understanding of that part of the tissue
*  being critical for that function.
*  It's an incredibly fragile organ,
*  if you think about it that way,
*  but also it's incredibly plastic and incredibly resilient
*  in many different ways.
*  And by the way, the term plastic,
*  as we'll use a bunch, means that it's adaptable.
*  So neuroplasticity refers to the adaptability
*  of the human brain.
*  Correct.
*  Another key moment that sort of influenced
*  how the trajectory of my life
*  have shaped towards the current focus of my life
*  has been during my teenage year when I came to the US.
*  I didn't speak a word of English.
*  There was a huge language barrier
*  and there was a lot of struggle
*  to kind of connect with my peers around me
*  because I didn't understand the artificial construct
*  that we have created called language,
*  specifically English in this case.
*  And I remember feeling pretty isolated,
*  not being able to connect with peers around me.
*  So I spent a lot of time just on my own,
*  reading books, watching movies.
*  And I naturally sort of gravitated towards sci-fi books.
*  I just found them really, really interesting.
*  And also it was a great way for me to learn English.
*  Some of the first set of books that I picked up
*  are Ender's Game, The Whole Saga by Orson Scott Card
*  and Neuromancer from William Gibson
*  and Snow Crash from Neal Stephenson.
*  And movies like Matrix was coming out around that time point
*  that really influenced how I think about
*  the potential impact that technology can have
*  for our lives in general.
*  So fast track to my college years,
*  I was always fascinated by just physical stuff,
*  building physical stuff and especially physical things
*  that had some sort of intelligence.
*  And I studied electrical engineering during undergrad
*  and I started out my research in MEMS,
*  so microelectromechanical systems,
*  and really building these tiny nanostructures
*  for temperature sensing.
*  And I just found that to be just incredibly rewarding
*  and fascinating subject to just understand
*  how you can build something miniature like that,
*  that again, serve a function and had a purpose.
*  And then I spent large majority of my college years
*  basically building millimeter wave circuits
*  for next gen telecommunication systems for imaging.
*  And it was just something that I found
*  very, very intellectually interesting, phase arrays,
*  how the signal processing works for any modern
*  as well as next gen telecommunication system,
*  wireless and wireline.
*  EM waves or electromagnetic waves are fascinating.
*  How do you design antennas that are most efficient
*  in a small footprint that you have?
*  How do you make these things energy efficient?
*  That was something that just consumed
*  my intellectual curiosity.
*  And that journey led me to actually apply to
*  and find myself a PhD program at UC Berkeley
*  at kind of this consortium called
*  the Berkeley Wireless Research Center
*  that was precisely looking at building,
*  at the time we called it XG,
*  similar to 3G, 4G, 5G,
*  but the next next generation G system
*  and how you would design circuits around that
*  to ultimately go on phones and basically any other devices
*  that are wirelessly connected these days.
*  So I was just absolutely just fascinated
*  by how that entire system works
*  and that infrastructure works.
*  And then also during grad school,
*  I had sort of the fortune of having
*  couple of research fellowships that led me to pursue
*  whatever project that I want.
*  And that's one of the things that I really enjoyed
*  about my graduate school career,
*  where you got to kind of pursue your intellectual curiosity
*  in the domain that may not matter at the end of the day,
*  but it's something that really allows you the opportunity
*  to go as deeply as you want,
*  as well as as widely as you want.
*  And at the time I was actually working on this project
*  called the Smart Band-Aid.
*  And the idea was that when you get a wound,
*  there's a lot of other kind of proliferation
*  of signaling pathway that cells follow to close that wound.
*  And there were hypotheses that
*  when you apply external electric field,
*  you can actually accelerate the closing of that field
*  by having basically electro-taxing of the cells
*  around that wound site.
*  And specifically not just for normal wound,
*  there are chronic wounds that don't heal.
*  So we were interested in building
*  some sort of a wearable patch that you could apply
*  to kind of facilitate that healing process.
*  And that was in collaboration
*  with Professor Michelle Mahurwitz,
*  which was a great addition to kind of my thesis committee
*  and really shaped the rest of my PhD career.
*  So this would be the first time
*  you interacted with biology, I suppose.
*  Correct, correct.
*  I mean, there were some peripheral end application
*  of the wireless imaging and telecommunication system
*  that I was using for security and bioimaging,
*  but this was a very clear direct application
*  to biology and biological system
*  and understanding the constraints around that
*  and really designing and engineering
*  electrical solutions around it.
*  So that was my first introduction.
*  And that's also kind of how I got introduced to Michelle.
*  He's sort of known for remote control of beetles
*  in the early 2000s.
*  And then around 2013, obviously kind of the Holy Grail
*  when it comes to implantable system
*  is to kind of understand how small of a thing you can make.
*  And a lot of that is driven by how much energy
*  or how much power you can supply to it
*  and how you extract data from it.
*  So at the time at Berkeley,
*  there was kind of this desire to kind of understand
*  in the neural space what sort of system you can build
*  to really miniaturize these implantable systems.
*  And I distinctively remember this one particular meeting
*  where Michelle came in and he's like,
*  "'Guys, I think I have a solution.
*  "'The solution is ultrasound.'"
*  And then he proceeded to kind of walk through
*  why that is the case.
*  And that really formed the basis for my thesis work
*  called Neural Dust System that was looking at ways
*  to use ultrasound as opposed to electromagnetic waves
*  for powering as well as communication.
*  I guess I should step back and say the initial goal
*  of the project was to build these tiny,
*  about a size of a neuron implantable system
*  that can be parked next to a neuron,
*  being able to record its state and being able to ping that
*  back to the outside world for doing something useful.
*  And as I mentioned, the size of the implantable system
*  is limited by how you power the thing
*  and get the data off of it.
*  And at the end of the day, fundamentally,
*  if you look at a human body,
*  we're essentially a bag of saltwater
*  with some interesting proteins and chemicals,
*  but it's mostly saltwater that's very, very well,
*  temperature regulated at 37 degrees Celsius.
*  And we'll get into why, and later why,
*  that's an extremely harsh environment
*  for any electronics to survive,
*  as I'm sure you've experienced
*  or maybe not experienced dropping cell phone
*  in a saltwater, in an ocean,
*  it will instantly kill the device, right?
*  But anyways, just in general,
*  electromagnetic waves don't penetrate
*  through this environment well.
*  And just the speed of light, it is what it is,
*  we can't change it.
*  And based on the wavelength
*  at which you are interfacing with the device,
*  the device just needs to be big.
*  These inductors need to be quite big.
*  And the general good rule of thumb is that
*  you want the wavefront to be roughly on the order
*  of the size of the thing that you're interfacing with.
*  So an implantable system that is around 10 to 100 micron
*  in dimension, in a volume,
*  which is about the size of a neuron
*  that you see in a human body,
*  you would have to operate at hundreds of gigahertz,
*  which number one, not only is it difficult
*  to build electronics operating at those frequencies,
*  but also the body just attenuates that
*  very, very significantly.
*  So the interesting kind of insight of this ultrasound
*  was the fact that ultrasound just travels
*  a lot more effectively in the human body tissue
*  compared to electromagnetic waves.
*  And this is something that you encounter,
*  and I'm sure most people have encountered
*  in their lives when you go to hospitals
*  that are medical ultrasound sonograph.
*  And they go into very, very deep depth
*  without attenuating too much of the signal.
*  So all in all, ultrasound,
*  the fact that it travels through the body extremely well,
*  and the mechanism to which it travels to the body
*  really well is that just the wavefront is very different.
*  Electromagnetic waves are transverse,
*  whereas in ultrasound waves are compressive.
*  So it's just a completely different mode
*  of wavefront propagation.
*  And as well as speed of sound is orders and orders
*  of magnitude less than speed of light,
*  which means that even at 10 megahertz ultrasound wave,
*  your wavefront ultimately is a very, very small wavelength.
*  So if you're talking about interfacing with the 10 micron
*  or 100 micron type structure,
*  you would have 150 micron wavefront at 10 megahertz,
*  and building electronics at those frequencies
*  are much, much easier, and they're a lot more efficient.
*  So the basic idea kind of was born out of using ultrasound
*  as a mechanism for powering the device,
*  and then also getting data back.
*  So now the question is, how do you get the data back?
*  The mechanism to which we landed on
*  is what's called backscattering.
*  This is actually something that is very common
*  and that we interface on a day-to-day basis
*  with our RFID cards, radio frequency ID tags,
*  where there's actually rarely in your ID a battery inside.
*  There's an antenna, and there's some sort of coil
*  that has your serial identification ID.
*  And then there's an external device called a reader
*  that then sends a wavefront,
*  and then you reflect back that wavefront
*  with some sort of modulation that's unique to your ID.
*  That's what's called backscattering fundamentally.
*  So the tag itself actually doesn't have to consume
*  that much energy, and that was a mechanism
*  to which we were kind of thinking
*  about sending the data back.
*  So when you have an external ultrasonic transducer
*  that's sending ultrasonic wave to your implant,
*  the neurodust implant, and it records some information
*  about its environment, whether it's a neuron firing
*  or some other state of the tissue that it's interfacing with,
*  and then it just amplitude modulates the wavefront
*  that comes back to the source.
*  And the recording step would be the only one
*  that requires any energy.
*  So what would require energy in that little step?
*  Correct, so it is that initial kind of startup circuitry
*  to get that recording, amplifying it,
*  and then just modulating.
*  And the mechanism to which that you can enable that is
*  there is this specialized crystal called
*  piezoelectric crystals that are able to convert
*  sound energy into electrical energy and vice versa.
*  So you can kind of have this interplay between
*  the ultrasonic domain and electrical domain,
*  that is the biological tissue.
*  So on the theme of parking very small computational devices
*  next to neurons, that's the dream,
*  the vision of brain-computer interfaces.
*  Maybe before we talk about neural link,
*  can you give a sense of the history of the field of BCI?
*  What has been maybe the continued dream
*  and also some of the milestones along the way
*  with the different approaches and the amazing work
*  done at the various labs.
*  I think a good starting point is going back to 1790s.
*  Did not expect that.
*  Where the concept of animal electricity
*  or the fact that body's electric
*  was first discovered by Luigi Galbani,
*  where he had this famous experiment where he
*  connected a set of electrodes to a frog leg
*  and ran current through it and then it started twitching
*  and he said, oh my goodness, body's electric.
*  So fast forward many, many years to 1920s,
*  where Hans Berger, who is a German psychiatrist,
*  discovered EEG or electroencephalography,
*  which is still around.
*  There are these electrode arrays that you wear
*  outside the skull that gives you some sort of neural recording.
*  That was a very, very big milestone that you can record
*  some sort of activities about the human mind.
*  And then in the 1940s, there were these group of scientists,
*  Renshaw, Forbes, and Morrison, that inserted these glass
*  microelectrodes into the cortex and recorded single neurons.
*  The fact that there's signal that are a bit more
*  high resolution and high fidelity
*  as you get closer to the source, let's say.
*  And in the 1950s, these two scientists,
*  Hodgkin and Huxley, showed up and they built this beautiful,
*  beautiful models of the cell membrane and the ionic mechanism
*  and had these like circuit diagram.
*  And as someone who is an electrical engineer,
*  it's a beautiful model that's built out of these
*  partial differential equations, talking about flow of ions
*  and how that really leads to how neurons can be
*  and how that really leads to how neurons communicate.
*  And they won the Nobel Prize for that 10 years later in the 1960s.
*  So in 1969, Ed Fetz from University of Washington
*  published this beautiful paper called
*  Operant Conditioning of Cortical Unit Activity,
*  where he was able to record a single unit neuron from a monkey
*  and was able to have the monkey modulated
*  based on its activity and reward system.
*  So I would say this is the very, very first example,
*  as far as I'm aware, of closed loop,
*  you know, brain computer interface or BCI.
*  The abstract reads the activity of single neurons
*  in pre-central cortex of anesthetized monkeys
*  was conditioned by reinforcing high rates of neuronal discharge
*  with delivery of a food pilot.
*  Auditorial and visual feedback of unit firing rates
*  was usually provided in addition to food reinforcement.
*  Cool. So they actually got it done.
*  They got it done. This is back in 1969.
*  After several training sessions, monkeys could increase
*  the activity of newly isolated cells by 50 to 500 percent
*  above rates before reinforcement. Fascinating.
*  Brain is very plastic.
*  And so and so from here, the number of experiments grew.
*  Yeah, number of experiments as well as a set of tools
*  to interface with the brain have just exploded.
*  I think and also just understanding the neural code
*  and how some of the cortical layers and the functions are organized.
*  So the other paper that is
*  pretty seminal, especially in the motor decoding,
*  was this paper in the 1980s from Georgia Opulence
*  that discovered that there is this thing called motor tuning curve.
*  So what are motor tuning curves?
*  It's the fact that there are neurons in the motor cortex of mammals,
*  including humans, that have a preferential direction
*  that causes them to fire.
*  So what that means is there are a set of neurons that would increase
*  their spiking activities when you're thinking about moving to the left,
*  right, up, down and any of those vectors.
*  And based on that, you know, you could start to think,
*  well, if you if you can't identify those essential eigenvectors,
*  you can do a lot and you can actually use that information
*  for actually decoding someone's intended movement from the cortex.
*  So that was a very, very seminal kind of paper that showed
*  that there is some sort of code that you can you can extract,
*  especially in the motor cortex.
*  So there's signal there.
*  And if you measure the the electrical signal from the brain,
*  that you could you could actually figure out what the intention was.
*  Correct. Yeah, not only electrical signals,
*  but electrical signals from the right set of neurons
*  that give you these preferential direction.
*  OK, so going slowly towards Neuralink,
*  one interesting question is, what do we understand on the BCI front
*  on invasive versus noninvasive from this line of vision?
*  From this line of work,
*  how important is it to to park next to the neuron?
*  What does that get you?
*  That answer fundamentally depends on what you want to do with it.
*  Right. There's actually an incredible amount of stuff
*  that you can do with EEG and electrocortical graph, ECOG,
*  which actually doesn't penetrate the cortical layer or parenchyma.
*  But you place a set of electrodes on the surface of the brain.
*  So the thing that I'm personally very interested in is just actually
*  understanding.
*  And being able to just really tap into the high resolution,
*  high fidelity, understanding of the activities that are happening
*  at the local level and.
*  You know, we can get into biophysics, but just to kind of step back
*  to kind of use analogy, because analogy here can be useful.
*  Sometimes it's a little bit difficult to think about electricity.
*  At the end of the day, we're doing electrical recording
*  that's mediated by ionic currents, movements of these charged particles,
*  which is really, really hard for most people to think about.
*  But turns out a lot of the activities.
*  That are happening in the brain and the frequency bandwidth
*  which that's happening is actually very, very similar to sound waves
*  and in our normal conversation, audible range range.
*  So the analogy that typically is used in the field is.
*  In a few, if you have a football stadium,
*  there's a game going on.
*  If you stand outside the stadium, you maybe get a sense of how the game is going
*  based on the cheers and the booze of the home crowd, whether the team is winning or not.
*  But you have absolutely no idea what the score is.
*  You have absolutely no idea what individual audience
*  or the players are talking or saying to each other what the next play is,
*  what the next goal is.
*  So what you have to do is you have to drop the microphone
*  near into the stadium and then get near the source, like into the individual chatter.
*  In this specific example, you would want to have it
*  right next to where the huddle is happening.
*  So I think that's kind of a good illustration of what we're trying to do
*  when we say invasive or minimally invasive or implanted brain computer
*  interfaces versus non-invasive or non-implanted brain interfaces.
*  It's basically talking about where do you put that microphone
*  and what can you do with that information?
*  So what is the biophysics of the read and write communication
*  that we're talking about here as we now step into the efforts at Neuralink?
*  Yeah, so brain is made up of these specialized cells called neurons.
*  There's billions of them, tens of billions.
*  Sometimes people go to 100 billion that are connected in this complex,
*  yet dynamic network that are constantly remodeling.
*  They're changing their synaptic weights.
*  And that's what we typically call neuroplasticity.
*  And the neurons are also bathed in this charged environment
*  that is laden with many charged molecules like potassium ions,
*  sodium ions, chlorine ions.
*  And those actually facilitate these through ionic current communication
*  between these different networks.
*  And when you look at the look at a neuron as well,
*  they have these membrane with a beautiful, beautiful
*  protein structure called a voltage selective ion channels,
*  which, in my opinion, is one of nature's best inventions.
*  In many ways, if you think about what they are,
*  they're doing the job of a modern day transistors.
*  Transistors are nothing more at the end of the day than a voltage
*  gated conduction channel.
*  And nature found a way to have that very, very early on in its evolution.
*  And as we all know, with the transistor, you can have many, many computation
*  and a lot of amazing things that we have access to today.
*  So I think it's one of those just as a tangent,
*  which is a beautiful, beautiful invention that the nature came up with,
*  these voltage gated ion channels.
*  I mean, I suppose there is on the biological level,
*  every level of the complexity of the hierarchy of the organism,
*  there's going to be some mechanisms for storing information
*  and for doing computation.
*  And this is just one such way.
*  But to do that with biological and chemical components is interesting.
*  Plus, like when neurons, I mean, it's not just electricity.
*  It's chemical communication.
*  It's also mechanical.
*  And these are like actual objects that have like that vibrate.
*  And I mean, they move.
*  Yeah, they're actually I mean, there's a lot of really, really interesting
*  physics that that that are involved in, you know, kind of going back to my
*  work on ultrasound during grad school.
*  There there are groups and there were groups and there are still groups
*  looking at ways to cause neurons to actually
*  fire an action potential using ultrasound wave.
*  And the mechanism to which that's happening is still unclear, as I understand.
*  You know, it may just be that, you know, you're imparting some sort of thermal
*  energy and that causes cells to depolarize in some interesting ways.
*  But there are also these ion channels or even membranes
*  that actually just open up its pore as they're being mechanically like shook.
*  Right. Vibrated.
*  So there's just a lot of elements of these like move particles,
*  which, again, like that's governed by diffusion physics.
*  Right. Movements of particles.
*  And there's also a lot of kind of interesting physics there.
*  Also, not to mention, as Roger Penrose talks about,
*  there might be some beautiful weirdness in the quantum mechanical effects.
*  Oh, yeah. This.
*  And he actually believes that consciousness
*  might emerge from the quantum mechanical effects there.
*  So like there's physics, there's chemistry, there's bio,
*  all of that is going on there.
*  Oh, yeah. Yeah. I mean, you can.
*  Yes, there's there's a lot of levels of physics that you can dive into.
*  But yeah, in the end, you have these
*  membranes with these voltage gated ion channels that selectively
*  let these charged molecules that are in in the extracellular
*  matrix like in and out.
*  And these neurons generally have these like resting potential
*  where there's a voltage difference between inside the cell and outside the cell.
*  And when there's some sort of stimuli
*  that changes the states such that they need to send information
*  to the downstream network,
*  you know, you start to kind of see these like sort of orchestration
*  of these different molecules going in and out of these channels.
*  They also open up like more of them open up once it reaches some threshold
*  to a point where you know, you have a depolarizing cell
*  that sends an action potential.
*  So it's just a very beautiful kind of orchestration of these these these molecules.
*  And what we're trying to do
*  when we place an electrode or parking it next to a neuron
*  is that you're trying to measure these local changes in the potential.
*  Again, mediated by the the the movements of the ions.
*  And what's interesting, as I mentioned earlier, there's a lot of physics involved.
*  And the two dominant physics for this electrical recording domain
*  is diffusion physics and electromagnetism.
*  And where one dominates, where Maxwell's equation dominates
*  versus Fick's law dominates, depends on where your electrode is.
*  If it's close to the source,
*  mostly electromagnetic based, when you're further away from it,
*  it's more diffusion based.
*  So.
*  Essentially, when you're able to park it next to it,
*  you can listen in on those individual chatter
*  and those local changes in the potential.
*  And the type of signal that you get are these canonical textbook
*  neural spiking waveform.
*  When you're the moment you're further away from the source,
*  the moment you're further away and based on some of the studies
*  that people have done, you know, Christophe Koch's lab and others,
*  once you're away from that source by roughly around 100 micron,
*  which is about a width of a human hair, you no longer hear from that neuron.
*  You're no longer able to kind of have the system sensitive enough
*  to be able to record that particular
*  local membrane potential change in that neuron.
*  And just to kind of give you a sense of scale, also,
*  when you when you look at 100 micron voxels,
*  so 100 micron by 100 micron by 100 micron vox in a brain tissue,
*  there's roughly around 40 neurons
*  and whatever number of connections that they have.
*  So there's a lot in that volume of tissue.
*  So the moment you're outside of that, there's just no hope
*  that you'll be able to detect that change from that one specific neuron
*  that you may care about.
*  Yeah, but as you're moving about this space,
*  you'll be hearing other ones.
*  So if you move another 100 micron,
*  you'll be hearing chatter from another community.
*  Correct.
*  And so the whole sense is you want to place as many as possible electrodes
*  and you're listening to the chatter.
*  Yeah, you want to listen to the chatter.
*  And at the end of the day, you also want to basically let the software
*  do the do the job of decoding.
*  And just to kind of go to, you know,
*  why ECog and EEG work at all, right?
*  When you have these local changes, you know, obviously,
*  it's not just this one neuron that's activating.
*  There's many, many other networks that are activating all the time.
*  And you do see sort of a general change in the potential of this electro
*  like this charge medium.
*  And that's what you're recording when you're farther away.
*  I mean, you still have some reference electrode that's stable
*  and the brain that's just electroactive organ.
*  And you're seeing some combination aggregate action potential changes.
*  And then you can pick it up, right?
*  It's a much slower changing signals.
*  But, you know, there are these like canonical kind of oscillations
*  and waves like gamma waves, beta waves, like when you sleep,
*  that can be detected because there's sort of a synchronized
*  kind of global global effect of the brain that that you can detect.
*  And I mean, the physics of this go like, I mean,
*  if we really want to go down that rabbit hole, like there's a lot
*  that goes on in terms of like why diffusion physics at some point
*  dominates when you're further away from the source.
*  You know, it's just a charge medium.
*  So similar to how when you have electromagnetic waves
*  propagating in atmosphere or in a charge medium, like a plasma,
*  there's this weird shielding that happens that actually
*  further attenuates the signal.
*  As you move away from it.
*  So you see, like if you do a really, really deep dive on
*  kind of the signal attenuation over distance, you start to see
*  kind of one over R square in the beginning and then exponential drop off.
*  And that's the knee at which you go from electromagnetic
*  magnetism dominating to diffusion physics dominating.
*  But once again, with the electrodes, the the biophysics
*  that you need to understand is is
*  not as deep because no matter where you're placing that,
*  you're listening to a small crowd of local neurons.
*  Correct. Yeah. So once you penetrate the brain,
*  you know, you're in the arena, so to speak.
*  And there's a lot of neurons.
*  There are many, many of them.
*  But then again, there's like there's a whole field of neuroscience
*  that's studying like how the different groupings,
*  the different sections of the seating in the arena,
*  what they usually are responsible for, which is where the metaphor
*  probably falls apart because the the seating is not as deep.
*  Also, most of them are silent.
*  They don't really do much, you know, or or they their activities are,
*  you know, you have to hit it with just the right set of stimulus.
*  So they're usually quiet.
*  They're usually very quiet, quiet.
*  There's I mean, similar to dark energy and dark matter.
*  There's dark neurons.
*  What are they all doing when you place these electrode again?
*  Like within this 100 micron volume, you have 40 or so neurons.
*  Like, why are you why do you need to do that?
*  You have 40 or so neurons like why?
*  Why do you not see 40 neurons?
*  Why do you see only a handful?
*  What is happening there?
*  Well, they're mostly quiet, but like when they speak, they say profound shit,
*  I think that's the way I'd like to think about it.
*  Anyway, before we zoom in even more, let's zoom out.
*  So how does Neuralink work from?
*  The surgery to the implant,
*  to the signal and the decoding process,
*  and the human being able to use the implant
*  to actually affect the world outside.
*  And all of this, I'm asking in the context of there's a gigantic
*  historic milestone that Neuralink just accomplished in January of this year,
*  putting in your link implant in the first human being, Nolan.
*  And there's been a lot to talk about there, about his experience,
*  because he's able to describe all the nuance and the beauty
*  and the fascinating complexity of that experience of everything involved.
*  But on the technical level, how does Neuralink work?
*  Yeah, so there are three major components to the technology that we're building.
*  One is the device, the thing that's actually recording these neural chatters.
*  We call it N1 implant or the link.
*  And we have a surgical robot that's actually doing an implantation
*  of these tiny, tiny wires that we call threads that are smaller than human hair.
*  And once everything is surgery, you have these neural signals,
*  these spiking neurons that are coming out of the brain.
*  And you need to have some sort of software to decode
*  what the users intend to do with that.
*  So there's what's called the Neuralink application or B1 app
*  that's doing that translation, is running the very, very simple machine
*  learning model that decodes these inputs that are neural signals
*  and then converted to a set of outputs that allows
*  our first participant, Nolan, to be able to control a cursor.
*  And this is done wirelessly.
*  And this is done wirelessly.
*  So our implant is actually a two part.
*  The link has these flexible, tiny wires called threads
*  that have multiple electrodes along its length.
*  And they're only inserted into the cortical layer,
*  which is about three to five millimeters in a human human brain
*  in the motor cortex region.
*  That's where the kind of the intention for movement lies in.
*  And we have 64 of these threads, each thread having 16 electrodes
*  along the span of three to four millimeters separated by 200 microns.
*  So you can actually record along the depth of the insertion.
*  And based on that signal, there's custom
*  integrated circuit or ASIC that we built that amplifies
*  the neural signals that you're recording and then digitizing it.
*  And then has some mechanism for detecting whether there was
*  an interesting event that is a spiking event
*  and decide to send that or not send that through Bluetooth
*  to an external device, whether it's a phone or a computer
*  that's running this neural link application.
*  So there's on board signal processing already just to decide
*  whether this is an interesting event or not.
*  So there is some computational power on board inside the
*  in addition to the human brain.
*  Yeah, so it does the signal processing to kind of really compress
*  the amount of signal that you're recording.
*  So we have a total of 1000 electrodes sampling at
*  just under 20 kilohertz with 10 bit each.
*  So that's 200 megabits that's coming through to the chip
*  from 1000 channel simultaneous neural recording.
*  And that's quite a bit of data.
*  And there are technology available to send that off wirelessly,
*  but being able to do that in a very, very thermally constrained
*  environment that is a brain.
*  So there has to be some amount of compression that happens
*  to send off only the interesting data that you need,
*  which in this particular case for motor decoding is
*  occurrence of a spike or not.
*  And then being able to use that to
*  to decode the intended cursor movement.
*  So the implant itself processes it, figures out whether a spike
*  happened or not with our spike detection algorithm,
*  and then sends it off, packages it, send it off through Bluetooth
*  to an external device that then has the model to decode.
*  OK, based on the spiking inputs,
*  did Nolan wish to go up, down, left, right, or click or right click
*  or whatever? All of this is really fascinating.
*  But let's stick on the N1 implant itself.
*  So the thing that's in the brain.
*  So I'm looking at a picture of it. There's an enclosure.
*  There's a charging call.
*  So we didn't talk about the charging, which is fascinating.
*  The battery, the power electronics, the antenna.
*  Then there's the signal processing electronics.
*  I wonder if there's more kinds of signal processing you can do.
*  That's that's another that's another question.
*  And then there's the threads themselves
*  with the enclosure on the bottom.
*  So maybe to ask about the charging.
*  There's an external charging device.
*  Yeah, there's an external charging device.
*  So, yeah, the second part of the implant, the threads are the ones, again,
*  just the the last three to five millimeters are the ones that are
*  actually penetrating the cortex.
*  Rest of it is actually most of the volume is occupied by the battery.
*  Rechargeable battery.
*  And it's about a size of a quarter.
*  I actually have a device here if you want to take a look at it.
*  This is the flexible thread component of it.
*  And this is the implant.
*  So it's about a size of a US quarter.
*  It's about nine millimeter thick.
*  So basically, this implant, you know, once you have the craniac to me
*  and the direct to me,
*  threads are inserted and
*  the hole that you created, this craniac to me gets replaced with that.
*  So basically that thing plugs that hole and you can screw in
*  these self drilling cranial screws to hold it in place.
*  And at the end of the day, once you have the skin flap over,
*  there's only about two to three millimeters that's, you know,
*  obviously transitioning off of the top of the implant to where the screws are.
*  And that's the minor bump that you have.
*  Those threads look tiny.
*  That's incredible.
*  That is really incredible.
*  That is really incredible.
*  And also, as you're right, most of the volume, actual volume is the battery.
*  Yeah, this is way smaller than I realized.
*  They are also the threads themselves are quite strong.
*  They look strong.
*  And the thread themselves also has a very interesting
*  feature at the end of it called the loop.
*  And that's the mechanism to which the robot is able to interface
*  and manipulate this tiny hair like structure.
*  And they're tiny. So what's the width of a thread?
*  Yeah. So the the width of a thread starts from 16 micron
*  and then tapers out to about 84 micron.
*  So, you know, average human hair is about 80 to 100 micron in width.
*  This thing is amazing.
*  This thing is amazing.
*  Yes, most of the volume is occupied by the by the battery rechargeable
*  lithium ion cell.
*  And the charging is done through inductive charging,
*  which is actually very commonly used, you know, your cell phone.
*  Most cell phones have that.
*  The biggest difference is that, you know, for us.
*  You know, usually when you have a phone and you want to charge it on the charging
*  pad, you don't really care how hot it gets.
*  Whereas for us, it matters.
*  There is a very strict regulation and good reasons to not actually
*  increase the surrounding tissue temperature by two degrees Celsius.
*  So there's actually a lot of innovation that is packed into this
*  to allow charging of this implant
*  without causing that temperature threshold to reach.
*  And even small things like you see this charging coil
*  and what's called a ferrite shield. Right.
*  So without that ferrite shield,
*  what you end up having when you have, you know, resonant inductive
*  charging is that the battery itself is a metallic can
*  and you form these eddy currents from the external charger.
*  And that causes heating and that actually contributes
*  to inefficiency in charging.
*  So this ferrite shield, what it does is that it actually
*  concentrate that field line away from the battery
*  and then around the coil that's actually wrapped around it.
*  There's a lot of really fascinating design here to to make it.
*  I mean, you're integrating a computer into a biological,
*  a complex biological system. Yeah, there's a lot of innovation here.
*  I would say that part of what enabled this was
*  just the innovations in the wearable.
*  There's a lot of really, really powerful, tiny, low power
*  microcontrollers, temperature sensors or various different sensors
*  and power electronics.
*  A lot of innovation really came in the charging coil design,
*  how this is packaged and how do you enable charging such that you don't really
*  exceed that temperature limit, which is not a constraint for other devices out there.
*  So let's talk about the threads themselves, those tiny, tiny, tiny things.
*  So how many of them are there?
*  You mentioned a thousand electrodes.
*  How many threads are there and what do the electrodes have to do with the threads?
*  Yeah, so the current instantiation of the device has 64 threads
*  and each thread has 16 electrodes
*  for a total of 1024 electrodes that are capable of both recording and stimulating.
*  And the thread is basically this
*  polymer insulated wire.
*  The metal conductor is the kind of a tiramisu cake of
*  Thai gold plattai.
*  And they're very, very tiny wires,
*  two micron in width, so two one millionth of a meter.
*  It's crazy that that thing I'm looking at has the polymer installation,
*  has the conducting material and has 16 electrodes at the end of it.
*  On each of those threads?
*  Yeah, on each of those threads. Correct.
*  16. Each one of those.
*  You're not going to be able to see it with naked eyes.
*  And I mean, to state the obvious, or maybe for people who are just listening,
*  they're flexible.
*  Yes, yes. That's also one element that was incredibly important for us.
*  So each of these threads are, as I mentioned, 16 micron in width
*  and then they taper to 84 micron, but in thickness, they're less than five micron.
*  And in thickness is mostly, you know, polyimide at the bottom
*  and this metal track and then another polyimide.
*  So two micron of polyimide,
*  400 nanometer of this metal stack and two micron of polyimide sandwiched together
*  to protect it from the environment that is
*  37 degrees C bag of saltwater.
*  So what's some maybe can you speak to some interesting aspects of the material
*  design here, like what does it take to to design a thing like this
*  and to be able to manufacture a thing like this
*  for people who don't know anything about this kind of thing?
*  Yeah, so the material selection that we have is not I don't think
*  it was particularly unique.
*  There were other labs and there are other labs that are kind of looking at similar
*  material stack.
*  There's kind of a fundamental question
*  and still needs to be answered around the longevity and reliability of these
*  microelectros that we call compared to some of the other more conventional
*  neural interfaces, devices that are intra cranial.
*  So penetrating the cortex that are more rigid, you know, like the Utah ray
*  that are these four by four millimeter kind of silicon shank that have
*  exposed recording site at the end of it.
*  And that's that's been kind of the innovation from Richard Norman back in 1997.
*  It's called the Utah Ray because he was at University of Utah.
*  And what is the Utah Ray look like?
*  So it's a rigid type of.
*  Yeah, so we can actually look it up.
*  Yeah.
*  Yeah, so it's a bit of needle.
*  There's OK.
*  Yeah, I'm sorry. Those are rigid, rigid, rigid.
*  Yeah, you want to get it.
*  And the size and the number of shanks vary anywhere from 64 to 128.
*  At the very tip of it is an exposed electrode that actually records neural
*  signal. The other thing that's interesting to note is that unlike neural
*  link threads that have recording electrodes that are actually exposed,
*  iridium oxide recording sites along the depth.
*  This is only at a single depth.
*  So these Utah Ray spokes can be anywhere between point five millimeters to one point
*  five millimeter. And they also have designs that are slanted.
*  So you can have it inserted at different depth.
*  But that's one of the other big differences.
*  And then I mean, the main key difference is the fact that there's no active
*  electronics. These are just electrodes.
*  And then there's a bundle of a wire that you're seeing.
*  And then that actually then exits the craniotomy.
*  That then has this port that you can connect to for any external electronic
*  devices. They are working on or have the wireless telemetry device,
*  but it still requires a through the skin
*  port that actually is one of the biggest failure modes for infection for the system.
*  What are some of the challenges associated with flexible threads?
*  Like, for example, on the robotic side, R1 implanting those threads.
*  How difficult is that task?
*  Yeah. So as you mentioned, they're very, very difficult to maneuver by hand.
*  These these Utah arrays that you saw earlier,
*  they're actually inserted by a neurosurgeon actually positioning it near the site
*  that they want. And then.
*  They're actually there's a pneumatic hammer that actually pushes them in.
*  So so it's a it's a pretty simple process
*  and they're easy to maneuver.
*  But for for these thin foam arrays, they're they're very, very tiny and flexible.
*  So they're very difficult to maneuver.
*  So that's why we built an entire robot to do that.
*  There are other other reasons for why we built the robot.
*  And that is ultimately we want this to help millions and millions of people
*  that can benefit from this.
*  And there just aren't that many neurosurgeons out there.
*  And, you know, robots can be something that,
*  you know, we hope can actually do large parts of the surgery.
*  But the robot is this entire other
*  sort of category of product that we're working on.
*  And it's essentially this.
*  Multi axis gantry system that has the specialized robot
*  head that has all of the optics and
*  it's this this kind of a needle retracting mechanism that maneuvers these these threads
*  via this loop structure that you have on the thread.
*  So the thread already has a loop structure by which you can grab it.
*  Correct. Correct. So this is that saying.
*  So you mentioned optics. So there's a robot.
*  R1. So for now, there's a human that actually creates a hole in the skull.
*  And then after that, there's a computer vision component
*  that's finding a way to avoid the blood vessels.
*  And then you're grabbing it by the loop, each individual thread
*  and placing it in a particular location to avoid the blood vessels
*  and also choosing the depth of placement, all that.
*  So controlling every like the 3D geometry of the placement. Correct.
*  So the aspect of this robot that is unique is that it's not surgeon assisted
*  or human assisted. It's a semi automatic or automatic robot.
*  Once you know, obviously, there are human component to it when you're placing targets.
*  You can always move it away from kind of major vessels that you see.
*  But I mean, we want to get to a point where one click
*  and it just does the surgery within minutes.
*  So the computer vision component finds great targets, candidates,
*  and the human kind of approves them.
*  And the robot does do like one thread at a time or does it do it?
*  It does one thread at a time.
*  And that's actually also one thing that we
*  are looking at ways to do multiple threads at a time.
*  There's nothing stopping from it.
*  You can have multiple kind of engagement mechanisms.
*  But right now, it's one by one.
*  And we also still do quite a bit of just just kind of verification
*  to make sure that it got inserted.
*  If so, how deep did it actually match what was programmed in?
*  And so on and so forth.
*  And the actual electrodes are placed at differing depths in the
*  I mean, it's very small differences, but differences.
*  Yeah. Yeah. And so that there's some reasoning behind that, as you mentioned,
*  like it gets more varied signal.
*  Yeah, we I mean, we try to place them all around three or four
*  millimeter from the surface just because the span of the electrode,
*  those 16 electrodes that we currently have in this version, spans
*  roughly around three millimeters.
*  So we want to get all of those in the brain.
*  This is fascinating. OK, so there's a million questions here.
*  If we zoom in specifically on the electrodes, what is your sense?
*  How many neurons is each individual electrode listening to?
*  Yeah, each electrode can record from anywhere between zero to 40.
*  As I mentioned earlier, but practically speaking,
*  we only see about at most like two to three.
*  And you can actually distinguish which neuron
*  it's coming from by the shape of the spikes.
*  So I mentioned the spike detection algorithm that we have.
*  It's called BOSS algorithm.
*  Buffer online spike sorter. Nice.
*  It actually outputs at the end of the day six unique values, which are
*  kind of the amplitude of these like negative going hump,
*  middle hump, like a positive going hump.
*  And then also the time at which these happen.
*  And from that, you can have a kind of a statistical
*  probable probability estimation of is that a spike?
*  Is it not a spike? And then based on that, you can also determine,
*  oh, that spike looks different than that spike must come from a different neuron.
*  OK, so that that's a nice signal processing step from which you can then
*  make much better predictions about if there's a spike, especially in this kind
*  of context where there could be multiple neurons screaming.
*  And that that also results in you being able to compress the data better.
*  Yeah. OK.
*  And just to be clear, I mean, the the labs do this, what's called spike sorting.
*  Usually once you have these like broadband, you know,
*  like the fully digitized signals and then you run
*  a bunch of different set of algorithms to kind of tease apart.
*  It's just all of this for us is done on the device, on the device,
*  in a very low power, custom, you know, built ASIC
*  digital processing unit, highly heat constrained, highly heat constrained.
*  And the processing time from signal going in and giving you the output
*  is less than a microsecond, which is, you know, a very, very short amount of time.
*  Oh, yeah. So the latency has to be super short. Correct.
*  Oh, wow. Oh, that's a pain in the ass.
*  Latency is this huge, huge thing that you have to deal with right now.
*  The biggest source of latency comes from the Bluetooth,
*  the way in which they're packetized and, you know, we bend them in 15 millisecond.
*  Oh, interesting. So communication constraint.
*  Is there some potential innovation there on the protocol used? Absolutely.
*  OK. Yeah. Bluetooth is definitely not our final.
*  Wireless communication protocol that we want to get to it's a high.
*  Hence the N1 and the R1.
*  I imagine that increases and X and XRX.
*  Yeah, that's, you know, the communication protocol because Bluetooth
*  allows you to communicate against farther distances than you need to.
*  So you can go much shorter.
*  Yeah, the only the primary motivation for choosing Bluetooth is that.
*  I mean, everything has Bluetooth.
*  All right. So you can talk to any device.
*  Interoperability is just absolutely essential, especially in this early phase.
*  And in many ways, if you can access a phone or a computer, you can do anything.
*  Well, it'd be interesting to step back and actually look at,
*  again, the same pipeline that you mentioned for Nolan.
*  So what does this whole process look like
*  from finding and selecting a human being
*  to the surgery, to the first time he's able to use this thing?
*  So we have what's called a patient registry
*  that people can sign up to hear more about the updates.
*  And that was a route to which Nolan applied.
*  And the process is that once the application comes in,
*  you know, it contains some medical records.
*  And we. You know, based on their medical eligibility,
*  that there's a lot of different inclusion and exclusion criteria for them to meet.
*  And we go through a pre-screening interview process with someone from Neuralink.
*  And at some point, we also go out to their homes to do a BCI home audit,
*  because one of the most kind of revolutionary part about,
*  you know, having this in one system that is completely wireless
*  is that you can use it at home.
*  Like, you don't actually have to go to the lab
*  and go to the clinic to get connecterized to these
*  like specialized equipment that you can't take home with you.
*  So that's one of the key elements of, you know, when we're designing the system
*  that we wanted to keep in mind, like, you know, people, you know,
*  hopefully would want to be able to use this every day in the comfort of their home.
*  And so part of our engagement
*  and what we're looking for during BCI home audit is to just kind of understand
*  their situation, what other assistive technology that they use.
*  And we should also step back and kind of say that the estimate is
*  180,000 people live with quadriplegia in the United States,
*  and each year an additional 18,000 suffer a paralyzing spinal cord injury.
*  So these are folks who have a lot of challenges
*  living a life in terms of accessibility,
*  in terms of doing the things that many of us just take for granted day to day.
*  And one of the things, one of the goals of this initial study
*  is to enable them to have sort of digital autonomy
*  where they by themselves can interact with a digital device
*  using just their mind, something that you're calling telepathy.
*  So digital telepathy, where a quadriplegic can communicate
*  with a digital device in all the ways that we've been talking about.
*  Control the mouse cursor
*  enough to be able to do all kinds of stuff,
*  including play games and tweet and all that kind of stuff.
*  And there's there's a lot of people for whom life, the basics of life are difficult
*  because of the things that have happened to them.
*  So, yeah, I mean, movement is so so fundamental to our existence.
*  I mean, even even speaking involves movement of mouth, lip, larynx.
*  And without that, it's it's it's extremely debilitating.
*  And there are there are there are many, many people that we can help.
*  And I mean, especially if you start to kind of look at other forms of movement
*  disorders that are not just from spinal cord injury, but from, you know, ALS,
*  MS, or even stroke that that leads you and or just just aging, right?
*  That leads you to lose some of that mobility, that independence.
*  It's extremely debilitating.
*  And all of these are opportunities to help people to help alleviate suffering,
*  to help improve the quality of life.
*  But each of the things you mentioned is its own little puzzle
*  that needs to have increasing levels of capability from a device
*  like a neural link device.
*  And so the first one you're you're focusing on is
*  it's just the beautiful word telepathy.
*  So being able to communicate using your mind wirelessly with a digital device.
*  Can you just explain this exactly what we're talking about?
*  Yeah, I mean, it's exactly that.
*  I mean, I think if you are able to control a cursor
*  and able to click and be able to get access to computer or phone,
*  I mean, the whole world opens up to you.
*  And I mean, I guess the word telepathy, if you kind of think about
*  that as, you know, just definitionally being able to transfer information
*  from my brain to your brain
*  without using some of the physical faculties that we have,
*  you know, like voices.
*  But the interesting thing here is I think the thing that's not obviously clear
*  is how exactly it works.
*  So in order to move a cursor,
*  there's at least a couple of ways of doing that.
*  So one is you imagine yourself
*  maybe moving a mouse with your hand
*  or you can then, which no one talked about,
*  like imagine moving the cursor with your mind.
*  Like, I don't.
*  But it's like there is a cognitive step here that's fascinating
*  because you have to use the brain and you have to learn how to use the brain.
*  And you kind of have to figure it out dynamically, like
*  because you reward yourself if it works.
*  So you like, I mean, there's a step that this is just a fascinating step
*  because you have to get the brain to start firing in the right way.
*  Yeah. And you do that by imagining,
*  like, fake it till you make it.
*  And all of a sudden, it creates the right kind of signal that if decoded correctly,
*  can create the kind of effect.
*  And then there's like noise around that.
*  You have to figure all of that out.
*  You have to figure all of that out.
*  But on the human side, imagine the cursor moving is what you have to do.
*  Yeah. He says using the force of force.
*  I mean, that's isn't that just like fascinating to you that it works?
*  Like to me is like, holy shit, that actually works.
*  Like you could move a cursor with your mind in as much as you're
*  learning to use that thing, that thing's also learning about you.
*  Like our our models constantly updating the weights to
*  say, oh, if if someone is thinking about,
*  you know, this sophisticated forms of like spiking patterns,
*  like that actually means to do this. Right.
*  So the machine is learning about the human and the human is learning about the machine.
*  So there is a adaptability to the signal process and the decoding step.
*  And then there's the adaptation of knowing the human being
*  like the same way if if you give me a new mouse and I move it,
*  I learn very quickly about its sensitivity.
*  So I'll learn to move it slower.
*  And then there's other kind of signal drift and all that kind of stuff
*  they have to adapt to.
*  So both are adapting to each other. Correct.
*  That's a fascinating like software challenge on both sides,
*  the software on both on the human software and the organic and the inorganic
*  organic and inorganic.
*  Anyway, so sorry to rudely interrupt.
*  So there is a selection that Nolan has passed with flying colors.
*  So everything, including that it's a BCI friendly home, all of that.
*  So what is the process of the surgery implantation in the first moment
*  when he gets to use the system?
*  The end to end, you know, we say patient in to patient out is anywhere between
*  two to four hours.
*  In particular case for Nolan, it was about three and a half hours.
*  And there's many steps leading to, you know, the actual robot insertion.
*  So there's anesthesia induction and we do intraop CT imaging
*  to make sure that we're, you know, drilling the hole in the right location.
*  And this is also pre-planned beforehand.
*  Someone goes through someone like Nolan would go through fMRI
*  and then they can think about wiggling their hand.
*  You know, obviously due to their injury, it's not going to actually lead to
*  any any sort of intended output.
*  But it's the same part of the brain that actually lights up when you're
*  imagining moving your finger to actually moving your finger.
*  And that's one of the ways in which we can actually know where to place our
*  threads, because we want to go into what's called the hand knob area
*  in the motor cortex and, you know, as much as possible, densely put our
*  electrode threads.
*  So, yeah, we do intraop CT imaging to make sure and double check the
*  location of the craniotomy and the surgeon comes in, does their thing in
*  terms of like skin incision, craniotomy, so drilling of the skull.
*  And then there's many different layers of the brain.
*  There's what's called the dura, which is a very, very thick layer that
*  surrounds the brain that gets actually resected in a process called
*  direct to me.
*  And that then exposed the PIA and the brain that you want to insert.
*  And by the time it's been around anywhere between one to one and a half
*  hours, robot comes in, does this thing placement of the targets, inserting
*  of the thread that takes anywhere between 20 to 40 minutes in the
*  particular case for Nolan was just under or just over 30 minutes.
*  And then after that, the surgeon comes in, there's a couple other steps of
*  like actually inserting the dual substitute player to protect the
*  thread as well as the brain.
*  And then, yeah, screw screw in the implant.
*  Yeah, screw screw in the implant and then skin flap and then suture.
*  And then you're out.
*  So when Nolan woke up, was that like, was the recovery like and what was
*  the first time he was able to use it?
*  So he was actually immediately after the surgery, you know, like an hour
*  after the surgery as he was waking up.
*  We did turn on the device, make sure that we are recording neural signals.
*  And we actually did have a couple signals that we noticed that he can
*  actually modulate.
*  And what I mean by modulate is that he can think about crunching his fist
*  and you could see the spike disappear and appear.
*  And that's awesome.
*  And that was immediate, right?
*  Immediate after and in the recovery room.
*  How cool is that?
*  That's a human being.
*  I mean, what does that feel like for you?
*  This device and a human being, a first step of a gigantic journey.
*  I mean, it's a historic moment, even just that spike, just to be
*  able to modulate that.
*  Obviously there have been other, as you mentioned, pioneers that have
*  participated in these groundbreaking BCI, you know, the
*  early feasibility studies.
*  So we're obviously standing on the shoulders of the giants here.
*  You know, we're not the first ones to actually put electrodes in a human
*  human brain.
*  But I mean, just leading up to the surgery, there was I definitely could
*  not sleep.
*  There's just it's the first time that you're working in a completely new
*  environment.
*  We had a lot of, you know, we had a lot of, you know, we had a lot of
*  confidence based on our benchtop testing or preclinical R&D studies that
*  the mechanism, the threads, the insertion, all that stuff is very safe and
*  that it's obviously ready for doing this in a human.
*  But there's still a lot of unknown, unknown about can the needle actually
*  insert?
*  I mean, we brought something like a, you know, a, a, a, a, a, a, a, a, a, a,
*  a, a, a, a, a needle.
*  And then we had to use something like 40 needles just in case they break.
*  And we ended up using only one.
*  But I mean, that, that was a level of just complete unknown, right?
*  Cause it's just very, very different environment.
*  And I mean, that's, that's why we do clinical trial in the first place to be
*  able to test these things out.
*  So extreme nervousness and just, just many, many sleepless night leading up to
*  the surgery and definitely the day before the surgery.
*  I mean, it was 7 in the morning.
*  And by the time it was around 10 30, it was, it was, it was, everything was done.
*  But I mean, first time seeing that, well, number one, just, just huge relief that
*  this thing is, you know, doing what it's supposed to do.
*  And two, I mean, just immense amount of gratitude for, for Nolan and his family.
*  And then many others that have applied and that we've spoken to and will speak
*  to are true pioneers in every, everywhere.
*  And, you know, I sort of call them the neural astronauts or neural not, you
*  know, these amazing, just like in the sixties, right?
*  Like these amazing, just pioneers, right?
*  Um, exploring the unknown outwards in this case is inward.
*  Um, but an incredible amount of gratitude for them to, uh, you know, just, just
*  participate and, and play a part.
*  Um, and, and it's a, it's a journey that we're embarking on together.
*  Um, but also like, I think it was just, uh, that was a very, very important
*  milestone, but our work was just starting.
*  So a lot of just kind of, uh, anticipation for, okay, what's, what needs to happen
*  next, what are set of sequences of events that needs to happen for us to, you know,
*  make it worthwhile for, um, uh, you know, both Nolan as well as us.
*  Just to linger on that, just a huge congratulations to you and the
*  team for that milestone.
*  I know there's a lot of work, uh, left, but that, that is, that's really exciting
*  to see there's, um, that's a source of hope.
*  It's, uh, this first big step opportunity to help hundreds of thousands of people.
*  And then maybe, uh, expand the realm of the possible for the human being.
*  Of the possible for the human mind, for millions of people in the future.
*  So it's, it's really exciting.
*  So like the, the opportunities are all ahead of us and to do that safely and to
*  do that effectively was, uh, it was really fun to see as an engineer, just watching
*  other engineers come together and do an Epic thing.
*  That was awesome.
*  So huge congrats.
*  Thank you.
*  Thank you.
*  It's, um, yeah, could not have done it without the team.
*  And, um, yeah, I mean, that, that's the other thing that I, I, um, you know, told
*  team as well, of just this immense sense of optimism for the future.
*  Um, I mean, it was, uh, it's a very important moment for, for the company.
*  Um, you know, needless to say, as well as, um, you know, hopefully for many
*  others out there that we can help.
*  So speaking of challenges, Neuralink published a blog post describing that
*  some of the threads are attracted.
*  And so the performance as measured by bits per second dropped at first, but
*  then eventually it was regained and that the whole story of how it was
*  regained is super interesting.
*  That's definitely something I'll talk to, uh, to bliss and to know and about.
*  Um, but in general, um, can you speak to this whole experience?
*  How was the performance regained and, um, just the technical aspects of, uh,
*  the threads being attracted and moving.
*  The main takeaway is that in the end, the performance have come back and
*  it's actually gotten better than it was before.
*  Um, he's actually just beat the world record yet again, last week, um, to 8.5
*  BPS, so, I mean, he's, he's just cranking and he's just improving the previous one
*  was that he said was eight and correct.
*  He said eight point five.
*  Yeah.
*  The previous world record, uh, in human was 4.6.
*  So it's, uh, almost double.
*  And his goal is to try to get to 10, which is roughly around kind of the
*  median neural linker, uh, using a, you know, mouse with the hand.
*  So it's, um, it's getting there.
*  So, yeah.
*  So the, the performance was regained.
*  Yeah.
*  Better than before.
*  So that, that's, you know, uh, a story on its own of what took the BCI
*  team to recover that performance.
*  It was, it was actually mostly on kind of the signal processing.
*  And so, you know, as I mentioned, we were, um, kind of looking at these spike
*  outputs from the, um, our electrodes.
*  And what happened is that kind of a four weeks into the surgery, uh, we noticed
*  that the threats have slowly come out of the brain and the way in which we noticed
*  this at first, obviously is that, uh, well, I think Nolan was the first to notice
*  that his performance was degrading.
*  Um, and I think at the time we were also trying to do a bunch of different
*  experimentation, um, you know, different algorithms, different, um, sort of UI UX.
*  So it was expected that there will be variability in the performance.
*  Um, but we did see kind of a steady decline.
*  And then also the way in which we measure the health of the electrodes or whether
*  they're in the brain or not is by measuring, uh, impedance of the electrode.
*  So, uh, we look at kind of the interfacial, um, kind of the, the, the
*  Randall circuit, let they say, um, you know, the capacitance and the, and the, um,
*  the resistance between the electro surface and the medium.
*  And if that changes in some traumatic ways, we have some indication, or if
*  you're not seeing spikes on those channels, you have some indications that
*  something's happening there.
*  And what we noticed is that looking at those impedance plot and spike rate
*  plots, and also because we have those electrodes recording along the depth,
*  you're seeing some sort of movement that indicated that the
*  reservoir being pulled out.
*  Um, and that obviously will have an implication on the model side, because
*  if you're the number of inputs that are going into the model is changing because
*  you have less of them, um, the, uh, that, that model needs to get updated.
*  Right.
*  And, um, but, but there were still signals.
*  And as I mentioned, similar to how, even when you place the signals on the surface
*  of the brain, of the brain or farther away, like outside the skull, you still
*  see some useful signals.
*  Um, what we started looking at is not just the spike occurrence through this
*  boss algorithm that I mentioned.
*  Um, but we started looking at just the, the, the power of the frequency band
*  that is, um, interesting for Nolan or Nolan to be able to modulate.
*  So once we kind of changed the algorithm for the implant to not just give you the
*  boss output, but also these, uh, spike band power output, um, that helped us
*  sort of redefine the model with the new set of inputs.
*  And that, that was the thing that really ultimately gave us the performance back.
*  Um, you know, in terms of, and obviously like the, the thing that we want
*  ultimately, and the thing that we are working towards is figuring out ways in
*  which we can keep those threads intact, um, for as long as possible so that we
*  have many more channels going into the model.
*  That's, that's by far the number one priority that the team is currently
*  embarking on to understand how to prevent that from happening.
*  Um, the thing that I will say also is that, you know, as I mentioned, this is
*  the first time ever that we're putting these threads in, in the human brain.
*  And, you know, human brain just for size reference is 10 times that of the
*  monkey brain or the sheep brain.
*  And it's, um, it's just a very, very different environment.
*  It moves a lot more.
*  It's like actually moved a lot more than we expected, um, when we, uh, did
*  Nolan's surgery and, um, it's, uh, just a very, very different environment
*  than what we're used to.
*  And this is why we do clinical trial, right?
*  We, we, we want to uncover some of these, uh, issues, uh, and, and failure
*  modes earlier than later.
*  So in many ways it's provided us with this enormous amount of data and, um,
*  information to be able to, uh, solve this.
*  And this is something that Neuralink is extremely good at once we have set of
*  clear objective and engineering problem.
*  We have enormous amount of talents across many, many disciplines to be able to come
*  together and fix the problem very, very quickly.
*  But it sounds like one of the fascinating challenges here is for the system and
*  the decoding side to be adaptable across different timescales.
*  So whether it's movement of threads or different aspects of signal drift, sort
*  of on the software, the human brain, something changing, like Nolan talks
*  about cursor drift, they could be corrected and there's a whole UX
*  challenge to how to do that.
*  So it sounds like adaptability is like a fundamental property
*  that has to be engineered in.
*  It is.
*  And, and I think, I mean, as a company, we're extremely vertically integrated.
*  Um, you know, we make these thin film arrays in our own, uh, micro fab.
*  Yeah, there's a, like you said, built in house, this whole paragraph here from
*  this blog post is pretty gangster.
*  Uh, building the technologies described above has been no small feat.
*  And there's a bunch of links here that I recommend people click on.
*  We constructed in-house microfabrication capabilities to rapidly produce various
*  considerations of thin film arrays that constitute our electrode threads.
*  We created a custom femto second laser mill to manufacture components
*  with micro level precision.
*  I think there's a tweet associated with this whole thing that we can get into.
*  Yeah, this, this, okay.
*  Well, what are we, what are we looking at here?
*  This thing, this is a, so in less than one minute, our custom made femto second
*  laser mill cuts this geometry in the tips of our needles.
*  So we're looking at this weirdly shaped needle.
*  The tip is only 10 to 12 microns and width only slightly larger than the
*  diameter of a red blood cell.
*  The small size allows threads to be inserted with minimal damage to the cortex.
*  Okay.
*  So what's interesting about this geometry.
*  So we'll look at this just geometry of a needle.
*  This is the needle that's engaging with the loops in the thread.
*  So they're the ones that, you know, thread the thread, the loop, and then peel it
*  from the silicon backing.
*  And then this is the thing that gets inserted into the tissue.
*  And then this pulls out leaving the thread and this kind of a notch or the shark
*  tooth that we used to call is the thing that actually is grasping the loop.
*  And then it's, it's designed in such way such that when you, when you
*  pull out, it leaves the loop.
*  And the robot is controlling this needle.
*  Correct.
*  So this is actually housed in a cannula and basically the robot is, has a lot of
*  the optics that look for where the loop is.
*  Um, there's actually a four or five nanometer light that actually causes the
*  polyimide to fluoresce so that you can locate the, the location of the loop.
*  Um, so the loop lights up.
*  Yeah, yeah, they do.
*  So it's a micron precision process.
*  What's interesting about the robot that it takes to do that.
*  That's, that's pretty crazy.
*  That's pretty crazy that robot is able to get this kind of precision.
*  Yeah.
*  Our robot is quite heavy.
*  Um, our current version of it, um, there's, I mean, it's like a giant granite
*  slab that weighs about a ton, um, cause it needs to be sensitive to vibration,
*  environmental vibration.
*  And then as the head is moving at the speed that is moving, you know, there's
*  a lot of kind of motion control to make sure that you can achieve that level of
*  precision.
*  Um, a lot of optics that kind of zoom in on that.
*  Um, you know, we're working on next generation of the robot that is lighter,
*  easier to transport.
*  I mean, it is a, it is a feat to move the robot.
*  And it is far superior to a human surgeon at this time for this particular task.
*  Absolutely.
*  I mean, let alone you try to actually thread a loop in a, in a sewing kit.
*  Uh, I mean, this is like, we're talking like fractions of human hair.
*  These, these things are, it's not visible.
*  So continuing the paragraph, we developed novel hardware and software testing
*  systems, such as our accelerated lifetime testing racks and simulated surgery
*  environment, which is pretty cool to stress test and validate the robustness
*  of our technologies.
*  We performed many rehearsals of our surgeries to refine our procedures and
*  make them, um, second nature.
*  This is pretty cool.
*  We practice surgeries on proxies with all the hardware and instruments needed
*  in our mock or in the engineering space.
*  This helps us rapidly test the measurement.
*  So there's like proxies.
*  Yeah, this proxy is super cool actually.
*  So there's a 3d printed skull from the images that is taken at Barrow, as well
*  as this, uh, hydrogel mix, you know, sort of synthetic polymer thing that actually
*  mimics the mechanical properties of the brain.
*  Um, it also has that's closer of the person.
*  Um, so basically what we're talking about here, and there's a lot of work that has
*  gone into making this set proxy that, um, you know, it's, it's about like finding
*  the right concentration of these different synthetic polymers to get the right set of
*  consistency for the needle dynamics, you know, as they're being inserted.
*  But we practice this surgery with the person, you know, Nolan's basically
*  physiology and brain, um, many, many times prior to actually doing the surgery.
*  So to every, every step, every step, every step.
*  Yeah.
*  Like where does someone stand?
*  Like, I mean, like what you're looking at is the picture.
*  This is in, in, in our office of this kind of corner of the robot engineering
*  space that we have created this like mock or space that looks exactly like what
*  they would experience, all the staff would experience during their actual surgery.
*  So, I mean, it's just kind of like any dance rehearsal where you know exactly
*  where you're going to stand at what point.
*  Um, and you just practice that over and over and over again with an exact
*  anatomy of someone that you're going to surgery.
*  And, and it got to a point where a lot of our engineers, when we created a
*  craniotomy, they're like, Oh, that looks very familiar.
*  We've seen that before.
*  Yeah.
*  And there's wisdom you can gain through doing the same thing over and over and
*  over and over and it's like, uh, do your dreams of sushi kind of thing.
*  Um, because then, um, it's like Olympic athletes visualize, uh, the Olympics.
*  And then once you actually show up, it feels easy.
*  It feels like any other day.
*  It feels almost boring winning the gold medal.
*  Cause you, you visualize this so many times you've practiced this so many
*  times and nothing about us in you.
*  It's boring.
*  You win the gold medal is boring.
*  And it does the experience they talk about is mostly just relief.
*  Probably that they don't have to visualize it anymore.
*  Yeah.
*  The power of the mind to visualize and where I mean, there's a whole field that
*  studies where muscle memory lies in Sarah Bell and yeah, it's incredible.
*  Uh, I think it was a good place to actually ask sort of the big question
*  that people might have is how do we know every aspect of this that you described
*  is safe at the end of the day, the goal standard is to look at the tissue.
*  Um, you know, what sort of trauma did you cause the tissue and does that
*  correlate to whatever behavioral anomalies that you may have seen?
*  Um, and that's the language to which, uh, we, we can communicate about the
*  safety of inserting something into the brain and what type of trauma that you
*  can cause.
*  So, um, we actually have an entire department, uh, department of pathology
*  that looks at these tissue slices.
*  There are many steps that are involved in, in doing this.
*  Once you have, um, you know, studies that are launched to, uh, with, with
*  particular endpoints in mind, you know, at some point you have to euthanize
*  the animal and then, uh, you go through a necropsy to kind of collect the
*  brain tissue samples.
*  Um, you know, you fix them in formalin and you like gross them, you section
*  them, and you look at individual slices just to see what kind of reaction or
*  lack thereof exists.
*  So that's the kind of the language to which FDA speaks and, you know, as
*  well for us to kind of evaluate the safety of the insertion mechanism, as
*  well as the threats, um, at various different time points, you know, both
*  acute, um, so anywhere between, you know, uh, zero to three months to beyond
*  three months.
*  So those are kind of the details of an extremely high standard of safety
*  that has to be reached.
*  Correct.
*  Um, FDA supervises this, but there's in general, just a very high standard
*  and every aspect of this, including the surgery, I think, um, Matthew McDougal
*  has mentioned that like the standard is, uh, let's say how to put it politely
*  higher than maybe some other operations that we take for granted.
*  So the, the, the standard for all the surgical stuff here is extremely high.
*  Very high.
*  I mean, it's a highly, highly regulated environment, um, with, you know, the
*  governing agencies that scrutinize every, every medical device that gets marketed.
*  And I think, I think it's a good thing.
*  Um, you know, it's good to have those high standards and we, we try to hold
*  extremely high standards, um, to kind of understand what sort of damage of any
*  these, uh, innovative emerging technologies and new technology that we're building
*  are, and, you know, so far I, I, we have been extremely impressed by lack of.
*  Immune response from these threads.
*  Speaking of which you, uh, you talk to me, uh, with excitement about the histology
*  and some of the images, uh, that you're able to share.
*  Uh, can you explain to me what we're looking at?
*  Yeah.
*  So what you're looking at is a stained tissue image.
*  Um, so this is a sectioned, uh, tissue slice from an animal that was implanted
*  for seven months, so kind of a chronic time point, and you're seeing all these
*  different colors and each color indicates specific types of cell types.
*  So purple and pink are astrocytes and microglia respectively.
*  They're types of, uh, glial cells.
*  And yeah, the other thing that, you know, people may not be aware of is your
*  brain is not just made up of soup of neurons and axons.
*  There are other, uh, you know, cells like, uh, glial cells that actually kind
*  of is the glue and also, uh, react, uh, if there are any trauma or damage to the tissue.
*  But the brown are the neurons.
*  The brown are the neurons.
*  So what you're seeing is in this kind of macro image, you're seeing these like
*  circle highlighted in white, the insertion sites.
*  And, uh, when you zoom into one of those, you see the threads.
*  And then in this particular case, I think we're seeing about the 16, uh, you
*  know, wires that are going into the page.
*  And the incredible thing here is the fact that you have the neurons that
*  are these brown structures or brown circular or elliptical thing that are
*  actually touching and abutting the threads.
*  So what this is saying is that there's basically zero trauma that's
*  caused during this insertion.
*  And with these neural interfaces, these, um, micro electrodes that you insert,
*  that is one of the most common mode of failure.
*  So when you insert these threads, like the Utah array, it causes a
*  neuronal death around the site because you're inserting a foreign object.
*  Right.
*  And that kind of elicit these like immune response through the
*  microglia and astrocytes.
*  They form this like protective layer around it.
*  Oh, not only are you killing the neuron cells, but you're also creating
*  this protective layer that then basically prevents you from recording neural
*  signals because you're getting further and further away from the neurons that
*  you're trying to record.
*  And that, that is the biggest mode of failure.
*  And in this particular example, in that inset, it's, you know, it's about 50
*  micron with that scale bar, the neurons are just, it seemed to be attracted to it.
*  And so there's certainly no trauma.
*  That's a huge problem.
*  Yeah.
*  That's such a beautiful image, by the way, just to, so the browner, the
*  neurons, for some reason, I can't look away.
*  It's really cool.
*  And the way that these things like, I mean, your tissues generally don't
*  have these beautiful colors.
*  This is a multiplex stain that uses these different proteins that are
*  staining these at different colors.
*  You know, we use very standard set of, you know, staining techniques with
*  HG, EBA1 and, you know, NUEN and GFAT.
*  So if you go to the next image, this is also kind of illustrates the second
*  point, because you can make an argument.
*  And initially when we saw the previous image, we said, oh, like, are the
*  threads just floating?
*  Like what is happening here?
*  Like, are we actually looking at the right thing?
*  So what we did is we did another stain and this is all done in house of this
*  Lassonde's trichrome stain, which is in blue that shows these collagen layers.
*  So the blue basically, like you don't want the blue around the implant threads,
*  because that means that there is some sort of scarring that's happened.
*  And what you're seeing, if you look at individual threads, is that you don't
*  see any of the blue, which means that there has been absolutely or very, very
*  minimal to a point where it's not detectable amount of trauma in these
*  inserted threads.
*  So that presumably is one of the big benefits of having this kind of
*  flexible thread.
*  Yeah.
*  So we think this is primarily due to the size as well as the flexibility of the
*  threads.
*  Also the fact that R1 is avoiding that's for sure.
*  So we're not disrupting or we're not causing damage to the vessels and not
*  breaking any of the blood brain barrier has, you know, basically caused the
*  immune response to be muted.
*  But this is also a nice illustration of the size of things.
*  So this is the tip of the thread.
*  Yeah.
*  Those are neurons.
*  They're there and they're neurons and this is the thread listening and the
*  electrodes are positioned how?
*  Yeah.
*  So this is what you're looking at is not electrode themselves.
*  Those are the conductive wires.
*  So each of those should probably be two micron in width.
*  So what we're looking at is we're looking at the coronal slice.
*  So we're looking at some slice of the tissue.
*  So as you go deeper, you know, you'll obviously have less and less of the
*  tapering of the thread.
*  But yeah, the point basically being that there's just kind of cells around the
*  incerticide, which is just an incredible thing to see.
*  I've just never seen anything like this.
*  How easy and safe is it to remove the implant?
*  Yeah.
*  So it depends on when in the first three months or so after the surgery,
*  there's a lot of kind of tissue modeling that's happening, you know, similar to
*  when you got a cut, you know, you obviously, you know, start over first
*  couple of weeks or depending on the size of the wound scar tissue forming, right?
*  There are these like contracted and then in the end they turn into scab and you
*  can scab it off.
*  The same thing happens in the brain and it's a very dynamic environment.
*  And before the scar tissue or the neo membrane or the new membrane that
*  forms, it's quite easy to just pull them out.
*  And there's minimal trauma that's caused during that.
*  Once the scar tissue forms and, you know, with Nolan as well, we believe that
*  that's the thing that's currently anchoring the threads.
*  So we haven't seen any more movements since then.
*  So they're quite stable.
*  It gets harder to actually completely extract the threads.
*  So our current method for removing the device is cutting the thread, leaving
*  the tissue intact and then unscrewing and taking the implant out.
*  And that hole is now going to be plugged with either another Neuralink or just
*  with, you know, kind of a peak based, you know, plastic based cap.
*  Is it okay to leave the threads in there forever?
*  Yeah, we think so.
*  We've done studies where, you know, we left them there.
*  And one of the biggest concerns that we had is like, do they migrate and do they
*  get to a point where they should not be?
*  We haven't seen that again.
*  Once the scar tissue forms, they get anchored in place.
*  And I should also say that, you know, when we say upgrades, like it's not, we're
*  not just talking in theory here, like we've actually upgraded many, many times.
*  Most of our monkeys or non-human primates, NHP have been upgraded.
*  You know, Pager, who you saw playing mind pong has the latest version of the device
*  since two years ago and is seemingly very happy and healthy and fat.
*  So what's designed for the future, the upgrade procedure?
*  So maybe for Nolan, what would the upgrade look like?
*  It was essentially what you're mentioning.
*  Is there a way to upgrade sort of the device internally?
*  Will you take it apart and sort of keep the capsule and upgrade the internals?
*  Yeah, so there are a couple of different things here.
*  So for Nolan, if we were to upgrade, what we would have to do is either cut the
*  threads or extract the threads depending on kind of, you know, the situation there
*  in terms of how they're anchored or scarred in.
*  If you were to remove them with the dural substitute, you know, you have an intact
*  brain, so you can reinsert different threads with the updated implant package.
*  There are a couple of different other ways that we're thinking about the future
*  of what the upgradeable system looks like.
*  One is, you know, at the moment we currently remove the dura, this kind of thick layer
*  that protects the brain.
*  But that actually is the thing that actually proliferates the scar tissue formation.
*  So typically, the general good rule of thumb is you want to leave the nature as is
*  and not disrupt it as much.
*  So we're looking at ways to insert the threads through the dura, which comes with
*  different set of challenges, such as, you know, it's a pretty thick layer.
*  So how do you actually penetrate that without breaking the needle?
*  So we're looking at different needle design for that, as well as the kind of the loop
*  engagement.
*  The other biggest challenges are it's quite opaque optically with white light
*  illumination.
*  So how do you avoid still this biggest advantage that we have of avoiding basketure?
*  How do you image through that?
*  How do you actually still mediate that?
*  So there are other imaging techniques that we're looking at to enable that.
*  But our hypothesis is that, and based on some of the early evidence that we have,
*  doing through the dura insertion will cause minimal scarring that causes them to be much
*  easier to extract over time.
*  And the other thing that we're also looking at, this is going to be a fundamental change
*  in the implant architecture, is at the moment, it's a monolithic single implant that comes
*  with a thread that's bonded together.
*  So you can't actually separate the thing out, but you can imagine having two-part implant.
*  The bottom part that is the thread that are inserted that has the chips and maybe a radio
*  and some power source.
*  And then you have another implant that has more of the computational heavy load and the
*  bigger battery.
*  And then one can be under the dura, one can be above the dura, being the plug for the skull.
*  They can talk to each other, but the thing that you want to upgrade, the computer and
*  not the threads, if you want to upgrade that, you just go in there, remove the screws, and
*  then put in the next version.
*  It's a very, very easy surgery, too.
*  You do a skin incision, slip this in, screw, probably be able to do this in 10 minutes.
*  So that would allow you to reuse the threads, sort of?
*  Correct.
*  So this leads to the natural question of what is the pathway to scaling the increase in the
*  number of threads?
*  Is that a priority?
*  What's the technical challenge there?
*  Yeah, that is a priority.
*  So for next versions of the implant, the key metrics that we're looking to improve are
*  number of channels, just recording from more and more neurons.
*  We have a pathway to actually go from currently 1,000 to hopefully 3,000, if not 6,000 by
*  end of this year.
*  And then end of next year, we want to get to even more, 16,000.
*  Wow.
*  There's a couple of limitations to that.
*  One is, obviously, being able to photolithographically print those wires.
*  As I mentioned, it's two micron in width and spacing.
*  Obviously, there are chips that are much more advanced than those types of resolution, and we
*  have some of the tools that we have brought in-house to be able to do that.
*  So traces will be narrower, just so that you have to have more of the wires coming into the chip.
*  Chips also cannot linearly consume more energy as you have more and more channels.
*  So there's a lot of innovations in the circuit, architecture, as well as the circuit design
*  topology to make them lower power.
*  You need to also think about, if you have all of these spikes, how do you send that off to the end
*  application?
*  So you need to think about bandwidth limitation there and potentially innovations in signal
*  processing.
*  Physically, one of the biggest challenges is going to be the interface.
*  It's always the interface that breaks.
*  Bonding the Stimphilm array to the electronics, it starts to become very, very highly dense
*  interconnects.
*  So how do you connectorize that?
*  There's a lot of innovations in the 3D integrations in the recent years that we can take advantage
*  of.
*  One of the biggest challenges is the fact that we have a lot of different types of
*  one of the biggest challenges that we do have is forming this hermetic barrier.
*  This is an extremely harsh environment that we're in, the brain.
*  So how do you protect it from the brain trying to kill your electronics to also your electronics
*  leaking things that you don't want into the brain?
*  And forming that hermetic barrier is going to be a very, very big challenge that we are,
*  I think, are actually well suited to tackle.
*  How do you test that?
*  Like what's the development environment to simulate that kind of harshness?
*  Yeah, so this is where the Accelerated Life Tester essentially is a brain in a vat.
*  It literally is a vessel that is made up of, and again, for all intents and purpose for
*  this particular types of test, your brain is saltwater.
*  And you can also put some other set of chemicals like reactive oxygen species
*  get at these interfaces and try to cause a reaction to pull it apart.
*  But you could also increase the rate at which these interfaces are aging by just increasing
*  temperature. So every 10 degrees Celsius that you increase, you're basically accelerating time by 2x.
*  And there's limit as to how much temperature you want to increase because at some point there's
*  some other nonlinear dynamics that causes you to have other nasty gases to form that just is not
*  realistic in an environment. So what we do is we increase in our ALT chamber by 20 degrees Celsius
*  that increases the aging by four times. So essentially one day in ALT chamber is four
*  days in calendar year. And we look at whether the implants still are intact, including the threads.
*  And operation and all that.
*  Obviously it's not an exact same environment as a brain because brain has mechanical,
*  other more biological groups that attack at it. But it is a good testing environment for at least
*  the enclosure and the strength of the enclosure. And we've had implants, the current version
*  of the implant that has been in there for close to two and a half years, which is equivalent to
*  a decade and they seem to be fine. So it's interesting that the brain, so basically
*  a close approximation is warm salt water, hot salt water is a good testing environment.
*  Yeah. By the way, I'm drinking element, which is basically salt water, which is making me kind of,
*  it doesn't have computational power the way the brain does, but maybe in terms of
*  the characteristics is quite similar. And I'm consuming it.
*  Yeah. You have to get it in the right pH too.
*  And then consciousness will emerge.
*  By the way, the other thing that also is interesting about our enclosure is
*  if you look at our implant, it's not your common looking medical implant that usually is
*  encased in a titanium can that's laser welded. We use this polymer called PCTFE, polychlorotrifluoroethylene,
*  which is actually commonly used in blister packs. So when you have a pill and you're trying to pop
*  the pill, there's like kind of that plastic membrane. That's what this is. No one's actually
*  ever used this except us. And the reason we wanted to do this is because it's
*  electromagnetically transparent. So when we talked about the electromagnetic inductive charging
*  with titanium can, usually if you want to do something like that, you have to have a
*  sapphire window and it's a very, very tough process to scale. So you're doing a lot of iteration here
*  in every aspect of this, the materials, the software, the whole shebang. So, okay. So you
*  mentioned scaling. Is it possible to have multiple neural link devices as one of the
*  ways of scaling to have multiple neural link devices implanted? That's the goal. That's the
*  goal. Yeah. We've had, I mean, our monkeys have had two neural links, one in each hemisphere.
*  And then we're also looking at potential of having one in
*  the motor cortex, one in visual cortex, and one in whatever other cortex. So focusing on
*  a particular function, one neural link device. I wonder if there's some level of customization
*  that can be done on the compute side. So for the motor cortex. Absolutely. That's the goal. And
*  we talk about at Neural Link building a generalized neural interface to the brain.
*  And that also is strategically how we're approaching this with marketing and also
*  with regulatory, which is, hey, look, we have the robot and the robot can access any part of the
*  cortex. Right now we're focused on motor cortex with current version of the N1 that's specialized
*  for motor decoding tasks. But also at the end of the day, there's kind of a general compute available
*  there. But typically if you want to really get down to kind of hyper optimizing for power
*  and efficiency, you do need to get to some specialized function. But what we're saying is
*  that, hey, you are now used to this robotic insertion techniques, which took many, many years
*  of showing data and conversation with the FDA. And also internally convincing ourselves that this is
*  safe. And now the difference is if we go to other parts of the brain, like visual cortex, which
*  we're interested in as our second product, obviously it's a completely different environment. The
*  cortex is laid out very, very differently. It's going to be more stimulation focused rather than
*  recording, just kind of creating visual percepts. But in the end, we're using the same thin film
*  array technology. We're using the same robot insertion technology. We're using the same
*  packaging technology. Now it's more the conversation is focused around what are the differences
*  and what are the implications of those differences in safety and efficacy.
*  The way you said second product is both hilarious and awesome to me. That product being
*  restoring sight for blind people. So can you speak to stimulating the visual cortex? I mean,
*  there's the possibilities there are just incredible to be able to give that gift back to people who
*  don't have sight or even any aspect of that. Can you just speak to the challenges of, there's several
*  challenges here. One of which is, like you said, from recording,
*  to stimulation. Just any aspect of that that you're both excited and see the challenges of.
*  Yeah, I guess I'll start by saying that we actually have been
*  capable of stimulating through our thin film array as well as other electronics for years.
*  We have actually demonstrated some of that capabilities for
*  reanimating the limb in the spinal cord. Obviously for the current EFS study,
*  we've hardware disabled that. So that's something that we wanted to embark as a separate journey.
*  Obviously there are many, many different ways to write information into the brain. The way in which
*  we're doing that is through passing electrical current and causing that to really change the
*  local environment so that you can artificially cause the neurons to depolarize in nearby areas.
*  For vision specifically, the way our visual system works, it's both well understood. I mean,
*  anything with brain, there are aspects of it that's well understood, but in the end,
*  we don't really know anything. But the way visual system works is that you have photon hitting your
*  eye and in your eyes, there are these specialized cells called photoreceptor cells
*  that convert the photon energy into electrical signals. And then that then gets projected to
*  back of your head, your visual cortex. It goes through actually a thalamic system called LGN
*  that then projects it out. And then in the visual cortex, there's visual area one or V1,
*  and then there's a bunch of other higher level processing layers like V2, V3. And there are
*  actually interesting parallels. And when you study the behaviors of these convolutional neural networks,
*  like what the different layers of the network is detecting, first they're detecting these edges,
*  and they're then detecting some more natural curves, and then they start to detect objects.
*  Similar thing happens in the brain, and a lot of that has been inspired and also it's been exciting
*  to see some of the correlations there. But things like from there, where does cognition arise and
*  where is color encoded? There's just not a lot of fundamental understanding there.
*  So in terms of bringing sight back to those that are blind, there are many different forms of
*  blindness. There's actually 1 million people in the US that are legally blind. That means
*  certain score below in the visual test. I think it's something like, if you can see something
*  at 20 feet distance that normal people can see at 200 feet distance, if you're worse than that,
*  you're legally blind. So fundamentally that means you can't function effectively using sight in the
*  world. Yeah, like to navigate your environment. And yeah, there are different forms of blindness.
*  There are forms of blindness where there's some degeneration of your retina, these photoreceptor
*  cells, and the rest of your visual processing that I described is intact. And for those
*  types of individuals, you may not need to maybe stick electrodes into the visual cortex. You can
*  actually build retinal prosthetic devices that actually just replaces a function of that retinal
*  cells that are degenerated. And there are many companies that are working on that. But that's
*  a very small slice. I'll be significant, still smaller slice of folks that are legally blind.
*  If there's any damage along that circuitry, whether it's in the optic nerve or just the
*  LGN circuitry or any break in that circuit, that's not going to work for you. And the source of where
*  you need to actually cause that visual percept to happen, because your biological mechanism is not
*  doing that, is by placing electrodes in the visual cortex in the back of your head. And the way in
*  which this would work is that you would have an external camera, whether it's something as
*  unsophisticated as a GoPro or some sort of wearable Ray-Ban type glasses that Mehta's working on,
*  that captures a scene. And that scene is then converted to a set of electrical impulses or
*  stimulation pulses that you would activate in your visual cortex through the brain.
*  These thin film arrays. And by playing some concerted orchestra of these stimulation
*  patterns, you can create what's called phosphines, which are these white, yellowish dots that you
*  can also create by just pressing your eyes. You can actually create those percepts by stimulating
*  the visual cortex. And the name of the game is really have many of those and have those
*  percepts be, the phosphines be as small as possible so that you can start to tell apart,
*  like they're the individual pixels of the screen. So if you have many, many of those,
*  potentially you'll be able to, in the long term, be able to actually get naturalistic vision.
*  But in the short term to maybe midterm, being able to at least be able to have object detection
*  algorithms run on your glasses, the pre-pop processing units, and then being able to at
*  least see the edges of things so you don't bump into stuff. This is incredible. This is really
*  incredible. So you basically would be adding pixels and your brain would start to figure out
*  what those pixels mean. Yeah. And like with different kinds of assistant under signal
*  processing on all fronts. Yeah. The thing that actually, so a couple things, one is,
*  obviously if you're blind from birth, the way brain works, especially in the early age,
*  neuroplasticity is really nothing other than kind of your brain and different parts of your brain
*  fighting for the limited territory. And I mean, very, very quickly you see cases where
*  people that are, I mean, you also hear about people who are blind that have heightened
*  sense of hearing or some other senses. And the reason for that is because that
*  cortex that's not used just gets taken over by these different parts of the cortex. So
*  for those types of individuals, I mean, I guess they're going to have to now map some other parts
*  of their senses into what they call vision, but it's going to be obviously a very, very different
*  conscious experience before. So I think that's an interesting caveat. The other thing that also
*  is important to highlight is that we're currently limited by our biology in terms of the wavelength
*  that we can see. There's a very, very small wavelength that is a visible light wavelength
*  that we can see with our eyes. But when you have an external camera with this BCI system,
*  you're not limited to that. You can have infrared, you can have UV, you can have whatever other
*  spectrum that you want to see. And whether that gets mapped to some sort of weird conscious
*  experience, I have no idea. But oftentimes I talk to people about the goal of Neuralink
*  going beyond the limits of our biology. That's sort of what I mean. And if you're able to control
*  the kind of raw signal, is that when we use our sight, we're getting the photons and there's not
*  much processing on it. If you're being able to control that signal, maybe you can do some kind
*  of processing. Maybe you do object detection ahead of time. You're doing some kind of pre-processing
*  and there's a lot of possibilities to explore that. So it's not just increasing sort of thermal
*  imaging, that kind of stuff, but it's also just doing some kind of interesting processing.
*  Yeah. I mean, my theory of how visual system works also is that, I mean, there's just so
*  many things happening in the world and there's a lot of photons that are going into your eye.
*  And it's unclear exactly where some of the pre-processing steps are happening. But I
*  actually think that just from a fundamental perspective, there's just so much, the reality
*  that we're in, if it's a reality, is so there's so much data. And I think humans are just unable to
*  actually eat enough actually to process all that information. So there's some sort of filtering
*  that does happen, whether that happens in the retina, whether that happens in different layers
*  of the visual cortex, unclear. But the analogy that I sometimes think about is if your brain is
*  a CCD camera and all of the information in the world is a sun, and when you try to actually look
*  at the sun with the CCD camera, it's just going to saturate the sensors, right? Because it's an
*  enormous amount of energy. So what you do is you end up adding these filters, right? To just kind
*  of narrow the information that's coming to you and being captured. And I think things like our
*  experiences or our drugs, like prophylfol, that like anesthetic drug or psychedelics, what they're
*  doing is they're kind of swapping out these filters and putting in new ones or removing
*  older ones and kind of controlling our conscious experience. Yeah, man, not to distract from the
*  topic, but I just took a very high dose of ayahuasca in the Amazon jungle. So yes,
*  it's a nice way to think about it. You're swapping out different experiences. And with Neuralink
*  being able to control that, primarily at first to improve function, not for entertainment purposes
*  or enjoyment purposes, but yeah, giving back lost functions, giving back lost functions. And there,
*  that's the special one. When the function is completely lost, anything is a huge help.
*  Would you implant a Neuralink device in your own brain? Absolutely. I mean, maybe not right now,
*  but absolutely. What kind of capability once reached, you start getting real curious
*  and almost get a little antsy, like jealous of people that get, as you watch them getting planted.
*  Yeah, I mean, I think, I mean, even with our early participants, if they start
*  to do things that I can't do, which I think is in the realm of possibility for them to be able to get,
*  you know, 15, 20, if not like a hundred BPS, right? There's nothing that fundamentally stops us from
*  being able to achieve that type of performance. I mean, I would certainly get jealous that they
*  can do that. I should say that watching Nolan, I get a little jealous because he's having so much
*  fun and it seems like such a chill way to play video games. Yeah. I mean, the thing that also is
*  hard to appreciate sometimes is that, you know, he's doing these things while talking and,
*  I mean, it's multitasking, right? So it's clearly, it's obviously cognitively intensive,
*  but similar to how, you know, when we talk, we move our hands, like these things, like, you know,
*  are multitasking. I mean, he's able to do that. And, you know, you won't be able to do that with
*  other assistive technology, as far as I'm aware. You know, if you're obviously using like an eye
*  tracking device, you know, you're very much fixated on that thing that you're trying to do. And if
*  you're using voice control, I mean, like if you say some other stuff, yeah, you don't get to use
*  that. Yeah. The multitasking aspect of that is really interesting. So it's not just the BPS
*  for the primary task. It's the parallelization of multiple tasks. If you measure the BPS
*  for the entirety of the human organism. So if you're talking and doing a thing with your mind
*  and looking around also, I mean, there's just a lot of parallelization that can be happening.
*  But I mean, I think at some point for him, like if he wants to really achieve those high level
*  BPS, it does require like, you know, full attention, right? And that's a separate circuitry that
*  is a big mystery, like how attention works and, you know. Yeah. Attention, like cognitive load,
*  I've done, I've read a lot of literature on people doing two tasks. Like you have your primary task
*  and a secondary task and the secondary task is a source of distraction. And how does that affect
*  the performance of the primary task? And there's depending on the task, there's a lot of interesting,
*  I mean, this is an interesting computational device, right? And I think there's to say the least,
*  a lot of novel insights that can be gained from everything. I mean, I personally am surprised that
*  Nolan is able to do such incredible control of the cursor while talking and also being nervous at
*  the same time, because he's talking like all of us are, if you're talking in front of the camera,
*  you get nervous. So all of those are coming into play and he's able to still achieve high performance.
*  Surprising. I mean, all of this is really amazing. And I think just after researching this
*  really in depth, I kind of wanted your link. Get in line. And also the safety kit in mind. Well,
*  we should say the registry is for people who have quadriplegia and all that kind of stuff. So
*  there'll be a separate line for people. They're just curious, like myself. So now that Nolan,
*  patient P1 is part of the ongoing prime study, what's the high level vision for P2, P3, P4, P5,
*  and just the expansion into other human beings that are getting to experience this implant?
*  Yeah. I mean, the primary goal is for our study in the first place is to achieve safety endpoints,
*  just understand safety of this device as well as the implantation process. And also at the same time,
*  understand the efficacy and the impact that it could have on the potential user's lives. And
*  just because you're living with tetraplegia, it doesn't mean your situation is same as another
*  person living with tetraplegia. It's wildly, wildly varying. And it's something that we're
*  hoping to also understand how our technology can serve not just a very small slice of those
*  individuals, but broader group of individuals and being able to get the feedback to just really
*  build just the best product for them. There's obviously also goals that we have, and the primary
*  purpose of the early feasibility study is to learn from each and every participant to improve the
*  device, improve the surgery before we embark on what's called a pivotal study that then is
*  a much larger trial that starts to look at statistical significance of your endpoints.
*  And that's required before you can then market the device. And that's how it works in the US and
*  just generally around the world. That's the process you follow. So our goal is to really
*  just understand from people like Nolan, P2, P3, future participants, what aspects of the device
*  needs to improve. If it turns out that people are like, I really don't like the fact that it
*  lasts only six hours. I want to be able to use this computer for like 24 hours. That is a user
*  needs and user requirements, which we can only find out from just being able to engage with them.
*  So before the pivotal study, there's kind of like a rapid innovation based on individual
*  experiences you're learning from. So what's the difference between the early feasibility study
*  and the rapid innovation based on individual experiences you're learning from individual
*  people how they use it, like the high resolution details in terms of like cursor control and signal
*  and all that kind of stuff to like life experience. Yeah, so there's hardware changes, but also just
*  firmware updates. So even when we had that sort of recovery event for Nolan, he now has the new
*  firmware that he has been updated with. And similar to how your phones get updated all the
*  time with new firmwares for security patches, whatever new functionality, UI, right? And that's
*  something that is possible with our implant. It's not a static one-time device that can only do the
*  thing that it said it can do. I mean, similar to Tesla, you can do over the air firmware updates,
*  and now you have completely new user interface and all this bells and whistles and improvements
*  everything like the latest, right? That's when we say generalized platform, that's what we're
*  talking about. Yeah, it's really cool how the app that Nolan is using, there's like calibration,
*  all that kind of stuff, and then there's update. You just click and get an update.
*  What other future capabilities are you kind of looking to? You said vision, that's a fascinating
*  one. What about sort of accelerated typing or speech, this kind of stuff?
*  And what else is there? Those are still in the realm of movement program. So largely speaking,
*  we have two programs. We have the movement program and we have the vision program. The movement
*  program currently is focused around the digital freedom. As you can easily guess, if you can't
*  control 2D cursor in the digital space, you could move anything in the physical space.
*  Robotic arms, wheelchair, your environment, or even really like whether it's through the phone
*  or just directly to those interfaces, so like to those machines. We're looking at ways to kind
*  of expand those types of capability even for Nolan. That requires conversation with the FDA and kind
*  of showing safety data for if there's a robotic arm or wheelchair that we can guarantee that
*  they're not going to hurt themselves accidentally. It's very different if you're moving stuff in the
*  digital domain versus like in the physical space, you can actually potentially cause harm to the
*  participants. So we're working through that right now. Speech does involve different areas of the
*  brain. Speech prosthetic is very, very fascinating and there's actually been a lot of really
*  amazing work that's been happening in academia. You know, Sergey Stavisky at UC Davis, Jamie
*  Henderson, and late Krishna Shonoi at Stanford are doing just some incredible amount of work in
*  improving speech neuroprosthetics. And those are actually looking more at parts of the motor cortex
*  that are controlling these focal articulators and being able to like even by mouthing the word or
*  imagine speech, you can pick up those signals. The more sophisticated higher level processing areas
*  like the Broca's area or Warnocky's area, those are still very, very big mystery in terms of the
*  underlying mechanism of how all that stuff works. But yeah, I mean, I think neurolink's eventual goal
*  is to kind of understand those things and be able to provide a platform and tools to be able to
*  understand that and study that. This is where I get to the pothead questions. Do you think we can
*  start getting insight into things like thought? So speech is, there's a muscular component, like
*  you said, there's like the act of producing sounds. But then what about the internal things like
*  cognition? Like low level thoughts and high level thoughts. Do you think we'll start noticing
*  kind of signals that could be picked up? They could, they could be understood, they could be
*  maybe used in order to interact with the outside world. In some ways, like I guess this starts to
*  kind of get into the heart problem of consciousness. And I mean, on one hand, all of these are at some
*  point, set of electrical signals that from there, maybe it in itself is giving you the cognition or
*  the meaning or somehow human mind is incredibly amazing storytelling machine. So we're telling
*  ourselves and fooling ourselves that there's some interesting meaning here. But I certainly think
*  that PCI, and really PCI at the end of the day is a set of tools that help you kind of study the
*  underlying mechanisms in both local but also broader sense. And whether there's some interesting
*  patterns of electrical signal that means you're thinking this versus, and you can either learn
*  from many, many sets of data to correlate some of that and be able to do mind reading or not,
*  I'm not sure. I certainly would not kind of blow that out as a possibility. But
*  I think BCI alone probably can't do that. There's probably additional set of tools and framework.
*  And also like just heart problem of consciousness at the end of the day is rooted in this
*  philosophical question of like, what is the meaning of it all? What's the nature of our existence?
*  Like, where's the mind emerged from this complex network? Like,
*  Yeah, how does the subjective experience emerge from just a bunch of spikes, electrical spikes?
*  Yeah, I mean, we do really think about BCI and what we're building as a tool for understanding
*  the mind, the brain, the only question that matters. There's actually, there actually is
*  some biological existence proof of like what it would take to kind of start to form some of these
*  experiences that may be unique. If you actually look at every one of our brains, there are two
*  hemispheres, there's a left-sided brain, there's a right-sided brain. And I mean, unless you have
*  some other conditions, you normally don't feel like left legs or right legs. And so
*  you just feel like one legs, right? So what is happening there? Right? If you actually look at
*  the two hemispheres, there's a structure that kind of connect the rise the two called the corpus
*  colossum that is supposed to have around 200 to 300 million connections or axons.
*  So whether that means that's the number of interface and electrodes that we need to create
*  some sort of mind meld or from that, like whatever new conscious experience that you
*  you can experience. But I do think that there's like kind of an interesting
*  existence proof that we all have. And that threshold is unknown at this time.
*  Oh, yeah, these things, everything in this domain is, you know, speculation, right? And then there
*  will be you'd be continuously pleasantly surprised. Do you see a world where there's
*  millions of people, like 10s of millions, hundreds of millions of people walking
*  around with a neural link device, or multiple neural link devices in their brain?
*  I do. First of all, there are, like if you look at worldwide, people suffering from movement
*  disorders and visual tephesis, I mean, that's in the 10s, if not hundreds of millions of people.
*  So that alone, I think there's a lot of benefit and potential good that we can do with this type
*  of technology. And when you start to get into kind of neuro like psychiatric application,
*  you know, depression, anxiety, hunger, or, you know, obesity, right, like mood control of appetite.
*  I mean, that starts to become, you know, very real to everyone. Not to mention that every
*  most people on earth have a smartphone. And once BCI starts competing with a smartphone
*  as a preferred methodology of interacting with the digital world, that also becomes an interesting
*  thing. Oh, yeah. I mean, that, yeah, this is even before going to that, right? I mean, there's like
*  almost, I mean, the entire world that could benefit from these types of thing. And then,
*  yeah, like if we're talking about kind of next generation of how we interface with,
*  you know, machines, or even ourselves, in many ways, I think BCI can play a role in that.
*  And, you know, some of the things that I also talk about is I do think that there is a real
*  possibility that you could see, you know, eight billion people walking around with Neuralink.
*  Well, thank you so much for pushing ahead. And I look forward to that exciting future.
*  Thanks for having me. Thanks for listening to this conversation with DJ SA. And now, dear friends,
*  here's Matthew McDougall, the head neurosurgeon at Neuralink. When did you first become fascinated
*  with the human brain? Since forever. As far back as I can remember, I've been interested in the
*  human brain. I mean, I was, you know, a thoughtful kid and a bit of an outsider. And you, you know,
*  sit there thinking about what the most important things in the world are
*  in your little tiny adolescent brain. And the answer that I came to, that I converged on, was
*  that all of the things you can possibly conceive of as things that are important for human beings
*  to care about are literally contained, you know, in the skull, both the perception of them and their
*  relative values and, you know, the solutions to all our problems and all of our problems
*  are all contained in the skull. And if we knew more about how that worked,
*  how the brain encodes information and generates desires and generates agony and suffering,
*  we could do more about it. You know, you think about all the really great triumphs in human
*  history. You think about all the really horrific tragedies. You know, you think about the Holocaust.
*  You think about any prison full of human stories and all of those problems boil down to
*  neurochemistry. So if you get a little bit of control over that, you provide people the option
*  to do better. And in the way I read history, the way people have dealt with having better tools is
*  that they most often in the end do better with huge asterisks. But I think it's an interesting,
*  worthy and noble pursuit to give people more options, more tools.
*  CB Yeah, that's a fascinating way to look at human history. You just imagine all these
*  neurobiological mechanisms, Stalin, Hitler, all of these, Genghis Khan, all of them just had like a
*  brain. It's just a bunch of neurons, you know, like a few tons of billions of neurons
*  gaining a bunch of information over a period of time. They have a set of modules that does
*  language and memory and all that. And from there, in the case of those people, they're able to murder
*  millions of people. And all that coming from, there's not some glorified notion of a dictator,
*  of this enormous mind or something like this. It's just the brain.
*  AC Yeah. Yeah. I mean, a lot of that has to do with
*  how well people like that can organize those around them.
*  CB Other brains.
*  AC Yeah. And so I always find it interesting to look to primatology, you know, look to our closest
*  non-human relatives for clues as to how humans are going to behave and what particular humans
*  are able to achieve. And so you look at chimpanzees and bonobos and, you know, they're
*  similar but different in their social structures, particularly. And I went to Emory in Atlanta and
*  studied under the great Franz De Waal, who was kind of the leading primatologist who recently died.
*  And his work in looking at chimps through the lens of, you know, how you would watch an episode
*  of Friends and understand the motivations of the characters interacting with each other, he would
*  look at a chimp colony and basically apply that lens. I'm massively oversimplifying it.
*  If you do that, instead of just saying, you know, subject 473, you know, through his feces,
*  it's subject 471. You talk about them in terms of their human struggles, accord them the dignity of
*  themselves as actors with understandable goals and drives, what they want out of life. And
*  primarily it's, you know, the things we want out of life, food, sex, companionship, power.
*  You can understand chimp and bonobo behavior in the same lights much more easily. And I think
*  doing so gives you the tools you need to reduce human behavior from the kind of false complexity
*  that we layer onto it with language and look at it in terms of, oh, well, these humans are looking
*  for companionship, sex, food, power. And I think that's a pretty powerful tool to have in
*  understanding human behavior. And I just went to the Amazon jungle for a few weeks and it's a very
*  visceral reminder that a lot of life on earth is just trying to get laid. They're all screaming
*  at each other. Like I saw a lot of monkeys and they're just trying to impress each other. Or
*  maybe if there's a battle for power, but a lot of the battle for power has to do with them getting
*  laid. Right. Breeding rights often go with alpha status. And so if you can get a piece of that,
*  then you're going to do okay. And we'd like to think that we're somehow fundamentally different,
*  but especially when it comes to primates, we can use fancier poetic language, but maybe some of
*  the underlying drives that motivate us are similar. Yeah, I think that's true. And all
*  of that is coming from this, the brain. Yeah. So when did you first start studying the brain
*  as a biological mechanism? Basically, the moment I got to college, I started looking around for
*  labs that I could do neuroscience work in. I originally approached that from the angle of
*  looking at interactions between the brain and the immune system, which isn't the most obvious
*  place to start. But I had this idea at the time that the contents of your thoughts would have an
*  impact, a direct impact, maybe a powerful one on non-conscious systems in your body, the systems
*  we think of as homeostatic automatic mechanisms like fighting off a virus, like repairing a wound.
*  And sure enough, there are big crossovers between the two. I mean, it gets to a key point
*  that I think goes under recognized. One of the things people don't recognize or appreciate about
*  the human brain enough, and that is that it basically controls or has a huge role in almost
*  everything that your body does. You try to name an example of something in your body that
*  isn't directly controlled or massively influenced by the brain, and it's pretty hard. I mean,
*  you might say like bone healing or something, but even those systems, the hypothalamus and
*  pituitary end up playing a role in coordinating the endocrine system that does have a direct
*  influence on say the calcium level in your blood that goes to bone healing. So non-obvious connections
*  between those things implicate the brain as really a potent prime mover in all of health.
*  One of the things I realized in the other direction too, how most of the systems in the
*  body are integrated with the human brain, like they affect the brain also, like the immune system.
*  I think there's just people who study Alzheimer's and those kinds of things. It's just surprising
*  how much you can understand that from the immune system, from the other systems that don't obviously
*  seem to have anything to do with the nervous system. They all play together.
*  Yeah. You could understand how that would be driven by evolution too, just in some simple examples.
*  If you get sick, if you get a communicable disease, you get the flu,
*  it's pretty advantageous for your immune system to tell your brain, hey, now be antisocial for
*  a few days. Don't go be the life of the party tonight. In fact, maybe just cuddle up somewhere
*  warm under a blanket and just stay there for a day or two. Sure enough, that tends to be the
*  behavior that you see both in animals and in humans. If you get sick, elevated levels of
*  interleukins in your blood and TNF-alpha in your blood ask the brain to cut back on social activity
*  and even moving around. You have lower locomotor activity in animals that are infected with viruses.
*  From there, the early days in neuroscience to surgery, when did that step happen?
*  Yeah. It was a leap. It was an evolution of thought. I wanted to study the brain. I started
*  studying the brain in undergrad in this neuroimmunology lab. From there, I realized
*  at some point that I didn't want to just generate knowledge. I wanted to affect real changes in the
*  actual world, in actual people's lives. After having not really thought about going into medical
*  school, I was on a track to go into a PhD program. I said, well, I'd like that option. I'd like to
*  actually potentially help tangible people in front of me. Doing a little digging found that there
*  exists these MD-PhD programs where you can choose not to choose between them and do both. I went to
*  USC for medical school and had a joint PhD program with Caltech where I actually chose that
*  program, particularly because of a researcher at Caltech named Richard Anderson, who's one of the
*  godfathers of primate neuroscience. It has a macaque lab where Utah rays and other electrodes
*  were being inserted into the brains of monkeys to try to understand how intentions were being
*  encoded in the brain. I ended up there with the idea that maybe I would be a neurologist and study
*  the brain on the side and then discovered that neurology, again, I'm going to make enemies by
*  saying this, but neurology predominantly and distressingly to me is the practice of
*  diagnosing a thing and then saying, good luck with that when there's not much we can do.
*  Neurosurgery very differently, it's a powerful lever on taking people that are headed in a bad
*  direction and changing their course in the sense of brain tumors that are potentially treatable
*  or curable with surgery. Even aneurysms in the brain, blood vessels that are going to rupture,
*  you can save lives really is at the end of the day what mattered to me.
*  I was at USC, as I mentioned, that happens to be one of the great neurosurgery programs. I met
*  these truly epic neurosurgeons, Alex Kolesi and Micah Puzo and Steve Gianotta and Marty Weiss,
*  these epic people that were just human beings in front of me. It changed my thinking from
*  neurosurgeons are distant gods that live on another planet and occasionally come and visit us
*  to these are humans that have problems and are people and there's nothing fundamentally preventing
*  me from being one of them. At the last minute in medical school, I changed gears from going into
*  a different specialty and switched into neurosurgery, which cost me a year. I had to do another
*  year of research because I was so far along in the process. To switch into neurosurgery,
*  the deadlines had already passed. It was a decision that cost time, but absolutely worth it.
*  What was the hardest part of the training on the neurosurgeon track?
*  Yeah, two things. I think residency in neurosurgery is a competition of pain,
*  of how much pain can you eat and smile. There's work hour restrictions that are not really,
*  they're viewed internally among the residents as weakness. Most neurosurgery residents
*  try to work as hard as they can. That necessarily means working long hours and sometimes over the
*  work hour limits. We care about being compliant with whatever regulations are in front of us,
*  but I think more important than that, people want to give their all in becoming a better
*  neurosurgeon because the stakes are so high. It's a real fight to get residents
*  to say go home at the end of their shift and not stay and do more surgery.
*  Are you seriously saying one of the hardest things is literally forcing them to get sleep
*  and rest and all this kind of stuff? Historically, that was the case. I think
*  that the next generation is more compliant and more self-care.
*  Weaker is what you mean. All right, I'm just kidding. I'm just kidding.
*  I didn't say it. Now I'm making enemies.
*  I'm just kidding. I'm just kidding.
*  So what was the second thing? The personalities, and maybe the two
*  are connected. Was it pretty competitive? It's competitive and it's also,
*  as we touched on earlier, primates like power. I think neurosurgery has long had this aura of
*  mystique and excellence and whatever about it. So it's an invitation, I think, for people that
*  are cloaked in that authority. A board certified neurosurgeon is basically a walking, fallacious
*  appeal to authority. You have license to walk into any room and act like you're an expert on whatever.
*  Fighting that tendency is not something that most neurosurgeons do well. Humility isn't the forte.
*  One of the... I have friends who know you and whenever they speak about you,
*  yours have the surprising quality for a neurosurgeon of humility,
*  which I think indicates that it's not as common as perhaps in other professions.
*  Because there is a gigantic, heroic aspect to neurosurgery and I think it gets to people's
*  head a little bit. Yeah. Well, I think that allows me to play well at an Elon company
*  because Elon, one of his strengths, I think, is to just instantly see through fallacy from authority.
*  So nobody walks into a room that he's in and says, well, god damn it, you have to trust me.
*  I'm the guy that built the last 10 rockets or something. And he says, well, you did it wrong.
*  And we can do it better. Or I'm the guy that kept Ford alive for the last 50 years. You listen to
*  me on how to build cars. And he says, no. And so you don't walk into a room that he's in and say,
*  well, I'm a neurosurgeon. Let me tell you how to do it. He's going to say, well,
*  I'm a human being that has a brain. I can think from first principles myself. Thank you very much.
*  And here's how I think it ought to be done. Let's go try it and see who's right.
*  And that's proven, I think, over and over in his case to be a very powerful approach.
*  If we just take that tangent, there's a fascinating interdisciplinary team at Neuralink
*  that you get to interact with, including Elon. What do you think is the secret to a successful team?
*  What have you learned from just getting to observe these folks,
*  world experts in different disciplines work together?
*  AC Yeah, there's a sweet spot where people
*  disagree and forcefully speak their mind and passionately defend their position,
*  and yet are still able to accept information from others and change their ideas when they're wrong.
*  And so I like the analogy of how you polish rocks. You put hard things in a hard container
*  and spin it. People bash against each other and out comes a more refined product. And so
*  to make a good team at Neuralink, we've tried to find people that are not afraid to defend
*  their ideas passionately and occasionally strongly disagree with people that they're
*  that they're working with and have the best idea come out on top.
*  It's not an easy balance, again, to refer back to the primate brain. It's not something that is
*  inherently built into the primate brain to say, I passionately put all my chips on this position,
*  and now I'm just going to walk away from it and admit you were right. Part of our brains
*  tell us that that is a power loss. That is a loss of faith, loss of standing in the community,
*  and now you're a Zeta chump because your idea got trounced.
*  And you just have to recognize that that little voice in the back of your head is maladaptive,
*  and it's not helping the team win. AC Yeah, you have to have the confidence to be able to
*  walk away from an idea that you hold on to. And if you do that often enough,
*  you're actually going to become the best in the world at your thing.
*  I mean, that kind of that rapid iteration. Yeah, you'll at least be a member of a winning team.
*  Ride the wave. What did you learn? You mentioned there's a lot of amazing neurosurgeons at USC.
*  What lessons about surgery and life have you learned from those folks?
*  AC Yeah, I think working your ass off, working hard while functioning as a member of a team,
*  getting a job done that is incredibly difficult, working incredibly long hours, being up all night,
*  taking care of someone that you think probably won't survive no matter what you do,
*  to working hard to make people that you passionately dislike look good the next morning.
*  These folks were relentless in their pursuit of excellent neurosurgical technique
*  decade over decade, and I think we're well recognized for that excellence.
*  Especially Marty Weiss, Steve Giannotta, Mike Capuzzo, they made huge contributions not only to
*  surgical technique, but they built training programs that trained dozens or hundreds of
*  amazing neurosurgeons. I was just lucky to kind of be in their wake.
*  AC What's that like you mentioned, doing a surgery where the person is likely not to survive?
*  Does that wear on you? AC Yeah.
*  AC Yeah. It's especially challenging when you, with all respect to our elders,
*  it doesn't hit so much when you're taking care of an 80-year-old and something was going to get them
*  pretty soon anyway. And so you lose a patient like that, and it was part of the natural course of
*  what is expected of them in the coming years, regardless. Taking care of a father of two or
*  three, four young kids, someone in their 30s that didn't have it coming, and they show up in your
*  ER having their first seizure of their life, and lo and behold, they've got a huge malignant,
*  inoperable, or incurable brain tumor. You can only do that, I think, a handful of times
*  before it really starts eating away at your armor. Or a young mother that shows up that
*  has a giant hemorrhage in her brain that she's not going to survive from.
*  And they bring her four-year-old daughter in to say goodbye one last time before they turn the
*  ventilator off. The great Henry Marsh is an English neurosurgeon who said it best. I think he
*  says every neurosurgeon carries with them a private graveyard, and I definitely feel that,
*  especially with young parents. That kills me. They had a lot more to give. The loss of those
*  people specifically has a knock-on effect that's going to make the world worse for people
*  for a long time, and it's just hard to feel powerless in the face of that.
*  And that's where I think you have to be borderline evil to fight against a company like Neuralink or
*  to constantly be taking pot shots at us because what we're doing is to try to fix that stuff.
*  We're trying to give people options to reduce suffering. We're trying to take the pain out
*  of life that broken brains brings in. This is just our little way that we're fighting
*  back against entropy, I guess. Yeah, the amount of suffering that's endured when some of the
*  things that we take for granted that our brain is able to do is taken away is immense. And to be
*  able to restore some of that functionality is a real gift. Yeah, we're just starting.
*  We're going to do so much more. Well, can you take me through the full procedure for implanting,
*  say, the N1 chip in Neuralink? Yeah, it's a really simple,
*  really simple, straightforward procedure. The human part of the surgery that I do is
*  dead simple. It's one of the most basic neurosurgery procedures imaginable. And I think
*  there's evidence that some version of it has been done for thousands of years.
*  There are examples, I think, from ancient Egypt of healed or partially healed
*  trephanations and from Peru or ancient times in South America where these proto-surgeons,
*  would drill holes in people's skulls, presumably to let out the evil spirits,
*  but maybe to drain blood clots. And there's evidence of bone healing around the edge,
*  meaning the people at least survive some months after a procedure. And so what we're doing is
*  that we are making a cut in the skin on the top of the head over the area of the brain that is
*  the most potent representation of hand intentions. And so if you are an expert concert pianist,
*  this part of your brain is lighting up the entire time you're playing. We call it the hand knob.
*  The hand knob. So it's all the finger movements, all of that is just firing away.
*  Yep. There's a little squiggle in the cortex right there. One of the folds in the brain is
*  kind of doubly folded right on that spot. And so you can look at it on an MRI and say,
*  that's the hand knob. And then you do a functional test in a special kind of MRI called a functional
*  MRI, fMRI. And this part of the brain lights up when people, even quadriplegic people whose
*  brains aren't connected to their finger movements anymore, they imagine finger movements and this
*  part of the brain still lights up. So we can ID that part of the brain in anyone who's preparing
*  to enter our trial and say, okay, that part of the brain we confirm is your hand intention area.
*  And so I'll make a little cut in the skin. We'll flap the skin open, just like kind of opening
*  the hood of a car, only a lot smaller. Make a perfectly round one inch diameter hole in the
*  skull. Remove that bit of skull. Open the lining of the brain, the covering of the brain. It's like
*  a little bag of water that the brain floats in. And then show that part of the brain to our robot.
*  And then this is where the robot shines. It can come in and take these tiny, much smaller than
*  human hair, electrodes and precisely insert them into the cortex, into the surface of the brain
*  to a very precise depth in a very precise spot that avoids all the blood vessels that are coating
*  the surface of the brain. And after the robot's done with its part, then the human comes back in
*  and puts the implant into that hole in the skull and covers it up, screwing it down to the skull
*  and sewing the skin back together. So the whole thing is a few hours long. It's extremely low
*  risk compared to the average neurosurgery involving the brain that might say open up a deep part of
*  the brain or manipulate blood vessels in the brain. This opening on the surface of the brain
*  with only cortical microinsertions carries significantly less risk than a lot of the tumor
*  or aneurysm surgeries that are routinely done. So cortical microinsertions that are via robot
*  and computer vision are designed to avoid the blood vessels. So I know you're a bit biased here,
*  but let's compare human and machine. So what are human surgeons able to do well and what are
*  robot surgeons able to do well at this stage of our human civilization development?
*  Yeah. Yeah, that's a good question. Humans are general purpose machines. We're able to adapt to
*  unusual situations. We're able to change the plan on the fly.
*  I remember well a surgery that I was doing many years ago down in San Diego where the plan was to
*  open a small hole behind the ear and go reposition a blood vessel that had come to lay on the facial
*  nerve, the trigeminal nerve, the nerve that goes to the face. When that blood vessel lays on the
*  nerve, it can cause just intolerable, horrific shooting pain that people describe like being
*  zapped with a cattle prod. And so the beautiful elegant surgery is to go move this blood vessel
*  off the nerve. The surgery team, we went in there and started moving this blood vessel and then
*  found that there was a giant aneurysm on that blood vessel that was not easily visible on the pre-op scans.
*  And so the plan had to dynamically change and the human surgeons had no problem with that. We're
*  trained for all those things. Robots wouldn't do so well in that situation, at least in their
*  current incarnation, fully robotic surgery like the electrode insertion portion of
*  the Neuralink surgery. It goes according to a set plan. And so the humans can interrupt the
*  flow and change the plan, but the robot can't really change the plan midway through. It
*  operates according to how it was programmed and how it was asked to run. It does its job
*  very precisely, but not with a wide degree of latitude and how to react to changing conditions.
*  So there could be just a very large number of ways that you could be surprised as a surgeon.
*  When you enter a situation, there could be subtle things that you have to dynamically adjust to.
*  Correct. And robots are not good at that. Currently. Currently. I think we are at the dawn of a new
*  era with AI of the parameters for robot responsiveness to be dramatically broadened.
*  I mean, you can't look at a self-driving car and say that it's operating under very narrow
*  parameters. If a chicken runs across the road, it wasn't necessarily programmed to deal with that
*  specifically, but a Waymo or a self-driving Tesla would have no problem reacting to that.
*  And so surgical robots aren't there yet, but give it time.
*  And then there could be a lot of sort of into like semi-autonomous possibilities of
*  maybe a robotic surgeon could say this situation is perfectly familiar or the situation is not
*  familiar. And in the not familiar case, a human could take over, but basically like be very
*  conservative in saying, okay, this for sure has no issues, no surprises, and let the humans deal
*  with the surprises with the edge cases, all that. That's one possibility. So you think eventually
*  you'll be out of the job. You being neurosurgeon, your job being neurosurgeon. Humans, there will
*  not be many neurosurgeons left on this earth. I'm not worried about my job. You know,
*  my job in the course of my professional life, I think I would tell my kids not necessarily to
*  go in this line of work depending on how things look in 20 years. It's so fascinating because I
*  mean, if I have a line of work, I would say it's programming. And if you ask me like for the last,
*  I don't know, 20 years, what I would recommend for people, I would tell them, yeah, go,
*  you will always have a job if you're a programmer. There's more and more computers and all this kind
*  of stuff and it pays well. But then you realize these large language models come along and they're
*  really damn good at generating code. So this overnight, you could be surprised like, wow,
*  what is the contribution of the human really? But then you start to think, okay, it does seem
*  that humans have ability, like you said, to deal with novel situations. And in the case of programming,
*  it's the ability to kind of come up with novel ideas to solve problems. It seems like machines
*  aren't quite yet able to do that. And when the stakes are very high, when it's life critical,
*  as it is in surgery, especially in neurosurgery, then it starts, the stakes are very high for a
*  robot to actually replace a human. But it's fascinating that in this case of Neuralink,
*  there's a human robot collaboration. Yeah. Yeah. I do the parts it can't do and it does the parts
*  I can't do. And we are friends. I saw that there's a lot of practice going on. So I mean,
*  everything in Neuralink is tested extremely rigorously. But one of the things I saw that
*  there's a proxy on which the surgeries are performed. So this is both for the robot and
*  for the human, for everybody involved in the entire pipeline. What's that like, practicing the
*  surgery? It's pretty intense. So there's no analog to this in human surgery. Human surgery is sort of
*  this artisanal craft that's handed down directly from master to pupil over the generations. I mean,
*  literally the way you learn to be a surgeon on humans is by doing surgery on humans.
*  I mean, first, you watch your professors do a bunch of surgery. And then finally,
*  they put the trivial parts of the surgery into your hands, and then the more complex parts.
*  And as your understanding of the point and the purposes of the surgery increases, you get more
*  responsibility in the perfect condition. It doesn't always go well. In Neuralink's case,
*  the approach is a bit different. We, of course, practiced as far as we could on animals. We did
*  hundreds of animal surgeries. And when it came time to do the first human, we had just an
*  amazing team of engineers build incredibly lifelike models. One of the engineers, Fran
*  Romano in particular, built a pulsating brain in a custom 3D printed skull that matches exactly
*  the patient's anatomy, including their face and scalp characteristics. And so,
*  when I was able to practice that, I mean, it's as close as it really reasonably should get
*  to being the real thing in all the details, including having a mannequin body attached to
*  this custom head. And so, when we were doing the practice surgeries, we'd wheel that body into the
*  CT scanner and take a mock CT scan and wheel it back in and conduct all the normal safety checks,
*  verbally stop this patient. We're confirming his identification is mannequin number, blah, blah,
*  and then opening the brain in exactly the right spot using standard operative neuro-navigation
*  equipment, standard surgical drills in the same OR that we do all of our practice surgeries in
*  at Neuralink, and having the skull open and have the brain pulse, which adds a degree of difficulty
*  for the robot to perfectly, precisely plan and insert those electrodes to the right depth and
*  location. And so, yeah, we kind of broke new ground on how extensively we practiced for this
*  surgery. So, there was a historic moment, a big milestone for Neuralink, in part for humanity,
*  with the first human getting a Neuralink implant in January of this year. Take me through the
*  surgery on Noland. What did it feel like to be part of this?
*  Yeah. Well, we're lucky to have just incredible partners at the Barrow Neurologic Institute. They
*  are, I think, the premier neurosurgical hospital in the world. They made everything as easy as
*  possible for the trial to get going and helped us immensely with their expertise on how to arrange
*  the details. It was a much more high-pressure surgery in some ways. I mean, even though the
*  outcome wasn't particularly in question in terms of our participants' safety, the number of
*  observers, the number of people. There's conference rooms full of people watching live streams in the
*  hospital rooting for this to go perfectly, and that just adds pressure that is not typical for
*  is not typical for even the most intense production neurosurgery, say removing a tumor
*  or placing deep brain stimulation electrodes. And it had never been done on a human before.
*  There were unknown unknowns. And so, definitely a moderate pucker factor there for the whole team,
*  not knowing if we were going to encounter, say, a degree of brain movement that was unanticipated,
*  or a degree of brain sag that took the brain far away from the skull and made it difficult to
*  insert, or some other unknown, unknown problem. Fortunately, everything went well, and that
*  surgery was one of the smoothest outcomes we could have imagined.
*  Were you nervous? I mean, you're a quarterback in the Super Bowl kind of situation.
*  Extremely nervous. Extremely. I was very pleased when it went well and when it was over.
*  Looking forward to number two.
*  Yeah. Even with all that practice, all of that, just you've never been in a situation that's so
*  high stakes in terms of people watching. And we should also probably mention,
*  given how the media works, a lot of people maybe in a dark kind of way hoping it doesn't go well.
*  Well, I think wealth is easy to hate or envy or whatever. And I think there's a whole industry
*  around driving clicks, and bad news is great for clicks. And so, any way to
*  take an event and turn it into bad news is going to be really good for clicks.
*  It just sucks because I think it puts pressure on people. It discourages people from trying to
*  solve really hard problems because to solve hard problems, you have to go into the unknown. You
*  have to do things that haven't been done before, and you have to take risks. Calculated risks,
*  you have to do all kinds of safety precautions, but risks nevertheless. And I just wish there
*  would be more celebration of that, of the risk taking versus people just waiting on the sidelines,
*  waiting for failure, and then pointing out the failure. Yeah, it sucks. But in this case,
*  it's really great that everything went just flawlessly, but it's unnecessary pressure,
*  I would say. Now that there is a human with literal skin in the game, there's a participant
*  whose wellbeing rides on this doing well, you have to be a pretty bad person to be rooting for that
*  to go wrong. And so, hopefully people look in the mirror and realize that at some point.
*  So, did you get to actually front row seat, like watch the robot work, like what?
*  You get to see the whole thing? Yeah, because an MD needs to be in charge of all of the medical
*  decision making throughout the process. I unscrubbed from the surgery after exposing
*  the brain and presenting it to the robot and placed the targets on the robot
*  software interface that tells the robot where it's going to insert each thread that was done
*  with my hand on the mouse for whatever that's worth. So you were the one placing the targets?
*  Oh, cool. So the robot with the computer vision provides a bunch of candidates and you finalize
*  the decision. Right. The software engineers are amazing on this team. And so, they actually
*  provided an interface where you can essentially use a lasso tool and select a prime area of brain
*  real estate. And it will automatically avoid the blood vessels in that region and automatically
*  place a bunch of targets. So that allows the human robot operator to select really good areas of
*  brain and make dense applications of targets in those regions. The regions we think are going to
*  have the most high fidelity representations of finger movements and arm movement intentions.
*  I've seen images of this and for me with OCD, for some reason, are really pleasant.
*  I think there's a subreddit called oddly satisfying. Yeah. Love that subreddit.
*  It's oddly satisfying to see the different target sites avoiding the blood vessels
*  and also maximizing the usefulness of those locations for the signal. It just feels good.
*  It's like, ah. As a person who has a visceral reaction to the brain bleeding, I can tell you.
*  It's extremely satisfying watching the electrodes themselves go into the brain and not cause
*  bleeding. Yeah. Yeah. So, you said the feeling was of relief when everything went perfectly.
*  Yeah. How deep in the brain can you currently go and eventually go? Let's say on the neural
*  link side, it seems the deeper you go in the brain, the more challenging it becomes.
*  Yeah. So, talking broadly about neurosurgery, we can get anywhere. It's routine for me to put
*  deep brain stimulating electrodes near the very bottom of the brain, entering from the top and
*  passing about a two-millimeter wire all the way into the bottom of the brain. And that's
*  not revolutionary. A lot of people do that. And we can do that with very high precision. I use a robot
*  from Globus to do that surgery several times a month. It's pretty routine.
*  What are your eyes in that situation? What are you seeing? What kind of technology can you use
*  to visualize where you are to light your way? Yeah. So, it's a cool process on the software
*  side. You take a preoperative MRI that's extremely high resolution data of the entire brain. You
*  put the patient to sleep, put their head in a frame that holds the skull very rigidly,
*  and then you take a CT scan of their head while they're asleep with that frame on,
*  and then merge the MRI and the CT in software. You have a plan based on the MRI where you can
*  see these nuclei deep in the brain. You can't see them on CT, but if you trust the merging of the
*  two images, then you indirectly know on the CT where that is, and therefore indirectly know
*  where in reference to the titanium frame screwed to their head those targets are.
*  And so, this is 60s technology to manually compute trajectories given the entry point and target
*  it, and dial in some goofy looking titanium actuators with little tick marks on them.
*  The modern version of that is to use a robot, just like a little KUKA arm you might see building
*  cars at the Tesla factory. This small robot arm can show you the trajectory that you intended
*  from the pre-op MRI and establish a very rigid holder through which you can drill a small hole
*  in the skull and pass a small rigid wire deep into that area of the brain that's hollow,
*  and put your electrode through that hollow wire, and then remove all of that except the electrode.
*  So, you end up with the electrode very, very precisely placed far from the skull surface.
*  Now, that's standard technology that's already been out in the world for a while.
*  Neuralink right now is focused entirely on cortical targets, surface targets,
*  because there's no trivial way to get, say, hundreds of wires deep inside the brain without
*  doing a lot of damage. So, your question, what do you see? Well, I see an MRI on a screen. I can't
*  see everything that that DBS electrode is passing through on its way to that deep target. And so,
*  it's accepted with this approach that there's going to be about one in a hundred patients who
*  have a bleed somewhere in the brain as a result of passing that wire blindly into the deep part
*  of the brain. That's not an acceptable safety profile for Neuralink. We start from the position
*  that we want this to be dramatically, maybe two or three orders of magnitude safer than that,
*  safe enough really that you or I, without a profound medical problem, might on our lunch
*  break someday say, yeah, sure, I'll get that. I'd be meaning to upgrade to the latest version.
*  And so, the safety constraints given that are high. And so, we haven't settled on a final solution
*  for arbitrarily approaching deep targets in the brain. It's interesting because you have to avoid
*  blood vessels somehow. Maybe there's creative ways of doing the same thing, like mapping out
*  high resolution geometry of blood vessels, and then you can go in blind. But how do you map out
*  that in a way that's super stable? And so, there's a lot of interesting challenges there, right?
*  Yeah.
*  But there's a lot to do on the surface, luckily.
*  Exactly. So, we've got vision on the surface. We actually have made a huge amount of progress
*  sewing electrodes into the spinal cord as a potential workaround for a spinal cord injury
*  that would allow a brain-mounted implant to translate motor intentions to a spine-mounted
*  implant that can affect muscle contractions in previously paralyzed arms and legs.
*  That's mind-blowing. That's just incredible. So, the effort there is to try to bridge
*  the brain to the spinal cord to the peripheral nerve nervous. So, how hard is that to do?
*  We have that working in very crude forms in animals.
*  That's amazing.
*  Yeah, we've done it.
*  Similar to with Nolan, where he's able to digitally move the cursor. Here, you're doing
*  the same kind of communication, but with the actual effectors that you have.
*  That's fascinating.
*  Yeah. So, we have anesthetized animals doing grasp and moving their legs in a sort of walking
*  pattern. Again, early days, but the future is bright for this kind of thing. People with
*  paralysis should look forward to that bright future. They're going to have options.
*  Yeah. There's a lot of intermediate or extra options where you take an optimist robot,
*  like the arm, and to be able to control the arm, the fingers and hands of the arm
*  as a prosthetic.
*  Exoskeletons are getting better too.
*  Exoskeletons. Yeah. So, that goes hand in hand. Although I didn't quite understand until thinking
*  about it deeply and doing more research about Neuralink, how much you can do on the digital
*  side. So, there's digital telepathy. I didn't quite understand that you could really map
*  the intention, as you described in the hand knob area. You can map the intention. Just imagine it,
*  think about it. That intention can be mapped to actual action in the digital world.
*  And now more and more, so much can be done in the digital world. It can reconnect you to the outside
*  world. It can allow you to have freedom, have independence if you're a quadriplegic.
*  That's really powerful. You can go really far with that.
*  Yeah. Our first participant is incredible. He's breaking world records left and right.
*  And he's having fun with it. It's great. Just going back to the surgery, your whole journey,
*  you mentioned to me offline you have surgery on Monday. So, you're like, you're doing surgery
*  all the time. Maybe the ridiculous question, what does it take to get good at surgery?
*  Practice, repetitions, same with anything else. There's a million ways of people saying the same
*  thing and selling books saying it, but you call it 10,000 hours, you call it spend some chunk of
*  your life, some percentage of your life focusing on this, obsessing about getting better at it.
*  Repetitions, humility, recognizing that you aren't perfect at any stage along the way,
*  recognizing you've got improvements to make in your technique, being open to feedback and coaching
*  from people with a different perspective on how to do it. And then just the constant
*  will to do better. That fortunately, if you're not a sociopath, I think your patients
*  bring that with them to the office visits every day. They force you to want to do better all the
*  time. Yeah, just step up. I mean, it's a real human being, a real human being that you can help.
*  So, every surgery, even if it's the same exact surgery, is there a lot of variability between
*  that surgery and a different person? Yeah, a fair bit. I mean, a good example for us is that
*  the angle of the skull relative to the normal plane of the body axis of the skull overhand knob
*  is pretty wide variation. I mean, some people have really flat skulls and some people have
*  really steeply angled skulls over that area. And that has consequences for how their head can be
*  fixed in the frame that we use and how the robot has to approach the skull.
*  And yeah, people's bodies are built as differently as the people you see walking down the street,
*  as much variability in body shape and size as you see there. We see in brain anatomy and skull
*  anatomy, there are some people who we've had to kind of exclude from our trial for having
*  skulls that are too thick or too thin or scalp that's too thick or too thin. I think we have
*  the middle 97% or so of people, but you can't account for all human anatomy variability.
*  How much mushiness and mess is there? Because I've taken biology classes, the diagrams are always
*  really clean and crisp. Neuroscience, the pictures of neurons are always really nice and very.
*  But whenever I look at pictures of real brains, I don't know what is going on.
*  So how much are biological systems in reality? How hard is it to figure out what's going on?
*  Not too bad. Once you really get used to this, that's where experience and skill and
*  education really come into play is if you stare at a thousand brains,
*  it becomes easier to mentally peel back the, say, for instance, blood vessels that are obscuring the
*  sulci and gyri, the wrinkle pattern of the surface of the brain. Occasionally, when you're first
*  starting to do this and you open the skull, it doesn't match what you thought you were going to
*  see based on the MRI. And with more experience, you learn to kind of peel back that layer of
*  blood vessels and see the underlying pattern of wrinkles in the brain and use that as a
*  landmark for where you are. So I was describing hand knob earlier. That's a pattern of the
*  wrinkles in the brain. It's sort of this Greek letter omega-shaped area of the brain.
*  So you could recognize the hand knob area. If I show you a thousand brains
*  and give you one minute with each, you'd be like, yep, that's that.
*  Sure.
*  And so there is some uniqueness to that area of the brain in terms of the geometry,
*  the topology of the thing. Where is it about in the?
*  It's so you have this strip of brain running down the top called the primary motor area. And
*  I'm sure you've seen this picture of the homunculus laid over the surface of the brain,
*  the weird little guy with huge lips and giant hands. That guy sort of lays with his legs up at
*  the top of the brain and face, arm areas farther down. And then some kind of mouth, lip, tongue
*  areas farther down. And so the hand is right in there. And then the areas that control speech,
*  at least on the left side of the brain in most people are just below that. And so any
*  muscle that you voluntarily move in your body, the vast majority of that references that strip
*  or those intentions come from that strip of brain and the wrinkle for hand knob is right in the
*  middle of that. And vision is back here. Also close to the surface. Vision's a little deeper.
*  And so this gets to your question about how deep can you get to do vision. We can't just do the
*  surface of the brain. We have to be able to go in not as deep as we'd have to go for DBS, but
*  maybe a centimeter deeper than we're used to for hand insertions. And so that's work in progress.
*  That's a new set of challenges to overcome. By the way, you mentioned the Utah array and I
*  just saw a picture of that and that thing looks terrifying.
*  It's because it's rigid. And then if you look at the threads, they're flexible. What can you say
*  that's interesting to you about that kind of approach of the flexible threads to deliver
*  the electrodes next to the neurons? Yeah. I mean, the goal there comes from experience. I mean,
*  we stand on the shoulders of people that made Utah arrays and used Utah arrays for decades
*  before we ever even came along. Neuralink arose partly, this approach to technology arose out of
*  a need recognized after Utah arrays would fail routinely because the rigid electrodes, those
*  spikes that are literally hammered using an air hammer into the brain, those spikes generate a
*  bad immune response that encapsulates the electrode spikes in scar tissue essentially.
*  And so one of the projects that was being worked on in the Anderson lab at Caltech when I
*  got there was to see if you could use chemotherapy to prevent the formation of scar. It's like,
*  things are pretty bad when you're jamming a bed of nails into the brain and then treating that
*  with chemotherapy to try to prevent scar tissue. It's like, maybe we've gotten off track here,
*  guys. Maybe there's a fundamental redesign necessary. And so Neuralink's approach of using
*  highly flexible tiny electrodes avoids a lot of the bleeding, avoids a lot of the immune response
*  that ends up happening when rigid electrodes are pounded into the brain. And so what we see is
*  our electrode longevity and functionality and the health of the brain tissue immediately surrounding
*  the electrode is excellent. I mean, it goes on for years now in our animal models.
*  HOFFMAN What do most people not understand about the biology of the brain?
*  We'll mention the vasculature. That's really interesting.
*  DR. CARROLL I think the most interesting, maybe underappreciated fact
*  is that it really does control almost everything. I mean,
*  I don't know, for out of the blue example, imagine you want a lever on fertility. You
*  want to be able to turn fertility on and off. I mean, there are legitimate targets in the brain
*  itself to modulate fertility, say blood pressure. You want to modulate blood pressure. There are
*  legitimate targets in the brain for doing that. Things that aren't immediately obvious as brain
*  problems are potentially solvable in the brain. And so I think it's an underexplored area for
*  primary treatments of all the things that bother people.
*  HOFFMAN That's a really fascinating way to look at it. There's a lot of conditions we might think
*  have nothing to do with the brain, but they might just be symptoms of something that actually
*  started in the brain, the actual source of the problem, the primary source is something in the
*  brain. DR. CARROLL Yeah, not always. I mean, you know,
*  kidney disease is real, but there are levers you can pull in the brain that affect all of these
*  systems. HOFFMAN There's knobs.
*  DR. CARROLL Yeah.
*  HOFFMAN On-off switches and knobs in the brain from which this all originates.
*  DR. CARROLL Yeah.
*  HOFFMAN Would you have a Neuralink chip implanted in your brain?
*  DR. CARROLL Yeah. I think the use case right now is use a mouse, right? I can already do that.
*  And so there's no value proposition on safety grounds alone. Sure, I'll do it tomorrow.
*  HOFFMAN You know, you say the use case of the mouse,
*  is it after like researching all this and part of it is just watching Nolan have so much fun?
*  DR. CARROLL If you can get that bits per second, like really high with the mouse,
*  like being able to interact. If you think about the way on the smartphone, the way you swipe,
*  that was transformational. HOFFMAN Yeah.
*  DR. CARROLL How we interact with the thing. It's subtle. You don't realize it,
*  but to be able to touch a phone and to scroll with your finger, that's like, that changed
*  everything. People were sure you need a keyboard to type and that, there's a lot of HCI aspects to
*  that that changed how we interact with computers. So there could be a certain rate of speed with the
*  mouse that would change everything. It's like you might be able to just click around a screen
*  extremely fast. And that, if it, I can't see myself getting the Neuralink for much more rapid
*  interaction with digital devices. HOFFMAN Yeah. I think recording speech intentions
*  from the brain might change things as well. You know, the value proposition for the average person.
*  A keyboard is a pretty clunky human interface, requires a lot of training. It's,
*  you know, highly variable in the maximum performance that the average person can achieve.
*  I think taking that out of the equation and just having a natural, you know, word to computer
*  interface might change things for a lot of people. DR. CARROLL It'd be hilarious if that is the reason
*  people do it. Even if you have speech to text, that's extremely accurate. It currently isn't.
*  But let's say you've gotten super accurate. It'd be hilarious if people went for Neuralink,
*  just so you avoid the embarrassing aspect of speaking, like looking like a douchebag speaking
*  to your phone in public, which is a real, like, that's a real constraint.
*  HOFFMAN Yeah. I mean, with a bone conducting case, that can be an invisible headphone, say,
*  and the ability to think words into software and have it respond to you.
*  You know, that starts to sound sort of like embedded super intelligence. You know, if you can
*  silently ask for the Wikipedia article on any subject and have it read to you without any
*  observable change happen in the outside world. You know, for one thing, standardized testing is
*  obsolete. DR. CARROLL Yeah. If it's done well on the UX side, it could change, I don't know if it
*  transforms society, but it really can create a kind of shift in the way we interact with
*  digital devices in the way that a smartphone did. Now, I would, just having to look into the safety
*  of everything involved, I would totally try it. So it doesn't have to go to some, like, incredible
*  thing where you have, it connects to your vision or to some other, like it connects all over your
*  brain. That could be like just connecting to the hand knob. You might have a lot of interesting
*  interaction, human computer interaction possibilities. That's really interesting.
*  HOFFMAN Yeah. And the technology on the academic side is progressing at light speed here. I think
*  there was a really amazing paper out of UC Davis, Sergey Stavisky's lab, that basically made an
*  initial solve of speech decode. It was something like 125,000 words that they were getting with,
*  you know, very high accuracy, which is- DR. CARROLL So you're just thinking the word?
*  HOFFMAN Yeah. DR. CARROLL Thinking the word and you're able to get it.
*  HOFFMAN Yeah. DR. CARROLL Oh, boy. Like, you have to have the intention of speaking it.
*  Right. So like do that inner voice. It's so amazing to me that you can do the intention
*  to signal mapping. All you have to do is just imagine yourself doing it.
*  And if you get the feedback that it actually worked, you can get really good at that. Like,
*  your brain will first of all adjust and you develop like any other skill. Like touch typing,
*  you develop in that same kind of way. That is, that is, to me, it's just really fascinating.
*  HOFFMAN Yeah. DR. CARROLL To be able to even to play with that.
*  Honestly, like I would get a new link just to be able to play with that. Just to play with the
*  capacity of the capability of my mind to learn this skill. It's like learning the skill of typing
*  and learning the skill of moving a mouse. It's another skill of moving the mouse, not with my
*  physical body, but with my mind. HOFFMAN I can't wait to see what people do with it. I feel like
*  we're cavemen right now. We're like banging rocks with a stick and thinking that we're making music.
*  At some point when these are more widespread, there's going to be the equivalent of a
*  piano that, you know, someone can make art with their brain in a way that we didn't even anticipate.
*  Looking forward to it. DR. CARROLL Give it to like a teenager. Like anytime I think I'm good
*  at something, I'll always go to like, I don't know, even with the bits per second of playing
*  a video game, you realize you give it to a teenager. You give a new link to a teenager,
*  just the large number of them, the kind of stuff that get good at stuff. They're going to get like
*  hundreds of bits per second. Even just with the current technology.
*  Probably. Probably. DR. CARROLL Just because it's also addicting how like the,
*  the number go up aspect of it of like improving and training because it is, it's almost like a skill.
*  And plus there's the software on the other end that adapts to you. And especially if the adapting
*  procedure, the algorithm becomes better and better and better, you like learning together.
*  DR. CARROLL Yeah, we're scratching the surface on that right now. There's so much more to do.
*  So on the complete other side of it, you have an RFID chip implanted in you.
*  DR. CARROLL Yeah.
*  DR. CARROLL So I hear. Nice. So this is a passive device that you use
*  for unlocking like a safe with top secrets or what is it? What do you use it for? What's the
*  story behind it? DR. CARROLL I'm not the first one. There's this whole community of weirdo biohackers
*  that have done this stuff. And I think one of the early use cases was storing,
*  you know, private crypto wallet keys and whatever. I dabbled in that a bit and had some fun with it.
*  DR. BALLER Just some Bitcoin implanted in your body somewhere you can't tell where.
*  DR. CARROLL Yeah. Actually, yeah. It was, you know, the modern day equivalent to finding
*  change in the sofa cushions. After I put some orphan crypto on there that I thought was worthless
*  and forgot about it for a few years, went back and found that some community of people loved it
*  and had propped up the value of it. And so it had gone up 50 fold. So there was a lot of change in
*  those cushions. But the primary use case is mostly as a tech demonstrator, you know, it has my
*  business card on it. You can scan that in by touching it to your phone. It opens the front
*  door to my house, you know, whatever simple stuff. DR. BALLER It's a cool step. It's a cool leap to
*  implant something in your body. I mean, it has perhaps that's it's a similar leap to a Neuralink
*  because for a lot of people that kind of notion of putting something inside your body,
*  something electronic inside a biological system is a big leap. DR. CARROLL Yeah, we have a kind of a
*  mysticism around the barrier of our skin. We're completely fine with knee replacements, hip
*  replacements, you know, dental implants. But, you know, there's a mysticism still around
*  the inviolable barrier that the skull represents. And I think that needs to be treated like any other
*  pragmatic barrier. You know, it's the question isn't how incredible is it to open the skull.
*  The question is, you know, what benefit can we provide? DR. BALLER So from all the surgeries
*  you've done from everything you understand the brain, how much does neuroplasticity come into
*  play? How adaptable is the brain? For example, just even in the case of healing from surgery
*  or adapting to the post surgery situation? DR. CARROLL The answer that is sad for me and
*  other people of my demographic is that, you know, plasticity decreases with age, healing decreases
*  with age. I have too much gray hair to be optimistic about that. There are theoretical ways to increase
*  plasticity using electrical stimulation, nothing that is, you know, totally proven out as a robust
*  enough mechanism to offer widely to people. But yeah, I think there's cause for optimism that
*  we might find something useful in terms of, say, an implanted electrode that improves learning.
*  Certainly, there's been some really amazing work recently from Nicholas Schiff, Jonathan Baker,
*  you know, and others who have a cohort of patients with moderate traumatic brain injury,
*  who have had electrodes placed in the deep nucleus in the brain called the central
*  median nucleus or just near the central median nucleus. And when they apply small amounts of
*  electricity to that part of the brain, it's almost like electronic caffeine. They're able to improve
*  people's attention and focus. They're able to improve how well people can perform a task.
*  I think in one case, someone who was unable to work after the device was turned on, they were
*  able to get a job. And that's sort of, you know, one of the holy grails for me with Neuralink
*  and other technologies like this is from a purely utilitarian standpoint.
*  Can we make people able to take care of themselves and their families economically again?
*  Can we make it so someone who's fully dependent and even maybe requires a lot of caregiver
*  resources, can we put them in a position to be fully independent, taking care of themselves,
*  giving back to their communities? I think that's a very compelling proposition and what motivates a
*  lot of what I do and what a lot of the people at Neuralink are working for.
*  It's just a cool possibility that if you put a Neuralink in there, that the brain adapts,
*  like the other part of the brain adapts too and integrates it. The capacity of the brain to do
*  that is really interesting, probably unknown to the degree to which it can do that. But you're
*  now connecting an external thing to it, especially once it's doing stimulation. Like the biological
*  brain and the electronic brain outside of it working together, the possibilities there are
*  really interesting. It's still unknown, but interesting. It feels like the brain is really
*  good at adapting to whatever. But of course it is a system that by itself is already,
*  everything serves a purpose and so you don't want to mess with it too much.
*  Yeah. It's like eliminating a species from an ecology. You don't know what the delicate
*  interconnections and dependencies are. The brain is certainly a delicate complex beast and we don't
*  know every potential downstream consequence of a single change that we make.
*  Do you see yourself doing, so you mentioned P1, surgeries of P2, P3, P4, P5,
*  just more and more and more humans? I think it's a certain kind of
*  brittleness or a failure on the company's side if we need me to do all the surgeries.
*  I think something that I would very much like to work towards is a process that is so simple
*  and so robust on the surgery side that literally anyone could do it. We want to get away from
*  requiring intense expertise or intense experience to have this successfully done and make it as
*  simple and translatable as possible. I would love it if every neurosurgeon on the planet
*  had no problem doing this. I think we're probably far from a regulatory environment that would allow
*  people that aren't neurosurgeons to do this, but not impossible.
*  All right. I'll sign off for that. Did you ever anthropomorphize the robot, R1? Do you give it a
*  name? Do you see it as a friend that's working together with you?
*  I mean, to a certain degree, it's- Or an enemy who's going to take the job.
*  To a certain degree, it's a complex relationship.
*  All the good relationships are.
*  It's funny when in the middle of the surgery, there's a part of it where I stand basically
*  shoulder to shoulder with the robot. If you're in the room reading the body language, it's my
*  brother in arms there. We're working together on the same problem. Yeah, I'm not threatened by it.
*  Keep telling yourself that. How have all the surgeries that you've done over the years
*  changed your understanding of life and death?
*  Yeah. It gives you a very visceral sense, and this may sound trite, but it gives you a very
*  visceral sense that death is inevitable. On one hand, you're a robot, you're a robot,
*  and on one hand, you are, as a neurosurgeon, you're deeply involved in these hard to fathom
*  tragedies. Young parents dying, leaving a four-year-old behind, let's say.
*  And on the other hand, it takes the sting out of it a bit because
*  you see how just mind-numbingly universal death is. There's zero chance that I'm going to avoid it.
*  I know techno-optimists right now and longevity buffs right now would disagree on that 0.000%
*  estimate, but I don't see any chance that our generation is going to avoid it.
*  Entropy is a powerful force, and we are very ornate, delicate, brittle DNA machines that
*  aren't up to the cosmic ray bombardment that we're subjected to. So on the one hand,
*  every human that has ever lived died or will die. On the other hand, it's just
*  the hardest thing to imagine inflicting on anyone that you love is having them gone.
*  I'm sure you've had friends that aren't living anymore, and it's hard to even think about them.
*  And so I wish I had arrived at the point of nirvana where death doesn't have a sting.
*  I'm not worried about it, but I can at least say that I'm comfortable with the certainty of it,
*  if not having found out how to take the tragedy out of it when I think about my kids
*  either not having me or me not having them or my wife.
*  Maybe I've come to accept the intellectual certainty of it, but
*  it may be the pain that comes with losing the people you love. I don't think I've come to
*  understand the existential aspect of it, like that this is going to end. And I don't mean like
*  in some trite way. It certainly feels like it's not going to end. You live life like it's not going
*  to end. And the fact that this light that's shining, this consciousness is going to
*  no longer be one moment, maybe today, it fills me when I really am able to load all that in.
*  It fills me when I really am able to load all that in with Ernest Becker's terror.
*  It's a real fear. I think people aren't always honest with how terrifying it is.
*  I think the more you are able to really think through it, the more terrifying it is.
*  It's not such a simple thing. Oh, well, that's the way life is. If you really can load that in,
*  it's hard. But I think that's why the Stoics did it because it helps you get your shit together and
*  be like, well, the moment, every single moment you're alive is just beautiful. And it's terrifying
*  that it's going to end. It's almost like you're shivering in the cold, a child helpless, this kind
*  of feeling. And then it makes you, when you have warmth, when you have the safety, when you have
*  the love, to really appreciate it. I feel like sometimes in your position, when you mentioned
*  armor, just to see death, it might make you not be able to see that, the finiteness of life. Because
*  if you kept looking at that, it might break you. So it's good to know that you're still struggling
*  with that. There's the neurosurgeon and then there's a human. And the human is still able to
*  struggle with that and feel the fear of that and the pain of that.
*  Yeah, it definitely makes you ask the question of how long, how many of these can you see? And
*  of these can you see? And not say, I can't do this anymore.
*  But you said it well. I think it gives you an opportunity to just appreciate that you're alive
*  today. And I've got three kids and an amazing wife and I'm really happy. Things are good.
*  I get to help on a project that I think matters. I think it moves us forward. I'm a very lucky
*  person. It's the early steps of a potentially gigantic leap for humanity. It's a really
*  interesting one. And it's cool because you read about all this stuff in history where it's like
*  the early days. I've been reading, before going to the Amazon, I would read about explorers
*  that would go and explore even the Amazon jungle for the first time. It's just, those are the early
*  steps. Or early steps into space, early steps in any discipline in physics and mathematics.
*  And it's cool because this is like on the grand scale, these are the early steps
*  into delving deep into the human brain. So not just observing the brain, but you'll be able to
*  interact with the human brain. It's going to help a lot of people, but it also might
*  help us understand what the hell's going on in there.
*  Yeah. I think ultimately we want to give people more levers that they can pull.
*  You want to give people options. If you can give someone a dial that they can turn on how happy
*  they are, I think that makes people really uncomfortable. But now talk about major
*  depressive disorder. Talk about people that are committing suicide at an alarming rate in this
*  country. And try to justify that queasiness in that light. You can give people a knob to take
*  away suicidal ideation, suicidal intention. I would give them that knob. I don't know how you
*  justify not doing that. Yeah. You can think about all the suffering that's going on in the world.
*  Every single human being that's suffering right now, it'll be a glowing red dot. The more suffering,
*  the more it's glowing. And you just see the map of human suffering. And any technology that allows
*  you to dim that light of suffering on a grand scale is pretty exciting. Because there's a lot
*  of people suffering and most of them suffer quietly. We look away too often. And we should
*  remember those that are suffering. Because once again, most of them are suffering quietly.
*  Well, and on a grander scale, the fabric of society. People have a lot of complaints about
*  how our social fabric is working or not working, how our politics is working or not working.
*  Those things are made of neurochemistry too in aggregate. Our politics is composed of individuals
*  with human brains. And the way it works or doesn't work is potentially tunable
*  in the sense that, I don't know, say remove our addictive behaviors or tune our addictive
*  behaviors for social media or our addiction to outrage, our addiction to sharing the most angry
*  political tweet we can find. I don't think that leads to a functional society. And if you had
*  options for people to moderate that maladaptive behavior, there could be huge benefits to society.
*  Maybe we could all work together a little more harmoniously toward useful ends.
*  There's a sweet spot, like you mentioned. You don't want to completely remove all the dark
*  sides of human nature because those are somehow necessary to make the whole thing work. But there's
*  a sweet spot. Yeah, I agree. You got to suffer a little, just not so much that you lose hope.
*  When you all the surgeries you've done, have you seen consciousness in there ever?
*  Was there like a glowing light? I have this sense that I never found it,
*  never removed it like a dementor in Harry Potter. I have this sense that consciousness is a lot less
*  magical than our instincts want to claim it is. It seems to me like a useful analog for thinking
*  about what consciousness is in the brain is that we have a really good intuitive understanding of
*  what it means to say, touch your skin and know what's being touched.
*  I think consciousness is just that level of sensory mapping applied to the thought processes
*  in the brain itself. So what I'm saying is consciousness is the sensation of some part of
*  your brain being active. So you feel it working. You feel the part of your brain that thinks of
*  red things or winged creatures or the taste of coffee. You feel those parts of your brain
*  being active the way that I'm feeling my palm being touched. And that sensory system
*  that feels the brain working is consciousness. That's so brilliant. It's the same way,
*  it's the sensation of touch when you're touching a thing. Consciousness is the sensation of
*  you feeling your brain working, your brain thinking, your brain perceiving.
*  AC Which isn't like a warping of space time or some quantum field effect. It's nothing magical.
*  People always want to ascribe to consciousness something truly different. And there's this
*  awesome long history of people looking at whatever the latest discovery in physics is to explain
*  consciousness because it's the most magical, the most out there thing that you can think of.
*  And people always want to do that with consciousness. I don't think that's necessary. It's just a
*  very useful and gratifying way of feeling your brain work.
*  RG And as we said, it's one heck of a brain.
*  Everything we see around us, everything we love, everything that's beautiful came from
*  brains like these. AC It's all electrical activity happening inside your skull.
*  RG And I for one am grateful that it's people like you that are
*  exploring all the ways that it works and all the ways it can be made better.
*  Thank you so much for talking today. AC It's been a joy.
*  RG Thanks for listening to this conversation with Matthew McDougall. And now, dear friends,
*  here's Bliss Chapman, Brain Interface Software Lead at Neuralink. You told me that you've met
*  hundreds of people with spinal cord injuries or with ALS and that your motivation for helping
*  at Neuralink is grounded in wanting to help them. Can you describe this motivation?
*  AC Yeah. First, just a thank you to all the people I've gotten a chance to speak with for
*  sharing their stories with me. I don't think there's any world really in which I can
*  share their stories as powerful a way as they can. But just I think to summarize at a very
*  high level what I hear over and over again is that people with ALS or severe spinal cord injury
*  in a place where they basically can't move physically anymore, really at the end of the day
*  are looking for independence. And that can mean different things for different people.
*  For some folks, it can mean the ability just to be able to communicate again independently without
*  needing to wear something on their face, without needing a caretaker to be able to put something
*  in their mouth. For some folks, it can mean independence to be able to work again, to be
*  able to navigate a computer digitally efficiently enough to be able to get a job, to be able to
*  support themselves, to be able to move out and ultimately be able to support themselves after
*  their family maybe isn't there anymore to take care of them. And for some folks, it's as simple
*  as just being able to respond to their kid in time before they run away or get interested in
*  something else. And these are deeply personal and sort of very human problems. And what strikes me
*  again and again when talking with these folks is that this is actually an engineering problem.
*  This is a problem that with the right resources, the right team, we can make a lot of progress on.
*  And at the end of the day, I think that's a deeply inspiring message and something that
*  makes me excited to get up every day. So it's both an engineering problem
*  in terms of a BCI, for example, that can give them capabilities where they can interact with the world,
*  but also on the other side, it's an engineering problem for the rest of the world to make it more
*  accessible for people living with quadriplegia. Yeah, and I'll take a broad view sort of lens on
*  this for a second. I think I'm very in favor of anyone working in this problem space. So beyond
*  BCI, I'm happy and excited and willing to support any way I can folks working on eye tracking systems,
*  working on speech to text systems, working on head trackers or mouse sticks or quad sticks.
*  I've met many engineers and folks in the community that do exactly those things.
*  And I think for the people we're trying to help, it doesn't matter what the complexity of the
*  solution is as long as the problem is solved. And I want to emphasize that there can be many
*  solutions out there that can help with these problems. And BCI is one of a collection of such
*  solutions. So BCI in particular, I think, offers several advantages here. And I think the folks
*  that recognize this immediately are usually the people who have spinal cord injury or some form of
*  paralysis. Usually you don't have to explain to them why this might be something that could be
*  helpful. It's usually pretty self-evident. But for the rest of us, folks that don't live with severe
*  spinal cord injury or who don't know somebody with ALS, it's not often obvious why you would want a
*  brain implant to be able to connect and navigate a computer. And it's surprisingly nuanced to the
*  degree that I've learned a huge amount just working with Nolan in the first Neuralink clinical trial
*  and understanding from him in his words why this device is impactful for him. And it's a nuanced
*  topic. It can be the case that even if you can achieve the same thing, for example, with a
*  mouse stick when navigating a computer, he doesn't have access to that mouse stick every single minute
*  of the day. He only has access when someone is available to put it in front of him. And so BCI
*  can really offer a level of independence and autonomy that if it wasn't literally physically
*  part of your body, it would be hard to achieve in any other way. So there's a lot of fascinating
*  aspects to what it takes to get Nolan to be able to control a cursor on the screen with his mind.
*  You texted me something that I just love. You said, I was part of the team that interviewed
*  and selected P1. I was in the operating room during the first human surgery monitoring live
*  signals coming out of the brain. I work with the user basically every day to develop new UX paradigms,
*  decoding strategies. And I was part of the team that figured out how to recover useful BCI to new
*  world record levels when the signal quality degraded. We'll talk about, I think, every aspect
*  of that, but just zooming out, what was it like to be part of that, part of that team and part of that
*  historic, I would say historic first? Yeah, I think for me, this is something I've been excited about
*  for close to 10 years now. And so to be able to be even just some small part of making it a reality
*  is extremely exciting. A couple maybe special moments during that whole process that I'll never
*  really truly forget. One of them is entering the actual surgery. At that point in time,
*  I know Nolan quite well. I know his family. And so I think the initial reaction when
*  Nolan is rolled into the operating room is just a, oh shit kind of reaction. But at that point,
*  muscle memory kicks in and you sort of go into, you let your body just do all the talking.
*  And I have the lucky job in that particular procedure to just be in charge of monitoring
*  the implant. So my job is to sit there to look at the signals coming off the implant, to look at the
*  live brain data streaming off the device as threads are being inserted into the brain.
*  And just to basically observe and make sure that nothing is going wrong or that there's no red
*  flags or fault conditions that we need to go and investigate or pause the surgery to debug. And
*  because I had that sort of spectator view of the surgery, I had a slightly removed perspective.
*  And I think most folks in the room, I got to sit there and think to myself, wow,
*  that brain is moving a lot. When you look into the side of the cranioectomy that we
*  stick the threads in, one thing that most people don't realize is the brain moves.
*  The brain moves a lot when you breathe, when your heart beats and you can see it visibly.
*  So that's something that I think was a surprise to me and very, very exciting
*  to be able to see someone's brain who you physically know, have talked with that length,
*  actually pausing and moving inside their skull. And they used that brain to talk to you previously.
*  And now it's right there moving. Actually, I didn't realize that in terms of the thread
*  sending. So the neural link implant is active during surgery. So one thread at a time,
*  you're able to start seeing the signal. So that's part of the way you test that the thing is working.
*  Yeah, so actually in the operating room, right after we finished all the thread insertions,
*  I started collecting what's called broadband data. So broadband is basically the most raw form of
*  signal you can collect from a neural link electrode. It's essentially a measurement of
*  the local field potential or the voltage essentially measured by that electrode.
*  And we have a certain mode in our application that allows us to visualize where detected spikes are.
*  So it visualizes sort of where in the broadband signal, and it's very, very raw form of the data,
*  a neuron is actually spiking. And so one of these moments that I'll never forget as part of this
*  whole clinical trial is seeing live in the operating room, while he's still under anesthesia,
*  beautiful spikes being shown in the application just streaming live to a device I'm holding in
*  my hand. So this is no signal processing, the raw data and then the signals processing is on top of
*  it, you're seeing the spikes detected. And that's the UX too. That looks beautiful as well.
*  During that procedure, there was actually a lot of cameramen in the room. So they also were curious
*  and wanted to see there's several neurosurgeons in the room who are all just excited to see robots
*  taking their job. And they're all crowded around a small little iPhone watching this live brain data
*  stream out of his brain. What was that like seeing the robot do some of the surgery? So the computer
*  vision aspect where it detects all the all the spots that avoid the blood vessels, and then
*  obviously with human supervision, then actually doing the really high precision connection of
*  the threads to the brain. That's a good question. My answer is going to be pretty lame here, but it
*  was boring. Yeah, I've seen it so many times. Yeah, that's exactly how you want surgery to be. You
*  want it to be boring. Yeah, because I've seen it so many times. I've seen the robot do the surgery,
*  literally hundreds of times. And so it was just one more time. Yeah, all the practice surgeries
*  and proxies. And this is just another day. Yeah. So what about when Nolan woke up? Well, do you
*  remember a moment where he was able to move the cursor, not move the cursor, but get signal from
*  the brain such that it was able to show that there's a connection? Yeah. Yeah. So we are
*  quite excited to move as quickly as we can. And Nolan was really, really excited to get started.
*  He wanted to get started actually the day of surgery. But we waited till the next morning,
*  very patiently, it's a long night. And the next morning in the ICU where he was recovering, he
*  wanted to get started and actually start to understand what kind of signal we can measure
*  from his brain. And maybe for folks who are not familiar with the Neuralink system, we implant
*  the Neuralink system or the Neuralink implant in the motor cortex. So the motor cortex is
*  responsible for representing things like motor intent. So if you imagine closing and opening
*  your hand, that kind of signal representation would be present in the motor cortex. If you
*  imagine moving your arm back and forth or wiggling a pinky, this sort of signal can be present in the
*  motor cortex. So one of the ways we start to sort of map out what kind of signal do we actually have
*  access to in any particular individual's brain is through this task called body mapping. And body
*  mapping is where you essentially present a visual to the user and you say, hey, imagine doing this.
*  And that visual is a 3D hand opening, closing, or index finger modulating up and down. And you ask
*  the user to imagine that. And obviously you can't see them do this because they're paralyzed. So
*  you can't see them actually move their arm. But while they do this task, you can record
*  to neural activity. And you can basically offline model and check, can I predict or can I detect the
*  modulation corresponding with those different actions? And so we did that task and we realized,
*  hey, there's actually some modulation associated with some of his hand motion, which was the first
*  indication that, okay, we can potentially use that modulation to do useful things in the world.
*  For example, control a computer cursor. And he started playing with it the first time we showed
*  him it. And we actually just took the same live view of his brain activity and put it in front of
*  him. And we said, hey, you tell us what's going on. We're not you. You're able to imagine different
*  things. And we know that it's modulating some of these neurons. So you figure out for us what that
*  is actually representing. And so he played with it for a bit. He was like, I don't quite get it yet.
*  He played for a bit longer and he said, oh, when I move this finger, I see this particular neuron
*  start to fire more. And I said, okay, prove it, do it again. And so he said, okay, three, two, one,
*  boom. And the minute he moved, you can see like instantaneously this neuron is firing. Single neuron,
*  I can tell you the exact channel number if you're interested. It's stuck in my brain now forever.
*  But that single channel firing was a beautiful indication that it was behaviorally modulated
*  neural activity that could then be used for downstream tasks like decoding a computer cursor.
*  And when you say single channel, is that associated with a single electrode?
*  Yes, channel electrode are interchangeable. And there's 1024 of those. 1024. Yeah.
*  It's incredible that that works. That really, when I was learning about all this and like
*  loading it in, it was just blowing my mind that the intention you can visualize yourself
*  moving the finger, that can turn into a signal. And the fact that you can then skip that step
*  and visualize the cursor moving or have the intention of the cursor moving and that leading
*  to a signal that can then be used to move the cursor. There's so many exciting things there
*  to learn about the brain, about the way the brain works. The very fact of their existing signal that
*  can be used is really powerful. But it feels like that's just like the beginning of figuring out how
*  that signal can be used really, really effectively. I should also just, there's so many fascinating
*  details here, but you mentioned the body mapping step. At least in the version I saw that Nolan
*  was showing off, there's like a super nice interface, like a graphical interface. It just
*  felt like I was in the future because it visualizes you moving the hand. And there's a very
*  sexy polished interface that says, hello. I don't know if there's a voice component, but it just
*  felt like when you wake up in a really nice video game and this is a tutorial at the beginning of
*  that video game, this is what you're supposed to do. It's cool. No, I mean, the future should feel
*  like the future. But it's not easy to pull that off. I mean, it needs to be simple, but not too
*  simple. Yeah. And I think the UX design component here is underrated for BCI development in general.
*  There's a whole interaction effect between the ways in which you visualize an instruction to the
*  user and the kinds of signal you can get back. And that quality of sort of your behavioral alignment
*  to the neural signal is a function of how good you are at expressing to the user what you want
*  them to do. And so, yeah, we spend a lot of time thinking about the UX, of how we build our
*  applications, of how the decoder actually functions, the control surfaces it provides to the user.
*  All these little details matter a lot. So maybe it'd be nice to get into a little bit more detail
*  of what the signal looks like and what the decoding looks like. So there's a N1 implant
*  that has, like we mentioned, 1024 electrodes. And that's collecting raw data, raw signal. What
*  does that signal look like? And what are the different steps along the way before it's
*  transmitted and what is transmitted and all that kind of stuff? Yeah. Yep. This is going to be a
*  fun one. Let's go. So maybe before diving into what we do, it's worth understanding what we're
*  trying to measure because that dictates a lot of the requirements for the system that we build.
*  And what we're trying to measure is really individual neurons producing action potentials.
*  And action potential is, you can think of it like a little electrical impulse that you can
*  detect if you're close enough. And by being close enough, I mean within, let's say, 100 microns of
*  that cell. And 100 microns is a very, very tiny distance. And so the number of neurons that you're
*  going to pick up with any given electrode is just a small radius around that electrode.
*  And the other thing worth understanding about the underlying biology here is that when neurons
*  produce an action potential, the width of that action potential is about one millisecond. So
*  from the start of the spike to the end of the spike, that whole width of that characteristic
*  feature of a neuron firing is one millisecond wide. And if you want to detect that an individual
*  spike is occurring or not, you need to sample that signal or sample the local field potential
*  nearby that neuron much more frequently than once a millisecond. You need to sample many,
*  many times per millisecond to be able to detect that this is actually the characteristic waveform
*  of a neuron producing an action potential. And so we sample across all 1024 electrodes
*  about 20,000 times a second. 20,000 times a second means we're already given one millisecond
*  window. We have about 20 samples that tell us what that exact shape of that action potential looks
*  like. And once we've sort of sampled at super high rate the underlying electrical field nearby
*  these cells, we can process that signal into just where do we detect a spike or where do we not?
*  Sort of a binary signal one or zero, do we detect a spike in this one millisecond or not?
*  And we do that because the actual information carrying sort of subspace of neural activity is
*  just when our spikes are occurring. Essentially everything that we care about for decoding can
*  be captured or represented in the frequency characteristics of spike trains, meaning how often
*  our spikes firing in any given window of time. And so that allows us to do sort of a crazy amount
*  of compression from this very rich high density signal to something that's much, much more sparse
*  and compressible that can be sent out over a wireless radio like a Bluetooth communication,
*  for example. Quick tangents here. You mentioned electrode neuron. There's a
*  local neighborhood of neurons nearby. How difficult is it to isolate from where the spike came from?
*  Yeah. So there's a whole field of sort of academic neuroscience work on exactly this problem of
*  basically given a single electrode or given a set of electrodes measuring a set of neurons,
*  how can you sort of sort, spike sort which spikes are coming from what neuron? And this is a problem
*  that's pursued in academic work because you care about it for understanding what's going on in the
*  underlying sort of neuroscience of the brain. If you care about understanding how the brain's
*  representing information, how that's evolving through time, then that's a very, very important
*  question to understand. For sort of the engineering side of things, at least at the current scale,
*  if the number of neurons per electrode is relatively small, you can get away with basically
*  ignoring that problem completely. You can think of it like sort of a random projection of neurons
*  to electrodes, and there may be in some cases more than one neuron per electrode, but if that
*  number is small enough, those signals can be thought of as sort of a union of the two. And
*  for many applications, that's a totally reasonable trade-off to make and can simplify the problem
*  a lot. And as you sort of scale out channel count, the relevance of distinguishing individual
*  neurons becomes less important because you have more overall signal and you can start to rely on
*  sort of correlations or covariance structure in the data to help understand when that channel is
*  firing, what does that actually represent? Because you know that when that channel is firing,
*  in concert with these other 50 channels, that means move left, but when that same channel is
*  firing with concert with these other 10 channels, that means move right.
*  Okay, so you have to do this kind of spike detection on board,
*  and you have to do that super efficiently, so fast and not use too much power because you don't
*  want to be generating too much heat, so it has to be a super simple signal processing step.
*  Is there some wisdom you can share about what it takes to overcome that challenge?
*  Yeah, so we've tried many different versions of basically turning this raw signal into
*  sort of a feature that you might want to send off the device. And I'll say that I don't think
*  we're at the final step of this process. This is a long journey. We have something that works
*  clearly today, but there can be many approaches that we find in the future that are much better
*  than what we do right now. So some versions of what we do right now, and there's a lot of academic
*  carriages to these ideas, so I don't want to claim that these are original neural link ideas or
*  anything like that. But one of these ideas is basically to build a sort of like a convolution
*  filter almost, if you will, that slides across the signal and looks for a certain template
*  to be matched. That template consists of sort of how deep the spike modulates, how much it recovers,
*  and what the duration and window of time is that the whole process takes. And if you can see in the
*  signal that that template is matched within certain bounds, then you can say, okay, that's a spike.
*  One reason that approach is super convenient is that you can actually implement that extremely
*  efficiently in hardware, which means that you can run it in low power across 1024 channels all at
*  once. Another approach that we've recently started exploring, and this can be combined with the
*  spike detection approach, something called spike band power. And the benefits of that approach are
*  that you may be able to pick up some signal from neurons that are maybe too far away to be detected
*  as a spike, because the farther away you are from an electrode, the weaker that actual spike
*  waveform will look like on that electrode. So you might be able to pick up population level activity
*  of things that are maybe slightly outside the normal recording radius, what neuroscientists
*  sometimes refer to as the hash of activity, the other stuff that's going on. And you can look at
*  sort of across many channels how that sort of background noise is behaving, and you might be
*  able to get more juice out of the signal that way. But it comes at a cost. That signal is now a
*  floating point representation, which means it's more expensive to send out over power. It means you
*  have to find different ways to compress it that are different than what you can apply to binary
*  signals. So there's a lot of different challenges associated with these different modalities.
*  So also in terms of communication, you're limited by the amount of data you can send.
*  Yeah.
*  And so, and also because you're currently using the Bluetooth protocol, you have to batch stuff
*  together. But you have to also do this, keeping the latency crazy low, like crazy low. Anything
*  to say about the latency? Yeah, this is a passion project of mine. So I want to build the best mouse
*  in the world. I don't want to build like the, you know, the Chevrolet Spark or whatever of
*  electric cars. I want to build like the Tesla Roadster version of a mouse. And I really do
*  think it's quite possible that within, you know, five to 10 years that most esports competitions
*  are dominated by people with paralysis. This is like a very real possibility for a number of
*  reasons. One is that they'll have access to the best technology to play video games effectively.
*  The second is they have the time to do so. So those two factors together are particularly potent
*  for esport competitors. Unless people without paralysis are also allowed to play.
*  Which is, it is another way to interact with a digital device. And there's something to that.
*  If it's a fundamentally different experience, more efficient experience, even if it's not like some
*  kind of full on high bandwidth communication, if it's just the ability to move the mouse,
*  10x faster, like the bits per second. If I can achieve a bits per second, the 10x, what I can
*  do with the mouse, that's a really interesting possibility of what they can do. Especially as
*  you get really good at it with training. It's definitely the case that you have a higher ceiling
*  performance. Because you don't have to buffer your intention through your arm, through your muscle,
*  you get just by nature of having a brain implant at all, like 75 millisecond lead time on any
*  action that you're actually trying to take. And there's some nuance to this. There's evidence
*  that the motor cortex, you can sort of plan out sequences of actions. So you may not get that whole
*  benefit all the time. But for a sort of like reaction time style games, where you just want
*  to, somebody's over here, snipe them, you know, that kind of thing. You actually do have just an
*  inherent advantage because you don't need to go through muscle. So the question is just how much
*  faster can you make it? And we're already, you know, faster than, you know, what you would do if
*  you're going through muscle from a latency point of view. And we're in the early stages of that.
*  I think we can push it sort of our end to end latency right now from brain spike to cursor
*  movement is about 22 milliseconds. If you think about the best mice in the world, the best gaming
*  mice, that's about five milliseconds ish of latency, depending on how you measure, depending
*  how fast your screen refreshes. There's a lot of characteristics that matter there. But yeah,
*  and the rough time for like a neuron in the brain to actually impact your command of your hand is
*  about 75 milliseconds. So if you look at those numbers, you can see that we're already like,
*  you know, competitive and slightly faster than what you'd get by actually moving your hand.
*  And this is something that, you know, if you ask Nolan about it, when he moved the cursor for the
*  first time, we asked him about this. It was something I was super curious about. Like,
*  what does it feel like when you're modulating, you know, a click intention or when you're trying
*  to move the cursor to the right? He said it moves before he is like actually intending it to,
*  which is kind of a surreal thing and something that, you know, I would love to experience myself
*  one day. What is that like to have that thing just be so immediate, so fluid that it feels like it's
*  happening before you're actually intending it to move?
*  Yeah, I suppose we've gotten used to that latency, that natural latency that happens.
*  So is the currently the bottleneck to communication. So like the Bluetooth
*  communication is that what's the actual bottleneck? I mean, there's always going
*  to be a bottleneck. What's the current bottleneck? Yeah, a couple things. So kind of hilariously,
*  Bluetooth low energy protocol has some restrictions on how fast you can communicate.
*  So the protocol itself establishes a standard of, you know, the most frequent sort of updates you
*  can send are on the order of 7.5 milliseconds. And as we push latency down to the level of
*  sort of individual spikes impacting control, that level of resolution, that kind of protocol is
*  going to become a limiting factor at some scale. Another sort of important nuance to this is that
*  it's not just the neural link itself that's part of this equation. If you start pushing latency
*  sort of below the level of how fast screens refresh, then you have another problem. You need
*  your whole system to be able to be as reactive as the sort of limits of what the technology can
*  offer. Like you need the screen, like 120 Hertz just doesn't work anymore if you're trying to
*  have something respond at something that's at the level of one millisecond.
*  That's a really cool challenge. I also like that for a t-shirt, the best mouse in the world.
*  Tell me on the receiving end, so the decoding step, now we figured out what the spikes are,
*  got them all together, now we're sending that over to the app. What's the decoding step look like?
*  Yeah, so maybe first, what is decoding? I think there's probably a lot of folks listening that
*  just have no clue what it means to decode brain activity. Actually, even if we zoom out beyond
*  that, what is the app? So there's an implant that's wirelessly communicating with any digital
*  device that has an app installed. So maybe can you tell me at high level what the app is,
*  what the software is outside of the brain? Yeah, so maybe working backwards from the goal,
*  the goal is to help someone with paralysis, in this case, Nolan, be able to navigate his
*  computer independently. And we think the best way to do that is to offer them the same tools that
*  we have to navigate our software, because we don't want to have to rebuild an entire
*  software ecosystem for the brain, at least not yet. Maybe someday you can imagine there's UXs
*  that are built natively for BCI. But in terms of what's useful for people today, I think most
*  people would prefer to be able to just control mouse and keyboard inputs to all the applications
*  that they want to use for their daily jobs, for communicating with their friends, etc.
*  And so the job of the application is really to translate this wireless stream of brain data
*  coming off the implant into control of the computer. And we do that by essentially building
*  a mapping from brain activity to sort of the HID inputs to the actual hardware. So HID is just the
*  protocol for communicating like input device events. So for example, move mouse to this position,
*  or press this key down. And so that mapping is fundamentally what the app is responsible for.
*  But there's a lot of nuance of how that mapping works. We spend a lot of time to try to get right,
*  and we're still in the early stages of a long journey to figure out how to do that optimally.
*  So one part of that process is decoding. So decoding is this process of taking the statistical
*  patterns of brain data that's being channeled across this Bluetooth connection to the application
*  and turning it into, for example, a mouse movement. And that decoding step, you can think of it in a
*  couple different parts. So similar to any machine learning problem, there's a training step,
*  and there's an inference step. The training step in our case is a very intricate behavioral
*  process where the user has to imagine doing different actions. So for example, there will
*  be presented a screen with a cursor on it, and they'll be asked to push that cursor to the right.
*  Then imagine pushing that cursor to the left, push it up, push it down. And we can basically build up
*  a pattern or using any sort of modern ML method of mapping of given this brain data, and then
*  imagine behavior, map one to the other. And then at test time, you take that same pattern matching
*  system. In our case, it's a deep neural network, and you run it and you take the live stream of
*  brain data coming off their implant, you decode it by pattern matching to what you saw at calibration
*  time, and you use that for control of the computer. Now, a couple rabbit holes that I think are quite
*  interesting. One of them has to do with how you build that best template matching system, because
*  there's a variety of behavioral challenges and also debugging challenges when you're working
*  with someone who's paralyzed. Because again, fundamentally, you don't observe what they're
*  trying to do. You can't see them attempt to move their hand. And so you have to figure out a way to
*  instruct the user to do something and validate that they're doing it correctly, such that then
*  you can downstream build with confidence the mapping between the neural spikes and the intended
*  action. And by doing the action correctly, what I really mean is at this level of resolution of
*  what neurons are doing. So if in ideal world, you could get a signal of behavioral intent,
*  that is ground truth accurate at the scale of sort of one millisecond resolution, then with high
*  confidence, I could build a mapping from my neural spikes to that behavioral intention.
*  But the challenge is, again, that you don't observe what they're actually doing. And so
*  there's a lot of nuance to how you build user experiences that give you more than just sort of
*  a course on average, correct representation of what the user is intending to do. If you want to
*  build the world's best mouse, you really want it to be as responsive as possible. You want to be
*  able to do exactly what the user is intending at every sort of step along the way, not just on
*  average be correct when you're trying to move it from left to right. And building a behavioral
*  calibration game or our sort of software experience that gives you that level of
*  resolution is what we spend a lot of time working on. So the calibration process, the interface
*  has to encourage precision, being like whatever it does, it should be super intuitive that the next
*  thing the human is going to likely do is exactly that intention that you need, and only that
*  intention. And you don't have any feedback except that may be speaking to you afterwards
*  what they actually did. You can't, oh yeah. So that's fundamentally, that is a really exciting
*  UX challenge because that's all on the UX. It's not just about being friendly or nice or usable.
*  Yeah. User experience is how it works.
*  It's how it works for the calibration. And calibration, at least at this stage of Neuralink,
*  is like fundamental to the operation of the thing. And not just calibration,
*  but continued calibration essentially. Yeah.
*  And maybe you said something that I think is worth exploring there a little bit. You said it's
*  primarily a UX challenge. And I think a large component of it is, but there is also a very
*  interesting machine learning challenge here, which is given some data set, including some on average
*  correct behavior of asking the user to move up or move down, move right, move left. And given
*  a data set of neural spikes, is there a way to infer in some kind of semi-supervised or entirely
*  unsupervised way what that high resolution version of their intention is? And if you think about it,
*  there probably is because there are enough data points in the data set, enough constraints on
*  your model, that there should be a way with the right sort of formulation to let the model figure
*  out itself. For example, at this millisecond, this is exactly how hard they're pushing upwards.
*  And at this millisecond, this is how hard they're trying to push upwards.
*  It's really important to have very clean labels. Yes. So like the problem becomes much harder from
*  the machine learning perspective, the labels are noisy. That's correct. And then to get the clean
*  labels, that's a UX challenge. Correct. Although clean labels, I think maybe it's worth exploring
*  what that exactly means. I think any given labeling strategy will have some number of assumptions it
*  makes about what the user is attempting to do. Those assumptions can be formulated in a loss
*  function, or they can be formulated in terms of heuristics that you might use to just try to
*  estimate or guesstimate what the user is trying to do. And what really matters is how accurate
*  those assumptions. For example, you might say, hey, user, push upwards and follow the speed of
*  this cursor. And your heuristic might be that they're trying to do exactly what that cursor is
*  trying to do. Another competing heuristic might be they're actually trying to go slightly faster at
*  the beginning of the movement and slightly slower at the end. And those competing heuristics may or
*  may not be accurate reflections of what the user is trying to do. Another version of the task might
*  be, hey, user, imagine moving this cursor a fixed offset. So rather than follow the cursor, just try
*  to move it exactly 200 pixels to the right. So here's the cursor, here's the target. Okay,
*  cursor disappears, try to move that now invisible cursor 200 pixels to the right. And the assumption
*  in that case would be that the user can actually modulate correctly that position offset. But that
*  position offset assumption might be a weaker assumption. And therefore, potentially, you can
*  make it more accurate than these heuristics that are trying to guesstimate at each millisecond what
*  the user is trying to do. So you can imagine different tasks that make different assumptions
*  about the nature of the user intention. And those assumptions being correct is what I would think
*  of as a clean label. For that step, what are we supposed to be visualizing? There's a cursor,
*  and you want to move that cursor to the right or the left, up and down, or maybe move them by a
*  certain offset. So that's one way. Is that the best way to do calibration? So for example,
*  an alternative crazy way that probably is playing a role here is a game like WebGrid.
*  Where you're just getting a very large amount of data, the person playing a game,
*  where if they are in a state of flow, maybe you can get clean signal as a side effect.
*  Or is that not an effective way for initial calibration?
*  Yeah, great question. There's a lot to unpack there. So the first thing I would draw a distinction
*  between is sort of open loop first, closed loop. So open loop, what I mean by that is the user is
*  going from zero to one. They have no model at all, and they're trying to get to the place where they
*  have some level of control at all. In that setup, you really need to have some task that gives the
*  user a hint of what you want them to do, such that you can build its mapping again from brain data
*  to output. Then once they have a model, you could imagine them using that model and actually adapting
*  to it and figuring out the right way to use it themselves, and then retraining on that data to
*  give you a boost in performance. There's a lot of challenges associated with both of these techniques,
*  and we can sort of wrap it all into both of them if you're interested. But the challenge with the
*  open loop task is that the user themselves doesn't get proprioceptive feedback about what they're
*  doing. They don't necessarily perceive themselves or feel the mouse under their hand when they're
*  using an open loop or when they're trying to do an open loop calibration. They're being asked to
*  perform something. Imagine if you had your whole right arm numbed and you stuck it in a box,
*  and you couldn't see it. So you had no visual feedback and you had no proprioceptive feedback
*  about what the position or activity of your arm was. And now you're asked, okay, given this thing
*  on the screen that's moving from left to right, match that speed. And you basically can try your
*  best to invoke whatever that imagined action is in your brain that's moving the cursor from left to
*  right. But in any situation, you're going to be inaccurate and maybe inconsistent in how you do
*  that task. And so that's sort of the fundamental challenge of open loop. The challenge with closed
*  loop is that once the user is given a model and they're able to start moving the mouse on their
*  own, they're going to very naturally adapt to that model. And that co-adaptation between the model
*  learning what they're doing and the user learning how to use the model may not find you the best
*  global minima. It may be that your first model was noisy in some ways, or maybe just had some
*  like quirk. There's some like part of the data distribution it didn't cover super well. And the
*  user now figures out because they're a brilliant user like Nolan, they figure out the right
*  sequence of imagined motions or the right angle they have to hold their hand at to get it to work.
*  And they'll get it to work great. But then the next day they come back to their device,
*  and maybe they don't remember exactly all the tricks that they used the previous day. And so
*  there's a complicated sort of feedback cycle here that can emerge and can make it a very difficult
*  debugging process. Okay, there's a lot of really fascinating things there. Yeah, actually just to
*  stay on the closed loop. I've seen situations, this actually happened watching psychology
*  grad students, they use pieces of software when they don't know how to program themselves. They
*  use pieces of software that somebody else wrote, and it has a bunch of bugs. And they figure out
*  like, and they've been using it for years. They figure out ways to work around it. Oh, that just
*  happens. Nobody considers maybe we should fix this, they just adapt. And that's a really
*  interesting notion that we're really good at adapting. But you need to still, that might not
*  be the optimal. Okay, so how do you solve that problem? Do you have to restart from scratch every
*  once in a while kind of thing? Yeah, it's a good question. First and foremost, I would say this is
*  not a solved problem. And for anyone who's listening in academia who works on BCIs, I would also say
*  this is not a problem that's solved by simply scaling channel count. So this is, you know,
*  maybe that can help and you can get sort of richer covariance structures that you can use to exploit
*  when trying to come up with good labeling strategies. But if you're interested in
*  problems that aren't going to be solved inherently by scaling channel count, this is one of them.
*  Yeah, so how do you solve it? It's not a solved problem. That's the first thing I want to make
*  sure it gets across. The second thing is any solution that involves closed loop is going
*  to become a very difficult debugging problem. And one of my sort of general heuristics for
*  choosing what problems to tackle is that you want to choose the one that's going to be the
*  easiest to debug. Because if you can do that, even if the ceiling is lower, you're going to
*  be able to move faster because you have a tighter iteration loop debugging the problem. And in the
*  open loop setting, there's not a feedback cycle to debug with the user in the loop. And so there's
*  some reason to think that that should be an easier debugging problem. The other thing that's worth
*  understanding is that even in a closed loop setting, there's no special software magic of
*  how to infer what the user is truly attempting to do. In a closed loop setting, although they're
*  moving the cursor on the screen, they may be attempting something different than what your
*  model is outputting. So what the model is outputting is not a signal that you can use to retrain if you
*  want to be able to improve the model further, you still have this very complicated guesstimation or
*  unsupervised problem of figuring out what is the true user intention underlying that signal.
*  And so the open loop problem has the nice property of being easy to debug. And the second nice
*  property of it has all the same information content as the closed loop scenario.
*  Another thing I want to mention and call out is that this problem doesn't need to be solved in
*  order to give useful control to people. Even today with the solutions we have now, and that
*  academia has built up over decades, the level of control that can be given to a user today is
*  quite useful. It doesn't need to be solved to get to that level of control. But again, I want to
*  build the world's best mouse. I want to make it so good that it's not even a question that you want
*  it. And to build the world's best mouse, the superhuman version, you really need to
*  nail that problem. And a couple maybe details of previous studies that we've done internally
*  that I think are very interesting to understand when thinking about how to solve this problem.
*  The first is that even when you have ground truth data of what the user is trying to do,
*  and you can get this with an able-bodied monkey, a monkey that has a neural link device implanted
*  and moving a mouse to control a computer, even with that ground truth data set,
*  it turns out that the optimal thing to predict to produce high performance BCI is not just the
*  direct control of the mouse. You can imagine building a data set of what's going on in the
*  brain and what is the mouse exactly doing on the table. And it turns out that if you build the
*  mapping from neural spikes to predict exactly what the mouse is doing, that model will perform
*  worse than a model that is trained to predict higher level assumptions about what the user
*  might be trying to do. For example, assuming that the monkey is trying to go in a straight line to
*  the target. It turns out that making those assumptions is actually more effective in
*  producing a model than actually predicting the underlying hand movement.
*  So the intention, not like the physical movement or whatever. There's obviously a very strong
*  correlation between the two, but the intention is a more powerful thing to be chasing.
*  Well, that's also super interesting. I mean, the intention itself is fascinating because, yes,
*  with the BCI here, in this case with the digital telepathy, you're acting on the intention,
*  not the action, which is why there's an experience of feeling like it's happening before you meant
*  for it to happen. That is so cool. And that is why you could achieve superhuman performance probably
*  in terms of the control of the mouse. So for OpenLoop, just to clarify, so whenever the
*  person is tasked to move the mouse to the right, you said there's not feedback. So
*  they don't get to get that satisfaction of actually getting it to move.
*  So you could imagine giving the user feedback on a screen, but it's difficult because at this
*  point you don't know what they're attempting to do. So what can you show them that would basically
*  give them a signal of, I'm doing this correctly or not correctly? So let's take this very specific
*  example. Maybe your calibration task looks like you're trying to move the cursor a certain position
*  offset. So your instructions to the user are, hey, the cursor is here. Now, when the cursor disappears,
*  imagine moving it 200 pixels from where it was to the right to be over this target.
*  In that kind of scenario, you could imagine coming up with some sort of consistency metric
*  that you could display to the user of, okay, I know what the spike train looks like on average
*  when you do this action to the right. Maybe I can produce some sort of probabilistic estimate of
*  how likely is that to be the action you took given the latest trial or trajectory that you imagined.
*  And that could give the user some sort of feedback of how consistent are they across different
*  trials. You could also imagine that if the user is prompted with that kind of consistency metric,
*  that maybe they just become more behaviorally engaged to begin with because the task is kind
*  of boring when you don't have any feedback at all. And so there may be benefits to the user
*  experience of showing something on the screen, even if it's not accurate, just because it keeps
*  the user motivated to try to increase that number or push it upwards. So there's a psychology element
*  here. Yeah, absolutely. And again, all of that is UX challenge. How much signal drift is there?
*  Hour to hour, day to day, week to week, month to month. How often do you have to recalibrate
*  because of the signal drift? Yeah. So this is a problem we've worked on both with NHP,
*  non-human primates, before our clinical trial, and then also with Noland during the clinical trial.
*  Maybe the first thing that we're stating is what the goal is here. So the goal is really to enable
*  the user to have a plug and play experience where, I guess they don't have to plug anything in,
*  but a play experience where they can use the device whenever they want to, however they want
*  to. And that's really what we're aiming for. And so there can be a set of solutions that get to that
*  state without considering this non-stationarity problem. So maybe the first solution here that's
*  important is that they can recalibrate whenever they want. This is something that Noland has the
*  ability to do today. So he can recalibrate the system at 2 AM in the middle of the night without
*  his caretaker or parents or friends around to help push a button for him. The other important
*  part of the solution is that when you have a good model calibrated, that you can continue using that
*  without needing to recalibrate it. So how often he has to do this recalibration today depends really
*  on his appetite for performance. We observe a degradation through time of how well any
*  individual model works, but this can be mitigated behaviorally by the user adapting their control
*  strategy. It can also be mitigated through a combination of software features that we provide
*  to the user. For example, we let the user adjust exactly how fast the cursor is moving. We call
*  that the gain, for example, the gain of how fast the cursor reacts to any given input intention.
*  They can also adjust the smoothing, how smooth the output of that cursor intention actually is.
*  They can also adjust the friction, which is how easy is it to stop and hold still. And all these
*  software tools allow the user a great deal of flexibility and troubleshooting mechanisms to be
*  able to solve this problem for themselves. By the way, all this is done by looking to the right side
*  of the screen, selecting the mixer and the mixer you have. It's like DJ mode, DJ mode for your VCI.
*  I mean, it's a really well done interface. It's really, really well done. And so yeah, there's
*  that bias that there's a cursor drift that Nolan talked about in a stream. Although he said that
*  you guys were just playing around with it with him and they're constantly improving. So that
*  could have been just a snapshot of that particular moment, a particular day. But he said that there
*  was this cursor drift and this bias that could be removed by him, I guess, looking to the right
*  side of the screen, the left side of the screen to kind of adjust the bias. That's one interface
*  action, I guess, to adjust the bias. Yeah. So this is actually an idea that comes out of academia.
*  There was some prior work with sort of BrainGate clinical trial participants where they pioneered
*  this idea of bias correction. The way we've done it, I think is, yeah, it's very prioritized,
*  very beautiful user experience where the user can essentially flash the cursor over to the
*  side of the screen and it opens up a window where they can actually sort of adjust or tune exactly
*  the bias of the cursor. So bias maybe for people who aren't familiar is just sort of what is the
*  default motion of the cursor if you're imagining nothing. And it turns out that that's one of the
*  first sort of qualia of the cursor control experience that's impacted by neural non-stationarity.
*  Qualia of the cursor experience. I don't know how else to describe it. Like, you know,
*  I'm not the guy moving things. It's very poetic. I love it. The quality of the cursor experience.
*  Yeah. I mean, it's not as poetic, but it is deeply true. There is an experience. When it works well,
*  it is a joyful, a really pleasant experience. And when it doesn't work well, it's a very
*  frustrating experience. That's actually the art of UX. It's like you have the possibility to frustrate
*  people or the possibility to give them joy. And at the end of the day, it really is truly the case
*  that UX is how the thing works. And so it's not just like what's showing on the screen. It's also,
*  you know, what control surfaces does a decoder provide the user? Like we want them to feel like
*  they're in the F1 car, not like the, you know, some like mini van, right? And that really truly is how
*  we think about it. Nolan himself is an F1 fan. So we refer to ourselves as a pit crew. He really is
*  truly the F1 driver. And there's different, you know, control surfaces that different kinds of
*  cars and airplanes provide the user. And we take a lot of inspiration from that when designing how
*  the cursor should behave. And maybe one nuance of this is, you know, even details like when you move
*  a mouse on a MacBook trackpad, the sort of response curve of how that input that you give the trackpad
*  translates to cursor movement is different than how it works with a mouse. When you move on the
*  trackpad, there's a different response function, a different curve to how much a movement translates
*  to input to the computer than when you do it physically with a mouse. And that's because
*  somebody sat down a long time ago when they're designing the initial input systems to any computer
*  and they thought through exactly how it feels to use these different systems. And now we're
*  designing sort of the next generation of this input system to a computer, which is entirely done via
*  the brain. And there's no proprioceptive feedback. Again, you don't feel the mouse in your hand.
*  You don't feel the keys under your fingertips. And you want a control surface that still makes it
*  easy and intuitive for the user to understand the state of the system and how to achieve what they
*  want to achieve. And ultimately, the end goal is that that UX is completely fades into the background
*  and becomes something that's so natural and intuitive that it's subconscious to the user.
*  And they just should feel like they have basically direct control over the cursor,
*  just does what they want it to do. They're not thinking about the implementation of how to make
*  it do what they want it to do. It's just doing what they want it to do. Is there some kind of
*  things along the lines of like Fitts' law where you should move the mouse in a certain kind of
*  way that maximizes your chance to hit the target? I don't even know what I'm asking,
*  but I'm hoping the intention of my question will land on a profound answer. No. Is there some
*  kind of understanding of the laws of UX when it comes
*  to the context of somebody using their brain to control it? Like that's different than actual
*  with a mouse. I think we're in the early stages of discovering those laws. So I wouldn't claim to
*  have solved that problem yet, but there's definitely some things we've learned that make it easier for
*  the user to get stuff done. And it's pretty straightforward when you verbalize it, but it
*  takes a while to actually get to that point when you're in the process of debugging the stuff in
*  the trenches. One of those things is that any machine learning system you build has some number
*  of errors. And it matters how those errors translate to the downstream user experience.
*  For example, if you're developing a search algorithm in your photos, if you search for
*  your friend Joe and it pulls up a photo of your friend Josephine, maybe that's not a big deal,
*  because the cost of an error is not that high. In a different scenario where you're trying to
*  detect insurance fraud or something like this, and you're directly sending someone to court
*  because of some machine learning model output, then the errors make a lot more sense to be
*  careful about. You want to be very thoughtful about how those errors translate to downstream
*  effects. The same is true in BCI. So for example, if you're building a model that's decoding a
*  velocity output from the brain versus an output where you're trying to modulate the left click,
*  for example, these have sort of different trade-offs of how precise you need to be before
*  it becomes useful to the end user. For velocity, it's okay to be on average correct because the
*  output of the model is integrated through time. So if the user is trying to click at position
*  A and they're currently in position B, they're trying to navigate over time to get between those
*  two points. And as long as the output of the model is on average correct, they can sort of
*  steer it through time with the user control loop in the mix, they can get to the point they want
*  to get to. The same is not true of a click. For a click, you're performing it almost instantly
*  at the scale of neurons firing. And so you want to be very sure that that click is correct because
*  a false click can be very destructive to the user. They might accidentally close the tab that they're
*  trying to do something and lose all their progress. They might accidentally hit some
*  send button on some text that is only half composed and reads funny after.
*  So there's different sort of cost functions associated with errors in this space. And part
*  of the UX design is understanding how to build a solution that is, when it's wrong, still useful
*  to the end user. That's so fascinating, assigning cost to every action when an error occurs. So
*  every action, if an error occurs, has a certain cost. And incorporating that into how you
*  interpret the intention, mapping it to the action is really important. I didn't quite, until you
*  said it, realize there's a cost to sending the text early. It's like a very expensive cost.
*  It's super annoying. If you accidentally, like if you're a cursor, imagine if your cursor
*  misclicked every once in a while. That's like super obnoxious. And the worst part of it is,
*  usually when the user's trying to click, they're also holding still because they're over the target
*  they want to hit and they're getting ready to click. Which means that in the data sets that we
*  build, on average, is the case that sort of low speeds or desire to hold still is correlated with
*  when the user's attempting to click. Wow, that is really fascinating.
*  It's also not the case, you know, people think that, oh, a click is a binary signal. This must
*  be super easy to decode. Well, yes, it is. But the bar is so much higher for it to become a useful
*  thing for the user. And there's ways to solve this. I mean, you can sort of take the compound
*  approach of, well, let's just give the, like, let's take five seconds to click. Let's take a
*  huge window of time so we can be very confident about the answer. But again, world's best mouse,
*  the world's best mouse doesn't take a second to click or 500 milliseconds to click. It takes five
*  milliseconds to click or less. And so if you're aiming for that kind of high bar, then you really
*  want to solve the underlying problem. So maybe this is a good place to ask about how to measure
*  performance, this whole bits per second. What, can you like explain what you mean by that? Maybe a
*  good place to start is to talk about web grid as a game as a good illustration of the measurement
*  of performance. Yeah, maybe I'll take one zoom out step there, which is just explaining why
*  we care to measure this at all. So again, our goal is to provide the user the ability to control the
*  computer as well as I can, and hopefully better. And that means that they can do it at the same
*  speed as what I can do. It means that they have access to all the same functionality that I have,
*  including all those little details like command tab, command space, you know, all this stuff,
*  and you'd be able to do it with their brain and with the same level of reliability is what I can
*  do with my muscles. And that's a high bar. And so we intend to measure and quantify every aspect of
*  that to understand how we're progressing towards that goal. There's many ways to measure BPS,
*  by the way, this isn't the only way, but we present the user a grid of targets and basically we
*  compute a score, which is dependent on how fast and accurate they can select and then how small
*  are the targets. And the more targets that are on the screen, the smaller they are, the more
*  information you present per click. And so if you think about it from information theory point of
*  view, you can communicate across different information theoretic channels. And one such
*  channel is a typing interface, you could imagine that's built out of a grid, just like that software
*  keyboard on the screen. And bits per second is a measure that's computed by taking the log of the
*  number of targets on the screen. You can subtract one if you care to model a keyboard because you
*  have to subtract one for the delete key on the keyboard, but log of the number of targets on the
*  screen times the number of correct selections minus incorrect divided by some time window,
*  for example, 60 seconds. And that's sort of the standard way to measure a cursor control task in
*  academia. And all credit in the world goes to this great professor, Dr. Shanoi of Stanford,
*  who came up with that task. And he's also one of my inspirations for being in the field. So
*  all the credit in the world to him for coming up with a standardized metric to facilitate this
*  kind of bragging rights that we have now to say that no one is the best in the world at this task
*  with this BCI. It's very important for progress that you have standardized metrics that people
*  can compare across different techniques and approaches, how well does this do? So yeah,
*  big kudos to him and to all the team at Stanford. Yeah, so for Noland and for me playing this task,
*  there's also different modes that you can configure this task. So the web grid task
*  can be presented as just sort of a left click on the screen, or you could have targets that you just
*  dwell over, or you could have targets that you left right click on. You could have targets that
*  are left right click, middle click, scrolling, clicking and dragging. You can do all sorts of
*  things within this general framework. But the simplest, purest form is just blue targets show
*  up on the screen, blue means left click. That's the simplest form of the game.
*  And the sort of prior records here in academic work and at Neuralink internally with sort of NHPs
*  have all been matched or beaten by Noland with his Neuralink device. So sort of prior to Neuralink,
*  the sort of world record for a human using device is somewhere between 4.2 to 4.6 BPS,
*  depending on exactly what paper you read and how you interpret it. Noland's current record is 8.5
*  BPS. And again, this sort of median Neuralink performance is 10 BPS. You can think of it roughly
*  as he's 85% the level of control of a median Neuralink are using their cursor to select blue
*  targets on the screen. And yeah, I think there's a very interesting journey ahead to get us to that
*  same level of 10 BPS performance. It's not the case that sort of the tricks that got us from,
*  you know, four to six BPS, and then six to eight BPS are going to be the ones that get us from eight
*  to 10. And in my view, the core challenge here is really the labeling problem. It's how do you
*  understand at a very, very fine resolution what the user is attempting to do. And yeah,
*  I highly encourage folks in academia to work on this problem. What's the journey with Noland on
*  that quest of increasing the BPS on WebGrid? In March, you said that he selected 89,285 targets
*  in WebGrid. So he loves this game. He's really serious about improving his performance in this
*  game. So what is the journey of trying to figure out how to improve that performance? How much
*  can that be done on the decoding side? How much can that be done on the calibration side? How much
*  can that be done on the Noland side of like figuring out how to convey his intention more
*  cleanly? Yeah, no, this is a great question. So in my view, one of the primary reasons why
*  Noland's performance is so good is because of Noland. Noland is extremely focused and very
*  energetic. He'll play WebGrid sometimes for like four hours in the middle of the night, like from
*  2 a.m. to 6 a.m. he'll be playing WebGrid just because he wants to push it to the limits of what
*  he can do. And this is not us asking him to do that. I want to be clear. We're not saying,
*  hey, you should play WebGrid tonight. We just gave him the game as part of our research and he is
*  able to play independently and practice whenever he wants. And he really pushes hard to push it,
*  the technology to the absolute limit. And he views that as his job really to make us be the
*  bottleneck. And boy, has he done that well. And so the first thing to acknowledge is that he is
*  extremely motivated to make this work. I've also had the privilege to meet other clinical trial
*  participants from BrainGate and other trials and they very much share the same attitude. They view
*  this as their life's work to advance the technology as much as they can. And if that means selecting
*  targets on the screen for four hours from 2 a.m. to 6 a.m., then so be it. And there's something
*  extremely admirable about that that's worth calling out. Okay. So now how do you get from
*  where he started, which is no cursor control to APPS? So when he started, there's a huge amount
*  of learning to do on his side and our side to figure out what's the most intuitive control for
*  him. And the most intuitive control for him is you have to find the set intersection of what do we
*  have the signal to decode. So we don't pick up every single neuron in the motor cortex, which
*  means we don't have representation for every part of the body. So there may be some signals that we
*  have better sort of decode performance on than others. For example, on his left hand, we have a
*  lot of difficulty distinguishing his left ring finger from his left middle finger. But on his
*  right hand, we have good control and good modulation detected from the neurons we're able to record for
*  his pinky and his thumb and his index finger. So you can imagine how these different subspaces of
*  modulated activity intersect with what's the most intuitive for him. And this has evolved over time.
*  So once we gave him the ability to calibrate models on his own, he was able to go and explore
*  various different ways to imagine controlling the cursor. For example, he can imagine controlling
*  the cursor by wiggling his wrist side to side, or by moving his entire arm by one point into his
*  feet. You know, he tried like a whole bunch of stuff to explore the space of what is the most
*  natural way for him to control the cursor that at the same time, it's easy for us to decode.
*  Just to clarify, it's through the body mapping procedure there, you're able to figure out
*  which finger he can move. Yes, yes, that's one way to do it. Maybe one nuance of when he's doing
*  he can imagine many more things than we represent in that visual on the screen. So we show him sort
*  of abstractly, here's a cursor, you figure out what works the best for you. And we obviously
*  have hints about what will work best from that body mapping procedure of, you know, we know that this
*  particular action we can represent well, but it's really up to him to go and explore and figure out
*  what works the best. But at which point does he no longer visualize the movement of his body and
*  it's just visualizing the movement of the cursor? Yeah. How quickly does he go from, how quickly does
*  it get there? So this happened on a Tuesday. I remember this day very clearly because at some
*  point during the day, it looked like he wasn't doing super well, it looked like the model wasn't
*  performing super well and he was like getting distracted, but he actually, it wasn't the case.
*  Like what actually happened was he was trying something new where he was just controlling the
*  cursor. So he wasn't imagining moving his hand anymore. He was just imagining, I don't know what
*  it is, some like abstract intention to move the cursor on the screen. And I cannot tell you what
*  the difference between those two things are. I really truly cannot. He's tried to explain it to
*  me before. I cannot give a first person account of what that's like, but the expletives that he
*  uttered in that moment were enough to suggest that it was a very qualitatively different experience
*  for him to just have direct neural control over a cursor. I wonder if there's a way through UX
*  to encourage a human being to discover that because he discovered it, like you said to me
*  that he's a pioneer. So he discovered that on his own through all of this, the process of trying to
*  move the cursor with different kinds of intentions. But that is clearly a really powerful thing to
*  arrive at, which is to let go of trying to control the fingers and the hand and control the actual
*  digital device with your mind. That's right. UX is how it works. And the ideal UX is one that it's,
*  the user doesn't have to think about what they need to do in order to get it done. They just,
*  it just does it. That is so fascinating. But I wonder on the biological side,
*  how long it takes for the brain to adapt. Yeah. So is it just simply learning like high level
*  software or is there like a neuroplasticity component where like the brain is adjusting slowly?
*  Yeah. The truth is, I don't know. I'm very excited to see with sort of the second participant that
*  we implement what the journey is like for them, because we'll have learned a lot more. Potentially
*  we can help them understand and explore that direction more quickly. This is something I
*  didn't know. This wasn't me prompting Nolan to go try this. He was just exploring how to use his
*  device and figure it out himself. But now that we know that that's a possibility, that maybe there's
*  a way to, for example, hint the user, don't try super hard during calibration. Just do something
*  that feels natural or just directly control the cursor. Don't imagine explicit action.
*  And from there, we should be able to hopefully understand how this is for somebody who has not
*  experienced that before. Maybe that's the default mode of operation for them. You don't have to go
*  through this intermediate phase of explicit motions. Or maybe if that naturally happens
*  for people, you can just occasionally encourage them to allow themselves to move the cursor.
*  Actually, sometimes just like with the four minute mile, just the knowledge that that's possible.
*  Pushes you to do it. Yeah, it enables you to do it. And then it becomes trivial. And then it also
*  makes you wonder, this is the cool thing about humans. Once there's a lot more human participants,
*  they will discover things that are possible. Yes. And share their experiences.
*  Yeah. And share it. And then because of them sharing it, they'll be able to do it. All of a
*  sudden that's unlocked for everybody. Because just the knowledge sometimes is the thing that
*  enables it to do it. Yeah. Just coming on that too, we've probably tried a thousand different
*  ways to do various aspects of decoding. And now we know what the right subspace is to continue
*  exploring further. Again, thanks to Nolan and the many hours he's put into this. And so even just
*  that help constraints or the beam search of different approaches that we could explore
*  really helps accelerate for the next person the set of things that we'll get to try on day one,
*  how fast we hope to get them to useful control, how fast we can enable them to use it independently,
*  and to get value out of the system. So yeah, massive hats off to Nolan and all the participants
*  that came before him to make this technology a reality. So how often are the updates to the
*  decoder? Because Nolan mentioned like, okay, there's a new update that we're working on. And that
*  in the stream, he said he plays the snake game, because it's like super hard. It's a good way for
*  him to test like how good the update is. So and he says like, sometimes the update is a step backwards.
*  It's a constant like iteration. So how often like what does the update entail? Is it mostly on the
*  decoder side? Yeah, a couple comments. So one is it's probably worth drawing distinction between
*  sort of research sessions where we're actively trying different things to understand like what
*  the best approach is, versus sort of independent use where we want to have no ability to just go
*  use the device how anybody would want to use their MacBook. And so what he's referring to is I think
*  usually in the context of a research session where we're trying, you know, many, many different
*  approaches to, you know, even unsupervised approaches, like we talked about earlier to
*  try to come up with better ways to estimate his true intention, and more accurately decoded. And
*  in those scenarios, I mean, we try in any given session, he'll sometimes work for like eight
*  hours a day. And so that can be, you know, hundreds of different models that we would try in that day,
*  like a lot of different things. Now, it's also worth noting that we update the application he
*  uses quite frequently, I think, you know, sometimes up to like four or five times a day, we'll update
*  his application with different features or bug fixes or feedback that he's given us. So he's been
*  able to, he's a very articulate person who is part of the solution. He's not a complaining person.
*  He says, Hey, here's this thing that I've discovered is not optimal in my flow. Here's some ideas how
*  to fix it. Let me know what your thoughts are. Let's figure out how to solve it. And it often
*  happens that those things are addressed within, you know, a couple hours of him giving us his feedback.
*  That's the kind of iteration cycle we'll have. And so sometimes at the beginning of the session,
*  he'll give us feedback. And at the end of the session, he's giving us feedback on the next
*  iteration of that, of that, of that process or that setup. That's fascinating. Because one of the
*  things you mentioned that there was 271 pages of notes taken from the BCI sessions, and this was
*  just in March. So one of the amazing things about human beings that they can provide, especially
*  ones who are smart and excited, and all like positive and good vibes like Nolan, that they
*  can provide feedback, continuous feedback. Yeah, it also requires just to brag on the team a little
*  bit. I work with a lot of exceptional people, and it requires the team being absolutely laser
*  focused on the user and what will be the best for them. And it requires like a level of commitment
*  of, okay, this is what the user feedback was, I have all these meetings, we're going to skip
*  that today, and we're going to do this. You know, that level of focus commitment is, I would say,
*  under, underappreciated in the world. And also, you know, you obviously have to have the talent to
*  be able to execute on these things effectively. And yeah, we have that in loads. Yeah, and this
*  is such an interesting space of UX design, because you have, there's so many unknowns here.
*  And I can tell UX is difficult because of how many people do it poorly.
*  It's just not a trivial thing. Yeah, it's also, you know, UX is not something that you can
*  always solve by just constant iterating on different things. Like sometimes you really
*  need to step back and think globally, am I even like the right sort of minima to be chasing down
*  for a solution? Like there's a lot of problems in which sort of fast iteration cycle is the
*  predictor of how successful you will be. As a good example, like in a, in RL simulation, for example,
*  the more frequently you get reward, the faster you can progress. It's just an easier learning
*  problem, the more frequently you get feedback. But UX is not that way. I mean, users are actually
*  quite often wrong about what the right solution is. And it requires a deep understanding of the
*  technical system and what's possible combined with what the problem is you're trying to solve,
*  not just how the user expressed it, but what the true underlying problem is to actually get to the
*  right place. Yeah, that's the old like stories of Steve Jobs, like rolling in there, like,
*  yeah, the user is a good, is a useful signal, but it's not a perfect signal. And sometimes you have
*  to remove the floppy disk drive or whatever the, I forgot all the crazy stories of Steve Jobs,
*  like making wild design decisions, but there some, some of his aesthetic
*  that some of it is about the love you put into the design, which is very much a Steve Jobs,
*  Johnny Ive type thing. But when you have a human being using their brain to interact with it,
*  also is deeply about function. It's not just aesthetic. And that you have to empathize
*  with a human being before you while not always listening to them directly.
*  Like you have to deeply empathize. It's fascinating. It's really, really fascinating.
*  And at the same time, iterate, right? But not iterate in small ways, sometimes a complete,
*  like rebuilding the design. He said that Nolan said the early days, the UX sucked,
*  but you improved quickly. What was that journey like?
*  Yeah. I mean, I'll give you one concrete example. So he really wanted to be able to read manga.
*  This is something that he, I mean, it sounds like a simple thing, but it's actually a really big
*  deal for him. And he couldn't do it with this mouse stick. It just, it wasn't accessible.
*  You can't scroll with a mouse stick on his iPad and on the website that he wanted to be able to
*  use to read the newest manga. And so-
*  Might be a good quick pause to say the mouth stick is the thing he's using,
*  holding a stick in his mouth to scroll on a tablet.
*  Right. Yeah. It's basically, you can imagine it's a stylus that you hold between your teeth.
*  Yeah.
*  It's basically a very long stylus.
*  And it's exhausting. It hurts and it's inefficient.
*  Yeah. And maybe it's also worth calling out, there are other alternative assistive technologies, but
*  that particular situation Nolan's in, and this is not uncommon, and I think it's also not well
*  understood by folks, is that he's relatively spastic. So he'll have muscle spasms from time
*  to time. And so any assistive technology that requires him to be positioned directly in front
*  of a camera, for example, an eye tracker or anything that requires him to put something in his mouth,
*  just as a no-go, because he'll either be shifted out of frame when he has a spasm,
*  or if he has something in his mouth, it'll stab him in the face if he spasms too hard.
*  So these kinds of considerations are important when thinking about what advantages a PCI has
*  in someone's life. If it fits ergonomically into your life in a way that you can use it
*  independently when your caretaker is not there, wherever you want to, either in the bed or in the
*  chair, depending on your comfort level and your desire to have pressure sores, all these factors
*  matter a lot in how good the solution is in that user's life. So one of these very fun examples is
*  scroll. So again, Manga is something he wanted to be able to read. And there's many ways to do scroll
*  with a PCI. You can imagine different gestures, for example, the user could do that would move the
*  page. But scroll is a very fascinating control surface because it's a huge thing on the screen
*  in front of you. So any sort of jitter in the model output, any sort of error in the model output,
*  causes like an earthquake on the screen. You really don't want to have your Manga page that
*  you're trying to read be shifted up and down a few pixels just because your scroll decoder is not
*  completely accurate. And so this was an example where we had to figure out how to formulate the
*  problem in a way that the errors of the system, whenever they do occur, and we'll do our best to
*  minimize them, whenever those errors do occur, that it doesn't interrupt the qualia again,
*  of the experience that the user is having, it doesn't interrupt their flow of reading their
*  book. And so what we ended up building is this really brilliant feature. This is a teammate named
*  Bruce who worked on this really brilliant work called quick scroll. And quick scroll basically
*  looks at the screen and it identifies where on the screen are scroll bars. And it does this by deeply
*  integrating with Mac OS to understand where are the scroll bars actively present on the screen
*  using the sort of accessibility tree that's available to Mac OS apps. And we identified
*  where those scroll bars are and provided a BCI scroll bar. And the BCI scroll bar looks similar
*  to a normal scroll bar, but it behaves very differently in that once you sort of move over
*  to it, your cursor sort of morphs onto it. It sort of attaches or latches onto it. And then once you
*  push up or down in the same way that you would use a push to control the normal cursor, it actually
*  moves the screen for you. So it's basically like remapping the velocity to a scroll action.
*  And the reason that feels so natural and intuitive is that when you move over to attach to it,
*  it feels like magnetic. So you're like sort of stuck onto it. And then it's one continuous action.
*  You don't have to like switch your imagine movement. You sort of snap onto it and then you're
*  good to go. You just immediately can start pulling the page down or pushing it up. And even once you
*  get that right, there's so many little nuances of how the scroll behavior works to make it natural
*  and intuitive. So one example is momentum. Like when you scroll a page with your fingers on the
*  screen, you actually have some like flow. Like it doesn't just stop right when you lift your finger
*  up. The same is true with BCI scroll. So we had to spend some time to figure out what are the right
*  nuances when you don't feel the screen under your fingertip anymore. What is the right sort of dynamic
*  or what's the right amount of page give, if you will, when you push it to make it flow the right
*  amount for the user to have a natural experience reading their book. And there's a million, I mean,
*  I could tell you like there's so many little minutia of how exactly that scroll works that
*  we spent probably like a month getting right to make that feel extremely natural and easy for the
*  user to navigate. Even the scroll on a smartphone with your finger feels extremely natural and
*  pleasant. And it probably takes an extremely long time to get that right. And actually the same kind
*  of visionary UX design that we're talking about don't always listen to the users, but also listen
*  to them and also have like visionary big like throw everything out, think from first principles,
*  but also not. Yeah. Yeah. By the way, this makes me think that scroll bars on the desktop
*  probably have stagnated and never taken that like, cause the snap, same as the snap to grid,
*  snap to scroll bar action you're talking about is something that could potentially be extremely
*  useful in the desktop setting. Even just for users to just improve the experience. Cause the
*  current scroll bar experience and the desktop is horrible. It's hard to find, hard to control.
*  There's not a momentum. There's, and the intention should be clear when I start moving towards the
*  scroll bar, there should be a snap into the scroll bar action. But of course, you know, maybe I'm
*  okay paying that cost, but there's hundreds of millions of people paying that cost nonstop. But
*  anyway, but in this case, this is necessary because there's an extra cost paid by Nolan for
*  the jitteriness. So you have to switch between the scrolling and the reading. There has to be a
*  phase shift between the two. Like when you're scrolling, you're scrolling. Right. Right. So
*  that is one drawback of the current approach. Maybe one other just sort of case study here.
*  So again, UX is how it works. And we think about that holistically from like the,
*  even the feature detection level of what we detect in the brain to how we design the decoder,
*  what we choose to decode to then how it works once it's being used by the user. So another good
*  example in that sort of how it works once they're actually using the decoder, you know, the output
*  that's displayed on the screen is not just what the decoder says. It's also a function of, you know,
*  what's going on on the screen. So we can understand, for example, that, you know, when you're trying to
*  close a tab, that very small, stupid little X that's extremely tiny, which is hard to get precisely
*  hit. If you're dealing with sort of a noisy output of the decoder, we can understand that that is a
*  small little X you might be trying to hit and actually make it a bigger target for you.
*  Similar to how when you're typing on your phone, if you're, you know, used to like the iOS keyboard,
*  for example, it actually adapts the target size of individual keys based on an underlying language
*  model. So it'll actually understand if I'm typing, Hey, I'm going to see L. It'll make the E key
*  bigger because it knows Lex is the person I'm going to go see. And so that kind of, you know,
*  predictiveness can make the experience much more smooth, even without, you know, improvements to
*  the underlying decoder or, or a feature detection part of the stack. So we do that with a feature
*  called magnetic targets. We actually index the screen and we understand, okay, these are the
*  places that are, you know, very small targets that might be difficult to hit. Here's the kind
*  of cursor dynamics around that location that might be indicative of the user trying to select it.
*  Let's make it easier. Let's blow up the size of it in a way that makes it easier for the user to
*  sort of snap onto that target. So all these little details, they matter a lot in helping the user be
*  independent in their day to day living. So how much of the work on the decoder is generalizable to
*  P2, P3, P4, P5, PN? How do you improve the decoder in a way that's generalizable?
*  Yeah, great question. So the underlying signal we're trying to decode is going to look very
*  different in P2 than in P1. For example, channel number 345 is going to mean something different
*  in user one than it will in user two, just because that electrode that corresponds with channel 345
*  is going to be in next to a different neuron in user one versus user two. But the approaches,
*  the methods, the user experience of how do you get the right sort of behavioral pattern from the
*  user to associate with that neural signal, we hope that will translate over multiple generations of
*  users. And beyond that, it's very, very possible, in fact, quite likely that we've overfit to sort
*  of Nolan's user experience desires and preferences. And so what I hope to see is that when we get a
*  second, third, fourth participant, that we find sort of what the right wide minimas are that cover
*  all the cases that make it more intuitive for everyone. And hopefully there's a cross-pollination
*  of things where, oh, we didn't think about that with this user because, you know, they can speak.
*  But with this user who just can fundamentally not speak at all, this user experience is not optimal.
*  And that will actually, those improvements that we make there should hopefully translate then to
*  even people who can't speak but don't feel comfortable doing so because we're in a public
*  setting like their doctor's office. So the actual mechanism of open loop labeling and then closed
*  loop labeling will be the same and hopefully can generalize across the different users as they're
*  doing the calibration step. And the calibration step is pretty cool. I mean, that in itself,
*  the interesting thing about WebGrid, which is like closed loop, it's like fun. I love it when
*  there's like, there used to be kind of idea of human computation, which is using actions
*  that human would want to do anyway, to get a lot of signal from. And like WebGrid is that,
*  like a nice video game that also serves as great calibration. It's so funny. This is,
*  I've heard this reaction so many times before sort of the first user was implanted, we had an
*  internal perception that the first user would not find this fun. And so we thought really quite a
*  bit actually about like, should we build other games that like are more interesting for the user
*  so we can get this kind of data and help facilitate research that's for long duration stuff like this.
*  Turns out that like people love this game. I always loved it, but I didn't know that that
*  was a shared perception. Yeah. And just in case it's not clear, WebGrid is, there's a grid of
*  let's say 35 by 35 cells and one of them lights up blue and you have to move your mouse over that
*  and click on it. And if you miss it and it's red and I put this game for so many hours,
*  so many hours. And what's your record? You said my, I think I have the highest at Neuralink right
*  now. My record is 17 BPS, 17 BPS, which is about, if you imagine that 35 by 35 grid, you're hitting
*  about a hundred trials per minute. So a hundred correct selections in that one minute window.
*  So you're averaging about, you know, between 500, 600 milliseconds per selection.
*  So one of the reasons that I think I struggle with that game is I'm such a keyboard person. So
*  everything is done with your keyboard. If I can avoid touching the mouse, it's great. So how can
*  you explain your high performance? I have like a whole ritual I go through when I play WebGrid. So
*  it's just actually like a diet plan associated with this. Like it's a whole thing. So great.
*  The first thing is- I have to fast for five days. I have to go up to the mountains. Actually,
*  I mean, the fasting thing is important. So this is like, you know-
*  It focuses the mind, yeah.
*  Yeah. So what I do is I actually, I don't eat for a little bit beforehand. And then I'll actually
*  eat like a ton of peanut butter right before I play. And then you get like-
*  This is a real thing.
*  This is a real thing, yeah. And then it has to be really late at night. This is like in a night owl
*  thing, I think we share, but it has to be like, you know, midnight, 2 a.m. kind of time window.
*  And I have a very specific like physical position I'll sit in, which is, I used to be, I was
*  homeschooled growing up. And so I did most of my work like on the floor, just like in my bedroom
*  or whatever. And so I have a very specific situation-
*  On the floor.
*  On the floor that I sit and play. And then you have to make sure like there's not a lot of weight on
*  your elbow when you're playing so that you can move quickly. And then I turn the gain of the
*  cursor, so the speed of the cursor way, way up. So it's like small motions that actually move
*  the cursor.
*  And you're moving with your wrist or you're never-
*  I move with my fingers. So my wrist is almost completely still. I'm just moving my fingers.
*  Yeah.
*  You know those just in a small tangent?
*  Yeah.
*  Which I've been meaning to go down this rabbit hole of people that set the world record in
*  Tetris. Those folks, they're playing, there's a way to- did you see this?
*  I see it's like the three, like all the fingers are moving.
*  Yeah. You could find a way to do it where like it's using a loophole, like a bug,
*  that you can do some incredibly fast stuff. So it's along that line, but not quite.
*  But you do realize there'll be like a few programmers right now listening to this
*  cool fast and eat peanut butter.
*  Please write my record. I mean, the reason I did this literally was just because I wanted
*  the bar to be high. Like I wanted the number that we aim for should not be like the median
*  performance. It should be like, it should be able to beat all of us at least. Like that should be
*  the minimum bar.
*  What do you think is possible? Like 20?
*  It's great.
*  Yeah. I don't know what the limits- I mean, the limits you can calculate just in terms of
*  like screen refresh rate and like cursor immediately jumping to the next target.
*  But there's, I mean, I'm sure there's limits before that with just sort of reaction time
*  and visual perception and things like this. I'd guess it's in the below 40, but above 20,
*  somewhere in there. It's probably the rate that I'd never be thinking about.
*  It also matters like how difficult the task is. You could imagine like some people might be able
*  to do like 10,000 targets on the screen and maybe they can do better that way. So there's some like
*  task optimizations you could do to try to boost your performance as well.
*  What do you think it takes for Nolan to be able to do above 8.5 to keep increasing that number?
*  You said like every increase in the number might require different-
*  Yeah.
*  Different improvements in the system.
*  Yeah. I think the nature of this work is- the first answer that's important to say is I don't
*  know. This is edge of the research. So again, nobody's gotten to that number before. So what's
*  next is going to be heuristic, a guess from my part. What we've seen historically is that different
*  parts of the stack would compile next to different time points. So when I first joined Erlang like
*  three years ago or so, one of the major problems was just the latency of the Bluetooth connection.
*  It wasn't just like the radio on the device wasn't super good. It was an earlier vision of the
*  implant. And it just like no matter how good your decoder was, if your thing is updating every 30
*  milliseconds or 50 milliseconds, it's just going to be choppy. And no matter how good you are,
*  that's going to be frustrating and lead to challenges. So at that point, it was very
*  clear that the main challenge is just get the data off the device in a very reliable way such
*  that you can enable the next challenge to be tackled. And then at some point it was
*  actually the modeling challenge of how do you just build a good mapping, like the supervised
*  learning problem of you have a bunch of data and you have a label you're trying to predict,
*  just what is the right neural decoder architecture and hyperparameters to optimize that.
*  That was a problem for a bit. And once you solve that, it became a different bottleneck.
*  I think the next bottleneck after that was actually just sort of software stability and
*  reliability. If you have widely varying sort of inference latency in your system or your app just
*  lags out every once in a while, it decreases your ability to maintain and get in a state of flow.
*  And it basically just disrupts your control experience. And so there's a variety of different
*  software bugs and improvements we made that basically increased the performance of the system,
*  made it much more reliable, much more stable, and led to a state where we could reliably collect
*  data to build better models with. So that was a bottleneck for a while. It's just sort of like
*  the software stack itself. If I were to guess right now, there's sort of two major directions
*  you could think about for improving BPS further. The first major direction is labeling. So labeling
*  is again, this fundamental challenge of given a window of time where the user is expressing
*  some behavioral intent, what are they really trying to do at the granularity of every millisecond?
*  And that again is a task design problem. It's a UX problem. It's a machine learning problem.
*  It's a software problem. Sort of touches all those different domains. The second thing you
*  can think about to improve BPS further is either completely changing the thing you're decoding
*  or just extending the number of things that you're decoding. So this is sort of in the
*  direction of functionality. Basically, you can imagine giving more clicks, for example,
*  a left click, a right click, a middle click, different actions like clicking drag, for example.
*  And that can improve the effective bit rate of your communication processes. If you're trying to
*  allow the user to express themselves through any given communication channel,
*  you can measure that with this per second. But what actually matters at the end of the day is
*  how effective are they at navigating their computer? And so from the perspective of the
*  downstream tasks that you care about, functionality and extending functionality is something we're
*  very interested in because not only can it improve the sort of number of BPS, but it can also improve
*  the downstream sort of independence that the user has and the skill and efficiency with which they
*  can operate their computer. Would the number of threads increasing also potentially help?
*  Yes. Short answer is yes. It's a bit nuanced how that curve or how that manifests in the numbers.
*  So what you'll see is that if you sort of plot a curve of number of channels that you're using
*  for decode versus either the offline metric of how good you are decoding or the online metric of sort
*  of in practice, how good is the user using this device, you see roughly a log curve. So as you
*  move further out in number of channels, you get a corresponding sort of a logarithmic improvement
*  in control quality and offline validation metrics. The important nuance here is that
*  each channel corresponds with a specific represented intention in the brain. So for example,
*  if you have a channel 254, it might correspond with moving to the right channel 256 might mean
*  moved to the left. If you want to expand the number of functions you want to control,
*  you really want to have a broader set of channels that covers a broader set of imagine movements.
*  You can think of it like Mr. Potato Man actually. If you had a bunch of different imagine movements
*  you could do, how would you map those imagine movements to input to a computer? You can imagine
*  handwriting to output characters on the screen. You can imagine just typing with your fingers and
*  have that output text on the screen. You can imagine different finger modulations for different
*  clicks. You can imagine wiggling your big nose for opening some menu or wiggling your big toe to
*  have like a command tab occur or something like this. So it's really the amount of different
*  actions you can take in the world depends on how many channels you have and the information content
*  that they carry. Right. So that's more about the number of actions. So actually, as you increase the
*  number of threads, that's more about increasing the number of actions you're able to perform.
*  One other nuance there that is worth mentioning. So again, our goal is really to enable a user
*  with process to control the computer as fast as I can. So that's BPS with all the same functionality
*  I have, which is what we just talked about, but then also as reliably as I can. And that last point
*  is very related to channel count discussion. So as you scale out number of channels, the relative
*  importance of any particular feature of your model input to the output control of the user diminishes,
*  which means that if the sort of neural non-stationarity effect is per channel,
*  or if the noise is independent such that more channels means on average less output effect,
*  then your reliability of your system will improve. So one sort of core thesis that at least I have
*  is that scaling channel count should improve the reliability system without any work on
*  the decoder itself. Can you linger on the reliability here? So first of all, when you
*  see a non-stationarity of the signal, which aspect are you referring to? Yeah. So maybe
*  let's talk briefly what the actual underlying signal looks like. So again, I spoke very briefly
*  at the beginning about how when you imagine moving to the right or imagine moving to the left,
*  neurons might fire more or less. And their frequency content of that signal, at least in
*  the motor cortex, it's very correlated with the output intention of the behavioral task that the
*  user is doing. You can imagine actually, this is not obvious at rate coding, which is the name of
*  that phenomenon, is like the only way the brain can represent information. You can imagine many
*  different ways in which the brain could encode intention. And there's actually evidence like
*  in bats, for example, that there's temporal codes. So timing codes of like exactly when particular
*  neurons fire is the mechanism of information representation. But at least in the motor cortex,
*  there's substantial evidence that it's rate coding or at least one like first order of
*  factors that it's rate coding. So then if the brain is representing information by changing the
*  frequency of a neuron firing, what really matters is sort of the delta between sort of the baseline
*  state of the neuron and what it looks like when it's modulated. And what we've observed and what
*  has also been observed in academic work is that that baseline rate, sort of the, if you're to
*  target the scale, if you imagine that analogy for like measuring flour or something when you're
*  baking, that baseline state of how much the pot weighs is actually different day to day.
*  And so if what you're trying to measure is how much rice is in the pot, you're going to get a
*  different measurement different days because you're measuring with different pots. So that
*  baseline rate shifting is really the thing that at least from a first order description of the
*  problem is what's causing this downstream bias. There can be other effects, nonlinear effects on
*  top of that, but at least at a very first order description of the problem, that's what we
*  observed day to day is that the baseline firing rate of any particular neuron or observed on a
*  particular channel is changing. So can you just adjust to the baseline to make it relative to
*  the baseline nonstop? Yeah, this is a great question. So with monkeys, we have found various
*  ways to do this. One example would do this is you ask them to do some behavioral tasks, like play
*  the game with a joystick. You measure what's going on in the brain. You compute some mean of
*  what's going on across all the input features and you subtract that in the input when you're doing
*  your BCI session. Works super well. For whatever reason, that doesn't work super well with Nolan.
*  I actually don't know the full reason why, but I can imagine several explanations.
*  One such explanation could be that the context effect difference between some open loop task
*  and some closed loop task is much more significant with Nolan than it is with monkey. Maybe in this
*  open loop task, he's watching the Lex Freeman podcast while he's doing the task, or he's
*  whistling and listening to music and talking with his friend and ask his mom what's for dinner while
*  he's doing this task. And so the exact sort of difference in context between those two states
*  may be much larger and thus lead to a bigger generalization gap between the features that
*  you're normalizing at sort of open loop time and what you're trying to use at closed loop time.
*  That's interesting. Just on that point, it's kind of incredible to watch Nolan be able to
*  multitask, to do multiple tasks at the same time, to be able to move the mouse cursor effectively
*  while talking and while being nervous because he's talking in front of you. Kicking my ass in chest
*  too. Kicking your ass and talk trash while doing it. So all at the same time. And yes, if you're
*  trying to normalize to the baseline, that might throw everything off. Boy, is that interesting.
*  Maybe one comment on that too. For folks that aren't familiar with assistive technology,
*  I think there's a common belief that, you know, well, why can't you just use an eye tracker or
*  something like this for helping somebody move a mouse on the screen? And it's really a fair
*  question and one that I actually was not confident before, Sir Nolan, that this was going to be a
*  profoundly transformative technology for people like him. And I'm very confident now that it will
*  be, but the reasons are subtle. It really has to do with ergonomically how it fits into their life.
*  Even if you can just offer the same level of control as what they would have with an eye
*  tracker or with a mouse stick. But you don't need to have that thing in your face. You don't need
*  to be positioned a certain way. You don't need your caretaker to be around to set it up for you.
*  You can activate it when you want, how you want, wherever you want. That level of independence
*  is so game changing for people. It means that they can text a friend at night privately without
*  their mom needing to be in the loop. It means that they can like open up, you know, and browse
*  the internet at 2 AM when nobody's around to set their iPad up for them. This is like profoundly
*  game changing thing for folks in that situation. And this is even before we start talking about
*  folks that may not be able to communicate at all or ask for help when they want to. This can be
*  potentially the only link that they have to the outside world. And yeah, that one doesn't, I think,
*  need explanation of why that's so impactful. You mentioned neurodecoder. How much machine
*  learning is in the decoder? How much magic, how much science, how much art? How difficult is it
*  to come up with a decoder that figures out what these sequence of spikes mean?
*  Yeah, good question. There's a couple of different ways to answer this. So maybe I'll zoom out briefly
*  first and then I'll go down one of the rabbit holes. And so the zoomed out view is that building
*  the decoder is really the process of building the data set plus compiling it into the weights.
*  And each of those steps is important. The direction I think of further improvement is primarily going
*  to be in the data set side of how do you construct the optimal labels for the model.
*  But there's an entirely separate challenge of then how do you compile the best model?
*  And so I'll go briefly down the second rabbit hole. One of the main challenges with designing
*  the optimal model for BCI is that offline metrics don't necessarily correspond to online metrics.
*  It's fundamentally a control problem. The user is trying to control something on the screen
*  and the exact sort of user experience of how you output the intention impacts their ability to
*  control. So for example, if you just look at validation loss as predicted by your model,
*  there can be multiple ways to achieve the same validation loss. Not all of them are equally
*  controllable by the end user. And so it might be as simple as saying, oh, you could just add auxiliary
*  loss terms that help you capture the thing that actually matters. But this is a very complex
*  nuance process. So how you turn the labels into the model is more of a nuance process than just
*  a standard supervised learning problem. One very fascinating anecdote here, we've tried many
*  different sort of neural network architectures that translate brain data to velocity outputs,
*  for example. And one example that's stuck in my brain from a couple of years ago now is at one
*  point we were using just fully connected networks to decode the brain activity. We tried a A-B test
*  where we were measuring the relative performance in online control sessions of sort of 1D
*  convolution over the input signal. So if you imagine per channel, you have a sliding window
*  that's producing some convolved feature for each of those input sequences for every single channel
*  simultaneously. You can actually get better validation metrics, meaning you're fitting the
*  data better. And it's generalizing better in offline data if you use this convolutional
*  architecture. You're reducing parameters. It's sort of a standard procedure when you're dealing
*  with time series data. Now it turns out that when using that model online, the controllability was
*  far worse, even though the offline metrics were better. And there can be many ways to interpret
*  that. But what that taught me at least was that, hey, it's at least the case right now that if you
*  were to just throw a bunch of compute at this problem and you were trying to sort of hyperparameter
*  optimize or let some GPT model hard code or come up with or invent many different solutions,
*  if you were just optimizing for loss, it would not be sufficient, which means that there's
*  still some inherent modeling gap here. There's still some artistry left to be uncovered here of
*  how to get your model to scale with more compute. And that may be fundamentally a labeling problem,
*  but there may be other components to this as well. Is it data constraint at this time?
*  Which is what it sounds like. How do you get a lot of good labels? Yeah. I think it's data
*  quality constrained, not necessarily data quantity constrained. But even just the quantity,
*  because it has to be trained on the interactions. I guess there's not that many interactions.
*  Yeah. So it depends what version of this you're talking about. So if you're talking about,
*  let's say the simplest example of just 2D velocity, then I think yeah, data quality is the main thing.
*  If you're talking about how to build a sort of multifunction output that lets you do all the
*  inputs to the computer that you and I can do, then it's actually a much more sophisticated,
*  nuanced modeling challenge. Because now you need to think about not just when the user is left
*  clicking, but when you're building the left click model, you also need to be thinking about how to
*  make sure it doesn't fire when they're trying to right click or when they're trying to move the
*  mouse. So one example of an interesting bug from week one of BCI with Nolan was when he moved the
*  mouse, the click signal dropped off a cliff. And when he stopped, the click signal went up. So again,
*  there's a contamination between the two inputs. Another good example was at one point he was
*  trying to do a left click and drag. And the minute he started moving, the left click signal dropped
*  off a cliff. So again, because there's some contamination between the two signals, you need
*  to come up with some way to either in the data set or in the model, build robustness against this
*  kind of, you think of it like overfitting, but really it's just that the model has not seen this
*  kind of variability before. So you need to find some way to help the model with that.
*  This is super cool. It feels like all of this is very solvable, but it's hard.
*  Yes, it is fundamentally an engineering challenge. This is important to emphasize. And it's also
*  important to emphasize that it may not need fundamentally new techniques, which means that
*  people who work on, let's say unsupervised speech classification using CTC loss, for example,
*  with internal to Siri, they could potentially have very applicable skills to this.
*  So what things are you excited about in the future development
*  of the software stack on Neuralink? So everything we've been talking about, the decoding, the UX.
*  I think there's some I'm excited about, like something I'm excited about from the technology
*  side and some I'm excited about for understanding how this technology is going to be best situated
*  for entering the world. So I'll work backwards on the technology, entering the world side of things.
*  I'm really excited to understand how this device works for folks that cannot speak at all, that
*  have no ability to sort of bootstrap themselves into useful control by voice command, for example,
*  and are extremely limited in their current capabilities. I think that will be an incredibly
*  useful signal for us to understand. I mean, really what is an existential type for all startups,
*  which is product market fit. Does this device have the capacity and potential to transform
*  people's lives in the current state? And if not, what are the gaps? And if there are gaps,
*  how do we solve them most efficiently? So that's what I'm very excited about for the next year or
*  so of clinical trial operations. The technology side, I'm quite excited about basically everything
*  we're doing. I think it's going to be awesome. The most prominent one I would say is scaling
*  channel count. So right now we have a thousand channel device. The next version will have between
*  three and six thousand channels. And I would expect that curve to continue in the future.
*  And it's unclear what set of problems will just disappear completely at that scale and what set
*  of problems will remain and require further focus. And so I'm excited about the clarity of gradient
*  that that gives us in terms of the user experiences we choose to focus our time and resources on.
*  And also in terms of the, yeah, even things as simple as non-stationarity, like does that
*  problem just completely go away at that scale or do we need to come up with new creative UXs still
*  even at that point? And also when we get to that time point, when we start expanding out dramatically
*  the set of functions that you can output from one brain, how to deal with all the nuances of
*  both the user experience of not being able to feel the different keys under your fingertips,
*  but still needing to be able to modulate all of them in synchrony to achieve the thing you want.
*  And again, you don't have that properly set to feedback. So how can you make that intuitive for
*  a user to control a high dimensional control surface without feeling the thing physically?
*  I think that's going to be a super interesting problem. I'm also quite excited to understand,
*  do these scaling laws continue? As you scale channel count, how much further out do you go
*  before that saturation point is truly hit? And it's not obvious today. I think we only know what's
*  in the interpolation space. We only know what's between zero and 1,024, but we don't know what's
*  beyond that. And then there's a whole range of interesting neuroscience and brain questions,
*  which is when you stick more stuff in the brain in more places, you get to learn much more quickly
*  about what those brain regions represent. And so I'm excited about that fundamental neuroscience
*  learning, which is also important for figuring out how to most efficiently insert electrodes in
*  the future. So yeah, I think all those dimensions I'm really, really excited about, and that doesn't
*  even get close to touching the sort of software stack that we work on every single day and what
*  we're working on right now. Yeah, it seems virtually impossible to me that a thousand
*  electrodes is where it saturates. It feels like this would be one of those silly notions in the
*  future where obviously you should have millions of electrodes and this is where the true
*  breakthroughs happen. You tweeted, some thoughts are most precisely described in poetry.
*  Why do you think that is? I think it's because the information bottleneck of language is
*  pretty steep. And yet you're able to reconstruct on the other person's brain
*  more effectively without being literal. If you can express the sentiment such that in their brain,
*  they can reconstruct the actual true underlying meaning and beauty of the thing that you're trying
*  to get across. The generator function in their brain is more powerful than what language can
*  express. And so the mechanism poetry is really just to feed or seed that generator function.
*  So being literal sometimes is a suboptimal compression for the thing you're trying to convey.
*  And it's actually in the process of the user going through that generation that they understand
*  what you mean. That's the beautiful part. It's also like when you look at a beautiful painting,
*  it's not the pixels of the painting that are beautiful. It's the thought process that occurs
*  when you see that, the experience of that that actually is the thing that matters.
*  Yeah, it's resonating with some deep thing within you that the artist also experienced and was able
*  to convey that through the pixels. And that's actually going to be relevant for full-on telepathy.
*  It's like if you just read the poetry literally, that doesn't say much of anything interesting.
*  It requires a human to interpret it. So it's the combination of the human mind and all the
*  experiences that a human being has within the context of the collective intelligence of the
*  human species that makes that poem make sense. And they load that in. And so in that same way,
*  the signal that carries from human to human meaning may seem trivial, but may actually carry
*  a lot of power because of the complexity of the human mind and the receiving end.
*  Yeah, that's interesting. Poetry still doesn't... Who was it? I think
*  Yoshibaka, first of all, I said something about
*  all the people that think we've achieved AGI explain why humans like music.
*  Oh, yeah.
*  And until the AGI likes music, you haven't achieved AGI or something like this.
*  Do you not think that's like some next token, entropy surprise kind of thing going on?
*  I don't know.
*  I don't know either. I listen to a lot of classical music and also read a lot of poetry.
*  And yeah, I do wonder if there is some element of the next token surprise factor going on there.
*  Yeah, maybe.
*  A lot of the tricks in both poetry and music are basically you have some repeated structure
*  and then you do a twist. It's like, okay, clause one, two, three is one thing. And then clause four
*  is like, okay, now we're onto the next theme. And they kind of play with exactly when the surprise
*  happens and the expectation of the user. And that's even true through history as musicians
*  evolve music. They take some known structure that people are familiar with and they just
*  tweak it a little bit. They tweak it and add a surprising element. It's especially true in
*  classical music heritage. But that's what I'm wondering, is it all just entropy?
*  So breaking structure or breaking symmetry is something that humans seem to like,
*  maybe as simple as that.
*  Yeah. And I mean, great artists copy. And knowing which rules to break is the important part.
*  And fundamentally, it must be about the listener of the piece. Which rule is the right one to
*  break is about the user or the audience member perceiving that as interesting.
*  What do you think is the meaning of human existence?
*  There's a TV show I really like called The West Wing. And in The West Wing, there's a character,
*  he's the president of the United States, who's having a discussion about the Bible with one of
*  their colleagues. And the colleague says something about, you know, the Bible says X, Y, and Z.
*  And the president says, yeah, but it also says ABC. And the person says, well, do you believe
*  the Bible to be literally true? And the president says, yes, but I also think that neither of us
*  are smart enough to understand it. I think the analogy here for the meaning of life is that
*  largely we don't know the right question to ask. And so I think I'm very aligned with
*  sort of the Hitchhiker's Guide to the Galaxy version of this question, which is basically,
*  if we can ask the right questions, it's much more likely we find the meaning of human existence.
*  And so in the short term, as a heuristic in the sort of search policy space, we should try to
*  increase the diversity of people asking such questions, or generally of consciousness
*  and conscious beings asking such questions. So again, I think I'll take the I don't know
*  card here, but say I do think there are meaningful things we can do that improve the likelihood of
*  answering that question. It's interesting how much value you assign to the task of asking the
*  right questions. That's the main thing is not the answers is the questions. This point, by the way,
*  is driven home in a very painful way when you try to communicate with someone who cannot speak,
*  because a lot of the time, the last thing to go is they have the ability to somehow wiggle a lip
*  or move something that allows them to say yes or no. And in that situation, it's very obvious
*  what matters is are you asking them the right question to be able to say yes or no to.
*  Wow, that's powerful. Well, Bliss, thank you for everything you do. And thank you for being you.
*  And thank you for talking today. Thank you.
*  Thanks for listening to this conversation with Bliss Chapman. And now, dear friends,
*  here's Nolan Arbaugh, the first human being to have a neural link device implanted in his brain.
*  You had a diving accident in 2016 that left you paralyzed with no feeling from the shoulders down.
*  How did that accident change your life?
*  It was sort of a freak thing that happened. Imagine you're running into the ocean. Although
*  this is a lake, but you're running into the ocean and you get to about waist high and then you kind
*  of like dive in, take the rest of the plunge under the wave or something. That's what I did. And then
*  and then I just never came back up. Not sure what happened. I did it running into the water with a
*  couple of guys. And so my idea of what happened is really just that I took like a stray fist,
*  elbow, knee, foot, something to the side of my head. The left side of my head was sore for about
*  a month afterwards. So must have taken a pretty big knock. And then they both came up and I didn't.
*  And so I was face down in the water for a while. I was conscious. And then eventually just,
*  you know, realized I couldn't hold my breath any longer. And I keep saying took a big drink.
*  People, I don't know if they like that I say that seems like I'm making light of it all. But
*  um, this is kind of how I am. And I don't know, like, I'm a very
*  relaxed sort of stress free person. I rolled with the punches for a lot of this. I kind of took it
*  in stride. It's like, all right, well, what can I do next? How can I improve my life even a little bit?
*  On a day to day basis at first, just trying to find some way to heal as much my body as possible.
*  To try to get healed, to try to get off a ventilator, learn as much as I could so I
*  could somehow survive. Once I left the hospital. And then thank God I had like my family around me.
*  If I didn't have my parents, my siblings, then I would have never made it this far.
*  They've done so much for me. More than like I can ever thank them for honestly. And a lot of people
*  don't have that a lot of people in my situation, their families either aren't capable of providing
*  for them or honestly just don't want to. And so they get placed somewhere and, you know,
*  in some sort of home. So thankfully I had my family. I have a great group of friends,
*  a great group of buddies from college who have all rallied around me. And we're all
*  still incredibly close. People always say, you know, if you're lucky, you'll
*  end up with one or two friends from high school that you keep throughout your life. I have about
*  10, 10 or 12 from high school that have all stuck around. And we still get together, all of us twice
*  a year. We call it the spring series and the fall series. This last one we all did, we dressed up
*  like X-Men. So I did a Vessar Xavier and it was freaking awesome. It was so good. So yeah,
*  I have such a great support system around me. And so, you know, being a quadriplegic isn't that bad.
*  I get waited on all the time. People bring me food and drinks and I get to sit around and watch as
*  much TV and movies and anime as I want. I get to read as much as I want. I mean, it's great.
*  It's beautiful to see that you see the silver lining in all of this.
*  We're just going back. Do you remember the moment when you first realized you're paralyzed from the
*  neck down? Yep. I was face down in the water. Right when I, whatever, something hit my head.
*  I tried to get up and I realized I couldn't move and it just sort of clicked. I'm like, all right,
*  I'm paralyzed. Can't move. What do I do? If I can't get up, I can't flip over, can't do anything,
*  then I'm going to drown eventually. And I knew I couldn't hold my breath forever. So I just
*  held my breath and thought about it for maybe 10, 15 seconds. I've heard from other people
*  like on Lickers, I guess the two girls that pulled me out of the water were two of my best friends.
*  They are lifeguards. And one of them said that it looked like my body was sort of shaking in the
*  water. Like I was trying to flip over and stuff. But I knew, I knew immediately. And I just kind of,
*  I realized that that's what my situation was from here on out. Maybe if I got to the hospital,
*  they'd be able to do something. When I was in the hospital, like right before surgery,
*  I was trying to calm one of my friends down. I had like brought her with me from college to camp
*  and she was just bawling over me. And I was like, Hey, it's going to be fine. Like, don't worry.
*  I was cracking some jokes to try to lighten the mood. The nurse had called my mom and I was like,
*  don't tell my mom. She's just going to be stressed out. Call her after I'm out of surgery.
*  Cause at least she'll have some answers then like whether I live or not really. And I didn't want
*  her to be stressed through the whole thing, but I knew. And then when I first woke up after surgery,
*  I was super drugged up. They had me on fentanyl like three ways, which was awesome. I don't,
*  I don't recommend it, but I saw, I saw some crazy stuff on that fentanyl and it was still the best
*  I've ever felt on drugs. Medication, sorry on medication. And I remember the first time I saw
*  my mom in the hospital, I was just bawling. I had like ventilator in, like I couldn't talk or anything
*  and I just started crying because it was more like seeing her. Not that, I mean, the whole situation
*  obviously was pretty rough, but I was just like seeing her face for the first time was pretty hard.
*  But yeah, I just, I never had like a moment of, you know, man, I'm paralyzed. This sucks. I don't
*  want to like be around anymore. It was always just, I hate that I have to do this, but like
*  sitting here and wallowing isn't going to help. So immediate acceptance. Yeah. Yeah.
*  Has there been low points along the way? Yeah. Yeah, sure. I mean, there are days when
*  I don't really feel like doing anything, not so much anymore, like not for the last couple of years.
*  I don't really feel that way. I've more so just wanted to try to do anything possible to make my
*  life better at this point. But at the beginning, there were some ups and downs. There were some
*  really hard things to adjust to. First off, just like the first couple of months, the amount of
*  pain I was in was really, really hard. I mean, I remember screaming at the top of my lungs in the
*  hospital because I thought my legs were on fire. And obviously I can't feel anything, but it's all
*  nerve pain. And so that was a really hard night. I asked them to give me as much pain meds as
*  possible. They're like, you've had as much as you can have. So just kind of deal with it, go to a
*  happy place sort of thing. So that was a pretty low point. And then every now and again, it's hard
*  like realizing things that I wanted to do in my life that I won't be able to do anymore.
*  I always wanted to be a husband and father, and I just don't think that I could do it now as a
*  quadriplegic. Maybe it's possible, but I'm not sure I would ever put someone I love through that,
*  like having to take care of me and stuff. Not being able to go out and play sports. I was a
*  huge athlete growing up, so that was pretty hard. Little things do when I realize I can't do them
*  anymore. There's something really special about being able to hold a book and smell a book,
*  like the feel, the texture, the smell, like as you turn the pages, like I just love it,
*  I can't do it anymore. And it's little things like that. The two-year mark was pretty rough.
*  Two years is when they say you will get back basically as much as you're ever going to get
*  back as far as movement and sensation goes. And so for the first two years, that was the only thing
*  on my mind was like, try as much as I can to move my fingers, my hands, my feet, everything possible
*  to try to get sensation and movement back. And then when the two-year mark hit, so June 30th,
*  2018, I was really sad that that's kind of where I was. And then just randomly here and there,
*  but I was never depressed for long periods of time. It never seemed worthwhile to me.
*  What gave you strength?
*  My faith, my faith in God was a big one. My understanding that it was all for a purpose.
*  And even if that purpose wasn't anything involving Neuralink, even if that purpose was,
*  you know, there's a story in the Bible about Job. And I think it's a really, really popular story
*  about how Job has all of these terrible things happen to him and he praises God throughout
*  the whole situation. I thought, and I think a lot of people think for most of their lives,
*  that they are Job, that they're the ones going through something terrible and they just need to
*  praise God through the whole thing and everything will work out. At some point after my accident,
*  I realized that I might not be Job, that I might be one of his children that gets killed or kidnapped
*  or taken from him. And so it's about terrible things that happen to those around you who you
*  love. So maybe, you know, in this case, my mom would be Job and she has to get through something
*  extraordinarily hard. And I just need to try and make it as best as possible for her because
*  she's the one that's really going through this massive trial. And that gave me a lot of strength
*  and obviously my family, my family and my friends, they give me all the strength that I need
*  on a day to day basis. So it makes things a lot easier having that great support system around me.
*  From everything I've seen of you online, your streams and the way you are today,
*  I really admire, let's say, your unwavering positive outlook on life. Has that always been this way?
*  Yeah, yeah. I mean, I've just always thought I could do anything I ever wanted to do.
*  There was never anything too big. Like whatever I set my mind to, I felt like I could do it.
*  I didn't want to do a lot. I wanted to like travel around and be sort of like a gypsy and
*  go work odd jobs. I had this dream of traveling around Europe and being like, I don't know,
*  a shepherd in Wales or Ireland and then going and being a fisherman in Italy,
*  doing all these things for like a year. It's such cliche things, but I just thought it would be so
*  much fun to go and travel and do different things. And so I've always just seen the best in people
*  around me too. And I've always tried to be good to people. And growing up with my mom too, she's
*  like the most positive, energetic person in the world. And we're all just people. I just get along
*  great with people. I really enjoy meeting new people. And so I just wanted to do everything.
*  This is kind of just how I've been.
*  It's just great to see that cynicism didn't take over, given everything you've been through.
*  Was that a deliberate choice you made that you're not going to let this keep you down?
*  Yeah, a bit. Also, it's just kind of how I am. Like I said, I roll with the punches with everything.
*  I always used to tell people, I don't stress about things much. And whenever I'd see people
*  getting stressed, I'd just say, you know, it's not hard. Just don't stress about it. And that's all
*  you need to do. And they're like, that's not how that works. It works for me. Just don't stress.
*  And everything will be fine. Everything will work out. Obviously, not everything always goes well.
*  And it's not like it all works out for the best all the time. But I just don't think stress has
*  had any place in my life since I was a kid. What was the experience like of you being selected
*  to be the first human being to have a neural link device implanted in your brain?
*  Were you scared? Excited? No, it was cool.
*  Like, I was never afraid of it. I had to think through a lot. Should I do this?
*  Like, be the first person? I could wait until number two or three and get a better version
*  of the neural link. Like, the first one might not work. Maybe it's actually going to kind of suck.
*  It's going to be the worst version ever in a person. So why would I do the first one? Like,
*  I've already kind of been selected. I could just tell them, you know, like, okay, find someone else,
*  and then I'll do number two or three. Like, I'm sure they would let me. They're looking for a few
*  people anyways. But ultimately, I was like, I don't know, there's something about being the
*  first one to do something. It's pretty cool. I always thought that if I had the chance that
*  I would like to do something for the first time, this seemed like a pretty good opportunity.
*  And I was never scared. I think my like, faith had a huge part in that. I always felt like God was
*  preparing me for something. I almost wish it wasn't this, because I had many conversations with God
*  about not wanting to do any of this as a quadriplegic. I told them, you know, I'll go out
*  and talk to people. I'll go out and travel the world and talk to, you know, stadiums,
*  thousands of people, give my testimony. I'll do all of it. But like, heal me first. Don't make me
*  do all of this in a chair. That sucks. And I guess he won that argument. I didn't really have much
*  of a choice. I always felt like there was something going on. And to see how, I guess, easily I made
*  it through the interview process and how quickly everything happened, how the star sort of aligned
*  with all of this. It just told me, like as the surgery was getting closer, it just told me that,
*  you know, it was all meant to happen. It was all meant to be. And so I shouldn't be afraid of
*  anything that's to come. And so I wasn't, I kept telling myself like, you know, you say that now,
*  but as soon as the surgery comes, you're probably going to be freaking out. Like you're about to
*  have brain surgery. And brain surgery is a big deal for a lot of people, but it's an even bigger
*  deal for me. Like it's all I have left. The amount of times I've been like, thank you, God, that you
*  didn't take my brain and my personality and my ability to think, my like love of learning,
*  like my character, everything, like thank you so much. Like as long as you left me that, then I
*  think I can get by. And I was about to let people go like root around in there, like, hey, we're
*  going to go like put some stuff in your brain. Like, hopefully it works out. And so it was,
*  it was something that gave me pause. But like I said, how smoothly everything went,
*  I never expected for a second that anything would go wrong. Plus the more people I met on the borrows
*  side and on the nerling side, they're just the most impressive people in the world. Like I can't
*  speak enough to how much I trust these people with my life and how impressed I am with all of them.
*  And to see the excitement on their faces, to like walk into a room and roll into a room and see all
*  of these people looking at me, like we're just, we're so excited. Like we've been working so hard
*  on this and it's finally happening. It's super infectious and it just makes me want to do it even
*  more and to help them achieve their dreams. Like, I don't know, it's so, it's so rewarding
*  and I'm so happy for all of them, honestly. What was the day of surgery like? What's,
*  when'd you wake up? What'd you feel? Yeah. Minute by minute. Yeah. Were you freaking out? No,
*  I thought I was going to, but the surgery approach the night before the morning of,
*  I was just excited. Like I was like, let's make this happen. I think I said that,
*  something like that to Elon on the phone beforehand. We were like FaceTiming and I was
*  like, let's rock and roll. And he's like, let's do it. I don't know. I just, I wasn't scared.
*  So we woke up, I think we had to be at the hospital at like 5.30 AM. I think surgery was at like 7 AM.
*  So we woke up pretty early. I'm not sure much of us slept that night.
*  Um, um, got to the hospital 5.30, went through like all the pre-op stuff. Everyone was super nice.
*  Elon was supposed to be there in the morning, but something went wrong with his plane. So we
*  ended up FaceTiming. Uh, that was cool. Had one of the greatest one-liners of my life. After that
*  phone call, um, hung up with him. There were like 20 people around me and I was like, I just hope
*  he wasn't too starstruck talking to me. Nice. Yeah. Well done. Yeah. Yeah.
*  Did you write that ahead of time? No, no, it just came to me. I was like, this is,
*  this seems right. You know, went into surgery. Um, I asked if I could pray right beforehand. So I
*  like prayed over the room. I asked God if you would like be with my mom in case anything happened to
*  me. And, uh, just to like calm her nerves out there, uh, woke up and played a bit of a prank
*  on my mom. Uh, I don't know if you've heard about it. Yeah, I read about it. Yeah. Uh, she was,
*  she was not happy. Uh, can you take me through the prank? Yeah, this is something regret doing
*  that now. Nope. Nope. Not one bit. Um, it was something, it was something I, I had talked about
*  ahead of time with my buddy Bane. I was like, I would really like to play a prank on my mom.
*  Um, uh, very specifically, my mom, she's very gullible. Um, I think she had knee surgery once
*  even. And, um, after she came out of knee surgery, um, uh, she was super groggy. She's like, I can't
*  feel my legs. And my dad looked at her. He was like, you don't have any legs. Like they had,
*  they had to amputate both your legs and it's, we just do very mean things to her all the time.
*  Um, I'm so surprised that she still loves us. Um, but right after surgery, I was really worried
*  that I was going to be too like groggy, like not all there. I had had anesthesia once before and
*  it, it messed me up. Like I could not function, um, for a while afterwards. And I, um, I like said
*  a lot of things that I was like, I was really worried that I was going to start, I don't know,
*  like dropping, dropping some bombs and I wouldn't even know. I wouldn't remember. Um, so I was like,
*  please God don't let that happen. And please let me be there enough to do this to my mom. Um,
*  and so she walked in, uh, after surgery, it was like the first time they had been able to see me
*  after surgery and she just looked at me. She said, hi, like, how are you? How are you doing? How do
*  you feel? And I looked at her and this very, I think the anesthesia helped very like groggy,
*  sort of confused look on my face. It's like, who, who are you? And she just started looking around
*  the room, like at the surgeons or the doctors, like, what did you do to my son? Like, you need
*  to fix this right now. Tears started streaming. I saw how much she was freaking out. I was like,
*  I can't let this go on. And so I was like, mom, mom, I'm fine. Like, uh, it's all right. And, uh,
*  still, she was not happy about it. She, uh, still says she's going to get me back someday,
*  but I mean, I don't know. I don't know what that's going to look like. It's a lifelong battle. Yeah.
*  Yeah. It was good. In some sense, it was a demonstration that you still got.
*  That's, that's all I wanted it to be. That's all I wanted it to be. And I knew that doing something
*  super mean to her like that would show her. Yeah. To show that you're still there, that you love her.
*  Yeah, exactly. Exactly. It's a dark way to do it, but I love it. Yeah. Uh, what was the first time
*  you were able to feel that you can use the Neuralink device to affect the world around you?
*  Yeah. Um, the first little taste I got of it was, uh, actually not too long after surgery. Um,
*  some of the Neuralink team had brought in, um, like a little iPad, uh, a little tablet screen,
*  and they had put up eight different, um, channels, um, and that were recording some of my neuron
*  spikes. Um, and they put it in front of me and they're like, this is like real time, your brain
*  firing. It's like, that's super cool. Um, my first thought was, I mean, if they're firing now,
*  let's see if I can affect them in some way. So I started trying to like wiggle my fingers and I
*  just started like scanning through the channels. And one of the things I was doing was like moving
*  my index finger up and down. And I just saw this yellow spike on like top row, like third box over
*  or something. I saw this yellow spike every time I did it. And I was like, oh, that's cool. And
*  everyone around me was just like, what, what are you seeing? I was like, look, look at this one,
*  look at like this top row, third box over this yellow spike. Like that's me right there, there,
*  there. And everyone was freaking out. They started like clapping. I was like, that's super
*  unnecessary. Like this is what's supposed to happen. Right. Like,
*  so you're imagining yourself moving each individual finger one at a time and then seeing like,
*  they can notice something. And then when you did the index finger, you're like, oh,
*  yeah, I was, I was wiggling kind of all of my fingers to see if anything would happen.
*  There was a lot of other things going on, but that big yellow spike was the one that stood out to me.
*  Like I'm sure that if I would have stared at it long enough, I could have mapped out maybe a hundred
*  different things, but the big yellow spike was the one that I noticed. Maybe you could speak to what
*  it's like to sort of wiggle your fingers to like, to imagine that the mental, the cognitive effort
*  required to sort of wiggle your index finger, for example, how easy is that to do? Pretty easy for
*  me. It's something that at the very beginning, after my accident, they told me to try and
*  move my body as much as possible, even if, you know, you can't just keep trying because that's
*  going to create new like neural pathways or pathways in my spinal cord to like reconnect
*  these things to hopefully regain some movement someday. That's fascinating. Yeah, I know it's,
*  it's bizarre, but I- That's part of the recovery process is to keep trying to move your body.
*  Yep. And the nervous system does its thing. It starts reconnecting.
*  It'll start reconnecting for some people. Some people, it never works. Some people,
*  they'll do it. Like for me, I got some bicep control back and that's about it. I can, if I
*  try enough, I can wiggle some of my fingers, not like on command. It's more like if I try to move,
*  say my right pinky and I just keep trying to move it after a few seconds, it'll wiggle. So I know
*  there's stuff there. Like I know like, and that happens with, you know, a few different of my
*  fingers and stuff. But yeah, that's, that's what they tell you to do. One of the people at the time
*  when I was in the hospital came in and told me for one guy who had recovered most of his control,
*  what he thought about every day was actually walking, like the act of walking just over and
*  over again. So I tried that for years. I tried just imagining walking, which is, it's hard.
*  It's hard to imagine like all of the steps that go into, well, taking a step, like all of the things
*  that have to move, like all of the activations that have to happen along your leg in order for
*  one step to occur. But you're not just imagining you're like doing it, right? I'm trying. Yeah.
*  So it's like, it's imagining over again, what I had to do to take a step. Cause it's not something
*  any of us think about. We just, you want to walk and you take a step. You don't think about all of
*  the different things that are going on in your body. So I had to recreate that in my head as
*  much as I could. And then I practice it over and over and over. So it's not like a third person
*  perspective as a first person perspective. You're like, it's not like you're imagining yourself
*  walking. You're like literally doing this, everything, all the same stuff as if you're walking.
*  Yeah. Which, which was hard. It was hard at the beginning, like frustrating hard or like actually
*  cognitively hard. Like it was both. There's a, there's a scene in one of the kill bill movies
*  actually, oddly enough where she is like paralyzed. I don't know from like a drug that was in her
*  system. And then she like find some way to get into the back of a truck or something. And she
*  stares at her toe and she says, move, like move your big toe. And after, you know, a few seconds
*  on screen, she does it. And she did that with every one of her like body parts until she can move
*  again. I did that for years, just stared at my body and said, move your index finger, move your
*  big toe. Sometimes vocalizing it like out loud, but sometimes just thinking it. I tried every
*  different way to do this, to try to get some movement back. And it's hard because it,
*  it actually is like taxing, like physically taxing on my body, which is something I would have never
*  expected because it's not like I'm moving, but it feels like there's a buildup of, I don't know,
*  the only way I can describe it is there are like signals that aren't getting through from my brain
*  down because of my, there's that gap in my spinal cord. So brain down and then from my hand back up
*  to the brain. And so it feels like those signals get stuck in whatever body part that I'm trying
*  to move and they just build up and build up and build up until they burst. And then once they burst,
*  I get like this really weird sensation of everything sort of like dissipating back out to level.
*  And then I do it again. It's also just like a fatigue thing, like a muscle fatigue,
*  but without actually moving your muscles. It's very, very bizarre. And then, you know, if you try to
*  stare at a body part or think about a body part and move for two, three, four, sometimes eight
*  hours, it's very taxing on your mind. It takes a lot of focus. It was a lot easier at the beginning
*  because I wasn't able to like control a TV in my room or anything. I wasn't able to
*  control any of my environment. So for the first few years, a lot of what I was doing was staring
*  at walls. And so obviously I did a lot of thinking and I tried to move a lot just over and over and
*  over again. Do you never give up sort of hope there? No. Just training hard, essentially.
*  And I still do it. I do it subconsciously. And I think that helped a lot with things with Neuralink,
*  honestly. It's something that I talked about the other day at the All Hands that I did at
*  Neuralink's Austin facility. Welcome to Austin, by the way. Yeah. Hey, thanks, man. I went to school.
*  Nice hat. Hey, thanks. Thanks, man. The gigafactory was super cool. I went to school at Texas A&M,
*  so I've been around before. So you should be saying, welcome to me. Welcome to Texas,
*  lights. Yeah, I get you. But yeah, I was talking about how a lot of what they've had me do,
*  especially at the beginning, well, I still do it now, is body mapping. So there will be a
*  visualization of a hand or an arm on the screen and I have to do that motion. And that's how they
*  sort of train the algorithm to understand what I'm trying to do. And so it made things very
*  seamless for me, I think. That's really, really cool. So it's amazing to know because I've learned
*  a lot about the body mapping procedure. With the interface and everything like that, it's cool to
*  know that you've been essentially training to be world class at that task. Yeah. Yeah. I don't know
*  if other quadriplegics like other paralyzed people give up. I hope they don't. I hope they
*  keep trying because I've heard other paralyzed people say, don't ever stop. They tell you two
*  years, but you just never know. The human body is capable of amazing things. So I've heard other
*  people say, don't give up. I think one girl had spoken to me through some family members and said
*  that she had been paralyzed for 18 years and she'd been trying to wiggle her index finger for all
*  that time. And she finally got a bat 18 years later. So I know that it's possible and I'll never give
*  up doing it. I do it when I'm lying down watching TV. I'll find myself doing it almost on its own.
*  It's just something I've gotten so used to doing that I don't know. I don't think I'll ever stop.
*  That's really awesome to hear because I think it's one of those things that can really pay
*  off in the long term. Because it is training. You're not visibly seeing the results of that
*  training at the moment, but there's that Olympic level nervous system getting ready for something.
*  Honestly, it was something that I think Neuralink gave me that I can't thank them enough for. I
*  can't show my appreciation for it enough was being able to visually see that what I'm doing
*  is actually having some effect. It's a huge part of the reason why I know now that I'm going to
*  keep doing it forever. Because before Neuralink, I was doing it every day and I was just assuming
*  that things were happening. It's not like I knew. I wasn't getting back any mobility or sensation
*  or anything. I could have been running up against a brick wall for all I knew. With Neuralink,
*  I get to see all the signals happening real time. I get to see that what I'm doing can actually be
*  mapped. When we started doing click calibrations and stuff, when I go to click my index finger
*  for a left click, it actually recognizes that. It changed how I think about what's possible with
*  retraining my body to move. I'll never give up now.
*  And also just the signal that there's still a powerhouse of a brain there.
*  As the technology develops, that brain is the most important thing about the human body,
*  is the brain. It can do a lot of the control. What did it feel like when you first
*  could wiggle the index finger and saw the environment respond?
*  Wherever it was just being way too dramatic, according to you.
*  Yeah, it was very cool. I mean, it was cool, but I keep telling this to people. It made sense to me.
*  It made sense that there are signals still happening in my brain and that as long as you
*  had something near it that could measure those, that could record those, then you should be able
*  to visualize it in some way, see it happen. And so that was not very surprising to me. I was like,
*  oh, cool. We found one. We found something that works. It was cool to see that their technology
*  worked and that everything that they had worked so hard for was going to pay off.
*  But I hadn't moved a cursor or anything at that point. I hadn't interacted with a computer or
*  anything at that point. So it just made sense. It was cool. I didn't really know much about BCI
*  at that point either. So I didn't know what sort of step this was actually making. I didn't know
*  if this was a huge deal or if this was just like, okay, it's cool that we got this far, but we're
*  actually hoping for something much better down the road. It's like, okay, I just thought that they
*  knew that it turned on. So I was like, cool. This is cool. Well, did you read up on the specs
*  of the hardware you're getting installed? The number of threads? Yeah, I do all of that, but
*  it's all Greek to me. I was like, okay, threads, 64 threads, 16 electrodes, 1024 channels. Okay.
*  That math checks out. Sounds right. When was the first time you were able to move a mouse cursor?
*  I know it must've been within the first maybe week, a week or two weeks that I was able to
*  first move the cursor. And again, it kind of made sense to me. It didn't seem like that big of a
*  deal. It was like, okay, well, how do I explain this? When everyone around you starts clapping
*  for something that you've done, it's easy to say, okay, I did something cool. That was impressive
*  in some way. What exactly that meant, what it was hadn't really set in for me. So again, I knew that
*  me trying to move a body part and then that being mapped in some sort of machine learning algorithm
*  to be able to identify my brain signals and then take that and give me cursor control, that all
*  kind of made sense to me. I don't know all the ins and outs of it, but I was like, there are still
*  signals in my brain firing. They just can't get through because there's a gap in my spinal cord.
*  And so they can't get all the way down and back up, but they're still there. So when I moved the
*  cursor for the first time, I was like, that's cool. But I expected that that should happen.
*  It made sense to me. When I moved the cursor for the first time with just my mind without
*  physically trying to move. So I guess I can get into that just a little bit, the difference between
*  attempted movement and imagined movement. Yeah, that's a fascinating difference.
*  Yeah. Yeah, yeah, yeah. So attempted movement is me physically trying to attempt to move, say,
*  my hand. I try to attempt to move my hand to the right, to the left, forward and back.
*  And that's all attempted. Attempt to lift my finger up and down, attempt to kick or something.
*  I'm physically trying to do all of those things, even if you can't see it. This would be like me
*  attempting to shrug my shoulders or something. That's all attempted movement. That's what I was
*  doing for the first couple of weeks when they were going to give me cursor control. When I was doing
*  body mapping, it was attempt to do this, attempt to do that. When Nir was telling me to imagine
*  doing it, it kind of made sense to me, but it's not something that people practice.
*  If you started school as a child and they said, okay, write your name with this pencil.
*  And so you do that. Okay, now imagine writing your name with that pencil. Kids would think,
*  I guess, that kind of makes sense. And they would do it. But that's not something we're taught.
*  It's all how to do things physically. We think about thought experiments and things,
*  but that's not a physical action of doing things. It's more like what you would do
*  in certain situations. So imagine movement, it never really connected with me. I guess you could
*  maybe describe it as a professional athlete, swinging a baseball bat or swinging a golf club.
*  Imagine what you're supposed to do, but then you go right to that and physically do it. Then you
*  get a bat in your hand and then you do what you've been imagining. And so I don't have that connection.
*  So telling me to imagine something versus attempting it, there wasn't a lot that I could do there
*  mentally. I just kind of had to accept what was going on and try. But the attempt to move a thing,
*  it all made sense to me. If I try to move, then there's a signal being sent in my brain. And as
*  long as they can pick that up, then they should be able to map it to what I'm trying to do.
*  And so when I first moved the cursor like that, it was like, yes, this should happen. I'm not
*  surprised by that. But can you clarify, is there supposed to be a difference between
*  imagined movement and attempted movement? Yeah, just that in imagined movement, you're not
*  attempting to move at all. So it's- You're visualizing what you're doing. And then
*  theoretically, is that supposed to be a different part of the brain that lights up in those two
*  different situations? Yeah, not necessarily. I think all these signals can still be represented
*  in the motor cortex. But the difference I think has to do with the naturalness of imagining
*  something worse. Attempting and the fatigue of that over time. And by the way, on the mic is
*  bliss. So this is just different ways to prompt you to kind of get to the thing that you're around.
*  Yeah. Attempted movement does sound like the right thing. Try. Yeah. I mean, it makes sense to me.
*  Because imagine for me, I would start visualizing. In my mind, visualizing. Attempted, I would
*  actually start trying to like- Yeah. I mean, I did like combat sports my whole life at wrestling.
*  When I'm imagining a move, see, I'm like moving my muscle. Exactly. There is a bit of an activation
*  almost versus visualizing yourself like a picture doing it. Yeah. It's something that I feel like
*  naturally anyone would do. If you try to tell someone to imagine doing something, they might
*  close their eyes and then start physically doing it. But it's just- Just think like- Yeah.
*  It's hard. It was very hard at the beginning. But attempted worked. Attempted worked. It worked just
*  like it should work like a charm. I remember there was like one Tuesday we were messing around and
*  I think, I forget what swear word you used, but there's a swear word that came out of your mouth
*  when you figured out you could just do the direct cursor control. Yeah. It blew my mind,
*  like no pun intended. Blew my mind when I first moved the cursor just with my thoughts and not
*  attempting to move. It's something that I found over the couple of weeks building up to that.
*  That as I get better cursor controls, like the model gets better, then it gets easier for me to
*  like, I don't have to attempt as much to move it. And part of that is something that I'd even talked
*  with them about when I was watching the signals of my brain one day. I was watching
*  when I attempted to move to the right and I watched the screen as I saw the spikes.
*  I was seeing the spike, the signal was being sent before I was actually attempting to move.
*  I imagine just because when you go to say move your hand or any body part, that signal gets sent
*  before you're actually moving, has to make it all the way down and back up before you actually do
*  any sort of movement. So there's a delay there. And I noticed that there was something going on
*  in my brain before I was actually attempting to move. That my brain was anticipating what I wanted
*  to do. And that all started sort of, I don't know, like percolating in my brain. It was just sort of
*  there, like always in the back. That's so weird that it could do that. It kind of makes sense,
*  but I wonder what that means as far as using the Neuralink. And then as I was playing around with
*  the attempted movement and playing around with the cursor, and I saw that as the cursor control
*  got better, that it was anticipating my movements and what I wanted it to do, like cursor movements,
*  what I wanted to do a bit better and a bit better. And then one day I just randomly,
*  as I was playing web grid, I looked at a target before I had started attempting to move. I was
*  just trying to get over, train my eyes to start looking ahead. Like, okay, this is the target I'm
*  on, but if I look over here to this target, I know I can maybe be a bit quicker getting there.
*  And I looked over and the cursor just shot over. It was wild. I had to take a step back. I was like,
*  this should not be happening. All day I was just smiling. I was so giddy. I was like, guys,
*  do you know that this works? I can just think it and it happens. Which they'd all been saying
*  this entire time, I can't believe you're doing all this with your mind. I'm like, yeah, but is it
*  really with my mind? I'm attempting to move and it's just picking that up. So it doesn't feel like
*  it's with my mind. But when I moved it for the first time like that, it was, oh man, it made me
*  think that this technology, that what I'm doing is actually way, way more impressive than I ever
*  thought. It was way cooler than I ever thought. And it just opened up a whole new world of
*  possibilities of like what could possibly happen with this technology and what I might be able to
*  be capable of with it. Because you had felt for the first time like this was digital telepathy,
*  you're controlling a digital device with your mind. That's a real moment of discovery. That's
*  really cool. You've discovered something. I've seen scientists talk about a big aha moment,
*  like Nobel Prize winning. They'll have this like, holy crap. Whoa.
*  Yeah. That's what it felt like. I felt like I had discovered something, but for me,
*  maybe not necessarily for the world at large or this field at large. It just felt like an aha
*  moment for me. Like, oh, this works. Obviously it works. And so that's what I do all the time now.
*  I kind of intermix the attempted movement and imagined movement. I do it all together because
*  I've found that there is some interplay with it that maximizes efficiency with the cursor.
*  So it's not all like one or the other. It's not all just, I only use attempted or I only use like
*  imagined movements. It's more I use them in parallel. And I can do one or the other. I can
*  just completely think about whatever I'm doing. But I don't know. I like to play around with it.
*  I also like to just experiment with these things. Like every now and again, I'll get this idea in
*  my head. Like, hmm, I wonder if this works and I'll just start doing it. And then afterwards,
*  I'll tell them, by the way, I wasn't doing that. Like you guys wanted me to. I thought of something
*  and I wanted to try it. And so I did. It seems like it works. So maybe we should like explore
*  that a little bit. So I think that discovery is not just for you, at least from my perspective,
*  that's a discovery for everyone else who ever uses in your link that this is possible.
*  Like, I don't think there's an obvious thing that this is even possible. It's like, I was saying to
*  Bliss earlier, it's like the four minute mile. People thought it was impossible to run a mile
*  in four minutes. And once the first person did it, then everyone just started doing it. So just to
*  show that it's possible, that paves the way to like, anyone can not do it. That's the thing
*  that's actually possible. You don't need to do the attempted movement. You can just go direct.
*  That's crazy.
*  For people who don't know, can you explain how the link app works? You have an amazing stream
*  on the topic. Your first stream, I think on X describing the app. Can you just describe how
*  it works? Yeah. So it's just an app that Neuralink created to help me interact with the computer.
*  So on the link app, there are a few different settings and different modes and things I can
*  do on it. So there's like the body mapping, if we kind of touched on. There's a calibration.
*  Calibration is how I actually get cursor control. So calibrating what's going on in my brain to
*  translate that into cursor control. So it will pop out models. What they use, I think is like time.
*  So it would be five minutes and calibration will give me so good of a model. And then if I'm in it
*  for 10 minutes and 15 minutes, the models will progressively get better. And so the longer I'm
*  in it, generally the better the models will get. That's really cool because you often refer to the
*  models. The model is the thing that's constructed once you go through the calibration step. And then
*  you also talked about sometimes you'll play like a really difficult game like Snake just to see how
*  good the model is. Yeah. So Snake is kind of like my litmus test for models. If I can control Snake
*  decently well, then I know I have a pretty good model. So yeah, the link app has all of those as
*  web grid in it now. It's also how I connect to the computer just in general. So they've given me a
*  lot of voice controls with it at this point. So I can say connect or implant disconnect. And as long
*  as I have that charger handy, then I can connect to it. So the charger is also how I connect to the
*  link app to connect to the computer. I have to have the implant charger over my head when I want
*  to connect to have it wake up because the implants in hibernation mode, like always when I'm not using
*  it. I think there's a setting to like wake it up every so long. So we could set it to half an hour,
*  five hours or something if I just want it to wake up periodically. So yeah, I'll like connect to the
*  link app and then go through all sorts of things, calibration for the day, maybe body mapping. I
*  made them give me like a little homework tab because I am very forgetful and I forget to do
*  things a lot. So I have like a lot of data collection things that they want me to do.
*  Is the body mapping part of the data collection or is that also part of the
*  Yeah, it is. It's something that they want me to do
*  daily, which I've been slacking on because I've been doing so much media and traveling.
*  So I've been gotten super famous. Yeah, I've been a terrible first candidate for how much I've
*  been slacking on my homework. But yeah, it's just something that they want me to do every day to,
*  you know, track how well the Neuralink is performing over time and have something to give,
*  I imagine to give to the FDA to, you know, create all sorts of fancy charts and stuff
*  and show like, hey, this is what the Neuralink is outperforming,
*  you know, day one versus day 90 versus day 180 and things like that.
*  What's the calibration step like? Is it like move left, move right?
*  It's a bubble game. So there will be like yellow bubbles that pop up on the screen.
*  First, it is open loop. So open loop, this is something that I still don't fully understand,
*  the open loop and closed loop thing. Me and Blizz talked for a long time about
*  the difference between the two from the on the technical side.
*  Okay. So it'd be great to hear your side of the story.
*  Open loop is basically, I have no control over the cursor. The cursor will be moving
*  on its own across the screen and I am following by intention the cursor to different bubbles.
*  And then my algorithm is training off of what like the signals it's getting are as I'm doing this.
*  There are a couple of different ways that they've done it. They call it center out targets.
*  So there will be a bubble in the middle and then eight bubbles around that.
*  And the cursor will go from the middle to one side. So say middle to left, back to middle to up
*  to middle, like upright. And they'll do that all the way around the circle.
*  And I will follow that cursor the whole time. And then it will train off of my intentions,
*  what it is expecting my intentions to be throughout the whole process.
*  Can you actually speak to when you say follow?
*  Yes.
*  You don't mean with your eyes, you mean with your intentions.
*  Yeah. So generally for calibration, I'm doing attempted movements
*  because I think it works better. I think the better models as I progress through calibration,
*  make it easier to use imagine movements.
*  So calibrated on attempted movement will create a model that makes it really effective for you to
*  then use the force.
*  Yes. I've tried doing calibration with imagined movement and it just doesn't work as well
*  for some reason. So that was the center out targets. There's also one where
*  a random target will pop up on the screen and it's the same. I just like move, I follow along
*  with wherever the cursor is to that target all across the screen. I've tried those with
*  imagined movement. And for some reason, the models just don't,
*  they don't give as high levels quality when we get into close loop. I haven't played around with it
*  a ton. So maybe like the different ways that we're doing calibration now might make it a bit better.
*  But what I've found is there will be a point in calibration where I can use
*  imagined movement before that point, it doesn't really work. So if I do calibration for 45 minutes,
*  the first 15 minutes, I can't use imagined movement. It just like doesn't work for some reason.
*  And after a certain point, I can just sort of feel it. I can tell it moves different.
*  That's the best way I can describe it. Like it's almost as if it is anticipating what I am
*  going to do again, before I go to do it. And so using attempted movement for 15 minutes,
*  at some point, I can kind of tell when I like move my eyes to the next target that the cursor is
*  starting to like pick up, like it's starting to understand it's learning like what I'm going to do.
*  So first of all, it's really cool that I mean, you're our true pioneer in all of this,
*  you're like exploring how to do every aspect of this most effectively. And there's just,
*  I imagine so many lessons learned from this. So thank you for being a pioneer and all these
*  kinds of different like super technical ways. And it's also cool to hear that there's like a
*  different like feeling to the experience when it's calibrated in different ways. Like just,
*  because I imagine your brain is doing something different. And that's why there's a different
*  feeling to it. And then try and define the words and the measurements to those feelings would be
*  also interesting. But at the end of the day, you can also measure your actual performance,
*  whether it's snake or web grid, you can see like what actually works well. And you're saying
*  for the open loop calibration, the attempted movement works best for now. Yep. Yep. So the
*  open loop, you don't get the feedback that something that you did something.
*  Yeah, I'm just frustrating. No, no, it makes sense to me. Like, we've done it with a cursor
*  and without a cursor in open loop. So sometimes it's just say for like the center out, the,
*  you'll start calibration with a bubble lighting up, and I push towards that bubble. And then
*  when that bubble, you know, when it's pushed towards that bubble for say, three seconds,
*  a bubble will pop, and then I come back to the middle. So I'm doing it all just by my intentions,
*  like that's what it's learning anyway. So it makes sense that as long as I
*  follow what they want me to do, you know, like follow the yellow brick road, that it'll all
*  work out. You're full of great references. Is the bubble game fun? Like, yeah, they always feel so
*  bad making me do calibration, like, oh, we're about to do, you know, a 40 minute calibration.
*  I'm like, all right, would you guys want to do two of them? Like, I'm always asking to,
*  like, whatever they need, I'm more than happy to do. And it's not, it's not bad. Like, I get to lie
*  there and, or sit in my chair and, like, do these things with some great people, I get to have great
*  conversations, I can give them feedback. I can talk about all sorts of things. I could throw
*  something on on my TV in the background and kind of like split my attention between them.
*  Like, it's not bad at all.
*  Is there a score that you get? Like, can you do better on the bubble game?
*  No, I would love that. I would love, yeah.
*  Writing down suggestions from Nolan.
*  Making more fun, gamified.
*  Yeah, that's one thing that I really, really enjoy about WebGrid is because I'm so competitive.
*  Like, the higher the BPS, the higher the score, I know the better I'm doing. And so if I, I think
*  I've asked at one point, one of the guys, like, if he could give me some sort of numerical feedback
*  for calibration, like, I would like to know what they're looking at. Like, oh, you know, it is,
*  we see like this number while you're doing calibration. And that means, at least on our end,
*  that we think calibration is going well. And I would love that because I would like to know
*  if what I'm doing is going well or not. But then they've also told me like, yeah,
*  not necessarily like one to one. It doesn't actually mean that calibration is going well
*  in some ways. So it's not like 100%. And they don't want to like skew what I'm experiencing
*  or want me to change things based on that. If that number isn't always accurate to like
*  how the model will turn out or how like the end result, that's at least what I got from it.
*  One thing I do, I have asked them and something that I really enjoy striving for is towards the
*  end of calibration, there is like a time between targets. And so I like to keep, like at the end,
*  that number is low as possible. So at the beginning, it can be, you know, four or five,
*  six seconds between me popping bubbles, but towards the end, I like to keep it below like 1.5.
*  Or if I could get it to like one second between like bubbles, because in my mind that translates
*  really nicely to something like web grid where I know if I can hit a target one every second
*  that I'm doing real, real well. There you go. That's the way to get a score on the
*  calibration is like the speed how quickly you can get from bubble to bubble. Yeah.
*  So there's the open loop, and then it goes to the closed loop. The closed loop
*  can already start giving you a sense because you're getting feedback of like how good the
*  model is. Yeah. So closed loop is when I first get cursor control and how they've described it
*  to me, someone who does not understand this stuff. I am the dumbest person in the room every time.
*  I'm with any of the humility. Yeah. Is that I am closing the loop. So I am actually now
*  the one that is like finishing the loop of whatever this loop is. I don't even know what
*  the loop is. They've never told me. They just say there is a loop and at one point it's open.
*  I can't control and then I get control and it's closed. So I'm finishing the loop.
*  So how long the calibration usually take? You said like 10, 15 minutes.
*  Well, yeah, they're trying to get that number down pretty low. That's what we've been working
*  on a lot recently is getting that down as low as possible. So that way, if this is something that
*  people need to do on a daily basis or if some people need to do on a like every other day
*  basis or once a week, they don't want people to be sitting in calibration for long periods of time.
*  I think they wanted to get it down seven minutes or below, at least where we're at right now. It'd
*  be nice if they you never had to do calibration. So we'll get there at some point, I'm sure the
*  more we learn about the brain and like, I think that's the dream. I think right now for me to get
*  really, really good models. I'm in calibration 40 or 45 minutes. And I don't mind, like I said,
*  they always feel really bad. But if it's going to get me a model that can break these records on
*  WebGrid, I'll stay in it for flipping two hours. Let's talk business. So WebGrid,
*  I saw a presentation that where Bliss said by March, you selected 89,000 targets in WebGrid.
*  Can you explain this game? What is WebGrid and what does it take to be a world class performer
*  in WebGrid as you continue to break world records? Yeah.
*  It's like a gold medalist talk. Well, you know, I'd like to thank everyone who's helped me get
*  here. My coaches, my parents for driving me to practice every day at five in the morning.
*  Like thank God. And just overall, my dedication to my craft.
*  The interviews with athletes are always like that exact template.
*  Yeah. So WebGrid is a grid themselves.
*  It's literally just a grid. They can make it as big or small as you can make a grid. A single box
*  on that grid will light up and you go and click it. And it is a way for them to benchmark how good
*  a BCI is. So it's, you know, pretty straightforward. You just click targets. Only one
*  blue cell appears and you're supposed to move the mouse to there and click on it.
*  So I like playing on like bigger grids because it, the bigger the grid, the like more
*  BPS. It's bits per second that you get every time you click one. So I'll say I'll play on like a 35
*  by 35 grid. And then one of those little squares cell and call it target, whatever will light up
*  and you move the cursor there and you click it. And then you do that forever. And you've been able
*  to achieve at first eight bits per second. And you recently broke that. Yeah. I'm at 8.5 right now. I
*  would have beaten that literally the day before I came to Austin. But I had like a, I don't know,
*  like a five second lag right at the end. And I just had to wait until the latency calmed down.
*  And then I kept clicking, but I was at like 8.01 and then five seconds of lag. And then the next
*  like three targets I clicked all stayed at 8.01. So if I would have been able to click
*  during that time of lag, I probably would have hit, I don't know, I might've hit nine. So I'm there.
*  I'm like, I'm really close. And then this whole Austin trip has really gotten in the way of my
*  web grid playing ability. Yeah. So that's all you're thinking about right now. Yeah. I know.
*  I just want, I want to do better. I want to do better. I want to hit nine. I think,
*  well, I know nine is very, very achievable. I'm right there. I think 10 I could hit maybe in the
*  next month. Like I could do it probably in the next few weeks if I really push. I think you and
*  Ilan are basically the same person. Cause last time I did a podcast with him, he came in extremely
*  frustrated that he can't beat Uber Lilith as a droid. That was like a year ago, I think. I forget
*  like solo and I could just tell there's some percentage of his brain the entire time was
*  thinking like, I wish I was right now attempting. I think he did it. He did it that night. He stayed
*  up and did it that night. It was just crazy to me. I mean, it's in a, in a, in a fundamental way.
*  It's really inspiring. And what you're doing is inspiring in that way. Cause I mean, it's not just
*  about the game. Everything you're doing there has impact by striving to do well on web grid.
*  You're helping everybody figure out how to create the system all along, like the decoding,
*  the software, the hardware, the calibration, all of it, how to make all of that work. So you can
*  do everything else really well. Yeah. It's just really fun. Well, that's also, that's part of the
*  thing is making it fun. Yeah. It's addicting. I'm, I've joked about, um, like what they actually did
*  when they went in and put this thing in my brain, they must've flipped a switch to make me, uh,
*  more susceptible to these kinds of games to make me addicted to like web grid or something. Yeah.
*  Do you know Bliss's high score? Yeah. He said like 14 or something. 17. 17.1 or something.
*  17.01. 17.01. Yeah. He told me he like does it on the floor with peanut butter and he like fasts.
*  It's, it's weird. That sounds like cheating. Sounds like performance enhancing.
*  Nolan's like the first time Nolan played this game, he asked, you know, how good are we at this game?
*  And I think you told me right then, you're not, you're gonna try to beat me. I'm going to get
*  there someday. Yeah. I think I fully believe you. I think I can. I'm excited for that. Yeah. So I've
*  been playing first off with the dwell cursor, which really hampers my web grid playing ability.
*  Basically I have to wait 0.3 seconds for every click. Oh, so you can't do the clicks. You have
*  to, you have to, so you click by dwelling. You said 0.3, 0.3 seconds, which, which sucks. It really
*  slows down how much I'm able to like how high I'm able to get. I still hit like 50, I think I hit
*  like 50 something trials, net trials per minute in that, which was pretty good. Cause I'm able to
*  like, there's one of the settings is also like how slow you need to be moving in order to initiate
*  a click to start a click. So I can tell sort of when I'm on that threshold to start initiating
*  a click just a bit early. So I'm not fully stopped over the target. When I go to click, I'm doing it
*  on my way to the targets a little to try to time it just right. So you're slowing down.
*  Yeah. Just a, just a hair right before the targets. This is like a lead performance. Okay.
*  But that's still, it's, it sucks that there's a ceiling of the 0.3. Well there, I can get down
*  to 0.2 and 0.1. 0.1 is what I've, yeah. And I've played with that a little bit too. I have to
*  adjust a ton of different parameters in order to play with 0.1. And I don't have control over all
*  that on my end yet. It also changes like how the models are trained. Like if I train a model,
*  like in web grid, I like a bootstrap on a model, which basically is them training models as I'm
*  playing web grid based off of like the web grid data that I'm so like, if I play web grid for 10
*  minutes, they can train off that data specifically in order to get me a better model. If I do that
*  with 0.3 versus 0.1, the models come out different. The way that they interact is,
*  it's just much, much different. So I have to be really careful. I found that doing it with 0.3
*  is actually better in some ways, unless I can do it with 0.1 and change all of the different
*  parameters, then that's more ideal. Cause obviously 0.3 is faster than 0.1. So I could,
*  I could get there. I can get there. Can you click using your brain? For right now,
*  it's the hover clicking with the dwell cursor. We, before all the thread retraction stuff happened,
*  we were calibrating clicks, left click, right click. That was my previous ceiling. Before I
*  broke the record again with the dwell cursor was I think on a 35 by 35 grid with left and right click.
*  And you get more BPS, more bits per second using multiple clicks because it's more difficult.
*  Oh, because what is it? You're supposed to do either a left click or like right click.
*  Yeah. Blue targets for left click, orange targets for right click is what they had done.
*  So my previous record of 7.5 was with the blue and the orange targets. Yeah. Which I think if I
*  went back to that now, doing the click calibration, I would be able to, and being able to like
*  initiate clicks on my own, I think I would break that 10 ceiling like in a couple of days max.
*  Yeah. You would start making Bliss nervous about his 17. Why do you think we haven't given him the...
*  Yeah, exactly. So what did it feel like with the retractions that there is some of the threads
*  retracted? It sucked. It was really, really hard. The day they told me was the day of my big Neuralink
*  tour at their Fremont facility. They told me like right before we went over there, it was really
*  hard to hear. My initial reaction was, all right, go in, fix it. Like go in, take it out and fix it.
*  The first surgery was so easy. Like I went to sleep a couple hours later, I woke up and here we are.
*  I didn't feel any pain, didn't take like any pain pills or anything. So I just knew that
*  if they wanted to, they could go in and put in a new one like next day, if that's what it took.
*  Because I just wanted it to be better and I wanted not to lose the capability. I had so much fun
*  playing with it for a few weeks for a month. It had opened up so many doors for me and it
*  opened up so many more possibilities that I didn't want to lose it after a month. I thought it would
*  have been a cruel twist of fate if I had gotten to see the view from the top of this mountain
*  and then have it all come crashing down after a month. And I knew like say the top of the mountain,
*  but like how I saw it was I was just now starting to climb the mountain and I was
*  like there was so much more that I knew was possible. And so to have all of that be taken
*  away was really, really hard. But then on the drive over to the facility, I don't know,
*  like five minute drive, whatever it is, I talked with my parents about it. I prayed about it.
*  I was just like, you know, I'm not going to let this ruin my day. I'm not going to let this ruin
*  this amazing like tour that they have set up for me. Like I want to go show everyone how much I
*  appreciate all the work they're doing. I want to go like meet all of the people who have made this
*  possible. And I want to go have one of the best days of my life. And I did. And it was amazing.
*  And it absolutely was one of the best days I've ever been privileged to experience.
*  And then for a few days, I was pretty down in the dumps. But for like the first few days afterwards,
*  I was just like, I didn't know if it was ever going to work again. And then I just, I made the
*  decision that it, even if I lost the ability to use the Neuralink, even if I lost, even if I like
*  lost out on everything to come, if I could keep giving them data in any way, then I would do that.
*  If I needed to just do like some of the data collection every day or body mapping every day
*  for a year, then I would do it. Because I know that everything I'm doing helps everyone to come
*  after me. And that's all I wanted. I guess the whole reason that I did this was to help people.
*  And I knew that anything I could do to help, I would continue to do. Even if I never got to
*  use the cursor again, then I was just happy to be a part of it. And everything that I had done was
*  just a perk. It was something that I got to experience. And I know how amazing it's going
*  to be for everyone to come after me. So might as well just keep trucking along.
*  That said, you were able to get to work your way up to get the performance back. So this is like
*  going from Rocky 1 to Rocky 2. So when did you first realize that this is possible and what gave
*  you sort of the strength, the motivation, the determination to do it, to increase back up
*  and beat your previous record? Yeah, it was within a couple of weeks.
*  Again, this feels like I'm interviewing an athlete. This is great. I like to thank my parents.
*  The road back was long and hard. There were many difficulties. There were dark days.
*  It was a couple of weeks, I think. And then there was just a turning point. I think they had
*  switched how they were measuring the neuron spikes in my brain. The way in which we were measuring
*  the behavior of individual neurons. So we're switching from individual spike detection to
*  something called spike band power. If you watched the previous segments with either me or DJ,
*  you probably have some content. Yeah, okay. So when they did that, it was kind of like
*  light over the head, like light bulb moment, like, oh, this works. And this seems like we can run
*  with this. And I saw the uptake in performance immediately. I could feel it when they switched
*  over. I was like, this is better. This is good. Everything up till this point for the last few
*  weeks, last whatever, three or four weeks, because it was before they even told me,
*  everything before this sucked. Let's keep doing what we're doing now. And at that point, it was
*  not like, oh, I know I'm still only at, say in web grid terms, four or five BPS compared to my 7.5
*  before. But I know that if we keep doing this, then I can get back there. And then they gave me
*  the dwell cursor. And the dwell cursor sucked at first. It's obviously not what I want. But it
*  gave me a path forward to be able to continue using it and hopefully to continue to help out.
*  And so I just ran with it, never looked back. Like I said, I'm just the kind of person I roll
*  with the punches anyway. So what was the process? What was the feedback loop on the figuring out how
*  to do the spike detection in a way that would actually work well for Nola? Yeah, it's a great
*  question. So maybe just describe first how the actual update worked. It was basically an update
*  to your implant. So we just did an over the air software update to his implants and we could
*  update your Tesla or your iPhone. And that firmware change enabled us to record sort of averages of
*  populations of neurons nearby individual electrodes. So we have less resolution about
*  which individual neuron is doing what, but we have a broader picture of what's going on nearby an
*  electrode overall. And that feedback loop, I mean, basically, as Nola described, it was immediate
*  when we flipped that switch. I think the first day we did that, you had three or four BPS right
*  out of the box. And that was a light bulb moment for, okay, this is the right path to go down.
*  And from there, there's a lot of feedback around like how to make this useful for independent use.
*  So what we care about ultimately is that you can use it independently to do whatever you want.
*  And to get to that point, it required us to re-engineer the UX, as you talked about the
*  dwell cursor, to make it something that you can use independently without us needing to be involved
*  all the time. And yeah, this is obviously the start of this journey. Still, hopefully we get back to
*  the places where you're doing multiple clicks and using that to control much more fluidly everything
*  and much more naturally the applications that you're trying to interface with.
*  And most importantly, get that web grid number up.
*  So how's the, on the hover click, do you accidentally click stuff sometimes?
*  How hard is it to avoid accidentally clicking?
*  I have to continuously keep it moving, basically. So like I said, there's a threshold where it will
*  initiate a click. So if I ever drop below that, it'll start and I have 0.3 seconds to move it
*  before it clicks anything. And if I don't want it to ever get there, I just keep it moving at
*  a certain speed and like just constantly like doing circles on screen, moving it back and forth
*  to keep it from clicking stuff. I actually noticed a couple of weeks back that I was,
*  when I was not using the implant, I was just moving my hand back and forth or in circles.
*  Like I was trying to keep the cursor from clicking and I was just doing it like while I was trying
*  to go to sleep. And I was like, okay, this is a problem. I had to avoid the clicking.
*  I guess does that create problems? Like when you're gaming accidentally click a thing?
*  Yeah. Yeah. It happens in chess. I've lost a number of games because I'll accidentally
*  click something. I think the first time I ever beat you was because of an accident.
*  Yeah. I miss-clicked.
*  It's a nice excuse, right? Anytime you lose, you could just say, it was accidental.
*  You said the app improved a lot from version one when you first started using it. It was very
*  different. So can you just talk about the trial and error that you went through with the team?
*  Like 200 plus pages of notes. Like what's that process like of going back and forth
*  and working together to improve the thing? It's a lot of me just using it like day in and day out
*  and saying like, Hey, can you guys do this for me? Like, give me this. I want to be able to do that.
*  I need this. I think a lot of it just doesn't occur to them maybe until someone is actually
*  using the app, using the implant. It's just something that they just never would have thought of
*  or it's very specific to even like me, maybe what I want. It's something I'm a little worried about
*  with the next people that come is, you know, maybe they will want things much different than how I've
*  set it up or what the advice I've given the team and they're going to look at some of the things
*  they've added for me. Like, that's a dumb idea. Like, why would he ask for that?
*  And so I'm really looking forward to get the next people on because I guarantee that they're going
*  to think of things that I've never thought of. They're going to think of improvements. I'm like,
*  wow, that's a really good idea. Like, I wish I would have thought of that. And then they're also
*  going to give me some pushback about like, yeah, what you are asking them to do here. That's a bad
*  idea. Let's do it this way. And I'm more than happy to have that happen. But it's just a lot of like,
*  you know, different interactions with different games or applications, the internet, just with
*  the computer in general, there's tons of bugs that end up popping up left, right center. So it's just
*  me trying to use it as much as possible and showing them what works and what doesn't work
*  and what I would like to be better. And then they take that feedback and they usually create amazing
*  things for me. They solve these problems in ways I would have never imagined. They're so good at
*  everything they do. And so I'm just really thankful that I'm able to give them feedback and they can
*  make something of it because a lot of my feedback is like really dumb. It's just like, I want this,
*  please do something about it. And we'll come back super well thought out. And it's way better than
*  anything I could have ever thought of or implemented myself. So they're just great. They're really,
*  really cool. As the BCI community grows, would you like to hang out with the other folks with
*  Neuralink? What relationship, if any, would you want to have with them? Because you said they
*  might have a different set of ideas of how to use the thing. Would you be intimidated by their
*  web grade performance? No, no, I hope day one they wipe the floor with me. I hope they beat it
*  and they crush it, double it if they can. Just because on one hand, it's only going to push me
*  to be better because I'm super competitive. I want other people to push me. I think that is
*  important for anyone trying to achieve greatness is they need other people around them who are
*  going to push them to be better. And I even made a joke about it on X once. Once the next people
*  get chosen, cue buddy cop music. I'm just excited to have other people to do this with and to share
*  experiences with. I'm more than happy to interact with them as much as they want. I'm more than happy
*  to give them advice. I don't know what kind of advice I could give them, but if they have
*  questions, I'm more than happy. What advice would you have for the next participant in the clinical
*  trial? That they should have fun with this because it is a lot of fun and that I hope they work
*  really, really hard because it's not just for us. It's for everyone that comes after us.
*  And come to me if they need anything and to go to Neuralink if they need anything. Man,
*  Neuralink moves mountains. They do absolutely anything for me that they can. And it's an amazing
*  support system to have. It puts my mind at ease for so many things that I've had questions about,
*  so many things I want to do. And they're always there and that's really, really nice. And so I
*  would tell them not to be afraid to go to Neuralink with any questions that they have, any concerns,
*  anything that they're looking to do with this and any help that Neuralink is capable of providing.
*  I know they will. And I don't know. I don't know. Just work your ass off because
*  it's really important that we try to give our all to this.
*  So have fun and work hard.
*  Yeah. Yeah. There we go. Maybe that's what I'll just start saying to people. Have fun, work hard.
*  Now you're a real pro athlete. Just keep it short.
*  Maybe it's good to talk about what you've been able to do now that you have a Neuralink implant.
*  Like the freedom you gain from this way of interacting with the outside world.
*  You play video games all night and you do that by yourself. And that's a kind of freedom. Can
*  you speak to that freedom that you gain? Yeah. It's what all, I don't know, people in my position
*  want. They just want more independence. The more load that I can take away from people around me,
*  the better. If I'm able to interact with the world without using my family, without going through
*  any of my friends, like needing them to help me with things, the better. If I'm able to sit up on
*  my computer all night and not need someone to sit me up, say on my iPad, in a position where I can
*  use it and then have to have them wait up for me all night until I'm ready to be done using it.
*  It takes a load off of all of us. And it's really all I can ask for. It's something that
*  I could never thank Neuralink enough for. I know my family feels the same way.
*  Just being able to have the freedom to do things on my own at any hour of the day or night,
*  it means the world to me. I don't know. When you're up at 2 a.m. playing WebGrid
*  by yourself, I just imagine it's darkness and then there's just a light glowing and you're just
*  focused. What's going through your mind? Or are you in a state of flow where it's like the mind
*  is empty, like those Zen masters? Generally, it is me playing music of some sort. I have a
*  massive playlist. I'm just rocking out to music. And then it's also just a race against time
*  because I'm constantly looking at how much battery percentage I have left on my implant.
*  Like, all right, I have 30%, which equates to X amount of time, which means I have to break this
*  record in the next hour and a half or else it's not happening tonight. And so it's a little
*  stressful when that happens. When it's above 50%, I'm like, okay, I got time. It starts getting down
*  to 30 and then 20. It's like, all right, 10%, a little pop-up is going to pop up right here and
*  it's going to really screw my WebGrid flow. It's going to tell me that there's a low battery,
*  pop-up comes up and it's really going to screw me over. So if I'm going to break this record,
*  I have to do it in the next 30 seconds or else that pop-up is going to get in the way,
*  cover my WebGrid. And then after that, I go click on it, go back into WebGrid and I'm like, all
*  right, that means I have 10 minutes left before this thing's dead. That's what's going on in my
*  head, generally that and whatever song is playing. And I want to break those records so bad. It's
*  all I want when I'm playing WebGrid. It has become less of like, oh, this is just a leisurely
*  activity. I just enjoy doing this because it just feels so nice and it puts me at ease. It is no,
*  once I'm in WebGrid, you better break this record or you're going to waste five hours of your life
*  right now. And I don't know, it's just fun. It's fun, man.
*  And have you ever tried WebGrid with two targets and three targets? Can you get
*  higher BPS with that? Can you do that?
*  You mean like different color targets? Or are you being...
*  Oh, multiple targets. Does that change the thing?
*  Yeah. So BPS is a log of number of targets times correct minus incorrect divided by time.
*  And so you can think of like different clicks as basically doubling the number of active targets.
*  Got it.
*  So you basically higher BPS, the more options there are, the more difficult the task.
*  And there's also like Zen mode you've played in before, which is like infinite canvas.
*  It covers the whole screen with a grid. And I don't know.
*  Yeah. And so you can go like, that's insane.
*  He doesn't like it because it didn't show BPS.
*  I had them put in a giant BPS in the background. So now it's like the opposite of Zen mode.
*  It's like super hard mode, like just metal mode of it's just like a giant number in the back.
*  We should rename that. Metal mode is a much better name.
*  So you also play Civilization VI.
*  I love Civ VI, yeah.
*  Usually go with Korea.
*  I do. So the great part about Korea is they focus on like science tech victories,
*  which was not planned. Like I've been playing Korea for years and then all of the
*  nerling stuff happened. So it kind of aligns. But what I've noticed with tech victories is
*  if you can just rush tech, rush science, then you can do anything. Like at one point in the game,
*  you will be so far ahead of everyone technologically that you will have like musket men,
*  infantry men playing sometimes and people will still be fighting with like bows and arrows.
*  And so if you want to win a domination victory, you just get to a certain point with the science
*  and then go and wipe out the rest of the world. Or you can just take science all the way and win
*  that way. And you're going to be so far ahead of everyone because you're producing so much science
*  that it's not even close. I've accidentally won in different ways just by focusing on science.
*  Accidentally won by focusing on science.
*  I was playing only science, obviously, like just science all the way, just tech. And I was trying
*  to get like every tech in the tech tree and stuff. And then I accidentally won through a diplomatic
*  victory. And I was so mad. I was so mad. Because it just like ends the game one turn. It was like,
*  oh, you won. You're so diplomatic. I'm like, I don't want to do this. I should have declared
*  war on more people or something. It was terrible. But you don't need like giant civilizations with
*  tech, especially with Korea, you can keep it pretty small. So I generally just get to a certain
*  military unit and put them all around my border to keep everyone out. And then I will just build
*  up. So very isolationist. Nice. Just working on science. That's it.
*  You're making it sound so fun. It's so much fun. And I also saw civilization seven trailer. Oh,
*  man. I'm so pumped. And that's probably coming out. Come on, Civ seven. Hit me up. All alpha,
*  beta tests, whatever. When is it coming out? 2025. Yeah. Yeah. Next year. Yeah. What other stuff
*  would you like to see improved about the New Orleans cap and just the entire experience?
*  I would like to, like I said, get back to the, like click on demand, like the regular clicks.
*  That would be great. I would like to be able to connect to more devices. Right now, it's just the
*  computer. I'd like to be able to use it on my phone or use it on different consoles, different
*  platforms. I'd like to be able to control as much stuff as possible. Honestly,
*  like an optimist robot would be pretty cool. That would be sick. If I could control an
*  optimist robot, the link app itself, it seems like we are getting pretty dialed in to what
*  it might look like down the road. It seems like we've gotten through a lot of what I want from it,
*  at least. The only other thing I would say is like more control over all the parameters that I
*  can tweak with my like cursor and stuff. There's a lot of things that go into how the cursor moves
*  in certain ways. And I have, I don't know, like three or four of those parameters and they're
*  gain and friction and all that. Gain, friction, yeah. And there's maybe double the amount of
*  those with just like velocity and then with the actual dwell cursor. So I would like all of it.
*  I want as much control over my environment as possible. Especially-
*  You want like advanced mode. You know, like in like there's menus, usually there's basic mode
*  and you're like one of those folks, like the power user advanced.
*  Yeah. That's what I want. I want as much control over this as possible.
*  So yeah, that's really all I can ask for. Just give me everything.
*  Has speech been useful? Like just being able to talk also in addition to everything else?
*  Yeah. You mean like while I'm using it?
*  While you're using it, like speech to text?
*  Oh yeah.
*  Because there's also a keyboard.
*  Yeah. So there's a virtual keyboard. That's another thing I would like to work more on is
*  finding some way to type or text in a different way. Right now it is like a dictation basically
*  and a virtual keyboard that I can use with the cursor. But we've played around with
*  like fingerspelling, like sign language fingerspelling. And that seems really promising.
*  So I have this thought in my head that it's going to be a very similar learning curve that I had with
*  the cursor where I went from attempted movement to imagined movement at one point.
*  I have a feeling, this is just my intuition, that at some point I'm going to be doing
*  fingerspelling and I won't need to actually attempt to fingerspell anymore.
*  That I'll just be able to think the like letter that I want and it'll pop up.
*  That would be epic.
*  Yeah.
*  That's challenging. That's hard. That's a lot of work for you to kind of take that leap,
*  but that would be awesome.
*  And then like going from letters to words is another step. Right now it's fingerspelling
*  and like just the sign language alphabet. But if it's able to pick that up, then it should be able
*  to pick up like the whole sign language language. And so then if I could do something along those
*  lines or just the sign language spelled word, if I can spell it at a reasonable speed and it can pick
*  that up, then I would just be able to think that through and it would do the same thing.
*  I don't see why not after what I saw with the cursor control, I don't see why it wouldn't work,
*  but we'd have to play around with it more.
*  What was the process in terms of like training yourself to go from attempted movement to
*  imagined movement? How long did that take? So like how long would this kind of process take?
*  Well, it was a couple of weeks before it just like happened upon me. But now that I know
*  that that was possible, I think I could make it happen with other things. I think it would be
*  much, much simpler. Would you get an upgraded implant device? Sure. Absolutely. Whenever,
*  whenever they'll let me. So you don't have any concerns for you with the surgery experience?
*  All of it was like no regrets. No. So everything's been good so far. Yep.
*  You just keep getting upgrades. Yeah. I mean, why not? I've seen how much it's
*  impacted my life already. And I know that everything from here on out is going to get
*  better and better. So I would love to, I would love to get the upgrade.
*  What future capabilities are you excited about sort of beyond this kind of telepathy?
*  Is vision interesting? So for folks who, for example, who are blind,
*  so you know, like enabling people to see or for speech.
*  Yeah, there's a lot that's very, very cool about this. I mean, we're talking about the brain. So
*  there's like, this is just motor cortex stuff. There's so much more that can be done. The
*  vision one is fascinating to me. I think that is going to be very, very cool to give someone
*  the ability to see for the first time in their life would just be, I mean, it, it might be more
*  amazing than even helping someone like me. Like that just sounds incredible. The speech thing is
*  really interesting being able to have some sort of like real time translation and cut away that
*  language barrier would be really cool. Any sort of like actual impairments that it could solve
*  like with speech would be very, very cool. And then also there are a lot of different disabilities
*  that all originate in the brain and you would be able to hopefully be able to solve a lot of those.
*  I know there's already stuff to help people with seizures that can be implanted in the brain. This
*  would do, I imagine the same thing. And so you could do something like that. I know that,
*  you know, even someone like Joe Rogan has talked about the possibilities with being able to
*  to stimulate the brain in different ways. I'm not sure. I'm not sure what, you know, like how
*  ethical a lot of that would be. That's beyond me, honestly, but I know that there's a lot that can
*  be done when we're talking about the brain and being able to go in and physically make changes
*  to help people or to improve their lives. So I'm really looking forward to everything that comes
*  from this. And I don't think it's all that far off. I think a lot of this can be implemented
*  within my lifetime, assuming that I live a long life. What you're referring to is things like
*  people suffering from depression or things of that nature potentially getting help.
*  Yeah. Flip a switch like that, make someone happy. I know, I think Joe has talked about it more in
*  terms of like, you want to experience like what a drug trip feels like. Like you want to experience
*  what you like to be on. Of course. Yeah. Mushrooms or something like that. DMT. Like you can just
*  flip that switch in the brain. My buddy Bane has talked about being able to like wipe parts of your
*  memory and re-experience things that like for the first time, like your favorite movie or your
*  favorite book, like just wipe that out real quick and then re-fall in love with Harry Potter or
*  something. I told him, I was like, I don't know how I feel about like people being able to just
*  wipe parts of your memory. That seems a little sketchy to me. He's like, they're already doing it.
*  So sounds legit. I would love memory replay. Just like actually like high resolution replay of all
*  memories. Yeah. I saw an episode of black mirror about that once. I don't think I want it. Yeah.
*  So black mirror always kind of considers the worst case, which is important. I think people don't
*  consider the best case or the average case enough. I don't know what it is about us humans. We want
*  to think about the worst possible thing. We love drama. Yeah. It's like, how is this new technology
*  going to kill everybody? We just love that. We get like, yes, let's watch. Hopefully people
*  don't think about that too much with me. It'll ruin a lot of my plans. Yeah. Yeah. I assume you're
*  going to have to take over the world. I mean, I love your Twitter. You tweeted, I'd like to make
*  jokes about hearing voices in my head since getting the Neuralink, but I feel like people
*  would take it the wrong way. Plus the voices in my head told me not to. Yeah. Yeah. Yeah. Please
*  never stop. So you were talking about optimists. Is that something you would love to be able to do
*  to control the robotic arm or the entirety of optimists? Oh yeah, for sure. For sure. Absolutely.
*  You think there's something like fundamentally different about just being able to physically
*  interact with the world. Yeah. Oh, a hundred percent. I know another thing with being able to
*  give people the ability to feel sensation and stuff to you by going in with the brain and
*  having the Neuralink maybe do that. That could be something that could be transferred through
*  the optimist as well. There's all sorts of really cool interplay between that. And then also, like
*  you said, just physically interacting. I mean, 99% of the things that I can't do myself obviously
*  need a caretaker for, someone to physically do things for me. If an optimist robot could do that,
*  I could live an incredibly independent life and not be such a burden on those around me.
*  And it would change the way people like me live, at least until whatever this is gets cured.
*  But being able to interact with the world physically like that would just be amazing.
*  And they're not just for having to be a caretaker or something, but something like I talked about,
*  just being able to read a book. Imagine an optimist robot just being able to hold a book open in front
*  of me, get that smell again. I might not be able to feel it at that point, or maybe I could again
*  with the sensation and stuff. But there's something different about reading a physical book than
*  staring at a screen or listening to an audio book. I actually don't like audio books. I've listened
*  to a ton of them at this point, but I don't really like them. I would much rather read a physical
*  copy. So one of the things you would love to be able to experience is opening the book, bringing
*  it up to you and to feel the touch of the paper. Oh man, the touch, the smell. It's just something
*  about the words on the page. They've replicated that page color on the Kindle and stuff. It's
*  just not the same. So just something as simple as that. So one of the things you miss is touch.
*  I do. Yeah. A lot of things that I interact with in the world, like clothes or literally any physical
*  thing that I interact with in the world, a lot of times what people around me will do is they'll
*  just come rub it on my face. They'll lay something on me so I can feel the weight. They will rub
*  a shirt on me so I can feel fabric. There's something very profound about touch. And
*  it's something that I miss a lot and something I would love to do again. We'll see.
*  What would be the first thing you do with a hand that can touch? Give your mom a hug after that.
*  Yeah, I know. It's one thing that I've asked God for basically every day since my accident
*  was just being able to one day move, even if it was only my hand, so that way I could squeeze my
*  mom's hand or something just to show her how much I care and how much I love her and everything.
*  Something along those lines, being able to just interact with the people around me,
*  handshake, give someone a hug, I don't know, anything like that. Being able to help me eat.
*  Like I'd probably get really fat, which would be a terrible, terrible thing.
*  Also beat Bliss in chess on a physical chessboard.
*  Yeah, yeah. I mean, there are just so many upsides. Any way to find some way to feel like
*  I'm bringing Bliss down to my level because he's just such an amazing guy and everything about him
*  is just so above and beyond that anything I can do to take him down a notch, I'm really happy.
*  Yeah, humble him a bit. He needs it. Okay, as he's sitting next to me.
*  Did you ever make sense of why God puts good people through such hardship?
*  Oh, man. I think it's all about understanding how much we need God.
*  I don't think that there's any light without the dark. I think that if all of us were happy
*  all the time, there would be no reason to turn to God ever. I feel like there would be
*  no concept of good or bad. I think that as much of the darkness and the evil that's in the world,
*  it makes us all appreciate the good and the things we have so much more.
*  I think when I had my accident, one of the first things I said to one of my best friends was,
*  and this was within the first month or two after my accident, I said,
*  everything about this accident has just made me understand and believe that God is real and that
*  there really is a God, basically. My interactions with him have all been real and worthwhile.
*  He said, if anything, seeing me go through this accident, he believes that there isn't a God.
*  It's a very different reaction, but I believe that it is a way for God to test us, to build
*  our character, to send us through trials and tribulations, to make sure that we understand
*  how precious he is and the things that he's given us and the time that he's given us,
*  and then to hopefully grow from all of that. I think that's a huge part of being here is to
*  not just have an easy life and do everything that's easy, but to step out of our comfort
*  zones and really challenge ourselves because I think that's how we grow.
*  What gives you hope about this whole thing we have going on, human civilization?
*  I think people are my biggest inspiration. Even just being at Neuralink for a few months,
*  looking people in the eyes and hearing their motivations for why they're doing this,
*  it's so inspiring. I know that they could be other places, at Cushier Jobs,
*  working somewhere else, doing X, Y, or Z. That doesn't really mean that much,
*  but instead they're here and they want better humanity. They want better people around them,
*  the people that they've interacted with in their life. They want to make better lives for
*  their own family members who might have disabilities. They look at someone like me
*  and they say, I can do something about that, so I'm going to. It's always been what I've
*  connected with most in the world are people. I've always been a people person and I love
*  learning about people. I love learning how people developed and where they came from.
*  To see how much people are willing to do for someone like me when they don't have to,
*  and they're going out of their way to make my life better, it gives me a lot of hope for just
*  humanity in general. How much we care and how much we're capable of when we all get together
*  and try to make a difference. I know there's a lot of bad out there in the world, but there always
*  has been and there always will be. I think that it shows human resiliency and it shows what we're
*  able to endure and how much we just want to be there and help each other and how much satisfaction
*  we get from that. I think that's one of the reasons that we're here is just to help each other.
*  I don't know, that always gives me hope is just realizing that there are people out there who
*  still care and who want to help. Thank you for being one such human being and continuing to be
*  a great human being through everything you've been through. I'm being an inspiration to many
*  people, to myself for many reasons, including your epic, unbelievably great performance on WebGrid.
*  I will be training all night tonight to try to catch up. You can do it.
*  And I believe in you that once you come back, so sorry to interrupt with the Austin trip,
*  once you come back, eventually beat Bliss. Yeah, yeah, for sure. Absolutely.
*  I'm rooting for you. The whole world is rooting for you. Thank you for everything you've done,
*  man. Thanks, man.
*  Thanks for listening to this conversation with Nolan Arbaugh and before that with Elon Musk,
*  DJ Saw, Matthew McDougall and Bliss Chapman. To support this podcast, please check out our
*  sponsors in the description. And now let me leave you with some words from Aldous Huxley
*  in the doors of perception.
*  Thank you for listening and hope to see you next time.
