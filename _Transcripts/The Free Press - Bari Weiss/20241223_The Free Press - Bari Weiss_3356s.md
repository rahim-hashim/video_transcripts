---
Date Generated: April 08, 2025
Transcription Model: whisper medium 20231117
Length: 3356s
Video Keywords: []
Video Views: 85314
Video Rating: None
Video Description: Think for yourself. Subscribe to The Free Press today: https://thefp.pub/3DmLpLi

Just a few years ago, as AI technology was beginning to spill out of start-ups in Silicon Valley and hitting our smartphones, the political and cultural conversation about this nascent science was not yet clear. I remember asking former Google CEO Eric Schmidt on Honestly in January 2022 if AI was just like the sexy robot in Ex Machina. I literally said to him, “What is AI? How do you define it? I do not understand.”

Today, not only has it become clear what AI is and how to use it—ChatGPT averages more than 120 million active daily users and processes over a billion queries per day—but it’s also becoming clear with the political and cultural ramifications—and the arguments and debates—around AI are going to be over the next few years.

Among those big questions are who gets to lead us into this new age of AI technology, what company is going to get there first and achieve market dominance, how those companies are structured so that bad actors with nefarious incentives can’t manipulate this technology for evil purposes, and what role the government should play in regulating all of this.

At the center of these important questions are two men: Sam Altman and Elon Musk. And if you haven’t been following, they aren’t exactly in alignment. 

They started off as friends and business partners. In fact, Sam and Elon co-founded OpenAI in 2015. But over the years, Elon Musk grew increasingly frustrated with OpenAI until he finally resigned from the board in 2018. That feud escalated this past year when Elon sued Sam and OpenAI on multiple occasions to try to prevent the company from launching a for-profit arm of the business, a structure that Elon claims is never supposed to happen in OpenAI—and he also argues that changing its structure in this way might even be illegal.

On the one hand, this is a very complex disagreement. To understand every single detail of it, you probably need a law degree and special expertise in American tax law. But you don’t need a degree or specialization to understand that at its heart, this feud is about something much bigger and more existential than OpenAI’s business model, although that’s extremely important.

What this is really a fight over is who will ultimately be in control of a technology that some say, if used incorrectly, could very well make human beings obsolete.

So, you know, the stakes are low.

Here to tell his side of the story is Sam Altman. We talk about where AI is headed, and why he thinks superintelligence—the moment where AI surpasses human capabilities—is closer than ever. We talk about the perils of AI bias and censorship, why he donated $1 million to Trump’s inaugural fund as a person who has long opposed Trump, what happens if America loses the AI race to a foreign power like China, and of course, what went wrong between him and the richest man on Earth.
---

# Sam Altman on His Feud with Elon Musk—and the Battle for AI's Future
**The Free Press - Bari Weiss:** [December 23, 2024](https://www.youtube.com/watch?v=DfOt_cqXCFI)
*  What is the fundamental conflict between? [[00:00:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=0.0s)]
*  Elon Musk and his various allies meta being one of them and you guys like what what is the disagreement fundamentally about? [[00:00:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=4.26s)]
*  Look, I'm I don't live inside Elon's head. So this is a little bit of speculation [[00:00:11](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=11.64s)]
*  Elon definitely did a lot to help open eye in the early days and in spite of all of this [[00:00:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=19.2s)]
*  I'm very grateful and I think he's just a sort of legendary entrepreneur [[00:00:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=23.26s)]
*  He's also clearly a bully and he's also someone who clearly likes to get in fights, you know right now it's me [[00:00:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=28.419999999999998s)]
*  It's been Bezos Gates Zuckerberg lots of other people [[00:00:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=33.5s)]
*  Hi, honestly listeners Barry here and I'm so excited for you to listen to this wide-ranging and fascinating conversation [[00:00:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=37.1s)]
*  With open AI's Sam Altman before you watch it [[00:00:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=44.06s)]
*  I wanted to come and talk to you about a big end of year push [[00:00:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=47.82s)]
*  By the end of 2024 in just a few days [[00:00:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=53.14s)]
*  We want to get to a million free press subscribers a million people who value [[00:00:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=56.02s)]
*  Independence and curiosity and who above all want a news source that reflects reality [[00:01:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=61.82s)]
*  If you're here if you're on this YouTube page, we know it's not just because you believe in fearless old-school journalism for yourself [[00:01:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=67.26s)]
*  It's because you think it's a necessity for democracy [[00:01:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=74.14s)]
*  Free pressers tell us again and again that we're not just a media company. We're a public trust [[00:01:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=77.5s)]
*  I'm confident that by becoming one of the first million free pressers you will be getting in on the ground floor [[00:01:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=82.82s)]
*  So before you watch this video take out your cell phone or open a new tab and go to the fp.com [[00:01:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=89.25999999999999s)]
*  Slash subscribe and become a free presser today [[00:01:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=97.33999999999999s)]
*  If you're already signed up you can earn a free year subscription or even a pair of TGIF socks [[00:01:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=100.85999999999999s)]
*  Pre-worn by Nelly if you refer your friends or family members [[00:01:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=107.17999999999999s)]
*  Okay [[00:01:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=110.7s)]
*  One more time before we get to Sam Altman go to the free presses website and the fp.com [[00:01:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=111.17999999999999s)]
*  Slash subscribe and help us get to our goal of a million free pressers by 2025 [[00:01:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=116.38s)]
*  We are so close and we really appreciate your support on to the show from the free press. This is honestly and I'm Barry Weiss [[00:02:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=122.74s)]
*  Just a few years ago as AI [[00:02:11](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=131.57999999999998s)]
*  Technology was beginning to spill out of startups in Silicon Valley and hit our smartphones [[00:02:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=133.94000000000003s)]
*  The political and cultural conversation about this nascent technology was not yet clear [[00:02:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=138.54000000000002s)]
*  Or at least it wasn't clear yet to civilians like me [[00:02:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=144.26000000000002s)]
*  I remember asking former Google CEO Eric Schmidt on honestly in January [[00:02:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=146.74s)]
*  2022 if AI was just like and this is actually what I said the sexy robot in ex Machina [[00:02:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=152.38000000000002s)]
*  I literally said to him what is AI? How do you define it? I do not understand I [[00:02:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=158.82s)]
*  Cringe listening back to that because today in the waning days of 2024 [[00:02:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=165.46s)]
*  Not only has it become clear what AI is and how to use it chat GPT averages more than 120 million daily active users [[00:02:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=170.1s)]
*  And processes over a billion queries per day [[00:02:58](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=178.18s)]
*  But it's also becoming clear what the political and cultural ramifications and the arguments and debates [[00:03:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=181.22s)]
*  Around AI are and what they're going to be over the next few years [[00:03:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=188.3s)]
*  Those are the big questions who gets to lead us into this new age of AI technology [[00:03:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=192.94s)]
*  What company is going to get there first and achieve market dominance? [[00:03:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=198.34s)]
*  How those companies are going to be structured so that bad actors with bad incentives can't manipulate this technology for evil [[00:03:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=202.58s)]
*  Purposes what role the government should play in regulating all of this at the center of these important questions [[00:03:30](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=210.5s)]
*  At least for right now are two men [[00:03:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=217.06s)]
*  Sam Altman and Elon Musk and if you haven't been following they aren't exactly in alignment [[00:03:39](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=219.94s)]
*  I don't trust open AI. I don't trust them all tonight, and I don't think we want to have the most powerful [[00:03:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=226.26s)]
*  AI in the world controlled by someone who is not trustworthy and be profoundly un-american to use [[00:03:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=232.42000000000002s)]
*  political power [[00:03:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=239.34s)]
*  to the degree that Elon has it to [[00:04:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=240.94s)]
*  Hurt your competitors and advantage your own businesses. They started off as friends and business partners [[00:04:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=244.1s)]
*  In fact Sam and Elon co-founded open AI the company that makes chat GPT in 2015 [[00:04:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=249.70000000000002s)]
*  But over the years Elon Musk grew increasingly frustrated with open AI until he finally resigned from the board in 2018 [[00:04:16](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=256.14s)]
*  The feud between Altman and Musk escalated this past year when Elon sued Sam and open AI on multiple occasions [[00:04:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=264.9s)]
*  to try and prevent open AI from launching a for-profit arm of the business a [[00:04:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=272.94s)]
*  Structure that Elon claims is not only never supposed to happen in open AI [[00:04:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=278.78000000000003s)]
*  He likes to remind people that a non-profit [[00:04:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=283.66s)]
*  Transparent company should not become a closed for-profit one [[00:04:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=287.22s)]
*  But he argues that changing its structure in this way might even be illegal now on the one hand [[00:04:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=291.58000000000004s)]
*  This is a very complex disagreement to understand every single detail of it [[00:04:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=297.5s)]
*  You probably need a law degree and special expertise in American tax law neither of which I happen to have [[00:05:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=301.86s)]
*  But you don't need any special degree or specialization [[00:05:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=308.02s)]
*  To understand that at its heart the feud is about something much bigger and more existential than open AI's business model [[00:05:11](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=311.3s)]
*  Although that's extremely important and something we discussed today what this is really about [[00:05:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=318.7s)]
*  I think [[00:05:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=322.86s)]
*  Foundationally is a fight over who will ultimately control this technology a [[00:05:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=323.9s)]
*  Technology that some say if used incorrectly could very well make human beings obsolete. So the stakes are low [[00:05:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=329.82s)]
*  Here to tell his side of the story is Sam Altman [[00:05:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=337.65999999999997s)]
*  We talk about where AI is headed why he thinks super intelligence [[00:05:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=340.98s)]
*  In other words the moment where AI surpasses human capabilities is closer than ever [[00:05:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=345.78s)]
*  We talked about the perils of AI bias and censorship [[00:05:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=350.66s)]
*  Why he donated a million dollars to Trump's inaugural fund as a person who had long opposed Trump [[00:05:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=354.02s)]
*  What happens if America loses the AI race to a foreign power like China? [[00:05:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=359.74s)]
*  And of course what went wrong and is going wrong between him and the richest man on earth. We'll be right back [[00:06:03](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=363.66s)]
*  Sam Altman, thank you so much for coming out. Honestly. Thank you [[00:06:16](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=376.54s)]
*  The last time we spoke and I know you've given a zillion interviews since then but it was in April of 2023 [[00:06:20](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=380.74s)]
*  And it feels like a world away [[00:06:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=386.1s)]
*  chat GPT had just launched and people were just at the very beginning of [[00:06:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=388.9s)]
*  trying to figure out like in the abstract what this technology was and how it might transform their everyday lives and [[00:06:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=394.62s)]
*  Now sitting here in December of 2024 chat GPT is a household name [[00:06:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=402.34s)]
*  So is open AI and of course some of your competitors are too like perplexity and Gemini and Claude [[00:06:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=407.7s)]
*  Average Americans are using these tools every day [[00:06:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=413.5s)]
*  Everything from math tutoring to debugging code to drafting emails and it's very very good at doing that [[00:06:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=416.58s)]
*  Tell me about how chat GPT and I guess AI technology more broadly has changed [[00:07:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=421.78s)]
*  Since we last spoke a year and a half ago and whether or not it's where you expected it to be today or further along [[00:07:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=427.78s)]
*  So I think there's two different things when you talk about one is how much the technology itself has changed and that has gotten way [[00:07:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=433.85999999999996s)]
*  Better if you think about the AI we were excited about back in April of 2023 [[00:07:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=439.06s)]
*  It was so primitive relative to what we have now and the things that the technology is capable of are [[00:07:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=443.53999999999996s)]
*  Pretty mind-blowing to me [[00:07:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=449.9s)]
*  But even more than that that the rate at which it will continue to get better over the next year and if we came back [[00:07:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=451.14s)]
*  In another 18 months and talked about what it can do [[00:07:35](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=455.78s)]
*  I think it'll feel like as big or maybe even bigger as a gap from April 20 23 to December of 2024 [[00:07:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=458.74s)]
*  As projecting that same amount of time, I guess it's more like 20 months going forward. The other thing that's happened is [[00:07:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=465.14s)]
*  It's really integrated into society like back then it was still a curiosity [[00:07:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=471.98s)]
*  So many people had heard of people really use it now a lot for like a lot of their work their personal lives there. It's [[00:07:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=476.58s)]
*  I've never seen a technology become widely adopted this fast [[00:08:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=484.9s)]
*  Not just as some mean people like dabble with with something that people like really use and all the ways you were talking about [[00:08:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=488.38s)]
*  so that [[00:08:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=493.26s)]
*  That part of the adoption curve happened much more quicker than I thought I expected the technology to happen quickly [[00:08:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=495.74s)]
*  Give me a sense of like how are you using the tool that you have helped create in your daily life? [[00:08:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=502.06s)]
*  Like the way that most people I know are using it Tyler Cowan and lots of people who are like passionate early adopters [[00:08:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=508.1s)]
*  It almost seems to have like replaced Google for them [[00:08:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=514.06s)]
*  And it's just like a much much deeper Google. Is that how it's working for you? [[00:08:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=516.5s)]
*  I use it in all sorts of ways, but the newest one a few months ago [[00:08:39](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=519.86s)]
*  we release we released search integration and now chat GPT can search the internet for kind of real-time information and [[00:08:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=524.54s)]
*  Of everything we've ever shipped that was the one that felt like it doubled my usage all at once and [[00:08:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=534.1s)]
*  since then I [[00:09:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=540.02s)]
*  Mean, I must have still used Google for something [[00:09:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=541.74s)]
*  But I can't remember what it is [[00:09:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=544.62s)]
*  Wow, and I switched chat GPT to be my default search in Chrome [[00:09:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=547.54s)]
*  And I have not looked back [[00:09:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=553.54s)]
*  the degree to which [[00:09:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=557.62s)]
*  That behavior changed me for something that was really deeply ingrained and [[00:09:20](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=560.6999999999999s)]
*  Now the fact that like when I remember the way that I used to search [[00:09:25](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=565.26s)]
*  Feels like kind of oh man that was like a pre iPhone kind of equivalent [[00:09:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=569.34s)]
*  That's the sort of like level of shift that I feel about it [[00:09:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=572.98s)]
*  That's that's been the most surprising change to me in the last few months is that I don't I do all my searching now [[00:09:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=576.86s)]
*  Instead of checking what do you call it? Do you call it searching or is there a verb in the way that googling suburb? [[00:09:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=585.26s)]
*  I still call it search [[00:09:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=590.02s)]
*  I mean, I just like people other people say like I chatted it or I chatted I chatted it because I chatted it a lot like [[00:09:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=591.1s)]
*  You say I chatted it a lot like young people seem to just only call it chat, but I would say I just use search [[00:09:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=597.5s)]
*  Sam in September so just a few months ago. You published this manifesto on your website [[00:10:03](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=603.62s)]
*  predicting the emergence of super intelligence in the next few years or as you put it and memorably in the next few thousand days [[00:10:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=609.38s)]
*  Explain to us what super intelligence is [[00:10:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=617.06s)]
*  Tell us how we'll know if it's actually here and how it stands to change people's lives [[00:10:21](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=621.1s)]
*  over the next decades [[00:10:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=627.3s)]
*  one one thing that I use is a sort of [[00:10:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=629.78s)]
*  My attempt at my own mental framework for it is the rate of scientific progress [[00:10:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=633.54s)]
*  If the rate of scientific progress that's happening in the world as a whole [[00:10:39](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=639.02s)]
*  Tripled maybe even like 10x [[00:10:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=644.8199999999999s)]
*  You know the discoveries that we used to expect to take 10 years and the technological progress that we used to expect [[00:10:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=646.66s)]
*  To take 10 years if that happened every year and then we compounded on that the next one [[00:10:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=652.62s)]
*  and the next one and the next one that to me would feel like super intelligence had arrived and [[00:10:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=657.26s)]
*  It would I think in many ways change [[00:11:03](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=663.02s)]
*  The way that society the economy work it what it won't change and I think a lot of the sort of AI [[00:11:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=667.06s)]
*  Commentators get this wrong is it won't change like the deep fundamental human drives [[00:11:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=675.18s)]
*  And so in that sense, you know, we've been through many technological revolutions before [[00:11:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=679.86s)]
*  things that we tend to care about and [[00:11:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=684.9s)]
*  What what drive all of us I think change very little or maybe not at all through most of those [[00:11:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=687.26s)]
*  But the world in which we exist will change a lot [[00:11:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=693.66s)]
*  Okay [[00:11:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=697.02s)]
*  Well Sam one of the reasons we wanted to have this conversation with you today is not just because we want to hear about the ways [[00:11:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=697.54s)]
*  That AI is gonna transform the way that we live and work [[00:11:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=703.78s)]
*  But because you're in a very public battle right now with your original open AI co-founder [[00:11:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=707.62s)]
*  Elon Musk and I think it's safe to say that most listeners of this show will like vaguely know that there's a conflict between [[00:11:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=712.98s)]
*  Elon Musk having to do with this one of his companies one of his many companies [[00:12:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=720.7s)]
*  But they're certainly not following the nitty-gritty details of the various lawsuits and of the conflict more generally [[00:12:06](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=726.38s)]
*  So I want to try and summarize it for you in the most fair way that I can and then you'll tell me if I've gotten it [[00:12:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=732.5600000000001s)]
*  Wrong or where I've where I've overstepped so open AI begins in 2015 and it starts as a nonprofit and in a blog post [[00:12:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=738.94s)]
*  Introducing open AI to the world in December of that year you wrote this [[00:12:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=747.58s)]
*  Open AI is a nonprofit artificial intelligence research company [[00:12:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=751.94s)]
*  Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole [[00:12:35](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=755.94s)]
*  Unconstrained by a need to generate financial return since our research is free from financial obligations [[00:12:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=762.6600000000001s)]
*  We can better focus on a positive human impact and this was a huge aspect of the brand [[00:12:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=767.9s)]
*  Then fast forward four years in 2019 [[00:12:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=773.18s)]
*  Open AI moves to what it called a hybrid model with a for-profit arm that got a billion dollar investment from Microsoft in that year [[00:12:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=776.42s)]
*  since then Microsoft has poured something like 13 billion dollars it might be a higher number more into the company and [[00:13:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=784.98s)]
*  Elon was one of the co-founders as I mentioned since the beginning but his relationship with the company soured over time [[00:13:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=792.9000000000001s)]
*  Because he disagreed with the shift that I just described the shift from this nonprofit model to a hybrid model [[00:13:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=799.6600000000001s)]
*  and he eventually leaves the company and steps down from the board and [[00:13:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=806.5s)]
*  That takes us to this year in which Elon has sued you and open AI on several different occasions so far this year [[00:13:30](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=810.74s)]
*  And he has gone given many interviews and posted [[00:13:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=817.98s)]
*  Countless amount of tweets or X's or whatever was supposed to call them about this conflict [[00:13:41](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=821.1800000000001s)]
*  All of the lawsuits claim that you were in some kind of contract violation [[00:13:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=826.26s)]
*  By putting profits ahead of the public good in the move to advance AI [[00:13:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=831.5400000000001s)]
*  And then last month and this is the most recent development [[00:13:55](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=835.98s)]
*  Elon asked the district judge in California to block open AI from converting to this for-profit structure [[00:13:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=839.6600000000001s)]
*  Okay, that was a mouthful did I summarize it properly and is there anything crucial that I left out you [[00:14:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=847.3s)]
*  Must summarize it properly, but I mean it was Elon that most wanted to convert not many [[00:14:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=853.7s)]
*  It was Elon that most wanted open AI to be a for-profit at one point and had made a bunch of proposals that would have [[00:14:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=859.74s)]
*  also things like opening I being part of Tesla but mostly just create a new for-profit that he was gonna be in control of and [[00:14:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=867.34s)]
*  You know, so other than that I think a lot of the summary errors is correct [[00:14:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=873.54s)]
*  I have a bunch of thoughts and opinions on it [[00:14:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=878.42s)]
*  But as a statement of facts that was otherwise mostly correct give us like the 10,000 foot version [[00:14:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=880.28s)]
*  What is the fundamental conflict between? [[00:14:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=886.0799999999999s)]
*  Elon Musk and his various allies meta being one of them and you guys like what what is the disagreement? [[00:14:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=890.26s)]
*  Fundamentally about look I don't live inside Elon's head. So this is a little bit of speculation [[00:14:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=896.66s)]
*  Elon [[00:15:03](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=903.3s)]
*  Definitely did a lot to help open eye in the early days and in spite of all of this [[00:15:05](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=905.3s)]
*  I'm very grateful and I think he's just a sort of legendary entrepreneur [[00:15:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=909.2199999999999s)]
*  He's also clearly a bully and he's also someone who clearly likes to get in fights, you know right now it's me [[00:15:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=914.42s)]
*  It's been Bezos Gates Zuckerberg lots of other people and I think fundamentally this is about [[00:15:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=919.5s)]
*  Open eyes doing really well Elon cares about doing really well Elon [[00:15:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=926.24s)]
*  Started and now runs a very direct competitor. That's trying to do exactly what open AI does [[00:15:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=931.92s)]
*  and [[00:15:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=940.48s)]
*  I'll point out is a structure [[00:15:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=942.0s)]
*  You know, it's like a public benefit Corp and I heard Elon has majority ownership and control and [[00:15:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=944.56s)]
*  Seems like a reasonable thing he would do. I think a lot of the press has been [[00:15:49](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=949.92s)]
*  Missed reported we're not like the non-profit even if we go through with some of the any of the conversion ideas or [[00:15:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=953.64s)]
*  Evolution ideas we're talking about something nonprofit goes away. The nonprofit doesn't like stopping nonprofit becomes a for-profit [[00:16:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=960.84s)]
*  We've talked publicly about maybe we evolve our current LLC into a PBC [[00:16:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=967.28s)]
*  But anything we do with strength of the nonprofit the nonprofit would continue to exist would continue to serve [[00:16:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=972.08s)]
*  Hopefully better serve the same purpose and the overall mission of the nonprofit is to [[00:16:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=978.24s)]
*  Re-establish the vision of the company that you talked about which is develop this incredible technology do it in a way that we think is [[00:16:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=983.64s)]
*  Maximally beneficial to humans and get it out into the world for people we keep doing that [[00:16:30](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=990.36s)]
*  I'm incredibly proud of our track record on doing that so far people as you were saying earlier use chat GPT and love it [[00:16:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=994.92s)]
*  There's an incredible free tier of chat GPT. We lose money on it. It's not ad support or anything [[00:16:41](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1001.0s)]
*  We just want to put AI in people's hands. We continue to want to deploy this technology [[00:16:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1005.8s)]
*  So that people [[00:16:49](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1009.92s)]
*  Co-evolve with it understand it the world is going through this process [[00:16:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1011.4399999999999s)]
*  it's going through right now of contending with AI and eventually a GI and thinking that's going to go and [[00:16:55](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1015.12s)]
*  Everything we're doing I believe Elon would be happy about if he weren't in control of the company [[00:17:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1020.68s)]
*  He left when he thought we were like on a trajectory to certainly fail [[00:17:05](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1025.0s)]
*  He and also wouldn't do something where he had like total control over open AI [[00:17:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1029.0s)]
*  But I think it's like a little bit of a sideshow and the right thing for us to do is just keep [[00:17:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1033.12s)]
*  Doing incredible research keep shipping products people love and and most importantly like keep pursuing this mission of [[00:17:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1038.1200000000001s)]
*  AGI to benefit people and getting that out to the world for someone who's just sort of tuning into this topic [[00:17:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1044.64s)]
*  Why is it important Sam that open AI has a for-profit arm or converts in the way that you've been talking about? [[00:17:30](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1050.5600000000002s)]
*  Why why is that essential to your growth when we started open AI? [[00:17:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1058.44s)]
*  We thought it's hard to go back and remember how different things were in 2015 [[00:17:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1062.5600000000002s)]
*  That was before language models and chatbots [[00:17:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1068.68s)]
*  It was way before chat GPT we were doing research and publishing papers and working on AI's the complete video games and [[00:17:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1070.96s)]
*  Control robotic hands and things like that and we we were supposed to get a billion dollars [[00:17:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1076.48s)]
*  But ended up not we thought with a billion dollars [[00:18:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1080.92s)]
*  We could make substantial progress towards what we were trying to do as we learned more and got into the scaling language model world [[00:18:03](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1083.76s)]
*  We realized that it was not going to cost 1 billion or even 10 [[00:18:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1090.48s)]
*  But like 100 billion plus and we couldn't do that as a nonprofit so that was the fundamental reason for it [[00:18:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1093.1999999999998s)]
*  Okay, so like it's based [[00:18:20](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1100.1599999999999s)]
*  Maybe another way to say it is like it's absolutely essential for the computational power to create [[00:18:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1102.56s)]
*  Okay, and every other effort pursuing AI has realized this and is set up in some way where they can sort of access capital markets [[00:18:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1107.8s)]
*  You've said a lot of different things about Elon in recent days [[00:18:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1114.32s)]
*  You gave this interview at Dealbook where Andrew Ross Sorkin is sort of asking you how you feel about the conflict and you say [[00:18:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1116.84s)]
*  Sad and you also say that you think Elon's companies are awesome [[00:18:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1123.08s)]
*  And then he asked you, you know [[00:18:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1126.6799999999998s)]
*  Do you think he's gonna use his newfound political influence to kind of? [[00:18:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1128.76s)]
*  Punish you or punish open AI or punish his competitors and you said in that interview that you thought he would do the right thing [[00:18:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1132.76s)]
*  How do you square that with what you just told me which is that Elon's a bully bullies don't typically do the right thing [[00:18:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1139.96s)]
*  I think they can totally be like I think I think there are people who will really be a jerk on Twitter [[00:19:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1144.9199999999998s)]
*  Who will still not like abuse the system of a country they're now in a sort of [[00:19:11](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1151.44s)]
*  extremely influential political role for [[00:19:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1157.12s)]
*  That seems completely different to me [[00:19:20](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1160.1599999999999s)]
*  Until now much of this battle for you know for those of us who are like perpetually online perpetually on Twitter [[00:19:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1163.04s)]
*  We have been following the conflict via like tweets lobbed sub tweets [[00:19:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1168.72s)]
*  It's all sort of been playing out in real time on Twitter for us to watch [[00:19:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1173.28s)]
*  Open AI though has sort of been in like response mode sometimes or mostly kind of ignoring everything [[00:19:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1177.88s)]
*  That's sort of how I'd characterize it that changed a few days ago when you guys published this very very long memo on [[00:19:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1184.4s)]
*  Open it's like a blog post on open AI's website people should go and read it again [[00:19:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1192.08s)]
*  We'll put in the show notes and it's sort of like complete. It's it's like a timeline going back to 2015 [[00:19:55](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1195.8s)]
*  Proving from your perspective that you know via emails and screenshots of texts and [[00:20:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1202.48s)]
*  explanations of those screenshots and those texts that [[00:20:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1209.56s)]
*  Elon wanted open AI to or Elon rather was open to open AI being a for-profit [[00:20:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1213.16s)]
*  Going all the way back then I read all 29 pages for those who don't want to do that [[00:20:20](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1220.92s)]
*  They could go to chat GPT and ask them to summer asked chat to summarize it [[00:20:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1226.64s)]
*  Here's how chat GBT summarized it this article details the rift between Elon Musk and open AI's leadership [[00:20:30](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1230.8s)]
*  Particularly Sam Altman stemming from Musk's dissatisfaction with open AI shift from a non-profit to a hybrid for-profit model [[00:20:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1237.56s)]
*  This feud is crucial chat told me because it underscores the broader ethical dilemma of how AI should be developed and controlled [[00:20:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1244.96s)]
*  Whether it should prioritize public good or corporate profit [[00:20:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1251.92s)]
*  Especially as powerful AI technologies become increasingly influential in society in the economy. I thought that was pretty good [[00:20:55](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1255.12s)]
*  What do you think? [[00:21:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1262.1999999999998s)]
*  No, but on your general point you are right that we do not sit there and like throw tomatoes back and forth on Twitter [[00:21:03](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1263.36s)]
*  The reason for this one was we had to make a legal filing and we wanted to provide some context [[00:21:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1269.3999999999999s)]
*  We've published about this once before also when we had to make a legal filing [[00:21:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1274.26s)]
*  I've lost track of how many times that Elon has sued us [[00:21:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1277.6s)]
*  I think it's like for you know withdraws changes at goes for this preliminary injunction [[00:21:21](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1281.32s)]
*  Whatever. Our job is to build a GI in a way that benefits humanity and figure out how to safely and broadly distribute it [[00:21:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1286.3999999999999s)]
*  Our job is not to engage in [[00:21:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1294.6399999999999s)]
*  Like a Twitter fight with Elon [[00:21:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1297.72s)]
*  But when we have to respond to a legal filing we will we will and sometimes will provide context [[00:21:41](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1301.28s)]
*  Only done this twice in the early days of open AI the brand like the way I encountered the brand of it was [[00:21:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1307.3200000000002s)]
*  Transparency and [[00:21:55](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1315.88s)]
*  Nonprofit like those were the things that it over and over [[00:21:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1317.88s)]
*  emphasized and the reason you said that you couldn't take any equity and the reason you took such a small salary is because [[00:22:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1321.68s)]
*  You said you know, I don't want to be conflicted [[00:22:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1328.4s)]
*  I want to always be motivated to do the thing that's best for humanity [[00:22:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1330.68s)]
*  The day after open AI launched in December in 2015 you described it to Vanity Fair as a [[00:22:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1334.28s)]
*  Nonprofit company to save the world from a dystopian future. You also said that [[00:22:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1339.96s)]
*  Trying to make open AI a for-profit would lead to quote misaligned incentives that would be suboptimal to the world as a whole. I [[00:22:25](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1345.12s)]
*  Guess I want to ask like do you still agree with that? [[00:22:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1353.3999999999999s)]
*  But simply you've had to adapt to the reality which is that developing these models takes [[00:22:35](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1355.6399999999999s)]
*  billions and billions and billions of dollars [[00:22:41](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1361.6399999999999s)]
*  Two things one. I think I was like a little bit wrong about that [[00:22:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1364.08s)]
*  And I have been although I have had concerns [[00:22:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1367.48s)]
*  I have been impressed by how much not just us but the other AI labs [[00:22:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1371.76s)]
*  even though they have this like a wild sort of [[00:22:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1377.8s)]
*  market or economic incentive have really [[00:23:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1381.48s)]
*  Been focused on developing safe models. I think there's many factors that went into that [[00:23:05](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1385.1999999999998s)]
*  We did get a little lucky on the direction the technology went [[00:23:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1390.88s)]
*  But also if you deploy these models in a way that is harmful to people you would like very quickly [[00:23:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1394.16s)]
*  I believe lose your license to operate if it was an obvious one now [[00:23:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1399.0s)]
*  There are subtle things that can go wrong [[00:23:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1402.0s)]
*  like I think social media is an example of a [[00:23:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1403.96s)]
*  Place where maybe the harms weren't so obvious at the time and then there was an emergent property at scale and you could imagine [[00:23:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1406.6000000000001s)]
*  Something happening, but the incentive problem has been better than I thought at the time [[00:23:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1412.32s)]
*  And I will cheerfully say I was like a little bit naive about how the world works ten years ago [[00:23:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1416.84s)]
*  And I feel better now. Naive how? Oh the the pressure the societal pressure on big companies and the sort of [[00:23:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1420.44s)]
*  The power of researchers to push their companies to do the right thing [[00:23:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1427.9199999999998s)]
*  Even in even in the face of this gigantic profit motive have been pretty good [[00:23:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1431.3999999999999s)]
*  But there is something that I don't feel naive about that. I felt at the time too, which is it continues to be [[00:23:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1436.6s)]
*  fairly crazy to me that [[00:24:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1444.28s)]
*  This is happening in the hands of a small number of private companies to me [[00:24:06](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1446.8s)]
*  this feels like the Manhattan Project or the Apollo program of our time and [[00:24:11](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1451.2s)]
*  Those were not done by private companies and I think is like a mark of a well-functioning society [[00:24:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1455.3999999999999s)]
*  Do you think that we need a Manhattan Project here? [[00:24:20](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1460.96s)]
*  I think the companies are gonna do the right thing and it's gonna go well [[00:24:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1463.58s)]
*  And I I don't think a government effort in this current world would work at all [[00:24:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1467.28s)]
*  I don't think it'd be good if it did honestly [[00:24:30](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1470.8799999999999s)]
*  I just I I wish we were in a world where I said this is you know [[00:24:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1472.8799999999999s)]
*  I felt like that was the way it should and was happening meta right now is also siding with Elon a few days ago [[00:24:35](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1475.8799999999999s)]
*  Meta asked California's AG to block open AI from becoming a for-profit [[00:24:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1482.3999999999999s)]
*  And this is what they said in their letter opening eyes conduct could have seismic implications for Silicon Valley [[00:24:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1487.0s)]
*  If open AI's new business model is valid [[00:24:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1492.28s)]
*  Nonprofit investors would get the same for-profit upside as those who invest in the conventional way in for-profit companies [[00:24:55](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1495.12s)]
*  While also benefiting from benefiting from the tax write-offs bestowed by the government [[00:25:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1500.82s)]
*  This echoes what Musk said last year when he said I'm confused as to how a nonprofit which I donated to [[00:25:05](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1505.54s)]
*  Somehow became a market cap for profit in other words if this is legal like why isn't everyone doing this? [[00:25:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1512.1s)]
*  I don't know why I'm gonna set that letter, but I do know they know that's not how it works [[00:25:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1517.66s)]
*  I know that parts in bad faith if you [[00:25:21](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1521.18s)]
*  In any of these worlds our nonprofit will keep going and the people that invested in the nonprofit [[00:25:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1524.34s)]
*  Don't like you don't get to have a benefit from a nonprofit donation accrue to a [[00:25:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1529.78s)]
*  source for profit equity of course and [[00:25:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1534.9s)]
*  And they know that too you can imagine lots of other reasons that that I might have sent this letter [[00:25:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1537.34s)]
*  You can imagine what they want it. I mean you can imagine they wanted to curry favor with Elon you can imagine that they [[00:25:41](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1541.82s)]
*  Felt like it would help them compete with us. You could imagine that they were like [[00:25:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1547.7s)]
*  Annoyed with us for a perceived anti open source stance [[00:25:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1552.6s)]
*  Which I don't think is accurate or something that I feel I don't know you should ask them what the reason was for the [[00:25:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1556.3999999999999s)]
*  Civilian who's hearing how does a nonprofit become a for-profit? What's the answer? It doesn't like the nonprofit stays as the nonprofit [[00:26:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1562.6799999999998s)]
*  I believe that the opening-eyed nonprofit is on the trajectory [[00:26:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1570.36s)]
*  I hope if we do well to be the largest and most impactful nonprofit of all time that nonprofit doesn't become anything else [[00:26:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1572.9199999999998s)]
*  Like many other things this our world our ecosystem can have a [[00:26:20](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1580.68s)]
*  For-profit business also, but that doesn't the nonprofit does not convert the nonprofit doesn't go anywhere [[00:26:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1587.88s)]
*  The nonprofit does not stop doing nonprofit things at the end of the day Sam who is going to profit most from the success of open AI [[00:26:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1592.3600000000001s)]
*  Everyone I'll tell you what I hope [[00:26:39](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1599.3200000000002s)]
*  everyone gives their analogy for [[00:26:41](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1601.72s)]
*  What technological revolution this is most like, you know, it's the Industrial Revolution [[00:26:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1605.4s)]
*  It's like electricity. It's like the web [[00:26:49](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1609.48s)]
*  The thing I hope for is that it's like the transistor. We discovered a new important [[00:26:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1613.04s)]
*  fundamental [[00:27:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1620.52s)]
*  Physical law whatever you want to call it [[00:27:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1621.68s)]
*  we did a bunch of research so did others and [[00:27:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1624.24s)]
*  it's it will seep into all aspects of the economy products everything and [[00:27:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1627.76s)]
*  You and I today are using many devices with transistors in them to make this podcast possible [[00:27:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1633.8400000000001s)]
*  Computer has some your microphone has some [[00:27:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1642.3200000000002s)]
*  the all of the internet equipment between you and me has a lot but we don't sit here and think about [[00:27:25](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1645.0s)]
*  transistors and the [[00:27:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1652.3200000000002s)]
*  Transistor company does not sit here and make all of the money [[00:27:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1654.68s)]
*  It is this this new incredible scientific discovery that seeped into everything we do and everybody made a lot of money [[00:27:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1658.28s)]
*  That's what I hope AI will be like and I think there's many reasons why it's the best analogy [[00:27:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1666.72s)]
*  Will you have equity or do you have equity or what kind of stake do you have in this new capped for profit? [[00:27:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1671.1200000000001s)]
*  Well, so we haven't formed a new entity yet [[00:27:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1677.5600000000002s)]
*  We have obviously considered a forming a new entity or maybe converting our existing LLC into one [[00:28:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1680.96s)]
*  More accurate I have a tiny sliver of equity from old YC fund [[00:28:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1687.1999999999998s)]
*  I used to have some via Sequoia fund but that one turned out to be easier to [[00:28:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1694.32s)]
*  Like sell and not keep the position in so I have a very small amount [[00:28:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1698.6799999999998s)]
*  It's like quite insignificant to me in terms of what I will it won't have going forward. I don't know [[00:28:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1702.48s)]
*  It's not like there's no current plan or promise for me to get anything [[00:28:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1708.4199999999998s)]
*  I will and I if I got anything it would not be there were like outlandish rumors about some number that would not happen [[00:28:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1711.8799999999999s)]
*  Do you get why people are fixated on that for sure as I've said many times for if I could go back in time [[00:28:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1718.44s)]
*  I would have taken equity. I think again, I understand more about why my earlier misgivings were misplaced [[00:28:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1724.28s)]
*  I also get that it's weird for me to take it now after not earlier on the other hand [[00:28:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1730.84s)]
*  I would love to never have to answer this question again and be like war in a normal company. I run it got some equity [[00:28:55](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1735.0s)]
*  Investors don't have to worry that I'm like misaligned there does the whole like air of suspicion and not having any is one of the [[00:29:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1740.92s)]
*  Decisions I regret the most of opening eye structure things [[00:29:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1747.4s)]
*  But I understand why people are fixated on it that makes sense if you could go back in time [[00:29:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1750.68s)]
*  How would you have done this from the beginning like let's wind back the clock to 2015 if an Oracle had said to me on? [[00:29:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1755.0s)]
*  What was it November of 2015 before we set up? [[00:29:21](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1761.4s)]
*  Number one, you're gonna need a hundred plus billion dollars number two [[00:29:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1764.52s)]
*  Even though you have no idea today how you're gonna ever productize this and you think of yourself as a research lab [[00:29:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1768.6399999999999s)]
*  Eventually, you're gonna become a company that does have a way to productize it and business model it so you can explain to investors [[00:29:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1773.76s)]
*  Why they're not just funding a research lab [[00:29:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1778.6799999999998s)]
*  and number three that the incentives of [[00:29:41](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1781.28s)]
*  People working on this are gonna be more naturally kept in check because it's not gonna be what I and many others thought at the [[00:29:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1784.96s)]
*  Time of like one effort that is way far ahead of everyone else [[00:29:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1791.84s)]
*  But something more like the transistor that seeps out and so there will be better [[00:29:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1794.42s)]
*  Equilibrium dynamics if an Oracle had told me all three of those things that turned out to be true [[00:29:58](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1798.58s)]
*  I would say great. Let's be a public benefit court [[00:30:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1802.6s)]
*  How it essential was Elon to getting open AI off the ground like if the Oracle also told you about this fight that would ensue [[00:30:05](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1805.22s)]
*  With someone that you regarded as your close friend. Would you have said? [[00:30:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1812.46s)]
*  You know don't need him can do it myself. No, he was really helpful [[00:30:16](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1816.78s)]
*  I'm super appreciative [[00:30:21](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1821.02s)]
*  I think it was the first time I ever saw Elon Musk was on stage at a conference you were interviewing him [[00:30:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1822.42s)]
*  You guys had a wonderful dynamic. You seemed like you were really good friends. He has said [[00:30:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1827.82s)]
*  Some really harsh things about you. He's compared you to little finger in the Game of Thrones [[00:30:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1833.54s)]
*  most devastatingly said I [[00:30:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1838.54s)]
*  Don't trust him and I don't want the most powerful AI in the world to be controlled by someone who isn't trustworthy [[00:30:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1840.78s)]
*  Why is he saying that? [[00:30:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1846.18s)]
*  I think it's because he wants the most powerful I know what to be controlled by him. And again, I've seen [[00:30:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1848.18s)]
*  Elon's attacks to many other people many friends of mine, you know, everyone gets their period of time in his [[00:30:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1854.42s)]
*  Spotlight, but this all seems like standard behavior from him [[00:31:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1860.8600000000001s)]
*  I'm trying to put myself in a position of a former friend a former co-founder of mine saying those kinds of things about me [[00:31:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1864.26s)]
*  you seem [[00:31:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1872.3400000000001s)]
*  Relatively calm about it. No, I'm upset by it for sure [[00:31:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1874.74s)]
*  I was talking to someone recently who I did think of as close and they said like [[00:31:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1877.58s)]
*  Elon doesn't have any friends. You know, it doesn't do peers. You know, it doesn't do friends. That was sort of a sad [[00:31:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1882.54s)]
*  moment for me because I do think of him as a friend, but I I [[00:31:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1887.86s)]
*  Don't know. I can look at this like somewhat dispassionately [[00:31:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1892.78s)]
*  I remember what it was like when he said opening eyes can has a zero percent chance of success and you know [[00:31:35](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1895.3s)]
*  You guys are idiots and I'm pulling funding and I'm gonna do my own thing [[00:31:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1900.02s)]
*  there were moments since then where it felt like [[00:31:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1902.58s)]
*  He kind of wanted to reconcile and figure out a way to work together and I remember moments where he's just like [[00:31:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1905.4199999999998s)]
*  You know off doing his thing on Twitter [[00:31:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1911.24s)]
*  But if it were only towards me, I think it'd be much more painful [[00:31:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1913.86s)]
*  But you know, I think you see who he is on Twitter and so I can like hold it [[00:31:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1917.54s)]
*  Somewhat impersonally and just be like this is about Elon. This is not about me. It still sucks [[00:32:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1922.46s)]
*  I [[00:32:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1928.3s)]
*  Had a long time to get used to it, I guess this recent blog post [[00:32:11](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1931.26s)]
*  The that that went up on open AI site [[00:32:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1935.78s)]
*  Said that Elon should quote be competing in the marketplace rather than in the courtroom [[00:32:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1938.3799999999999s)]
*  And the cynical view of course is to say and you've alluded to this in this conversation that Elon who now owns an open AI [[00:32:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1942.82s)]
*  Competitor himself called X AI is suing you not out of some concern over AI safety or anything else [[00:32:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1949.48s)]
*  But really just to get in on the competition. What do you say to that? [[00:32:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1956.38s)]
*  You know, is this really is the cynical view true? [[00:32:39](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1959.98s)]
*  Is this really just a fight to be the first to dominate the market or you should ask him? I [[00:32:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1962.3400000000001s)]
*  Hope yeah, I hope to I invited him on great [[00:32:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1967.18s)]
*  You're not just known as one of the most important AI CEOs AI developers in the world [[00:32:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1970.3000000000002s)]
*  You're also a very very well-known proponent of AI regulation and the cynical view here [[00:32:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1976.3400000000001s)]
*  Is that in the very same way that you could cast dispersions on Elon's motives [[00:33:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1981.78s)]
*  You could look at the way that you have lobbied for AI [[00:33:06](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1986.5s)]
*  Regulations as a way to stifle competition and benefit your company. Obviously you've heard that argument before I think too much regulation [[00:33:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1989.6599999999999s)]
*  Clearly has huge negative consequences in society right now in many places we have [[00:33:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=1997.58s)]
*  too much me Elon has also been a lot of opponent of calling for AI regulation as have as has [[00:33:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2003.78s)]
*  The heads of most other large efforts when you step on an airplane you think you know very high likelihood [[00:33:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2009.7s)]
*  It's gonna be a safe experience [[00:33:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2016.5s)]
*  When you eat food in the US you don't think too much about food safety [[00:33:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2018.42s)]
*  Some regulations clearly a good thing now I can imagine versions of AI regulation that are [[00:33:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2024.1s)]
*  Really problematic and would disadvantage smaller efforts and I think I think that would be a [[00:33:49](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2029.66s)]
*  real mistake [[00:33:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2036.46s)]
*  but [[00:33:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2039.14s)]
*  for [[00:34:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2040.42s)]
*  Some safety guardrails on the most powerful systems that should only affect the people at the frontier [[00:34:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2041.58s)]
*  That's only if I open AI in a small handful others [[00:34:06](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2046.98s)]
*  I don't think we're at the level yet where these systems have huge safety implications [[00:34:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2048.9s)]
*  But I don't think we're like wildly far away either the argument that some of these startups are making startups like [[00:34:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2055.62s)]
*  There's an AI startup called hugging face, which is an unbelievable name [[00:34:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2062.66s)]
*  The founder of a company called stability AI they're basically saying [[00:34:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2066.46s)]
*  What Sam and the other big guys the incumbents are trying to do open AI Google and Apple? [[00:34:30](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2070.82s)]
*  Basically asking government to kind of build a moat around you and stifle the competition to regulatory capture [[00:34:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2076.9s)]
*  What do you say to those people and this is sort of like the the argument between big tech and little tech we can frame [[00:34:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2082.32s)]
*  It in all kinds of ways [[00:34:47](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2087.18s)]
*  What do you say to those people who are saying we want to get in on the competition? [[00:34:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2088.34s)]
*  The regulation that's people like Sam and others that many other times are pushing for [[00:34:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2092.1800000000003s)]
*  Will hurt us and benefit them. Well if what they're saying is we're behind opening eyes [[00:34:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2097.5s)]
*  So it doesn't matter and what we're calling for is only regulation at the frontier like only stuff like only stuff that is [[00:35:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2101.54s)]
*  new and untested [[00:35:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2109.34s)]
*  But you know, otherwise put out whatever open source model you want [[00:35:11](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2111.34s)]
*  I don't think it's reasonable for them to make that argument. I don't know [[00:35:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2114.1800000000003s)]
*  I'm curious what you think if we if we do let's say we succeed and make a super intelligence [[00:35:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2118.72s)]
*  You know, we make this computer program that is smarter. Maybe more capable than all of humanity put together [[00:35:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2123.44s)]
*  Do you think there should be any regulation on that at all or just they just say no [[00:35:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2129.72s)]
*  I definitely think first of all [[00:35:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2132.8799999999997s)]
*  I don't even understand what we're talking about when we talk about super intelligence [[00:35:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2134.3199999999997s)]
*  Like you understand what that means and the implications of it in a way that I just don't [[00:35:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2138.24s)]
*  So that's number one and number two [[00:35:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2143.96s)]
*  You know if this [[00:35:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2146.32s)]
*  Technology is as powerful as people like you and Elon and so many others that are closer to it say that it is [[00:35:49](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2149.8s)]
*  Of course, I think it should be regulated in some way [[00:35:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2157.36s)]
*  how and when is obviously like the relevant question for sure how and when matters a lot, but but uh, I [[00:35:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2159.92s)]
*  Agree with that and I could easily see it going really wrong recently Marc Andreessen was on this show and [[00:36:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2168.68s)]
*  He talked to me about his perception of what the Biden administration was trying to do around AI [[00:36:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2174.68s)]
*  Technology he came on and made the argument and told a story really that he experienced [[00:36:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2182.04s)]
*  he says that the Biden administration was trying to sort of completely control AI and [[00:36:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2186.7599999999998s)]
*  What they were aiming to do was to make it so closely regulated by the government [[00:36:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2192.08s)]
*  that in his words there would only be sort of two or three big companies that they would work with and that they were trying to [[00:36:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2197.64s)]
*  Ultimately protect them from competition. Is that true? Do you know what he's referencing was open AI one of those companies? [[00:36:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2203.7999999999997s)]
*  I don't always referencing. I also will say very very clearly. I think [[00:36:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2210.04s)]
*  Regulation that reduces competition for AI is a very bad thing [[00:36:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2214.8799999999997s)]
*  That's so open AI was not one of those companies. No, I don't actually know what that's about [[00:36:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2219.16s)]
*  But it's we've certainly as far as I know I've never had you weren't in a room ever with the Biden administration other AI companies [[00:37:03](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2223.68s)]
*  No, I don't I don't I don't anything like the Biden administration is competent enough to [[00:37:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2229.16s)]
*  I mean we were in a room with them but never and other companies in the administration, but never like here's our conspiracy theory [[00:37:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2233.68s)]
*  We're gonna make it only you few companies that can build AI and then you have to always say never anything like that [[00:37:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2239.8399999999997s)]
*  What was your feeling in general about the Biden administration's? [[00:37:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2244.3599999999997s)]
*  Posture toward AI and tech more generally you just you just said like you didn't think they'd have the confidence to I think Gina [[00:37:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2248.04s)]
*  Raimondo was it is fantastic, you know every conversation I have with her. I thought she kind of got it [[00:37:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2254.8799999999997s)]
*  I think that [[00:37:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2260.3s)]
*  Overall I would say the administration was not that effective [[00:37:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2262.3s)]
*  The things that I would most that I think should have been the administration's priorities and I hope will be the next administration's priorities are [[00:37:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2265.94s)]
*  Building out massive AI infrastructure in the US [[00:37:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2273.54s)]
*  Having a supply chain in the US things like that when Mark was on I asked him to kind of steel man the Biden [[00:37:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2276.1800000000003s)]
*  administration's perspective or steel man the perspective that this should be [[00:38:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2282.34s)]
*  Heavily regulated and he basically drew the analogy to the Manhattan Project and the development of the atomic bomb [[00:38:05](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2285.18s)]
*  When the government felt that it needed to make sure that this new science and innovation remained classified [[00:38:11](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2291.14s)]
*  First of all, do you think that that's a good analogy? [[00:38:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2297.78s)]
*  And if so if if it is as powerful as nuclear weapons wouldn't it make sense for this to be? [[00:38:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2299.86s)]
*  Not open AI and Gemini and Claude but rather a project of the federal government [[00:38:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2307.3s)]
*  I think all the analogies are tough because they work in some ways and don't work in other ways like you can you can point [[00:38:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2313.14s)]
*  To things that are similar to the nuclear era you can talk about like, you know, it takes enormous [[00:38:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2317.98s)]
*  resources and huge amounts of energy to [[00:38:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2325.46s)]
*  Enrich uranium on one hand or to produce these models on the other [[00:38:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2328.2599999999998s)]
*  So you can find things like that that work and then the use of one of these models and the use of a nuclear weapon [[00:38:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2332.46s)]
*  Are like quite different things and sort of the geopolitical implications are also quite different things [[00:38:58](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2338.02s)]
*  I think to steal men the argument of people who say things like it's like nuclear weapons [[00:39:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2341.92s)]
*  I think what they mean is that it's it's extremely expensive and it has extreme geopolitical consequences [[00:39:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2347.56s)]
*  We don't know exactly what those are or how to think about them [[00:39:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2353.08s)]
*  But because we don't know exactly what they are [[00:39:16](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2356.16s)]
*  Shouldn't we have like a principle of letting the government decide? [[00:39:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2358.52s)]
*  I can imagine other governments at other times in history where we would have we should be very thrilled about that outcome [[00:39:21](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2361.16s)]
*  I think putting the current United States government in charge of [[00:39:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2367.0s)]
*  Developing a GI [[00:39:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2371.68s)]
*  Faster and better than our competitors would not likely go [[00:39:33](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2373.52s)]
*  Well, I think the kind of the decline in state capacity in this country is not a new observation [[00:39:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2376.64s)]
*  But a mournful one at the beginning of the nuclear age. We had people in this country who functioned almost like [[00:39:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2383.3599999999997s)]
*  chief science officers, right I'm thinking about people like [[00:39:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2390.6s)]
*  Vannevar Bush who helped launch the Manhattan Project and came up with the National Science Foundation and kind of [[00:39:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2394.2599999999998s)]
*  guided American policy for those first few like very crucial years of new of nuclear energy [[00:40:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2400.7799999999997s)]
*  Does that person right now? [[00:40:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2408.06s)]
*  Whether or not they're in DC or not. Does that person exist like if we wanted to have someone like that who sort of [[00:40:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2410.18s)]
*  Understood the technology had no financial stake in it and could talk [[00:40:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2417.58s)]
*  Whether it's President Biden or Trump or whoever comes after him sort of the pros and cons [[00:40:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2423.08s)]
*  not just of the development of AI here, but the [[00:40:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2428.48s)]
*  competition with China like [[00:40:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2432.2s)]
*  Does that does that person exist actually right now in America? Like could you be that person arguably? I think the [[00:40:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2434.12s)]
*  the willingness [[00:40:41](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2441.6s)]
*  It's coming back a little bit. But for a long time the willingness of the American public to be [[00:40:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2443.7599999999998s)]
*  excited about [[00:40:49](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2449.0s)]
*  Future developments in science and technology has been gone. I sort of think it [[00:40:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2451.68s)]
*  Went away with the nuclear weapons. Actually if I had to pick one moment in time [[00:40:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2456.32s)]
*  There was sort of a you know [[00:41:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2460.6s)]
*  a weird like a few decade hangover before it there was the generational change when the bomb was dropped kind of got [[00:41:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2462.0s)]
*  older and in power like I don't think [[00:41:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2469.8s)]
*  America ever embraced the excitement and belief in science and technology [[00:41:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2472.8s)]
*  Driving the world forward to the same degree as as we used to you read these stories about what people like that used to [[00:41:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2477.44s)]
*  Do and how revered they were and how? [[00:41:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2482.7999999999997s)]
*  People believed that [[00:41:25](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2485.96s)]
*  Scientific technological progress more broadly was going to make the world better [[00:41:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2487.7999999999997s)]
*  That seems missing now and I don't think it's because we don't have an individual who could do that [[00:41:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2491.7999999999997s)]
*  I think it's because the government doesn't want it and the public doesn't want it. I mean, what do you make of? [[00:41:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2497.2s)]
*  Not just the political vibe shift [[00:41:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2502.92s)]
*  But the cultural vibe shift that we've been experiencing since November 5th [[00:41:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2504.72s)]
*  Like if you made that argument to be eight weeks ago, I would say yeah, he's Sam's probably right now [[00:41:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2508.28s)]
*  It feels like a different country. There's a huge cultural vibe shift and I think there's a very positive [[00:41:52](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2512.7s)]
*  There's positive momentum in many ways. I'm not sure that it exists for hey [[00:41:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2517.36s)]
*  We think science is really important again and science is what's gonna save us and you know solve all of our problems [[00:42:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2521.6s)]
*  Do you think that or do you think it's like that's the one area where I haven't felt it? [[00:42:06](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2526.2s)]
*  I just think that there's a shift in the direction of growth is a good thing [[00:42:09](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2529.7799999999997s)]
*  Technological progress is a good thing [[00:42:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2535.66s)]
*  Nihilism is feels like it's passe and falling out of favor. Like I feel that change [[00:42:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2538.2599999999998s)]
*  I feel that changed in a dramatic way [[00:42:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2543.8199999999997s)]
*  now maybe it's because I spend a lot of time on X and [[00:42:25](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2545.66s)]
*  Like a lot of it's sort of like fomenting there and sort of leaping from the online into the real world [[00:42:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2549.62s)]
*  So, you know if you went and like talk to the average [[00:42:35](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2555.3799999999997s)]
*  PhD student uptown at Columbia, I don't think that they would have the same experience I do [[00:42:39](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2559.42s)]
*  Because everything's so bulk and as I said earlier, I think it is getting better even on site [[00:42:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2564.74s)]
*  like I strongly agree with you on the kind of general shift towards excitement about growth and [[00:42:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2568.72s)]
*  Success and having the country and the economy do well [[00:42:56](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2576.62s)]
*  I saw I do somewhat agree as I was saying earlier that I think even [[00:43:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2580.06s)]
*  Excitement about science is in a better place than it's not here [[00:43:05](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2585.8199999999997s)]
*  But when you talk about those people who were like the scientific ambassadors of the country and who people like really listened to and [[00:43:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2590.66s)]
*  Were excited about and you know preach to a willing audience [[00:43:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2597.58s)]
*  I'm still not sure I feel that I think there's that excitement for business [[00:43:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2602.9s)]
*  but not for science [[00:43:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2609.58s)]
*  One of the companies that I feel excited about [[00:43:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2611.7400000000002s)]
*  Perhaps it's controversial to say this but I just think the founders one of the most interesting people in the country is [[00:43:35](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2615.7000000000003s)]
*  Palmer lucky and his company and are all [[00:43:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2620.42s)]
*  And real industries and open AI recently entered into an agreement with [[00:43:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2623.7000000000003s)]
*  Anderil to develop AI with military applications now previously [[00:43:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2628.5s)]
*  Open AI had had a prohibition against using its technology for weaponry now with the caveat [[00:43:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2633.26s)]
*  Of course that you're concentrating on defensive systems at the moment the sorts of things that could you know guard us against [[00:43:58](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2638.62s)]
*  Attacks like drone swarms perhaps like what's happening in New Jersey right now [[00:44:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2644.58s)]
*  We don't have time to talk about that. What made you change your mind fundamentally about [[00:44:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2647.7799999999997s)]
*  integrating your company's technology [[00:44:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2652.34s)]
*  Into even a defensive weaponry system [[00:44:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2655.22s)]
*  Yeah [[00:44:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2657.9s)]
*  So we have a set of principles that we established and we prove this one for some use cases that comply with those [[00:44:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2658.06s)]
*  But I think if the leading United States efforts do not help defend the United States and our allies against our adversaries [[00:44:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2663.8199999999997s)]
*  We're going to be in a very bad place [[00:44:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2671.2599999999998s)]
*  And so we need to figure out how to do that a year and a half ago when we were talking [[00:44:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2672.62s)]
*  Part of our conversation was whether or not we were like where the AI arms race with China was [[00:44:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2677.7s)]
*  I think now it's like well and definitively clear that we are very much in that arms race with China [[00:44:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2684.58s)]
*  And you know, I think [[00:44:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2691.58s)]
*  Even people who worry about the power of AI in this country feel like well if it's a choice between us and China [[00:44:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2694.46s)]
*  It's gotta be us we gotta win spell out for us Sam in your mind because I'm sure you're thinking about this all the time [[00:45:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2701.58s)]
*  Like what it looks like if China wins the AI arms race like what what happens to America? [[00:45:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2708.66s)]
*  What happens to the world whatever China wants and do you think the possibility of that happening is a real one? [[00:45:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2715.6s)]
*  Then when I I mean we intend to work our fucking hardest to make sure they don't [[00:45:21](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2721.02s)]
*  How do we know if they are winning given how much they lie and also steal stuff from us? [[00:45:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2724.34s)]
*  This is the hard thing right we we know what they publicly release. We don't know what they don't publicly release [[00:45:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2729.3s)]
*  we have a lot of signals and we have a [[00:45:35](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2735.54s)]
*  Intelligence system, but it's my own stance on this is we have got to try to be cooperative and [[00:45:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2738.22s)]
*  Arms races are bad for everybody involved. We've learned that lesson again and again throughout history [[00:45:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2745.78s)]
*  But we need to be able to win if we need to I am hopeful that this can be a great moment for world peace [[00:45:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2750.9s)]
*  And I believe that if there's ever a time for humanity to come together [[00:45:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2757.54s)]
*  This seems like a good candidate, and I want us to get there [[00:46:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2761.3799999999997s)]
*  But we can't be naive about that president Trump is talks a lot about you know peace through strength [[00:46:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2764.94s)]
*  Is your is the Sam Altman open AI version of peace through strength? We have to crush [[00:46:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2770.06s)]
*  Get ahead and win on AI so it's not even a question that China could do whatever it wants not crushes [[00:46:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2775.94s)]
*  We have to be ahead, and then we have to be as willing to work together as possible [[00:46:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2782.36s)]
*  I think that is somewhat similar to peace through strength [[00:46:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2786.96s)]
*  It's like if there's an arms race will win it, but we don't want to meaning if there's an arms race [[00:46:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2789.46s)]
*  We want to win, but we don't want the arms race. Yeah, period. Yeah, but it's here [[00:46:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2794.06s)]
*  It's not even that it's more like if there's any path towards doing this as a collaborative effort [[00:46:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2797.78s)]
*  We should but we have to be kid. We can't control what other [[00:46:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2804.06s)]
*  Entities do you mean collaborate with our enemies we collaborate with China. Yeah, actually I'll say that directly [[00:46:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2808.86s)]
*  I think we collaborate with people we don't get along with all the time in areas where it's in our strategic interest to do [[00:46:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2814.42s)]
*  So and this is one where I think the interests of the world and certainly the mission of our company [[00:46:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2819.62s)]
*  Would dictate that if it is possible to be truly collaborative we should do that [[00:47:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2824.14s)]
*  Are we doing that right now with China on AI like you know more than I do [[00:47:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2828.58s)]
*  I was gonna say you might know more than I like that it that will be a big question for the new administration [[00:47:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2832.66s)]
*  But that's not gonna happen to the company in a company level [[00:47:17](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2837.58s)]
*  That's gonna happen like the presidents of the two countries level if Trump called you tomorrow and said hey Sam [[00:47:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2839.46s)]
*  I want to make you like AI SAR AI regulation chief you can do whatever you want in this position [[00:47:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2844.62s)]
*  What's the first thing that you would do? [[00:47:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2851.42s)]
*  What's the most important thing that the person in that position would do? [[00:47:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2852.94s)]
*  US infrastructure and supply chain add a little bit more for people that don't know what that means build our own chips here [[00:47:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2856.54s)]
*  build enough energy to run data centers here change what it takes to build data centers here, but be able to like build the [[00:47:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2862.32s)]
*  very expensive [[00:47:49](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2869.4s)]
*  Complex supply chain very expensive infrastructure in the United States [[00:47:51](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2871.0s)]
*  bias and censorship in AI is a [[00:47:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2874.4s)]
*  Enormous topic and one that we think a lot about here at the free press and you know [[00:47:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2877.0s)]
*  The most obvious example of this the one that trended for days and everyone was laughing at that was when Gemini generated those images of [[00:48:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2881.76s)]
*  Like a black George Washington and like a trans Nazi and it was hilarious [[00:48:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2888.6000000000004s)]
*  But in a way it was really serious because it felt like only the most sort of like exaggerated [[00:48:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2893.1200000000003s)]
*  hyperbolic obvious example of a much much deeper endemic problem, which is [[00:48:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2899.2400000000002s)]
*  The bias that is baked into these [[00:48:25](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2905.28s)]
*  technologies [[00:48:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2908.6400000000003s)]
*  Both because of the people programming those technologies and because of the information that they're sort of scraping online [[00:48:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2909.8s)]
*  Talk to us about how you're thinking about it at chat GPT because obviously the system that is closest to reality [[00:48:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2917.08s)]
*  It seems to me will will win in the end of the day if a chat GPT is giving me images of you know [[00:48:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2923.8399999999997s)]
*  He's telling me George Washington was trans. I'm like, I'm not gonna rely on this. I don't do that [[00:48:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2930.4s)]
*  So, okay fine, but you understand my point. How do you think about the problem of bias and how are you solving for it? [[00:48:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2934.04s)]
*  I think there are two things that matter one is [[00:49:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2940.44s)]
*  What flexibility a user has to [[00:49:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2944.2400000000002s)]
*  Get the system to behave the way they want and I think we think there should be very wide bounds [[00:49:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2948.08s)]
*  Like, you know, there are some things like you don't want a system to tell you how to create nuclear weapons [[00:49:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2953.52s)]
*  Fine, we can all agree on that [[00:49:18](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2958.84s)]
*  But if you want a system to be pretty offensive and you ask it to be I think part of alignment is doing what its user [[00:49:20](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2960.2s)]
*  asks for within these [[00:49:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2966.28s)]
*  Broad bounds that society agrees on the second thing that really matters is what the defaults are [[00:49:29](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2969.08s)]
*  so if you don't do any of that which most users don't and you ask whatever controversial question you want how should the system respond and [[00:49:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2974.0s)]
*  We put a ton of work into both of those things [[00:49:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2982.7200000000003s)]
*  We also try to write up how the model should behave [[00:49:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2986.44s)]
*  We call this the model spec such that you can tell if it's a bug or you disagree with us on some stance [[00:49:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2988.94s)]
*  Is it possible to build a thing like chat GPT or any other technology in this lane that we can't even conceive of yet [[00:49:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=2993.96s)]
*  That doesn't have a political point of view. Isn't that inevitable? I [[00:50:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3001.7200000000003s)]
*  Think no matter how neutral you try to write the thing [[00:50:05](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3005.8s)]
*  It will either be useless because it will just say I can't answer that because there's politics and everything [[00:50:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3008.18s)]
*  Or it will have some sort of point of view which is why what we think we can do is write down [[00:50:12](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3012.2s)]
*  What we intend for our default people can debate that if there's bugs in there [[00:50:16](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3016.52s)]
*  We can look at the bugs if there's problems with how we define that we can change what the definition is and retrain the system [[00:50:21](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3021.4s)]
*  But yeah, I don't think any system can be no two people are ever gonna agree that one system is perfectly unbiased [[00:50:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3026.96s)]
*  But that's another reason why personalization matters so much. Do you believe that AI or chat GPT has a [[00:50:32](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3032.84s)]
*  Responsibility to fight pernicious ideas. Let me give you an example of what I mean [[00:50:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3040.2000000000003s)]
*  like if you knew that by [[00:50:44](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3044.48s)]
*  Putting your thumb on the scale and in the teeniest tiniest way you might be able to usher in a world where there's less racism less [[00:50:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3046.6s)]
*  antisemitism less misogyny and maybe it would even be invisible to people because [[00:50:54](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3054.04s)]
*  You know, they wouldn't know you know at a certain point as we've just talked about [[00:50:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3059.0s)]
*  This is gonna be you know, I don't know if this is mark or somebody else the control layer of all of our information [[00:51:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3062.32s)]
*  How do you think about that? Actually? Here's one thing [[00:51:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3067.86s)]
*  I've been thinking about recently as a principle like opening I has not [[00:51:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3070.6s)]
*  Adopted this at all [[00:51:13](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3073.84s)]
*  But this has just been an idea that I think gets at what you're saying like let's say let's say we discover some new [[00:51:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3075.1200000000003s)]
*  Thing where it's like if you do this people learn way better if chat GPT [[00:51:22](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3082.44s)]
*  Responds always with the Socratic method or whatever students using it learn way better [[00:51:28](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3088.28s)]
*  But let's say user preferences are not to get the Socratic message users [[00:51:34](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3094.0800000000004s)]
*  Just say like I just want you to answer my question then like how should we? [[00:51:38](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3098.44s)]
*  Decide what to do there as the default behavior and one idea that I have increasingly [[00:51:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3102.08s)]
*  thinking about is [[00:51:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3108.56s)]
*  What if we're always just really clear when we make a change to the spec and so you'll never have our thumb on the scale [[00:51:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3110.7599999999998s)]
*  Hiding behind an algorithm which I think Twitter does all the time for example and all sorts of weird things [[00:51:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3117.04s)]
*  They're like we'll always tell you what the behave what the intended behavior is and if we make a change to it [[00:52:01](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3121.4s)]
*  We'll explain why but if we do discover something like what you just said [[00:52:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3127.52s)]
*  Or like what I just use as an example and we say okay when people are using it for education [[00:52:11](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3131.64s)]
*  We are gonna use the Socratic method [[00:52:16](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3136.4s)]
*  Because it does seem to have this measurable effect and here's why we're doing it we can debate that publicly [[00:52:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3139.16s)]
*  Maybe we change our default if you can miss us otherwise [[00:52:23](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3143.68s)]
*  Anyone can of course change that in their user preferences because the AI is like a tool for you and should do what you want [[00:52:27](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3147.16s)]
*  But I think the thing that would be wrong is if we change that and didn't reflect it in the spec and didn't tell people [[00:52:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3151.8399999999997s)]
*  We were changing it [[00:52:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3156.04s)]
*  You know, I think the like black box of the Twitter algorithm for example [[00:52:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3157.56s)]
*  it's like [[00:52:40](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3160.82s)]
*  Doesn't feel good to me Sam [[00:52:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3162.2200000000003s)]
*  You've donated million dollars to Trump's inauguration and it turned some heads because in the past you've called him a racist a misogynist [[00:52:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3163.86s)]
*  And a conspiracy theorist among other things you've been a prolific donor to [[00:52:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3170.2000000000003s)]
*  Democratic candidates and causes over the years [[00:52:55](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3175.1800000000003s)]
*  But now you say that Trump is gonna lead us into the age of AI and you're eager to support his efforts to ensure [[00:52:57](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3177.1200000000003s)]
*  America stays ahead [[00:53:02](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3182.46s)]
*  Is this a change of heart a political evolution a vibe shift inside of you? [[00:53:03](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3183.78s)]
*  What's going on all of those things and also I I hope I mean like he's our president and I wish him every bit of success [[00:53:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3188.38s)]
*  Anyway, we can you know work to support this part of what he wants to do. We want to do [[00:53:15](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3195.5s)]
*  What's the vibe shift inside of you? We know that there's one going on inside Silicon Valley and one going on in the culture [[00:53:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3199.2200000000003s)]
*  How have you changed in the past few years? I mean a ton of ways but one one is that I [[00:53:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3204.86s)]
*  Know I've watched for the last maybe 10 12 years as I think things have gotten off track [[00:53:30](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3210.26s)]
*  Things have been good in some ways, but I think gotten really off track in terms of how we think about the importance of growth [[00:53:37](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3217.02s)]
*  and [[00:53:43](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3223.94s)]
*  economic success and a focus on the right things in in the country and in the world more broadly and I think it got [[00:53:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3225.1000000000004s)]
*  It got very off track and I'd say the vibe shift is a hope that as we're facing down one of these most important moments in [[00:53:50](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3230.98s)]
*  technological history [[00:53:58](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3238.1000000000004s)]
*  That can help drive a vibe a vibe shift back to what I believe in very deeply [[00:53:59](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3239.42s)]
*  Which is that growth is [[00:54:04](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3244.22s)]
*  The only good way forward [[00:54:07](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3247.06s)]
*  Do you think growth and the growth of open AI and the growth of AI more generally is a patriotic duty? Yes [[00:54:08](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3248.58s)]
*  I actually wrote something like I someone just sent this back to I was more than 10 years ago [[00:54:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3254.8199999999997s)]
*  About how growth like I think is my very first blog post ever about how growth was the central ingredient to democracy working [[00:54:19](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3259.8999999999996s)]
*  Well, and I believe I think the world got badly confused about that and I'm happy to see it re-recognized [[00:54:26](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3266.14s)]
*  I'm gonna use my 30 seconds on a lightning round Sam lightning round. What are the drone things? [[00:54:31](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3271.98s)]
*  What are the flying objects flying over New Jersey right now? I have no idea. I'm really interested in this question [[00:54:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3276.54s)]
*  Do you know? [[00:54:41](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3281.02s)]
*  No, we're reporting on it a lot. I find it interesting that various [[00:54:42](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3282.14s)]
*  Electeds are saying it's the Iran mothership or China [[00:54:45](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3285.94s)]
*  Do you think Twitter has become better or worse since Elon Musk took control worse? You're having a baby [[00:54:48](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3288.38s)]
*  Yes, will you let your kid have an AI friend? Yes. Will you let them go on social media at some point? [[00:54:53](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3293.7s)]
*  Will you let them have screen time? Yes, what's your favorite sports car? You love sports cars? There's a lot of good ones [[00:55:00](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3300.12s)]
*  I can't pick one. What's your favorite of yours? No, I can't pick a single favorite [[00:55:05](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3305.7599999999998s)]
*  I'm a clear enough one favorite movie the Dark Knight. Do you have any normal hobbies? [[00:55:10](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3310.7599999999998s)]
*  I like have dinner with my friends. I go hiking. I like, you know exercise. I just like sit around my friends doing dumb stuff. I I [[00:55:14](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3314.8399999999997s)]
*  Don't know yeah, it feels pretty normal you built a tree house recently I did do that. Why'd you do that? [[00:55:24](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3324.64s)]
*  It was Thanksgiving and we look in activity for a lot like the adults and the kids that we all thought everybody was at [[00:55:30](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3330.0s)]
*  Our ranch and we want an activity [[00:55:35](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3335.36s)]
*  We all thought would be fun and was not just sitting around drinking all day and it was great [[00:55:36](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3336.68s)]
*  Would you box Logan Paul? No, will we enter World War three in 2025? I hope what's your New Year's resolution? [[00:55:39](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3339.72s)]
*  I know to this Sam Altman. Thank you so much for coming out. Honestly. Thank you [[00:55:46](https://www.youtube.com/watch?v=DfOt_cqXCFI&t=3346.96s)]
