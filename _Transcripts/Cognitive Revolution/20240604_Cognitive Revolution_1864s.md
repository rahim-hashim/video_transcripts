---
Date Generated: June 05, 2024
Transcription Model: whisper medium 20231117
Length: 1864s
Video Keywords: []
Video Views: 525
Video Rating: None
Video Description: Tune in to today's special episode airing a recent panel with the founders of Scale AI, Anthropic, and AI Fund who gathered in Washington DC to discuss China as an adversary. They argue that the papers out of Tsinghua University are just as impressive as those coming out of American universities. China is just as creative, but maybe even more motivated. While discussions of regulations have encompassed certain restraints, Alex Wang, Andrew Ng, and Jack Clark argue that we’re not moving fast enough (moderated by US senator Cory Booker).

This session was recorded live at The Hill & Valley Forum in 2024, a private bipartisan community of lawmakers and innovators committed to harnessing the power of technology to address America's most pressing national security challenges. The Hill & Valley podcast is part of the Turpentine podcast network. Learn more: www.turpentine.co

--

SPONSORS:
Oracle Cloud Infrastructure (OCI) is a single platform for your infrastructure, database, application development, and AI needs. OCI has four to eight times the bandwidth of other clouds; offers one consistent price, and nobody does data better than Oracle. If you want to do more and spend less, take a free test drive of OCI at https://oracle.com/cognitive

The Brave search API can be used to assemble a data set to train your AI models and help with retrieval augmentation at the time of inference. All while remaining affordable with developer first pricing, integrating the Brave search API into your workflow translates to more ethical data sourcing and more human representative data sets. Try the Brave search API for free for up to 2000 queries per month at https://bit.ly/BraveTCR

Head to Squad to access global engineering without the headache and at a fraction of the cost: head to https://choosesquad.com/ and mention “Turpentine” to skip the waitlist.

Omneky is an omnichannel creative generation platform that lets you launch hundreds of thousands of ad iterations that actually work customized across all platforms, with a click of a button. Omneky combines generative AI and real-time advertising data. Mention "Cog Rev" for 10% off https://www.omneky.com/

--

TIMESTAMPS:
(00:00) Intro
(03:29) Assembling the founders of Anthropic, Scale AI, and AI Fund
(04:45) Predictions for AGI
(08:21) Navigating AI innovation amidst regulation
(16:15) Global AI competition and the urgency of Innovation
(24:34) Empowering future generations
---

# The Roadmap to AGI and Implications on the Global Balance of Power
**Cognitive Revolution:** [June 04, 2024](https://www.youtube.com/watch?v=SuSQpnyJ9SI)
*  Hello and welcome to the Cognitive Revolution, where we interview visionary researchers,
*  entrepreneurs, and builders working on the frontier of artificial intelligence.
*  Each week we'll explore their revolutionary ideas and together we'll build a picture of
*  how AI technology will transform work, life, and society in the coming years.
*  I'm Nathan Labenz, joined by my co-host Eric Torenberg.
*  Hello and welcome back to the Cognitive Revolution.
*  Today we are sharing a thought-provoking panel discussion from the recent Hill and
*  Valley Forum, a private bipartisan community of lawmakers and innovators convened to consider
*  how the United States can best use technology to address its national security challenges.
*  Moderated by Senator Cory Booker, who it's worth noting I supported in the 2020 Democratic
*  presidential primary, the panel featured three AI A-listers. Alex Wang, the visionary wonder kid
*  founder and CEO of Scale AI, Jack Clark, co-founder of Anthropic, a company for which my fandom is
*  well-documented, and Andrew Ng, managing partner of the AI Fund and co-author of more than 200 AI
*  research papers over the years. As you hear, there was a lot of agreement amongst the panelists,
*  including on the key point that when it comes to AI, China is already producing lots of outstanding
*  research advances, will not easily be held back by policies such as chip or intellectual property
*  export controls, and generally should not be underestimated. I share this outlook and I also
*  strongly agree that the US government should embrace the day-to-day utility that AI can provide,
*  whether that comes in the form of AI doctors, streamlined government processes, or Jetsons-style
*  self-driving cars and domestic servant robots. And yet, candidly, I will say that there was
*  something about this conversation that left me a bit uneasy. Too much of the analysis, in my view,
*  is framed through the lens of competition between the United States and other nations.
*  While I certainly would not want to live in Xi's China, and I deeply appreciate the fact that I can
*  freely disagree with a sitting US Senator, I think we should make our AI decisions based on the
*  practical value that AI systems can provide and the most grounded risk analyses we can manage.
*  And I really worry that we will end up making bad decisions if we allow ourselves to make a habit
*  of us versus them thinking. Personally, I would love to see the United States lead the world not
*  by striving to maintain a technology edge through any means necessary, but by working to transcend
*  the paradigm of nation-state rivalry and seeking collaboration with all nations in pursuit of a
*  positive AI future. You may say that I'm a dreamer for taking this position, and I certainly wouldn't
*  want the United States to be too naive when it comes to China's capabilities or intentions,
*  but technology revolutions do represent a rare opportunity to rethink how we live, work, play,
*  and relate to one another. And given the overwhelming momentum toward continued rivalry
*  and escalation of tensions with China, I think it's important that at least some of us step back
*  and try to imagine a more positive dynamic. After all, the true others in the AI era are not the
*  Chinese, but the AIs themselves. If you're finding value in the show, please do take a second to
*  share it with friends. And as always, we value your feedback. You can reach us via our website,
*  cognitiverevolution.ai, or by DMing me on your favorite social network. Now, here's Senator
*  Booker, Andrew Ng, Alex Wang, and Jack Clark for a discussion on the future of American leadership
*  in artificial intelligence. I think that you all know the folks that are up here. I'm going to
*  introduce them in a second. But for the purposes of this panel, AI stands for awesome individuals
*  with amazing insight. This is the best I got. It truly is an excellent panel that I'm really
*  excited about. And we have Jack Clark, the co-founder of Anthropic. Please, more than a
*  smattering of applause. Thank you very much. That's both an a smattering of applause.
*  Alex Wang, the CEO of Scale AI. Don't applaud him. He's appallingly young for crying out loud.
*  Has a great head of hair, too, that makes me very jealous. And then of course,
*  Andrew Ng, who I love because he's from my alma mater, the managing general partner of the AI fund.
*  So I want to ring right in, if I can, to get to the conversation people
*  hear enough from politicians. But you all are on the front lines of what I really believe is the
*  greatest frontier in human innovation that we may ever see. It's an exciting dawn of a whole new
*  era for humanity as a whole. But there are a lot of people who bring up concerns. And one of them
*  that I'm almost sort of tired of is the fear predictions for AGI, for artificial general
*  intelligence. And I'm wondering if you all think that the talk is overblown or if it's something
*  that those who want to have sci-fi movie like Dystopic Futures should have a right to be somewhat
*  concerned. And this is a jump ball, gentlemen. I'm happy to start by answering. I think the key to
*  this conversation is there's some truth to the fear that we'll develop very powerful AI systems,
*  but there's also a lot of truth that the AI systems we have today are extremely powerful,
*  are extremely beneficial, can have a lot of positive impacts on humanity, positive impacts
*  on society. And I think the key is for us to develop a very grounded and scientific conversation
*  around what are the capabilities of these algorithms? How are those capabilities developing?
*  And when do we need to start having the conversations around, you know, do we need
*  to start putting controls around this? And I think that there have been a number of places that I
*  think have really led the policy conversation around, you know, the development of this kind
*  of scientific framework and the development of the right testing procedures to be able to do so.
*  So in the United States, we have our AI Safety Institute as a part of NIST, which I think is
*  a key part of this conversation. The UK has an AI Safety Institute that they started as well.
*  Japan is starting an AI Safety Institute. Korea is starting an AI Safety Institute. And so I think
*  we're seeing a very global effort around developing a much more precise and grounded
*  scientific research into exactly how to adjudicate whether or not the models are,
*  you know, going to be worthy of concern or not worthy of concern. And I think that's the right
*  way to have the conversation, not to make it so emotional. Thanks, Alex. Well, just to tap
*  onto what Alex said, it's kind of like if AI is the new electricity, we're sitting here wondering
*  about how we regulate everything that gets plugged into an electric outlet, which would drive you
*  completely crazy. So what we need to do is have standard like product safety testing measures,
*  figure out a shared global framework and figure out if there's anything different about this
*  technology. And we can only do that if we build a testing regime and figure out stuff that seems
*  sensible and avoid doing things that would restrict competition or like crush an ecosystem
*  that's just getting going. Over the last year, I think many of you have seen, I was surprised by
*  the intensity of the lobbying efforts from a number of parties that invested billions of dollars in
*  training foundation models to trash open source and shut down innovation, often on kind of safety
*  concerns to keep on shifting. I think a year ago, AI was supposed to take over and cause all, then
*  it was about weapons risks and its defense risks. AI does have risks, but to take the electricity
*  analogy further, today it feels like we're trying to make home appliances safe, the applications,
*  electric home appliances safe by regulating the solar panel makers. We're going to the solar panel
*  makers saying, guaranteed to me that electron you're generating is safe for the application
*  and that's just impossible. So I think the mistake that a lot of regulatory agencies in the US and
*  abroad and in Europe, for example, are making is trying to regulate the technology. That's like
*  saying solar panels, make sure your electricity is safe. Can't do that versus the applications. I
*  want to save self-driving cars, reasonable underwriting software, save medical devices,
*  but regulate the application layer, not the technology layer. And so I'm one of these folks
*  that has been frustrated with unnecessary regulations since the time I was mayor.
*  But when I got to be a United States Senator, I was blown away that I found that the government,
*  federal government was not moving at the speed of innovation and trying to regulate things that
*  were really undermining that innovation. And I had a lot of worries very vocally. I used to be on
*  the Commerce Committee and I remember the head of the FAA came in and there was this incredible
*  industry that was booming for drones. Europe was using them to survey mines to fix poles.
*  We weren't issuing any licenses except for the movie industry, of course. And I said to the head
*  of the FAA, if you were around during the time of Orville and Wilbur Wright, they would have never
*  gotten the airplane off the ground. And so I'm wondering for the ThreeView, there's got to be
*  some fears about the regulators here and things they might do specifically, I'm wondering from you,
*  that you're really worried that they might do to choke the innovation. But there's got to be on
*  the flip side of that, some areas where you say, wait a minute, we need regulation. And I'll,
*  one more example just for the sake of just sort of setting you all up. The social media was
*  something I was an early innovator in when I was mayor of the city of Newark. One of the first
*  politicians to really use it as a management tool, transparency tool, engagement tool for my city.
*  But now I look at social media and I'm like, dear God, we need to regulate there.
*  Really bad things are happening. So I'm wondering if you can give me for this next
*  era of human innovation, where you think is good regulation and where you're like, dear God, Booker,
*  you and your posse in the Senate, please don't get this wrong.
*  So I'll give one example, which is, I think when you start an AI company, you may not be
*  interested in national security, but national security is interested in you. And you end up
*  building these very powerful systems that may have national security uses or misuses. And for that,
*  I think we do need to come up with tests that make sure that we don't put technologies into the
*  market, which could unwittingly to us like advantage someone or allow some non-state actor
*  to commit something harmful. Beyond that, I think we can mostly rely on existing regulations and law
*  and existing testing procedures that exist like the FDA or the FAA or other things. And we don't
*  need to create some entirely new infrastructure. I think, I think I know that in even earlier
*  sessions, people use the term dual use to refer to AI. I think that's the wrong framework to think
*  about it. There are some technologies like nuclear or maybe rockets with some civilian use cases and
*  some military use cases, and we can contain the military use cases without crushing civilian
*  innovation. AI is a general purpose technology like electricity. Electricity can be used for
*  warfare, but can be used for tons of other beneficial things. So that term dual use is not
*  like there are two uses, one military, one civilian. Yes, there are military use cases, but there's so
*  many civilian use cases that we don't want to crush. So I think having a carefully scoped way
*  to contain the military applications without limiting the dramatic, I think of AI as multi is
*  not dual use with way more civilian than military use cases. Hey, we'll continue our interview in a
*  moment after a word from our sponsors. AI might be the most important new computer technology ever.
*  It's storming every industry and literally billions of dollars are being invested. So buckle up. The
*  problem is that AI needs a lot of speed and processing power. So how do you compete without
*  costs spiraling out of control? It's time to upgrade to the next generation of the cloud,
*  Oracle Cloud Infrastructure or OCI. OCI is a single platform for your infrastructure database,
*  application development and AI needs. OCI has four to eight times the bandwidth of other clouds,
*  offers one consistent price instead of variable regional pricing. And of course, nobody does data
*  better than Oracle. So now you can train your AI models at twice the speed and less than half the
*  cost of other clouds. If you want to do more and spend less like Uber, eight by eight and Databricks
*  Mosaic, take a free test drive of OCI at oracle.com slash cognitive. That's oracle.com slash cognitive.
*  Oracle.com slash cognitive. The brave search API brings affordable developer access to the brave
*  search index, an independent index of the web with over 20 billion web pages. So what makes the brave
*  search index stand out? One, it's entirely independent and built from scratch. That means
*  no big tech biases or extortionate prices. Two, it's built on real page visits from actual humans,
*  collected anonymously, of course, which filters out tons of junk data. And three, the index is
*  refreshed with tens of millions of pages daily. So it always has accurate up to date information.
*  The brave search API can be used to assemble a data set to train your AI models and help with
*  retrieval augmentation at the time of inference, all while remaining affordable with developer
*  first pricing. Integrating the brave search API into your workflow translates to more ethical data
*  sourcing and more human representative data sets. Try the brave search API for free for up to 2000
*  queries per month at brave.com slash API. They didn't really cover though, not to be critical
*  of my new friends. The regulation that we desperately need are the things that you're
*  standing up here and saying, I want to get back to you guys and say, please do this. But you have
*  such a great experience with the cases that they both went to, which is defense and national
*  security. So why don't you give some maybe another layer of insights there? Yeah. I mean, I think
*  what we actually have in defense and national security, if anything, is the opposite problem,
*  which is not enough use of AI to modernize our national security apparatus. And this is,
*  I think this is somewhat the purpose of this forum, but in general, the DOD is hamstrung by
*  a lot of process, a lot of bureaucracy, and a lot of stuff that just doesn't serve an era when
*  technology is moving extremely quickly. And you have near peer adversaries that are moving
*  super quickly as well. I think if you look at China or Russia, their willingness and speed in
*  integrating new frontier technologies into every component of how they operate is vastly outpaces
*  what we're able to do if we continue operating in the same confines and bureaucracy that we've
*  been operating to date. I think this is a known problem within the DOD. A lot of people are working
*  very hard to try to solve this, both in legislation, in appropriations, as well as just
*  how the DOD itself operates. But my greatest fear is not that we accidentally, we don't
*  build the right regulation to prevent AI from being used in national security,
*  is that we as a national security apparatus, the DOD, the US DOD, and the US intelligence community,
*  don't use it enough to ensure that we maintain competitive in this next era.
*  Senator Clark, you've got to put a piece of legislation on the floor to regulate this space.
*  And I'm happily to change places with you as long as our net worths go together with us.
*  Senator Clark, what are you doing?
*  I think you'd want to find ways to aggressively field experimental technology into Alex's point,
*  get departments to actually use it. Because at Anthropic, we discover that the more we find
*  ways to use this technology, the more ways we find it could help us. And you also need a testing and
*  measurement regime that closely looks at whether the technology is working and if it's not, how you
*  fix it from a technological level and if it continues to not work, whether you need some
*  additional regulation. But to Alex's point, I think the greatest risk is us not using it.
*  What private industry is making itself faster and smarter by experimenting with this technology,
*  we do ourselves. And I think if we fail to do that at the level of the nation,
*  some other entrepreneurial nation will succeed here.
*  Isn't that great? I really expected you to give me something that would create parameters. But both
*  of you seem to be expressing the fear that if we aren't on the cutting edge of this,
*  we open up a whole world of vulnerabilities. So if I was a legislator, I'd be telling them to start
*  trying to regulate oversight over the administration to push them into doing it more. But I'm wondering,
*  you're on the left. I'm wondering if on the right here of the divide, Senator Ng, what are you,
*  us politicians always trying to create partisan shit and tribalism.
*  Or do you agree? What legislation are you putting to the floor of the Senate now?
*  If you're in a foot race with one or more competitors, I think there may be two ways to
*  win. One is you can try to trip up the other guy. Maybe we should do a little bit of that in some
*  cases. And the other is you could run faster and harder. I think here in the US, there's a lot we
*  could do to run faster and harder ourselves, invest much more in training, education, upskilling,
*  invest in computer infrastructure, as Alex mentioned, improve the appropriations process.
*  I think that I see lots of wins we could do there rather than constraining ourselves in the hope
*  that by constraining ourselves, we can trip up the other guy. And there's actually one other risk.
*  So today we see many nations buy surveillance software from other nations, from some of our
*  adversaries, and the limits our ability to influence other nations' respect for human
*  rights and privacy because there's no other software they're using anymore. I worry that a
*  lot of the spifing regulations being proposed in DC will shut American companies out of the supply
*  chain, cause other companies to use alternatives. And then someday, you know, when the large
*  language models ask the question, what do you think of democracy? I would quite like that AI to
*  give an answer that reflects our values rather than someone else's value. And I worry about those
*  spifing things shut ourselves out. It'd be like an own goal of shutting ourselves out of the supply
*  chain. Hey, we'll continue our interview in a moment after a word from our sponsors.
*  Hey all, Eric Torenberg here. I'm hearing more and more that founders want to get profitable
*  and do more with less, especially with engineering. Listen, I love your 30 year old ex-fang senior
*  software engineer as much as the next guy, but honestly, I can't afford them anymore. Founders
*  everywhere are trying to turn to global talent, but boy is it a hassle to do at scale from sourcing
*  to interviewing to on the ground operations and management. That's why I teamed up with Sean
*  Lennahan, who's been building engineering teams in Vietnam at a very high level for over five years
*  to help you access global engineering without the headache. Squad, Sean's new company, takes care of
*  sourcing, legal compliance, and local HR for global talent so you don't have to. With teams across Asia
*  and South America, we can cover you no matter which time zone you operate in. Their engineers
*  follow your process and use your tools. They work with React, Next.js, or your favorite front end
*  frameworks. And on the backend, they're experts at Node, Python, Java, and anything under the sun.
*  Full disclosure, it's going to cost more than the random person you found on Upwork that's doing two
*  hours of work per week, but billing you for 40. But you'll get premium quality at a fraction of
*  the typical cost. Our engineers are vetted top 1% talent and actually working hard for you every day.
*  Increase your velocity without amping up burn. Head to choose squad.com and mention Turpentine
*  to skip the wait list.
*  Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually
*  work customized across all platforms with a click of a button. I believe in Omniki so much that I
*  invested in it, and I recommend you use it too. Use Cogrev to get a 10% discount.
*  Well, let's be more direct and hit it on the head. We're competing globally with China, and there is
*  a lot of competition going on in the world. And we're competing with China, and we're competing
*  with China. There's a lot of concern. Some people, though, write off that concern. Here's Rand
*  Corporation recently suggested that China is unlikely to produce major new advances in AI
*  because of US's superiority in empowering private sector innovation. Is that true?
*  It's not true.
*  I don't know. Strong disagree. Some of the best open source models in the world have been built by
*  Chinese companies. So that's one indication of their very vast ability to catch up to our
*  technology. And I think one point just on this entire topic that is very important to make
*  is the urgency of the current moment. We kind of have a triple whammy situation right now,
*  which is that one, the technology is moving faster than it ever has before. I mean, the
*  increase in investment as well as the just raw scientific progress in AI is faster than
*  any technology we've seen in recent decades for sure. Then number two, we are in a geopolitical
*  environment and geopolitical atmosphere where there's continually increasing levels of conflict.
*  We're just seeing, you know, over the past few years, the amount of global conflict has increased
*  dramatically, and it's not clear what are the off-ramps for this conflict to decrease.
*  It's not looking, it doesn't make me feel great. And then the third whammy is that you have
*  a dictatorial leaders, you have President Xi Jinping, you have Putin, who are nearing,
*  you know, in the late stages of their times of rule, in which case they're going to be
*  more aggressive, more risk-seeking and make bolder moves. And so, you know, you look at this powder
*  keg of ingredients and we're just in a moment where we have to act really quickly.
*  And I'd like to make just one point I think is really important. At this event, there's been
*  lots of talk of how China can do fast following and China copies. In AI, it's actually different.
*  China has great inventors and great researchers in response to things like the export controls.
*  It's doing really fantastic work on distributed training to get around that, on all kinds of
*  low-level things to make training more efficient. And it would be a chronically stupid thing to
*  underestimate their capacity for inventiveness here. And I think it's important we keep that in
*  mind that we're not dealing with someone that's not creative. We're dealing with a competitor
*  that's going to be just as creative as us and is even more motivated.
*  So here, they're putting brakes on. One might argue, the United States talking about putting
*  parameters. You said, you mentioned very rightfully that from Europe to some of our
*  Asian allies are all putting these kind of lanes in which this can operate. China doesn't have
*  those rules. Is this sort of creating a competitive advantage for them or maybe a race to the bottom
*  when it comes to human rights? I'm wondering if this is something we should really be concerned
*  with it somehow we're advantaging them. I think I would love to see technology
*  spread around the world that reflects kind of democratic values. And I think we're
*  at a campaign on the ability to do that. Just to give an example, AI now is advancing on multiple
*  fronts. They're scaling up very large models. Jack and Tim has been doing that well. That's one
*  front that's well known. But there are multiple fronts. One example, I think a major front in AI
*  technology now is what we call AI agents or agentic AI. And what that means is if you use
*  Chaijit Deo or Claude, you might prompt an interterritor to write an essay. As I said,
*  while asking AI, type an essay for me going from start to finish without ever using backspace.
*  And AI could do that. It's a difficult task. With AI agents, we tell the AI, write an outline,
*  then write your first draft, then critique your own first draft, and then do some web search and
*  improve it. And it's a much more iterative process. The results are much better with our product. This
*  is one example of cutting edge AI called AI agents. And candidly, when I look at the research literature
*  on what's cutting edge, I see probably as many innovations coming out of, you know, like Tsinghua
*  University, for example, as many of the American universities. So the cat's out of the bag. But I
*  think that there is an open question of when some other country is going to download some open source
*  package to implement their own agentic writing journalism thing, you know, do we want the source
*  to be primarily other nations' suppliers? Or do we want to make sure that America has a huge voice?
*  Which is the area that we should be focusing on building out our capacity in those so that America
*  stays competitive in that way. Yes. And that we earn the right by helping the world to continue
*  to influence the world. Okay, well, speaking, I'm sorry, go ahead, Senator. Just one quick idea.
*  Thank you, Senator. There's lots of talk about funding compute in different countries. And
*  this idea does not favor Anthropic because we fund our own, but we want to create more competition
*  for these like large foundation companies. We want to help startups and researchers from academia
*  cross this chasm from research into production. And to do that, we should find ways to fund or
*  use the US supercomputing basis, sort of based to give startups and researchers a leg up,
*  because that's one way to take advantage of our inventiveness and competitiveness and use the
*  ecosystem around us. And Jack, you've been great. One of my cards here was all about
*  this idea of a national AI research effort. Strong supporter. I know you are. And I'm really more
*  than you know, I'm grateful for that because I think, again, it'll create more investments
*  that could produce more innovation and expand more opportunity. It's actually, I don't think
*  is an Anthropic selfish interest to promote that. So really, you know, a flawed. Yeah.
*  I'm wondering though, and maybe Jack, you can pick up on this, and then we can go through because
*  it is stunning to me. And the incredible moves and plays that Saudi Arabia and the UAE are making
*  in this space. I mean, at numbers that are mind boggling, and I have a good relationship
*  with some extraordinary leaders in both countries, the enthusiasm even for being big players in this
*  space. What do you, how do you view that for us as a nation is a hopeful sign and exciting sign?
*  Or does that worry you in the sense of shared values or anything that might be of concern?
*  If you want leverage here, you need infrastructure. Infrastructure lets you build the systems that
*  define this kind of reality and define the norms. So we need to invest money to do well here. And
*  to pick up on what another panelist said earlier, who knew that the path to AGI lay through US permit
*  reform, but that's probably one of the areas we need to work on so we can build data centers,
*  build power, and build the infrastructure here at home that lets us lead a press.
*  That's a really wise input. Do you want to add to that?
*  Yeah. I mean, I think regardless of what the United States does, the Middle East and other
*  countries around the world are going to build gigantic data centers and are going to build
*  huge amounts of AI computation power. So I think the key for us as a country is to figure out how
*  do we do what we've done with many core technologies in the past, the internet, telecom,
*  and many others to ensure that as much of the world's AI capacity that comes on board is in
*  accordance with our values and our system. Are you concerned at all about the big
*  investments that the Saudis and Emiratis are making? After Thomas Edison modernized the
*  electric infrastructure, lots of other countries got electricity too, but it was great. It led to
*  global economic growth, increased global prosperity. I think AI will be like that too. I think it's
*  great if lots of countries have a good electric grid. So I think it'll also be good if lots of
*  countries have more intelligence, including artificial intelligence. So let's end this way.
*  I love humanity and the endless potential of possibilities for innovation and everything
*  from the arts to the sciences, the capacity of humanity to reimagine futures that were never
*  even seen possible a generation before. And I love when I gave you guys legislative abilities,
*  which makes me think I might run your next campaign, that you all were like me wanting
*  to say that technology is not something to be afraid of. We need to create some basic security,
*  but when it comes to everything from our actual defense all the way to expanding
*  democratic ideals of level playing field, more opportunity to learn, to grow, this should be
*  the one of the most exciting moments in the evolution of humanity. And so maybe just an acute
*  way to end. When you look at the year 2055, what is one thing that you think that most people aren't
*  even getting their mind around yet that we might be experiencing because of this hopeful, promising
*  area called artificial intelligence? I think anyone will be able to learn everything. They
*  will get a customized education plan and future that works perfectly for them and lets anyone
*  pick something they're curious about and become an expert on that. I think that's within reach with
*  this technology. I think the scientific breakthroughs that we're going to have over
*  the coming decades through use of this technology will make all the sci-fi futures that we've been
*  thinking about slowly and slowly become a reality. So we'll live in the Jetsons.
*  Wow. I think today intelligence is one of the most expensive things in the world,
*  which is why only the wealthy among us can hire a specialist doctor to carefully look at your
*  condition and give you advice or hire a patient tutor to coach your child. I think AI, artificial
*  intelligence, is making intelligence cheap and this means that if you decades hence, I think any
*  of us will be able to hire an army of specialists, well-trained staff to advise us and help us with
*  our things in a way that only the wealthiest in our society can today. Well, I pray and hope that
*  this doesn't create more concentrations of wealth and power but a more democratized spread where
*  genius, which is equally distributed. There's many geniuses being born in Burkino Faso per
*  capita as are being born in the most affluent places of New Jersey, but what we do inefficiently
*  right now is cultivate that genius. And if your vision of the future is really one where human
*  genius anywhere can have access to the tools and resources, that unlocks a potential for humanity
*  that is is sheerly astonishing. And I know from our history books, when I was in high school,
*  history textbook had an over emphasis on the George Washingtons, the Jeffersons, the Reagans
*  go through it. But the real people I think that are often doing unsung heroes are those
*  that are the innovators and the scientists and those who are creating systems and opportunities
*  that we now in our generation take for granted. You three are frontline players in ways that has
*  me humbled and in awe. And the fact that I got a chance to sit on the same level as you for 20
*  minutes really excites me. And I pray that all your hope and all your aspirations for this technology
*  come true and that generations from now benefit from your genius. Thank you very much. Don't give
*  us too much credit. We really need the politicians to settle the framework. I'm gonna let you that
*  be the last word. Thank you everybody. Thank you. Thank you. Thank you.
