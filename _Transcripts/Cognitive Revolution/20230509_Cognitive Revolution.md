---
Date Generated: April 03, 2024
Transcription Model: whisper medium 20231117
Length: 3677s
Video Keywords: []
Video Views: 771
Video Rating: None
---

# Scouting the AI Revolution with Robert Scoble and "Ben's Bites" creator Ben Tossell
**Cognitive Revolution "How AI Changes Everything":** [May 09, 2023](https://www.youtube.com/watch?v=7pAq5IEKIYY)
*  I mean, I tried to talk Bill Gates out of $300 million one time,
*  actually a little bit more, but he's like, I don't think so.
*  So I know how hard it is to get a corporation the size of
*  Microsoft to spend $300 million.
*  They just spent $10 billion on chat on open AI.
*  With AI, it's not where are you today.
*  It's how fast is it improving even chat GPT if you say,
*  oh, I can't use it.
*  It generates too much bullshit for my work.
*  Right.
*  How many more updates do you need before it's perfect?
*  Every hour is changing.
*  Everyone should always want less tools.
*  I don't need to use 10 things when one thing will do.
*  AI will be in all of the big tools, all the big platforms.
*  We're seeing them all move to push stuff out every single day.
*  How much of their market share could be eaten by these smaller
*  tools who do take an AI first approach because then I think
*  the details really matter.
*  Hello and welcome to the cognitive revolution where we
*  interview visionary researchers, entrepreneurs, and builders
*  working on the frontier of artificial intelligence.
*  Each week we'll explore their revolutionary ideas and together
*  we'll build a picture of how AI technology will transform work,
*  life, and society in the coming years.
*  I'm Nathan Labenz joined by my co-host Eric Torenberg.
*  Hi everyone and welcome back to the cognitive revolution.
*  Today we're talking to two more prolific AI scouts,
*  Robert Scoble and Ben Tossel.
*  I've used that term AI scout a couple times recently,
*  including to describe myself.
*  So before diving into today's episode, I wanted to take just a minute
*  to tell you how I think about the role of the AI scout
*  and how it relates to the show.
*  Zooming way out as I often ask our guests to do, I really do
*  believe that there's a good chance that we're entering a critical
*  period in human history.
*  While the best AIs still generally fall short of human expert
*  performance, they do now consistently outperform the average human
*  on a huge number of challenging and economically valuable tasks.
*  And of course, they are only continuing to improve.
*  Considering that their architectures and training processes
*  are so fundamentally different from our own, that their strengths
*  and weaknesses are also so distinct from ours, and that their capabilities
*  are proving difficult to predict and their behaviors sometimes hard
*  to control, I believe that society is flying very rapidly and all too
*  blindly into an increasingly hard to predict AI future.
*  In other contexts, governments and large corporations routinely make
*  major investments in intelligence and competitive research to better
*  understand both their rivals and their market dynamics.
*  And while I certainly hope that AI never becomes a rival to humanity,
*  it seems only prudent at this point that society should develop specialists
*  who devote themselves to studying AI from every angle, at every level
*  of abstraction, using all the available information and all relevant analytical
*  frameworks so that we can better characterize AI behavior and understand AI
*  systems as they actually exist rather than how we might wish they were.
*  I call this new role the AI Scout, taking inspiration in part from
*  Julia Galiff, author of The Scout Mindset, who emphasizes the value of
*  working toward accurate beliefs even when they may lead to uncomfortable
*  conclusions. To become the most effective AI Scout that I can be, I aim to spend
*  50% of my time just studying AI fundamentals and keeping up with the
*  latest developments. Talking to the entrepreneurs, builders, researchers, and
*  fellow Scouts that you've heard on this show has been a major part of that for
*  me over the last few months. But I also spend a lot of time reading research
*  papers, trying all sorts of AI products, using the latest models, and of course,
*  scrolling Twitter and listening to some other great podcasts. My goal in all
*  this is to have no major AI blind spots and to continually deepen my
*  understanding of the most critical questions in the space so that I can help
*  my teammates, the companies that I advise, you, the Cognitive Revolution
*  audience, and perhaps even policymakers and society at large understand AI more
*  accurately and ultimately make better decisions about how to develop, deploy,
*  and use it. In addition to the show, I'm also starting to publish some more
*  polished and hopefully enduring AI analyses. Recent topics include LLM
*  pricing trends and their economic implications, the competitive dynamics
*  between the leading AI companies, whether GPT-4 can do science, and lots
*  more besides. To get that content, if you don't already, I encourage you to
*  follow me on Twitter where I am LeBenz, and my DMs are open, and also to sign
*  up for our newsletter on the website cognitiverevolution.ai. I share all this
*  today because I really do think we need more AI scouts, and if you're listening
*  to this podcast and fascinated by the subject, there's a good chance that you
*  can add value in such a role, likely sooner than you'd expect. My approach is
*  just one approach. Today you'll hear from two other AI scouts who scout in their
*  own ways, and in any case, as Riley Goodside, another pioneering AI scout,
*  said in the recent episode, we're all still new to this. The pace is relentless,
*  and the volume of information can be overwhelming, but the good news is that
*  amidst such rapid change, new people can quickly reach the frontier and begin to
*  contribute. Now, on to today's guests. Robert Scoble, who writes as
*  Scobleizer on Twitter, is a long-time Silicon Valley technology explorer and
*  connector, a futurist who's met so many technology legends in their prime that
*  he's now also something of a historian. Like me, he attempts to understand
*  technology from as many angles as possible, to identify the driving forces,
*  and to anticipate what's going to happen next. We covered a lot of ground,
*  including how he expects people to interact with AI systems in our daily lives,
*  what Apple is going to do with Siri and all those extra chips that have been
*  sitting dormant in our devices for years now, what form factors will dominate the
*  future, how AI will power augmented and virtual reality, and lots more. In the
*  second half of the episode, I talked to Ben Tossel. Ben is the author of the AI
*  newsletter, Ben's Bites, which combines editorial and curated stories in a
*  choose-your-own-adventure format, which often include more than 50 links in a
*  single edition. We talked about the relentless pace of AI and the challenges
*  inherent in keeping up, when it's worth switching tools for new AI features,
*  versus better to just wait for your current tool to add AI support, how he sees the
*  competition between startups and incumbents developing, and how he
*  personally uses AI in his own daily work. Though he says at one point that he
*  doesn't use many AI tools, he then goes on to describe six or so in intimate
*  detail, showing that in fact, he very much does. These are two fast-paced and
*  wide-ranging conversations, and I hope you enjoy hearing from AI Scouts,
*  Robert Scoble and Ben Tossel. Robert Scoble, welcome to the Cognitive
*  Revolution. Hey, thanks for having me on. Our audience will probably be familiar
*  with you from your prolific output online for years. So yeah, just give us a
*  quick intro to who you are, what you do. As a child, I was Apple's first child
*  laborer when I was 13. That's where it got me started. That's the benefit of
*  having a dad who's an electrical engineer and moved us here to Coofer T.
*  Now back in 1971. That got me to fall in love with new things. I fell in love with
*  the Apple II motherboard because I made a couple hundred of them with my mom. But
*  that got me to study new things. Apple was my first startup that I
*  toured, and since then I've been seeing startups at a pretty fast rate,
*  thousands of them. I launched Siri. I was the first one to see Flipboard. I was the
*  79th user of Instagram. I had the first ride in the first Tesla with Elon Musk.
*  Mercedes-Benz gave me its first ride in its first autonomous car. So I've been
*  at it for a while. I wrote four books on technology that predict decade-long
*  changes. And the last book was on spatial computing, which is still happening,
*  which includes AI. So I've been watching AI because I care about augmented reality,
*  and AI is going to be how that is all fed. Today I'm following 38,000 people in the AI
*  space on Twitter, and I'm the only human to do that.
*  I'm kind of trying, in a sense, to follow in your footsteps a little bit. I'm describing myself,
*  these days, as an AI scout. And I kind of think of that as like,
*  trying to zoom out as far as possible. All of that kind of comes together, hopefully,
*  into a worldview. Yeah, yeah. It's why I still do Twitter. I don't really care that people are
*  reading me. I'm using it to learn about the market and learn about all sorts of things,
*  watch my investments and stuff like that. And it's a very powerful way to learn.
*  We're on an exponential path of a whole bunch of technologies. I mean, these data centers that run
*  our lives are getting so massive now. I mean, Microsoft has data centers that are a mile long.
*  It's crazy to think about that, to our data centers. Because I used to work at Rackspace
*  and Cloud Competing World, and so I got inside a lot of data centers. The ones that are being
*  built now are just insane. Also, the data flows. I mean, we're in a different world than we were
*  15 years ago. Today, if something happens, my grandma calls me up really quick because
*  she's not on Twitter. She's not on Facebook. But she finds out the news so fast because of
*  Twitter and Facebook. There's a bunch of work being done behind the scenes on these things.
*  The reason I'm following 38,000 people, I started noticing all sorts of college kids are
*  going into AI. They're going into computer science, but then they're grouping up with a few
*  kids at Stanford or Carnegie Mellon or a bunch of different places around the world
*  and making all sorts of new AIs. The new AI papers that are coming out from those kids are
*  just extraordinary and fast. I'm seeing a lot of papers every day. Then you start looking at
*  ChatGPT and it's like, oh, this is not Siri anymore. You can talk to it and it can write you some code,
*  and then it can explain how the code works. That leads you into a whole bunch of new things,
*  and not just code, but marketing copy, emails. It can do a lot of things.
*  Now business people are starting to go, oh, what does this all mean for my business, for myself?
*  How do I use it? Where are the mistakes? Because it still generates mistakes because
*  this new AI, it really predicts what your next possible word is. If it's writing a sentence,
*  it's just going, what's the next word? What's the next word? It doesn't know anything. It doesn't
*  really understand anything. It does, but not like a human being, things that they understand things.
*  Sometimes it goes down a bad path and generates you some bullshit.
*  It can help you find it too. It's like, this code doesn't run. Can you help me debug it?
*  It usually knows where the mistakes are. It's like, whoa, this is a new kind of intelligence
*  you have to learn to talk to and learn where to trust it and not trust it.
*  I love it because it has richness on multiple dimensions. The technical depth is great. The
*  practical utility and fun is certainly at this point with GPT-4 next level.
*  There's this philosophical, what does it all mean? What does it understand? Maybe a better
*  question, maybe a better frame on that is like, how does it understand? You mentioned your
*  experience writing decade long forward looking predictions. It's probably never been tougher
*  to do that than right now. If you go to the right Silicon Valley parties, you know what's coming
*  for a while. That's why I read the paper, started reading all these AI research papers,
*  because those might not come out for consumers for five, seven, ten years.
*  They tell you how the technology is working in their lab at Stanford or Carnegie Mellon or
*  somewhere like that. Very practically, can you paint a picture for us of daily life? I'm walking
*  around, what do I have? What am I wearing? How am I communicating with what am I communicating?
*  If you could take that as far out as 2030, I'd be very interested to hear what that sketch looks
*  like. I'm talking to you on an iMac. It has an M1 processor in it. 21% of that processor is neural
*  network, is a very powerful AI inferencing engine. Think of it as the runtime for chat GPT,
*  can go in that or stable diffusion, right? Two gigabyte model, you can run it in the
*  processor on an M1. An entrepreneur last week that I talked to about this said it's more powerful on
*  inferencing than a 3080 Nvidia card, right? Not on model building. If you need to build the model,
*  if you're an AI team, you're going to need to buy some Nvidia 100 cards and run them either in your
*  office or run them up on the cloud somewhere, buy some Nvidia space from Amazon or somewhere like
*  that. This is real interesting. This part of the chip is cold right now. It's not being used at all.
*  They shipped it two years ago. I bought this computer almost two years ago. It's been sitting
*  on my desk with that part of the chip completely, almost completely unused. I mean, it turns on once
*  in a while, but almost completely unused. It's cold right now. It's not being used right now,
*  right? And next to it is an ultra wideband chip. So I have a bunch of these radios. This is a
*  ultra wideband radio from Estimo. What is ultra wideband? It's in your phone. It's in your
*  headphones. It's in your Mac. It's in your TV. So Apple has shipped 15 devices into my house
*  that have this chip, and it too is pretty much not turned on. At least the full capabilities aren't
*  turned on, right? So Apple has shipped a mesh network with a huge amount of AI into people's
*  homes. Millions of people's homes are like mine, right? And they haven't turned it on.
*  Check out the first episode with A16Z's Park and Treason. The link is in the description.
*  Omnike uses generative AI to enable you to launch hundreds of thousands of ad iterations that
*  actually work customized across all platforms with a click of a button. I believe in Omnike so much
*  that I invested in it, and I recommend you use it too. Use Cogrev to get a 10% discount.
*  That tells you right there that this move has been planned for a long, long time. I had dinner with
*  the guy who ran Siri nine years ago. I said, what are you learning by working at Apple? And he goes,
*  well, I'm learning that Google's kicking my ass. And I'm like, how do you know that? Oh, we
*  instrumented Google's AI and we instrumented our AI. This was nine years ago. We know that Google
*  is learning faster than we are, so we have to rebuild Siri from scratch and have a whole
*  different idea. And that's what's coming in June this year, 2023. So there's a new headset that
*  uses this AI mesh. The whole ecosystem uses the AI mesh. Think of your phone can talk to the AI
*  inferencing engine that's in your Mac and run stable diffusion in there. Or you can run all
*  sorts of things. The entrepreneur who told me about this runs the company called SuperNormal,
*  which takes notes on a video meeting like this, takes a transcript, and then at the end of the
*  call, it looks through the transcript for patterns. Hey, did we talk about tasks? Did we talk about
*  themes? Right? And pull those out as notes. By the way, that takes 300 milliseconds. So a fraction
*  of a second, it takes your notes. Right? And that's why I know the chip is unused because even
*  this guy is using it already, but I don't run that many things that have these new AI workloads yet
*  on the AI part of the M1 processors. It's sitting there mostly unused. So you're going to see all
*  sorts of new AI things coming out later this year that use the Apple mesh or a hybrid, right? Some
*  inferencing done on the local machine, some done up in the cloud. Right? Yeah. So tell me, so give
*  me a little more color on like, okay, you're painting the picture of the capability. There's
*  all this kind of latent potential that hasn't been realized and the hardware is already deployed,
*  which is pretty incredible. I mean, I tried to talk Bill Gates out of $300 million one time.
*  Actually a little bit more, but and he turned me down and I had a good reason to I sat next
*  to Tim O'Reilly when he wrote the web two memo that became web two, right? So I went back and
*  told him about a bunch of things in the web two space and he turned me down. And he turned me down
*  a second time. Because I was seeing a bunch of things happening. And it's like, hey, you should
*  buy this and this and that's give me $300 million. I'll go buy them for you. He's like, I don't think
*  that's gonna work. Right? So I know how hard it is to get a corporation the size of Microsoft to
*  spend $300 million. They just spent $10 billion on chat on open AI, right? So they laid a bunch of
*  people off, took that money savings and invested it in open AI. And then just this morning, they
*  showed off their new office suite that has chat GPT built into a bunch of their tools. So they're
*  now building all sorts of things like the slide decks, just by talking to the engine, Hey, I need
*  a slide deck. I'm, you know, I need to pitch a bunch of people next week. You know, you just talk
*  to it and it starts building things. It's crazy. What's my life going to be like? That's what I
*  really want to know. Like, am I going to be still using a computer and a keyboard for a while?
*  I mean, how many years if we're talking five years from now, you're wearing a pair of
*  augmented reality glasses and talking to the computer, you know, Hey, Siri or Hey, chat,
*  GPT or Microsoft, what you might even not even need to use Hey, right, because it's going to know
*  where you're looking. It's going to know what your hands are. Siri is going to have some fun thing.
*  There's a new Siri coming in June too, because of all this AI stuff. And Siri, if you're wearing a
*  headset, can know what you're holding, what you're touching, what you're gesturing toward, right,
*  what you're looking at, what you're staring at. And so it can answer questions that chat GPT can't
*  answer. Right. And we haven't yet seen Tesla, Twitter move into this world. Twitter knows what
*  things we're talking about right now. Right. So, oh, man, it's endless. If you're wearing the glasses
*  or the headset, you're going to be able to talk to Siri and have it do all sorts of things and have
*  a conversation with you about a whole lot of things. Right. And that's going to be
*  pretty interesting. You know, the typical white collar, you know, worker today is,
*  I think, working probably more than ever. And is kind of always on and feels like,
*  you know, I was promised on some level this like future of leisure and it never seems to
*  quite materialize. Right. We get all these new tools and connectivity and, you know, famously,
*  like we see that everywhere, but the productivity statistics and everybody's like working a lot.
*  Somebody's on TikTok because the numbers keep going up.
*  Yeah, there may be a lot of, there is a lot of social media use on the clock, I think as well.
*  Yeah. And that's leisure is intermixed into, you know, your work day. I mean,
*  you know, I have a surround sound system here. I listen to music all day long. And at night,
*  you watch movies and TV shows. I mean, that's that alone is different than when I was a kid. I mean,
*  when I was a kid, my parents had a black and white TV that you had to get off the couch to
*  change the channel between four channels. You know, now you have trillions of videos on YouTube
*  to watch on these TVs. Right. It's like the problem with trying to predict the future
*  is it's easy to predict what we have and how it might be impacted by this new technology.
*  But what we're about to get is on our camera, on our glasses, a camera and an eye sensor and a
*  microphone and an AI computer. So it's going to do computer vision. That's going to be pretty crazy
*  someday. The computer vision just in GPT-4 might be the most mind blowing part of it for me. That's
*  something, you know, my company Waymark uses small business images that they posted online to like
*  synthesize more content for them. And man, it has been a grind to interpret what is in these small
*  business, you know, user generated content uploads. It's like imagine you get something
*  from a vendor, right? You know, and you hold it in front of your glasses and it understands it.
*  It understands what is this a legal document? Is this a note from your doctor? Is this a customer
*  complaint? You know, whatever it is where they took a picture of handwritten notes that the guy
*  had made some ideas and I built an app out of that. It's like, whoa, you know, and brain computer
*  interfaces are coming that sort of understand how your brain works and lets you talk to the brain.
*  That's what I'm saying. It's going to get even weirder from here. If a million people already had
*  a neural link in their heads and you could by getting one yourself enable thought to text,
*  in other words, you know, you think and your thoughts go directly to, you know, computer
*  interface. Would you be interested in getting one? I thought actually one of the best answers we got
*  was basically like it depends on the competitive landscape. Oh, yeah. A person said, you know,
*  if everybody else has it and I can't compete without it, then I'd probably get one. This is
*  why you're going to get augmented reality glasses because if I show up at a boardroom and I have
*  glasses on and I have access to all this chat GPT stuff and patterns, right, it can display that in
*  3D in a way that a 2D screen isn't as good. I've seen many, many, many examples of that. If I have
*  glasses and you don't, I have a huge advantage over you. I can get you probably get you fired
*  because I can see patterns that you can't and certainly the boss can't and the boss is going
*  to ask me ask you why aren't you wearing the glasses that this guy has because he obviously
*  is seeing patterns in your business that you don't see and you're screwed. You're not up to date.
*  Imagine you go to a board meeting without a phone today or without a computer and say,
*  hey, I don't want to use this new fang of that computer stall. You're not going to last very long.
*  What's your outlook for robotics that could be like domestic robots?
*  It's coming. It's just what year if we have a humanoid robot, let's say right now my wife,
*  but you know, orders some door dash and a robot comes to the front door and rings the doorbell.
*  If it's that good to deliver something to my front door, it's good enough to come in the
*  house and do a bunch of work for me. The robot could be at the front door and say, hey,
*  here's your grocery. You just work. Would you like me to come in and put it away for you?
*  Yeah. Would you like me to do your dishes? Would you like me to do your laundry? And if it's
*  capable enough to get in the car, you know, pick up a delivery somewhere, you know, go into a
*  grocery store and buy all your groceries, get in a car and then bring it to your house and bring
*  it to your front door. It's also capable enough to go and fold laundry and stuff like that.
*  Stanford has a robot that already can do thousands of tasks. Right. So we know it's coming.
*  It's just, is it four years away? Is it six? We could have an argument about that. I think it's
*  around four years. When that comes, it's also going to have a large language model AI that you
*  talk to because it's going to understand you. Hey, robot, can you tell me a story from bedtime
*  story for my kids? I mean, a lot of people are now using chat GPT to write bedtime stories for their
*  kids and they're reading their kids the bedtime story that the chat GPT made for them. Right.
*  So now you're going to have a robot. Oh, can you play chess with me? Robot. Hey, sit down,
*  have a chess game with me. Teach me how to play chess. It can do that. All of a sudden you have
*  a thing in your house that you have a relationship with, a friendship, a friendship with a relationship
*  with, and you trust it. Right. So if you tell it to wash your clothes, do you care that it got rid
*  of the tied soap in the garage and replaced it with some other brand? No, as long as the clothes
*  come out nice and clean, I don't really care. Right. I trust my robot to do that.
*  And as long as the robot keeps doing it as well as I used to do it, it's going to take over my
*  whole house, my whole life. Right. Again, so I can dream, so I can talk to chat GPT and build a new
*  business or answer some customer email that it's having some trouble with. Right. So yeah,
*  I'm with you on almost all that vision. I think the one thing that I kind of, that still seems
*  almost anachronistic as you describe that is responding to the customer email. You know,
*  why is that even coming to you at that point? Because it might not understand something
*  specific because the customer is making a new request that it's never heard before. Right. Or
*  it knows it understands the email, but it knows that needs a human approval. That tap, that thing
*  that it's being asked for, you know, can you send a hundred thousand dollars to this company?
*  Human probably will still need to want to sign off on that one. Yeah. You still want to, you know,
*  watch to make sure that system doesn't go and empty all your bank accounts. Right.
*  So what is your expectation for the next Siri? Like, will it be able to
*  execute transactions? You know, if I were to say, order me, you know, Uber Eats from whatever,
*  get me the burrito, you think it can go all the way through to, to transaction and
*  burrito is set to be delivered in 22 minutes? Siri might call other AIs to load onto the M1
*  processor and run like, like a super normal app that, that watches your video conferencing, right.
*  And takes notes. And all of a sudden an AI is firing up. Do you care that it's super normal
*  and it just charged you five bucks? It might ask you, right. Hey, you know, you got to turn on
*  super normal or turn on our meeting note thing and that'll cost you five bucks a month. So you
*  approve. Yes. And by the way, you can approve with your eyes, with your hands, right. With your voice,
*  with your pen, right. Cause it's watching you draw, you know, so you can even select a virtual
*  thing on a table, you know, yeah, go ahead. I approve. And all of a sudden it's calling super
*  normal shoving that into the neural network and firing up. And now it's taking notes on our meeting.
*  Yeah. I'm definitely seeing a lot of that kind of multimodal systems and delegations,
*  ensemble, you know, architectures. But I do think one question for all of these,
*  really for all entrepreneurs right now, right. Is like, is this a startup scheme or is it an
*  incumbent scheme? So if you're building something on Lang chain and then I'm listening to you and
*  I'm like, wait a second, this is coming to Siri and all of, and by the way, probably Google Assistant
*  too, and like all of the phones natively this year, do you see startups like winning in this
*  space or do you see them kind of exploring the space and then just being kind of crushed by like
*  Siri to play? Siri was bought by Apple for $220 million. I was talking to somebody who's talking
*  to Satya at Microsoft. They spent 10 billion on open AI's chat GPT to integrate all that.
*  Apple, if Apple wants to buy chat GPT, it's going to cost 40 or license it. If they want to buy open
*  AI, it'll be a lot more. So 40 billion for compared to 15 years ago or 12 years ago when Siri was bought
*  $228 million. That alone tells you something major has changed. And open AI is startup.
*  It's 300 people and they're talking, they already got $10 billion from Microsoft.
*  It feels like we're in this kind of Cambrian explosion moment, but yeah, I don't know. It
*  does seem like we're kind of headed for like super app, where Siri and Google Assistant and
*  whatever, the Microsoft version are going to kind of code on the fly, spin up little
*  interfaces with things to the point where,
*  what's the future of apps? I kind of wonder. If you ask chat GPT to create you a spreadsheet and
*  put in all my customer data, and if it can hook up and do that, you know, whoa, and that's not very
*  far from here. I mean, it might be possible. I have even that kind of thing is getting there. I mean,
*  certainly now that Microsoft and Google are building these things into their tooling,
*  right into their apps, I'm expecting that kind of thing to happen pretty quick.
*  I think you're the perfect person to ask about tools that you use today.
*  They're doing drug discovery with this technology, right? At Pfizer and other places.
*  Music is coming along and music generated music will matter in augmented reality glasses. So
*  you're going to see new kinds of music. For instance, if you want to walk through a high
*  school marching band digitally in your living room, you can't the music industry tells me that's very,
*  very difficult to capture and distribute right now because of a lot of reasons, but your generative
*  AIs can create music in your house so they can create a drum, a saxophone, a clarinet, a flute.
*  Let you walk between those in your house in a way that the music industry cannot do.
*  And so there's going to be a new thing. There's a new holodeck coming.
*  Holodeck is an interesting way to think about it because you're going to have a 3D environment
*  probably by Christmas from Unity or other or stable diffusion that you can talk to.
*  Hey, environment, take me to the Taj Mahal. And you're in the Taj Mahal. You're in front of the
*  Taj Mahal. Take me to Yosemite National Park. You're in the park or something that looks sort
*  of like Yosemite because it still hallucinates a little bit. Our memories aren't that accurate
*  anyway. You just need to feel like you're in Yosemite National Park and have it accurate enough.
*  You can start talking to this environment and then manipulating it with your eyes and your hands and
*  your voice. Hey, can you put a purple tree right there? It knows where your chest ring to.
*  It knows where you're looking at. And it knows how to do that. That's called inpainting from
*  stable diffusion. It can inpaint to a purple tree in the 3D scene around you. So now you have a
*  holodeck, right? And if it can hook up and do all sorts of things like, can you hook up that remote
*  control so it actually works? If it can hook up all the code for the remote control and make it so
*  that if I push a button, some code runs and runs the environment around me, oh my God, right?
*  And that's coming. So are we going to, how are we going to absorb all this? Do you think that society
*  is going to just, Hey Chad, GBT, I'm really a slow human being. This stuff is overwhelming for me.
*  Can you simplify your environment? Can you teach me step by step what I need to know to make you,
*  you know, answer a customer email today? Or entertain me in any way? Yeah, yeah, we can
*  show you all sorts of things we can do. That user experience I think could be probably pretty good,
*  but the fallout like outside of the glasses, you know, is what I am wondering if you have any
*  intuition for. It'll work on the phone too. It's just, you know, phone has just a little tiny
*  screen compared to glasses could have a wrap around environment around you, right? All the
*  way around you. And huge instead of looking at, you know, I'm looking at an iMac right now, which is a
*  a two and a half foot wide screen. If I'm wearing glasses, it's a wrap around, you know,
*  40 foot screen, right? A screen like Universal Studios has, they drive you through these
*  screens, the world's biggest screens they claimed. And they have huge, huge, huge screens on both
*  sides of the trim. It was really awesome. Yeah, that's coming to your living room this Christmas.
*  If you have the Apple headset, most people won't get the first one. So they'll get the second one
*  next Christmas, right? Or the third one, which is the pair of glasses, which is the Christmas after
*  that. So by 2025, 2026, we're in a new world. And humans will deal. We always do. We haven't even
*  talked about this really scary stuff, right? Which is I sat next to an AI safety researcher
*  for 10 hours coming home from UK. And he freaked me out. He's like, AI could run away and
*  and figure out, you know, humans aren't needed. And here was the thing. AI is already better than
*  surgeons at seeing tumors in scans. And surgeons are highly trained, highly educated people who
*  have been doing this a while, right? And AI is already better than them. So he said, well,
*  let's take it 25 steps down the line. Does the AI decide it doesn't need humans anymore? Right.
*  And that's a risk. Runaway AI. I don't know how that all is going to play out because humans are
*  clearly going to build the AI and not worry too much about the potential downsides 20 years from
*  now. So if you were in charge, do you have any thought on what would be wise to do?
*  The problem is if you stop it, you stop all the productivity that's about to happen. So you sort
*  of cripple your economy. And is China going to stop it? No, they're going to be very, very
*  aggressive about using this. I asked a worker at VW who VW has digitized their entire factory
*  floor where they make cars. Right. And I was like, when are you going to put a 3D sensor on the
*  entire factory floor? Like camera, camera, camera, camera, camera, and have an AI watching the human
*  and looking for patterns of how people work. Right. Looking for inefficiencies, looking for a part
*  that took a little bit too long to get to the worker who puts it in the car, stuff like that.
*  Oh, we can't do that in Germany. Why not? Oh, we have laws against recording employees.
*  In China, they're already doing this. They don't have laws like this. Right. To protect workers,
*  privacy and stuff like that. So you're going to see one country gets hyper hyper productive.
*  And one country falls behind. That's not good for the country that's falling behind.
*  Right. Because all of a sudden all the jobs goes to China, in which already it's happened a lot.
*  Right. But even more because they're better at making things for cheaper price, faster,
*  because they studied human behavior on the factory floor and reorganized the factory floor. I mean,
*  this is what Elon's doing with Tesla. He's studying the factory floor every day and looking
*  for advantages to make his products faster and cheaper than anybody else's. Yeah. The race
*  dynamics, I think, are a real problem. And the US-China relationship and the sorry state of it
*  also is just a, because that's where everybody goes in this discussion right now. And I think,
*  man, if we could just be a little bit more friendly with China, we might have a much better
*  long-term AI safety governance discussion as well.
*  They have 1.3 billion people. We have 380 million people. I know how AI works. The AI that has more
*  data wins. Every single time it wins usually. So that gives China a huge, huge advantage there.
*  Now, if all the Western world all worked together and wasn't fighting with each other,
*  that'd be a better thing. But I don't know. The global politics is a whole other discussion of
*  how this would play out and work. But if you ban an autonomous vehicle from your community because
*  you're scared of jobs going away, for instance, like truck drivers are the number one job in
*  America. 1.3 million people work driving trucks around. Those jobs are going away. They're going
*  away someday, soon, 15 years, five years. Tell me about your FSD experience. It sounds like
*  you're a regular user. It's upgrading this week too, by the way. And that's another major AI thing.
*  We haven't even talked about it. That's another one. It's coming on Saturday. It has a little
*  cherry on top of this week. It's just crazy AI. It's amazing. Every three months, Tesla owners
*  get a major update. So how many more major updates do you need to prove to the world
*  that this thing drives better than any human being? Not many. Four? That's a year. 12? That's three
*  years. It already is better. I mean, it drives me from my house to Santa Cruz, which is a 40-minute
*  drive on curvy roads with walls on both sides of the road at 55 miles an hour. And it does just fine.
*  It does better than me. It's smoother than me. Yeah. I heard a little bit about that from a friend
*  who works at Tesla and already has the merged stacks. And they said, yeah, it's much more human
*  even than when I took my test drive with them a month ago. Here's one. If a motorcycle is
*  splitting lanes behind you and you're not watching the rear mirror, your Tesla will move over and let
*  them by. That's human. And that's version 11. It didn't do that in the version that I currently
*  have. So that kind of thing. On the new stack on the road to Santa Cruz, I came up to a bunch of
*  stopped emergency vehicles that were in my lane. My car went right around them like a human.
*  Slowed down a little bit and then went, you know, signaled and went into the other lane and went
*  right around them. With AI, it's not where are you today. It's how fast is it improving. Even
*  chat GPT, if you say, oh, I can't use it, it generates too much bullshit for my work, right?
*  The code it writes is a little buggy. How many more updates do you need before it's perfect?
*  And they're improved. I have a friend who's a computer vision expert and is really watching
*  OpenAI. He said every hour is changing. They're checking in code changes for the model
*  to make it more accurate. And it's changing over time. So how many more months do we need to make
*  it so perfect that everybody's like, I'm using that to write everything. Right. I had a friend
*  who said, oh, I used to write code for a month. Now it takes an hour, right, to do the same thing.
*  And it's going to train new people. I mean, you can learn the code on it, right? Hey, write me a
*  Twilio API call that'll call X from my phone. Twilio is a service that does phone calls. It's
*  underneath Uber. When you make a call to your driver on an Uber app, you're actually using
*  Twilio, right? So the app developer made a Twilio API call and Twilio took care of the phone call.
*  And then it comes back to Uber. Chat GPT can write that. And then chat GPT can explain the code to
*  you line by line and explain what is it doing. And so now the human being, you know, like my
*  13 year old kid can learn how it all works. Can you explain how this thing works? Yeah, well,
*  let's walk you through line by line. And it has a lot to pull up and teach you. Right. Same thing
*  with German. Can you teach me how German works? Right. You want to learn how to speak German
*  because you're going to Europe next week? You know, chat GPT or Duolingo just added
*  its own AI, which teaches you how to how to how to speak German. Welcome to change. Welcome
*  to the exponential age. Until we talk again, where can our listeners find you? Twitter.
*  Robert Scoble, thank you very much for being part of the cognitive revolution.
*  Ben Tossel, welcome to the cognitive revolution. Thanks for having me. From what I understand,
*  you are taking the leap and making Ben's Bites a full time venture. So I'd love to just hear a
*  little bit of like, where you plan on taking it, you know, what how you're thinking about developing
*  it as a business. It's gone through some of those iterations already. The first two emails were
*  editorial completely, and I hated it and I was terrible at it. So I went to more of the curated,
*  like, choose your own stuff. Like, when you read it, there's a lot of things on there.
*  But it's just like a summary of what has happened today or yesterday in AI. So then you can pick
*  what you're interested in. And the plan basically is there's a gray space between
*  non technical people who are interested in AI, but are like, what do I do with it? Where do I go?
*  What do I play with? What do I use day to day and all of these questions where
*  people are probably reading an article hearing about it. And then it's like, well, what next?
*  And I'm, I'm not trying to build something for very technical people in the space. I think there's
*  loads of stuff going on there, which is awesome. And I want to support any of that, but it's more
*  of a, what kind of space can we create in this area where I think there's probably the biggest
*  amount of people. And I think there's loads of stuff we could do. And I know that's one of my
*  problems is always thinking, oh, we should do that and that and that and that and just keep
*  adding stuff on. So we're trying to be a bit intentional about what that's going to look like.
*  And I think we can grow the newsletter, but it's then what are the interesting pieces that are
*  coming out of that? Like what interesting conversations are we having? What interesting
*  questions am I having? How do we service those? Do we service them? Is there some way to like
*  spin out a bunch of these single use applications, like a little studio, or is it more on just
*  pumping out content and thinking about that side of things and even investing and doing a fund
*  around everything? There's so many different ways to explore it. And what I'm doing is taking the
*  leap so that I just can't explore everything and anything and look at everything and think,
*  should this be what we do or is that something that is a distraction and it's not worth our time?
*  And we'll experiment with a bunch. I'm going to try and build up a team of AI first people,
*  employees, and try to like make sure that that is used heavily because I want to sort of
*  talk our own shop and actually try and give people an example of, oh, this is how we're using it.
*  What's going to win? Is it going to be the AI first kind of rethinking things from the ground up?
*  Or is it going to be more of a AI as a layer that gets kind of added to everything and it becomes
*  kind of a new way to interact, but the products that you interact with maybe don't change as much
*  because they already do lots of useful things. And now you can just kind of layer on this
*  natural language mode of working with them. Do you have a position on that? And do you think
*  that that's evolving? Where are we in that moment as kind of, we've seen certainly a proliferation
*  of stuff, but now the incumbents seem to be coming back with their answer. Who do you think is winning
*  that battle right now? Originally, I would have thought, oh, no, AI first products will win.
*  Just that's how I think it'll happen. And then I am changing my mind a bit to think, well,
*  if I already work in Notion and Notion adds the AI capabilities of insert other tool that I'm using
*  for those things, everyone should always want less tools. I don't need to use 10 things when one
*  thing will do. So I think it just becomes AI will be in all of the big tools, all the big platforms.
*  We're seeing them all move to push stuff out every single day. So I think that's definitely
*  going to change. But I do wonder how much of their market share could be eaten by these smaller tools
*  who do take an AI first product. Because then I think the details really matter on if you're
*  a specific type of writer. If I'm a newsletter writer, Notion might work. But Notion is like
*  a big tool to fit anyone. Whereas I might want a really, really specific, I'm a newsletter writer,
*  and I want to have a specific tool that does this certain thing, which I think AI enables.
*  And I think we'll see some big tools that are AI first. Like if you think of education,
*  everything we know about education is someone tells you something, you're sort of sitting there
*  consuming it, and then you go off and somehow replicate it or do the thing. Whereas if there's
*  a case to say, well, actually, teachers always tell you the working out is where the value is.
*  So why not have your challenges to get to prove this thing or figure out this thing. And actually,
*  the work is just in you working with the AI and figuring out where you're gathering information,
*  putting that together. And it's just a completely different way of learning than we would have been
*  used to. I think things like that that will come up that maybe don't feel obvious now,
*  but in the age of AI might. But I think the big thing is like what I was speaking about where
*  AI in a big incumbent, the thing that I don't know would work is how does that then trickle back
*  through the organization? Because if AI can do a lot of the stuff that the humans, the humans,
*  I keep saying that, but it's like, I'm in this world now where I'm actually having to reference
*  humans versus another thing. But if the AI is actually pulling together reports, like helping
*  summarize a bunch of stuff, suggesting things to improve, like generating content, all of these
*  things, can't we see a world where a lot of these bigger companies have 20% of the actual headcount
*  that they need? Lots of them always go through these layoff cycles. I just wonder what impact
*  that will have here. I think it's definitely plausible. Can you give any examples of
*  incumbents that you think have done either a particularly good or particularly underwhelming
*  job of integrating AI into their existing product flow? I mean, bizarrely, Microsoft is the one that
*  everyone seems to be looking at as like, oh yeah, this is doing great stuff. It's actually shipping
*  something. So I think that's a good example of people being able to use products in a big way.
*  But I, like many people, don't use the Office products and Microsoft products that much. So
*  I'm waiting for the Google version and the Google version has not come. It's just there, but it's
*  behind a waiting list and everything else and a research paper and all the rest of it. So
*  that feels like a flop to me. And it feels like Google had enough people thinking about this for
*  enough amount of time that they really should have been able to ship something, at least
*  a lot quicker than they are now. But I think actually ChatSpot by HubSpot, I know Domesh,
*  one of the founders, he's been noodling on stuff and he loves doing that. And I think
*  I don't even use HubSpot, but the example of that just saying, oh, can you find some leads for me?
*  Oh, let's follow up with an email to that lead. Where was the sales I had for this thing? And
*  it's just a way of talking to your data, but it gives you a visual example of, oh yeah, I get those
*  use cases and I can translate that use case for mine quite easily. So I think those are three
*  fairly big companies that I think are doing a good, poor, best job.
*  It's interesting that you describe Google as kind of poor and yet as into this as you are,
*  it doesn't sound like the Microsoft suite of tools is enough to get you to change your whole
*  productivity suite. So does that translate in your mind to kind of evidence that the incumbents are
*  going to win? If you're not switching, who's going to switch? And I'm in the same boat, by the way.
*  There's some level of, well, all my stuff's there. So yeah, I'm kind of reluctant to up and
*  change my whole workflow when I know I can see where in a few months time, those Google
*  workspace stuff, that's going to roll out and it's going to be more or less the same as the
*  Microsoft stuff. It's not a unique take on what that thing needs to do for me, but the basic
*  foundation of that tool, I prefer the Google version than the Microsoft version currently.
*  I'll have to say currently, no. But yeah, I think it's just an ease of use and it's until
*  AI really creeps into your day to day and you're stuck in those habits of,
*  I use this thing to do those things. I don't know, the switching cost seems
*  a big one for those kinds of products. I mean, I've stopped using Google search
*  for as much as possible. That's had to be like an actual choice that I'm remembering that I'm making.
*  I mean, it's easy to switch the default browser and things like that. So that's not so bad,
*  but like knowing that I'm searching something, it's actually, I'm using Neva for the search.
*  But actually if I'm trying to find out something, I'll use chat GBT. So I'm trying to do that,
*  but I mean, that's a behavior that I'm willing to do where my parents are not ever like,
*  they're not going to be thinking about that for a long time. They're going to be wanting
*  the thing to be good, be there and be what they know and know how to use it. So yeah,
*  it is interesting to see how much will it take for someone to flock from one big product that
*  they actually use all the time and ingrained in their life to another? Yeah. Even the browser,
*  I've also been kind of reluctant to change. I have the new Microsoft Edge and the dev edition and
*  have the new Bing access. And I do flip over to Edge to use the new Bing chat and search,
*  and it's kind of native environment. But still again, I have not gone as far as saying, all
*  right, I got to move all my, I got LastPass attached to Chrome. And so all my sign-ins are
*  there and my history is there. And I'm like, well, how much of this do I want to move? And maybe I
*  just start using Bing in Chrome or, I don't know. And then there's obviously going to be a Chrome
*  version too, as you say. So I think that's a challenge that a lot of people are wrestling
*  with right now. It's good to know that you also are wrestling with it and not chasing every
*  new product. Flipping over to the new stuff, one thing I've been struck by in doing these
*  interviews and talking to people that really are building the future is when I ask them what AI
*  tools they use on a daily basis, most of them cite very few things. And it's usually chat GPT
*  is kind of the core thing. And now we've obviously recently, we're on recording today on GPT-4 plus
*  seven, which is how I'm now thinking about the calendar with the new zero date. But it seems
*  like the constant improvement of the core models and that core experience now up to and including
*  GPT-4 for subscribers anyway, does put a lot of pressure on what you might call thin wrapper
*  products or kind of clever, but minimal use cases that kind of package up the GPT in a certain way.
*  What are you seeing in the new product category in the sort of AI first paradigm that you feel like
*  is breaking through as measured either by a consistent place in your day-to-day workflow
*  or just something that you think is different enough and kind of going to be here in a while?
*  I'm actually in the camp where I don't use that many AI tools, which might surprise a lot of
*  people. But I mean, it's not because I don't want to, but it's the same thing, as you mentioned
*  before, where I need the AI tool to be where I am working or where I'm used to working or how I like
*  working. To upend and change all of that takes a lot of doing and takes a lot of remembering to do
*  that. And then you're always looking at is this trade off worth it and all that sort of stuff.
*  So, I mean, the things that I use, I use barely.ai, which is a Chrome extension that is always
*  floating around on my browser screen. And I'm not using Chrome, I'm using the Arc browser. So I'm
*  trying to do some different stuff there, but that's always just there. So it's like a click away for
*  when I'm including articles, reading up stuff, I'm consuming a lot of content every day. So
*  I use that to summarize things and pull things out where I can use that for the newsletter.
*  I'm not a developer, so a lot of these dev tools seem to be just sitting there sort of dangling a
*  carrot of, oh, if you had learned to code back in those days when you said you were never going to,
*  you might know what to do here. So I find that funny. And I do want to do some more stuff there
*  because I try and play with Replet and the Ghostwriter and stuff like that. And I only can get so
*  far. Read-wise, I have for collecting lots of links and helping me with the text to speech stuff.
*  I'm using that quite a lot. There's not a whole lot of tools that I'm using every single day.
*  I know that some of these tools are wrappers on top of OpenAI or whatever model they're running.
*  But a lot of them are really good for one use case. So if it's like, I've got a health question,
*  I'm seeing people talk about magnesium something to help you sleep. I'm like, right, I can go and
*  search Neva or Google or Perplexity or anything else. Or I can go and find one of those Andrew
*  Huberman podcast chatbots and see like, he must have spoken about this somewhere. Let me just
*  search that and find out, okay, like from someone I sort of trust and can validate, knows what they're
*  talking about, what would they say? And I'm finding that behavior interesting where I think
*  lots of tools nowadays are sort of all in one. Everything comes in one place. But I don't know
*  why it needs to be that. If there's very specific, like I've got my own little AI legal bot that
*  every time I've got legal questions, instead of pinging my dad about everything, I'll just ask
*  that. Or if there's like a little accountant bot that I've got that knows my finances and
*  have very specific use cases, I think we'll see a lot more of that. And I think eventually we'll have
*  an idea for I want my own legal assistant. And then you could have AI create the code and then
*  just deploy it on your machine. And then you're like, okay, that whole thing was no code because
*  I didn't write anything, but it was deployed and created by AI. And you can start training it that
*  way. I think we'll see a lot of those. So yeah, it feels like there'll be a lot of individual tools
*  around in this space.
*  Yeah, you mentioned Replet. And we've had Amjad on the show once talking about all the things that
*  they're working on. It does seem like this notion of disposable software or single use applications
*  is coming at us also very quickly and likely to be a transformative paradigm. Because now you can
*  just speak little mini apps into existence to solve your problems as you encounter them.
*  And just move on. You don't really have to worry about maintaining that code. You don't really have
*  to worry about how it works or edge case testing all that much. It just needs to do what you needed
*  to do right in the moment. And then you can throw the whole thing away. So that's really interesting.
*  And I'm experimenting with that. I think for me, the number one use case is code generation.
*  I can code, but man, it can code faster and better than me in most cases. And I think that's
*  really a huge unlock in that respect. Ben Tassel, thank you so much for being part of the cognitive
*  revolution.
*  Appreciate it. Yeah, thanks a lot.
*  Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that
*  actually work customized across all platforms with a click of a button. I believe in Omniki so much
*  that I invested in it, and I recommend you use it too. Use Cogrev to get a 10% discount.
