---
Date Generated: November 05, 2024
Transcription Model: whisper medium 20231117
Length: 8287s
Video Keywords: []
Video Views: 587
Video Rating: None
Video Description: In this special episode of The Cognitive Revolution, Nathan shares his thoughts on the upcoming election and its potential impact on AI development. He explores the AI-forward case for Trump, featuring interview with Samuel Hammond. Nathan outlines his reasons for not supporting Trump, focusing on US-China relations, leadership approach, and the need for a positive-sum mindset in the AI era. He discusses the importance of stable leadership during pivotal moments and explains why he'll be voting for Kamala Harris, despite some reservations. This thought-provoking episode offers a nuanced perspective on the intersection of politics and AI development.

Be notified early when Turpentine's drops new publication: https://www.turpentine.co/exclusiveaccess

SPONSORS:
Weights & Biases RAG++: Advanced training for building production-ready RAG applications. Learn from experts to overcome LLM challenges, evaluate systematically, and integrate advanced features. Includes free Cohere credits. Visit https://wandb.me/cr to start the RAG++ course today.

Shopify: Shopify is the world's leading e-commerce platform, offering a market-leading checkout system and exclusive AI apps like Quikly. Nobody does selling better than Shopify. Get a $1 per month trial at https://shopify.com/cognitive

Notion: Notion offers powerful workflow and automation templates, perfect for streamlining processes and laying the groundwork for AI-driven automation. With Notion AI, you can search across thousands of documents from various platforms, generating highly relevant analysis and content tailored just for you - try it for free at https://notion.com/cognitiverevolution

LMNT: LMNT is a zero-sugar electrolyte drink mix that's redefining hydration and performance. Ideal for those who fast or anyone looking to optimize their electrolyte intake. Support the show and get a free sample pack with any purchase at https://drinklmnt.com/tcr

CHAPTERS:
(00:00:00) About the Show
(00:00:22) Sponsors: Weights & Biases RAG++
(00:01:28) About the Episode
(00:13:13) Introductions
(00:14:22) The Case for Trump
(00:16:32) Trump: A Wildcard
(00:21:02) Governing Philosophies (Part 1)
(00:26:10) Sponsors: Shopify | Notion
(00:29:06) Ideological AI Policy
(00:33:47) Republican Ideologies
(00:40:31) Trump and Silicon Valley (Part 1)
(00:40:31) Sponsors: LMNT
(00:42:11) Trump and Silicon Valley (Part 2)
(00:47:49) Republican Nuance
(00:53:36) Elon Musk and AI
(00:55:43) Utilitarian Analysis
(00:58:01) Internal Consistency
(01:00:31) Trump's Cabinet
(01:04:22) Counter-Establishment
(01:05:53) Immigration Reform
(01:10:37) Teddy Roosevelt Analogy
(01:15:30) Creative Destruction
(01:22:29) Racing China
(01:32:51) The Chip Ban
(01:44:20) Standard Setting
(01:48:36) Values and Diplomacy
(01:52:50) American Strength
(01:55:56) Red Queen Dynamic
(01:59:23) Interest Groups & AI
(02:05:06) Peering into the Future
(02:08:32) Concluding Thoughts
(02:17:45) Outro

SOCIAL LINKS:
Website: https://www.cognitiverevolution.ai
Twitter (Podcast): https://x.com/cogrev_podcast
Twitter (Nathan): https://x.com/labenz
LinkedIn: https://www.linkedin.com/in/nathanlabenz/
Youtube: https://www.youtube.com/@CognitiveRevolutionPodcast
Apple: https://podcasts.apple.com/de/podcast/the-cognitive-revolution-ai-builders-researchers-and/id1669813431
Spotify: https://open.spotify.com/show/6yHyok3M3BjqzR0VB5MSyk
---

# AI Under Trump? The Stakes of 2024 w Samuel Hammond [Pt 1 of 2]
**Cognitive Revolution:** [November 01, 2024](https://www.youtube.com/watch?v=D5j87v2UnyY)
*  Hello and welcome to the Cognitive Revolution, where we interview visionary researchers,
*  entrepreneurs, and builders working on the frontier of artificial intelligence.
*  Each week we'll explore their revolutionary ideas and together we'll build a picture of
*  how AI technology will transform work, life, and society in the coming years.
*  I'm Nathan Labenz, joined by my co-host Eric Torenberg.
*  As a developer, the journey from concept to production-ready large language model apps
*  is fraught with challenges. Dealing with unpredictable language model outputs,
*  hallucinations, and ballooning API costs can all be blockers to shipping your next AI-powered feature.
*  That's where Advanced RAG comes in. With the new RAG++ course from Weights and Biases,
*  you can overcome these hurdles and build reliable, production-ready RAG applications.
*  Go beyond proof of concept and learn how to evaluate systematically,
*  use hybrid search correctly, and give your RAG system access to tool calling.
*  Based on 21 months of running a customer support bot in production,
*  industry experts at Weights and Biases, Cohere, and Weaviate show you how to get to a deployment
*  grade RAG application. This offer includes free credits from Cohere to get you started.
*  Make real progress on your large language model development and visit wnb.me.cr to get started
*  with their RAG++ course today. That's wnb.me.cr to get started with their RAG++ course today.
*  Hello and welcome back to the Cognitive Revolution. This weekend we're running two episodes which
*  originally appeared on the Moment of Zen feed focusing on the election, in which I attempt to
*  give an honest hearing and questioning to two different AI forward cases for Trump. I like this
*  exercise because in my honest opinion, this election is ultimately a referendum on Trump.
*  My interlocutors are in the first episode Samuel Hammond, senior economist at the Foundation for
*  American Innovation and a thinker that I generally very much respect. We cross-posted his appearance
*  on the Future of Life podcast last year and I also really appreciated his 95 theses on AI,
*  most of which I agreed with. In the second episode, I speak with Joshua Steinman,
*  Trump's National Security Council Senior Director for Cyber Policy and Deputy Assistant to the
*  President from 2017 to 2021, the entire Trump term. Before launching into it, I'm going to briefly
*  share where I've landed on Trump as I expect a possible Trump presidency might relate to AI
*  development. If you see AGI as a real possibility in the 2027 timeframe, it seems totally reasonable
*  to consider the election's impact on AI as a major decision-making factor. Of course, I understand
*  that people have other priorities, but this is not a politics channel, so I'm not going to offer my
*  opinion on every issue, just AI and AI-adjacent issues. Interestingly, as you'll hear, I find that
*  on a number of these AI-adjacent issues, I agree with the Trump supporters that I talked to. To
*  name a number of them, nuclear energy is good. We should build more nuclear plants. Population
*  decline is a problem and does merit real concern. Freedom of speech is valuable and should be
*  protected. On the current margin, we should have fewer rules and more right to build on one's own
*  property. We should cultivate a culture of achievement. We should aim for an age of abundance
*  and dismiss degrowth. And it makes sense to prioritize high-skilled immigration, at least
*  to some degree. Finally, American companies like Amazon, Google, and Tesla should not be allowed
*  to abuse their market power at the expense of consumers, but neither should they be subject
*  to government harassment just because they're outcompeting many legacy businesses. Fortunately,
*  it does seem that the Democratic establishment is coming around on at least a number of these.
*  But regardless, there are three big reasons that I cannot ultimately support Trump,
*  despite these important points of agreement. Those are, 1. He is far too inclined to escalate
*  tension with China, accelerate decoupling, and prioritize his own narrow domestic political
*  interests over the national and global interests. 2. The lack of rigor in his thinking and discipline
*  in his communications seems like a recipe for unnecessary risk-taking in an increasingly volatile
*  environment. And 3. I believe we are far better off approaching the future with a positive sum
*  and inclusive mindset, not just within the US, but globally, if we're to have a healthy conversation
*  about a new social contract that befits the AI era. On the question of US-China relations,
*  I think we have a general failure of leadership and vision on both sides, unfolding slowly,
*  but gathering more momentum all the time. People now see adversarial relations with
*  China as a foregone conclusion. Joshua Steinman calls it the physics of the environment.
*  To put it plainly, I do not accept this. Conflict with China would be a disaster,
*  and an arms race would take us ever closer to that disaster. But I don't see this as an
*  inevitability because I don't see China as a meaningful threat to America, Americans,
*  or the American way of life. That's not to say that the Chinese government hasn't wronged us
*  at times. Their cover-up of early COVID, whatever its origins, was shameful. And obviously,
*  Chinese agencies and companies have stolen a lot of intellectual property from American companies.
*  I don't think we should ignore that, and of course we should take steps to make ourselves
*  less vulnerable, but I think we should stay level-headed about it. The possibility that
*  our grandkids could be speaking Chinese one day seems far more remote to me than that AI
*  destroys the world. I would say that the Biden administration has done OK on AI policy
*  domestically. The 10-26 threshold for reporting requirements has aged pretty well for a 2023 rule,
*  and I do believe in some strategic industrial policy as well. Subsidizing the building of
*  new chip fabs in the US so that we're not so easily disrupted by a Chinese attack on Taiwan
*  seems, under the current circumstances, a prudent step for a great power to take.
*  At the same time, the chip ban still feels wrong to me, and I have to admit that Kamala's rhetoric
*  on China also depresses me. There's simply no way for China to understand recent US statements
*  and actions other than as an attempt to keep them down. And for me, this escalation seems premature
*  at best. Given the shape of an exponential curve, we could have retained the option value of cutting
*  them off from chip sales later, and still the bulk of the total hypothetical chip sales would
*  have remained in the future. Relatedly, I've been really interested to see Miles Brundage,
*  OpenAI's recently departed head of policy research, saying that we need to make a much
*  more proactive effort to demonstrate that Western AI development is benign, which of course is much
*  easier to do if it actually is benign and to some degree open or otherwise shared. If we must frame
*  our relationship with China as a competition, I would love to see us race them on metrics like
*  life expectancy improvements, the number of diseases we can eradicate, or perhaps the tonnage
*  that we can send to Mars. Of course, I do understand that it's a complicated situation,
*  that naive solutions won't work, and that real solutions will be both nuanced and difficult to
*  find. And I do intend to invite more China experts onto the show going forward in an effort to more
*  substantively contribute to a positive vision for the future. For now, I wish that Kamala and
*  democratic leadership in general were both less hawkish and more visionary, but considering just
*  how much trust has already broken down and how difficult it's going to be for the two countries
*  to make credible commitments to one another, I'd rather have a steady hand who is more predictably
*  going to follow a sane consensus path and might actually make some arms control type deals,
*  even if politically costly for them, to help us navigate a tricky period as well as we possibly
*  can. Trump, I think it's well established, will do anything to avoid looking weak, has credibility
*  with rival countries perhaps when it comes to threats, but not when it comes to positive
*  follow through. And for me, his withdrawal from the Iran nuclear deal, general taste for inflammatory
*  rhetoric and stated plans for blanket tariffs, which will hurt the American consumer in order
*  to vaguely somehow stick it to China, all suggest to me that he is overwhelmingly likely to make
*  things worse. Zooming out from US-China relations, while I agree with Sam Hammond when he says that
*  the more fucked you think we are, the more willing you should be to roll the dice with Trump,
*  I don't actually think that we are all that likely to be fucked. I've been a bit ambiguous about this
*  over time, often saying that my P-Doom is 5 to 95%. And I've meant that to reflect the fact that
*  while nobody has convinced me that we don't need to worry about AI risk, neither has anyone convinced
*  me that it's inevitable. After all, while we don't really know how they work and we see all sorts of
*  surprising and sometimes alarming capabilities, today's best AIs do understand human ethics and
*  values quite well and seem to be getting at least a bit more aligned with each passing generation.
*  This may not continue and we should absolutely be vigilant about it, but this is a much better
*  position for 2024 than most AI safety people expected 5 or 10 years ago. Today, facing a
*  decision like this referendum on Trump, I recall the words of a wise friend who told me that we
*  should think less about what the probabilities currently are and more about what we can shift
*  them to. Here I have to say, with competent, stable leadership, I believe we can steer
*  towards scenarios on the lower end of that range, where the nature of the risk is more
*  intrinsic to the technology itself and less the result of letting domestic political incentives
*  lead us toward imprudent escalations, AI arms races, or catastrophic, impulsive decisions.
*  I often think of the role that Kennedy played in the Cuban Missile Crisis. My understanding is that
*  he overrode the recommendations of his military advisors to insist that the United States would
*  not escalate to nuclear war first. That was heroic, but scenarios in which executive authority
*  really matters can cut both ways. When I imagine Trump versus Kamala in moments of intense crisis,
*  where a single decision could alter the course of history, I have to say, I find it much more
*  likely that Trump would impact things substantially for the worse than substantially for the better.
*  After all, we all saw how he handled COVID. To be clear, Kamala has not impressed me on the topic
*  of AI either, and in general, her track record suggests not the great foresight of excellent
*  leadership, so much as the tendency to follow local trends and incentives. We absolutely could
*  hope for better. But still, if I have to choose a leader for a potentially highly volatile period
*  of time, I'll take the stable, sane person who will listen to the expert consensus, even acknowledging
*  that the experts could be wrong, rather than betting that Trump will somehow manage to override
*  the experts in a positive way. You'll hear my conversation partners make the case, which I won't
*  attempt to summarize here for fear of doing it too poorly, that Trump represents our best case to
*  break out of a broken consensus and revitalize the American state for the AI era. In the end,
*  I just don't see it. It sounds to me like chaos when we need capability. Finally, when it comes
*  to the future of American society and the world at large, I think we have a never-before-seen
*  opportunity to adopt a positive-sum mindset, create a world of abundance, and ultimately
*  update our social contract. I think OpenAI and other leading companies do have roughly the right
*  vision when they talk about benefiting all humanity. And I think Sam Altman, for all the
*  other criticisms that I've made of him, absolutely should be praised for his experiments in universal
*  basic income. While neither candidate has shown this kind of vision, Kamala at least aims to speak
*  and extend opportunity to all Americans. I thought her best moment of the recent debate
*  was when she said that when Americans look at one another, quote, we see a friend. This is at least
*  something of a foundation on which to start building a shared positive vision for the future.
*  Trump, of course, is far more zero-sum in his thinking and negative in his outlook,
*  and that does have real consequences. I grew up in Macomb County, Michigan, one of those bellwether
*  counties that swung hard from Obama to Trump. And I also have family in Ohio. My beloved mamaw
*  and papaw belonged to the same cohort as JD Vance's grandparents. They moved from rural
*  Kentucky to southern Ohio for jobs, the whole thing. To be totally honest with you, one thing
*  that I have seen for myself is that Trump has brought out the worst in a lot of people. Sure,
*  JD Vance, Elon Musk, and others in Trump's orbit are no doubt more sophisticated thinkers about
*  technology than Trump himself. But still, I cannot imagine this brand of cynical populist politics
*  could possibly lead to a healthy national conversation about adapting to AI as it,
*  let's face it, is going to be disrupting a lot of people's jobs, let alone reimagining what it
*  means to contribute as a citizen or to live a good life. It would be shameful if we ended up
*  hoarding the benefits of AI or restricting access for non-Americans due to some sense of scarcity
*  that isn't even justified by the fundamentals. But unfortunately, that's the direction that I
*  would expect Trump to take us. Ultimately, the idea that Trump could be president as
*  AGI is first developed strikes me as an imprudent move, to say the least, with far more and more
*  likely downside than upside. By all means, listen to these conversations with an open mind and form
*  your own judgment. But for my part, I can't support putting a loose cannon in power as we head into
*  such a potentially pivotal period. And so I will be voting for Kamala, primarily as a rejection
*  of Trump. Hello. There we are. Yo, there we are. Hey, guys. So sorry about the slow start or the
*  missed counting on my end. I'm really stoked to have this conversation, guys. Thanks for joining.
*  We just had a chance to chat a little bit and get familiar. Actually, first time we've ever spoken,
*  although we've exchanged DMs, occasionally appreciating one another's various outputs.
*  So it was good to have a little warm up. You two thinkers are two of the thinkers I respect the
*  most. You can't fit you two in a box. You both get into arguments, heated arguments, good natured,
*  but deep arguments with people who are on your side of the, who are kind of in your peer group.
*  So you don't fit neatly into any category. So I wanted to invite you both on. And Sam, let's
*  start with the piece you wrote, but kind of the broader thinking that you've been undergoing as
*  it relates to the case for Trump. That's been what we've been debating the last few episodes.
*  And you brought the effective altruist perspective to it as well as your other perspective. So
*  let's start there. Sure. And for the record, I'm not an effective altruist. I just, I can put on
*  that hat and try to think about what an EA would say. I am a kind of rationalist. And one of the
*  things rationalists are known for is trying to see through convention and social desirability
*  bias. Is supporting Trump going to hurt you in your social circles? Well, then maybe you should
*  have a degree of metarationality and try to interrogate that and overcome it potentially.
*  At least it doesn't mean support Trump, but it means factor that into how you understand yourself.
*  So from my lens, to take a more utilitarian look at how two candidates would play out,
*  what matters most, at least in the long run, is innovation and innovative capacity,
*  especially if you care about future people. Innovation compounds on itself, productivity
*  improvements compound on themselves. So the question becomes who is better for innovation,
*  at least at first order. And in my piece, I break down some of the most obvious areas,
*  drug and medical innovation is a huge one. Kamala Harris and piggybacking on some Biden initiatives
*  wants to cap pharma prices based on the basket of international prices. This, I think, this would be
*  a huge mistake. I mean, there's been tons of research into how the US is a kind of provider
*  of global public goods, because the fact that we pay exorbitantly for all kinds of drugs enables
*  big pharma companies and small pharma companies for that matter to actually do the R&D that goes
*  into designing and manufacturing new drugs and then jumping through the FDA approval hoops.
*  And so there's been estimates that even just the pharma caps that were put in under the Inflation
*  Reduction Act have delayed or maybe killed up to 170 new drugs, untold costs associated with that
*  policy, even if they're relatively unseen. And I don't think it really stops there. I mean,
*  later in the piece, I get into AI, which is maybe where Nathan can get into it. But I think the
*  two administrations, the Trump or Harris administration, would take a very different
*  tack on AI. And that might be the biggest issue of all, depending on how you see it playing out
*  and where you think the technology is headed. Getting AI policy right could easily swamp the
*  costs or benefits of every other domestic policy you think about. Well, I agree with the last
*  statement most that the AI policy seems to matter most. I guess the way I think about Trump is as a
*  total wild card. And I do agree. I think EAs and do I call myself an EA is an interesting question.
*  I'm definitely highly influenced by EA thought. I would say if I'm not an EA, it's probably because
*  I'm not virtuous enough to count myself among them. I generally have a lot of respect for
*  the EA community and especially those that really hold themselves accountable to living up to EA
*  values. And I don't always feel like I do that. So I sometimes, I want to say like,
*  I'm not worthy of the EA label. But I think the EAs are right to think long term, right to care
*  about future people, right to not discount the future too much, whether you should go all the
*  way to zero discount is an interesting question. But then when I think about Trump in that way,
*  I kind of can't even get down to the level of resolution on these like super specific policies.
*  I would agree that like, we want to get more drugs. I, you know, I don't necessarily always
*  like paying the higher prices for drugs, but I do buy the argument that there's something good about
*  subsidizing drug development for the rest of the world. And yet, I'm like, that seems so small
*  compared to the really big questions. I think the EAs are also right to worry a lot about
*  the tail risks. And when I talk to EA thought leaders, I really don't hear anything along
*  the lines of like, you know, this policy, that policy tax, you know, incentives, you know, what
*  what's the sort of amortization going to be? Instead, what I hear is like, how do we make sure
*  we don't have nuclear war? How to make sure we are as prepared as we can be if a really bad pandemic
*  comes our way? And how we make sure we have the best possible thinkers in place to make whatever
*  judgment calls might need to be made as AI really starts to potentially heat up, you know, maybe as
*  soon as within the next presidential term. So I guess, you know, when we get to we can unpack all
*  those things, but I think all of them are kind of tail risks. You know, if you were to tell me that,
*  you know, another pandemic would happen, but would only be as bad as COVID, you know, then I could
*  sleep reasonably well at night. If you're just telling me like, we might have a small nuclear
*  war, but it'll only be like one nuclear weapon, then again, I could be like, okay, well, I can,
*  you know, the world can probably deal with that. The real risk is like the pandemic that is super
*  lethal, or the nuclear war that like goes all out. And it's in those sort of scenarios where I'm just
*  like, I have no idea what Trump would do. I don't trust that he is like, a very stable genius, you
*  know, at all, quite the opposite, I would say he seems like a very unstable and not genius person.
*  He has managed to, you know, in his first term, he did seem to kind of get away with crazy in most
*  cases. But I sort of look at that, you know, when I look at the better angels of our nature graph,
*  you know, of fewer conflicts and lower casualties and war, and then I look at the spikes, I'm like,
*  you know, I really don't want to see that next spike. And Trump to me feels like the kind of
*  guy who might tamp down the small spikes, but inadvertently create the conditions for a really
*  big spike. And so I don't know even what I should expect, you know, from an AI policy from Trump.
*  I don't think that, you know, I don't think like Harris is a genius on AI, you know, her famous
*  clip of just two little two little letters, you know, is not super confidence inspiring.
*  But Trump feels like, you know, he's totally all over the map. I have no idea what to expect from
*  him one day to the next. And I, I don't feel like we can really even talk about, you know,
*  this policy or that policy or whatever, because he's just so erratic. And there is a lot of power
*  vested in the presidency, right? I mean, he, at the end of the day, like if he if he holds the office,
*  people are supposed to listen to him. And that just seems like a very unstable
*  situation to put ourselves in, given all the other uncertainties that we're likely to face.
*  So that's the hump. I mean, I would be interested to know, like, what do you think
*  Trump AI policy would be? And how confident are you in that assessment? Because I, you know,
*  don't have a lot of confidence in my ability to predict what Trump will do from one day to the
*  next. Yeah, I mean, before getting maybe getting into the concrete policy details of, you know,
*  how different missions could pan out, I think maybe we could zoom out to just the different
*  governing philosophies and the kind of coalitions behind each party. That first of all, from an
*  EA perspective, you know, especially the more doomer you are, it's probably probably because
*  you think things just go bad by default, right? And how do we get off a default path without
*  embracing some higher variance option? And so that's like point number one, the high variance
*  of a Trump administration actually should be in its favor, because there could be very high highs
*  and very low lows. And it's very hard to, you know, it definitely leads to some discomfort or
*  some uncertainty. But if they were going to do something that's sort of out of left field,
*  it's I think much more likely to come out of administration. Second, you know, Matt Grossman
*  and David Hopkins, these two political scientists have an excellent book that I always recommend
*  called Asymmetric Politics. And it talks about how to understand the Republican and Democratic
*  Party from a sort of more analytical structure based lens. And their argument is essentially
*  Democrats should be thought of as a coalition of social groups. We have like the teachers unions,
*  the trial lawyers, the, you know, Joe Biden and the credit card companies. There's all these
*  different stakeholders and they kind of have to balance each other's interests and often pursue
*  policies that are very concrete and directed a particular interest group. But ultimately,
*  it's sort of through the stakeholder negotiation path. Republican Party in contrast is much more
*  of an ideological vehicle, right? It's based around the conservative movement. There's obviously
*  different factions within the Republican Party. But because it's more ideologically driven,
*  it can also do things if you are able to couch a policy within that vision and show why it's
*  consistent that are in some ways more first best, right? And in some ways even cut against their
*  narrow interests, right? So like the fact that they appointed justices that overturned Roe v.
*  Wade has cost them in the election, but it was driven out of the ideological view of what
*  the Supreme Court is for. You know, the fact that Paul Ryan during the Tax Custodian Jobs Act
*  repealed the home mortgage, severely capped the home mortgage interest reduction,
*  assault deductions, which are like very popular credits. You know, it instigated a war with the
*  realtors associations. You know, that was because he had this ideological view of like tax, the tax
*  code should be simpler, right? It wasn't driven from an interest group. It was driven from this
*  sort of supply side ideology. Similarly, like if you look at the personnel and to a large extent,
*  personnel's policy within a Republican administration, at least in the last Trump
*  administration, they drew heavily from more libertarian circles, right? So we talked about
*  you know, talk about the tail risks from pandemics, Operation Warp Speed occurred under the Trump
*  administration. And I think it only could have occurred under Trump administration in part
*  because they had a couple of Chicago School economists that were at FDA, and that were
*  basically given the mandate to apply Chicago School theory within the Chicago School economists
*  been thinking a lot about like the hidden costs of FDA drug regulations, like the drugs that don't
*  go to market, how do we streamline these things. And so they were already in the process of
*  deregulating FDA for the explicit purpose of accelerating vaccine approval. And part of that
*  was an architecture for public-private partnerships, which then was deployed with Operation Warp Speed
*  and that pulled forward, you know, the vaccine by like five or six months and saved like
*  up to 200,000 lives. Probably has all kinds of second order effects because now there's been a
*  boom in activity around MNRA and there's MNRA candidates for malaria, for cancer, for there's
*  like a pan influenza vaccine that's in development. And so like on the surface, yes, now politics have
*  polarized and during the pandemic, Trump suddenly became, you know, went from being pro-vaccine to
*  anti-vaccine. And you saw the exact opposite on the Democratic side where like Kamala Harris,
*  before the first vaccines were approved, was saying, I don't know if I put that in my body.
*  And then like now they're out and then all of a sudden things repolarize. That doesn't mean,
*  I think, in the event that we had another pandemic that they wouldn't also just pull out that same
*  playbook and accelerate a vaccine because ultimately the way Trump appears on TV is much
*  different from how he ends up governing. And you probably make a similar point about like World War
*  Three and like nuclear risks and stuff like that. In interviews, Trump will say, you know, it's the
*  N-word, you know, the other N-word, nuclear. And he talks about like, you know, World War Three,
*  the chance of World War Three being at its highest in our lifetimes. He said that AI is,
*  called it super-duper intelligence, is, quote, alarming and scary. Meanwhile, you know, you hear
*  Biden saying that our biggest existential risk is climate change and Harris saying that the
*  existential risk from AI is that it denies you healthcare because healthcare is existential.
*  And I think there's just a different level of like attention to these sort of potential black swans
*  through the different lenses. And that's also partly downstream, again, of these different
*  party structures where you have something that's more ideas-driven. And I think you can only really
*  tackle like AGI risks through a more ideological lens precisely because they're still theoretical.
*  Whereas something that comes through a stakeholder lens is going to be, say, you know,
*  connecting AI risks and these other risks to particular constituencies.
*  Hey, we'll continue our interview in a moment after a word from our sponsors.
*  The Cognitive Revolution is brought to you by Shopify. I've known Shopify as the world's
*  leading e-commerce platform for years, but it was only recently when I started a project with my
*  friends at Quikly that I realized just how dominant Shopify really is. Quikly is an urgency
*  marketing platform that's been running innovative time-limited marketing activations for major
*  brands for years. Now we're working together to build an AI layer, which will use generative AI
*  to scale their service to long-tail e-commerce businesses. And since Shopify has the largest
*  market share, the most robust APIs, and the most thriving application ecosystem, we are building
*  exclusively for the Shopify platform. So if you're building an e-commerce business, upgrade to
*  Shopify and you'll enjoy not only their market-leading checkout system, but also an
*  increasingly robust library of cutting-edge AI apps like Quikly, many of which will be exclusive
*  to Shopify on launch. Cognitive Revolution listeners can sign up for a $1 per month trial
*  period at Shopify.com slash Cognitive, where Cognitive is all lowercase. Nobody does selling
*  better than Shopify, so visit Shopify.com slash Cognitive to upgrade your selling today. That's
*  Shopify.com slash Cognitive. As a Cognitive Revolution listener, you're obviously interested
*  in cutting-edge AI technology. And with that in mind, I'm proud to say that this episode is
*  brought to you in part by Notion. Notion has been a clear leader in high-value applications of
*  generative AI since the wave began. Earlier this year, we had Notion AI engineer Linus Lee on the
*  podcast. The quality of his insights showcased the caliber of talent that Notion employs. And
*  that inside look at how Notion builds with AI is still extremely valuable. Now, I'm going to
*  talk about the
*  first two episodes of Notion AI. They're extremely valuable. Given my personal focus on AI
*  automation recently, I specifically wanted to highlight Notion's library of workflow and
*  automation templates. If you're looking to streamline your processes and lay the foundation for
*  future AI-driven automation, these templates are an excellent starting point. And even if you're not
*  ready for full automation, you'll benefit immediately from Notion AI, Notion's latest all-in-one AI
*  platform like Slack or Google Docs to deeply understand the context of your work and generate
*  highly relevant analysis and content just for you. Notion is used by more than half of Fortune 500
*  companies, helping teams reduce emails, meetings, and time spent searching for information.
*  Want to try it? Head to Notion.com slash Cognitive Revolution. You can start for free and using our
*  link supports the show. So join me in giving Notion AI a shot today at Notion.com slash Cognitive
*  Revolution.
*  Yeah, I mean, I don't want to be the person who's going to defend the stakeholder-based
*  approach to AI. It is pretty easy to imagine the scenario where lots of good things that I want to
*  see come online are blocked by interest groups. And you can look at all the cost disease segments
*  of the society and imagine what AI can do for those segments. And then you could imagine how
*  the people who might stand to lose out in relative income and status and whatever would want to block
*  those things. As an aside, I've been pretty pleased with how the medical establishment has responded
*  to AI so far. I would have expected a much harsher anti-AI stance from doctors in general
*  at this point than we've seen. There's been perhaps just because they're also overworked
*  and exhausted and just fed up with all the paperwork that they have to do. Like anything
*  that could reduce the paperwork burden is maybe welcome. But one can still imagine that that could
*  change. And certainly, I don't have a high level of confidence in what teachers' unions are going
*  to do when it comes to implementing AI in classrooms. And I definitely would like to see
*  my kid have the benefit of the best AI that we can bring to bear on his education. My only one
*  is so far in school. So sure, I'm with you. That could suck. At the same time, I also
*  really don't like the sound of an ideological approach to AI. I feel like one of the biggest
*  things I've learned or I feel like I've learned in the last couple years of obsessive study of it
*  is that these things have to be understood on their own terms. That we can't really bring
*  preloaded frameworks or we can't really reason by analogy all that much. We really have to
*  get down to ground truth on what is this thing? How does it work? Ideally, as much as possible
*  mechanistically, that's why I'm so excited about the actual study of what is going on in these
*  systems and why are they doing what they're doing? And can we engineer ways to control them?
*  If we're really going to get to any sort of sustainable safety, it's presumably going to be
*  with engineering solutions. But in the meantime, I really don't like the idea that we would have a
*  sort of ideological approach. And most of the people that I think are kind of
*  the smartest or that have the most insightful things to say about AI are, first of all,
*  very quick to admit that they're high level of uncertainty on where we're going in the biggest
*  picture. Even Anthropic has their sort of core views on AI safety blog posts, which is kind of
*  like their canonical statement on the matter. And even in that, they're just like, we really have
*  no idea. We don't know how hard this problem is going to be. It could be relatively easy. It could
*  be near impossible. We're going to just try to do our best and update this view as we go.
*  I think that's basically the right view to take right now. It's also interesting to note that a
*  lot of these people are techno-optimists and libertarians in every other way than AI. They're
*  all kind of eager to see more drugs come out. I mean, I think among people that are AI safety
*  hawks, you would find many FDA reformers, for example. And so I think these people who have
*  broken their normal, and I count myself among them, I'm probably a libertarian minded person.
*  But I think these people who have been willing to recognize that, like, yikes, this is not something
*  that we have precedent for. It's not something we have good analogies for. It is something we need
*  to understand on its own terms. Those are the people whose analysis I find most compelling.
*  What ideology are we even talking about in the Republican Party? It does seem like there are
*  several, right? There is this sort of Chicago school market maximalist. There's also a Christian
*  thing. There's, I don't know, there's like neo-reactionary elements. I'm not sure whose
*  ideology it would be, but none of those three seem like they're giving us an actual grounded
*  in the substance of technology understanding, which feels to me critical to
*  making good decisions as the situation evolves. So yeah, I don't know. Which ideology are we
*  talking about and why should we trust that? Yeah. I mean, the first point of clarification is just
*  I don't mean ideology in a pejorative sense. I just mean driven by ideas. In this case,
*  broadly the conservative movement and it does contain many factions.
*  Ideologically, it's like, let's follow the constitution. Let's be concerned about
*  surveillance and censorship. Let's preserve basic civil liberties. Let's try to simplify government
*  and roll back programs that we think were part of a progressive social engineering project or
*  whatever. And so there's no interest group behind that per se, right? Sometimes they will be
*  tied to an interest group. But I guess a good way to illustrate this is during the first insight
*  forum that the Senate held on AI, Republicans and Democrats both get to invite people.
*  The Republicans invited Elon Musk and Mark Zuckerberg, but the Democrats invited
*  Randy Weingarten, who's the head of the Federation of Teachers. And they also have had hearings with
*  Emily Bender and Timnit Jebrew. And so there's other... The people who are informing the left
*  on AI policy are also ideological in a certain sense, maybe a more pejorative sense in this case.
*  I think to the National AI Advisory Committee, which advises the White House,
*  the Democratic appointees on that include a woman named Janet Haven, who runs this
*  program called the Digital Society Initiative that includes a land acknowledgement for their
*  servers, a digital land acknowledgement. I was at a conference with her where she said that AI is
*  just web three all over again, and we really need to be concerned about the race and equity and
*  discrimination implications of AI. I think that's the lens that, more ideological lens,
*  that the prism that AI policy will be passed through in the Harris administration. You already
*  see that as well with some of the policies that the Biden administration already adopted, right?
*  Biden made Harris his AISAR. She was the representative at the AIS Summit in the UK.
*  Part of what came out of that was this AI Bill of Rights. And then that was somewhat formalized with
*  the White House executive order, which included a directive to OMB, the Office of Management and
*  Budget, which is sort of the brains of the executive branch. And now OMB has this
*  directive that says any application of AI in government has to pass through this minimum
*  practice of standards. And they include external consultations, an audit of risks,
*  ongoing quality management. And this applied retroactively to all kinds of existing uses of AI.
*  So there's worries now that the post office, because the US post office uses an AI,
*  simple AI tool for routing mail, that this has to then retroactively go through this process and
*  verify that it's not going to be rights impacting. And so in one sense, that is a kind of
*  safety. I do worry that it's a form of safety that comes with the cost of dramatically reducing
*  US state capacity and ability to adapt to new technology. Because on the ideological side for
*  the right, there's been a long project to try to, quote unquote, deconstruct the administrative state
*  and challenge administrative law. And part of that is trying to figure out how do we actually make
*  government more efficient and do the things that it needs to do without having a Trump person,
*  what's called agents of the deep state interfere. And so that kind of energy can actually be
*  applied towards more rapid diffusion of AI within government to the extent that we could
*  either augment existing civil servants or substitute civil servants with AI. And in many cases,
*  a lot of what government does is a kind of fleshy API passing PDS back and forth and check boxes.
*  That's a longer term project. I think one of the ways you have to motivate and how do you
*  actually get that project done is by building some kind of counter-establishment. And this is
*  where someone like JD Vance may come in. I think back to the first Trump term, I was sitting in a
*  Starbucks and this was during the transition and Trump, of course, didn't expect to win. So they
*  barely had a transition team in place. And then the news came out that-
*  That's the kind of preparedness we need for AI.
*  Well, this time is different. This time is different. But news came down the wire that
*  none other than Balaji Srinivasan was on the short list for FDA commissioner.
*  Right. And I remember at the time I tweeted a link to his startup exit talk, Silicon Valley's
*  ultimate exit. And I said, this is a surprising pick. Watch this infamous talk. And then my phone
*  rang and it's Balaji. And he said, infamous. I think he means famous. And I had never spoken
*  to Balaji before at that point. I don't know how he got my number, but I was intrigued and started
*  talking to him about like, in his background, he's now known as a Bitcoin maxi, but his
*  background is computational genomics. He taught the first computational genomics course at Stanford
*  and developed a DNA counseling company with his brother. But I talked to him and he was like,
*  what I want to do is right now FDA has a pre-market approval regime where new drugs have to go through
*  clinical trials, phase one, two, three, and then pass through and then finally enter the market.
*  But this is anathema for personalized medicine. And if you just extrapolate falling costs of
*  genomics and the potential for AI to revolutionize medicine in this way, what we need is a post-market
*  surveillance regime. And there's a way I'm going to do this. And we're going to use the post-market
*  adverse reaction system. So anytime there's a new drug on the market that has this one in a million
*  interaction, doctors are supposed to report this to the FDA. We'll use that and a variety of other
*  big data techniques and sort of Bayesian machine learning to have like a real-time update on the
*  efficacy of a drug and how it correlates with the eosincratic factors, including your genetic
*  profile. And I don't know whether or not he would have been able to enact that. We will never know.
*  But the fact that he was even under consideration was only because Blake Masters and Peter Thiel
*  were running the transition. Now I use that as an example of the kind of thinking that we're going
*  to need if we're going to actually adapt and co-evaluate with AI on an institutional level.
*  We need the kind of community notes version of everything, right? Or we move from a system where
*  you have a bunch of people, flesh-blooded people with their own ideological proclivities doing
*  policy, deleting tweets, whatever the case may be, and transition that to something that is
*  actually scalable. And that won't come through a stakeholder process, I'm afraid to say. I think
*  it's only going to come through something that is a little more ideologically driven,
*  provided that faction has the resources to call upon. Because right now, the problem with the
*  Republican Party more generally is this education polarization means that they lack the kind of
*  technocratic elites that you need to actually run agencies. But the tech world can potentially
*  fill that void. Hey, we'll continue our interview in a moment after our word from our sponsors.
*  The cognitive revolution is brought to you by Element, a zero sugar electrolyte drink mix that's
*  working to change how we think about the role of salt in hydration and performance. I have to say,
*  when I started an AI podcast, I never thought we'd be sponsored by a drink company. But when
*  Element inquired about a possible sponsorship, they also offered to send me a sample pack.
*  And so I figured, might as well try it out. When the sample arrived, my wife Amy could not believe
*  what a perfect fit it was for me specifically. For years, I have felt that my body needs more
*  salt than nutrition labels indicate. And so I was interested to learn that the Element formula is
*  based on a growing body of research, suggesting that most people perform best with two to three
*  times more sodium than official guidelines recommend. I was also fascinated to see that they
*  specifically recommend it for people who fast regularly, since I personally don't eat until
*  dinner time most days. Obviously, I'm not a doctor and what my body responds well to may or may not
*  work well for you. But after drinking Element for a couple of weeks, I can sincerely say that I
*  really do enjoy the product. My favorite flavors so far are the mango chili and grapefruit. And I,
*  for one, also enjoy the raw, unflavored version, which reminds me of the taste of the ocean.
*  If you're curious about optimizing your electrolyte intake, you can support the show and get a free
*  sample pack with any purchase by visiting drink element.com slash TCR. That's drink lmnt.com
*  slash TCR. Yeah, I mean, boy, you can paint a picture that sounds pretty attractive. But
*  I kind of still come back to that doesn't seem to bear any resemblance to the actual Republicans
*  that we have in today's world, right? I mean, this is sort of a, I think people are like really
*  investing a lot of hope in the, you know, this sort of bromance between Trump and Silicon Valley
*  and thinking that we're going to get like a very high competence government out of it that notably
*  didn't really happen the first time around. I mean, with maybe a couple of, and I'm not somebody
*  who can't recognize that there were some good things to come out of the Trump administration
*  and happy to give credit for Operation Warp Speed. That's, you know, we needed that bad. And, you
*  know, it's certainly very good that it happened. I don't know what the counterfactual would have
*  been if that was a Hillary project. Like, I think she was also pretty competent, you know, and very
*  likely could have figured out a way to do an operation Warp Speed, but who knows? We'll never
*  know. But I just, I don't, you know, I guess, first of all, still on just ideology for a second, like
*  the, what is the opposite of ideology? It might be one way to describe it would be like being
*  responsive to new evidence and being willing to update your beliefs on new evidence where I know
*  you're not saying like the, you know, pejorative form of ideology too much.
*  Structure in the pejorative sense.
*  But this is, I mean, this is where the rubber hits the road though, right?
*  The Republicans that we have are not those people.
*  And I wouldn't say we're public.
*  We're not been SAS.
*  Yeah. I mean, you just look at Congress, you know, I mean, if you don't like,
*  I guess I would, I think there's a, there's a version of the Republican party that doesn't
*  currently dominate the actual Republican party that I think we could have like this discussion
*  about, but this discussion feels like it is sort of forgetting the fact that we have like,
*  by all accounts, a like, valueless sort of purely self-interested maniac at the top of the party
*  and a Congress that is full of people who are, you know, some mix of like religious zealots on the
*  one hand and, you know, sort of Craven opportunists on the other hand, with like a small,
*  you know, section that is like still sort of the old guard that's like kind of institutionalist
*  or, you know, is interested in a future of, you know, state capacity or whatever.
*  But like the actual Republicans in power, I don't see any signs that they're interested
*  in state capacity. I see like they want to drain the swamp. They want to burn it down.
*  They, you know, I have no idea how to anticipate what they'll do with respect to AI, but it just,
*  I can't reconcile the people that are actually there that are like actually casting the votes,
*  you know, that would actually have the sort of top level control of the administrative apparatus of
*  the country with the characterization of like, you know, Chicago school or biology. I mean,
*  these are like very different people. Like biology wants to burn it all down too. If given power,
*  I think you would do a much better job than a lot of other people, but they're not like,
*  this project seems like quite fanciful, honestly. I mean, it seems like
*  it would be great maybe, but I just don't think that the people, you know, as Americans like go
*  to the polls in a couple of months, I don't think that the vision that you're giving them
*  right now is actually on the ballot. I think what is on the ballot in almost every congressional
*  district is like the person that Trump endorsed, who was the one that was like the most religious,
*  right? The most like focused on abortion. I mean, that's what wins Republican primaries.
*  Like these people are, they don't care about AI. They don't care about anything, right? They're
*  outright, and they are ideological in the pejorative sense. They are not like ideas motivated.
*  If you visited every member of Congress, I would be very confident that you would have much more
*  ideas-driven conversations with the Democrats than you would with the Republicans. The Republicans
*  that you're going to meet actually in Congress are like ideologues. You know, they are like,
*  most of them are. A few of them I think are a little bit more sophisticated, but most of them
*  are really not. That's not to say all the Democrats are great. Certainly we can, you know,
*  there's this sort of excess of wokeness over the last few years is like well documented,
*  but I still think at the end of the day, and the real, I think the real EA case,
*  the real EA outlook I think is anti-Trump. I think the real case for that is just like,
*  we want people who are going to think carefully. We don't want people who are like motivated by
*  scripture. That's like a lot of what the Republicans are. Scripture is just not going to
*  be a good guide to a lot of these modern challenges, AI or otherwise. I wish we had,
*  I feel this dissonance where I'm like, as I listen to your talk, I'm like, no,
*  that sounds pretty good. We could get like FDA reform, we can get all these things going on.
*  Chicago school, this and that and great. You're speaking to the 10 years ago me who was like,
*  you know, man, this Romney guy makes a lot of good points, right? But now we like that dude has been
*  totally, he's like the last guy, you know, one of the last few standing that,
*  and he has basically no power, right? Yeah. So I think this is a bit of a caricature maybe through
*  the media lens, media filter, because, you know, I work with congressional offices on a daily basis,
*  both sides of the aisle. And I think you'd be shocked by the amount of ideas driven
*  hard discussion that takes place in Republican offices and how
*  disappointed you actually be on the other side of the aisle. You know, I've been in reading groups
*  with Republican members where we read like Joan Robinson's, you know, heterodox work on like
*  monopsony power. And then we like, you know, someone like Marco Rubio, like I worked with Rubio
*  and his staff on this small business administration reauthorization where they wanted to like return
*  into a development bank, like to do, you know, hard manufacturing projects and stuff like that.
*  Whereas what the SBA typically does is like give loans to gas stations and nail salons.
*  So that's another example of like what I mean by they have a vision in mind and want to reform the
*  agency, any given agency. And certainly I would agree that like on the surface level, Republicans
*  seem much more chaotic. They seem much more religious. I know I would make the kind of argument
*  that Democrats are also in their own way, deeply theologically motivated. Maybe it's more of a
*  progressive version of theology, but it's also one that is much more institutionalized rather than,
*  you know, I think actually with the Republican National Convention, Trump made a
*  gesture of like actually pushing the social cons out of the coalition to some extent. So,
*  you know, I think really what we're voting for, I'm not voting, I'm Canadian. So this is-
*  You're telling me he's not still playing to his beautiful Christians? I don't know if I quite
*  believe that. Yeah. He said the Bible is his favorite book after the Are the Deal.
*  And, you know, he couldn't quote a verse. You know, I think in some ways Trump may just be a
*  apotheist, right? He's not really- and I think he's actually kind of weirded out by them, right?
*  Because what Trump actually is, is a kind of populist New York City Democrat who has sort of
*  paleo-con views on immigration and trade, who's somehow found himself leading the Republican
*  coalition supported by his cult of personality. And, you know, in some ways that's better than
*  the alternative. You know, if not for that cult of personality, then you might actually have to
*  pander even more to those various interest groups. But even on this point, like, you know,
*  there's good eschatological reasons for the evangelical movement to be actually terrified
*  of AI. You've seen, you know, Steve Bannon has done episodes on what he's called the
*  cyborg theocracy and the singularity. You know, Tucker Carlson has actually called for
*  bombing the data centers. Stumbling it in the crib.
*  But more fundamentally, when it comes down to like, if we enter a crisis, and I do think,
*  even though this is not on the ballot, I fully agree. You know, I think we're sort of talking
*  at a more, you know, esoteric level of like, what's actually going on versus what is projected to the
*  masses who may be just be voting on inflation or table, kitchen tabletop issues. You know,
*  I think to this recent Dwarcash podcast with Patrick McKenzie, where Patrick was explaining,
*  you know, he, that he kind of ran vaccine logistics out of a Discord server during the
*  pandemic, because there was no one that was in charge, right? There was no adult in the
*  room to say, you're the person running logistics. And so it ended up falling to this sort of poly
*  math. And, you know, in that conversation, he said, you know, what should have happened was like,
*  when the pandemic started going on, like, they should have said, you know, found the smartest
*  person and said, you are now a Colonel of the US Army. You have all the authorities of a Colonel.
*  Go figure out vaccine logistics. And don't worry about racial quotas. Don't worry about like,
*  all this other junk. Like, let's just get shots in arms. And like, let's not throw them into the
*  waste because that's super stupid. And, you know, if this really, if there's a reason to believe that,
*  like, the next major technological inflection point in human history could possibly happen within the
*  next five years, that means the next president could be presiding over an intelligence explosion
*  or an AI takeoff or some, whatever, transformative AI, whatever you want to define it as. And that
*  could be a moment of crisis where you need to call somebody the smartest person in the room and
*  make them a Colonel to do whatever. And the question is, is that going to be Elon Musk? Or
*  is it going to be designed by committee with, you know, and particularly when you start talking
*  about like what jobs, at least in the near term, are most threatened by AI? You know, you listed
*  some of the classes use sectors. You know, I don't think it's going to be that like public schools
*  adopt AI into the classroom. I think it's much more likely that they drag their feet and AI tutors
*  and run the system. And then we end up having like a totally new kind of education system where
*  people can just in-source the same way that we saw during the pandemic, like the shift to remote
*  schooling led to this 2 million student increase in homeschooling. You know, there's going to be
*  huge resistance from, you know, what you could call the professional managerial class to any kind
*  of AI diffusion. And that's going to translate into a kind of decelerationism targeting use
*  rather than actual safety. Whereas if we actually are in a crisis and emergency situation,
*  I would much rather, you know, have actual experts in the room, including someone like
*  Elon Musk who is incredibly polarizing, probably because, you know, he's a little bit on the
*  spectrum and says things that you probably shouldn't and is not politic in that sense.
*  But I think would, you know, has demonstrated an operational and executive ability to handle
*  very complex engineering problems. Yeah. I mean, I guess, again, there's a
*  hopefulness to the description here that I have a real hard time really signing on to. I would agree
*  that, you know, I'm a big Elon Musk fan. I'm not of everything he's ever done. Certainly,
*  you know, it feels like you have to sort of almost ritualistically say,
*  you shouldn't spend so much time on Twitter. And, you know, I would definitely advise him to
*  get offline a little bit more often if I was an advisor. But yeah, I mean, he's clearly
*  able to make things happen in the world. Not entirely clear that's what we'll need,
*  you know, in a moment of crisis, maybe. But I'm not sure it's like a technical solution that is
*  ultimately what we will need. It very much depends on the crisis, right? Like, and when I think back
*  to the pandemic, I don't, you know, I recall these news conferences where we're getting like,
*  extemporaneous, you know, oh, maybe we could inject bleach and whatever. And, you know, it's like,
*  okay, sure, that was a low light. But it is a reflection of the fact that the dude at the top
*  was not disciplined, was not, you know, ideas driven, was not, like, in command of the facts,
*  and just kind of went around, like, making a mess for his people to clean up and kind of further
*  polarizing the issue. And I don't think it's hard to imagine at all a different president doing a
*  better job on the pandemic than Trump did. You would have to imagine, I would think, that it
*  would have become less polarized. Some of the fault of that definitely resides with Democrats. I do
*  think that, you know, we did not need a statement from Kamala Harris that she, you know, maybe
*  didn't trust the rushed Trump vaccine. That wasn't healthy. You know, unfortunately, like,
*  nothing is healthy around Trump, though. That seems to be the problem, right? It's like,
*  I do think when somebody makes everybody around them worse, both the people on their team, who
*  they're constantly, you know, throwing off of what they're trying to do and creating problems for
*  them to clean up and distracting them, and the opposition, you know, that they're just, like,
*  driving insane, like, that's not a good person, right? Like, that's not the person that we want
*  to be in charge. Oh, I totally, you know, I'm not trying to, you know, defend his character by any
*  means. Again, going back to, like, utilitarian analysis, you know, someone like Norman Borlaug,
*  who, you know, kicked off the Green Revolution, right, with his research into wheat varieties.
*  You know, he plausibly saved hundreds of millions, maybe even a billion lives
*  incrementally through that research. He could have spent the rest of his life
*  being a raving anti-Semite and playing the knockout game and punching babies, you know.
*  A utilitarian should still be happy that we lived in a timeline where he existed,
*  right? And likewise, like... But Trump hasn't given us anything like that. We don't, I mean,
*  where's my Green Revolution from Trump? Sure, I guess, maybe, but, like,
*  you know, if he were all those things and he had done the Green Revolution, I still wouldn't want
*  him to be president. And Trump doesn't have a Green Revolution to his credit. I just don't...
*  It feels like we're really being asked here to imagine a scenario that we don't really have
*  evidence for, that this next... You know, it didn't happen last time, but this time is different,
*  right? I mean, I think you said that earlier. This time is different. This time we're going to get,
*  like, competent executives to run all these things. Like, I just don't see that that's
*  likely to happen at all. If I did believe that was going to happen, I would, you know, have a
*  very different outlook on this. I think the competence of the first administration is
*  underrated as it is. It just was a rocky transition because they didn't expect to win
*  and had to, you know, especially in the White House, have to staff up with a bunch of people who
*  were... Had very conflicted views of what to do and, like, the leaks were constant.
*  Now, I think that's one big thing that will change. There'll be much tighter ship.
*  But I know the people... I mean, I'm not sure who you are referring to when you refer to the
*  competence of the first administration, but there's, like, a long list of...
*  Headed HHS or, you know, his Trump NSC. I thought that, you know, there are people in very important
*  decision-making roles who were very competent and partly were able to express that competence
*  because they came from a more right center orientation. And again, like, going back to,
*  to, like, you know, one of the things I think we need to do is try to make our beliefs consistent
*  with each other, right? Like, you know, this is a big topic all the time when we talk about,
*  like, AGI timelines, you know. Are you long the market or short the market? Or how is it...
*  Are you joining a nine-year fellowship program? Do you think AGI is three years away? You know,
*  there's all kinds of ways where our beliefs and actions may be internally inconsistent.
*  But if you do believe that there is an inflection point, technological inflection point, within
*  potentially the next administration, then all these things become open, right? Open questions.
*  You know, I meant, you know, it's not just a matter of, like, oh, we could prospectively make the FTA
*  more efficient. It's that, no, we're going to have, like, a Google Gnome project, but for drug
*  discovery, that is going to take us from 50 new drugs a year to 500,000 new drugs a year. And we
*  do not have the state capacity. And state capacity in this context does not mean
*  civil service protections. It might even mean the opposite. It may mean actually firing 70%
*  of the people so you can bring in the 20% more who are the hyperscalers, right? And I think of
*  this in terms of history, because if you look at other major technological transitions, they have
*  had major second order effects on our institutions, right? And the last major one we went through was
*  the Industrial Revolution. And in some ways, we're still going through it. But the Industrial
*  Revolution took us from, you know, the world of 1900 to 1950 on the level of governance is, like,
*  night and day, right? And how did that transition take place, right? What we had was first in the
*  early progressive era, the rise of the first large corporations, right? Railway networks,
*  the Carnegie's and Rockefellers, those types of industrialists. And they developed new science
*  and management. This was the first time where you could have big multinational companies,
*  and you had to understand supervisors and direct reports and all these basic things that we take
*  for granted today. And that learning was then brought into government, directly and indirectly
*  through osmosis and to how to build an administrative state. And we're going to go
*  through another transition because AI directly implicates the machinery of government, right?
*  And, you know, what we need is like, you know, and I use this more of a metaphor, but like,
*  how do we get the Patrick Colson Secretary of Commerce, right? How do we get the Palmer
*  Lucky Secretary of Defense, right? And that is much harder to see coming through the Democratic
*  side of the aisle, partly because they are their horizons of possibility are much more constrained
*  because in a weird way, they've become the Burkian Party. Yeah, I mean, a lot of that holds water,
*  I think. But then, like, look at what all of the previous cabinet members are currently,
*  even the vice president, you know, I mean, the number of people that were in the White
*  House that served at the most senior levels under Trump in the first administration are now saying
*  in very clear terms, this dude should never be back in a position of power, right? He did this,
*  he did that, all these things, right? I mean, there's a laundry list of cabinet members that,
*  I mean, basically, to a degree that I would say is unprecedented in American history,
*  I don't know that there's ever been a president, even Nixon, I think, like, mostly had people that
*  were loyal to him, you know, and still thought highly of him despite his mistakes, or crimes,
*  if you want to, you know, be more blunt about it. But not a lot of not a lot of returning starters,
*  right? From the first administration, like most of those people have fallen out of favor, they've
*  mostly hit their limit of what they were willing to put up with from Trump, and finally spoke out
*  about it, and now they won't be back. And so now we're going to have like this whole other regime,
*  and we can hope he, you know, I mean, if he does get elected, you know, I certainly hope he picks
*  wisely. And I certainly hope we get executive competence that can, you know, create great stuff
*  for us. We will at least get much less inner inner, you know, internal conflict, right? Because
*  one of the ways that that lack of transition manifested was they had to pull in a bunch of
*  like new conservatives and, you know, old Bush operatives and people who naturally reviled Trump,
*  you know, throughout and had to basically, you know, falsify their preferences until they could
*  achieve what they wanted to achieve. And then you have like Miles Taylor and like,
*  JD Vance is doing now. I mean, isn't it? I think I think really doing that very sincere.
*  You think he likes Trump now? I don't think he I mean, he's genuinely, I don't know,
*  like a little bit, maybe somewhat on some dimensions, but you think he like thinks Trump
*  is a good leader for the free world after he said, you know, very clearly that he was like,
*  not to be trusted. Well, I think that was a, you know, a reasonable, like, I think you actually tell
*  a story where we're coming through the Trump administration, seeing how things played out that
*  there is a case for that Trump is the only person that can do certain things, right? He is the only
*  person that can go before, you know, German German members of the European Parliament and tell them
*  they need to increase their defense budget or their own pullout of NATO, right? I don't think
*  he was ever actually going to pull out NATO, but I think you need to have that credible threat.
*  And certainly, no, certainly Trump was uniquely capable of that, right?
*  But in this new and another administration, he's not going to have this. It's sort of like
*  if Elizabeth Warren became president and had to hire a bunch of Obama Democrats,
*  because she didn't have a transition prepared, you'd have a lot of people exiting saying that
*  she's going overboard on things. It won't be the same that time. Go ahead.
*  One quick analogy might be, you know, Elon and Twitter, like a lot of Elan's, you know,
*  former execs aren't going to say great things about Elon, he kind of had to clean house. I know Trump
*  had more selection over those executives than Elon did, but he was fundamentally misaligned with
*  the party, right? With Tillerson, with Mattis, with McMaster, with Kelly. He was a new regime.
*  And he had, you know, the fact that he, you know, is that they're not a fan of him in some circles
*  is actually a plus that Trump didn't sort of bow down to people who were fundamentally misaligned
*  with him. And you see, you know, very serious people like Bill Barr who are supporting Trump,
*  who are aligned with him. So he is bringing a new regime into the party. And that regime wasn't
*  stocked up, you know, in 2016, wasn't ready. Michael Lin in his book, The New Class War,
*  talks about this as the first Trump administration was a counterculture, right? To be a Trump
*  supporter, you were a counterculture. And what you really need is a counter-establishment,
*  because a counterculture doesn't actually affect change, whereas a counter-establishment can. And
*  a counter-establishment needs to be reasonably, you know, institutionally complete to actually
*  move the ship of state because there's like, it's a 2.2 million person organization. There are
*  tons of different agencies, tons of moving parts, needs expertise in administrative law,
*  and all kinds of stuff. And so you can't just do that based on cultural personality alone.
*  And we have the green shoots of a new counter-establishment forming. And if Trump
*  wins again, they will be able to solidify their position. And it won't be like, you know,
*  sunshine and roses overnight. It's not like we're going to rebuild the FDA or whatever overnight.
*  But it does establish a new hierarchy within the right. And I think that it's like, would be
*  incredibly solitary. In part because like, when you look at who are the biggest attractors from
*  the first Trump administration, it is like the Mike Pompeos and so forth that were like, you know,
*  I didn't get a long enough leash on my kill list and like, I wanted to invade Iran, but you know,
*  all we had to do was a silly bomb. And, you know, and they're mad at Trump, I think,
*  for some of the right reasons. Right? Especially when you start talking about like, avoiding World
*  War III, like who else could like, broker a diplomatic channel with Xi Jinping, right?
*  You know, someone who is like aggressively hawkish on China rhetorically, but at the same time has
*  a more transactional stance and wants to strike a deal. But where's the deal, right? I mean, this is
*  where we keep coming back to like these stories. I notice in the piece that you wrote, there was a
*  link to a 2016 article from the Federalist, February 2016. And the link text is only Trump
*  can fix America's broken immigration system. But in reality, he was president for four years,
*  he didn't fix it. Then he was not president. And there was allegedly, I mean, I guess we can't know
*  for sure that it was going to pass. But by all accounts that I understand, there was a bipartisan
*  deal to make some meaningful reform just in the last however many months. And what did he do?
*  Comes in from left field and tries to destroy the deal, ultimately successfully destroying the deal,
*  because he wants the issue to remain live for his own electoral grievance campaign.
*  So maybe he's the only one that can fix but that article was by me.
*  So you would not say he scuttled the bipartisan immigration deal? I mean, that's seemingly been
*  reported a lot of places. So the argument is that you need to take a, we may need, if we want to
*  liberalize immigration in the long run and get to a more sensible system, not one that is based on
*  dozens of different visa categories that each has their own bespoke interest group and that are
*  easily abused, even like H1Bs, as much as you may favor high school immigration, as a Canadian
*  working in America, the visa system is incredibly exploitative and cluj, just clujocracy. How do you
*  transcend that? The Trump people wanted to do a points-based immigration system and there was a
*  proposal from Tom Cotton called the RAISE Act. But in the first term, Paul Ryan and what's his name?
*  Just having a brain fart. The Senate Majority Leader, Mitch McConnell, both met with Trump
*  in the Oval Office and said, look, I know you want to do immigration. We promise we'll do that in the
*  next Congress. This time around, we're going to do a big tax cut. And he got rolled. He had the majority
*  used to do immigration reform in his first term, but he got rolled and he's not going to get rolled
*  again. I think moving to a points-based immigration system would be beneficial in the long run, even
*  if it came at the cost of short run reductions in total numbers, simply because it would massively
*  clean up the system as it currently exists and lead to some semblance of order and control.
*  And points-based, just to make sure I understand this policy, is like you get points for having
*  advanced degrees and for just having various positive traits that we want.
*  Right. Like a more Canadian-based system. And again, as a Canadian, I kind of like that system. I think
*  it actually allows you to have higher rates of immigration in the long run because it gives a
*  sense of democratic ownership over the policy rather than something that's... You look at what drives
*  xenophobia and anti-immigrant sentiment. It's not necessarily rates of immigration. It's whether
*  those immigration rates come through democratic consent or a product of chaos and lack of control.
*  And going to the point about this border deal, you don't want to put too much stock into this. It
*  wasn't going to solve the problem. The main thing it was going to do was increase the number of
*  judges for these amnesty court or for these asylum courts so they could process more of these claims.
*  The Republican argument was that this is another plunge, another patch to the system that is going
*  to only further delay the more structural reform that we need because it's going to take a release
*  valve on the pressure for deeper reform. This is actually a recurring pattern in a lot of how
*  Republican votes get interpreted by the mainstream media where they say, oh, you're for the child
*  tax credit, then why did you vote against it? And this thing was like, actually, there's more of a
*  game through behind this. And I'm not just like wish casting or projecting. This is what they will
*  tell you. We want to get more deep structural reform done, and that will only be possible
*  if we have the motivation and the will to do that. And if we do little patchworks here and there that
*  sort of give the semblance of fixing the problem, then that kills the political capital to get
*  deeper change. And time and time again, from my personal experience working on the Hill,
*  Republicans are the ones proposing actual deep structural reforms to things. Even something like
*  healthcare, where Obama, the biggest healthcare expansion you could do without upsetting anybody.
*  How do we do this big policy without actually doing anything structural? And that, again,
*  is part of the problem is all these policies get filtered through existing coalitions of
*  interest groups that want a particular outcome without rocking the boat. And we're going to need
*  to rock the boat. Yeah, I mean, I think that time is coming. I don't disagree with that.
*  My second son is named Teddy in part after Teddy Roosevelt. And I think a lot of this comes down
*  to for me, like, is he do we have the right person? And, you know, Teddy Roosevelt did some amazing
*  things that people thought, you know, somebody from his class or his party could never do because
*  he was willing to cross those lines or, you know, be a I wouldn't say he was a traitor to his class,
*  but whatever, you know, to be dramatic about it, you could describe him that way. Certainly, you
*  know, he was willing to speak truth to his own constituencies when needed. I just don't, you know,
*  I don't see Trump as that guy. And I don't see the Republican Congress as like largely full of those
*  guys. And that's not to deny that you're having some substantive discussions behind closed doors.
*  But, I mean, at some point, you know, if they're so substantive, like, why are they keeping it such
*  a secret? You know, is it because they just have a very hard time believing that, like, there's all
*  that many of these Republicans who project as like, abortion focused, religious zealots, that are, in
*  fact, like, very thoughtful, you know, state capacity, structural reformers. I don't know
*  there's a few, but I don't really buy that there's all that many. And I just don't think we have this
*  is not the group, you know, that can reform America. They're like, if they are given
*  the levers of real power, well, you know, as we've recently seen, like they didn't do it,
*  you know, they did big tax cut, they didn't do the immigration. You know, this, and give me some
*  relief, too. You know, I mean, if we are in this, it's just also cynical, right? I mean, I, the idea
*  that, okay, we're going to hold our, you know, we're going to hold this issue hostage, and we're
*  going to keep the pain alive, because that's the only way we're going to get, you know, a real win
*  in the future. I don't know. How about incremental progress? You know, how about, how about taking
*  wins when they present themselves? How about relieving pressure from a system that, you know,
*  by the Republicans own account is like about to blow. If this is like, you know, if we're being
*  invaded, if we have like, you know, it's recently been reported, I don't know if this is really true
*  that Trump is somewhat confused about asylum, the, you know, immigration concept and asylums, the
*  like, you know, place that holds crazy people. And he certainly has said many times that they're like
*  sending, you know, criminals and crazy people into the country. So who knows what he believes
*  or I mean, it's all very hard to read. But if you bring it back to the AI question,
*  I don't think it's a very healthy outlook on AI to say, Oh, well, yeah, we could like get a win here
*  or do something sensible here, but it's only on the margin. Therefore, like, let's, you know,
*  hold off or, you know, kill that deal, because we want to let this pressure build until we can really
*  do the right thing. That just does not seem like a healthy approach. I mean, Trump was not in command
*  of the exponential of COVID. Yeah, I have the receipts for that. Right. I mean, he was like,
*  tweeting in like February of 2020 that, oh, you know, this is how many people have had it. And
*  only this many people have died and compare that to the flu and whatever. And he just like clearly
*  did not get the fundamental, you know, underlying nature of the process that he was going to be
*  forced to deal with. And if he brings that same sort of, you know, outlook to AI, and it's kind of
*  like, Oh, this thing is, you know, not that big of a deal, or I can sort of kick the can down the
*  road, or I can sort of use this as like a, you know, wedge issue in the next election.
*  I just don't think these are the guys, you know, and they almost all are guys too. And I would,
*  I do think we need to, you know, we would do very well to have some meaningful reform in this
*  country. But are these the guys that are really going to deliver us that reform? I still am just
*  like, I don't see it at all. And I would rather kick the can down the road one more administration,
*  frankly, you know, I don't expect that the Democrats are going to change the system. But
*  Trump seems to be a burn it down guy. I don't see the build it up part, you know, he, I kind of
*  think of him almost as like a tornado where it's like, this extremely destructive force, you know,
*  that sits at the middle of like two, you know, giant opposed masses, and is kind of this vortex
*  of energy. It's largely destructive, right? I mean, some towns that got like wiped out by tornadoes
*  may years later look back and say, well, yeah, actually, we have a nicer Main Street now than
*  we used to because we had to rebuild. But I don't want to go through that process on a national level.
*  And that seems to be, you know, the base case. I'm not I don't know, I'm not sold on the on the
*  creative destruction is the engine of prosperity in the private sector, right? You know,
*  I guess Blockbuster had an opportunity by Netflix, but they passed on right, but ultimately,
*  Netflix was a new company that displaced Blockbuster, you know, Uber and Lyft were
*  new companies that displaced tax commissions. This is how creative destruction tends to work.
*  Creative destruction is can be very dramatic. And you know, it does have costs, right? Like
*  Uber example, you know, there were the taxi drivers in Paris that were throwing rocks
*  off bridges and people committing suicide in New York because their medallion became worthless,
*  and so on and so forth. So creative destruction is dramatic, even in the private sector.
*  The problem is that in the public sector, we don't have a system of profit and loss allows,
*  you know, the NIH to fail and a new better public health science funder to rise in its place. There's
*  no competitive process. And as a result, we get this sort of buildup of entropy over time,
*  where we're kind of living on the capital that was developed in the New Deal era and then the
*  Great Society eras. And that long 20th century is rapidly coming to an end, right? And there's
*  going to be some necessary destruction to even begin the rebuilding process, right? And part of
*  that, it looks like massive deregulation, right? It looks like getting existing agencies, reallocating
*  resources you want to keep and setting a new framework, right? And again, it's much easier
*  to do that if you have some philosophical motivation or some vision that you're trying
*  to enact that sort of detached or sits above pecuniary interests. And I agree, like Trump
*  on the surface certainly doesn't seem like he's like totally in charge of the facts on any given
*  issue. On the other hand, you know, he does have this like remarkable ability to absorb things.
*  And, you know, often he'll echo what he's absorbed in a kind of mangled way, but you kind of get what
*  he's getting at. And, you know, one of the things that's leaked thus far on their potential AI
*  policy is this executive order that's been drafted by the American First Policy Institute
*  that calls for Manhattan projects on AI, that calls for broad-based deregulation and situates
*  this under a framework of we need to make America first in AI, right? And speaking as somebody who
*  took part in one of the Project 2025 policy committees, totally voluntary role, sort of
*  an outside participant offering, you know, submitting some memos on like whether AI policy
*  should be, I was actually quite surprised and I can't really reveal too much, but surprised by
*  how many like AI safety filled people there were on these committees. You know, we had actual
*  memos on like timelines to AGI, what are the risks, how do we respond. You know, there's been some
*  worry that the Trump administration would repeal the Biden executive order and then therefore repeal
*  the compute thresholds for monitoring large models. My sense is that they will retain those
*  provisions and do sort of more of a repeal and replace a day one executive order, keeping some
*  of the monitoring capacity, but adding, you know, getting rid of all the things that are hindering
*  adoption within government and doing these Manhattan projects. And so like, you know,
*  there certainly within the EA world, there's a lot of debate about like whether this is a good thing
*  or a bad thing because you don't want AI to become, you know, a pure, a true arms race.
*  On the other hand, my intuition is that if you're going to take AGI seriously and respond
*  in an appropriate way, you at least need to believe it's a thing that can happen
*  and have some realistic expectations of like the timelines. And I can assure you that the people
*  within the Trump world and within the heritage world and who would be on his NSC and so on down
*  the line are situationally aware, right? In the Ashton Brenner sense, like they see what's coming.
*  They take it very seriously. You know, again, partly this is because a lot of conservatives
*  come from, if they're not libertarian, they at least, you know, we're forced to sit through
*  some libertarian seminars at some point in their career. And, you know, and there's some adjacency
*  between the libertarian world and the rationalist world and the EA world where they think about these
*  things, you know, you know, I came up through all that stuff. I was at Mercatus. We all read
*  Dierdre McCloskey and like study the Industrial Revolution and, you know, Tyler Cowen's great
*  Stake Nation. And we're always trying to think like where, you know, where's our flying car, right?
*  And that to me seems at least prerequisite, right, to getting the policy right, because at least
*  gives you the sense of gravity. Now to the question of whether it's appropriate that we
*  accelerate a kind of militarized approach to AI, I don't think that's what this is. I think,
*  you know, overwhelmingly the talent and capacity to even build a super intelligence, let's say,
*  is still in the private sector and that doesn't seem to be going anywhere. And certainly if the
*  Department of Defense or the Department of Energy had some secret project, we'd probably be able to
*  see it from space, just because of all the energy we need. But what we do want to be wary of is that
*  to the extent that some of these dynamics are already baked in, it's probably inevitable that
*  the intelligence community and security apparatus is going to become situationally aware if they
*  aren't already. And you'd much rather that be done out in the open with some like explicit, you know,
*  conscious intent. And you wouldn't want to base your decision on who to support on something that
*  was probably inevitable anyway. So then the question becomes, who gets there first? Right?
*  And this is the Ashton Brenner thesis as well. It's like, you know, to the extent this is a lot
*  really baked in and the slow takeoffs are already taking off, like, do we want China to get there
*  first? Or do we want the US to get there first? And if getting there first means having a decisive
*  military, technological, economic advantage in perpetuity, I think you'd much rather the US get
*  there first. And moreover, if you're worried about Skynet scenarios, you probably also want the people
*  who are governing that policy to be like militantly anti-censorship and surveillance,
*  right? Which just so happens to describe a lot of people in the Trump world who are like terrified
*  of, you know, big tech censorship and so on and so forth. And I think this is, even before we get to
*  super intelligence, going to be a really important issue just because of all the ambient information
*  we're constantly shedding and the ways in which even existing sort of like financial reporting
*  systems and big data that could be applied, you know, we could have LLMs and multimodal models
*  that are spying on everybody right now, right? NSA could have a dragnet surveillance program that is
*  filtering data using an AI to detect whether it would pass a FISA warrant or not, right? And I
*  would much rather have people in there who could plausibly pardon Edward Snowden than people who
*  don't think it's even an issue. Let me take it from the top. I think the top is
*  if we are racing China to some notion of strategic dominance indefinitely, I think we're all kind of
*  screwed. We are still living under the shadow of the last Cold War and the arms race. And I think
*  the US government still has like 5,000 nuclear weapons that are in some form of like operational
*  readiness. That, first of all, by the way, raises the cost of creative destruction in the government
*  sector a lot higher than in the taxi sector, not to diminish the personal tragedies involved there.
*  But, you know, I don't really think we have the luxury of a, you know, very chaotic
*  creative destruction of the US government without it being like truly catastrophic,
*  just in virtue of the sheer, you know, weapons cash that we have that the president is, you know,
*  according to policy, like, independently, you know, authorized to make a decision on, right?
*  Now, hopefully, there would be somebody in the chain of command or something.
*  Reforming an agency is much different than state collapse, right? I'm not talking about state
*  collapse. That would be catastrophic if like suddenly the US government just had total system
*  failure and the world was like flooded in deep fakes and drones swarmed and we didn't know who,
*  you know, was handling the nukes. That would be really bad. I agree. But I'm talking about
*  something a little more mild, right? And to me, like, as it again, as a Canadian and just looking
*  at other parliamentary systems, it's totally normal in a parliamentary system for like a new
*  government to form. They would really call it forming a new government. And then for like
*  ministries to be shut down, new ministries to be created. You know, my political idol growing up
*  was Jean Chrétien. In the late 90s, he fired a third of the federal civil service in his unilateral
*  budget, right? And so like the US is uniquely ossified in this respect, partly because our
*  system of checks and balances makes it very hard to do more dramatic kinds of change. And my basic
*  thesis is just that this change will be forced upon us. Yeah. So I mean, we could like eliminate
*  the filibuster and, you know, start to have, I think there's all kinds of like incremental
*  steps we could take to unjam our, you know, to get ourselves unstuck. But I guess going back to the
*  top, if we're racing China for strategic, you know, indefinite strategic military dominance,
*  I don't think that's a race either of us can really win. Even if we last a while,
*  you know, there's various estimates, of course, of like, what is the annual risk of catastrophic
*  nuclear war in today's world? But I think most people would have a very hard time saying it's
*  less than like a 10th of a percent. And we're not dealing with it. We're just sort of living with
*  that. And maybe it's even more than that. Maybe it's a half a percent. I mean, these things really
*  start to compound over time. AI feels like even if we can reach some sort of, you know,
*  quasi stable equilibrium, it's very hard to imagine a actually safe outcome that is predicted that we
*  arrive at through a race to strategic dominance. So I sort of feel like the only way that we get
*  to a good place is to challenge that frame. And that's again, where I just don't have I don't have
*  a lot of confidence in Kamala Harris about that either. But I have basically negative confidence
*  in Trump. I mean, it seems like he will play the it's us versus China card to the end of the road.
*  And he's not thinking far enough ahead to, you know, it's not going to be his problem.
*  He'll just be dead, right? But you know, presumably, unless it happens really fast,
*  he'll be he'll age out. And like the rest of us will be here for the you know, however many
*  decades and our kids will be here and we'll be living under at best, a sort of, you know,
*  mutually assured AI destruction regime. And I just really don't want us to create that.
*  I would, you know, if there was anyone who, you know, would say anything contrary to this
*  notion that we have to like race China for AI dominance, like they would be my candidate.
*  But Trump just seems like he's absolutely going to ratchet that up, you know, and he's going to
*  play to those fears. And he's like, you know, what is a Manhattan project? I mean, the history of
*  Manhattan project is not exactly a glorious one, right? I mean, it's a scientific triumph in some
*  sense. But, you know, notably, like a lot of the people involved immediately regretted what they
*  had done when they actually unleashed it on the world. And then they were like, shit, you know,
*  can we get a mulligan on this? And you know, you can't. So what I mean, I don't know what
*  Manhattan projects we really expect. But I mean, it's kind of chilling to me to think that that's
*  the sort of historical precedent we want to look back to to say, you know, back when America was
*  really great, you know, and unleashing mutual assured destruction paradigm on the world. And I
*  don't know. I mean, the counterfactuals are always created a century of peace, right? Again, I look
*  at the spikes, you know, I don't know that it created a century of peace. I think it pushed
*  a lot of sort of mid level conflict risk into the tail. And the tail is potentially what ultimately
*  kills us. You know, I mean, I think all war is bad. But do you think that the A-bomb was
*  going to be built at some point? I don't know. I think that's very hard to say. I don't I would
*  say there certainly are plenty of people who are more expert in this than I am. But I think there's
*  at least a credible case that if the US had not built the A-bomb that maybe nobody would have.
*  I mean, Germany wasn't close. Nobody else was close at the time. The Soviet Union stole it from,
*  you know, stole the original IP from the US. There was no real other as far as I'm aware,
*  there was no other credible project that was on the path to the A-bomb. So maybe somebody else
*  would have started one. Maybe they wouldn't, you know, I mean, especially if it if we had sort of
*  gotten to a general period of relative peace. Who knows? I don't know. I think we can at least hope
*  for a scenario where we don't end up with mutual AI destruction, which I don't think we should take
*  it as a foregone conclusion that, well, we're, you know, we're going to have mutual AI destruction.
*  So made, I'm calling a new term here. We had mad now we're going to have made.
*  You know, I think there's there's all kinds of ways you can deploy even existing AI in like
*  an offensive way. Like, yes, Stuxnet was, I think, initially developed like the mid 2000s, right?
*  So, you know, there's lots of ways you can cause damage with existing capabilities with the way I
*  think AI gives potentially gives us supremacy is not necessarily through like wielding a
*  superintelligence singleton that like imposes U.S. hegemony on the world. It's more that if we are the
*  first to begin having a productivity boom like none other, right, where we have major automation of
*  R&D and factories and services, that this gives us a huge dividend in terms of economic prowess
*  and lets us also do some of the defensive work, right? And, you know, I think if there's any like
*  ethic among the AI people in the Trump world, it is a kind of defensive accelerationist
*  point of view, right? It's it's we need to have iron domes everywhere type of thing.
*  And if you look at what China is already doing, like the main bottleneck for who gets there first
*  is going to be energy, right? At least in the medium term. And China is creating new coal fire
*  plants and building, you know, has tons of battery and electric capacity. And Trump seems to be,
*  again, situationally aware enough that he thinks that we need to double our electric energy
*  production by the end of the decade. And I think they'll do anything that's going to require,
*  you know, embracing natural gas and deregulating nuclear even more than has already been pushed
*  for. And again, I think that's energy abundance is much more likely under Trump administration.
*  And I don't think I don't see this in terms of a mutual destruction more as how do we, you know,
*  US infrastructure is already deeply compromised. There's tons of stuff that's probably burrowed
*  into her critical infrastructure that China could turn on at any point. You know, the US government
*  itself is incredibly fragmented. It's not like we have like some WeChat single platform that
*  everyone uses. It's like, you know, different agencies have like different cloud contracts.
*  You know, Microsoft is constantly having leaks and so on and so forth. So I think it actually
*  is quite existential for the US, US disposition in the world. And I don't think it necessarily
*  has to be a race to oblivion. It's a race to getting to a point where we can credibly defend
*  ourselves against oblivion and have a degree of deterrence, both technologically and through our
*  economic strength. And I look at the political actors in the world right now, and there's only one
*  group that are actually sort of talking about this in a way that seems sort of like,
*  at least proportional to what's coming down the line. And again, like, I would beg to differ on
*  your characterization of who's been more hawkish on China. Like in some ways, I think the Biden
*  administration has been much more escalatory vis-a-vis China, whether, you know, from Nancy
*  Pelosi visiting Taiwan to the chip export controls, which I support. But we're sort of at a nadir in
*  terms of our diplomatic relations with China. And that actually took place under Biden, not Trump.
*  Trump cared about tariffs. He wanted a fair trade deal. He didn't really care a whole lot
*  about human rights. And he said he had a lot of respect for Xi. And he brokered a peace with
*  North Korea. He's like best buddies with Kim Jong-un. And so there's lots of ways I think a
*  Trump administration on foreign policy could actually surprise us on the upside, while still
*  maintaining, you know, an America first posture. I'd be interested to hear more of your take on the
*  chip ban. I've never been sold on that policy. And I would say I'm broadly a China dove and quite,
*  you know, just under, I feel like the case has not been made really, that this is something that we
*  need to do. I would totally agree that the chip ban is like very escalatory. And I'm not sure,
*  it doesn't feel like the case has been made that it's actually going to help us. It feels to me like
*  we sort of said, this is like the one bipartisan thing, right? This is the sad reality in my view
*  that the one thing that the two parties can agree on is that we need to stick it to China at every
*  turn. And, you know, to what end really, right? Like, it seems like there is some sort of assumption
*  in there that we're going to achieve some sort of kind of weaponized, you know, dominance,
*  because if it's just about a productivity boom, then they can have some productivity boom too,
*  right? Why do we need to cut them off of the productivity boom? Like when you think about
*  that from China's perspective, to me, it seems that they can only interpret this as these guys
*  will do anything to stop our rise. And they're probably trying to create strategic military
*  dominance that we can never come back from. But at worst, they're just trying to stop our, you know,
*  mundane application of development and application of AI. And that's also like a shitty thing to do.
*  If it's, you know, if it's all kind of benign, is there a story about this that makes sense,
*  that isn't predicated on the Leopold sort of narrative that we're going to use our... And
*  there's a talk about it, you know, there's a lot of chapters in that story, right? And they're not
*  supposed to be playing out over that long of a time. It's like, we're going to first, you know,
*  use our little lead to solve alignment. And then once we have this, then we can finally talk to
*  China and have a nice conversation with them. And I'm just kind of like, maybe we could start having
*  a nice conversation now. Maybe we could start building some trust. You know, this is another
*  issue where it's like, do I want to play the card of, yeah, we could, you know, deescalate with China
*  now, but really, it'll be better if we keep the tensions high. And then later, you know, when the
*  when the pressure is at its highest, that's when we'll have like this great, you know, moment of
*  reconciliation with China. That doesn't sound that great. You know, I'd much rather like pick up some
*  wins along the way. But what's, is there, what would be your sort of non-made case for the chip
*  ban? Well, I view this as just securing American standard setting capacity over AI, right? Like the
*  fact that we're 90 something, you know, something like 90% of cloud infrastructure, and Nvidia is
*  a US company, it gives us enormous leverage over how AI governance gets actually implemented,
*  right? At the compute layer. And if not for like, short timelines, AGI, I would probably maybe be
*  against the export controls, because they have been so escalatory, and also easily evaded. But to the
*  extent that they could add a year or 18 months or two years to our lead, I think they become
*  potentially decisive. Especially when you think about like inference compute, right? Like, if,
*  you know, maybe we build the AGI in a lab, and they steal the IP, but if they don't have
*  the scaled infrastructure to actually, you know, commercialize it and make it useful,
*  that gives us a huge upper hand. And this comes back to a piece, a line of thinking I've written
*  a lot about in the essay series called AI and Leviathan, where I kind of see a kind of knife
*  edge scenario where AI can either go in a very totalitarian, authoritarian, panopticon kind of
*  direction or into something potentially better, right? And something that tries to preserve our
*  liberty, right? And that gets much more difficult when it is possible in principle to have a big
*  brother watching you. And what does that look like in practice? Well, the country that comes
*  closest to what I think we need to come is Estonia. And Estonia, because they had a blank slate after
*  the fall of the Soviet Union, and a bunch of young policy hacker type people in government,
*  adopted all these e-government reforms in the late 90s, were the first to have e-banking.
*  This was all built on a system called the X-road, which was like a precursor,
*  pre-Satoshi version of the blockchain. So the Estonian government is like on this big distributed
*  data exchange layer that has like an open API, you can develop tools for, you know, the same ID card
*  that you used to ride the bus and pay your taxes and vote and start a business in a way that like
*  has the economies of scale of a big scale up system, but with the civil liberties and privacy
*  protections built in. Like the whole thing is like PGP encrypted and so on. Like how do we,
*  so it's no longer getting to Denmark, it's like getting to Estonia, right? And I don't think we're
*  going to like literally put the US government on a blockchain, but like who's actually thinking in
*  those terms on that level. And they tend to be, on the more libertarian right, they tend to be like
*  the Bellagio type people. And you know, that comes with a lot of baggage, right? Because, you know,
*  Bellagio may be great on the FDA, but he's going to lose any ideas on like the Federal Reserve,
*  and you can say that about like a lot of different actors on that side. And this is why it becomes a
*  high variance play. And I'm not saying this is dispositive. I'm saying that it's the gamble that's
*  on the table. We're, you know, in the kind of political system we have, we have like the turd
*  or the douchebag, right? And we need to assess expected values over those two options. And one
*  has a much higher variance, but I think a low variance incrementalist approach is the default,
*  right? And the default path, if you look at the stars, according to Fermi's paradox, is not a
*  viable path. We need something that sort of takes us off that default.
*  Yeah, I would love to see something. I mean, I think I'm still inclined to fold this hand on this
*  particular gamble and wait for somebody that I think I can actually trust. On the chip in for
*  a second more. I don't know if I quite find the standard setting argument compelling.
*  And I'll try a different argument out on you. I don't know if I necessarily believe this argument.
*  I broadly am like very uncertain about a lot of these things. I guess my the highest level
*  summary of my worldview here and the reason that I don't want to put Trump in a position of power
*  is that I don't think we know what we need to do. I do think we need to be like very, very, you know,
*  keenly in tune with what is happening on the ground and very responsive to new information,
*  very willing to update our worldviews. And I just don't trust him to do that. And even if he has
*  good people around him, I don't trust him to listen to those people. So that's kind of my Trump
*  view. But now going to the chip thing and maintaining that same level of like humility on I really
*  don't know if what I'm about to say, you know, carries the day or not. I think there's an argument
*  to be made that China is not going to be denied AI. They will make their own chips. They've like
*  seemingly made pretty good progress on that already. I don't think they're, you know, caught
*  up. But I've seen them build a hospital in like seven days. You know, I wouldn't underestimate
*  their state capacity to really mobilize and create this industry if they need to. They also have like
*  tons of great researchers. So my guess is like they'll figure out a way to have enough chips.
*  And if we say to them, Hey, you can't use the same hardware that we use. And then the next thing
*  might be the sort of classification of research, then and even, you know, by all accounts, like even
*  the frontier labs are getting more and more secretive all the time. Like even open AI internally
*  is now said to be quite secretive to the point where most of the people that work there don't
*  have all that much more information than we do about, you know, what the status of GPT five is,
*  or what Q star is, or strawberry or what have you, the more secretive we become about all that sort
*  of stuff. Perhaps that pushes China toward a, like a significantly different branch of the tech tree.
*  And I actually quote you on this, I thought from your 95 theses, I thought one of the most compelling
*  was that RL based threat models have been prematurely discounted. I'm not sure that was exactly
*  the right quote. But that's kind of the worry that I have for if we put China in a position
*  where they're like, okay, we can only understand the United States as an adversary, they're trying
*  to keep us down. They're trying to gain decisive advantage over us. They're cutting us off from
*  hardware, they're cutting us off from research, we've got to go our own way. Who's to say that
*  they don't spin up enough compute to pursue some like RL based killer bot scenario.
*  Reward is all you need.
*  And then, yeah, then we're like, we're back to screwed again, right? Because and did we really
*  set standards in that case? I would say that on the contrary, we sort of balkanize, you know,
*  right now we're still in this miraculously, we're still in a zone where I see US China papers
*  every week, you know, whether it's often Microsoft, but it can be other things too,
*  where we have leading minds across the US China divide working on AI technology together. And
*  it seems like we're going to end that, you know, this trajectory is like, we're going to cut them
*  off, they're going to have to go their own way, they will go their own way. Who knows what comes
*  out of that. But the more we sort of aren't talking to each other, and we're racing, and we
*  don't even have a great sense of what one another's technology progress looks like.
*  It just seems like it feeds that dynamic where, you know, how does one pull back from that? The
*  only way I can see to pull back is to begin to ease up on them a bit and say, hey, like, why don't
*  we, you know, share some benefits sooner rather than later? Let's maybe try to stay on the same
*  tech tree. Like that, that would, if we were really all inclined to take AI risk seriously,
*  one shared global tech tree that we can all kind of be on and understand. And like the fact that
*  LLMs have a decent understanding of human values, you know, relative to your, I know you understand
*  this from that one like nine word sentence, you know, these, the LLMs that we have for all their
*  flaws. Like I can have a very sophisticated conversation with Claude about any number of
*  ethical quandaries. And I would say it's more ethical than most people that I know. And there's
*  like a very different type of AI that they could create to try to, you know, take an asymmetric
*  strategy on us. And I just think we run the risk of, you know, in our effort to quote unquote,
*  standard set, it seems like we run the risk of pushing them to a totally dark portion of the map
*  that could have some very unpleasant surprises for us. Again, not super confident in all that.
*  Yeah, I like export controls, probably because they're kind of robust in many different worlds,
*  right? And we don't know what the final architecture will be for AGI, but my expectation
*  is that it will still benefit from accelerated computing and scale. And if you want to have many
*  AGI's that are revolutionizing the economy, you need lots of inference compute on top of that,
*  right? And the export controls that were introduced in 2022 and strengthened in 2023,
*  it's a complex threshold, but roughly around H100 level. You know, NVIDIA produced on the order of
*  half a million H100s last year. This year, they're projected to produce four million, right? And then
*  the new series of chips coming behind that. And so there's been the thresholds where they're set
*  today are exerting a cost on China, but it's relatively manageable cost. That cost will
*  escalate over time as the delta between where the threshold is set and the volume of chips
*  being produced above that threshold increases dramatically. And so they're ramping up their
*  efforts around smuggling and so on and so forth. So a big part of state capacity here is like
*  investing in the Bureau of Industry and Security, which enforces export controls. So they actually
*  have the capacity to monitor supply chains and plant down on smuggling and identify new Chinese
*  entities and add them to the list and so on and so forth. But I do think that the export controls
*  are really binding and they're binding regardless of what, you know, if you take a more RL approach
*  or transformer based approach or whatever the case might be, it's all going to need hardware.
*  I think there's a longer term risk that this forces them to maybe down the tech tree of like
*  doing like some like energy-based chip, like an extrapick kind of thing. That's like a totally new
*  paradigm that like induces a platform shift. I think that's a ways away, right? The semiconductor
*  manufacturing industrial corporation SMIC, the China state chip national champion, I think broke
*  around like 2000. So they've been working on this for like 24 years and they have not,
*  not only have they not cut up, I think they're still at least like a decade behind.
*  That's my impression. You know, they have made progress on with the seven nanometer chip with
*  Huawei that was basically repurposing old semiconductor manufacturing equipment. And so
*  they're really, that was impressive, but they were really squeezing, you know, juice out of like
*  existing equipment. And they're now completely cut off from like newest stuff. And those controls
*  go even further because ASML is still servicing their equipment and that equipment breaks all the
*  time, right? And so I think it's much harder to just like indigenize your own chip production,
*  especially at the frontier. It's probably one of the hardest things any country could ever do.
*  They've been trying to do it with chips. They've been trying to do it with wide body airplanes and
*  they've failed on both accounts. So I'm not, I'm not so worried about like inducing a search down
*  some dark path part of the phase space, at least on that dimension, especially when we're talking
*  about like potential transitions in the next five, five, six, seven years, maybe anything that pushes
*  that lead out, I think redounds to the U S just to give us at least some breathing room, partly
*  because our political process moves so much slower. So, you know, going back to like the question
*  about diplomacy and having olive branches and like collaborations, I'm all for that, you know,
*  especially before, if it was done in a way that like had some reciprocity and didn't have this,
*  didn't have this asymmetric cost of the fact that China has no qualms about taking our IP
*  and using these joint partnerships to basically transfer U S technology into China.
*  And we get very little in return other than, you know, citations and, you know, our H index goes up,
*  but, you know, what could matter more than that? Right. But the question like who could actually
*  broker that, you know, I think what pisses off China more than, than a tariff war is being
*  scolded on their human human rights record and questioned about like their internal politics,
*  right. And, you know, while Trump is hawkish on China in one sense, it comes at it from a more
*  purely economic standpoint. You know, it's, it's, he was on the same bandwagon about Japan back in
*  the eighties, right. And for that reason, I think they could, yeah, again, this is maybe wish casting.
*  I think there's more, more opportunity, more potential to have stronger diplomatic ties while
*  still turning the screws on the economic front. Yeah, something feels a little,
*  I'm not one who goes down this path of like, you know, whose values are going to prevail. You know,
*  this is like the new framing that I am extremely allergic to the, you know, now we got Sam Altman
*  on this, on this vibe as of recently with, I think it was a Washington Post op-ed, stark departure
*  from what he was saying even just one year ago. I went back and looked at just one year ago. He had
*  a interview in which he said, you know, so often in the West, we basically act like there's no,
*  what, no hope of cooperating with China. And I don't think we should give up on that too soon.
*  And now he's in the Washington Post saying there's no third way. It's our values are their values.
*  First of all, I'm like, what are Chinese values? Can anyone who's saying this articulate Chinese
*  values? What are they? Do we have a summary? It feels like we're basically, you know,
*  it feels like we're basically just talking about Xi in many cases there.
*  I don't know what China, sometimes I say like 5,000 years of civilization can't be all wrong.
*  Like, I think there are probably some Chinese values that we would also, you know, find to be
*  valuable. But then there does seem to be something weird too about this. And I feel like this is kind
*  of the theme that I'm just not able to get over the hump on is that somehow
*  it's this big contest of values between our values, their values, we're the good guys,
*  they're the bad guys, we're for freedom, they're for not freedom. But then we've talked ourselves
*  into this position where Trump, because he's not going to push them on values, can actually do a
*  better job of somehow getting to something good, where I'm like, I don't know, it all seems very
*  bank shoddy to me. If we actually believe that our values are better than their values, then why
*  don't we just- That's all we get though. Well, I don't know, we could play it straight. Like,
*  if I was president, my proposal would be let's deescalate with China. Let's try to stay on a
*  similar branch of the technology tree. Let's have a shared sense of what we're building and where
*  we're trying to go. And then let's tell them to let the people out of the camps at the same time.
*  And if they're annoyed by that, fine. But I would think they would be a lot less annoyed
*  by some chiding at the UN or whatever than they are by being cut off from chips. I don't know if
*  you mean to say that you think otherwise, but if I think anything about Chinese leadership,
*  it's that they're quite practical. I would think they would be able to handle some rhetorical
*  abuse if we had an actual technology sharing and vision for a positive future of shared prosperity.
*  How we get to this point where we're like, Trump is going to be better for our values because he
*  doesn't even mention them to the Chinese. And so that's going to somehow lead to better relations.
*  I'm not saying the Trump would be better for the hegemonic position of our values on them.
*  I think if you want that, then you should vote for Harris. I'm saying
*  in terms of having some separation, some firewall where we're able to preserve our values and build
*  an open society without being overrun by an AI takeoff occurring in a country with very different
*  values, where however hard it is to define, they have in law that no AI system may be developed that
*  does not reflect socialist values. I think it's something that we should at least take very
*  seriously. And when it comes to multilateralism, I think if you look at the history of the last
*  century, most acts of multilateralism are really just wrappers on American hegemony.
*  There's been very few binding, strong multilateral peace treaties agreements,
*  arms control agreements, so on and so forth that didn't ultimately depend on US buy-in.
*  And we only bought into those things from a position of strength.
*  Well, I guess two reactions to that. One is like, we don't have that level of strength anymore.
*  We are not in a position to dictate global terms for all that much longer, it seems to me. China's
*  going to have their seat at the table barring some dramatic AI development that changes everything.
*  I guess I also think on the point of the idea that a Chinese AI would run off and impose socialist
*  values on us, we are the ones doing this. They are not leading. We are leading. It's our companies
*  that are talking about AGI in the next couple of years. It's not their companies.
*  I think we just need to look at ourselves. We're the ones, if anybody's going to have a runaway AI
*  in the short term, overwhelming odds would be that it comes out of the United States.
*  I just don't like the idea that we're going to hold up this Chinese socialist AI bogeyman
*  as the reason that we need to do all these things when it's almost for sure going to be us.
*  If anybody destroys the world with AI, it will be us. I would say that's easily an order of magnitude
*  more likely that it would be us than that it would be them. We just got to keep that in mind.
*  We're doing all these things out of this paranoia of, and maybe that's too pejorative, but this fear
*  that China has a policy about socialist values must be encoded in the AI, sure.
*  If there's actually an AI that comes out of anywhere that's powerful enough that if it were
*  to have come out of China that it would impose socialist values on America, then we're probably
*  all screwed. I think the general AI safety view on this is like, it's not your values or my values.
*  Do we survive this thing at all? If it gets that powerful, do we survive it at all?
*  I think there is just so much. You look back in deep history, I always think about the...
*  This is a bit of a non sequitur, but I always think of the oxygenation of the planet, not of
*  the universe. The oxygenation of the planet was the first mass extinction event. I just think
*  we have no way of predicting just how weird an AI future might be. It's probably going to be way...
*  If it gets that powerful that fast, that in the next four-year presidential term,
*  something on the scale of a socialist AI taking over America is at all in the realm of possibility,
*  then my sense is that the over the window is way more open than that. It's going to be way
*  weirder than socialist values. Whether the bot can talk honestly about Tiananmen Square is not
*  going to be important anymore. Instead, we need to just get prepared for super weird,
*  super disruptive. Again, look at ourselves, we're the ones that are going to do it, almost for sure.
*  Yeah, you're making the case for me though, because things are going to get super weird
*  and super disruptive. It's the Red Queen dynamic from evolutionary biology. You have to run just
*  to stay in place. You have to co-evolve with the technology if we're not going to be completely
*  subsumed by it. That gets back to the discussion around institutions. Going to the question of...
*  My picture of the world is not that some hegemonic Chinese super intelligence takes over the world.
*  I think that's maybe a little more fanciful than what I have in mind. I think more in terms of just
*  raw economic power and using that power to then establish some kind of new world order that is
*  consistent with federated views of how to run their society. That's more or less what the
*  history of the 20th century was. An AI could be that fulcrum for that prowess. I totally agree.
*  If it is possible that we could train a world destroying model on a single GPU, then we're
*  damned anyways. Either way. But if there's a possible world where we could have location
*  verification or other kinds of kill switches on GPU hardware that we have a de facto monopoly over
*  and cloud infrastructure that has to run these systems due to their scale that has our governance
*  standards within them, then we could potentially even export that technology to the global south
*  and provide services that respect liberties and freedoms in a way that by default we wouldn't do
*  because most of their telecom infrastructure is Huawei. In my own piece on the Manhattan project
*  for AI, I proposed... Well, less a proposal, more what I think is going to be a kind of inevitability
*  is a kind of joint venture between the major labs and the US government. Because the US government
*  is not going to do this on its own. But if there is a risk that super intelligence gets developed
*  in the lab and is super, super powerful, super duper AI, then I think it's imperative that be
*  done within some kind of democratic structure. We don't want open AI to become a sovereign citizen
*  and to be a total new source of sovereign power vis-a-vis the state. And you start to see this a
*  little bit already. Open AI has announced that they're working with Los Alamos, of all places,
*  on red teaming their models. Anthropic already has deep relationships with the national security
*  establishment. And I think this is actually good. I think partly it's good because it shows that
*  democratic institutions are now getting involved. Partly it's good because it shows that there could
*  be a roadmap towards some kind of joint venture where the companies work together on some of the
*  most sensitive parts of the research and have the scaling capital from the government that only
*  government has to sort of have a glimpse into the future. But it's also good because whether or not
*  we want this to be militarized, for better or worse, the defense vertical within the US government is
*  the one vertical that has loss of discretion and ability to pivot and work flexibly. And that's why
*  the Man in Project happened at all was because it was sort of run like a startup. And if I look
*  around the world of who is our Leslie Groves today, it is not in the US government. It's
*  leading one of our major tech companies. So what do you think is actually going to happen with,
*  I mean, that's a hard question, but partly when you go through that analysis, I'm like,
*  well, maybe we should just bring those interest groups back to the table. If we're going to run,
*  if we're headed for this, it seems like you take all the way up to intelligence explosion quite
*  seriously as a live possibility. I think if I was confident that that was going to happen soon,
*  I would be moving more toward advocating for a pause. It seems crazy to me that we would
*  push to that level of power given our current level of understanding.
*  I've been very encouraged over the last two years by how much progress has been made in
*  mechanistic interpretability and we haven't seen the next model yet. So part of what's weird is we
*  have this sort of some progress is happening in the open and some progress is happening in
*  places where we can't see it. So we both with respect to open source versus closed source models
*  and also just capability of systems versus ability to interpret and control them, we have these
*  major step changes seemingly happening or this certainly has been in the past and I'm guessing
*  probably will be again in the not too distant future, there'll be another model that takes a
*  big step up and it'll be like, okay, whoa, everybody has to recalibrate and then in the meantime,
*  that'll sort of open up a gap where it's like, oh yeah, closed source is way ahead of open again
*  and then open will kind of chip away at that lead until maybe it gets close right now. They're kind
*  of very similar. Same thing with interpreting what's going on. There's been a lot of
*  progress there for sure, but you can't interpret something you don't have access to. So by almost
*  definition, if there are AI systems under development that can reason at a human level,
*  only a very precious few people have had any chance to study how that works under the hood.
*  We're at this moment right now where it seems like the interpretability has kind of caught up,
*  but another shoe may be about to drop. At some point, I kind of expect myself to move into
*  advocating for, let's stop pushing the frontiers of this capability. It would be a mistake to race
*  China. It would be a mistake to push it any farther, not beyond the current point, but beyond some
*  point until we really have a robust understanding of what we're dealing with. And that's again why
*  I'm just so allergic to all these other things where it's like, oh, China this or whoever that.
*  We're the ones that are going to do it. We're going to make the decision to either push this
*  thing to the point where it becomes genuinely dangerous to us, or we're going to be the ones
*  to decide we need to understand what we're doing better before we continue.
*  Is that your worldview or how do you...? Yeah. I mean, in my Manhattan Project piece,
*  I talk about it more in terms of how to scale interpretability research and alignment research
*  and defensive applications. I think there's a subset of research that you could
*  describe as sort of gain a function, right? That is, you would much rather that be done in some
*  kind of joint public-private framework that included very secure facilities, more top secret
*  sort of protocols in place, more compartmentalization. Obviously another leg of the
*  Ashenbrenner thesis is that we need much better operational security at these labs. And we can
*  talk about the fact that OpenAI started to compartmentalize more and so on and so forth,
*  but I still imagine that they're doing these pitch meetings in the new training framework from
*  a conference room where their security protocols are closed to the blinds.
*  And so there's still a lot more to be done there. And I think that to do that,
*  you have to start imagining worlds where... And to coordinate a pause in the first place,
*  where the labs come together with the big three and agree to work jointly and are given some
*  safe harbor from antitrust considerations and so on, and given access to the scaling capital
*  to actually see into the future. And I really think this is where... You kind of give you that
*  scale is all you need to the point where simply scaling up a model, the M plus one model could
*  spontaneously learn to wiggle its ionic bonds and escape from the computer somehow. And I don't
*  buy into those sort of more hard takeoff scenarios, but I do think there are worlds
*  where we could trip into some kind of self-play mechanism or some other super scalable approach
*  that immediately reaps the benefits of the scale we already have and will be scary powerful.
*  And again, I'd rather... If that is the warning shot that leads us to pause, a pause will be much
*  easier to coordinate if companies are already working together in some kind of formal structure
*  and have some kind of blessing from the defense department. The US defense department spends a
*  billion dollars a year on directed energy weapons. And I don't think we've ever actually used them.
*  These are big microwave guns. Their main output has been to generate conspiracy theories about
*  Havana syndrome and so on. So we pour billions of dollars into boondoggles that don't go nowhere.
*  We could surely spend equivalent sums of money on a major alignment and peering into the future
*  effort to try to understand where this technology is going. Because if you can scale the $100 billion
*  model, you get some glimpse of what will be possible in a decade for much less. And that
*  is only something that nation states can do. So the argument there is peering into the future.
*  Yeah. I mean, I would feel a lot better about that plan with a genuine, very stable genius
*  at the top of the chain of command. It's like, who does this work and how competent they are,
*  and what is influencing their decisions, and whether they have the courage to
*  call a halt or to blow the whistle. I think so much depends on that sort of thing.
*  I just can't say. As much as I think I could imagine somebody I could be inclined to
*  gamble the future on and trust enough to do that, this would be at the very bottom of my
*  global power rankings of people that I would. I would probably bet on Xi first, honestly.
*  I see with Xi about a lot of things, and I don't want to live in Xi's China. I've said that many
*  times. But who do you think is better able to oversee a private-public partnership to peer
*  into the future and to channel billions of dollars of resources like Xi or Trump?
*  Honestly, it's a sad- I mean, that's what Operation Warp C was.
*  Because now advanced market commitments are all the craze, but that was
*  deep. That was like a Milton Friedman idea. We'll see. Civil-military fusion is happening
*  on both sides of the ocean, and that's somewhat priced in. The question is, are we going to do
*  this in a way that is proactive or reactive? My sense is that if you have Elon Musk and
*  Vitalik Buterin and some of these people who could plausibly have the ear of the National
*  Security Council in a Trump administration, whereas a Harris administration, well,
*  superficially much more competent, much more credentialed and expert-driven, will be turning
*  to the ethicists and major hospital networks and other stakeholders in terms of how they think
*  about the technology. There's no genius without a little bit of madness.
*  We've got to take the- it's a package deal. I say that as somebody who temperamentally,
*  I love walls like the Paris VP pick. If we were at the end of history, and I didn't think there
*  was going to be another major technological transition point in the near future, let's have
*  competent managerial people to increase SNAP benefits a little bit. All for that, right?
*  But that's not the world we're running into. There's a segment of the Democratic Party that
*  is basically- sees itself as managing a relatively stable social-technical equilibrium. That's just
*  not the world as it really is. Yeah. Lord knows. They may have a real wake-up call in store for
*  them if they are actually in power as AI becomes what it might very well become.
*  Yeah, I guess the choice that you're putting to me is what I bet on the Democrats to update their
*  worldview in response to new evidence and get it together on a rolling basis, or should I
*  put it all on black with Trump and hope that the right people are going to whisper to him in the
*  right way and he's going to make the right decisions? We don't have any great answers.
*  Maybe we could conclude by drafting somebody for president. Do you have any- if you were going to
*  put another name on the ballot, who do you think would be a good leader that has the right mix of
*  grounded temperament, responsiveness to evidence, idea-driven but not ideological?
*  Yeah, I think we put too much stake into the person, right? And that's sort of in the
*  bigger message of this is we're not just voting for individuals. We're voting- and with that,
*  we're not just voting for their epistemics. We're voting for blocks of power, establishments,
*  and the political economy that comes with that. So I think it doesn't even matter if Harris
*  reads superintelligence or the Singularity is Nearer and has a wake-up. If the political economy
*  of the Democratic Party constrains her and what she's able to do. And so I don't know who I would
*  draft for my presidential pick. We had our chance of Andrew Yang. He was kind of ahead of his time
*  maybe, but it has to be someone relatively outsiderish, right? The kind of dominant
*  Cummings profile because you need to be an exogenous force. If you're working from within
*  an existing political establishment, you're going to be tied and constrained in what you're able
*  to do because those is sort of the classic innovator's dilemma, right? You're making
*  incremental progress while the world changes around you. What do you think happens if Trump
*  wakes up and says he wants to nuke somebody? Do you think that he can do it? I don't think that's him.
*  I think he's actually a bit of a pacifist. Well, okay. I mean, we're projecting a lot of hopes and
*  dreams onto Trump during this exercise. I hope that's right. I'm not so sure. I think when he
*  bombed Soleimani on the runway, he had no idea where that was going to go.
*  They wanted to do a lot more than that, right? And you had Tucker Carlson on the phone with him
*  pleading him not to invade Iran. But I mean, I don't know. We could even cut this off.
*  He wasn't going to in the first place, right? We could even cut this off the pot face. I don't know
*  to what degree I believe the individual matters or not. I think the
*  line that the public is broadly given is that the commander in chief makes these decisions
*  and that we're ready to respond and that we carry a nuclear football around. And
*  you know, it is supposed to be one person's decision. I guess you could say, well, that
*  won't happen. But I mean, Trump's done a lot of crazy things. That's not really a dispute.
*  He said a lot of crazy things. If he were to say something like that, do you think that
*  the chain of command acts on his instruction or like refuses him in that moment?
*  I mean, this is a total hypothetical. I don't think this would happen in the first place,
*  right? Like his number one priority getting into office is to broker a peace with Ukraine and
*  Russia, right? And I think he's uniquely capable of doing something like that. He's terrified of
*  World War III and nukes. He's like... I mean, he was threatening nukes against North Korea.
*  He's gone further than any other president has gone in invoking the threat theory.
*  He is a madman. So he has gone further than... I think it's undisputable.
*  Right. Yes, he's definitely convinced me that he is a madman. He has gone further than any president
*  in 60 years, at least, in terms of threatening nuclear war. I would say that's clear.
*  He walks across the DMZ and now they're like bosom buddies. I think there's like... Trump has
*  Psy-opped the world into thinking he's one thing when he's really not. And you look at the actions,
*  again, like the NATO example, how are we going to actually get Europe to pay their fair share,
*  if not to make some kind of credible threat? And how do you motivate that credibility without having
*  some kind of actual capacity to pull out, right? Or even if it's feigned, right?
*  Same with the Taiwan situation. We've benefited from a policy of ambiguity, right? Whether it's
*  its own independent country or not. But those are the kind of things, the sort of game theory
*  that having someone like Trump, I think is actually an asset. But again, I don't think
*  this is where things are going to hinge. The president obviously has a lot of unilateral power.
*  Individual decisions made by a president can reshape the world order. On AI policy in particular,
*  I think it's going to come down to more how things are delegated. And if you had to appoint a colonel
*  in a moment of crisis, who would that be type of thing? And what sort of broad social base are
*  you drawing on? Are you drawing from a bunch of ethicists and sociologists and union representatives
*  or people who actually know the technology and know how to scale large organizations and large
*  responses? Trump's CTO, Kratzius, is now head of policy at scale, right? He ran his OSTP. These are
*  very, very smart, capable people who I think are below the fray in terms of what you see on CNN,
*  right? You don't hear this level of granularity and how the Trump administration the last time
*  around actually operated. And it was much more rational than sort of met the eye. And that was
*  partly Trump's own fault that that didn't get communicated because he was, again, telling people
*  to drink bleach and mired in lawsuits. But look at what he did in spite of that.
*  I do want to be mindful of time. This has been a great discussion, but maybe Nathan will give
*  you the last word and we'll wrap on that. Boy, how to land this plane after all this.
*  There are two pills before you.
*  I'm inclined to gamble at some point. I think that there is a strong case,
*  and I've been one to make it in years past. I've only kind of stopped making it
*  because of the current crop of leaders of the Republican Party.
*  I buy a lot of the analysis that we're not going to handle a technology revolution by
*  calling in union leaders from every different sector to ask what they think should be done
*  about it. I definitely buy that. I think it's undeniable that we need a reform of many parts
*  of government. It seems like you do need somebody who has some sort of independent
*  power base to do that. It seems unlikely that it would be a total creature of the machine
*  that can affect those sorts of big changes. So I do buy a lot of the overall story
*  that you're telling. I think for me, it ultimately does come down to
*  do I want to bet on this now? We don't have full control of the timing. I've said to people in
*  the past, I'm sorry that the timing of the AI revolution is inconvenient for you.
*  So I can't move that timeline, but
*  man, do I want to gamble on this group to do this? Do I want to put Trump in the ultimate
*  say-so position or would I rather keep with the incrementalists for another term, hope that
*  they'll rise to the occasion if things really get crazy, and hope that we might get a better reformer
*  at a future date? I can't get myself to want to bet on Trump.
*  I'm Canadian, so I can't vote, but you're in Michigan where your vote actually matters.
*  Awesome. Well, that's a good place to wrap. Sam, Nathan, this has been a fantastic conversation.
*  Thank you as always, and until next time.
*  Great, guys.
*  Thank you.
*  It is both energizing and enlightening to hear why people listen and learn what they value about
*  the show. So please don't hesitate to reach out via email at tcr at turpentine.co,
*  or you can DM me on the social media platform of your choice.
