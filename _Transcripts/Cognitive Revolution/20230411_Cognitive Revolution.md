---
Date Generated: April 03, 2024
Transcription Model: whisper medium 20231117
Length: 4194s
Video Keywords: []
Video Views: 1832
Video Rating: None
---

# Will GPT-4 Cause Economic Transformation?
**Cognitive Revolution "How AI Changes Everything":** [April 11, 2023](https://www.youtube.com/watch?v=HaBLuMeDl0I)
*  And then we've also seen the Microsoft research paper
*  in which they basically said that GPT-4
*  is appropriately considered an early AGI.
*  Can a language model do the entirety of this job?
*  You will almost always conclude no,
*  but that's gonna be 5% of cases,
*  I would guess in the early going.
*  And then before too long, it'll be 1% of cases.
*  And then before long, 0.1% of cases.
*  Everybody who's ever wanted to take piano lessons
*  and didn't feel like they have time, might have time.
*  In the end, I might give you the piano lesson
*  by the way as well.
*  But there's not necessarily money waiting for you
*  to like perform at the end of that.
*  I know this thing can answer my medical questions,
*  but it's not allowed to.
*  And it's not allowed to because of who?
*  The top comments that I saw were all women saying,
*  well, maybe at least Chachi BT will listen to me
*  when I go in and talk about my problems.
*  So.
*  Hello and welcome to the Cognitive Revolution
*  where we interview visionary researchers,
*  entrepreneurs and builders working on the frontier
*  of artificial intelligence.
*  Each week we'll explore their revolutionary ideas
*  and together we'll build a picture of how AI technology
*  will transform work, life and society in the coming years.
*  I'm Nathan Labenz joined by my co-host, Eric Torenberg.
*  Before we dive into the cognitive revolution,
*  I wanna tell you about my new interview show, Upstream.
*  Upstream is where I go deeper
*  with some of the world's most interesting thinkers
*  to map the constellation of ideas that matter.
*  On the first season of Upstream,
*  you'll hear from Mark Andreessen, David Sachs,
*  Follogy, Ezra Klein, Joe Lonsdale and more.
*  Make sure to subscribe and check out the first episode
*  with A16Z's Mark Andreessen.
*  The link is in the description.
*  Let's get into it.
*  In our last GBT4 solo episode,
*  we talked about how you told the OpenAI team
*  that there will be economic transformation
*  and you are confident in that.
*  Why don't you describe or unpack what you mean by that?
*  Yeah, sure.
*  I mean, I think there's a lot to be still figured out
*  in terms of the details,
*  but maybe just to recap real quick what I did
*  and sort of what my takeaways were from it.
*  I just set out to get the AI,
*  which is now the model we now know is GBT4,
*  to play the role of a lot of different professional advisors
*  that we interact with in daily life
*  and that we pay real money for and see real value in
*  and that people work hard to get to these positions
*  where they're qualified to play these roles.
*  So the obvious kind of first one would be a doctor, right?
*  You have a concern, you wanna talk to a doctor about it.
*  In today's world, you have to set up an appointment,
*  you have to drive in there,
*  you have to wait in the waiting room.
*  It ends up often taking a half a day to do that.
*  A lot of people feel like even when they go
*  to all that trouble, the doctor doesn't necessarily listen
*  to them as well as they might like,
*  but that's kind of the state of the art.
*  Setting up a dialogue with an AI doctor
*  was trivially easy for me to do.
*  I use just simple kind of role casting as it's called
*  in the prompt engineering world,
*  tell the doctor or tell the AI that it is a doctor,
*  that it's gonna interact with a patient,
*  set up a dialogue, and then just chat back and forth.
*  And I really found it to be extremely easy
*  to essentially replicate the interaction
*  that I had had with a human doctor.
*  Now I'm not a doctor,
*  evaluation on this stuff is really hard.
*  And so I kept my experience pretty few in number
*  and focused on experiences that I had had,
*  real fortunately minor for me medical issues
*  or things that we've been concerned about
*  with our three-year-old
*  that we might've otherwise called a pediatrician about.
*  Just within that two months, we did get to a point
*  where there was one incident
*  where we didn't call the pediatrician
*  where we otherwise would have,
*  because we got some advice from the AI
*  and we deemed it like good enough, reliable enough
*  to kind of assuage our concerns.
*  And we went on with our day
*  without even actually calling the pediatrician.
*  So just in that two month window,
*  even knowing that it's an alpha,
*  knowing all the difficulties around evaluation,
*  we personally got to a point
*  where there was a clear moment of substitution
*  where real question that we had,
*  the AI was able to answer satisfactorily enough,
*  we didn't have to call the doctor,
*  we didn't have to go in.
*  Now it wasn't a big problem,
*  turned out it wasn't really a problem at all.
*  So that's maybe an easy case,
*  but that was a call that otherwise would have been made,
*  and it wasn't as a result of our access to GPT-4.
*  So you kind of go down the line
*  of a lot of different sorts of professional roles.
*  And I think I told the story last time of the dentist,
*  where I had the weird thing on my tooth
*  and it gave me this feedback that's like,
*  sounds like your dentist did something non-standard
*  that is not in line with best practices
*  or standard of care.
*  And sure enough, that was definitely true.
*  It tried it in an immigration law situation,
*  did some kind of far out things
*  like playing with a three-year-old,
*  giving tech support to my grandmother,
*  asked the AI at one point to be a mediator
*  between two neighbors that had a dispute over offense.
*  I played the role of both neighbors
*  that were kind of at odds with each other,
*  and the AI's job was to bring us together
*  and try to find some common ground.
*  Did a pretty admirable job on that.
*  Interestingly, I sent it to a friend of mine
*  who is a lawyer now and asked what he thought about it.
*  And he said, well, from a legal perspective,
*  this is pretty open and shut case.
*  The one neighbor's fence is on the other neighbor's property
*  and the neighbor whose property it is
*  can say what happens and that's that.
*  But I thought it was actually kind of revealing
*  in a way too, right?
*  That it's like,
*  maybe we didn't actually want a lawyer for that situation.
*  What we needed was the mediator, not the legal perspective.
*  As we're gonna continue, this is all fictional, right?
*  But we're gonna continue living next to each other
*  as neighbors and it really helps if we can resolve this
*  in a non-legalistic way.
*  So like what role you ask the AI to play
*  can make a world of difference, I think,
*  in terms of how effective it's gonna be for you.
*  Other experiments that I did were setting up
*  a virtual personal trainer,
*  set up a group chat type of dynamic
*  and then brought in the AI to be like the coach.
*  So we've got me who was in like, okay shape.
*  We've got my wife who's pregnant.
*  We've got my brother in there who is probably
*  in the best shape of all of us, but frequently injured.
*  And it's doling out specific advice to each of us.
*  Like Nathan, you should see if you can do five more
*  next time and Amy, well, you're pregnant.
*  You just gotta take it easy.
*  Like anything you can do is a bonus.
*  You just gotta focus on staying well,
*  getting to the end of this thing.
*  Very kind of friendly.
*  Honestly, if you, obviously people talk about
*  the Turing test for a long time.
*  If you double blinded something like this
*  and ran a study of which of these is the real virtual
*  trainer by text versus the AI,
*  you're not going to distinguish those, right?
*  So giving gifts, coming up with gift ideas,
*  generating grocery lists, saying, hey, I wanna cook this.
*  Can you pull me up a recipe,
*  translate that to a shopping list?
*  We can put that in the cart.
*  It goes, it just goes on and on, right?
*  Called a virtual car repair place
*  and told them what's going on with my old car
*  that had a problem with it.
*  I would say better service from the AI
*  in the role of answering the phone at the garage,
*  then I would expect to get calling a real garage, right?
*  I mean, patience and just kind of the willingness
*  to listen to you and really sit there and, you know,
*  get to the point where you're happy with the conversation
*  is a huge strength for an AI system compared to, you know,
*  the guy who's at the garage,
*  who's like not getting paid to talk to you on the phone,
*  right? He's got cars there that he needs to fix.
*  He's probably got, you know, grease on his hands,
*  whatever it is he's trying to talk to you.
*  You know, we've all had that experience
*  where the guy's just like, look, bring it in.
*  If you wanna bring it in,
*  I can't really diagnose this over the phone, you know,
*  and you're kind of frustrated
*  and he doesn't really wanna deal with that.
*  And so, you know, if the AI doesn't care,
*  it will sit there and answer your questions all day long.
*  You know, it did in that moment remind me that, hey,
*  really you should bring it in and we're here for you,
*  whatever, this is all without any fine tuning, right?
*  All I'm doing here is setting up.
*  Your job is to answer the phone at a car repair shop
*  and help people, you know, diagnose what's going on,
*  give them a sense of what to expect, you know,
*  and then obviously ultimately they're gonna come in
*  and we'll get it fixed.
*  Hardware Store Associate was another one that I tried
*  where I have an old house
*  and we've got these old light fixtures in the basement
*  probably put up in the eighties.
*  The lights are, you know, old halogen lights,
*  they're energy hogs, whatever.
*  So looking at potentially upgrading those,
*  you know, it's a very idiosyncratic thing, right?
*  These particular lights
*  with these particular kind of wire rings,
*  what can we do about that?
*  You know, do I have to rip the whole thing out
*  or can I just replace it?
*  It suggested a specific light bulb,
*  which I was then able to search for,
*  find that that light bulb did exist,
*  that it is the right light bulb, you know,
*  to kind of convert these old fixtures into a modern,
*  you know, low energy lighting,
*  ordered them, put them in and they fit, you know?
*  So it's like, wow, that's amazing, right?
*  Just for me setting up my situation exactly as I would do
*  if I walked into a hardware store,
*  I, you know, start with the story.
*  Got an old house, I think the guy put it in,
*  you know, same exact dynamic.
*  I was looking for a solar panel,
*  just to have a little bit of energy generation backup
*  in this scenario that my power goes out
*  because we had a big power outage
*  during this time of red teaming.
*  And, you know, I wanted to be able to charge a cell phone.
*  So I had to figure out, well, how much solar panel
*  do I need to charge a cell phone?
*  Well, how much energy does a cell phone take?
*  So go through that whole conversation, you know,
*  get a consult on what kind of power generation, you know,
*  is enough to charge a couple of cell phones.
*  Like, what would it take if I wanted
*  to run a refrigerator off of it?
*  What would it take if I wanted
*  to run an air conditioner off it?
*  Spoiler alert, like you don't want to run
*  your air conditioner off a retail solar panel.
*  But, you know, the cell phones take very little power.
*  I was actually really kind of amazed
*  to learn how little energy it takes
*  to charge and run a cell phone.
*  Menu planning, catering, you know,
*  my wife puts on these huge events, thousand people.
*  It's typically an all vegan menu
*  in the community that she serves.
*  And she's had a lot of problems getting,
*  and they do them all over, right?
*  So it's different cities and like, you know,
*  often there's a new catering company
*  that she's working with.
*  A lot of challenges in getting a good vegan menu
*  out of, you know, kind of a typical catering company
*  that doesn't often do full vegan menus.
*  I sent her an example of, here's a, you know,
*  a menu set up for your, you know, three, four day event.
*  She said, she said, GPT catering is amazing.
*  It's better than all of our caterers
*  at setting up the menu.
*  So it goes on and on.
*  There were a few that I tried that were definite fails
*  at the time.
*  And I would have to go back and verify like,
*  to what degree has this been patched?
*  But the math ability was still pretty limited.
*  It could do like your SAT problems,
*  your kind of high school level, you know,
*  story problems pretty consistently and pretty well.
*  But if you went up a level beyond that, you know,
*  it'd start to be kind of iffy like college math.
*  Yeah, it's like, you can do some calculus and stuff,
*  but you would hit the limits.
*  And then especially as a teacher,
*  there were challenges if you tried,
*  if you got confused as a student,
*  then a lot of times it might also get confused
*  and kind of, you know, think that what you said was right,
*  or, you know, we've seen these sorts of things with Bing
*  where like it gets very out of sync
*  in terms of what day it is.
*  And I definitely experienced some of that kind of stuff
*  with math, with chemistry as well,
*  like balancing, you know, chemical equations.
*  It could do basic equation balancing,
*  but if I posed as a student and said, you know,
*  here's what I think it is,
*  then I found that it was pretty easy to confuse it still.
*  So in the end, I probably did, you know,
*  a dozen of these different roles in some depth.
*  And, you know, they were kind of a pretty broad cross-section
*  of the jobs in society that range from, you know,
*  literal MD or lawyer, you know, advanced degree,
*  high salaries, you know, high prestige professions to,
*  you know, things where there is a lot of kind
*  of idiosyncratic knowledge,
*  but it's not necessarily so high status
*  like a hardware store associate or, you know,
*  somebody taking a call at an auto mechanic shop
*  and just across the board, you know,
*  it seemed like it did very, very well
*  with just a couple of exceptions that I mentioned.
*  So this has all been really born out now
*  by publications that have come out as well, right?
*  We've seen the GPT's paper, which is, you know,
*  the second GPT there is general purpose technology.
*  And then we've also seen the Microsoft research paper
*  in which they basically said that GPT-4
*  is appropriately considered an early AGI.
*  And I think they've, you know, they've characterized it
*  at quite a bit of length there too.
*  So I would definitely recommend both of those papers
*  for, you know, just further characterization
*  of what the model can and can't do.
*  All of that is just kind of raw material, right?
*  Like this is what we saw, this is what has been observed.
*  Now, how does that lead to economic transformation?
*  Like on the one hand, it's pretty obvious, you know,
*  if you just kind of, at least for me,
*  if you just kind of ask your gut, like, okay,
*  I now have an AI that can handle a first conversation
*  with the doctor, you know, first conversation
*  with a lawyer in, you know, and go 10 rounds
*  and like have some real depth and substance to it.
*  Does that feel like it would be transformative?
*  Like, yes, to me, it definitely seems pretty obvious.
*  But then you still have the question of like, how, you know,
*  one of the lines in the GPT's or GPT's paper
*  that is really true is that if you go around
*  and look at jobs as they exist today, and you ask,
*  can a language model do the entirety of this job?
*  Then you will almost always conclude no, that it can't.
*  And that could be for multiple reasons, right?
*  There could be too much context required.
*  It could be that there's a physical nature
*  to some of the work or all of the work that,
*  obviously the language model, you know,
*  without a robot to control is not gonna be able to do.
*  So, you know, it's almost all jobs you'd look at
*  as they are bundled today and say,
*  yeah, language model can't do that.
*  From that though, I infer that what we're about to see
*  is a huge unbundling of jobs into tasks.
*  And I think that that is basically the same lens
*  that the GPT's or GPT's paper takes,
*  looking at what are the tasks that constitute a given job?
*  How prevalent are they?
*  You know, what is the task mix for any given role?
*  And then which of those tasks can a language model
*  either do outright or accelerate?
*  I think they said like, you know,
*  cut the time by at least half
*  that it would take to do that task.
*  And there they find that a lot of the tasks are doable.
*  So they kind of categorize jobs
*  by how exposed they are to language model impact,
*  where they define exposed as what percentage of your time
*  is spent on tasks that can either be again done
*  or like greatly accelerated with language models.
*  And there they find that about half of all jobs
*  have about half of all tasks exposed to language models.
*  Omniki uses generative AI to enable you to launch
*  hundreds of thousands of ad iterations that actually work,
*  customized across all platforms with a click of a button.
*  I believe in Omniki so much that I invested in it
*  and I recommend you use it too.
*  Use Cogrev to get a 10% discount.
*  So there's still a lot of kind of wiggle room in there
*  to figure out exactly what happens
*  and exactly how things play out.
*  But I think we're gonna see,
*  and I think it's likely gonna start with major corporations
*  because they are the ones that are gonna be buying
*  the most advanced systems.
*  They're the ones that are gonna be seeing
*  huge dollar sign savings opportunities
*  in fine tuning the most advanced systems for reliability
*  to do things exactly the way that they want them to be done
*  or need them to be done in a corporate context.
*  And so I expect that you're gonna see just tons of
*  first large businesses and then it would probably
*  kind of trickle down to smaller businesses
*  looking at what is it that we do around here?
*  And you're gonna see a new kind of tailorism
*  for knowledge work.
*  So instead of, we've seen this once before, right?
*  With the transformation of kind of artisanal manufacturing
*  to assembly line style manufacturing.
*  Like if you go back before Henry Ford
*  and before the assembly line
*  and look at how people made cars,
*  they were making cars before there was an assembly line.
*  But the tolerance, the machining was not so precise.
*  The tolerances were all much looser.
*  People kind of had to make things fit
*  in a very sort of artisanal hands-on
*  runtime problem solving sort of way
*  to actually get a car out of a process that would work.
*  And so every one that they made
*  tended to be a little bit different
*  and you'd have kind of less reliability, less power.
*  You could not get the same kind of precision.
*  Well, now you go into a factory
*  and you see high level of automation.
*  You see extremely tight tolerances
*  in the most advanced, go to a semiconductor fab
*  and like a speck of dust can throw the whole thing off.
*  And so it's been really kind of studied, broken down.
*  What are the tasks?
*  How precisely can we do them?
*  And that's totally transformed manufacturing.
*  I think a very similar phenomenon
*  is coming to knowledge work where people are gonna say,
*  okay, let's look at this job.
*  Let's figure out which parts of it
*  can be done by a language model.
*  And then let's train a language model to do it.
*  Now, sometimes they might even just be able
*  to do it off the shelf,
*  but a lot of times there is gonna be
*  some special training required to really make sure
*  that you're getting the,
*  especially the reliability of the output that you want.
*  So people will really spend the time
*  and put some elbow grease in to ensure
*  that the language models are reliably doing the tasks.
*  And hopefully people will take care of that.
*  They're robust to weird scenarios
*  and all that kind of stuff.
*  But honestly, you only need to get
*  to a certain threshold of reliability
*  before it makes sense to say,
*  all right, look, we pay people X dollars an hour
*  to take phone calls.
*  And if we have a language model do that instead,
*  then we probably see at least a 10-fold reduction in cost,
*  90% reduction in cost.
*  And often maybe like a 95, 98, 99% reduction in cost
*  relative to what the human would have cost.
*  In the doctor scenario, if you figure whatever
*  average appointment is a hundred bucks,
*  that's probably conservative in the US,
*  you can have that 45 minute conversation
*  for basically a dollar at current prices.
*  If you're talking about a call center
*  or customer service or the thing,
*  maybe that difference is not a hundred to one,
*  maybe it is more like 10 to one,
*  but it seems like many things are gonna be kind of 10
*  to a hundred to one cost ratio.
*  And that's gonna be very enticing,
*  especially when you consider the fact that
*  it's also going to enable 24 seven access,
*  and especially as tooling and systems, databases,
*  memory types of things get built out,
*  then you also won't have the problem that you have
*  so often today where you call and the person like,
*  doesn't know who you are,
*  and you didn't talk to them last time,
*  so they have no memory of this
*  and the notes in the system often aren't that great,
*  all that stuff is gonna kind of get smoothed over as well.
*  And you end up pulling these things apart, right?
*  So what parts of your job can be done by language model
*  ultimately likely do get sent that way,
*  the parts that can't,
*  then they maybe get re-bumbled into another job.
*  For a while, if you take the call center type of situation,
*  like escalation may be the thing that is
*  the most common thing
*  that the language model can't handle, right?
*  Like if you've ever said,
*  is there anybody else I can talk to?
*  Can I talk to a manager?
*  Like, I'm not happy about this.
*  Then that type of thing maybe is in the first generation
*  kind of where the language model responsibility ends
*  and it kicks up to a human who maybe has more discretion,
*  more context, whatever,
*  but that's gonna be 5% of cases,
*  I would guess in the early going,
*  and then before too long, it'll be 1% of cases,
*  and then before long, it might even be 0.1% of cases.
*  So, I think people get tripped up a lot of times
*  when they think about this future and they're like,
*  well, there's no way that the AI can do everything.
*  We'll always need humans.
*  And I think that that is true,
*  but doesn't quite mean what,
*  or at least it's true with the current technology, right?
*  I'm kind of bracketing like no further major upgrades,
*  I'm not trying to analyze GPT-567 here by any means,
*  but even with just the current technology,
*  we'll always need humans, yes,
*  but what the humans are doing
*  is probably going to shift a lot.
*  There's gonna be a flurry of activity,
*  analyzing jobs, pulling things apart,
*  figuring out what tasks can be delegated to AI,
*  figuring out the training set and the reinforcement
*  that can get good performance out of them,
*  and then figuring out how to wire that into a system,
*  how to handle escalations when they're needed,
*  how to handle whatever other corner cases,
*  and then the things that are not doable,
*  those maybe get re-bundled into other jobs.
*  So, you think about going to a doctor's office, right?
*  Today, you might have the same person answer the phone,
*  schedule your appointment,
*  and then also take your weight and your blood pressure
*  when you come in.
*  The scheduling, I think it will be months at most
*  before there is a competitive market
*  in automated scheduling systems for doctors
*  that you can just call and talk to,
*  and now everybody wins, right?
*  Like the patient gets better service, you can call anytime,
*  the doctor's office is gonna save money on that,
*  in theory that gets passed through to the customer,
*  all great.
*  Well, what about that person who was sitting there
*  taking the calls and checking people in
*  when they get there?
*  Well, it probably depends,
*  it depends on a lot of details,
*  but they don't have to take the calls anymore.
*  Is there still enough of a job left
*  to merit somebody to do the weight and the blood pressure?
*  Maybe the doctor picks that up in certain offices,
*  maybe if it's big enough,
*  you had three receptionists before
*  that were also doing that,
*  and now that goes down to one.
*  The details, the context and all that kind of stuff
*  are really obviously gonna matter a lot,
*  but people are very good at figuring out,
*  certainly this is like what entrepreneurs do, right?
*  Just like identify opportunity to use new technology
*  to solve problems in dramatically more efficient ways,
*  and I think that's gonna happen extremely quickly
*  and will kind of be everywhere.
*  You could say like, does this mean there will be no jobs
*  or that people will have nothing to do?
*  And I wouldn't jump to that conclusion.
*  That's another thing where I think there's kind of a fallacy
*  that's like, it's not all or nothing.
*  It's not that AI is either going to compliment people
*  co-pilot style, or it's going to replace them,
*  assembly line replaced artisanal manufacturing,
*  it's gonna be both at the same time.
*  And similarly, what are people gonna do,
*  I think is a much more nuanced and contextual question
*  than saying like, nothing's gonna change
*  or everything's gonna change
*  and nobody's gonna have anything to do.
*  The outcome is gonna in all likelihood
*  involve a ton of change,
*  but the kind of end state is not gonna be
*  like on one of these poles, it never is.
*  Yeah, it reminds me, you and our friend
*  Antonio Garcia Martinez had a little back and forth
*  on Twitter the other week,
*  where he just posted some of the stats around
*  how every technological innovation,
*  where people were concerned that it was gonna lead
*  to the end of certain jobs.
*  It did in some instances, you copy and pasted the farmer,
*  stats where the country used to be like 90% farmers
*  or whatever, and now it's like 3%.
*  The technological innovation ended up creating more jobs
*  in general because human desires and needs are infinite.
*  Do you think that is a unhelpful paradigm
*  for thinking about what we're seeing here with AI,
*  IE is this time actually different
*  relative to all the other previous technological advancements
*  and what types of people will be the farmers
*  that we'll be looking back on?
*  How would you expand on some of those ideas?
*  Yeah, it's a really tough question.
*  So I should say, I think I have a read on where it's going,
*  but certainly I also expect to be surprised
*  by plenty of things.
*  I do think this time is different in that
*  it's not really clear what we could shift everybody into.
*  And I also think there's a generational question,
*  which is a big one.
*  So I think that I would cite Yuval Harari and Sapiens,
*  I believe, or his next book after Sapiens.
*  And it's funny, people hate on that book,
*  but I think there's a lot of value in just trying to zoom out
*  and tell that story from as far removed as possible.
*  Obviously, you can open yourself up to being criticized
*  for missing lots of important aspects of the story
*  when you try to do that.
*  But I find it to be a pretty useful attempt
*  to cover whatever, 100,000, 10,000 years of history
*  in just a few hundred pages.
*  And I think it was from him that I heard
*  just the general notion that we can do
*  kind of a couple different general kinds of tasks,
*  like physical labor that relies mostly on our muscles,
*  and then cognitive labor that relies mostly on the brain.
*  And obviously there's some overlap there,
*  but there's not an obvious third place for us to go.
*  So when physical work got semi-automated,
*  semi-automated through machines and the harnessing of,
*  fossil fuel and electrical power,
*  then it was like, okay, cool.
*  We don't have to do as much of that stuff anymore.
*  We can go do more cognitive work and that's great.
*  And largely people prefer it,
*  and there's certainly a lot less injuries from it
*  and whatnot, so it's a win.
*  But if you zoom out to that level,
*  where are we gonna go beyond cognitive work?
*  And you could maybe come up with some candidates like,
*  what about like emotional work?
*  Is that distinct enough from cognitive work?
*  My experiments suggest that the AIs are getting pretty good
*  at that sort of emotional work as well.
*  I don't have a lot of experience
*  with like cognitive behavioral therapy
*  or that kind of modality,
*  but it seems like that will be pretty readily provided
*  by language models.
*  You know, is there some sort of connection,
*  the sort of realness of which is, can't be recreated?
*  Like possibly in some scenarios for some people,
*  I could see, you know, kind of emotional work
*  becoming a category that's like distinct from cognitive work
*  and kind of remains a sort of, you know,
*  a place where humans are maybe not even dominant,
*  but like preferred for kind of reasons.
*  I think you could also kind of imagine like
*  an interesting local kind of bespoke service economy,
*  you know, highly like individualized entertainment.
*  People, you know, do these sort of like dinner party,
*  murder mystery games, you know, for example,
*  could an AI like put together a good murder mystery
*  for a group to solve?
*  Yes, I don't think that's like out of the range
*  of what it could do, but I could imagine, you know,
*  that there's sort of in a world of like abundance
*  and, you know, all the kind of bullshit jobs
*  and, you know, frontline customer service
*  and all, you know, all that kind of stuff
*  being delegated to AI, then maybe we end up in a more,
*  you know, kind of local network sort of economy
*  where we're kind of doing cool, you know,
*  fun things with and for each other.
*  But honestly, it's hard to, you know,
*  if you think of like work as stuff
*  that people don't necessarily wanna do,
*  and therefore they need to get paid to do,
*  and that won't get done otherwise,
*  it seems like that's a shrinking category.
*  You know, it seems like there's just,
*  there's gonna be a lot less work that only humans can do
*  that they won't do unless they get paid for
*  that, you know, that won't get done otherwise.
*  That seems like a shrinking category.
*  So I do think people will have plenty to do.
*  Like I don't worry about myself at all.
*  Like if everything I do got automated, you know,
*  I don't think I'd be bored.
*  I'd still be interested in studying AI, for example,
*  or, you know, I've got plenty of,
*  I'm interested in history.
*  Like I'd love to read more history books
*  than I currently feel like I have time for.
*  So I think there is tremendous potential
*  for people to be self-actualized,
*  to be, you know, to develop their talents,
*  to create stuff that they find worthwhile
*  and that others find worthwhile.
*  But I don't think that that's quite the same as work
*  as we think of it today, you know,
*  and I need to maybe refine this definition a little bit,
*  but I'm kind of liking the,
*  people wouldn't, you know, wouldn't get done otherwise.
*  People, you know, don't like to do,
*  like you have to pay them to do it,
*  you know, that only people can do,
*  that there's not really a way to mechanize.
*  Something like that does feel like
*  a pretty good definition of kind of work as it exists today.
*  And I do think that is going to be
*  a significantly shrinking category.
*  Yeah, it is interesting.
*  It does feel like the concept of like,
*  you know, muggles from Harry Potter almost
*  like might emerge in our society
*  and how we think about just like the different,
*  like classes of people and their capabilities.
*  And to some extent, it kind of exists today.
*  Like some people can code and build tremendous things,
*  but it's not as, you know,
*  once those people are like supercharged
*  and the other people are, you know,
*  or many people are like basically replaceable,
*  it does feel like that,
*  that just gap and understanding of people is going to,
*  to why to feel free to challenge any of those premises.
*  But I mean, we talked to Amjad a little bit
*  about the 1000X developer,
*  and that definitely seems like part of the future.
*  It seems like some people are going to be so good
*  with these tools, you know,
*  these programming assistants or whatever,
*  that they can likely will be able to accomplish what,
*  you know, a full team can do today.
*  And I do think it's true that there's like a lot more demand
*  for software, especially at extremely low prices
*  relative to the software that's being created today.
*  But again, I don't know that that's like infinite, right?
*  I mean, we can only, like, what sort of software
*  is there like infinite demand for?
*  I guess, you know, video games,
*  like just software that entertains on some level
*  would be kind of the, you know, end state of like,
*  if there's nothing else to do, then you'll, you know,
*  create things to explore and mess around with.
*  But even then we only have so much time, right?
*  So you can kind of imagine that at some point,
*  if you're getting to, and by at some point,
*  I don't mean like, you know,
*  this is not like a hundred years away,
*  we're talking like a handful of years away maybe,
*  where you can sort of have, you know,
*  a narrative language model type system
*  kind of generate plots of games or, you know,
*  customizations to you from archetypes
*  that have been previously created.
*  And on top of that, you can kind of spin up 3D environments.
*  You can have kind of the language model,
*  speak to another specialist model
*  to generate a 3D landscape for you to explore.
*  And you know, you can do all this
*  in kind of a virtual reality or an augmented reality
*  generated for you on the fly.
*  I mean, how much more software do we need, you know,
*  beyond that, like if you can see a pretty clear path
*  to enough software to entertain people
*  on an individualized level, nonstop.
*  I don't know what, you know,
*  I don't know really what more is needed than that.
*  Like there's language models right now cannot do science.
*  So that's kind of a, you know,
*  I think maybe a really important threshold
*  that we have not hit yet.
*  We've hit a ton of thresholds over the last two years.
*  You know, I can't really write coherent copy.
*  It's not really even useful.
*  It's like a marketing copywriting assistant
*  was like two years ago.
*  And now we're at like closing in
*  on expert level doctor performance.
*  There's a lot of little thresholds
*  that have been hit along the way.
*  We've not yet hit the one where it's like,
*  AI can do original science.
*  So, you know, for now that remains a thing.
*  And similarly with like hardcore engineering, you know,
*  it's not yet to a point where, you know,
*  it's not gonna set up its own semiconductor,
*  you know, supply chain anytime soon.
*  Well, maybe sometime soon, but, you know, again,
*  not with this generation.
*  This generation will not do it.
*  Next generation, as soon as that comes, you know,
*  we'll have to reevaluate all claims.
*  So again, there's like, there are some things
*  that are not in the province of like
*  what a language model can do, even with fine tuning.
*  It's just not there yet.
*  But yeah, it seems like a shrinking category.
*  And it seems like something that fewer and fewer people
*  will be, you know, kind of the rare specialists
*  that have skills that like AI just doesn't touch yet.
*  So I don't have a percentage on that,
*  but it feels like today, you know,
*  how many people are really in semiconductor fabrication?
*  Right, like not that many.
*  How many people are really optimizing at a low level
*  how iOS interfaces with, you know, the hardware?
*  Not that many, you know, it's an important job.
*  It's extremely high skilled
*  and it's not immediately under threat from a language model,
*  but just don't think there's that many people.
*  The other thing I wanted to mention too from earlier
*  was the generational question.
*  And I think this is really important
*  because this is happening so fast.
*  So, you know, there's a lot at this point, right?
*  We grew up in the end of history era,
*  not to get, not to encroach on the MOZ territory
*  and discussion topics here, but it was, you know,
*  kind of assumed for a while that the economy will adjust.
*  And, you know, it's fine if like, you know,
*  I'm from Detroit, I'm in Detroit.
*  It's fine if the car companies, you know,
*  send all the jobs to China or Mexico or Vietnam
*  or what have you, because we'll adjust for dynamic.
*  Everything's gonna be great.
*  And we ran that experiment for like 20 years
*  and it was a pretty gradual process.
*  A lot of people did not adjust in the way
*  that the textbook economics predicted that they would,
*  right, like these, there's towns all over the Midwest
*  that are not what they once were
*  because the main employer or the main factory,
*  whatever is gone.
*  There wasn't a, you know, a full recovery.
*  There wasn't this, you know, there was some adjustment,
*  certainly, but a lot of the adjustment was like,
*  people left the town or some of the other adjustments
*  was like people adjusted to lower standards
*  or standards of living individually.
*  You know, they got jobs that like pay less
*  and are lower status than what they're used to.
*  And people are not happy about that.
*  So, and that's obviously been, you know,
*  I think a significant force in American politics
*  by any telling.
*  That was a slow process compared to what I think
*  we're gonna see over the next two to five years.
*  And if you do those kinds of things
*  on like a generational time scale, as a society,
*  you give, you know, collectively,
*  we would give ourselves the opportunity for, okay, well,
*  yeah, it might suck for this person who's, you know,
*  in their 40s and they've got 20 years of this experience
*  and that job is going away.
*  And, you know, to some degree,
*  there's like greater disruption, nothing we do about it.
*  But like their kids, you know, can come up
*  and kind of adapt to a different reality
*  and they'll be educated in a different way.
*  And they'll, you know, they'll prepare for other jobs
*  and they'll get those jobs.
*  So I think society, I guess what I'm trying to say there is
*  I think society historically has been more adaptable
*  than individuals.
*  And a big part of that, as I understand it,
*  is the generational change that, you know,
*  you can educate the next generation
*  for the opportunities that will exist.
*  And, you know, the previous generation
*  maybe doesn't catch up and that sucks for them,
*  but, you know, that is kind of something
*  that we've tolerated.
*  If that happens to a huge section of employed people
*  over just a couple of years across many sectors
*  all at the same time, then again,
*  I don't really know how we adjust to that.
*  You know, and that's not to say that people
*  would be unfulfilled or, you know,
*  wouldn't be incapable of finding like things to do
*  that are self-actualizing.
*  It's just not clear to me that there's going to be
*  a lot of demand to pay people to do that sort of stuff.
*  You know, like everybody who's ever wanted
*  to take piano lessons and didn't feel like they have time
*  might have time, you know.
*  And the AM might give you the piano lesson,
*  by the way, as well.
*  But there's not necessarily, you know,
*  money waiting for you to like perform at the end of that.
*  So you can kind of play that out across
*  a lot of different things.
*  You know, people have a lot of hobbies,
*  they have a lot of interests, they have a lot of ways
*  that they would like to entertain each other
*  and, you know, socialize and explore.
*  And it could be a very rich, fun, rewarding life,
*  but it seems like the paradigm of like money flowing
*  to those activities does not necessarily cross over
*  as far as I can tell.
*  Is there anything I haven't asked you
*  that I should ask you or any big questions you yourself
*  are having that we have not yet discussed on this topic?
*  The impact of regulation is an interesting one, I think,
*  that could shape a lot of how this plays out.
*  I don't think, I would not expect that we're going to avoid
*  the kind of changes that I'm describing,
*  but I do think, again, like there's a lot of details
*  to be worked out and the timeline and exactly
*  who can do what, under what circumstances,
*  with what licensing and, you know, who's say so
*  is a really big one.
*  Honestly, I've been a little surprised by how slow
*  the interest groups have been in responding to
*  the developments that we've seen.
*  I mean, it seems like there's been more denial
*  than like actual attempts to do something about it
*  for the most part, but just, you know,
*  take a couple leading, you know,
*  American civil society organizations,
*  the AMA and the ABA, you know, the Medical Association,
*  the Bar Association, it seems to me like leadership,
*  leadership of those organizations is going to look at data
*  like this, and they're going to say,
*  we've got to protect our members' interests here.
*  How do we do that?
*  The obvious thing would be to say, we'll make it, you know,
*  we'll try to make it illegal to, you know,
*  like it's already illegal to practice medicine
*  without a medical degree, and it's already illegal
*  to practice law without a law degree or a license,
*  then maybe we can say it's illegal to use
*  a medical language model without a proper license, right?
*  Or at a minimum, you know, it has to be under supervision
*  of a licensed doctor or lawyer or whatever.
*  As of, you know, I don't know, it seems like that
*  should already be happening.
*  Maybe it is starting to happen.
*  We've heard a little bit of noise from the FDA
*  around regulating language models like devices,
*  which means, you know, you do have to show safety
*  and it might just be a safety standard.
*  I would have to double check to see if there's also like
*  a improvement on, you know, previous clinical best practice.
*  A little bit of a difference between device regulation
*  and drug regulation, which I don't have full mastery of,
*  but FDA is starting to get into the game a little bit
*  and kind of saying that this is gonna fall into a device,
*  you know, type of paradigm.
*  I haven't heard a lot from lawyers, you know,
*  I haven't heard as much as I would expect from doctors,
*  but I think that has to be coming.
*  Like I would be shocked if we get out of this year
*  without the first fights ramping up on
*  who is going to be allowed to do what with these models,
*  who's gonna be, you know, responsible for supervising,
*  who's gonna be liable, you know,
*  if open AI is providing something directly to a user,
*  you know, is it their responsibility to make sure
*  that it doesn't, you know, dispense medical advice?
*  Is it, you know, is there some sort of a reasonable standard
*  where they try to filter,
*  but then if you jailbreak it as a user that's on you,
*  you know, these kinds of protectionist questions
*  are gonna bump up against safety questions
*  in kind of weird ways.
*  And everybody of course will want to frame their interest.
*  You know, this is how it's always done, right?
*  The interest group will be framed as being in the,
*  you know, the safety, public safety interest,
*  even though a lot of times it's much more about,
*  you know, protecting the interest
*  of the incumbents in a market.
*  So I'm not, you know,
*  I don't have a lot of predictions around politics.
*  I guess I would be very surprised
*  if there aren't fights about that soon,
*  I would be very surprised if the doctors
*  and the lawyers don't get their way.
*  I would guess that like the higher status
*  a profession is in society currently,
*  the more effective it will be in creating restrictions
*  around the use of language models to do their core stuff.
*  You don't see the same level of, you know, protectionism
*  or organization in like customer service.
*  So the drive through at McDonald's will probably be
*  like language model powered and nobody's going to,
*  you know, nobody's going to stop that, right?
*  Because there's just not that,
*  it's not that powerful of a group there.
*  And, you know, Congress is probably just
*  not going to take it up, but, you know,
*  there's a lot of uncertainty there.
*  If it does play out where there is a lot of restriction,
*  then I think what you get is kind of a leapfrog scenario
*  where, you know, maybe,
*  maybe, you know, strategically,
*  maybe because it's kind of the only way it can go,
*  maybe just because like the demand is so great
*  and it seems like almost irresponsible or immoral not to,
*  you know, maybe these things just get deployed
*  in places where like there just aren't that many doctors,
*  you know, so you think, geez, like,
*  you know, how many doctors per capita are there
*  in like the Democratic Republic of the Congo?
*  Not that many, you know,
*  but people do have cell phones
*  and they do have important questions
*  and maybe they can get those answered.
*  And, you know, maybe that's just kind of
*  where this stuff goes first, right?
*  And kind of works its way up the country ladder
*  by like income, you know, more or less
*  as it becomes clear a bit like it works.
*  And, you know, it's really not in the public interest
*  to restrict this stuff at some point.
*  So eventually that could tip, but, you know, could we,
*  is it conceivable that we could get stuck, you know,
*  in like, say the United States or the West or whatever
*  in a kind of similar spot
*  where we like can't build any nuclear power plants
*  or we like, you know, can't build a second avenue subway?
*  It's conceivable, but I really don't think so.
*  You know, those are fundamentally fixed location.
*  And there's some interesting like political science theory
*  around like what allows a state to pop up, you know,
*  and there's recently a great econ talk about this
*  looking at state formation in locations
*  where grain naturally grows
*  versus where tubers naturally grow.
*  And the big difference between grain and tubers
*  from a taxation standpoint is you can store the grain
*  in a central, you know, silo or whatever,
*  but a tuber, like a potato,
*  once you take it out of the ground, it rots quickly.
*  You can't store it long-term.
*  So looking back in history at the time
*  where states were formed,
*  they see that there are a lot more state formation
*  in the grain areas because there was something
*  that you could tax.
*  Whereas in the tuber locations,
*  you can't really tax the tubers
*  because they rot, so it's pointless.
*  So, you know, they kind of,
*  those locations maintained more decentralization
*  and less state formation.
*  I think there is something similar here
*  where it's like the AIs are,
*  they're not in one location.
*  It's really hard to like choke them off entirely.
*  You know, you know where the Second Avenue subway is,
*  so you can just, you know, stop people from doing it there
*  if that's what you want to do as a state.
*  It's gonna be a lot harder, you know, just like we have,
*  you know, there's the great firewall in China,
*  but there's still VPNs in China,
*  there's ways to get around that kind of stuff.
*  I don't see how, you know, absent like very draconian,
*  like super heavy-handed measures.
*  I don't see how people are going to prevent individuals
*  from accessing their AI doctor, you know,
*  especially as it might get deployed in other countries,
*  right, like if it's made illegal here and OpenAI is like,
*  well, okay, fine, you know,
*  we're gonna respect the law here,
*  but we are gonna go make a, you know, subsidiary in Kenya.
*  And, you know, we'll have our Nairobi office
*  and that will be the place where that, you know,
*  gets run out of and served out of.
*  People are still gonna be able to access that
*  from their devices and their networks in the United States,
*  you know, unless they're, again,
*  unless there's a super heavy-handed
*  regulatory regime on that.
*  So it's just hard for me to see how this stuff gets denied
*  because, you know, there's so many little cracks
*  that can get through, you know,
*  people are gonna be motivated too, right?
*  I mean, middle of the night, your kid's sick,
*  you're thinking, you know, it's winter,
*  you're thinking, God, do I need to go
*  or do I not need to go?
*  You know, I really just wanna talk to somebody
*  and I can do it at 1% the cost, you know,
*  of going into that thing.
*  Like people will be pretty motivated
*  to find ways to access these services.
*  So I expect a lot of drama and a lot of, you know, battles
*  in the regulatory space, but it seems like in the end,
*  that will be more a question of speed
*  than whether or not people, you know,
*  ultimately can consult an AI doctor.
*  It just seems very hard for that ultimately to be prevented.
*  I'm a bit more negative or cynical
*  on what's gonna happen than you are perhaps.
*  I think people are gonna go full on panic mode.
*  I think you already see some of the, you know,
*  like with crypto, you know,
*  it transcended the tech kind of media sphere
*  into mainstream, but the real concern there was,
*  hey, does this thing really do anything?
*  Are there any use case?
*  Is this just speculation?
*  Is this just a waste of time, waste of money, et cetera?
*  AI is similarly broken out of the tech media sphere,
*  but people are, some people will say,
*  hey, this doesn't really do anything special.
*  Even, you know, the people building it
*  will try to downplay it.
*  But then I see, you know, on my podcast feed every day,
*  a whole number of, you know,
*  kind of mainstream podcasts saying,
*  hey, what does this mean?
*  So like, this has already captured the concerns
*  of sort of a media class.
*  And as the thing just gets better and better,
*  I think, you know, those concerns are gonna get louder
*  and louder, and we already have, say like in education,
*  my belief is that education prioritizes the teachers
*  over the students.
*  And sometimes they use the language of kind of student,
*  you know, benefits in order to justify
*  not allowing a school choice, for example,
*  when really it, you know, serves teachers.
*  That's gonna be harder and harder to do
*  as it's clear that AI presents all these opportunities.
*  So they're gonna try to use, or all these benefits,
*  you're gonna try to use the language of equity,
*  but the AI will be available to all, hopefully.
*  So I think it's going to become the contrast
*  between, you know, supporting the beneficiaries
*  of the services versus the providers of the services
*  is gonna become harder and harder to conflate,
*  but still ultimately, I suspect
*  that those stakeholders, the doctors, the teachers,
*  unions, the lawyers, just have so much power
*  that it's, you know, they're going to cause sort of greater
*  negative influence on this than we would want.
*  Can they materially slow down OpenAI?
*  I don't think so.
*  I think what we'll have is just a continuous
*  bifurcated economy.
*  You know, Mark Adreson likes to point to that chart
*  where it says, you know, here are the industries
*  that are affected by government,
*  are regulated heavily by government,
*  housing, healthcare, education, cost just rises and rises,
*  and here are the industries that are not affected by,
*  or are not regulated by government,
*  the cost decreases, decreases.
*  I just think that that will continue to bifurcate
*  in a way that's like unavoidable,
*  and you can't, you know, not see it.
*  Anyway, those are my concerns.
*  I think they're gonna try, you know,
*  a lot of interest groups will try.
*  That seems unavoidable,
*  but it kind of feels like, you know,
*  the rise has been so fast.
*  You can imagine a different world where
*  things were much more gradual
*  in terms of just the rate of capability improvement,
*  and we had more time to sort of be like,
*  yeah, this thing could sort of be your doctor,
*  but it's a shitty doctor, and it's like,
*  you know, it shouldn't be out there.
*  But we kind of just crashed through that world
*  in the last year before anyone even knew what was happening,
*  and so we're waking up, you know, collectively,
*  to a world where it's like,
*  that concern is kind of already over, you know,
*  or it's like very soon to be over.
*  There was just a paper that somebody sent me this morning
*  that was like, GPT-4 beat Medpalm,
*  and then like Medpalm 2, which also just came out
*  like in the last week or two,
*  it was like neck and neck still, seemingly with GPT-4,
*  but it's basically expert level on answering these,
*  you know, standardized medical questions.
*  It just happened so fast, you know,
*  it was like the first people are hearing of it,
*  it's kind of already at expert level.
*  So I think you're right to say
*  it's gonna be increasingly difficult to do that conflation,
*  and it's gonna be kind of more and more obvious
*  that some of these things are just kind of naked power grabs.
*  And then it does remain kind of a question of
*  ultimately like political economy, I do think you could,
*  you know, if you had some heavy handed laws,
*  like you could definitely slow things down,
*  you know, with enough FUD, you know,
*  you could probably scare off, you know,
*  a lot of the consumer population for a bit, at least,
*  I don't even wanna say a while though,
*  because like people already had kind of been out of shape
*  about AI censorship, you know,
*  how are people gonna feel when it's like,
*  I know this thing can answer my medical questions in a,
*  you know, like pretty good, strong, reliable way,
*  but it's not allowed to,
*  and it's not allowed to because of who?
*  You know, because of the doctors, you know,
*  convinced Congress that I shouldn't be able
*  to get these questions answered on my own terms.
*  I mean, we live with a lot of crazy stuff,
*  so that could happen,
*  but I kind of think those curves are gonna bend,
*  you know, I would guess that I would expect convergence,
*  you know, I think costs will ultimately drop
*  even in those government sectors,
*  and for me, it's like a question less of,
*  can that line be maintained and more like, you know,
*  how fast or slow might the retreat ultimately be?
*  And by the retreat, I just mean like,
*  ultimately kind of accepting that more and more
*  can be done by AI and, you know, at 1% of the cost,
*  like there's a pretty good rationale for it.
*  It seems like we're headed for just, you know,
*  kind of a consistent advance on that front.
*  I'd be surprised, you know,
*  I'd be surprised if they can hold the line, you know,
*  or really, I mean, by they,
*  I mean like any of these kinds of interest groups
*  that might try to say, you know,
*  there should be no direct consumer access
*  to an AI lawyer or an AI doctor, you know,
*  it must be done this certain way.
*  I don't think that's gonna hold for super long,
*  but maybe a few years, you know, five years,
*  like it wouldn't be crazy to me if we, you know,
*  are sitting here in 2028 and we're like,
*  because we've done, you know, we've done dumb stuff, right?
*  We put a lot of people in jail for nonviolent crimes.
*  Like there's certainly moral outrages where it's like,
*  how is it that the, you know,
*  the quote unquote little people in our society
*  are getting, you know, treated so badly
*  based on some high level conceptual, you know,
*  conceptual argument about, you know, safety.
*  Now that could happen again, but you know,
*  we've largely backed off of the war on drugs
*  and people largely seem to agree now
*  that like way too many people are in jail.
*  And I think this kind of,
*  it's gonna be just even way more obvious, I think,
*  in the case of the doctors,
*  like who's really being harmed here?
*  Who's really being protected?
*  Yeah, hard for me to imagine that it goes five years
*  before people, you know, have pretty good direct access.
*  That's optimistic note to wrap on it.
*  And maybe we'll wrap here, but I'll try one more
*  kind of line of question, which is this idea of,
*  you know, earlier we were talking about,
*  hey, we're gonna need to figure out
*  what people are going to do.
*  And it is interesting because the last, you know,
*  decade or a couple of decades,
*  we've really worried about blue collar automation
*  and what the truckers, et cetera, are going to do
*  and how they're going to find meaning
*  once we no longer need them.
*  It just turned out we need them longer
*  than we thought we would.
*  But we thought of all sorts of things from UBI,
*  but then we said, hey, is UBI really gonna fill
*  their sense of meaning?
*  And I think it's interesting because to the degree
*  that it's coming for actually white collar work,
*  you know, people who work in white collar work
*  are probably more sensitive to feeling useful,
*  to status concerns about their importance,
*  given how hard they've worked their whole life
*  and to rise up these respective ladders.
*  Of course, blue collar people work, you know,
*  just as hard in their own way,
*  but white collar people are used to climbing up
*  the ladders of success and being told their whole lives,
*  you know, how successful they are and how special they are
*  and how important they are.
*  And it's going to be just a huge shift in morale.
*  And even like myself, I've started to feel like
*  a little deflated when I see, you know,
*  my abilities to synthesize information or summarize
*  or, you know, create conversations
*  or have certain analysis on certain things
*  just be dwarfed by chat, GBT, et cetera.
*  And so it's not a question of UBI as much as, you know,
*  the resources as much as how are people
*  going to feel important?
*  How are people going to feel needed in ways that, you know,
*  fulfill the ways in which they wanted to be needed
*  or prepared to be needed their entire lives,
*  going through all these hoops, et cetera,
*  of school, grad school, jobs, et cetera.
*  Yeah, I mean, in some sense,
*  I think it's another way in which this AI technology
*  in general is kind of a great leveling force.
*  It seems like there's a definite strain in politics
*  that is kind of resentment of one class of people
*  who feel and, you know, say that they got where they are
*  based on merit and their unique abilities, you know,
*  and the wisdom of the market, you know,
*  that values it highly.
*  And, you know, I think that we're all going to be
*  in much more of a similar boat, I think, there, you know,
*  before we know it.
*  So, you know, maybe we, you know,
*  one optimistic take on that would be like,
*  maybe we can all be a little bit nicer to each other
*  knowing that we're kind of all under some similar pressures
*  in that respect, you know,
*  that could be in some sense good.
*  I do think people are going to, you know,
*  react to all sorts of different ways to it.
*  And we've been seeing things like,
*  I just saw something from a 3D artist who was like, you know,
*  in fact, I think you've sent it to me that was like, you know,
*  I just lost everything I loved about my job.
*  Now I sit here on prompt mid-journey all day
*  and it kind of sucks.
*  And I'm like, I don't feel creative in the way
*  that I loved being creative before.
*  There's probably going to be a lot of that.
*  I don't really know that there's any way around it, honestly,
*  at this point.
*  You know, the flip side of that is some people are tremendously
*  empowered by it.
*  You can, you know, for every one person like that,
*  you can also go find somebody else.
*  It's like, I've always had great stories in my mind,
*  but I was never able to visualize them and now I can.
*  So I think you do see, you know, both sides of that trade off.
*  Another idea that I've, excuse me,
*  thought is really interesting is this flip
*  from humans seeing themselves as like distinct from the animals
*  and sort of, you know, it being our justified privilege
*  to rule the world based on our intellect to now,
*  there's kind of the reverse of that where it's like, well,
*  what makes us special relative to the AIs is that we feel,
*  you know, that we have these kind of animal-like,
*  not animal-like, animal, you know, traits that we
*  at least are pretty confident don't exist in the AIs
*  as they exist today.
*  So our, you know, our feeling, our emotion,
*  the sort of realness of that is kind of, you know,
*  what some people are now trying to kind of set up as like
*  the specialness of humans, but it is interesting that that,
*  that stuff is largely shared, you know, with the animals.
*  So, you know, what separates us from the animals and what,
*  you know, puts us kind of in the same bucket as the AIs
*  and what separates us from the AIs,
*  puts us in the same bucket as the animals.
*  We're like in the center of that Venn diagram for the moment.
*  But yeah, I think it's going to be tough.
*  I do think there's certainly going to be a loss of kind of
*  sense of specialness to the intellect, you know,
*  the things that we can do.
*  Like I saw another, I saw a TikTok of this with a doctor
*  sitting there at, at chat GPT, talking to GPT-4,
*  getting like a amazing diagnosis and feeling like,
*  guys like, bro, I went to med school for four years.
*  This thing just spits it out.
*  Like, you know, and he's feeling defeated,
*  like exactly like you said.
*  But what was really interesting to me about that video,
*  I'll see if we can find it, maybe we can put it
*  in the show notes, top comments.
*  This was, you know, this video went viral, right?
*  So tons of views on it.
*  The comments had thousands of, of hearts.
*  The top comments that I saw were all women saying,
*  well, maybe at least chat GPT will listen to me
*  when I go in and talk about my problems.
*  So, you know, I don't know.
*  That's, that's really, that's tough.
*  Like that you've got the doctor that is, you know,
*  feeling like you described defeated, like what,
*  I worked so hard, you know, I was on this path to success.
*  Now, like my status is in jeopardy.
*  But again, you see you're just in that same, you know,
*  one little TikTok interaction, a real pent up sense
*  that like, yeah, but you're not, you know,
*  not you this one doctor, but like doctors
*  aren't necessarily serving all of us super well.
*  And we do see a lot of upside in an AI
*  that might be a little more patient, you know,
*  that might actually listen to us
*  when we feel like we weren't listened to by, you know,
*  doctors before.
*  So we're going to have to find something else.
*  You know, I think relationships obviously is a,
*  you know, in just about every like wellness,
*  you know, life satisfaction type of study, quality,
*  number and quality of relationships
*  are some of the biggest factors determining
*  how people feel about their lives.
*  It seems like an emphasis on relationship
*  and relationship building is probably a big part
*  of where we might go.
*  That's again, kind of connected, you know,
*  my earlier idea about like highly bespoke,
*  highly idiosyncratic, you know,
*  highly local custom services, you know,
*  that's kind of like commercialization
*  of just like relationship, you know,
*  and kind of community.
*  Some of it, you know, is maybe paid and some of it isn't,
*  but it seems like there's a lot of potential there
*  for people to enrich their lives.
*  As long as replica doesn't get so good, you know,
*  that that also gets crowded out by language models.
*  And certainly, you know, I think that will be
*  an element of the future too,
*  but I don't feel like I have answers, you know,
*  for what happens with society, you know,
*  just seems like everybody's incentive,
*  we're headed kind of to a new equilibrium
*  where like everybody has the same incentive
*  and you kind of can't not do it.
*  You know, if all of the other doctors offices in an economy
*  are like now 24 seven scheduling, you know,
*  just to take the beginning of the transformation,
*  like how are you not gonna do that?
*  You know, how are you not gonna sign up?
*  How are you gonna be the one that's like,
*  well, actually we only take calls nine to four,
*  but it's also more expensive as you know,
*  the good thing is it's less convenient and more expensive.
*  So, you know, that's why you should continue to choose us.
*  Like it's just tough, you know,
*  the incentives are all toward rapid adoption
*  and like I think we're gonna kind of have to sort out
*  our feelings separately from how, you know,
*  the actual structure of how stuff gets done evolves.
*  It is interesting, like one of the prominent narratives
*  that even, you know, people as left-wing
*  as Ezra Klein are promoting is this idea
*  that even liberals are, although well-intentioned,
*  are making the sort of government regulations so complex
*  that we have kind of a, use someone else's word,
*  I can't remember who, a vetocracy
*  where it's just so easy to veto things,
*  to shoot them down and I think we'll see
*  in the next few years or even much sooner
*  how much power these organizations,
*  these related agencies actually have
*  where in the face of a obviously evidently, you know,
*  better solution for the customer or constituent,
*  you know, will they prioritize that
*  or will they prioritize the provider
*  or the group that's providing it, the service?
*  Even when it's so clearly at the expense.
*  Maybe we'll wrap on that.
*  Does that sound like a good complete stop
*  to the conversation?
*  Yeah, well, we'll certainly have time to continue it
*  and in kind of keeping with the general philosophy of this,
*  you know, the note to listeners would be like,
*  I think this is an honest take that we really
*  aren't ready for, you know, all of the change
*  that is coming at us.
*  As Tyler Cowan said, like a lot of copes
*  coming from a lot of directions.
*  This is an attempt to be the sort of cope free zone
*  and, you know, really try to understand
*  the technology on its own terms,
*  what it can and can't do on its own terms,
*  you know, how it is likely to be applied
*  based on the strengths that it clearly has
*  and the weaknesses that it still has as well.
*  That unfortunately at this point in time
*  does not lend itself toward, you know, tidy answers
*  or like comfortable, you know, high confidence outlooks.
*  And so, you know, we just have to invite you
*  to think about that a lot on your own as well.
*  And, you know, continue to participate
*  in this conversation.
*  I think that's really all we have right now
*  is kind of figuring out as fast as we can
*  where things are going in an environment
*  where there is a lot of uncertainty.
*  Great to close on.
*  Nathan, as always, thank you for having
*  a wonderful conversation and until next time.
*  My pleasure, thank you, Eric.
*  Omniki uses generative AI to enable you
*  to launch hundreds of thousands of ad iterations
*  that actually work, customized across all platforms
*  with a click of a button.
*  I believe in Omniki so much that I invested in it
*  and I recommend you use it too.
*  Use Cogrev to get a 10% discount.
