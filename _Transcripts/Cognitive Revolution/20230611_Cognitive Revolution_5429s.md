---
Date Generated: April 03, 2024
Transcription Model: whisper medium 20231117
Length: 5429s
Video Keywords: []
Video Views: 515
Video Rating: None
---

# The Consumer Rights Revolution with Joshua Browder of DoNotPay
**Cognitive Revolution "How AI Changes Everything":** [June 11, 2023](https://www.youtube.com/watch?v=ejB2kvwb4nI)
*  My admission is if the big companies are using AI,
*  consumers should have access to it too.
*  I think the whole financial system is stacked against
*  an average person where if you get a wire transfer,
*  it charges a fee unless you have a lot of money in your account.
*  It's cash or check if they charge a fee, all of this stuff.
*  What angers me the most is these large banks and
*  financial institutions not paying people any interest,
*  but also at the same time charging
*  huge amounts of fees to ordinary people.
*  That's also a good job for AI where you can link your bank account,
*  and AI goes in and finds
*  all the areas that people are being ripped off.
*  Our AI said, I'm not an AI,
*  I'm just a consumer that knows my rights.
*  The AI is lying to keep it going.
*  It really is an arms race to
*  keep getting these successes for consumers.
*  Hello and welcome to the Cognitive Revolution,
*  where we interview visionary researchers,
*  entrepreneurs, and builders working
*  on the frontier of artificial intelligence.
*  Each week, we'll explore their revolutionary ideas,
*  and together we'll build a picture of how AI technology will transform
*  work, life, and society in the coming years.
*  I'm Nathan LeBenz joined by my co-host, Eric Thornburg.
*  Hello and welcome back to the Cognitive Revolution.
*  Today, I'm talking with Josh Browder,
*  founder and CEO of Do Not Pay,
*  the world's first robot lawyer.
*  Josh has been called by the BBC the Robin Hood of the Internet.
*  He and the Do Not Pay team have been helping consumers fight for
*  what's rightfully theirs for a number of years already,
*  and have been aggressive early adopters of
*  LLMs as they've recognized that nobody has time to spend filling out forms,
*  waiting on hold, processing paperwork,
*  or negotiating for refunds and discounts,
*  making all of this activity the perfect job for AI.
*  In this conversation, we cover a range of topics,
*  including how Do Not Pay works today,
*  how that's changing with the implementation of advanced AI systems,
*  how larger companies are responding and using AI in their own right,
*  what an AI-powered consumer rights arms race dynamic might look like in the medium term,
*  why Chinese consumers have so much higher standards than Americans,
*  what sorts of regulations and liability standards might make sense for AI,
*  the future of high-cost sectors like education and medicine,
*  as well as the future of special interest protectionism and employment in general.
*  We also touch on whether we may soon have a right to an AI lawyer,
*  the case for a universal basic income,
*  how Do Not Pay is stretching its own AI budget,
*  and lots more along the way.
*  I think this conversation is a great opportunity to begin to game out and plan
*  for possible midterm future scenarios.
*  While we definitely shouldn't become overconfident or attached to any particular possibility,
*  as the saying goes, plans may be useless,
*  but planning is essential.
*  Sharpening up my own midterm worldview and helping you develop yours,
*  while hopefully improving AI discourse in general,
*  is the mission of the cognitive revolution.
*  So if you're finding this valuable,
*  I would ask you to take a moment to share the show with a friend
*  who you think might also benefit from a deeper, more multifaceted understanding of AI.
*  With that, I hope you enjoy this conversation with Josh Browder of Do Not Pay.
*  Josh Browder, welcome to the cognitive revolution.
*  Thank you for having me.
*  Very excited to have you.
*  I have been a follower of your company,
*  Do Not Pay, the world's first robot lawyer for a number of years now.
*  And I think you're one of these entrepreneurs who's in an extremely interesting position
*  where you've been building this business before the kind of modern AI moment really took off,
*  but obviously you've seen the potential of it and really rushed to embrace it
*  and already kind of gotten yourself out to the frontier of what is possible.
*  So maybe for starters, can you just kind of introduce the company,
*  you know, your original vision for it and how that has grown over time as AI has come onto the scene?
*  Yes. So I started the company, Do Not Pay, in 2015, almost eight years ago.
*  So I'm getting old.
*  And I started it because I got a bunch of parking tickets.
*  I have a British accent.
*  I moved from England to study at Stanford.
*  I will use the excuse that everyone drives on the other side of the road,
*  but in reality, I was a terrible driver.
*  But I learned something remarkable, which is if you know the right things to say, you can save a lot of money.
*  And I created the first version just with templates to help my friends.
*  And I could never have imagined that it would be so popular, appealing hundreds of thousands of tickets.
*  And that's what made me realize that this idea is bigger than just tickets and I should expand to all of consumer rights.
*  So I spent the past few years working on these templates to help people with consumer rights.
*  But now what's really exciting in the AI era is we're going through AI and that's increasing the value of the disputes we can fight and also our success rate.
*  Give us a little bit of a sense for how that worked in the early days, because I think the contrast is super interesting.
*  And I've been in a similar spot with my company, Waymark.
*  We help people create video content and the hornet's nest of rules based approaches that we had created up until a few years ago.
*  That has now been washed away entirely by language models that we fine tune for the purpose.
*  It's sometimes hard to communicate to people just how much of a nightmare it was before and what a delight it is now.
*  So I'd love to hear your take on that transition.
*  Yeah, so rules based approaches can have some success.
*  Otherwise, no one would do them at all.
*  With consumer rights and very simple legal disputes, it makes sense because the law is very formulaic.
*  So imagine with a ticket, you can pick a defense.
*  For example, the signage was not correct and it would pick a template letter that said that they pulled the San Francisco Signage Law,
*  insert that into a letter and send it off to the right place.
*  Similarly, if the in-flight Wi-Fi doesn't work, we had a great template that would send the most aggressive letter ever to United Airlines to get your money back.
*  And the letter was scary enough that the big companies like United would do so.
*  The problem with templates is that they get old quickly.
*  If you submit 10,000 templates to a single source, they'll start ignoring them.
*  And so what we started to do was randomize the templates.
*  But even that, you could kind of tell that it was a template.
*  And also, it wouldn't be versatile.
*  Users might not pick the right template.
*  They might pick the wrong template, all of that sort of stuff.
*  Whereas AI, you could just match natural conversation to what should actually be done on the back end.
*  Your comment there about the companies beginning to react to the template letters,
*  as they would kind of start to detect that they're getting a lot of these that look the same,
*  I think is an incredible foreshadowing of a lot of the stuff that I really want to get into with you,
*  which is kind of how the world evolves as AI comes online and not just people start to use it,
*  but then people start to react to that.
*  And there's going to be all these kind of escalations and dynamics that I find kind of hard to predict.
*  But I think you probably have one of the best viewpoints on trying to anticipate where that's all going to go.
*  People say sometimes, and I think it's definitely true, that life is like a lot more expensive, paradoxically,
*  when you're poor and there's all these kind of petty injustices that people have a hard time fighting.
*  What are the ones that you are just like super outraged about and super focused on as a result?
*  Yeah. So at a high level, DoNotPay is a robot lawyer that helps consumers fight for their rights.
*  And we have over 200 use cases since we started with parking tickets many years ago.
*  Things like getting refunds, canceling subscriptions, negotiating bills, getting out bank fees.
*  I think the whole financial system is stacked against an average person where if you get a wire transfer,
*  it charges a fee unless you have a lot of money in your account.
*  It's cash or check if they charge a fee, all of this stuff.
*  And so what angers me the most is these large banks and financial institutions not paying any people any interest,
*  but also at the same time, charging huge amounts of fees to ordinary people.
*  And that's also a good job for AI where you can link your bank account and AI goes in and finds all the areas that people are being ripped off.
*  I think we have a big problem in society of concentrated benefit but spread out harm.
*  So what I mean by that is Wells Fargo can charge one million people a $10 fee.
*  They make $10 million, but the people being charged $10 can't afford to fight back because the money amount is so small
*  and everyone is busy with their jobs and life and they don't have time to do so.
*  Yeah, interesting. So I kind of think of you as like the AI Robin Hood.
*  I don't know if I am the first to use that label for you, but how do you feel about that?
*  Would that be like a badge you would wear with pride or would you revise the notion somehow?
*  That's my goal. It's something hard to live up to.
*  But I think the great tragedy with AI and any new technology is that it typically gets in the hands of the most powerful first.
*  You see that large corporations using AI, you see actually in sentencing guidelines,
*  the judges where the reports are generated using expert systems and some AI already to say literally putting people in prison.
*  But for consumers, there's not really being much done.
*  And so my goal is to give power to the people and fight back.
*  Interestingly, we have AI products where it negotiates bills with utility companies like Comcast.
*  I know you submitted a Comcast dispute and our bot will go on Comcast chat and negotiate with them to get a bill reduced.
*  And it's obvious that on that they're and they're using AI.
*  So the two AIs are talking to each other.
*  And so my admission is if the big companies are using AI, consumers should have access to it too.
*  I think it is a really maybe emblematic of the future that we're all headed toward.
*  So I go into do not pay as a customer.
*  And I'm thinking to myself, OK, what are the things that are like annoying me most financially right now that I might
*  otherwise just kind of live with?
*  And, you know, shout out to Xfinity for topping that list at the moment.
*  I've had the same plan right for whatever however long couple of years that I've lived in this house about the best
*  Internet package that they offered at the time.
*  I was pretty sure it was like unlimited.
*  And all of a sudden, somehow I've started to get these $15 incremental overages when I like use more data that I guess maybe they changed the terms.
*  Maybe I didn't understand the terms, whatever.
*  So now I'm like, all right, it's time to renegotiate.
*  A couple of things stood out to me about the beginning of the process.
*  One is that you're using kind of a chat like experience to guide me through that process.
*  It's not a traditional, you know, here's a web form where you're going to fill everything out, but it's a little bit more of an interactive,
*  you know, dialogue type experience just to even get the tickets submitted.
*  So I'd love to hear a little bit more about that.
*  And then really curious to hear, OK, now what's going to happen behind the scenes as you guys go engage Comcast for me?
*  Another transition with AI is we're looking to go from reactive to proactive.
*  So what I mean by that is you submitted your bill to Comcast.
*  We'll get a refund because Comcast we're very successful with.
*  But you have to submit the bill in the future.
*  What we want to do is we're actually you just wake up one day and the AI says, hey, I saved you $50 because I noticed you overcharged.
*  So we're going more in that kind of proactive direction in terms of how it works.
*  It will go to Comcast and chat with them.
*  And a GPT-4 bot will go in and negotiate a bill for you.
*  And I think we have your account because you sent it to us.
*  So what I'll do is I actually send you the video of what goes on behind the scenes with Comcast on the back end.
*  We've been doing this since GPT-3.
*  And interestingly, GPT-4 pushes back a lot harder during these bill negotiations.
*  So with GPT-3, Comcast would give some noble offer.
*  They would say, OK, I'll give you $20 off.
*  I'm sorry you didn't know about the overage charges.
*  And GPT-3 would be say, great, thank you so much.
*  And GPT-4 now says, no, that's not enough.
*  I want more.
*  We managed to get like a few hundred dollars back.
*  So like a 10 times improvement in success rate from 3 to 4 in GPT.
*  Interestingly, we had another utility company we were doing this with and they said, we don't accept AI disputes.
*  And our AI said, I'm not an AI.
*  I'm just a consumer that knows my rights.
*  And so the AI is lying to keep it going.
*  And so it really is an arms race to keep getting these successes for consumers.
*  OK, a lot to unpack there for sure.
*  So the ethical question is probably the most interesting, but I'm also a big fan of the practical.
*  So starting there, when this happens, are you running like an in browser kind of thing where you sort of set up your agent to click the buttons and type into the inputs?
*  Yeah, so we have a Selenium bot and this is another rules based versus AI thing.
*  In the past, we would manually triggering the bot with DOM elements on a web page and things like that.
*  But even the Selenium bot is now having AI to improve.
*  So if Comcast changed their website layout slightly, it still works and things like that.
*  The breadth and the kind of challenge of that product alone seems pretty substantial, as I'm sure you're well aware.
*  There's a number of companies that are trying to make your kind of browser co-pilot or your kind of agent that you maybe kick off in the browser that runs sort of in the background.
*  We've talked to a couple of different agent, AI agent companies on the show and have a couple more, I think, coming up as well.
*  You're in a sense kind of in that space, although with more kind of tailored use cases, it seems.
*  How do you think about where you want to draw the line on your product there?
*  Because presumably you're not trying to kind of be the everything agent, but it sounds like you're also kind of headed that direction.
*  I've worked on my company long enough to know one has to make idiot proofs.
*  And the problem with these agents is the people, ordinary people in middle America, in Ohio, aren't going to download a Chrome extension and have an AI agent.
*  And if they are, it will just be their phone or the operating system.
*  And it will be so simple. And so what we think about do not pay is the problem rather than some fancy AI agent.
*  The problem is that it wants to consume a download to a Chrome extension and logs in and all of this stuff.
*  They might as well just chat with Comcast themselves.
*  The whole point of them using this technology is that they don't have time to do it.
*  And so it should just work for them in the background.
*  And that's what we're trying to get to with the proactive approach.
*  I'm very skeptical of the AI agent companies because I think that eventually it will just be built into the phone or the Apple glasses coming out soon and things like that.
*  So we do want to do a lot. We want to do all of consumer rights, which is a huge challenge because America is a very broken country.
*  But at the same time, we're not going to help people order pizzas.
*  Prior to AI, I've done a bunch of things with Selenium bots and kind of web scraping.
*  Again, at my company, Waymark, we have this challenge where businesses show up, business owners typically show up at our product.
*  And I don't know why nobody else really seems to do this, but a huge challenge is just the friction of creating your account, setting up your profile.
*  People are going to create videos. They need to import their color palettes and their imagery and whatever.
*  So we've for a long time tried to automate that process, and it's also been transformed by AI from rules based to much more AI based.
*  So I definitely kind of understand that stuff.
*  But one of the challenges I always find so hard is authentication.
*  When you want to do something in a Selenium bot, do you log in?
*  I noticed when I went through the Comcast thing, I gave a screenshot of the bill, which was interesting.
*  And I assume you're OCRing that and parsing, structuring that data out, but then also gave my account ID and even my password.
*  And I was kind of like, well, I've followed this guy for a long time. I trust him.
*  But I wonder how you think about that security layer where people are kind of...
*  First of all, is that something that generally people are willing to do or do you get hesitation there?
*  And then, is there a better way than this kind of handoff of the password account controls to the bot?
*  Do not pay would not have been possible 10 years ago.
*  Ten years ago, we didn't have plat. Consumers weren't really comfortable sharing any of their passwords.
*  But now I think the culture has changed.
*  And so a lot of people are comfortable sharing their passwords because it gets results for them and saves them money.
*  Hey, we'll continue our interview in a moment after a word from our sponsors.
*  Omnike uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work,
*  customized across all platforms with a click of a button.
*  I believe in Omnike so much that I invested in it and I recommend you use it too.
*  Use Cogrev to get a 10% discount.
*  In terms of forces that we have against us, you're right, we have a lot.
*  These companies do not want to give up the refunds, and so they have all these authentications,
*  captures and things like that.
*  One tailwind we do have, though, is we're focusing on legal rights.
*  So there are a lot of companies in the past era that focused on automating customer service disputes.
*  One company that comes to mind is something called Paribas, which the RAMP founders previously founded.
*  And what it did was it helped automate credit card price protection policies.
*  And it was hugely successful.
*  A consumer would log in, provide their bank info, Amazon info, and it would scrape all of their purchases
*  and initiate price protection with their Chase card.
*  The problem is Chase only offered price protection because they thought no one would use it.
*  And AI comes and automates it, and then they decide to shut down all price protection on all of their cards.
*  And Paribas had to sell because of that.
*  What we focus on in contrast is US law.
*  And because we focus on the law, once we have a certain amount of information, we can almost guaranteed submit a correct dispute.
*  So one example would be credit report disputes.
*  There's a great law. It's called the Fair Credit Reporting Act, which says that if you submit a dispute and it's signed
*  and it has the address and it's correctly formatted, the company has to accept the dispute.
*  So our only issue is how can we get that data with as little friction as possible?
*  And that's what we're working on.
*  Maybe it can scrape your email.
*  Maybe it can get public records so you don't even have to give us your last four of your social.
*  And so there's not even that trust element there.
*  But that's that's our superpower.
*  We have the legal system behind us, which has existed for hundreds of years and laws aren't going to change overnight just because the company is unhappy.
*  So is that also the case in the Comcast example specifically?
*  Like, do I have legal rights there or am I just in a test of wills?
*  No. So the legal rights would be it would say FTC statutes.
*  It would say, I'm not sure if you said why you're upset with Comcast.
*  If you did, it will it will convert that into FTC laws.
*  And FTC laws are so broad.
*  It's like any sort of misleading stuff is against the law.
*  And so it will say you've broken this misleading FTC law and Comcast received this and it's just some agent or maybe even some AI.
*  And they don't want to have to deal with this. So they just press the refund button.
*  How do you think today when your GPT-4 bot is going in and talking to Comcast?
*  As you said, the laws don't exist for this yet.
*  And so we have people are kind of exploring all these different scenarios.
*  You've got I think chat GPT is kind of the anchor example of like while it will chat with you about anything largely,
*  they have branded it and even named it and certainly kind of sculpted its behavior in such a way where you get pretty frequent reminders that you're dealing with an AI and it's like not trying to be your buddy.
*  And I think the interaction there is pretty clear.
*  Then we see all these other things where we're like, hmm, that could be kind of weird or problematic.
*  We had, for example, the CEO of Replica on an earlier episode.
*  And I think they also take a very responsible approach to making clear to users what the deal is here.
*  But it's definitely more kind of fraught territory because what is the future of AI friends going to look like?
*  That's anybody's guess.
*  You're doing something that I would normally think might be outside of what I would consider appropriate.
*  However, given the power dynamics, I'm a lot more inclined to consider it where you're not telling Comcast you're an AI as you said, even willing to lie about it if it comes to that.
*  So how do you think about the ethics of that?
*  First of all, just today, I think that these disputes are so simple.
*  It really saves everyone time.
*  And when Do Not Pay first launched, we launched city by city and we launched in Los Angeles and NPR asked Los Angeles, what do you think of a service like Do Not Pay helping to appeal parking tickets?
*  And the head of the parking ticket division of Los Angeles said in the most great spin I could imagine, they said, we actually like it because people write such gibberish in their parking ticket appeals.
*  At least when it comes from a templated service, it's standardized and easy to process.
*  And I think that ultimately, it's positive sum.
*  As I mentioned, these companies are already using AI.
*  I don't think they're telling consumers if there's AI on their end.
*  And so consumers should have the option to use the same and it can save everyone time.
*  No one has time to argue over $20 or $100, not even the big companies.
*  And so it can make society more efficient.
*  For consumers, though, one really does have to disclose the AI is being used.
*  And there's actually a new legal theory.
*  There's all these class actions being filed in California against chat bots because they're saying that AI is secretly reading the messages against like customer support bots and things like that.
*  And so it would be interesting to see where that goes.
*  One of the kind of very simple candidate regulations that I've thought generally positively about has been at least championed by Yuval Noah Harari, who has said first regulation should be that AI must disclose that it's AI.
*  And I guess I wonder, first of all, would you support something like that?
*  And even if you had to then abide by it, and how do you think that would start to shape the landscape if a rule like that were dropped into place?
*  I think that it's surprising this is coming from someone so smart because I think that it's impossible to do that.
*  If you use autocomplete on iMessage, that's coming from AI.
*  But should that have in brackets, this was written by AI.
*  I think AI will be so ubiquitous in our lives that any sort of disclaimer is just holding back the technology.
*  If I were to support it, I would say that it should only be for consumers, but communication to businesses shouldn't have AI.
*  Any sort of regulation I've learned the hard way will be abused by lawyers who come up with these theories and they'll just go crazy and it will just hold back innovation.
*  Because regulation is easy to comply with for the big companies and the Apples and Googles of the world and open AI.
*  But smaller companies, not just Do Not Pay, but other customer support startups and things like that, will have a hard time.
*  So I'm not a big fan of regulation in general.
*  I don't think there's a problem where consumers are being tricked by AIs.
*  And to the extent that they are with scammers, with their relatives calling them up, the criminals are not going to comply with the laws and it will really just hurt businesses.
*  So I think your autocomplete point is a good one.
*  And the fuzzy line of what's autocomplete versus what did you actually write is getting fuzzier all the time as the autocomplete suggestions get longer and more robust.
*  So I think that's apt.
*  I wonder if maybe there could be a line still drawn around whether or not there's a human in the loop, pushing the send button.
*  We have these systems, for example, where like a human agent sits there and gets kind of candidate messages, but still is kind of operating controls versus something where there's just no human in the loop at all.
*  And you're just like totally interacting with the bot.
*  Anything there where you think you could kind of delineate something meaningful?
*  Yes. So I think for serious issues, that definitely has to be the case.
*  There's a lawyer right now in New York federal court who's got in huge trouble because he used chat GPT.
*  I'm not sure if you heard about this, too, generate one of his briefs and chat GPT made up cases and he just trusted the AI blindly and filed the case.
*  And it turned out all the cases were fake and the judge is not pleased.
*  And so he might go to prison or lose his law license.
*  And so I think blindly trusting AI and signing off on it in serious issues like federal court is a bad idea.
*  But I think for minor issues, it can help us a lot.
*  And every time someone has to disclose something, it almost reduces the benefit of the AI.
*  I also think that no one really cares.
*  They just care about the results.
*  I'm sure replica has disclaimers and chat GPT also has disclaimers.
*  This is an AI. I don't trust anything you're saying.
*  But people still just jump over the disclaimers and stuff.
*  So I do not pay even has disclaimers as well.
*  When you sign up, it says we're not a lawyer.
*  Things are generated automatically, things like that.
*  But people just want results.
*  In middle America, they just want to save their utility bill.
*  And so all of this over intellectualization is kind of like a academic problem versus a problem that real people care about, in my opinion.
*  Yeah, I think that's certainly for today.
*  I think that's that's fair.
*  And I can imagine a sort of even more dystopian future of the web where it's like,
*  now I have to accept all cookies and accept that I'm going to talk to AI and it's like on every website.
*  And it's sort of like I'm numb to those things already.
*  And I still, though, do feel like as I extrapolate this farther out, the dynamics become very hard to predict.
*  This is kind of a really interesting.
*  I wouldn't say we're in this conversation pattern quite yet, but a conversation pattern that I often
*  observe in the world is people are like, hey, shit, we just created AIs that are like better than the average human on most tasks.
*  And they're getting close to expert performance on a lot of tasks.
*  And that seems like a highly unpredictable technology that could play out in a lot of ways, good and bad.
*  And then other people are like, well, unless you can give me a specific way that it's going to be bad, that I don't want to hear anything about it.
*  Where do you think the burden of proof ultimately should be on?
*  Questions of like AI regulation and AI ethics, like who owns the ball or who should own the ball?
*  I completely agree with you.
*  It's not enough to just rest on our laurels and say everything will be great.
*  And I think we should ban AI for evil use cases.
*  So one example, lots of debt collectors are using AI right now.
*  They just have these prerecorded AI voice messages.
*  Instead of being able to call a thousand people a day, they can call a million people a day powered by AI.
*  I think we should ban AI in that collection.
*  I think AI should be completely banned in sentencing people.
*  In the UK, the country where I'm from, kind of expert systems are being used to give people speeding tickets.
*  So now in London, it's not that you just drive past a speeding camera.
*  If you go from two cities too quickly, the AI says, wait a minute, you got to the second city too quickly.
*  So it's not even just driving past a camera anymore.
*  It's like the entire road network with AI is giving people tickets.
*  I think that's inappropriate.
*  So I think we need to come up with all of the evil things that happen in society and create regulations to stop AI being used for evil.
*  And this is not a new thing.
*  In 1991, they passed a law against robocalls.
*  And in that time, recorded, pre-recorded voices were a big problem where someone would record a human and that recording would be like dialed a million times.
*  But now we need to update that law to say AI phone calls from debt collection and all these sales calls and things are also a problem.
*  So I think just ban for evil.
*  Could you just use open AI to do debt collection interaction or would they kind of shut you off, you think?
*  So they're terms of service.
*  They thought about a lot of these use cases.
*  I don't think they explicitly ban debt collection at the moment.
*  I know they ban lobbying.
*  And that's another evil use case.
*  Imagine someone pretending to be a politician phoning you up with Hillary Clinton's voice or something like that.
*  So I know that is banned, but I'm not sure about that collection.
*  But the stack there, so maybe they can use open AI, maybe they can't.
*  They certainly could go, especially if they're not too concerned about a commercial license, which I suspect most are not.
*  They could certainly go grab a...
*  I shouldn't cast aspersions too quickly.
*  Some, I imagine, are willing to cut some corners there at least.
*  They could certainly go get like a llama and fine tune it and kind of power their dialogue that way.
*  And then use just a commercial text to speech generator and kind of spin up a little bot and unleash it and see what happens.
*  How far do you think they are in terms of their sophistication right now?
*  I think a lot of them, there's like 10 different ways to get access to GPT-4.
*  You can go through Microsoft, you can go through open AI, you can go through lots of third party kind of aggregators of APIs.
*  So they're probably using the best stuff out there.
*  The open source stuff is catching up.
*  I don't think we can rely on gatekeepers and platforms to stop this because the technology is improving so quickly.
*  I think you have to rely on the law and I would say to stop it.
*  I think the political thing is a perfect example of where you definitely want it saying it's AI.
*  So I do agree with you. I don't want to be too relaxed about this issue.
*  There are definitely areas where it has to say it's AI, otherwise it's not good.
*  You're in this such a fascinating place because you're like fighting against all of the sort of regulatory state bullshit and unfairness
*  that falls on the general public.
*  But then, when you imagine the kind of relying on the law, relying on government,
*  it seems pretty clear that at best we're going to get an every so often update to the actual law,
*  which then means we're almost certainly going to end up in this kind of agency run regime where there will be an authority established
*  or maybe that authority gets divided up across some existing agencies, whatever.
*  But ultimately, there's going to be some bureaucrat that's going to have to create and implement rules and prosecute the law, I guess.
*  Do you have any sense for how you think that could go such that it could actually be responsive and serve the public?
*  I mean, it sounds extremely hard.
*  Not that that means we have any way around it, but what would your advice be to the policymakers as they try to think about getting that right?
*  I think they should regulate the extremely large businesses so that they do the hard work for us.
*  And if we go back to robocall legislation, that's what they do.
*  Robocalls have been such a big problem over the past few years that Congress has said, OK, it's the responsibility of the telephone companies to solve this issue.
*  And so now they have something called shaken slash star, which means that AT&T is responsible for identifying the caller.
*  So when you see on your iPhone, it says spam likely because it's probably a robocaller.
*  That's the law that's behind that, that forces the company, the big telephone company, to take responsibility and solve this issue.
*  So I think the same could be true for the Microsofts and open AIs of the world, where they're the ones being regulated to stop this bad action happening.
*  But I think for startups and consumers and businesses, they should be allowed to use this technology to benefit them without having to get a license,
*  because it's just going to be regulatory capture.
*  Otherwise, no one should have to hire a lawyer or a lobbyist to innovate.
*  Yeah, I think I agree with that.
*  And I would even say it seems like open AIs largely agrees with that.
*  There's been a lot of cynical reads of their calls for high level regulation, but it seems like they're not really trying to squash,
*  you know, certainly the consumer or the indie hacker use case, either despite accusations to the contrary.
*  In practice, do you think that that is kind of a monitoring system that sits on top of your usage?
*  Like, if I'm an open AI user in the future, I maybe use it knowing that there's some additional AI layer that kind of assesses my account at some scale
*  and kind of monitors for any number of harmful uses where it's like, OK, if it detects that I'm generating a lot of a certain kind of content,
*  you know, I get flagged. And is that kind of what you expect the future experience of that to be?
*  I think the way America works, it's the best country in the world, is it's all about liability and lawsuits.
*  So if you shift some of the liability onto the platforms, they will self-regulate.
*  So if you say that if they know or should have known about something going on with their big, big AI models,
*  then they will be much stricter in stopping the debt collections and things.
*  And I imagine the lawyers will keep them honest with endless lawsuits and class actions to make sure it happens.
*  And then beyond that, I think some sort of licensing for very large, very sophisticated models combined with some liability shift would probably stop like 95 percent of the bad actors.
*  I think one of the common patterns right now, which we see even among academics and published results,
*  but I imagine must be going on on a more kind of invisible level as well, is people will go use ChatGPT or even GPT-4 to create their training data set
*  that they'll then use to fine tune their own model, which they can host and run privately.
*  And I don't want to give anybody bad ideas here, but increasingly, it doesn't take that many examples to do a reasonably good fine tuning.
*  If you have a model that's already kind of chat or instruction tuned, a hundred examples, a thousand examples,
*  it's probably in that range where you can fine tune for a lot of kind of more specific tasks.
*  So if I go to an open AI and let's say I come up with some scenario, maybe it's a jailbreak, maybe it's just kind of not super obvious what I'm doing.
*  And I create like a hundred examples and then I go fine tune my own model and prosecute some scam campaign or whatever.
*  Would you extend that liability back to open AI for kind of having enabled me in the first place?
*  Or how would you think about drawing that line?
*  I think that every step of the implementation, it's only effective if AI is being used every step.
*  So to do the voice calls, you need to have a synthetic voice company that has really good synthetic voices.
*  So they're also liable. You have to have a telephone like dialing system with AI.
*  So the kind of Twilio AI is liable.
*  And if you create gatekeeping and liability every step, it becomes a lot harder and you'll have to like sign up.
*  They'll be like, know your business or know your customer to find out what you're doing and things like that.
*  It won't stop the truly evil people because they can just fine tune their own models.
*  But one thing I'll say about scammers is they're not very sophisticated.
*  That's why they're scammers. If they were so smart, they could make money in the economy that usual way.
*  And so they just want the low hanging fruit to get things done very quickly.
*  And that's why I think it would stop 95 percent because anyone who knows how to fine tune their own model and train it and do all of this engineering work is probably doing well, building their AI company or working at AI company.
*  They don't have to kind of pick up the bottom of the barrel with these scams.
*  So just making it harder for dumb people to scam has has a surprisingly big impact.
*  OK, yeah, certainly no doubt that if you have demonstrated any aptitude with AI today, like there's plenty of honest work out there for you.
*  You don't necessarily need to be scamming people over the phone.
*  I think big companies need to create tools to protect us from AI.
*  So in the same way, it's as fan cool likely if you pick up the phone and there's an AI on the other end and it's a fake AI voice of your grandparent.
*  Maybe the phone should vibrate and AT&T should protect you, saying this is not who you think it is.
*  And they need to build their own AI model to do that.
*  And and so there's a lot of things that are going to have to work through the system.
*  But I think putting the responsibility on these big companies is always the way to go.
*  So how does this kind of shape up in the next couple of years?
*  As you mentioned, this term arms race, right?
*  For many people, that is like the most scary thing, certainly at the level of like, you know, US-China military rivalry.
*  An AI arms race sounds like maybe the worst thing ever.
*  An AI arms race between even just the biggest companies, you know, a lot of people think is like a real disaster.
*  And then there's also this AI arms race potentially between kind of consumers and the companies that are overcharging us, nickel and diming us, so on and so forth.
*  What do you think that arms race ends up looking like?
*  I've got Do Not Pay and I've got your agent and they've got their agents.
*  Like, how does this kind of settle into some stable equilibria?
*  I know we've spoken about a lot of the dangers of AI, but I think it'll be hugely positive and hugely deflationary.
*  So if you look at customer service spend, it's estimated to be around 10 percent of total corporate costs.
*  And so that's the connection between the price of a hamburger and chat GPT, where McDonald's can take orders fully with AI.
*  United Airlines can lower their plane tickets, in theory, by 10 percent, even though planes have nothing to do with AI because they don't have to hire all these customer service agents.
*  So things will be cheaper and more efficient with our AI agents negotiating with each other.
*  And that's great because no one likes to pay high prices, lower prices are good.
*  And so I think that's the largest positive benefit where things are just more efficient and simple.
*  You compare it to China and China is using a lot more AI right now in customer service.
*  And it's just much, much better. You call an agent in the US and they're like, hold on, wait, let me just take down your account number.
*  And it takes like an hour to get something done. In China, you don't really have that.
*  Things just get done more quickly. People live simpler, cheaper lives because of AI.
*  So I think that's the equilibrium where things are just a lot cheaper.
*  Can you give me a little bit more on the China reality today?
*  Because I'm contrasting that in my head against the recent regulatory statement that they came out with that was kind of like seemingly a sort of chill for a large language from a large language model perspective.
*  There were some provisions in the, it wasn't the final rule, as I understand, but kind of the guidance from the CCP was like, you need to have as a large language model a good handle on even just the training data that you're using to ensure that it is reliable,
*  the quality content, not violating people's copyrights, etc.
*  And the general response to that seemed to be like China is not racing into this LLM future, but you're describing an LLM reality that is seemingly quite different from that.
*  Yeah, well, this is an interesting thing, which I'm sure you guys know.
*  This AI stuff has existed for two years now, kind of good LLMs like GPT-3 and GPT-3.5.
*  It was only when ChatGPT came out that the whole world's imagination and it became the AI hype.
*  But there's been really great machine learning and AI models out for a while.
*  And now everyone is focused on these ChatGPT style LLMs, where there's other use cases of AI that can be beneficial.
*  I think that China is concerned with LLMs from a content perspective, where it tells people the government in China is not good or communism is not good and things like that.
*  And that's what they're concerned about. But they're certainly not that concerned about corporate efficiency, where disputes are being processed.
*  And as a result, Chinese consumers have much higher standards than US consumers.
*  In the US, we're very angry and vocal, but ultimately, we still accept companies like Planet Fitness, where the only way to cancel is a signed letter or going into the store.
*  That would be unacceptable in China. And so because of how efficient everything is with technology, I think they have a lot higher standards.
*  Coming back then to the US and how, or the West, but the US specifically, as our equilibrium potentially starts to emerge,
*  I guess you could imagine a lot of different scenarios, but you could imagine kind of a new liability regime, but still kind of everybody interacting with each other on like a one to one.
*  My bot talks to your bot. You can imagine the company is kind of escalating through some like, you said that toward the top, somebody had said, we don't accept AI disputes.
*  That may, you know, you could imagine a law that says, well, that's not illegal. That's not legal. You must accept AI disputes.
*  You could imagine new sort of consumer standards that might be voluntary that companies could opt into to say, like, we will accept AI disputes because we know that people want that.
*  I think in some sense, I think do not pay is maybe a little bit too Robin Hood branded to be the one that brings all the companies on board.
*  But you have kind of an interesting position from which I wonder if you could even start to create something new like that, where it's like, can there be some sort of standard?
*  You know, can there be some sort of shared expectation of how these things are going to happen so that it's not just like bots, you know, bumping into each other and kind of, you know, because eventually they both just stonewall, right?
*  I mean, it seems like in some limit, one version of events would be my bot, like, refuses to, you know, accept their offer and their bot refuses to give me anything.
*  And so they just like, talk to each other until one like ends the conversation.
*  How do we get to a scenario where it's like actually all these bot interactions actually like productive?
*  I think we need like open AI regulations in the same way we need kind of open banking in Europe and even in the US, where you can have AI transact with other AIs.
*  And there's a technical standard where they can communicate.
*  Imagine an AI, all the banks rip us off because they give such low interest rates.
*  And imagine if AI was shifting your money from one low interest rate account to a higher interest rate account in a safe way.
*  And it had a power of attorney to do that on your behalf.
*  And so I'm definitely for kind of technical standards to allow different AIs to communicate.
*  And so maybe your AI could say, I want to move my money or close down this credit card because the fees are too high.
*  And the bank AI is like, that's an authentication AI to make sure it has the authority to do that.
*  And there's a way for them to communicate.
*  So I think that more open systems and technical standards would stop the problem of AI butting heads.
*  Rather than going through this janky web compensation that was designed for humans, they can go through a much more efficient, maybe API based framework to get it done.
*  How about a possibility of like an AI powered arbitration?
*  I wonder if there's kind of a, you know, another model would be today, right?
*  You either in the limit, you end up in a court or if there's some, you know, provision, you may end up in human powered arbitration.
*  Do you think there's a role for kind of a third party or, you know, obviously it could be multiple third parties that you could choose from that could sort of say, you know, look, this arms race has to stop somewhere.
*  We are going to be the provider that the companies and the consumers can kind of come to, you know, agree on in advance and then come to when there's a problem and will rent our AI will render judgment, you know, and that's kind of the service that will provide.
*  Yeah, in the US, so landlords hold people's security deposits and then it's almost negotiation after someone moves out, whether they'll even return it.
*  That's one of our biggest use cases that do not pay.
*  One could imagine AI arbitration for security deposits where at the beginning of the lease, someone deposits the money with AI and then when the lease ends, everyone can submit that evidence and AI decides.
*  And that's a great simple use case.
*  There's probably within the realms of current technology to shift and decide where the security deposit should go.
*  That's another area where we might need pro AI laws because the market is not going to shift to that pro consumer stance without some sort of law.
*  But that's a great example of where AI could be helpful.
*  It seems like there could be some hope for a market driven equilibrium shift there.
*  You know, you go to the grocery store, right?
*  And like food in general is legal.
*  There are certain like labeling standards that are maybe required.
*  But like, you know, the default assumption is if I want to, you know, start making my dad makes pickles, right?
*  And he's always assumed that if he makes enough of them, you can go sell them to a grocery store with like relatively minimal hassle.
*  But then there are these kind of, you know, certifying bodies if he wants to be organic, if he wants to be this or that, there's kind of these, you know, stamps that you can go out and try to earn.
*  But you don't, but it sounds like you don't really see a path to a future where Comcast might say, we, you know, support the do not pay, you know, AI arbitration standards so that you can sign up for us with peace of mind.
*  I'm perhaps more cynical than you guys, but I don't think so.
*  California had to pass a law that said that you have to have the option of canceling subscriptions online.
*  The fact that they have to pass that law shows how backwards these companies are.
*  If they could get away with it, they would say you have to fax a cancellation in.
*  In fact, up until a few years ago, that was the case with some subscriptions where you could only cancel by fax or mail.
*  Apple care, Apple care was actually one example, ironically.
*  Unless there's some laws, the companies will try anything to get out of their responsibilities.
*  Even like going back a long time ago, you see on every mattress, it's like, do not tear off this label if you're a retailer, because the retailers would stuff the mattresses with by rats to save money.
*  So I would think these big companies will do anything to save money and cheap people.
*  And there has to be some sort of law.
*  The market is good in some areas.
*  Ultimately, the best products win.
*  But on the lower end, there are a lot of shady stuff going on without the law.
*  You certainly know a lot more about that than I do.
*  And your cynicism might, in fact, be quite correct.
*  I want to get to the deflationary part, too, because I think that's a really kind of key dynamic.
*  And you mentioned it. But maybe before going into that, I also am really interested in how you think the consumer reality or experience is going to change, even beyond kind of the dispute moment.
*  I kind of think about you go to the grocery store, you get everything on your list, and then at the end, you've got kind of the candies in the checkout aisle.
*  And it seems like the AI layer on everything can really supercharge that for businesses, where we're all going to have these kind of highly personalized and probably often reasonably compelling.
*  You know, kind of do you want to add this on or impulse by this opportunity just kind of coming at us all the time?
*  And I wonder, do you think that that's just something we learn to live with or kind of learn to tune out?
*  Or do we have like an AI layer of defense for that that sort of filters that stuff for us?
*  I don't know what it's like to be a consumer to even two years from now.
*  So I wonder if you can help me get a little window into that.
*  I think that we'll have our own eyes on Apple, AR glasses, and it will be able to filter out stuff that we don't want.
*  But a lot of personalization people love.
*  I'm a I'm a I love consumer rights.
*  But I do think some of this privacy legislation is actually anti consumer.
*  I think consumers love personalized ads.
*  People love seeing stuff.
*  They love it so much that there's always these conspiracies that say, oh, I was talking about buying something and it just appeared as a Facebook ad.
*  In reality, they were Facebook is not recording you.
*  It's just that it knows what you want so much that it shows you what you want.
*  And I think giving people what they want is a good outcome.
*  But I do think that they will also have a eyes to filter out spam and maybe some laws around the edges to to stop the trash.
*  But I think it'll be a positive.
*  If I see the stuff in the checkout line that I like, like I love sparkling water, if there's like a sparkling water can, that would make me happy.
*  How do you think people will interact with this?
*  You mentioned the Google or not the Google, the Apple, you know, upcoming glass device a couple of times.
*  That could be potentially a huge part of it, I can imagine.
*  Do you guys have I know you have the you have the website, you have the app.
*  I looked for a plug in. I didn't see a plug in.
*  I wonder if you kind of imagine a future where, you know, people continue to come to do not pay website or app like directly to use stuff.
*  Or if there's this kind of like AI super app layer that you plug in, you know, kind of like the we you know, going back to China example, right?
*  They have kind of the WeChat super app for everything.
*  Do you think like chat GPT or similar has a chance of becoming that and then having all the things like do not pay plug into it or do not really buy that?
*  Unification period.
*  We're a big believer in being platform agnostic, in part because these companies that Apple are also evil and they they're very monopolistic.
*  And so if you're too reliant on them as an app, then they can shake you down and steal all your money by canceling your app.
*  I think it's about being idiot proof.
*  The best AI will just be an everywhere, everyday life where it will just work in the background.
*  When the Apple stuff comes out, we are ready to go.
*  I said to our engineers, we have something day one, we're going to launch using AR.
*  It's going to be able to scan everything at the supermarket and have prices hovering of cheaper prices at nearby retailers.
*  So we're already thinking about new platforms and things like that.
*  How do you try to get ahead of the dynamics that seem like inevitable to kind of shift pretty quickly?
*  Right. If everybody all of a sudden starts walking into the grocery store with your app on in their in their Apple, you know, AR device.
*  And now every price mismatch is subject to the match policy.
*  Presumably, they shut the match policy down, but maybe not.
*  Maybe everybody just gets like matches all the time.
*  And, you know, that's maybe one of the ways it drives a lot of kind of deflationary pressure.
*  But I just don't know how to start to get a handle on that.
*  How do you try to project what's likely to happen and and get a read on where things are going?
*  Yeah, there's the drop in the bucket bucket argument where I think Gartner or one of these research companies did a survey of how many people have actually tried chat.
*  You've been in America and I think it was 12 percent.
*  Fifty four percent of people have heard of it, but only 12 percent has tried it.
*  And so the people that try these technologies will have an unfair advantage, which is sad for the people not trying it, but good for the people trying it, because it means that things in the world won't change against them so quickly.
*  And so I think that the cynical view is that those that use technology like that, the media and consumer who's quite good at using some technology, but obviously not creating it or knowing how it works, they'll they'll do very well.
*  The people that don't use smartphones or don't know how to use and embrace those things will be left left behind for a few years until the rest of the world catches up.
*  That's not that long of a time, though, right?
*  I mean, it seems like when you say that, I kind of think, you know, I often think back to the anthropic fundraising deck that apparently was real and got leaked and written about where they say that they think that the companies that fall behind or, you know, it's basically that would be almost all companies, right?
*  Companies not on the frontier in the 2526, that's 2025, 2026, as in two to three years from now, timeframe, they kind of say, if you fall behind on in that window of time, you may never catch up, which, you know, sounds kind of insane, but also maybe realistic in the scenario that like models start to train their successors.
*  And there could be kind of, you know, hard, you know, the most really might get deep at that point, perhaps.
*  That sounds like a very different world.
*  Like, doesn't sound like to me, we're in a decades long transition.
*  Do you think this is actually going to take a lot longer than like, that anthropic deck, you know, suggests that it would think so that more things change and more things stay the same with there are a lot of old people in America, just demographically, and we're a geriatric society.
*  And it's increasingly so and old people, they don't embrace the technology that I've seen it all, my vision doesn't really work. And there's still a lot of people in America who use checks for everything. There's restaurants that accept checks and things like that.
*  And so I think there's going to be a huge contingent of society that don't see the benefits because they don't embrace the technology. And when when they touch like government services and things that do use AI, they'll benefit from that, but they might not benefit in that personal lives.
*  How much money does do not pay safe people today? And how do you think that's going to evolve? And like, if it gets into, you know, at some point, presumably, if it's like, you know, the median, you know, per capita income in the US is like, whatever, 30 some thousand dollars, maybe up to 40.
*  You know, if you can start to save people a couple thousand dollars a year consistently, and you're talking about saving people, you know, 5%, 10% of per capita income, it doesn't seem like people leave those size dollar bills on the sidewalk for very long.
*  So my picture is like, you probably can get there, you're probably about to save me a couple hundred bucks on Comcast. You probably can do that, you know, across a number of different things. Why like, why wouldn't everybody kind of pick up that free money? You think that people are just that slow or the, you know, the friction is just that high? Like, what am I missing?
*  I'm not sure what US GDP is. I think it's in the trillions, maybe three trillion, I could be wrong, it could be one trillion, but it's certainly over a trillion. So 10% of a trillion is 100 billion. And I think 100 billion a year of savings, at a minimum is hugely ambitious. And you're right, things would change a lot. I'd probably be in jail if I was saving people 100 billion, they would find a way to put me in jail.
*  Once again, it's the drop in the bucket argument right now, do not pay, save people like mid nine figures a year. But to scale that exponentially, we would face some serious pushback. So it's really about the people knowing how to use this and getting an unfair advantage. The advantage of do not pay that as though is we're very horizontal. If we were just doing parking tickets, this fight is so concentrated that the people were against have a big incentive to stop us more quickly.
*  But if you divide what we're doing by 200 use cases, and divide that by 1000s of companies we interact with, the impact is, is still strong, but it's more of a pope at the moment. The benefits of AI in terms of the companies will accrue to the capital holders. So inequality will be exacerbated by AI because these companies will be able to build huge outcomes with very few people. And that's great for the 1000 people that work in Menlo Park, but not the
*  so great for the 10s of millions of people putting out being put out of the job. On the other hand, I think AI will make the average person more powerful. In society, we live in a kind of pay to play society from a legal standpoint, those who have more money to intend to win their legal cases more those that have access to expensive professionals like doctors and therapists, that takes money to get access. And so AI can provide those services for free or much more cheaply. So
*  I think the solution would be to actually, I'm a big capitalist, but I think you have to redistribute some of the gains from these 1000 person AI companies, or maybe even 10 people AI companies that get all of the value from making all the society out of work. And I do think we will see some sort of basic income where someone could just have a decent standard of living paid for by the government.
*  Give me kind of your expected time. I mean, in the AI safety world, people always talk about your timelines, a little bit here, you're not your doom timelines, but you're like, you're kind of consumer, you know, trajectory timelines, because you're like a couple years, you know, still doesn't seem like everybody's going to be using it in your mind, you know,
*  well, on the consumer side, but enterprise will use it and lay off people. I think that within five years, most white collar jobs, I would say maybe the ballpark 30% of white collar jobs will be eliminated by AI. Everyone thought it would be the blue collar jobs first, but actually, those ones are protected, I think for five years, and then we'll start to see more blue collar jobs with self driving cars, stock, shelf, AI robot, and so on.
*  And things in the physical wildcat chart. So maybe within 15 years, maybe 60% of jobs will be eliminated. That that's my ballpark. I'm curious what you guys think that
*  Yeah, my crystal ball gets pretty foggy beyond a few months out. So I do try to venture predictions, because I feel like in, you know, in this line of work, I can't really shirk that responsibility, but always caveat them with the, you know, the fact that I find a lot of these dynamics, you know, hard to predict. But I think you're basically right, you know, it seems to me that, you know, we talked about, you know, Wendy's just made this announcement around their, you know, they've got fresh AI, and it's going to be a lot of work.
*  And so I think that's a great example of how, you know, you're going to take your order at the, you know, at the Wendy's drive through. And you think like, you know, I think it's a great example of how today, you know, the job description as it's traditionally been done, you know, it's, it's always just been humans, right, that are applying for the jobs. And so people like variety, and there's, you know, there's some resilience benefits, perhaps in kind of having these roles that sort of span different kinds of tasks.
*  So from what I see, you know, I've never actually worked a fast food job myself. But from what I see, you typically have somebody who's like, taking orders and filling sodas, and, you know, probably takes a shift on the grill, and they kind of rotate through and share duties in whatever sort of way. It does seem to me like, you know, certainly you're right that the order taking seems like it's ready, you know, soon if not now. Some of the statements from, you know, the Wendy's and the Google execs powering this I thought were pretty remarkable, you know, that one of the Wendy's guys says that the fresh AI
*  bot, I believe this is a direct quote, is better than any of our, you know, human order takers. They also do say, you know, you won't even know you're talking to an AI. Both of those things really stood out to me. So you know, that's how whatever percentage of work that is at a Wendy's seems like it's pretty clearly going to be taken on by AI. They can't yet man the grill, but you know, so the jobs will kind of change in nature. And they seem to like almost certainly that there will be fewer of them. I don't, you know, I don't really
*  know how that could play out any other way. And it seems like, you know, 30%, if I had to, you know, just to take your number, like, are there 30% fewer people working at Wendy's in the next couple years as like, all the order taking is automated.
*  My positive outlook is there are a lot of jobs that will be created as well. So that's why it's 30% and not 60%. Even like a podcast engineer, maybe like 20 years ago, that didn't exist. prompt engineers, although that will be a very small part of the economy. I think and the
*  entertainment sector will explode. If everyone is getting basic income, and is out of work, they need to be entertained. YouTube and OnlyFans and these things will just explode even further and especially in AR era, gaming and things like that. So maybe the future of
*  work will look like being a professional gamer, and there'll be more people doing fake work inside of a game, like mining rocks in RuneScape, and the AR version of RuneScape creates doing fake work, AI will create fake working games for people who knows, but it's an exciting area.
*  Yeah, although even in like Minecraft, for example, you know, there's been some interesting papers just the last couple weeks where it's like, even your Minecraft playing is, you know, not immune from AI competition. And in fact, like, again, probably the best Minecraft AIs, you know, outperform the average player, I would guess, you know, pretty, pretty decisively on like the vast majority of tasks. So it's it is going to be hard, I think, to find areas where this stuff doesn't kind of encroach. My best guess
*  is, this is not my best guess, but like one vision I do think is kind of a plausible part of the future is an almost like reactionary sort of offline. I think like mystery murder dinner party type things, you know, that are kind of bespoke, in person, you know, highly sort of customized and local and almost like peer to peer, you know, in terms of its provision.
*  But like something that, you know, is just a total reaction against the kind of everything being online, everything being AI, like, you know, it seems like there's going to be some kind of shift maybe just away from that. But again, you know, that's kind of like prompt engineering in the sense that like, we can't all prompt engineer our way to prosperity. And we also probably can't all provide like mystery murder dinner parties to each other. That's like, only so much of that. So maybe my imagination is limited. But and then two, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think, I think
*  like, geez, if I was doing that, you know, it's like the leap is so quick. If I was going to do that, you know, murder mystery, you know, immersive experience business, I'd probably use GPT-4 to help me like write the stories. So you know, is there? I don't know, is it? What's the refuge from it? I think I see two possibilities. One, there's a stall out basically now. And we find that, you know, this stuff just never works. I don't see how that would really happen. But it's at least still somewhat of a possibility. Or the other is like, it
*  becomes so ubiquitous that, you know, I don't really find that many things that seem like they are untouched by it.
*  I think to your point, people really value humor to human interaction. People appreciate Magnus Carlsen, the chess player, because they know he's not using AI. And I think there was another chess player who was caught using AI or some expert system. And he was completely shunned. And so there's a lot of things in life that are only valuable because it's a human to human connection. I think this podcast, I think a lot of people tune in because it's
*  great human beings versus versus some AI. And so I think there'll be like AI certification, like no AI was used. And maybe the AI will be doing the certifying so it can be sure and things like that. People underestimate how much stuff is in the real world. If the toilet breaks, there's not going to be an AI toilet breaking repair service anytime soon. And we look around us and the buildings and that's all created by human beings. So there's still a lot of stuff that will definitely be human powered.
*  And I don't even have to worry that much. There's going to be a huge shift with these people pay charging hundreds of dollars to copy and paste documents like lawyers that are biased against being replaced by AI. But there will also be a lot of jobs that are safe and also some exciting new jobs.
*  So then that's maybe a good transition to this kind of deflationary trend that you're predicting, which I also totally agree with, you know, the deflation starts in AI itself, with huge price drops on, you know, state of the art model from last year is now 97% cheaper and improved, you know, in terms of both capabilities and speed. And, you know, now we've got new higher end models that kind of maintain basically that top level price point from last year.
*  But when, you know, a certain capability level is dropping, you know, 20 to one within a year, sets a good stage for kind of further deflation. Do you think that this is the thing that finally kind of solves the cost disease like education, you know, access to things like law access to things like health care? How big of an impact do you expect in those, you know, kind of classically, prices out of control areas over the next few years?
*  Any services business will be touched by AI and experience deflation. Right now you can go on Khan Academy today and get a world class AI. There's that they have an AI version now where you can get a great maths education. And that's really great. At the same time, though, the areas you listed are highly regulated by the government. And that's the reason why they're expensive, not necessarily because they don't have any AI. TVs have dropped drastically in price over the past 30 years.
*  But education and housing has remained expensive because the government is regulating it. And I think that the one way that these professionals are going to save themselves is through huge, rediculous regulation and licensing. Lawyers especially do not pay his experience law challenges where lawyers are saying, oh, it's unauthorized practice of law to give people power to fight themselves.
*  There's a judge in Texas, a federal judge in Texas today, who has just said that every filing may you now have to certify either the AI was not used at all, or that if AI wants to use a human has manually checked everything that AI has done. And I think that was response to the guy in New York who's been put in the doghouse for making up the fake cases with TAC-EPD.
*  So all of the professionals are fighting back. They're not going easy. They're going to create AI regulations to save their jobs. And especially in the EU, the EU is going even farther than the US. They'll probably say you need a license for any use of AI and they basically maybe make TAC-EPD unusable in the EU because of all these rules. So that's another reason that will slow things down as well.
*  I've been very amazed, honestly, by how positive the medical establishment's response has been. I haven't got maybe as good of a read on the legal side. I guess, how do you think that you will fight that? You know, on the medical side, it seems like there's kind of so far this...everybody seems like reasonably happy thus far. Honestly, it's kind of weird. The technology providers are all being very sort of cautious and respectful.
*  We had one of the lead authors from Medpalm 2 out of Google on the show and they're very buttoned up. We've got to really prove this out. We're not trying to bypass doctors, all that kind of stuff. The doctors, meanwhile, are like, this is going to be a great aid to us. We're going to use it. That's by and large the message that I've got.
*  How would you contrast the legal side there? And then I really am curious to understand too, like, how you think about fighting that over time? Like, do you do it in a provocative way? You put some of these demos online where you're like, you know, we're going to have an earpiece in a courtroom. Do you think that's the way these kind of like, you know, highly visible examples? Or, you know, do you have hope still to work through the system? What's your strategy going to be to fight through all that stuff?
*  So there's not a lawyer in the world who will get out of bed to save someone $100 on their Comcast bill. But that still creates value for people. And so we're really serving an underserved area of the law. And that's largely kept the target off our backs for the past few years. When we started doing this earpiece stuff in court, the lawyers started paying attention and we're thinking maybe we should go after these people a bit. And that's what we're dealing with now.
*  At the same time, though, because we're focusing on this kind of non-competitive consumer rights area, I think everything will be okay. But if we were to start truly doing high level business disputes or going into federal court like this lawyer, then we would get into a lot of trouble. So I think if you go into an adjacent space that is less served, that's one strategy. Another strategy is changing the law yourself. One thing we've actually engaged a lot
*  of members of Congress, we're looking to pass an AI Assistance Act type thing that explicitly allows this sort of technology in some proceedings. We have a congressman here in New York called Richie Torres, who we're looking to sponsor this and that's going pretty well. So changing the law, not competing directly. And then finally, just throwing a firebomb and asking for kind of forgiveness rather than permission. Because if you do that, you can show consumers what's possible.
*  And that's what Friar Things. And so I would say those are our three strategies.
*  Yeah, I recently had a friend in the family who this was a mind blowing episode in a couple different ways. But basically young woman, she's like 19 years old. And she got into I don't as far as I understand, you know, as I've heard the story, she didn't do anything wrong at all. But she was asleep in her own car in a like parking lot somewhere.
*  And had been drinking and, you know, then was arrested for a DUI. And she was like, you know, I wasn't even driving, you know, I like got into the car was already parked and just fell asleep there. And nobody saw me driving and this is like ridiculous.
*  She then, you know, doesn't have a lot of money. So I was kind of advising her a little bit remotely. I'm not a lawyer, either she has a public defender that's assigned. She's like the public defender doesn't seem like he's really on my side. He just tells me to plead. I don't really want to plead like I didn't do anything. I don't you know, why should I be pleading guilty to something when I definitely didn't do it. And she ended up with a hung jury and then they're doing a retrial of this, you know, incredible, like, minuscule problem. And she's like, we don't need to be pleading guilty to something.
*  So she's gonna have to do it twice. And I was really thinking throughout that process, you know, and I was honestly using GPT-4 a little bit to just ground my kind of guidance for her. So we think about that layer, right? When we have this kind of notion that there is this constitutional you are guaranteed, you know, some right to representation. But in practice, that often falls down. It's that an area that you're interested in? I mean, it's certainly in some sense, it's like the greatest consumer right, you could say.
*  For low level traffic offenses, certainly, I think that for serious criminal cases, people deserve a public defender. And it's more of a question about getting rid of the bad public defenders, less of a production line and more of a well funded right to congressional, sorry, constitutional defense. I think these issues are too complicated, because it's often about the cops playing dirty or individual judges, like some judges will throw out the case immediately.
*  Some judges will allow a retrial somewhere. So so human and so emotional. In courtrooms for criminal cases, there's a police officers and bailiffs in every courtroom because they have to stop people punching each other. And I can't do that. And it's so emotional. Also with divorce cases, I think it will take a while to really seep in. But certainly making their work more efficient. A lot of lawyers are using tools like case tax and things to like find cases. But I don't think we'll have robot lawyers in criminal cases anytime soon.
*  And that's a humbling thing for me to say as as the biggest robot lawyer found out there.
*  Do you think there's a version of it where this was an interesting synthesis that came out of some of our medical episodes? We interviewed Professor Zach Kahane, who is leads a department at Harvard Medical School. And he said that he thinks it will very soon be considered substandard and ultimately unacceptable to have human
*  provided medical advice without the backing of a GPT four like system. And he's not saying, you know, we should bypass the doctors at all. But he is saying you wouldn't want to go in the near future. You won't want to go to a doctor. And it may be so standardized that like it's just expected or even required that the doctors or the medical system as a whole like must make this stuff in for your benefit. Is there a legal version of that you could see too?
*  Yes. So every year a lawyer has to keep their license going. And there's certain rules that one has to do to keep their license going. And I think two years ago in a lot of states, they have you have to be able to use the Internet. And that was like a few years ago. And so on the one hand, that's great that they have that I'm sure they'll add AI eventually. But on the other hand, two years ago, and the Internet seemed a bit slow. So it will happen. But the lawyers are very slow because they want to protect the privacy of the people who are in the law. And so I think that's a very good point.
*  They're the people writing the rules to benefit themselves. There are lawyers who steal from their clients. And there's a famous lawyer in California who stole from their clients for like 30 years and wasn't prosecuted. So that's the issues that they're dealing with because the rules are so relaxed. And so it will take a while for them to require that.
*  Medical, I think doctors are a lot more ethical than lawyers. They have the Hippocratic Oath to save people. I don't think there's a similar Oath with lawyers except for like maybe you do the best thing you can do for your client, but they're not saving lives. And so doctors are a lot more responsible, embracing technology than lawyers are.
*  So how about the deflationary elements as it applies to your own business that do not pay? Are you guys cost sensitive at all when it comes to the AI services that you use?
*  Yeah, so we're a team of seven people. We have hundreds of thousands of subscribers and it's our company name and mission to be very frugal and lean. These AI costs are racking up. It's probably one of our biggest expenses right now with the OpenAI API. And I think there'll be entire companies that are created that shift costs to different models. So what a lot of my friends have been asking for advice on how to lower API costs. And I say, you don't need to use GPT-4 for everything.
*  If it's a simple request, you can send it to GPT-3.5, which is 10 times cheaper, or maybe even an open source model like GPT-J if it's very simple. So I think shifting to the highest, you don't need the highest level models for everything. Shifting to the simple ones for simple requests will be good. And the positive outlook is that open source simple models are getting much more sophisticated every day. And I think even the open source models are maybe like 60% of where GPT-4 is. So you don't need to use GPT-J.
*  You don't need to use these expensive proprietary models to get a big outcome.
*  So how would you unpack that a little bit more for somebody? Just to give you a little bit of my perspective. I'm not a cost sensitive consumer of AI in the projects that I've taken on so far.
*  You know, again, I keep referencing my company Waymark. We use OpenAI fine-tuned models, which basically is the highest per token price out there, I think, on the market today. But it works well for us. And we have a pretty high hit rate. I've kind of come to focus in on this as potentially an important driver of how people decide what language models to use.
*  For us, it's something like people do a prompt and then we show them a video fully formed, which they can then edit. But we really try to deliver something that is ready to watch as if you could just publish it immediately.
*  And something like one in three, maybe as one in five, kind of in that range of the generations that people do, with some editing, they ultimately download and go publish somewhere.
*  So it's a pretty high hit rate where it's like, we're not, you know, if it were 100 to one and we were throwing out 99 out of 100 generations, you know, our cost profile could be quite different.
*  But where it's only like three or five to one and, you know, basically, whatever that kind of catches up to us is fine.
*  Then I do another thing with this company, Athena, which is in the executive assistant space where we're largely just doing like task automation for now.
*  And there, you know, the goal is ultimately for most tasks to like use all of the output, right? We want to, you know, you hope for reliability such that you're going to have some human in the loop, depending on the process still.
*  But like we hope that, you know, 99 plus percent of the generations, like once we really have it dialed in, will be usable.
*  I guess in those contexts, I feel I find like the easiest path is just use the best model. Don't really worry about the cost. I'm already taking usually like 90% plus out.
*  And so, you know, let's not try to save another couple percent. Like, let's get the best quality we can with the 90% cost reduction.
*  Where are you seeing different, you know, conclusions based on maybe different inputs in that analysis?
*  So enterprise businesses and even consumer subscriptions, I don't think it's a concern because the revenue far outweighs any sort of API costs.
*  One area that was hugely expensive for us as a law in the US is called the No Surprises Act. It helps people negotiate their medical bills and it requires hospitals to publish their bills and prices online.
*  And every hospital in the US has their prices in some PDF somewhere. And so what we did is we had a bot scrape all of it and then we used a custom trade model to standardize the pricing data.
*  And I think that cost us only 80k to actually get that done. And that's expensive, but we'll make that make up with lowering people's medical bills and the subscriber numbers we'll get from that.
*  There's a lot of use cases I see on Twitter of free consumer products where it's a demo and I don't think it will actually work because of the API costs.
*  So an example would be imagine you a browsing assistant is a great example. Imagine you have a browsing assistant that's analyzing a web page at the terms of service on every web page.
*  Consumers don't want to pay for that because it's so simple and so it would have to be a free product, but you would really get a good response unless it's GPT-4.
*  And I would imagine if that was going to become popular like an AI version of Honey, I don't think that could exist because the costs wouldn't actually pay for themselves.
*  So a lot of business models where it's freemium or free with ads like a credit karma or high honey style business model won't work with GPT-4 I feel like because the API costs outweigh the revenue per consumer.
*  But for subscription models and certainly enterprise use cases, it does work.
*  I was speaking with the founder of a popular podcast recording software which we may or may not be using right now.
*  And even he's having these issues with cost and AI. So I think everyone has to be concerned about it.
*  Well, you are certainly the most cost sensitive person I think I know at this point. So in some sense, that's not surprising.
*  I still feel like even in those use cases that you cited, there's certainly some fixed costs.
*  When you said the $80,000, I guess that is the cost of training a model. But it's done now.
*  I mean, in some of these other things too, if you were going to go process the terms of service on every website, largely that would be like a one time deal.
*  Wouldn't you cash it or have some embedding backed database where you wouldn't have to do it real time every time?
*  It seems like there's a lot of ways to take cost out where you could still use the best model, but maybe be clever about applying it opportunistically or only updating so often.
*  You don't want to run it every time I load a web page.
*  Yeah, and that's, I guess, where it comes down to shifting models as we spoke about.
*  Training to reduce inference costs and things like that. The more custom trained a model, the cheaper it will be.
*  But at the same time, the most powerful use cases of AI are where it's used in totality and every single time.
*  So for the imagine you have an AI coupon finder that scrapes the web looking for coupons and applying them.
*  You want that every single time because the coupon might not work. It upsates and things. And so you want the most reliable product.
*  And so I think that in these free consumer use cases, that's why you haven't really seen it as much where there's not where it's less transactional because of the costs.
*  And certainly for smaller businesses and individual developers, honey didn't start as honey.
*  It started as a team of startup engineers building something and they have to get funding and especially in this high interest rate environment.
*  It's much more difficult to justify money losing revenue model before you build great technology that does it itself.
*  There is a certain tier of company right now that is just taking the subsidized approach.
*  We talked to the CEO flow of Lindy AI, and he said that his costs were dozens of dollars per user per month.
*  But in his case, because he raised a bunch of money and he kind of used it as like first one to make a great product, he's going to get huge gains.
*  He's currently just subsidizing that and saying, I don't care. And the cost will come down and we'll kind of figure that out later.
*  Do you think he's making a mistake in that analysis?
*  Do you think the cost doesn't come down as fast as he's projecting or what's the disagreement?
*  I don't know enough about his business to criticize any aspect of his strategy personally, but I would say that the 20 of 21 mindset in general is wrong.
*  You saw a lot of companies spend $100 in customer acquisition costs to get a $70 LTV.
*  And the same is true with AI. And that's certainly not the approach we take to not pay partly because of the name,
*  but also because of our mission to save people money would be hypocritical if we weren't doing that ourselves.
*  One counter argument is that the technology is improving so much that if you get the user base and engagement today, you can shift the technology on the back end when it improves.
*  And GPT 3.5 was 10 times more expensive until OpenAI changed the pricing. So there's that argument as well.
*  But you can't count on that. I read an article that says we're almost at the limits of kind of Moore's law and things like that.
*  So you can't run a business on hope. It should be based on fundamentals.
*  What are the things that, you know, with all the hundreds of use cases, what are some of the most commonly applicable use cases?
*  I've poked around, but I've probably seen 10% of what you have.
*  So what should I go and do? You know, what should our listeners do to save themselves some money?
*  That's kind of maybe not obvious. My one time favorite use case app, all the things we have is doing Robo coolers.
*  We have a user, it's their full time job that they've just taken it upon themselves to sue every Robo cooler they get.
*  And they've made tens of thousands of dollars. They bought a new roof for their house.
*  There's a great law that says you can get 1.5 K per call.
*  But the problem is these Robo coolers hide behind spoof numbers. They don't tell you who they are.
*  So the question I'm sure you have is who would you actually sue?
*  And the way we've gone around this is actually with FinTech, not with AI, where we built a trap credit card.
*  And the way it works is a do not pay credit card. And when they try and sell you something, you can give them the card number and they run the transaction.
*  And it declines and it gets their business name, phone number, address, all the details you need to sue them through the payment network.
*  So I think this is a great kind of conclusion to this conversation, which is never about AI or FinTech.
*  It's just about using the best technology to fight for people.
*  And that's a great creative use case of like the card network to find these Robo coolers to sue them.
*  If I wanted to do this, I would start answering those calls.
*  I'd have your credit card on hand and I would then just say, yeah, I want to buy whatever you're selling.
*  And then as soon as that ping hits, now I sue you for the Robo call.
*  Yeah. And then it generates a demand letter and then lawsuit in small claims court and gets all of that going.
*  And what's interesting is they settle a lot because these Robo coolers are terrified of a class action.
*  So what they do is they'll say, we're not going to give you one thousand five hundred dollars.
*  We'll give you five hundred dollars if you sign here.
*  Confidentiality will give you a check.
*  And we actually see Robo call it disputes, settle a higher rate and security of the disputes, which I find interesting because you would think you're more entitled to the money as a security deposit.
*  But the Robo coolers are terrified of the big law firms finding out.
*  So it's almost an advantage to be a consumer fighting for your rights versus a big law firm because they know that once the lawsuit is filed, it becomes public record and the big guys start to target them.
*  Are there any things that you think are like coming at us that we didn't think to ask you about?
*  I've been working on my business eight years.
*  I like to think it's like overnight success eight years in the making.
*  And it's it's sad to see everyone you're seeing funds change that name from crypto to AI.
*  So I think that all of that is very disappointing.
*  That's my only hot take for you.
*  Other AI products and services that you find valuable and would recommend people check out.
*  Everyone has seen the viral influence of Karen, AI that influence to create an AI of ourselves that lots of people paid to talk to.
*  Not a lot of people know there's actually a startup kind of called Forever Voices that powers is bringing AI influences.
*  So I think that's really a cool company.
*  Let's imagine a perhaps not too distant future where Neuralink, which recently got its FDA trial approved.
*  It is soon, I think, registering clinical trial patients.
*  Let's imagine that goes through.
*  And now we're in a world where a million people have the Neuralink implant and it's like broadly found to be safe.
*  Let's say vaccine level safety. Right.
*  People generally acknowledge that it's safe, but you may have some noise out there.
*  If you get one, you can control your devices with your brain.
*  Your computers can ingest your thoughts and take actions just based on your thoughts, can record your thoughts.
*  Would you be interested in getting such a device?
*  100%. I think you've got to stay on top of the arms race.
*  Whatever tools help you, I would get.
*  And it will be the difference between the people using Chad GPT and those that aren't.
*  It's the same thing. You have to embrace technology and not be scared of it.
*  I wouldn't be in the house for that. I'd be in the beta.
*  Yeah. A million people, I think, is hopefully enough to demonstrate basic safety, at least.
*  So, OK, last one, then. You've covered this from a lot of different angles, but just trying to zoom out as far as possible.
*  What are your biggest hopes for and also fears for society as AI begins to touch everything?
*  My biggest hopes are that it levels the playing field and it's available to everyone.
*  And it makes goods and services much more cheap.
*  My biggest fears are just like everything else in society, it gets captured from a regulatory standpoint,
*  but also from a technology standpoint where it's just this tool to repress people.
*  And I think that I would be very sad if that happened.
*  Joshua Browder, thank you for being part of the cognitive revolution.
*  Thank you for having me.
*  Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work,
*  customized across all platforms with the click of a button.
*  I believe in Omniki so much that I invested in it, and I recommend you use it too.
*  Use Cogrev to get a 10% discount.
