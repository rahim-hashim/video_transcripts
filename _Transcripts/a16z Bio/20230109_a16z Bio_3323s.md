---
Date Generated: May 30, 2024
Transcription Model: whisper medium 20231117
Length: 3323s
Video Keywords: []
Video Views: 20733
Video Rating: None
---

# Expert AI as a Healthcare Superpower
**a16z Bio:** [January 09, 2023](https://www.youtube.com/watch?v=c7ScUDYSRYo)
*  Hey, I'm Vijay Pandey.
*  I'm the founding general partner of the A16Z Bio and Health Fund.
*  And I'm Mark Andreessen, co-founder of A16Z.
*  Mark, thank you so much for joining us.
*  Yeah, it's great to be here.
*  So you famously wrote about software eating the world.
*  And that was basically, what, 10 plus years ago?
*  And actually, that very much seems to have come to fruition.
*  If you look at all these other industries that software really
*  wasn't part of, software has actually become a dominant part.
*  But actually, this year's been kind of an amazing year
*  for another type of software, for AI.
*  And I'm curious to sort of talk about the arc of what we think
*  is going to happen in the future based on what we've seen in the past.
*  And really how this new technology is going to change everything,
*  much like we've seen software change the last 10 years.
*  I'm curious what you think for just this year.
*  It's been kind of an amazing year.
*  We always seem like not much happens in any given year.
*  But 2022 seems to have been an amazing year for AI.
*  Well, so Vladimir Lenin once said, there are decades in which nothing happens.
*  And then there are weeks in which decades happen.
*  And let's not hope that happens politically anymore.
*  But it does happen in science and technology.
*  It does happen.
*  There are moments where things kind of hit critical mass.
*  And this sort of AI machine learning revolution seems like that's what's happening right now.
*  It's been interesting to watch.
*  It feels to me, at least, it was like there was a breakthrough moment in 2012
*  that had to do with images.
*  And then there was a lot of work subsequently that led to things like the creation of self-driving
*  cars based on that.
*  And then there was some, it feels like some natural language breakthrough maybe three years ago.
*  And now that's really catalyzed into this kind of whole thing that we see happening around
*  GPT and text generation.
*  And then even other applications, transcription, is getting much better.
*  All of a sudden speech synthesis is getting much better.
*  And then now you've got this artistic revolution happening with image creation.
*  And now video creation is right next, coming up now really fast.
*  And so it seems like one of those catalytic moments.
*  And then it's like every week now, it seems like there's fundamental breakthroughs.
*  There's research papers.
*  There's product releases coming out.
*  So it seems like a cascading thing.
*  The way I think about it as a software person, sort of lifelong programmer, is that there
*  basically in the fullness of time it will appear, I think that there were kind of two
*  different ways to write software.
*  There was the sort of the old way to write software, which is sort of the classic von
*  Neumann machine, deterministic way.
*  And the whole problem with writing software in the old model is like computers are hyper literal.
*  And so they do exactly what you tell them to do.
*  Every time they do something wrong, it's because you have instructed them in properly.
*  And it's your very humbling experience to learn as a young programmer that everything
*  is your fault.
*  And the machine will just sit and wait for you to fix the problem.
*  Like it's not going to do that on its own.
*  And then there's this other way to write software.
*  And this has to do with having these AI systems and then having training data, training the
*  systems, tweaking the systems.
*  And the sort of capability that that...
*  The way I describe it to kind of normies is that sort of unlocks the ability for computers
*  to more and more interact with the real world.
*  And with the messiness of the real world, right?
*  And the probabilistic nature of the real world.
*  Yeah, well, it seems almost less like writing software, almost like training something.
*  It's like when I think about machine learning and image recognition, you talked about, it
*  felt like it was almost like training a dog, right?
*  Like reinforcement learning is like, we'll give treats as it gets better.
*  But there's something different now.
*  It feels like, I don't know, we've gone from like training a dog to recognize a bird versus
*  like a hot dog or hot dog or not hot dog or so on.
*  To actually something where it feels closer like training a person.
*  Or I don't know how you feel.
*  When we talk about learning and training and data, what are we training?
*  Where do you think we are in that arc of getting to like eventually how 9,000 and so on?
*  Well, so while this has been happening, you have kids, like I have a young child.
*  So I have a seven-year-old now.
*  So as this stuff has all been popping, I've been simultaneously training now the seven-year-old.
*  Yes, yes.
*  Anybody who's had kids will recognize what I'm about to say.
*  But it is really interesting watching little kids.
*  The way I think about it, or at least the look that I have, who's great.
*  It's like everything, for the first few years, it's like every single thing he did was like
*  a little applied physics experiment.
*  Which is like, let's see what happens if I drop this.
*  Let's see what happens if I eat this.
*  Let's see what happens if I do this to daddy.
*  Yes.
*  Right, and see what the response is.
*  And they just run experiment after.
*  And you can see it very clearly when they're learning how to walk.
*  Because they're running all these experiments about how to stand up and what to hold on to.
*  And they keep falling over.
*  And then at some point, the little neural network actually figures it out.
*  It does learn.
*  Off and away they go, right?
*  Yeah.
*  And so clearly, it's a little bit eerie.
*  You can see that, a similar kind of thing happening.
*  Having said that, the human brain just keeps developing.
*  And then it ultimately clearly has consciousness.
*  It achieves higher levels of consciousness.
*  It achieves higher levels of self-knowledge.
*  It reaches the Descartes stage where it has self-awareness.
*  Clearly, it's very creative from an early age.
*  I'm a little less convinced that the software technologies we have now
*  are on some linear path towards just quote unquote AGI or just quote unquote consciousness.
*  It's hard for me to believe that consciousness is just simply
*  emergent from higher scale neural networks.
*  That, to me, seems like a hand wave.
*  Now, having said that, I have a lot of smart friends who are pretty sure that that's what's
*  going to happen.
*  Yeah, actually, I feel that way as well.
*  So I want to get to AGI in a bit.
*  And also, we can debate whether consciousness is an illusion, as it is.
*  But where we are now is kind of amazing.
*  People can take GPT-3, you can give it SAT exams, it can do OK.
*  Actually, it can do quite well.
*  Yeah, it can do it.
*  It scores it like the one I saw that scored it like what, 1,200?
*  Yeah, something like that.
*  Yeah, so it's not bad.
*  I can do homework.
*  That would get you in a lot of challenges.
*  Yeah, I actually gave it like acid questions to explain the derivation for the source trial
*  radius, the black hole radius, to write a code for, let's say, 8 by 8 tic tac toe.
*  Random things that you should never be able to do because it's not just memorizing it,
*  it's generalizing.
*  And it's getting that.
*  But then also, it actually seems to have some sort of weird hiccups.
*  Actually, one thing that really does not seem to get is humor.
*  So I'm kind of curious where you think it's going to go.
*  Because before we get to AGI, there are things that an average human can do pretty well that
*  GPT-3 can't.
*  But then there's also what experts can do.
*  And what I'm very curious about is actually we may get to some of the expert stuff first
*  before it can do even something like humor.
*  The irony is that something like humor that we take for granted might actually be really hard.
*  And other areas might be easier.
*  Well, the ultimate example of the things it can't do, like it can't pack your suitcase.
*  Like there's no robot that will pack your suitcase.
*  Yeah.
*  If you try to make an omelet, it'll shred your clothes, it'll shred the eggs.
*  They're not, you know.
*  It can drive your car, but it can't pack your suitcase.
*  So it can't do your laundry.
*  So there are these interesting kind of twists.
*  So I would describe a little bit as follows, which is I think that this generation of AI
*  that we have is impressive.
*  It is a little bit of a sleight of hand, which we'll maybe talk about.
*  But I also think actually, to your point, human consciousness or human intelligence
*  is also a little bit of a sleight of hand.
*  Maybe slightly different sleights of hand.
*  So the sleight of hand that you see when you're using GPT or one of these image generation
*  things is it's not literally creating new information.
*  Like what it's doing is it has no opinion.
*  It has no point of view.
*  It has no like, you know, it's not sitting there like thinking on its own, coming up
*  with some new thing.
*  What it's doing is it's basically training, you know, ideally what it's doing is it's
*  training on the sum total of all existing human knowledge.
*  So for text generation, it's training on all existing human text.
*  Right.
*  And so it plays back at you basically projections from the sort of, you know, assembled
*  composite of all human text.
*  And so when you ask it to do the 8x8 like, probably somebody on the internet at some
*  point wrote some paper about how to do that.
*  I think it's a little more than that because it because I asked like 56x56 or 101x101.
*  It has some sense of generalization.
*  Yeah.
*  But I'll bet we can check this.
*  I'll bet if we Google long enough, I'll bet we can find a paper that described a
*  general purpose algorithm for, you know, multi-
*  That may be.
*  Right.
*  Somebody did that.
*  Yeah.
*  Yeah, I've done the same humor experiment.
*  I like have it write Seinfeld scripts and sometimes they're really funny and sometimes
*  they're just like, it makes no sense.
*  I went for curb, but same idea.
*  Exactly.
*  But like, look, there are a lot of jokes on the internet, right?
*  And so you'd have to kind of, you could kind of go back and kind of say, okay, it
*  probably like pluck these jokes.
*  By the way, maybe there was a paper somewhere where they articulated a general theory of
*  humor, right?
*  Because this has been, humor has been studied as a thing and maybe there's like a general
*  thing of like humor is like the unexpected or whatever.
*  And so it generalizes.
*  Well, it could be too, like all sitcoms might be the same sitcom at some level, right?
*  So here being an example, so I also had to do like dramatic screenplays, dramatic cast
*  stage plays.
*  It's quite good if those like three, you can say like write a three act screenplay.
*  It will do it and it will have the proper like setup and resolution and so forth.
*  But yeah, there are systems for like screenwriting in Hollywood where they have like three acts
*  and then they have like 15 beats and then they have-
*  It's all Rocky or it's all Star Wars.
*  Yeah.
*  Well, so actually it's really interesting that maybe what we think is magical when humans
*  do it isn't actually all that magical either.
*  So that's what I was going to say.
*  So then the human sleight of hand is like, you know, is there actually free will?
*  Is there actually creativity happening upstairs?
*  By the way, if there is, is it everybody?
*  Is there really a thousand types of movies or is there like one latent space of the monomyth?
*  And basically what's happening, I think the theory, I'm just, you know, I'm kind of making
*  this up, but I think the theory would be the hero with a thousand faces or the idea of
*  the Jungian hero's journey, which is sort of the basis for all of these plots, you know,
*  Star Wars and Harry Potter and everything else.
*  You know, somebody with your background might say that basically it's sort of an algorithm
*  for surfing human neurochemistry.
*  Yes.
*  Yes.
*  Right.
*  And just generating different like, you know, sort of neurochemical responses to like, you
*  know, fear and anxiety and, you know, love and all these other things.
*  I've always been fascinated.
*  There's this thing in psychology called core affect theory.
*  That one I don't know.
*  Oh yeah, this is great.
*  So, okay.
*  So what do humans have all these love and despair, like we have all these different
*  emotions.
*  It's all great.
*  Core affect theory says, no, we don't.
*  Oh yeah.
*  Yes or no?
*  Good bet.
*  Good or bad.
*  Yeah.
*  And then higher or low.
*  And so we either have like a positive, like we either have like a positive neural response
*  or a negative neural response and then it's either high intensity or low intensity.
*  And then you just basically, and so it's like, wistfulness is like, you know, just
*  slightly negative, but like, you know, despair is like extremely negative.
*  So it's all two by two.
*  It's a two by two.
*  And it's, and we're more basic organisms than we think.
*  And then we just, we retro, you know, as, and we're very, one of the things that's
*  great known is humans are very good at creating a story to justify whatever happened.
*  Right.
*  And so we create these stories, these scripts around this idea of an emotion, but it's
*  basically just justifying the neural response.
*  Yeah.
*  And so the, the, the cynical view would be like having an ice cream cone on a hot day
*  and like falling in love are like the same thing.
*  Well, maybe neurochemically maybe they are.
*  Well, this comes into play in like, you know, drug abuse, right?
*  Which is, you know, things that, things that generate an opioid response.
*  Yeah.
*  Like some people get an opioid response from alcohol.
*  Yeah.
*  Right.
*  And they're, they're far more prone to alcoholism and people don't get that response.
*  And so it's literally a neurochemical thing.
*  So, so yeah, look, maybe we're, maybe we're bundles of neurochemistry to a much deeper
*  extent than, or much simpler extent than we want to believe.
*  Yeah.
*  Having said that, you know, again, oh, and then that, that takes me to the other thing
*  on AI, which is I do, you know, one of the ways that people are testing AI is with the
*  so-called Turing test.
*  Yes.
*  And the simplified form of the Turing test is you're chatting with somebody that may
*  be a human or maybe a bot, but you chat for 20 minutes.
*  Yeah.
*  Can you guess better than random as to if it's a human or a bot?
*  Yeah.
*  You know, the, the, my take on that is the Turing, you know, Alan Turing was a genius,
*  but the Turing test is malformed.
*  Yes.
*  Humans are too easy to trick.
*  Yeah, yeah, yeah.
*  Yeah.
*  But, but that's too low of a bar because tricking a person is not that hard and does not prove
*  anything other than that you've tricked the person.
*  Yes.
*  Like I, I think, and this is relevant because I think, you know, things like GPT are about
*  to pass the Turing test.
*  Yes.
*  Because they haven't already.
*  Oh, they probably already have.
*  They probably have in some cases.
*  Yeah, exactly.
*  And so I think it's going to turn out that that was too lightweight of a test.
*  Yes.
*  Well, here's, here's my favorite example for why I know GPT is not self-aware.
*  If you ask it if it's self-aware and you ask it to elaborate on how it became self-aware,
*  it will happily tell you.
*  Yes.
*  And by the way, if you ask it if, well, how it's going to feel if you, if you turn it off,
*  it's going to tell you, please don't turn it off.
*  Yeah, yeah, yeah, yeah.
*  If you ask it to explain to you why it's not self-aware.
*  Yes.
*  It will do that too.
*  It will very happily do that too.
*  It does not have a differential opinion about those two outcomes.
*  Yeah.
*  Whereas every living, you know, every conscious, well, every even, even non-conscious living
*  or any, any, any living organism has a very different response to those two scenarios.
*  It's been amazing because in some ways I feel like it's as much been interesting to study
*  the AI as the AI has reflected for us to study ourselves, you know, and I think we are sort
*  of seeing that the magician has certain tricks, whether it's the AI magician or the human
*  magician, and it's going through this education process.
*  Curious though, like it feels like, you know, so, so like GPT can get into high school,
*  get into college, let's say, but like what would it take for it to get its PhD, you know,
*  and like we're, I think that's where the sort of dramatic stuff is to come.
*  Yeah.
*  Well, so again, exactly your point is that stressed, I would ask the question the other
*  way, which is like, well, okay, what does it take to get a PhD?
*  Yeah.
*  What does it take for a human to get a, like, how are the universities doing?
*  Yes, yes, yes, yes.
*  How are they doing on quality control of their own programs?
*  Yes.
*  How many people are getting PhDs today that we would say are like actually valid,
*  like scientific, you know, whatever, actual accomplishments?
*  Yeah.
*  By the way, people who got, you know, professors a hundred years ago, like how would they score
*  the PhDs that are being granted today?
*  Yeah.
*  Would they say the bar is higher?
*  I don't know the answer to that.
*  Or would they say the bar is lower?
*  Lower.
*  I think they would say the bar is dramatically lower.
*  Yes.
*  Right. And so, you know, the answer might be we have lowered the bar, but the same thing
*  for college admissions, like, you know, what does it take to get into college?
*  Well, what does it take to finish college?
*  Yeah.
*  And, you know, the education says, well, this is coming up a lot right now because it's
*  like, okay, GPT can auto-generate like, you know, essays, right?
*  And so student essays.
*  And so it's like, okay, the grading method of assign an essay and grade the result, like,
*  is probably not going to work anymore.
*  But it's like, wait, was that ever actually, like, just because we thought that that was
*  education, was that actually education?
*  Like, was that actually teaching anybody anything?
*  Like, actually, I'm sure someone's going to take that to apply to colleges.
*  Oh, yeah, yeah.
*  Yeah.
*  Absolutely.
*  Yeah.
*  College applications are basically done.
*  I mean, at least to the extent that you believe that college applications were a legitimate
*  way to evaluate anybody in the first place.
*  Yes.
*  Like, that's now over.
*  It's done.
*  I'd be more skeptical that they were ever useful in the first place, right?
*  Yeah.
*  Well, so in the PhD, let's talk about, like, at least in that old school mentality of a
*  PhD of some advanced learning where you become an expert in something.
*  Right.
*  You know, I think that's the thing where...
*  Expert.
*  What do you mean by expert?
*  Let's say the ability to be in the top 0.1% of humanity of, let's say, designing a drug
*  or building something.
*  Oh, interesting.
*  Is that what they teach?
*  Yeah.
*  Well, that's...
*  Is that what they teach in universities?
*  That is my goal.
*  I wasn't aware that was part of the curriculum.
*  I think it is.
*  Is it?
*  Sometimes.
*  Or at least that's what you have to do eventually when you get out.
*  Right.
*  Okay.
*  Yeah.
*  You know?
*  And you have to apply it.
*  I think it's...
*  One of the things about being an expert in my mind is that something that is the difference
*  between bad, good, and great can be really close.
*  Like, I could probably write a piece of music, but no one would think it's all that great.
*  You know?
*  And then you could have someone who's a good musician, but not a great one.
*  Then you have a genius, like a Mozart or Led Zeppelin or whatever you pick your genre.
*  And I think where we aren't there yet is that when the difference between good and great
*  is so close, or like I don't know if you remember from Spinal Tap, there's a fine line between
*  brilliant and stupid.
*  I think that is where I think it hasn't really hit yet.
*  In that if you look at the jokes, the jokes are just kind of, okay,
*  the screenplays it makes are not like brilliant screenplays.
*  I think it could get into college, but could it win best screenplay?
*  You know?
*  And so that's this part where I think we're not there yet.
*  But I think we're getting there.
*  So name a great music composer generated by a music PhD program in the university system
*  in the last hundred years.
*  Yeah.
*  Name one.
*  Yeah, I'm thinking more in the scientific side of things, but yeah, I don't think,
*  probably the PhD program in that space is probably not intended to generate music.
*  Okay.
*  Yeah.
*  Name one great screenplay written by a PhD in drama.
*  Yeah.
*  Yeah.
*  So that's an interesting point.
*  But I think what I'm getting at is still like the ability to do something.
*  And so the education part, we can talk about how they learn.
*  Because I think in the case of the screenplay or the music you're talking about,
*  they still have to learn something.
*  Right.
*  Or do you think they just innately sort of knew how to write a screenplay?
*  I don't know.
*  Yeah.
*  I assume there's a process where they write a screenplay, it's kind of mediocre.
*  Oh, yeah, yeah.
*  Yeah.
*  And then they get critiqued or they critique themselves and then
*  and then it improves and improves and improves.
*  Well, the screenplay, okay, so the divorce, divorce and the education.
*  Yeah, yeah, yeah.
*  Pre-education.
*  Yeah, yeah, yeah.
*  Behind.
*  Yeah.
*  Look, the screen, the test of the screenplay, the test for screenplay is does it sell?
*  Yeah.
*  So screenplays are subject to market discipline.
*  Yes.
*  Yeah.
*  Right.
*  And so question number one for a screenplay is does it sell to the studio?
*  Will they buy it?
*  Yeah.
*  And then test number two is when the movie comes out,
*  or the TV show comes out, does anybody watch it?
*  Yes.
*  Do they like it?
*  Do they finish it?
*  Yeah.
*  One of the fun things that Netflix will now tell people who make film and TV is they
*  actually tell them for the first time whether anybody's actually finishing their movie.
*  Yeah.
*  Yeah.
*  Yeah, just all those stats are kind of mind-boggling.
*  Right.
*  Yeah.
*  Yeah.
*  A lot of movies, and you know, people go to the theater and they feel invested in and they
*  don't want to leave in the middle, but Netflix, it's very easy to punch out or it turns out a
*  lot of screenplays.
*  You know, this is something that professional screenwriters will tell you, like it can't
*  ever sag.
*  Yeah.
*  Yeah.
*  Just as one example because people will stop watching.
*  So yeah, so screenwriting is subject to market test, popular music is subject to market test.
*  By the way, classical music, which I'm a huge fan of, is no longer subject to market test.
*  It's thoroughly subsidized.
*  Yes.
*  That's interesting.
*  Right?
*  It's not in the free market anymore.
*  Yeah.
*  Or maybe the equivalence of movie music is, you know.
*  Yeah, so movie music is subject to market test.
*  Right.
*  And it's probably the modern classical.
*  It is the modern classical.
*  Yeah, for that reason.
*  So yeah, like the market test is real, but yeah, let me grant your point.
*  So let's build on what you said.
*  Let me grant your point.
*  Like, let's use, could we use the term paste?
*  Yeah.
*  Like-
*  Yeah.
*  Or just ability to do something hard.
*  Well, ability, okay, so ability to do something hard and let's say create something hard.
*  Yes.
*  Create something complicated and then also the ability to judge.
*  Yeah.
*  Right.
*  Critically, like to start with judging your own work.
*  Yeah, and probably therefore the ability to prove.
*  And then therefore the ability to prove, right.
*  So yeah, I think that there's, yeah, so there is something about taste.
*  Yeah.
*  Like I tend to think this stuff all has like aesthetic.
*  Yes.
*  Like a properly constructed mathematical formula or software program has aesthetic.
*  100%.
*  Molecule design has aesthetic properties.
*  Physics.
*  Right.
*  Physics has aesthetic properties.
*  All of it.
*  Yeah.
*  So there's something about taste that's like some combination of quantitative, qualitative.
*  Yeah, like a great startup is like from a mediocre one, this taste.
*  Right.
*  Yeah, exactly.
*  And like there's certain signals, like there's certain methods and certain signals,
*  but it's not necessarily reducible to an algorithm.
*  It's more of like a composite, you know, it's sort of the foundational knowledge combined
*  with some scope of experience combined with some kind of ineffable characteristic of judgment.
*  Well, we associate an aesthetic with it, but I wonder whether that's also just our emotional
*  connection to it.
*  Right.
*  You know, because I think we have this good right or wrong or more right or more wrong.
*  Right.
*  Like a gradient, like yeah, that's the right direction.
*  Right.
*  And but a lot of it is also whether something is elegant versus like just a hack.
*  Right.
*  You can tell whether these great things are just simple and powerful rather than like some,
*  some complicated machine to do something that, you know, you know, this is going to
*  eventually fall apart or that.
*  You think about that's true in physics or in a go to market or in a or in music.
*  It has all that both that sort of complexity and simplicity at the same time.
*  But so but I'm curious, like so when I guess that point, which I think that's a when not an if.
*  Okay.
*  Yeah.
*  Yeah.
*  Yeah.
*  Or so why would you say why wouldn't it get there?
*  Because like, do we even understand how it works in people?
*  Maybe we don't have to.
*  Well, maybe we don't have to.
*  So this is where I describe this.
*  This is like the AGI question.
*  This is where I call the hand wave.
*  The embedded assumption that it's a when is that it will be an emergent process
*  that will sort of unlock as a consequence of greater and greater levels of scale.
*  Yeah.
*  Maybe.
*  Yeah.
*  One way of looking at that is yes, that is just what's going to happen.
*  That's the human consciousness emerged.
*  Like that's obviously what's going to happen.
*  The other impression that is it's just a mess.
*  And it's a hand wave.
*  It's a hand wave and it's what the kids would call cope.
*  And the cope would be okay.
*  So here let me ask you a question in return.
*  What is the sub specialty of human biology and medicine that best understands
*  the nature of human consciousness today?
*  Oh, I don't think there is one.
*  There is one.
*  Anesthesiology.
*  Okay.
*  Which is poorly understood.
*  Well, it's poorly understood.
*  But they know how to turn it off.
*  Yeah.
*  And they know how to turn it back on.
*  Yes.
*  They've got the on-off switch.
*  That's all we got.
*  That's all we have.
*  Like we have been we collectively have been studying this question of human
*  consciousness for a very long time.
*  We have very advanced technologies today.
*  Functional MRI and like all this stuff.
*  That speaks to there's a field I would love to see created,
*  which is molecular psychology.
*  Where you can start to probe this a little more than on-off.
*  Okay.
*  And molecular.
*  Is it literal or metaphorical?
*  Quite literal.
*  It's a play like molecular biology was this big thing in the 80s
*  where we finally can bring like chemistry of small molecules to poke at biology
*  or chemical biology as well.
*  And if we could use like small molecules to maybe perturb more than just on-off,
*  but like perturbs things, we can start to understand the brain a little bit.
*  Because reading is one thing, but like poking and sort of perturbing
*  and then seeing the result is usually how we do any sort of experiment.
*  Right.
*  And would you do that?
*  Is that a chemical?
*  Would that be a chemical experimentation?
*  Or that be electrical?
*  It could be either one.
*  It could be any of that, but probably some combination of those things.
*  Like neural links like on a track in theory to enable some of this.
*  Yeah.
*  So like look, we just don't.
*  Okay.
*  So here would be the counter argument is like we just we don't know how human
*  consciousness works.
*  We actually don't.
*  If I actually I didn't go in the field, but I didn't go in the field.
*  Actually was that was going to be what I was going to study in school 30 years ago.
*  But I looked at the field at the time and I was like they don't have a clue.
*  Yeah.
*  I'm going to spend my entire career.
*  So you want to go into consciousness.
*  Tilting at windmills.
*  Yeah.
*  At the time cognitive science was like the hot thing.
*  Yeah.
*  Building off of AI.
*  Yeah.
*  But that was like expert systems.
*  Expert systems.
*  Well, early neural networks and then a lot of it got into brain chemistry
*  and like we're going to figure this stuff out and we're going to learn how to build.
*  You know, it's just like they didn't know then as far as I know they don't know now.
*  So the counter argument would be this is all just like massive cope for the fact
*  that we actually we don't understand that.
*  So we don't understand how to do it.
*  And so all we can do is hand wave and kind of just say, well, it's just going to be
*  emergent.
*  And it's like, no, it's not.
*  And we're going to be sitting here 30 years from now and we're still not going to have
*  any more knowledge, you know, barring other scientific breakthroughs of the kind that
*  you're talking about.
*  What's interesting is if you think about that time, we had neural nets, but they were all
*  single layer basically.
*  And they couldn't even do XOR.
*  You know, you couldn't even do some simple things because you needed deeper networks
*  to get at them.
*  And you couldn't have deep networks then because we didn't have the computational power.
*  And so the space was pretty dormant for a while, you know, AI until like we started going to
*  having basically just the computational power from GPUs and other things to be able to go
*  deep.
*  And then you could feed the data through.
*  So it is possible that we sort of have a point where we sort of saturate the compute that
*  we have now.
*  We get to as much as we can get to.
*  And that may get to close to AGI, maybe not.
*  And then it takes another like 30 years to get to the next sort of breakthroughs to get
*  there.
*  Yeah.
*  But OK, so I would pull back from this.
*  So AGI is the fun thing.
*  There is a sort of step back, which is to pick a domain.
*  And you know the domains I think a lot about, like life sciences, designing drugs, doing
*  health care, like seeing if you can pick a diagnosis.
*  Can you suggest a drug?
*  In those areas, now we're talking about a much more limited domain.
*  So we're not talking about we don't need to go all the way to consciousness for that
*  necessarily.
*  You can have something that's more limited.
*  In that limited domain, right now it seems like generative AI isn't quite far enough
*  yet to be able to like, yeah, I don't see the examples quite yet.
*  Are you sure?
*  Yeah, well, we'll see.
*  I mean, so what's the counter?
*  And I know you especially think about health care a lot.
*  Yeah.
*  Yeah.
*  Well, so the first thing is whenever you score it, well, let's talk about medical diagnosis,
*  which is kind of just low hanging fruit question because everybody experiences it.
*  So to start up front, you have to ask a question up front, which is like, is the goal, what's
*  the threshold?
*  Is the threshold perfect or is the threshold better than human?
*  Yeah, that's a great point.
*  Right.
*  Yeah.
*  And by the way, this is a topic that comes up all the time with self-driving cars, right,
*  which is, is it perfect?
*  It will never make a mistake or is it just going to be better, better than human?
*  And the way that self-driving cars score this is accidents per 1,000 miles driven.
*  And self-driving cars are already lower than human drivers.
*  And humans may actually be getting worse with texting.
*  With texting and other forms of it.
*  By the way, they increase forms of certain kinds of drug abuse, right?
*  And then, of course, the machines have the characteristic they get better universally,
*  right?
*  So a car has one mishap in one location.
*  Every other car gets trained on how to deal with that in the future.
*  The learning happens across the entire system.
*  And so, like, I think you can make a serious argument that, like, basically,
*  self-driving cars are already better than people on a relative basis.
*  And therefore, like, morally, you could even go so far as to say human drivers should be outlawed today.
*  Yeah.
*  Right.
*  If you have the alternative, you can have the self-driving car, then, yeah.
*  Like the utilitarian, I'm not a utilitarian, but the utilitarian argument would be you should obviously
*  ban human drivers today because the machine-driven stuff is already better.
*  Probably, by the way, the same is true for airplanes.
*  Yeah.
*  Right.
*  Now, we're not actually going to do that and there are other considerations involved and so forth,
*  but, like, you know, logically speaking, you should at least think about that as a possibility.
*  And I think you should think about that as a possibility, I think, for medical diagnosis,
*  which is, you know, and here the test is very simple, which is, well, at least express two tests.
*  Test number one is the absolute test, which is if I feed in a set of symptoms, it generates the correct
*  diagnosis 100% of the time, deterministically guaranteed.
*  Right.
*  That's a high bar.
*  It is very high bar.
*  The other is I do that with the algorithm and then I go to 100 doctors, human doctors,
*  and I get back 100 different responses, and then let's compare.
*  Yeah.
*  Right.
*  And then let's track over time and so.
*  So you compare to the median doctors.
*  Yeah.
*  Yeah.
*  Right.
*  And, like, how good is the median doctor at doing the diagnosis?
*  And, like, I don't know what your experience has been.
*  Yes.
*  Well, and the median doctor may be smart, but also may be overloaded, may be exhausted,
*  may have, like, 12 other patients.
*  15 minutes.
*  Yeah.
*  Yeah, yeah, yeah.
*  A lot of experiences, 15 minutes.
*  Yeah.
*  You know, there's a thing here where, like, experts in these areas tend to either, like,
*  be, like, doctors themselves or they, like, know a lot of doctors or they have, like,
*  they're, you know, they work in the industry, they make money, they have a concept, they
*  have a concierge doctor who spends a lot of time with them and does house calls.
*  Yeah.
*  The median healthcare experience is 15 minutes in somebody's, you know,
*  harried schedule with a doctor that may or may not ever see you again and has very limited data.
*  Yeah.
*  Yeah.
*  And.
*  Yeah.
*  And there's a well-known algorithm, which is that they come up with a diagnosis,
*  they come up with a treatment, you go with that, that doesn't work, you repeat.
*  Yeah.
*  And while not sick and, while still sick and not dead, you just repeat.
*  Yeah.
*  And then I think many of us have been through that.
*  Well, and then there's, and then there's all the other sort of things.
*  So then there's like drug interaction, you know, is any one doctor tracking all the interactions of
*  your drugs?
*  Yeah.
*  Then there's this other issue, which is, okay, they give the prescription,
*  is there actually compliance for taking the prescription?
*  Does the doctor actually know whether you're taking the prescription?
*  Yes.
*  Compliance is one of the biggest disasters.
*  Right. But that means, like, the ability for a median doctor to even evaluate the
*  success of a treatment, they may actually may not be able to do it because they may not have the
*  data on compliance.
*  Yeah.
*  And so, like, you look at the existing, I don't know, for me, you look at the existing system by
*  which this all happens, it's very similar to looking at the existing system by which people
*  actually drive cars, which is like, oh my God, this is not good.
*  Like, this is really not good.
*  And we kind of fool ourselves into believing that it's good because it kind of feels good, and we
*  don't really want to look behind the curtain, but we look behind the curtain, and it's pretty
*  horrifying.
*  Yeah.
*  And so from that standpoint, if you follow that logic, then it says, okay, if the machine could do
*  a better job, you know, if the machine was twice as good at just, like, listening to symptoms,
*  giving the response, doing the prescription, doing the follow-up.
*  Yeah.
*  I mean, how far, I don't know if you've done this, but you plug in a list of symptoms.
*  I've been playing with it too. Yeah, yeah, yeah, yeah. Yeah, yeah. I mean.
*  Because it does have access. I mean, it has access to the collective medical knowledge.
*  And if it doesn't now, it can't, right? You know, it could be filled with all the EMRs,
*  all the medical records and so on, and then it could sort of learn from that as well.
*  Right. Well, then the other question I'm sure you thought about, but like, okay, so the medical
*  field moves. And so in the existing system, the media and doctor has to, like, read all the papers.
*  Yeah, yeah, yeah, yeah, which never happens, but no one has time for that.
*  Yeah, right. Yeah, and there's continuing education, but still it's not the same.
*  Well, here's an example. Do you want your GP? Would you want a MGP or an old GP?
*  Probably young, right? Well, presumably the old GP has more experience, and so they have more
*  pattern matching over time and more experience with patients. But the young GP is probably more
*  up in the current science. Yeah, yeah, yeah. Okay. Yeah. And then it's like, okay, do you really want
*  to have to make that trade-off? Or can the machine actually have both of those? Yeah, exactly. Well,
*  that's the thing is that, like, you talked about how, like, can it beat, let's say, how does it do
*  compared to 100 doctors? When the 100 doctors collaborate, presumably that's the ideal situation,
*  right? I mean, or, or, no, that sounds horrifying. No, no, no, I mean, that's the wisdom of the
*  crowd. No, that's a good thing. It could go, well, I guess it could go either way, but usually,
*  that's the Soviet method. Usually when you actually, when you pool it, you can, or at least maybe it's
*  how you collaborate. Have you really found human beings to make better decisions in groups than
*  they do as individuals? That's a good question. Yeah. In your entire life? Yeah. Oh, yeah, yeah.
*  The full, the serious answer is wisdom of crowds, madness of crowds. Yeah, yeah, yeah, yeah, yeah,
*  or flip sides of the same coin, right? And so when are you harnessing the wisdom? When are you
*  descending into madness or even just, you know, mediocrity? Yeah. Yeah, I can, very specific tasks,
*  groups can do well, but otherwise it's like one big group project from high school. Yeah. Yeah,
*  which is like a- Well, so generally, right, generally what happens to people in groups is
*  the social conformance kicks in, right? And so people want, there's a well-known, you know,
*  kind of thing. There's like this law of like group polarization, which is you take a group of people
*  who are inclined slightly to one side of the political spectrum. Yeah, yeah, yeah. You put
*  them together, let them talk for three hours. They all come out much more radical. Yes, yes.
*  Because they've self-reinforced. Yes, yes, yes. Right. Well, so maybe that's a really interesting
*  thing because you can imagine training AI to do have these different aspects and its collaboration
*  with other versions of it would be very different. Yeah, yeah, could be very different. I mean, yeah,
*  maybe it should do this effectively in Monte Carlo. Yeah, yeah, yeah, yeah. Right, right, run the same
*  inputs a hundred times. Yes, yes. Right. Yeah. Well, okay, so either we'll never get there or
*  we're already there now. Right. But I think in 10 years, it does seem especially, maybe we hit like
*  another winter, but it seems like things are accelerating so much. This seems pretty real.
*  It seems pretty real. What do you think society needs to do to change? Because there's like all
*  these things we were talking about, and this seems bigger than like just the revolution of
*  software over the last 20 years or internet from the last 20 years. Because we're talking about how
*  it changes government, how it changes regulatory, how it changes education. I mean, I don't even
*  know where you want to start with that, but I think that's something where it may take us 10
*  years just culturally to be able to get ready for this thing that may arrive in 10 years or may
*  already be here. Right, right. Yeah, I don't know where you want to start. Yeah, so where I would
*  start is we've already fallen into, we have deliberately kind of fallen into a trap already,
*  which is we've only been using a single kind of example, and we've used it both in our discussions
*  on medicine and also in education, which is basically something is done today. People are
*  doing something today and then maybe the machine can do it instead. That's an important thing,
*  and that's what we're thinking about. But the way that technological impact actually plays out in
*  human society is not just that. The way it plays out is it lets you basically revisit more fundamental
*  assumptions. Or what's not being done today. Or what's not being done today that all of a sudden
*  becomes possible. And this always comes up in any sort of discussion about employment,
*  whether people doing jobs versus machines doing jobs, so people get worried about technological
*  displacement of jobs. But technological displacement of jobs, like technology never actually creates
*  unemployment. Technology only ever creates jobs in that. And the reason for that is technology
*  makes possible things that were not possible before, which is what leads to growth. And so
*  specifically, for example, the role of the doctor. It's like, okay, the doctor of the future is
*  probably not going to be doing the same. We have a term in IT, break fix. It's kind of what doctors,
*  you know, the core motion of a lot of doctors is, as you said, diagnose, prescribe, diagnose,
*  prescribe. It's debugging. Yeah, debugging, iterative. Exactly. Doctors of the future,
*  probably, like the technologically empowered doctor 10 years from now is highly unlikely to be
*  spending their day doing that. They are probably going to be spending their day doing things that
*  are actually much more important than that. Yes. Right. And so, for example, maybe they have more
*  time, right, with patients because the machine is a time-saving device. Maybe they have more data
*  to draw on, you know, to be able to make their decisions. You know, they've got the machine as
*  a partner in making the decisions. Maybe they're able to spend more time in their conversation
*  with the patient talking about psychological issues as compared to just physical issues,
*  and as, you know, in a lot of medical conditions involve, you know, two sides of that, or behavioral
*  issues. Well, as you know, like a lot of primary medical issues today are a consequence of
*  different behaviors. Yes. And maybe doctors should be spending more time on behaviors.
*  Yes. And it speaks to compliance as well as other issues. Yeah. Yeah. I mean, compliance is a
*  behavioral issue. Like, why don't people do this or that? Right. But then also there's all the
*  behavioral health issues. Right. Which is probably one of the biggest catastrophes that we have
*  coming out of COVID. Yeah. Exactly. Right. Yeah. Exactly. And maybe doctors should be, you know,
*  maybe the doctor of the future will be more of a life coach, of which there will be a pharmacological,
*  you know, sort of a biological or pharmacological component. Right. But maybe it's like, maybe it's
*  more of, you know, sort of the dream of sort of holistic medicine. And so, you know, maybe the
*  doctor of the future is just as much, is actually a much more important and, you know, sort of
*  fundamental figure in your life than he or she is today. Yeah. That sounds fantastic. Yeah.
*  Right. Exactly. So if I'm a doctor, that's where I would want to be, like, angling towards. Right.
*  And then that's probably a bigger and more important market. Right. And then in terms of,
*  like, the size of that industry will probably expand, you know, kind of correspondingly. I think
*  the same thing is true in education. Like, you know, the teacher 10 or 20 years from now, I hope,
*  is not doing the same things the teacher is doing today. I hope they're doing much better things.
*  Yeah. Right. So for example, one-to-one tutoring. Like, there's basically, let's take education
*  example. Like, there's only one in the last, like, 50 years, there's basically only one known
*  education intervention at scale that actually improves outcomes after, you know, thousands of
*  experiments. It's one-to-one tutoring. Yes. Which is very ancient, actually. Which is very ancient,
*  right. Which is the original form of education. Yes. Which is literally how people used to get
*  educated. And so maybe this industrial, you know, the education system we have today is an artifact
*  of the industrial age. If the industrial age components of it become automated, the teacher
*  becomes freed up to actually work more one-to-one with students, the result might actually be a
*  significant breakthrough in how education works. Although the ways you're describing,
*  you can imagine also, like, AI doing one-on-one pretty intensively. Well, yeah, there will be
*  part of that. But also, yeah, and maybe the AI is the one-on-one, and maybe in that case, the teacher
*  is supervising the AI. Right. And maybe the teacher is making sure that the AI is, like, on the right
*  track and doing the right things and is able to kind of sit at the control panel and watch all
*  that happening, right. Well, that speaks to something really interesting because I think
*  we're probably a little nervous, at least short term, to just unleash this and, like, not pay
*  attention to it. And so you'll have the doctor using this as a tool but keeping an eye on it.
*  You'll have the teacher maybe scaling dramatically for all this one-on-one but keeping an eye on it.
*  Do you think that's actually the way it's going to? I mean, this is kind of how all technologies work.
*  Yeah. So it's sort of, another way to think about it is you can imagine two acronyms for
*  AIs, artificial intelligence, which kind of implies replacement. Yeah. The one I actually
*  like much better is augmented intelligence, which is like the old Doug Engelbart idea.
*  And augmented intelligence is, you know, another example, the term would be Steve Jobs,
*  a bicycle for your mind, right, or a bullet train for your mind. So the augmentation, right. And so
*  the way, if you just look at the history of new technologies, the way it plays out is everybody's
*  afraid it's going to be a replacement and it turns out it's an augmentation. Yes. So you take a human
*  being and you give them the technological tools. They therefore are much more productive. Like a
*  factory versus like an artisan with their tools. Yeah, exactly. Or like, you know, the dream of,
*  like, an exoskeleton, you know, any of these things. I mean, look, artists are much more
*  productive today with digital tools than they were with just, you know, painting canvas. Yeah.
*  And by the way, even artists that still work on painting canvas are much more productive today
*  because they can sell their products to a much larger audience online. Or like my favorite thing
*  for art is like, you know, photography comes online and that dramatically changes art because
*  being photorealistic isn't that interesting anymore. But so that creates modern art.
*  Extraction, right. Yeah. Which actually is maybe even more expressive than just taking a picture.
*  And so now I can make pictures with AI all the time. So where does that shove art? Maybe to more
*  interesting places. And the artists in history, the artists were not happy about the introduction
*  of photography because they viewed it originally as a threat. Of course. Yeah. But it transformed
*  things. Yeah, it turned out to be, it turned out, yeah, it turned out. The market for art is much
*  larger today than it was before the introduction of photography. I mean, we call it different
*  things. We call it things like TV shows and so forth. But like the market for creative
*  expression is much, much larger than it used to be. By the way, music, same thing, right? You know,
*  recorded music was originally a threat. It used to be musician would compose and perform,
*  right? And then, you know, to have music in your home, you'd have to hire a musician to come into
*  your home. You know, phonographs were a threat to that. But phonographs made the music industry
*  much, much larger. So people who were good at making music all of a sudden had a much bigger
*  market. Yeah. So I think AI is going to play out in a very similar way. Like there are people who
*  will argue, you know, AI is different because it just keeps climbing this ladder and it will replace
*  everything. I actually think it's going to be, basically it's the ultimate superpower. It's the
*  ultimate pairing. We were talking about creating screenplays and scripts. A good example, if I'm a
*  Hollywood screenwriter today, like GPT is my best friend and I'm just sitting there all day long and
*  I'm just saying, you know, playing out. It's like, okay, I reached this plot point dot dot dot. Give
*  me a list of like 10 ideas for what to do. It's like, oh, okay, that's an interesting one. I'll
*  give you an example of how this could work. So Mad Men is one of my favorite shows. Matthew Wiener,
*  you know, ran that show and he was always praised. He's like, wow, that show is so unpredictable.
*  Like, you know, you never knew where it was going. And he said, yeah, well, the technique we had in
*  the writers room was at any given time we had to figure out what happened next in the plot. We would
*  brainstorm. We would come up with the five sort of things, five obvious things and then we would rule all those out.
*  So GPT would be obvious things and you rule those out. Yeah, exactly. So it pushes creativity. All of a
*  sudden every individual screenwriter can do that without having to have a whole writer's room to
*  brainstorm. You just plug that in. It gives it back to you in two seconds. He was like, okay,
*  not those things. I'm going to do something else. And now I am more creative than I was before.
*  Well, your comment about music is really interesting because now we've got Spotify,
*  so we've got everything in your pocket. Can you imagine like the AI Spotify, which is like the doctor,
*  the personal trainer, the educator, like all those different things in my pocket available right now
*  for whatever I need to do. Yeah, that's right. Yeah. And with the human escalation path, right?
*  Yes. Like the AI therapist or whatever, but yeah, with the thing of like, well, okay, yeah,
*  I have a thing here. Especially if it gets really serious to escalate immediately. Yeah, that's right.
*  Yeah. Okay. So what's going to hold us back? What do we need to change? So I think it's mostly fear.
*  This is where maybe I'm a radical on it because this is usually where people start talking about
*  regulation. I think it's like we have these fear-driven reactions. I always think of it.
*  There's this deep-seated myth in human societies, the Prometheus myth, right? Yeah. And the Prometheus
*  myth is all about new technology, right? And the Prometheus myth is like basically this new technology
*  of fire. And fire is one of these classic technologies where it can be used for good.
*  It can burn the whole of death. Or it can be used very badly, right? And yeah, it can destroy your
*  whole world. And so Prometheus famously goes and retrieves fire from the gods. And his punishment
*  for it is to be chained to a rock and his liver pecked out every day for the rest of eternity.
*  So embedded in there is the anxiety about the new technology and then the arrival of the new
*  technology maybe is like the fear, right? Is that it's not bad and the person who does that should
*  be punished. And so I always find that myth kind of plays out over and over again in all these
*  discussions about regulation that this stuff needs. Especially it's the gods who punish him,
*  right? The existing gods. Yes. Well, on behalf of existence. But yeah, so yeah, I think generally
*  it's this, it's just you get these fears. If you look at the history of, we talked about some of
*  this, if you look at the history of new technologies, they generally have had these fears every step
*  along the way. Every new technology has been created with some prediction that it's going to
*  upend the social order and cause the enormous chaos. Well, it does upend to some degree.
*  It will do that. But generally speaking, in a positive way, on balance, technology is
*  why we live much better lives today. Certainly people now would not want what people had 50 years
*  ago. Nobody would make that, yes. Right. And you could do, you could go back in time infinitely.
*  It would be like that. Nobody would ever make the trade, yes. Nobody would ever make the trade to
*  go back in time. It would never happen. Yeah. And right. That's literally, it's because you would not
*  want to lose the technologies and the consequences of the technologies you have today. So I think
*  that's true. And so I actually think like fear may be the rip off FDR, fear may be the actual
*  biggest threat. Fear leads to the kind of reach for regulation. I'm a skeptic. I don't,
*  it's like, I don't know, right. Regulating math. Are we really going to regulate math?
*  Well, but it's not going to look like regulating math, right? It's going to look like regulating
*  this superpower. That's what they're going to say. Yeah. Right. But then the actual implementation
*  of this is regulating, regulating, regulating algebra. Yeah. Yeah. Regulating algebra,
*  regulating linear algebra. Are we really going to regulate linear algebra, matrix multiplication?
*  Really? Seriously? Yeah. And then even if we do, are we going to possibly do it in a way that makes
*  any sense? Yeah. Well, okay. But it won't obviously won't look like that. It will be saying, well,
*  we can't have computers drive cars. Right. Or like, what's, how do you give the computer a test?
*  Yeah. Or how do you know? Like, okay, you make this, I'll be the cynic. So, okay, you make this
*  claim that the computer AI is better than human. Like, how do I know that? Because that, well,
*  as it turns out, because the cars are driving. Yeah. So, yeah, it's okay. So here was, okay,
*  so here's how that played out in self-driving cars. Yeah. Yeah. There was one category company
*  that said, we're going to basically wait until it's perfect. Yes. And we're going to basically
*  try to validate it. We're going to work with regulators and build this stuff. Yes. Yes.
*  There's other- They're not driving. Yeah. And they're not on the road. They're still not on the
*  road. Yeah. There's another category company that said, you know what, let's evolve out of basically
*  the cruise control. Yes. And, you know, it's sort of cruise control and then it's radar-based
*  And you get humans driving with it and you label data and- Exactly. And you don't expect the car
*  to drive itself from the very beginning. The car is like an autopilot kind of thing. The expectation
*  is you pay attention. Like, you know, Tesla is the company I'm alluding to. And if you turn on
*  full self-driving on Tesla, you're still, you know, you're still told, like, you're not supposed to
*  be watching a movie. You're supposed to be actually paying attention. And the car will,
*  like, alert you when it's time to pay attention. But, you know, notwithstanding that, Tesla has
*  been climbing the ladder on self-driving car functionality capability. They do new software
*  releases push live to car at night anytime they want. Those new releases are not being tested by
*  any federal, you know, it's a whatever is not. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah.
*  There's no actual test happening. Yeah. And that has led to incredible progress including,
*  as you said, clearly in the data, this is now safer. Because you can't make it work just
*  magically, right? It has to happen gradually. Right. Because it's actually much like medicine.
*  It's centering into a complex system with a lot of variables in the real world. Like medicine,
*  too, it's like life or death. You know, it's just serious. But, yeah, but yeah, we go back to how
*  we started the conversation. Yeah. The the wait for permission thing, the binary zero or one wait
*  for permission, wait for perfection thing versus the incremental let's get better and better and
*  better. And the threshold is, is it better than humans? Is it is it is it a net improvement?
*  I mean, clearly in self-driving cars, that second approach is the approach that's working.
*  If you just observe the real world. And you think you get to the tipping point where, look, let's
*  look at the statistics we have because we have all this happening right now. We have the statistics
*  and it's like so much better than humans. Why wouldn't we do it? Yeah, exactly. Right. And then
*  at some point the morality tips where it's like, well, obviously we have to go in this direction
*  because it's just obviously better. Yeah. I suspect we're going to get there in medicine pretty quick.
*  Yeah, yeah, yeah, yeah. I'm an optimist on that. And again, I'm not an optimist because I think
*  the AI is going to be perfect. I'm an optimist because I think the status quo is not that great.
*  Yeah. Well, that might be like you start empowering doctors, you give them tools,
*  they start using them, you start empowering patients, patients start using them. And actually,
*  here I think it's even different than a car because you're not on a road. It's your body
*  or whatever. And actually, patients are driving their own healthcare more than ever. I think COVID
*  was another sort of tailwind there. So maybe you start, maybe it's just about developing the tools
*  and giving them out. Well, here would be an example. So let's use our screenwriting example.
*  It's applied to medicine, which is, you know, a given set of conditions, there may be many
*  possible diagnoses. An experience I've had is there's a set of symptoms. One doctor comes up
*  with one diagnosis, another doctor comes up with a different diagnosis. You read the literature and
*  it's like actually both of those diagnoses in theory are, but like for some reason the one guy
*  only thought of the one, the other guy only thought of the other. So a way for doctors to start using
*  this technology today would be plug in the symptoms, give me five possible diagnoses.
*  Yes. Okay. Oh, I didn't even realize that, you know, because maybe this is a new thing since,
*  you know, I went to medical school or something. I didn't realize diagnosis number three was an
*  option. I should go look at that. Yes. Yes. Right. And so the doctor is still doing the diagnosis.
*  It's your screenplay example. Yeah. You're augmented. As a doctor, you're augmented
*  because the AI in that case is alerting you to things that you should know, but you don't know.
*  Yeah. Yeah. I mean, that's interesting. It's almost like having a mentor or,
*  or just someone to riff with. That's right. Yeah. Yeah. Yeah. And they write, it's a great thing is
*  it is a machine. It will riff with you as much as you want. Like it will sit there at three in the
*  morning. It's a hundred times for you. It's happy to, it doesn't get bored. It doesn't get tired.
*  Yes. By the way. And then it also has the advantage. It has all the up-to-date information. Yes. Yes.
*  And all the outcomes. And when it makes a mistake, it actually can learn from it rather actually from
*  other than being like devastated by it or emotionally reacting to it. Right. Right.
*  And like self-driving cars, if it makes, if some other doctor in some other state had a patient
*  last week and made a mistake and they fixed the mistake, it will not make the mistake again.
*  You're a patient. Yeah. Yeah. Right. Yeah. So, I mean, so you think, and so that is a very
*  different regulatory play than we've seen in the history of healthcare. Well, I think that's just,
*  well, you tell me, I think that's just going to happen. So here's what everybody knows. I'll
*  give you a couple of things. Everybody knows that patients should not be on Google. Yes.
*  They're on their own symptoms. Everybody knows every patient now does that. It's called Dr. Google.
*  Exactly. Literally how it's called in the field. Right. And there's no way like you're not
*  practically speaking and I like regulate that out of existence. Yeah. That's going to happen.
*  I think doctors using these new tools as an augment is something that they can just do.
*  It doesn't require approval. So the ship has already sailed, do you think? I think so. Yeah.
*  And by the way, patients using GPT, if it hasn't started, it's going to start imminently. Yeah.
*  Probably. So the patients are going to show up with the results of GPT queries and the doctors
*  are going to have to respond to that. And so they're going to end up being in this world
*  whether they want to be or not. But that's actually really interesting because as a patient,
*  and I probably know just enough about medicine to be dangerous to myself, but like I show up
*  with the doctor and I have all of that thought out, basically that might equalize the patients.
*  Such that they can actually come much more educated and come from much more thoughtful
*  and they become much more in the process as well. Yeah. Okay. So what goes wrong? Double-edged
*  sword. I mean, as a doctor, do you want your patient? Yeah. You want your patient more educated
*  or less educated? They may just be humoring me, but I think they want them more educated. Maybe
*  with you they want you more educated. With me they might look a little bit more sideways.
*  But if it was really helpful, I think it's just about how good it is, right? Okay. So what goes
*  wrong? I mean, look, the big thing that goes wrong, I mean, look, the big thing, I think two things
*  go wrong. So one is just the expectation of perfection. And look, it's very easy to generate
*  the negative headline. It's very easy to set off the scare, the moral panic basically. A single
*  instance goes wrong and it gets extrapolated. We talk a lot about thalidomide. It'd be very easy
*  to have that kind of moment. Or like the person on a bike that got hit by a Tesla or something
*  like that. I think it was biking across a freeway. Right. Exactly. And so a human probably
*  hit him too. That's right. Oh, well, that's a good point. Yeah. So the trolley problem,
*  the trolley problem's been in the press a little bit more recently because it turns out that Sam
*  Beckman Fried was an expert in the trolley problem. So that shows you that maybe that's
*  not the route to ultimate morality as it's been marketed. But yeah, the trolley problem
*  always gets mooted about for self-driving cars, which is you have a choice between killing,
*  it's like, I don't know, five grandmas or one little kid or all these different like,
*  you have to pull the lever to decide. But human drivers don't. No, no, no. Human drivers never
*  make that decision. No, no, they have gas or brake. Yes. Right. And they have, I'm going to hit the
*  car in front of me or I'm not going to hit the car in front of me. It's never this elaborate thing.
*  It's always a very simple thing. And so it's not a question of whether the machine can ideally
*  solve this sort of idealized complex problem. It's going to hit the brakes faster when it's
*  about to crash into the car directly in front of it. And so properly, logically kind of containing
*  the expectation here to actual real world and not having this spin off into these like, basically,
*  fantasy narratives that you can then criticize. Yeah. So that, the absolute limits. And then,
*  yeah, look, I think just the generalized fear. And what I always have to remind myself is like,
*  like I say, I'm a software developer by background. It's like, okay, I can actually,
*  like the algorithms that do this, like, you know, can I tell you every aspect of how they work? No.
*  Like, do I understand how they work? Do I understand the basic foundations? Do I understand
*  the basic math? Yes. This is why I make the comment about regulating math. Yes. Now,
*  to somebody who's not a coder, right, this whole, all this stuff just seems like weird magic. Yeah.
*  And so there is a, I have to remind myself to be patient and tolerant of people who don't understand
*  the mechanics of what's happening. That said, I think the people who are going to be, I think
*  they also have to get into the mechanics and try to understand this. And there's always slippage
*  there. Yeah. So what's the antidote to fear? Is it optimism? Is it education? I mean, ideally,
*  I mean, I think there's, ideally it's, yeah, ideally it's cultural, cultural orientation
*  towards new technology. And then ideally it's, it's education and people learning and kind of,
*  or, you know, the CP Snow II cultures. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes.
*  Coming together and kind of educating each other. Honestly, a big part of it also, I think, is when
*  things become a fated company. And this is what Tesla's done with self-driving cars. Yeah. Like
*  if it's just happening. Yeah. Yeah. Right. Cause who would want to go back? Like nobody wants to
*  go back. And like the system adapts. Right. And so there was this famous Uber, Uber fought all these
*  regulatory wars in all the cities that they were in, cause it was not technically allowed under the
*  taxi limo charters in the beginning. And so one of the things they did early on was they just made
*  sure that there were always lots of Uber cars available around state houses and city halls.
*  Yeah. And so whenever somebody, you know, so you'd literally have somebody who's like, you know,
*  sort of giving this like roaring speech, you know, in city hall about shutting down Uber. Yeah. And
*  then they would come out and they'd have to get home really fast. And Uber would show up 20 seconds
*  later. Right. It's like at some point it just was like taken for granted. And then at that point,
*  if you just said, literally, are we going to take Uber away? People would have said, no, we can't.
*  It's over. And that's what happened. And then, and then they, and then literally what happened is they
*  changed the laws to accommodate that behavior. And so I actually think part of it here is just
*  like having these tools. Okay. Here's the thing. Here's a good news thing. Yeah. These tools are
*  becoming widely available upfront. Right. So like 50 years ago, a new technology like this would have
*  been like deployed in the government first and then in big companies. And then years later in the
*  form of something individual people could use the model today is like, it's just online. Yeah. Like
*  GPD is online right now. Yes. Well, the, the future of paint is really intriguing because from an
*  engineer point of view, it's the engineer's dream that if we make it good enough, such that it can
*  get to a point where people just love it and it's helpful and it does what it needs to do, the rest
*  will take care of itself. Yeah. I mean, I kind of think that's mostly how things are. I mean,
*  yeah, yeah. No, it's a beautiful future. Yeah. Yeah. So now look, having said that healthcare is
*  very sophisticated, right? There's lots of regulations, there's lots of payment, right?
*  All these things. So I saw this thing on Twitter the other night that blew my mind, right? Because
*  this whole time I've been thinking in terms of like, you know, diagnosis stuff in my life.
*  So this doctor posted a video and I think I saw that one. So that was a video and he said, look,
*  he said, the problem is whatever diagnosis or whatever, like I do the diagnosis, I do the
*  prescription. Then it's a question of whether or not I can get the insurance company to reimburse,
*  to actually pay for the thing. To do that for anything even slightly out of the ordinary,
*  I have to write a letter, I, the doctor has to write a letter to the insurance company and that
*  letter needs to be in a specific format and it needs to make the case and it needs to have the
*  scientific citations. And if I do the letter really well, it's going to get paid for it. If I don't
*  do the letter really well, it's not going to get paid for it. It's going to matter, you know, to
*  the life of the patient. And so he's like, it turns out GPT is really good at writing those letters.
*  With the references.
*  With the references, yes. With the scientific references, like full on, right? And so you've
*  got this, that's another way to think about it is you've got this bureaucratic process,
*  which is legitimate and required, it needs to exist. And that data needs to be submitted. And
*  honestly, it does not matter to that process whether that document is written by human or
*  machine. But all of a sudden, if every doctor in the world is really good at writing correctly,
*  those letters, then all of a sudden, it goes to the thing. All of a sudden that doctor now is
*  another, you know, whatever, four hours a week to actually take care of patients. Like that's the
*  kind of thing that I think is going to happen quite quickly. And that was interesting. What was
*  interesting about that example is you can imagine that example having a big impact on the efficiency
*  of the healthcare system today without any regulatory changes. Yes. Without any changes.
*  It's within the system.
*  Within the system, working within the system. And so, and that was just, and that was the one
*  where it's just like, oh, in retrospect, that's obvious. I just haven't thought about it. One guy
*  thinks about it. All the other doctors start to do that. The whole system upgrades, stuff function,
*  one time. That kind of thing, I think, is a real possibility.
*  Yeah. And that could be because someone's working within the system, you can have the
*  transformation immediately. But then eventually someone has to read all those letters. Someone
*  has to validate them. It's probably, you know, some sort of NLP on the other side.
*  Well, that's right. It's corresponding. So there's, we have this company,
*  this company called Do Not Pay, which is this company. It's an app that sort of acts like a bot.
*  I've used the app. It's pretty nice.
*  It's for people to try it. And it basically, it'll basically get you, it started to get you
*  like out of, it was starting to get you out of like basically sort of BS traffic tickets. And then
*  it's, he did this thing a while ago where it will unsubscribe you for, you know, all these
*  consumer subscription services like Comcast or whatever, like they all make it hard to like ever
*  turn off the subscription. And so he has this way to, the bot will do it for you. And so he just
*  started using AI in the bot. And so he now, so the way a lot of consumer subscription companies work
*  is you can't, you can subscribe online. You can't actually unsubscribe online. You have to call an
*  800 number and you have to argue with the person. And there's actually this thing in these companies
*  called Save Teams where they're actually paid specifically to prevent you from unsubscribing.
*  And they'll try to cut special deals with you and they'll try to talk you out of it.
*  And so he has this thing wired up where now he has the, he has AI generated text with,
*  with then text to speech. Oh, it's just talking. And it talks, and it talks, it talks to the customer
*  service person at the end of the line. And basically with infinite patience. And so it will just sit
*  and it will just argue like, no, I am actually going to unsubscribe for this. No, I'm not going
*  to accept your special offer. No, no, no, no, no. Right. Yeah, exactly. Until finally the other guy,
*  finally, you know, the guy gives up and says, okay, fine, I'll take it. I'll stop charging you.
*  And so it's like, okay, you know, it was, it was a precondition of the system that that worked the
*  way that it did. It was a burden on people to have to deal with that AI can now step in and equalize
*  the power imbalance between the customer and the company. And presumably that will change the system.
*  Yeah. Well, one would think, right? Yeah. Yeah. Yeah. Yeah. And to your point, like step one for
*  changing the system might be retaliation, which is all of a sudden the save teams will be bots.
*  And so maybe the bots will be arguing with the bots, but at least it gets you out of this kind
*  of Kafka-esque thing you're in today, where when you deal with these big companies, you're dealing
*  with this giant, you're an individual dealing with a giant bureaucracy. At least it like equalizes
*  the power. Well, that's kind of amazing. And that will be the spark for changing things.
*  Because once you're in that sort of system, like we got to do better than this. Yeah, this is crazy.
*  It's having bots argue with each other all day long. It's just clearly stupid. Yeah. Yeah. Yeah.
*  And especially when it's bots on both sides, now we can finally say, well, let's do an API on both
*  sides. So let's do something smart on both sides. Yeah. Just connected. Yeah. Yeah. Yeah. Well,
*  Mark, I mean, that's such a sort of beautiful, optimistic view of how this could go, right?
*  Because the future we're talking about is actually much more engineer driven that if an engineer can
*  build this and it really, really works, it really helps patients. It really changes things. It'll
*  get adopted as it gets adopted cultural work around it and we'll love it and we'll not want
*  to go back. And then the future will just be right in front of us. Yeah. I mean, patients are going
*  to get a vote. Yes. Doctors are going to get a vote. Right. Yeah. And you know, this, you know,
*  look, it's an, it's an industry made up of people, a world made up of people. People will get a vote.
*  Yeah. Beautiful. Thank you so much for joining us. Good. Yeah. You bet.
