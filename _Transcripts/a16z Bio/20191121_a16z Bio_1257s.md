---
Date Generated: May 30, 2024
Transcription Model: whisper medium 20231117
Length: 1257s
Video Keywords: []
Video Views: 13062
Video Rating: None
---

# AI is Industrializing Discovery
**a16z Bio:** [November 21, 2019](https://www.youtube.com/watch?v=yEFXgSV9soM)
*  Hi, my name is Vijay Pandey.
*  I'm a journal partner and recent Horowitz and founder of the biofund.
*  Today what I want to talk about is how AI is industrializing discovery.
*  This is the last holiday season.
*  I actually just randomly found this book and it really was intriguing.
*  This was Alan Greenspan and Adrian Wuldridge's book of the history of capitalism in America.
*  Their key point about this was the following is that when you think about industrial revolutions,
*  there's this key shift from the sort of bespoke artisan approach to making things or doing
*  things to an industrial process.
*  This is a critical shift in just how you completely think about a process.
*  Now it's well known that historically there are actually not everyone was happy with this.
*  In fact, before Luddite was a term, a drug and her term slung at other people, there
*  actually were literal Luddites who would come into factories and actually destroy them because
*  they felt that this was destroying a key part of the way of life and that industrializing
*  was actually not the right direction to go.
*  So Greenspan further makes a really interesting point about the difference between the industrial
*  revolution in America and the adoption of the products of it versus Europe.
*  So the point he made was actually that the adoption of these products from factories
*  was much greater in America than Europe.
*  I can only imagine that America is a very young country at the time.
*  We're talking about mid to late 1800s.
*  You're making a chair in Europe, maybe a chair or something that because of the wealth and
*  because of expectations, because of the history, a chair is something beautiful and artisanal.
*  In America, people just need a place to sit.
*  And therefore they were much more willing to adopt this new technology.
*  And part of the problem is that, and the reason why there was so much pushback is that typically
*  at first industrial products are worse.
*  That the chairs, the tables being made from these factories are not beautiful artisanal
*  bespoke things.
*  You know, kind of crude looking, kind of ugly, but much cheaper and in time actually kicking
*  into perhaps the most important aspect in the industrial revolution, which is connecting
*  to a feature that is often attributed to Einstein.
*  Einstein is often quoted as saying that the most powerful force in the universe is compound
*  interest.
*  There's an engineering aspect of compound interest.
*  That is the fact that when you can engineer something, when you can industrialize something,
*  you can make it better, you know, 10% year over year or 20% year over year.
*  And with that type of interest rate, so to speak, something that starts off kind of crappy,
*  kind of ugly or just basic can get cheaper exponentially, can get better exponentially
*  just with improvements year after year after year.
*  And that combination is the part that's where this gets really exciting.
*  No one's excited about the fact that they start off poorly.
*  We're excited about where this ends up.
*  This was one industrial revolution I was talking about, you know, in terms of making
*  factories.
*  And, you know, factories kind of is an amazing thing because it is this mental shift from
*  artisanal bespoke to industrialized.
*  It's the ability for actually for us to scale and for us to do things at scales that we
*  couldn't do any other way.
*  And there's been many different industrial revolutions.
*  And if you think about the hallmarks of each one of them, there's a couple of different
*  things that we've seen.
*  So first off, the science has to be born out.
*  So, you know, when we think about another industrial revolution associated with steam
*  engines, there's a lot of science associated with steam engines.
*  It wasn't that these companies were sort of doing major scientific studies to understand
*  steam engines because that was critical for building them.
*  You know, the basics were there such that the science was not the limiting part.
*  And not to say actually that all the science was understood, but that enough of it was
*  understood that you can start to industrialize it.
*  There would be new science discoveries along the way, system mechanics and thermodynamics
*  being one of them.
*  But that actually wasn't critical for engineering.
*  And so the second part, in addition to the ability for the science to be reasonably well
*  borne out, is that it has to be engineerable.
*  That there has to be enough dials, enough tweaks, enough different things that you can
*  work on to modify such that you can get your 10%, 20% year over year improvement.
*  And you know, if you look at more recent things like Moore's law or the exponential decrease
*  in the cost of genomics, it wasn't any one thing in each of these cases.
*  And there are many things in material science, in electrical engineering, in optics, many
*  different advances that multiply it up to that 20% year over year.
*  The key part is that you have those knobs that you can turn.
*  So you put these things together, it's really intriguing to think about them in the current
*  context of where we are in the healthcare system.
*  And you know, thinking about it, it really seems clear that we are in the middle of an
*  industrial revolution and that it is artificial intelligence, machine learning that is in
*  industrializing discovery itself.
*  So I want to unpack this statement.
*  So first off, what does it mean to be industrializing discovery?
*  What that means is that this intellectual process of discovering new drugs, diagnostics,
*  and even thinking about the healthcare system itself, this is something that used to be
*  a bespoke process, something that you would think about done by PhD scientists in the
*  labs, starting from a clean sheet of paper, trying to understand biology, which is a very
*  complicated thing.
*  That act of discovery now is something that we're starting to see really greatly enhanced
*  and in particular industrialized by artificial intelligence.
*  And I'll go into some details of that in a second.
*  The second part I want to unpack here is the tense.
*  So I didn't say AI has industrialized discovery or AI will industrialize discovery.
*  I say that it is industrializing, that we are in the middle of this now.
*  This is something that has already started.
*  We've seen the evidence of that.
*  And it could take two decades.
*  It could take maybe more for this to complete.
*  And so it's a really special time historically that we're in the middle of this industrial
*  revolution.
*  And that itself also has important implications.
*  Okay.
*  So what's the evidence of this?
*  Well, if you think about what we're starting to see, we're starting to see companies that
*  are applying AI very broadly.
*  So in some cases, we're seeing applications of artificial intelligence to synthesis of
*  small molecule drugs, to identification of lead compounds or even lead optimization in
*  medicinal chemistry.
*  We're seeing examples of companies that are industrializing biomarker discovery.
*  Biomarkers are typically not very accurate.
*  Like a PSA test is roughly 50% accurate.
*  These new AI discovered biomarkers are considerably more accurate with sensitivity and specificities
*  in the 90s.
*  And the key part of this is that it's industrialized.
*  That what you learn to make a PSA test doesn't tell you anything about a colorectal cancer
*  test.
*  The ability to industrialize this means coming up with a colorectal cancer test will allow
*  you to develop a process to repeat this in other tests as well.
*  So a great example, this is a company called Freenome.
*  And finally, I think we're also seeing AI apply to the healthcare delivery.
*  And so thinking about managing healthcare treatment, whether that would be thinking
*  about which drugs to give patients and cancer patients, what type of other treatments to
*  get, how to schedule treatments.
*  These things are very natural given the data-driven nature of healthcare today.
*  So what they all have in common is this industrialization of discovery that I've been talking about.
*  Okay, so given that we're in the middle of this, it's interesting to think of what we
*  need to do and what the future requires.
*  And we're not done.
*  When I look at this, I see a couple key challenges still remaining that people have made a lot
*  of progress into, but that I think are going to be the key areas of the future.
*  And we're going to see new companies and new technologies develop to tackle this.
*  First off is that biology itself is really difficult to sort of connect into a computer.
*  It's not as clean as images or something like that.
*  And we'll talk about that.
*  Secondly, often biology has very small data sets, and that's a real challenge.
*  And a differentiator from other areas in AI.
*  And finally, there's a lot of information that you have to learn to get to a PhD level.
*  And so if somehow AI is going to be able to compete with this, there's going to have
*  to be a lot of pre-training involved and a natural way to do that.
*  Maybe before even going into these medical examples, I want to sort of give you an example
*  of what it looks like for what AI can do and why this is special and why this is interesting.
*  Okay, so let's take a look at it.
*  So this is an example of deep learning.
*  So what is deep learning?
*  It's a series of neural networks.
*  And on the bottom is where the data goes in.
*  So that's where if we're going to apply this to images and recognizing what's in images,
*  let's say in facial recognition, on the bottom comes pixels, like just a raw image.
*  And then as the data moves up the different compute levels of a neural net, what happens
*  is that it builds a hierarchical understanding of how to put these pieces together.
*  So it starts by putting pixels together into shapes.
*  These shapes become features.
*  These features get put together into faces.
*  And then that's how you can recognize a specific face like Bob here.
*  The really intriguing thing and the key difference between deep learning versus other areas in
*  computer vision is that we didn't teach the computer that noses exist or that eyes exist.
*  It learned that.
*  It learned the features along the way directly from the data.
*  And it's for that reason that the exact same process can be used not just for faces but
*  for cars or for elephants or for chairs.
*  It's completely repeatable.
*  Okay, so this alone is actually really intriguing for biology and healthcare because so much
*  of biology and healthcare is images.
*  Thinking about microscopy, radiology, pathology, and exactly what you've seen here is already
*  starting to have a huge impact in the technology applied to those fields.
*  And that's one discussion we can have.
*  That's exciting in many ways, but that's really just the beginning because images as great
*  as they are, are not the only data obviously that we have to deal with.
*  One thing that's interesting to think about is that you can think of DNA almost like a
*  one-dimensional image.
*  And so you can use the exact same technology now to put in DNA sequences.
*  And maybe now you're not identifying a face, you're identifying whether someone has cancer
*  from circulating tumor cell DNA.
*  Okay, so those are two examples of how images and maybe DNA sequences can be really learned
*  and we can recognize things using these new AI techniques.
*  What I want to do after that introduction is to go through where we are right now and
*  especially a lot of the concerns that people have about why this technology might not be
*  applicable.
*  And we're actually, this new technology is actually very much breaking through those
*  myths.
*  So, like one myth that people have is that if you think about the difference between
*  AI and human beings, that human beings have intuitive grasp of molecules and that molecules
*  are just not going to be like images.
*  It's going to be much, much harder.
*  They're much more complex.
*  And this is where it's intriguing that there's a lot of different advances here.
*  One of my favorites is the use of representing molecules as graphs.
*  And graphs are also very natural computer science objects and perfect representation
*  for many aspects of chemistry as well.
*  And you can ask, well, okay, let's change representation to graphs.
*  If we do this, it turns out that we can use essentially the same analogous machinery that
*  you'd apply to images, so-called convolutional neural nets, but now onto graphs, so graph
*  convolutions.
*  And actually, if you apply graph convolutions as Evan Feinberg did in this ACS Central Science
*  paper in 2018, actually you can have a huge impact in terms of prediction comparing typical
*  machine learning methods like random forest, which is a typical state of the art for most
*  people using computational drug design to what you could do with these new advanced
*  methods.
*  The ability to predict goes up dramatically.
*  A second myth is that people don't need 10,000 data points to learn.
*  And when computers learn about images, let's say work from Google or from others, they
*  often have 1,000, 10,000 images you can train.
*  So you can train like this is a cat, this is a car, this is a pizza, you have 10,000
*  pictures of pizzas that it can learn from.
*  Well, in drug design, you don't have that luxury because by the time you have 10,000
*  active drugs, you don't need another one.
*  We don't even have 10,000 active drugs.
*  So we have to be able to do with many fewer data points and maybe even just one or two
*  data points.
*  And here's interesting to see where other areas of AI is starting to be applied into
*  drug design.
*  So this is an example of so-called one-shot learning.
*  So one-shot learning I think is really fascinating because it takes things that is very intuitive
*  to us about how we learn and applies to computers.
*  If you think about like how a baby learns, you don't have to show a baby 10,000 pictures
*  of a soccer ball or 10,000 pictures of an elephant.
*  You can show the soccer ball and say ball.
*  You can show them the elephant and say elephant.
*  And you can show another picture of an elephant, the baby will understand that's different
*  than a soccer ball.
*  It takes maybe just one shot, two shots.
*  It doesn't take a lot.
*  And you're starting to sort of understand the space of pictures and have a sort of a
*  metric for similarity that this picture of this elephant and elephant, these are close
*  enough and elephant to ball, those are fundamentally different.
*  And there's ways essentially to use AI to learn this type of metric to see whether two
*  things are going to be similar or not and not apply to pictures but apply to drugs.
*  And so what's intriguing here is that if you look at the results, you don't have to have
*  a lot of data either for a tox 21, toxicity.
*  You can have even in one case like just one positive and one negative and that these AUCs
*  area in the curves, which vary from 0.5 for just pure random, unpredictable results to
*  1.0, which is like a perfect predictor.
*  You can go from random forest being pretty close to just random with one positive and
*  one negative to these newer methods that get AUCs way up there considering that there's
*  so little data.
*  Okay, so third myth is that when you think about how people bring, they have some understanding
*  of the fundamentals, some knowledge that they can use and they come not as empty vessels
*  but with a lot of information.
*  And this is an area that in computer science is associated with so-called pre-training.
*  And so there's different ways to pre-train.
*  And essentially the idea is that by pre-training, you can take the large body of codified knowledge
*  or sometimes even uncodified knowledge, unlabeled data, and through pre-training schemes, you
*  allow the learning to both achieve a higher result that the performance is better of these
*  algorithms and it takes much less data to get there.
*  And so in recent results where actually small molecule drugs, their properties were predicted
*  with pre-training where the pre-training was actually not even with labeled data, with
*  pre-training with just understanding the nature of chemistry from just going through lots
*  of molecules, one can actually show that pre-training actually can make a huge impact in terms of
*  predictivity here as well.
*  One last myth to cover would be that when we think about how human beings deal with
*  small molecule drugs, they often have this intuition and they can combine different insights
*  in different ways that is just going to be really hard for computers to do.
*  And it's hard to sort of come up with something dramatically new.
*  And here's actually where I think it's going to be interesting to think about combining
*  areas of machine learning and AI with physics.
*  And so I talked about representation of small molecules as graphs.
*  You could also represent them by electron densities and this is a very natural representation
*  for a chemist.
*  If you look at actually the ability to represent these things in that way and then combine
*  a new physical theories, especially in this case, it's a physical theory using a variant
*  of cone-cham equations and train with computer data for quantum mechanics.
*  This new type of representation actually and new type of bringing together of physics and
*  machine learning can yield considerably more accurate results than previous attempts that
*  either just motivated by a sort of machine learning alone or by physics alone.
*  Okay, so I went through some myths.
*  There's a lot of things that had really exciting time in terms of all the different progress
*  that's happening.
*  And so we could spend hours talking about this, but hopefully you've got some sense
*  that there's a huge amount of work that's being done and that a lot of the challenges
*  actually that people would associate with machine learning in this space are being knocked
*  down one after the other after the other.
*  And what this is allowing us to do is that it's allowing us to rethink the whole process.
*  It's creating this aspect of where the machine can actually discover things, identify things.
*  It can learn features.
*  It can put together new insights to identify cancer in ways that no human being would have
*  a biomarker to be able to identify small molecule drugs by understanding different chemical
*  groups to put together.
*  It's essentially taking discovery and automating it, industrializing it.
*  Okay, so if discovery itself is being industrialized, what is this going to look like and what does
*  this mean?
*  You know, so one of the key things is that so much of discovery is done through an apprenticeship
*  model, a guild model.
*  Before coming to Andreessen Horowitz, I was a professor at Stanford for nearly 20 years
*  with many graduate students and postdoctoral fellows and so on.
*  And so that's very much an apprenticeship.
*  I myself got my PhD.
*  People get MDs and so on.
*  And this is handing down information from one person to another.
*  So I suspect that that's going to change to some degree, but what is the future going
*  to look like?
*  Is it going to go from apprenticeship to just computers?
*  Does industrialization here look like sort of removing the people from the equation?
*  Well, actually, I can't imagine that's going to be the case.
*  And you know, that's not what factories look like.
*  It's a combination of leveraging what human beings can do and allowing them to scale.
*  And so the industrialization of discovery is going to take people and give them superpowers
*  that they didn't have before and allow them to scale.
*  And it's going to be this combination of AI machine learning with things like robotic
*  data generation and people driving this and asking the right questions, this sort of industrialization
*  of discovery of the future.
*  So what do we see?
*  What do we get out of all this?
*  One example of something that we're always trying to see is the ability to predict clinical
*  trials from early stages in drug design.
*  So, you know, clinical trials are extremely expensive.
*  Just improving them 5%, 10% would be worth a huge amount of money.
*  Being able to speed them up 5% or 10% would be worth a huge amount of money in blockbusters.
*  And the ability to use early data from preclinical to predict phase one, to use phase one to predict phase two.
*  These are things that are very natural to do and machine learning could be very powerful in them.
*  And you know, the bar is not that high.
*  It's not like you have to be able to predict all clinical trials perfectly.
*  Because of the cost, even modest increases in accuracy of prediction or just prioritization
*  could bring drugs to market much faster, much cheaper, and could have a huge impact on human care.
*  As part of this, I think what we could start to do is thinking about animal models very differently.
*  Both animal models and ex vivo organoid-like models that we're not going to think about
*  these models as some sacrosanct up or down vote.
*  That they are basically going to be features in machine learning where you're going to
*  have this as the inputs and label data in humans from previous experiments to be able
*  to combine that to make predictions from mice to humans without actually having to go into
*  humans with much higher accuracy.
*  Another area that sounds pretty pedestrian but I think is going to have a huge impact
*  is going to be in decreasing the cost of proteins and protein therapeutics.
*  So seven of the top ten drugs right now are antibody protein drugs.
*  Right now these things are expensive to make.
*  If you could use machine learning methods to decrease the cost, and there's a lot of
*  reason to think the cost could go down by half or a fifth or even a tenth, that would
*  have a huge impact on drugs as well as all the different proteins that are used in the
*  biotechnology tool chain.
*  So with that, hopefully I've given you some sense of where we are, what are the challenges
*  that people point to and that might think that we're sort of not in the middle of this,
*  why I think we're starting to see them knock down, and where the future of this lies.
*  You know, if there was a single take-home message that I really want to emphasize, it's
*  the fact that we are in the middle of this revolution right now.
*  This is something that it's a really unusual thing in part of human history and it's part
*  of the exciting time.
*  And it's a time where if you can connect machine learning and artificial intelligence and have
*  skills in that area with a deep domain experience into a biopharm or a healthcare, any of those
*  domains, it's a very exciting time to put those things together, to be able to take
*  what used to be a bespoke human process to discovery, industrialize it, scale it, and
*  do things that we've only dreamed of in the past.
